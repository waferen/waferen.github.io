<!DOCTYPE html> <html><head>
		<title>VideoCLIP</title>
		<base href="..\..\../">
		<meta id="root-path" root-path="..\..\../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="note - VideoCLIP">
		<meta property="og:title" content="VideoCLIP">
		<meta property="og:description" content="note - VideoCLIP">
		<meta property="og:type" content="website">
		<meta property="og:url" content="project/大二论文/论文/videoclip.html">
		<meta property="og:image" content="lib\media\pasted-image-20231128211925.png">
		<meta property="og:site_name" content="note">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="stylesheet" href="lib/styles/theme.css"><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript></head><body class="publish css-settings-manager theme-dark show-inline-title show-ribbon"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles">mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mi{display:inline-block;text-align:left}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mn{display:inline-block;text-align:left}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("lib/fonts/mathjax_zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("lib/fonts/mathjax_main-regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("lib/fonts/mathjax_main-bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("lib/fonts/mathjax_math-italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("lib/fonts/mathjax_main-italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("lib/fonts/mathjax_math-bolditalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("lib/fonts/mathjax_size1-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("lib/fonts/mathjax_size2-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("lib/fonts/mathjax_size3-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("lib/fonts/mathjax_size4-regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("lib/fonts/mathjax_ams-regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("lib/fonts/mathjax_calligraphic-regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("lib/fonts/mathjax_calligraphic-bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("lib/fonts/mathjax_fraktur-regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("lib/fonts/mathjax_fraktur-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("lib/fonts/mathjax_sansserif-regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("lib/fonts/mathjax_sansserif-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("lib/fonts/mathjax_sansserif-italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("lib/fonts/mathjax_script-regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("lib/fonts/mathjax_typewriter-regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("lib/fonts/mathjax_vector-regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("lib/fonts/mathjax_vector-bold.woff") format("woff")}mjx-c.mjx-c1D464.TEX-I::before{padding:.443em .716em .011em 0;content:"w"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c1D465.TEX-I::before{padding:.442em .572em .011em 0;content:"x"}mjx-c.mjx-c2B::before{padding:.583em .778em .082em 0;content:"+"}mjx-c.mjx-c32::before{padding:.666em .5em 0 0;content:"2"}mjx-c.mjx-c2E::before{padding:.12em .278em 0 0;content:"."}mjx-c.mjx-c1D45B.TEX-I::before{padding:.442em .6em .011em 0;content:"n"}mjx-c.mjx-c2217::before{padding:.465em .5em 0 0;content:"∗"}mjx-c.mjx-c2212::before{padding:.583em .778em .082em 0;content:"−"}mjx-c.mjx-c1D44F.TEX-I::before{padding:.694em .429em .011em 0;content:"b"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}mjx-c.mjx-c30::before{padding:.666em .5em .022em 0;content:"0"}</style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="Abstract">Abstract</h1><div class="el-p"><p dir="auto"><a href="?query=tag:%E9%A1%B9%E7%9B%AE/%E4%B8%AA%E4%BA%BA%E9%A1%B9%E7%9B%AE/%E5%A4%A7%E4%BA%8C%E8%AE%BA%E6%96%87/%E8%AE%BA%E6%96%87" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大二论文/论文</a><br>
VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding<br>
关于<a data-href="CLIP" href="project/知识储备/clip.html" class="internal-link" target="_self" rel="noopener nofollow">CLIP</a><br>
论文地址：<strong><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2109.14084.pdf" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2109.14084.pdf" target="_blank">https://arxiv.org/pdf/2109.14084.pdf</a></strong></p></div><div class="el-p"><p dir="auto">代码地址：<strong><a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//github.com/pytorch/fairseq/tree/main/examples/MMPT" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//github.com/pytorch/fairseq/tree/main/examples/MMPT" target="_blank">https://github.com/pytorch/fair</a></strong></p></div><div class="el-h1 heading-wrapper"><div class="heading-children"><div class="el-p"><p dir="auto">在本文中，作者提出了VideoCLIP，这是一种不需要下游任务的任何标签，用于预训练零样本视频和文本理解模型的对比学习方法。VideoCLIP通过<strong>对比时间重叠的正视频文本对</strong>&nbsp;和<strong>最近邻检索的负样本对</strong>&nbsp;，训练视频和文本的Transformer。在本文中，作者对一系列下游任务（包括序列级文本视频检索、VideoQA、token级动作定位和动作分割）进行了实验，实验结果表明本文提出的VideoCLIP可以达到SOTA的性能，在某些情况下甚至优于监督方法。</p></div></div></div><div class="el-h1 heading-wrapper"><h1 data-heading="Motivation" dir="auto" class="heading" id="Motivation">Motivation</h1><div class="heading-children"><div class="el-p"><p dir="auto">练+微调”的训练范式对NLP和CV领域进行了革新。尽管以这种方式训练的模型可以获得不错的性能，但它们 仍然需要特定于任务的标注数据，并需要基于每个下游任务进行微调。<br>
基于这样的问题，最近也有一些工作<em>致力于研究无需微调的零样本迁移到下游任务的预训练</em>，比如NLP领域中GPT，CV领域中的CLIP。<br>
在本文中，作者<em>主要研究零样本迁移到视频文本理解任务的预训练</em>。本文的方法使用成对的视频文本 clip，基于对比学习的目标函数，对Transformer结构进行预训练。本文的VideoCLIP基于一个公开的预训练数据集HowTo100M来使模型能够获得视频理解的能力。实验表明，所得到的预训练模型可以直接应用于或通过微调应用于一系列视频文本任务。<br>
作者发现，简单直接的目标函数会导致较差的结果，并认为<em>学习视频和文本之间的细粒度关联对于零样本迁移到下游任务至关重要</em>，因为下游任务可能需要不同粒度的视频文本交互。以前的工作是在随机batch中对短时间的、对齐的视频和文本片段进行采样，但没有学习视频帧和单词token之间的细粒度关联。<br>
<span alt="Pasted image 20231128211925.png" src="Pasted image 20231128211925.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231128211925.png" src="lib/media/pasted-image-20231128211925.png"></span><br>
在本文中，作者提出了VideoCLIP，使用了两种关键技术（如上图所示）来计算训练目标，通过对比学习来预训练统一的视频文本表示。<br>
首先，作者的目标是改善视频和文本与不同序列长度的关联。尽管大多数视频和文本没有语义对齐，但当前的视频文本模型是通过精确的时间对齐进行训练的。因此，多个或更长的文本clip能与视频clip很好地对齐，但是许多视频clip并可能没有任何相应的文本。<br>
为了解决这些问题，<strong>作者使用临时重叠的视频和文本clip对进行预训练（如上图所示），从而大大提高视频文本对齐的质量和数量</strong>&nbsp;。其次，作者收集更难的负样本对，从对比损失函数中学习细粒度视频文本相似度。现有的工作通过从同一视频中采样多个视频片段来对比视频内的片段，但作者发现从其他视频中挖掘片段可以提供更具挑战性的负样本对。因此，<strong>作者提出了一种检索增强预训练方法来检索每个训练batch中相似的视频</strong>&nbsp;。</p></div><div class="el-h2 heading-wrapper"><h2 data-heading="问题一：这里的使用临时重叠的视频和文本clip对中临时重叠是什么意思？" dir="auto" class="heading" id="问题一：这里的使用临时重叠的视频和文本clip对中临时重叠是什么意思？"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>问题一：这里的使用临时重叠的视频和文本clip对中临时重叠是什么意思？</h2><div class="heading-children"></div></div></div></div><div class="el-h1 heading-wrapper"><h1 data-heading="Technology" dir="auto" class="heading" id="Technology">Technology</h1><div class="heading-children"><div class="el-p"><p dir="auto">在零样本迁移的多模态视频文本预训练范式中，关键的挑战是学习视频和文本之间的细粒度关联，以满足下游任务的不同需求。在本节中，作者首先介绍视频和文本模型的主干网络和<a data-href="对比损失函数" href="project/知识储备/对比损失函数.html" class="internal-link" target="_self" rel="noopener nofollow">对比损失函数</a>；然后，提出重叠的视频和文本clip，以提高正样本对的关联性；最后，介绍了检索增强的预训练，以改进负样本对的挖掘。</p></div><div class="el-h2 heading-wrapper"><h2 data-heading="3.1 Video and Text Encoding" dir="auto" class="heading" id="3.1_Video_and_Text_Encoding"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>3.1 Video and Text Encoding</h2><div class="heading-children"><div class="el-p"><p dir="auto">Video and Text Transformers<br>
<span alt="Pasted image 20231204101318.png" src="Pasted image 20231204101318.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231204101318.png" src="lib/media/pasted-image-20231204101318.png"></span><br>
注意：使用S3D卷积对视频clip进行信息提取，生成tokens</p></div><div class="el-p"><p dir="auto">使用均值池化而不是CLS标记来鼓励文本transformer和视频transformer学习标记级别的表征，可能对动作定位和动作分段有益。在实验中，作者发现共享两个transformer的参数只比不共享的效果差了一点。</p></div><div class="el-p"><p dir="auto">值得注意的是，使用冻结的S3D权重参数能够建模长期的视觉文本一致性（大约32s），而典型的video CNNs只能捕获大约3s的时间窗口。</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="3.2 Contrastive Loss" dir="auto" class="heading" id="3.2_Contrastive_Loss"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>3.2 Contrastive Loss</h2><div class="heading-children"><div class="el-p"><p dir="auto"><span alt="Pasted image 20231204101401.png" src="Pasted image 20231204101401.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231204101401.png" src="lib/media/pasted-image-20231204101401.png"></span><br>
<a data-href="对比损失函数" href="project/知识储备/对比损失函数.html" class="internal-link" target="_self" rel="noopener nofollow">对比损失函数</a></p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="3.3 Overlapped Video-Text Clips" dir="auto" class="heading" id="3.3_Overlapped_Video-Text_Clips"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>3.3 Overlapped Video-Text Clips</h2><div class="heading-children"><div class="el-p"><p dir="auto">首先，现有的很多预训练方法关注时序上精确对齐的视频文本对，它们的起止时间完全一致。大多数视频和文本并没有语义对齐，但现在的模型以精确的时序对齐来进行训练。比如一个人在说话，内容是“我去给你展示如何做炒饭”，这个片段和这个内容描述在语义上并不对齐，而随后一个米饭在锅中的片段可能与这个内容描述具有较高的相关性。因为人类很少同时说话和进行对应的动作。所以采取时间对齐可能导致多个或者较长的文本与一个视频具有更好的一致性，但是许多视频可能没有对应的字幕描述。因为在短片段中，时间上对齐的视频文本对在语义上也接近的可能性很小。该论文按照以下方法建立重叠的正样本对：</p></div><div class="el-p"><p dir="auto">1）采样一个文本段（先采样一个视频可能没有邻近的相应文本）</p></div><div class="el-p"><p dir="auto">2）在文本段的时间边界内取样一个时间戳作为视频片段的中心；</p></div><div class="el-p"><p dir="auto">3）从这个中心时间戳开始，裁剪出一个具有随机持续时间的视频片段（最长32s）</p></div><div class="el-p"><p dir="auto">该方法提高了视频和文本的相关性，并鼓励细粒度的关联。</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="3.4 Retrieval Augmented Training" dir="auto" class="heading" id="3.4_Retrieval_Augmented_Training"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>3.4 Retrieval Augmented Training</h2><div class="heading-children"><div class="el-p"><p dir="auto">通过使用对比预训练目标中更困难的负样例，可以学习建立更细粒度的视频文本相似性模型。因此作者在训练batch中使用难负例样本 ，它们在语义上与正例的样本对相关，这些难负例是通过检索采样得到的。</p></div><div class="el-p"><p dir="auto">本文的方法旨在通过视频聚类来构建一个batch的训练样本，因此作者将其建模成了在视频潜在空间中进行检索的任务。整个训练过程可以看成是一个二阶段的方法，在每个迭代过程中交替执行检索和训练任务，如下图所示：<br>
<span alt="Pasted image 20231204101424.png" src="Pasted image 20231204101424.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231204101424.png" src="lib/media/pasted-image-20231204101424.png"></span><br>
Retrieval Augmented Training 使用更困难的负样本对来建模视频和文本之间的细粒度关联。使用基于检索的采样，获取与正样本对语义上类似的负样本对，来构建训练批次。负样本并不只来自于同一视频中，还从其他不同的视频中挖掘。训练过程可以归结为一个两阶段的方法：检索和训练，如上图所示。检索的方法如下：</p></div><div class="el-p"><p dir="auto">1）上面line2通过平均一个视频的所有视频和文本的向量表示，来计算一个视频的全局特征。通过消融试验证明了这样获得的视频特征比只取视频的开始片段来推断视频的表示效果更好。</p></div><div class="el-p"><p dir="auto">2）上面line3为所有在训练中用到的视频构建了一个密度索引。</p></div><div class="el-p"><p dir="auto">3）上面line4首先找到个随机的视频（对应训练集中的批次数量），其中每个视频会生成一个视频簇。我们从K个最邻近的视频中采样K个视频，而不是直接取样K个最邻近的视频。这是因为我们想要一个簇中的视频互相接近，而不是全部靠近。这样从一个视频中采样的所有视频/文本片段可以作为从另一个视频中采样的片段的负例。</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="3.5 对比损失" dir="auto" class="heading" id="3.5_对比损失"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>3.5 对比损失</h2><div class="heading-children"><div class="el-p"><p dir="auto">使用InfoNCE来学习视频文本的一致性，对比损失函数如下图所示，其中T是一个temperature超参数。<br>
<span alt="Pasted image 20231204101604.png" src="Pasted image 20231204101604.png" class="internal-embed media-embed image-embed is-loaded"><img alt="Pasted image 20231204101604.png" src="lib/media/pasted-image-20231204101604.png"></span></p></div><div class="mod-footer mod-ui"></div></div></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="project\大二论文\论文\videoclip.html#Abstract"><div class="tree-item-contents heading-link" heading-name="Abstract"><span class="tree-item-title">Abstract</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="project\大二论文\论文\videoclip.html#Motivation"><div class="tree-item-contents heading-link" heading-name="Motivation"><span class="tree-item-title">Motivation</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="project\大二论文\论文\videoclip.html#问题一：这里的使用临时重叠的视频和文本clip对中临时重叠是什么意思？"><div class="tree-item-contents heading-link" heading-name="问题一：这里的使用临时重叠的视频和文本clip对中临时重叠是什么意思？"><span class="tree-item-title">问题一：这里的使用临时重叠的视频和文本clip对中临时重叠是什么意思？</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div><div class="tree-item" data-depth="1"><a class="tree-link" href="project\大二论文\论文\videoclip.html#Technology"><div class="tree-item-contents heading-link" heading-name="Technology"><span class="tree-item-title">Technology</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="project\大二论文\论文\videoclip.html#3.1_Video_and_Text_Encoding"><div class="tree-item-contents heading-link" heading-name="3.1 Video and Text Encoding"><span class="tree-item-title">3.1 Video and Text Encoding</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\大二论文\论文\videoclip.html#3.2_Contrastive_Loss"><div class="tree-item-contents heading-link" heading-name="3.2 Contrastive Loss"><span class="tree-item-title">3.2 Contrastive Loss</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\大二论文\论文\videoclip.html#3.3_Overlapped_Video-Text_Clips"><div class="tree-item-contents heading-link" heading-name="3.3 Overlapped Video-Text Clips"><span class="tree-item-title">3.3 Overlapped Video-Text Clips</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\大二论文\论文\videoclip.html#3.4_Retrieval_Augmented_Training"><div class="tree-item-contents heading-link" heading-name="3.4 Retrieval Augmented Training"><span class="tree-item-title">3.4 Retrieval Augmented Training</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\大二论文\论文\videoclip.html#3.5_对比损失"><div class="tree-item-contents heading-link" heading-name="3.5 对比损失"><span class="tree-item-title">3.5 对比损失</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>