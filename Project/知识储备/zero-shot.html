<!DOCTYPE html> <html><head>
		<title>zero-shot</title>
		<base href="..\../">
		<meta id="root-path" root-path="..\../">
		<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes, minimum-scale=1.0, maximum-scale=5.0">
		<meta charset="UTF-8">
		<meta name="description" content="note - zero-shot">
		<meta property="og:title" content="zero-shot">
		<meta property="og:description" content="note - zero-shot">
		<meta property="og:type" content="website">
		<meta property="og:url" content="project/知识储备/zero-shot.html">
		<meta property="og:image" content="https://pic3.zhimg.com/v2-d8efa9870a3ce5ee028277ec57033036_b.webp?consumer=ZHI_MENG">
		<meta property="og:site_name" content="note">
		<link rel="alternate" type="application/rss+xml" title="RSS Feed" href="lib/rss.xml"><script async="" id="webpage-script" src="lib/scripts/webpage.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script type="module" async="" id="graph-view-script" src="lib/scripts/graph-view.js"></script><script async="" id="graph-wasm-script" src="lib/scripts/graph-wasm.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="graph-render-worker-script" src="lib/scripts/graph-render-worker.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="tinycolor-script" src="lib/scripts/tinycolor.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="pixi-script" src="https://cdnjs.cloudflare.com/ajax/libs/pixi.js/7.4.0/pixi.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><script async="" id="minisearch-script" src="https://cdn.jsdelivr.net/npm/minisearch@6.3.0/dist/umd/index.min.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><link rel="icon" href="lib/media/favicon.png"><script async="" id="graph-data-script" src="lib/scripts/graph-data.js" onload="this.onload=null;this.setAttribute(&quot;loaded&quot;, &quot;true&quot;)"></script><style>body{--line-width:40em;--line-width-adaptive:40em;--file-line-width:40em;--sidebar-width:min(20em, 80vw);--collapse-arrow-size:11px;--tree-horizontal-spacing:0.6em;--tree-vertical-spacing:0.6em;--sidebar-margin:12px}.sidebar{height:100%;min-width:calc(var(--sidebar-width) + var(--divider-width-hover));max-width:calc(var(--sidebar-width) + var(--divider-width-hover));font-size:14px;z-index:10;position:relative;overflow:hidden;transition:min-width ease-in-out,max-width ease-in-out;transition-duration:.2s;contain:size}.sidebar-left{left:0}.sidebar-right{right:0}.sidebar.is-collapsed{min-width:0;max-width:0}body.floating-sidebars .sidebar{position:absolute}.sidebar-content{height:100%;min-width:calc(var(--sidebar-width) - var(--divider-width-hover));top:0;padding:var(--sidebar-margin);padding-top:4em;line-height:var(--line-height-tight);background-color:var(--background-secondary);transition:background-color,border-right,border-left,box-shadow;transition-duration:var(--color-fade-speed);transition-timing-function:ease-in-out;position:absolute;display:flex;flex-direction:column}.sidebar:not(.is-collapsed) .sidebar-content{min-width:calc(max(100%,var(--sidebar-width)) - 3px);max-width:calc(max(100%,var(--sidebar-width)) - 3px)}.sidebar-left .sidebar-content{left:0;border-top-right-radius:var(--radius-l);border-bottom-right-radius:var(--radius-l)}.sidebar-right .sidebar-content{right:0;border-top-left-radius:var(--radius-l);border-bottom-left-radius:var(--radius-l)}.sidebar:has(.sidebar-content:empty):has(.topbar-content:empty){display:none}.sidebar-topbar{height:2em;width:var(--sidebar-width);top:var(--sidebar-margin);padding-inline:var(--sidebar-margin);z-index:1;position:fixed;display:flex;align-items:center;transition:width ease-in-out;transition-duration:inherit}.sidebar.is-collapsed .sidebar-topbar{width:calc(2.3em + var(--sidebar-margin) * 2)}.sidebar .sidebar-topbar.is-collapsed{width:0}.sidebar-left .sidebar-topbar{left:0}.sidebar-right .sidebar-topbar{right:0}.topbar-content{overflow:hidden;overflow:clip;width:100%;height:100%;display:flex;align-items:center;transition:inherit}.sidebar.is-collapsed .topbar-content{width:0;transition:inherit}.clickable-icon.sidebar-collapse-icon{background-color:transparent;color:var(--icon-color-focused);padding:0!important;margin:0!important;height:100%!important;width:2.3em!important;margin-inline:0.14em!important;position:absolute}.sidebar-left .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);right:var(--sidebar-margin)}.sidebar-right .clickable-icon.sidebar-collapse-icon{transform:rotateY(180deg);left:var(--sidebar-margin)}.clickable-icon.sidebar-collapse-icon svg.svg-icon{width:100%;height:100%}.sidebar-section-header{margin:0 0 1em 0;text-transform:uppercase;letter-spacing:.06em;font-weight:600}body{transition:background-color var(--color-fade-speed) ease-in-out}.webpage-container{display:flex;flex-direction:row;height:100%;width:100%;align-items:stretch;justify-content:center}.document-container{opacity:1;flex-basis:100%;max-width:100%;width:100%;height:100%;display:flex;flex-direction:column;align-items:center;transition:opacity .2s ease-in-out;contain:inline-size}.hide{opacity:0;transition:opacity .2s ease-in-out}.document-container>.markdown-preview-view{margin:var(--sidebar-margin);margin-bottom:0;width:100%;width:-webkit-fill-available;width:-moz-available;width:fill-available;background-color:var(--background-primary);transition:background-color var(--color-fade-speed) ease-in-out;border-top-right-radius:var(--window-radius,var(--radius-m));border-top-left-radius:var(--window-radius,var(--radius-m));overflow-x:hidden!important;overflow-y:auto!important;display:flex!important;flex-direction:column!important;align-items:center!important;contain:inline-size}.document-container>.markdown-preview-view>.markdown-preview-sizer{padding-bottom:80vh!important;width:100%!important;max-width:var(--line-width)!important;flex-basis:var(--line-width)!important;transition:background-color var(--color-fade-speed) ease-in-out;contain:inline-size}.markdown-rendered img:not([width]),.view-content img:not([width]){max-width:100%;outline:0}.document-container>.view-content.embed{display:flex;padding:1em;height:100%;width:100%;align-items:center;justify-content:center}.document-container>.view-content.embed>*{max-width:100%;max-height:100%;object-fit:contain}:has(> :is(.math,table)){overflow-x:auto!important}.document-container>.view-content{overflow-x:auto;contain:content;padding:0;margin:0;height:100%}.scroll-highlight{position:absolute;width:100%;height:100%;pointer-events:none;z-index:1000;background-color:hsla(var(--color-accent-hsl),.25);opacity:0;padding:1em;inset:50%;translate:-50% -50%;border-radius:var(--radius-s)}</style><script defer="">async function loadIncludes(){if("file:"!=location.protocol){let e=document.querySelectorAll("include");for(let t=0;t<e.length;t++){let o=e[t],l=o.getAttribute("src");try{const e=await fetch(l);if(!e.ok){console.log("Could not include file: "+l),o?.remove();continue}let t=await e.text(),n=document.createRange().createContextualFragment(t),i=Array.from(n.children);for(let e of i)e.classList.add("hide"),e.style.transition="opacity 0.5s ease-in-out",setTimeout((()=>{e.classList.remove("hide")}),10);o.before(n),o.remove(),console.log("Included file: "+l)}catch(e){o?.remove(),console.log("Could not include file: "+l,e);continue}}}else{if(document.querySelectorAll("include").length>0){var e=document.createElement("div");e.id="error",e.textContent="Web server exports must be hosted on an http / web server to be viewed correctly.",e.style.position="fixed",e.style.top="50%",e.style.left="50%",e.style.transform="translate(-50%, -50%)",e.style.fontSize="1.5em",e.style.fontWeight="bold",e.style.textAlign="center",document.body.appendChild(e),document.querySelector(".document-container")?.classList.remove("hide")}}}document.addEventListener("DOMContentLoaded",(()=>{loadIncludes()}));let isFileProtocol="file:"==location.protocol;function waitLoadScripts(e,t){let o=e.map((e=>document.getElementById(e+"-script"))),l=0;!function e(){let n=o[l];l++,n&&"true"!=n.getAttribute("loaded")||l<o.length&&e(),l<o.length?n.addEventListener("load",e):t()}()}</script><link rel="stylesheet" href="lib/styles/obsidian.css"><link rel="stylesheet" href="lib/styles/theme.css"><link rel="preload" href="lib/styles/global-variable-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/global-variable-styles.css"></noscript><link rel="preload" href="lib/styles/main-styles.css" as="style" onload="this.onload=null;this.rel='stylesheet'"><noscript><link rel="stylesheet" href="lib/styles/main-styles.css"></noscript></head><body class="publish css-settings-manager theme-dark show-inline-title show-ribbon"><script defer="">let theme=localStorage.getItem("theme")||(window.matchMedia("(prefers-color-scheme: dark)").matches?"dark":"light");"dark"==theme?(document.body.classList.add("theme-dark"),document.body.classList.remove("theme-light")):(document.body.classList.add("theme-light"),document.body.classList.remove("theme-dark")),window.innerWidth<480?document.body.classList.add("is-phone"):window.innerWidth<768?document.body.classList.add("is-tablet"):window.innerWidth<1024?document.body.classList.add("is-small-screen"):document.body.classList.add("is-large-screen")</script><div class="webpage-container workspace"><div class="sidebar-left sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"><label class="theme-toggle-container" for="theme_toggle"><input class="theme-toggle-input" type="checkbox" id="theme_toggle"><div class="toggle-background"></div></label></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="search-input-container"><input enterkeyhint="search" type="search" spellcheck="false" placeholder="Search..."><div class="search-input-clear-button" aria-label="Clear search"></div></div><include src="lib/html/file-tree.html"></include></div><script defer="">let ls = document.querySelector(".sidebar-left"); ls.classList.add("is-collapsed"); if (window.innerWidth > 768) ls.classList.remove("is-collapsed"); ls.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-left-width"));</script></div><div class="document-container markdown-reading-view hide"><div class="markdown-preview-view markdown-rendered allow-fold-headings allow-fold-lists is-readable-line-width"><style id="MJX-CHTML-styles">mjx-texatom{display:inline-block;text-align:left}mjx-msub{display:inline-block;text-align:left}mjx-msup{display:inline-block;text-align:left}mjx-msubsup{display:inline-block;text-align:left}mjx-script{display:inline-block;padding-right:.05em;padding-left:.033em}mjx-script>mjx-spacer{display:block}mjx-c.mjx-c2F::before{padding:.75em .5em .25em 0;content:"/"}mjx-c.mjx-c2211.TEX-S1::before{padding:.75em 1.056em .25em 0;content:"∑"}mjx-c.mjx-c28::before{padding:.75em .389em .25em 0;content:"("}mjx-c.mjx-c1D466.TEX-I::before{padding:.442em .49em .205em 0;content:"y"}mjx-c.mjx-c1D456.TEX-I::before{padding:.661em .345em .011em 0;content:"i"}mjx-c.mjx-c1D703.TEX-I::before{padding:.705em .469em .01em 0;content:"θ"}mjx-c.mjx-c1D447.TEX-I::before{padding:.677em .704em 0 0;content:"T"}mjx-c.mjx-c29::before{padding:.75em .389em .25em 0;content:")"}mjx-c.mjx-c1D6FC.TEX-I::before{padding:.442em .64em .011em 0;content:"α"}mjx-c.mjx-c1D457.TEX-I::before{padding:.661em .412em .204em 0;content:"j"}mjx-c.mjx-c1D44A.TEX-I::before{padding:.683em 1.048em .022em 0;content:"W"}mjx-c.mjx-c1D44C.TEX-I::before{padding:.683em .763em 0 0;content:"Y"}mjx-c.mjx-c1D44B.TEX-I::before{padding:.683em .852em 0 0;content:"X"}mjx-c.mjx-c1D437.TEX-I::before{padding:.683em .828em 0 0;content:"D"}mjx-c.mjx-c1D45A.TEX-I::before{padding:.442em .878em .011em 0;content:"m"}mjx-c.mjx-c1D43F.TEX-I::before{padding:.683em .681em 0 0;content:"L"}mjx-container[jax=CHTML]{line-height:0}mjx-container [space="1"]{margin-left:.111em}mjx-container [space="2"]{margin-left:.167em}mjx-container [space="3"]{margin-left:.222em}mjx-container [space="4"]{margin-left:.278em}mjx-container [space="5"]{margin-left:.333em}mjx-container [rspace="1"]{margin-right:.111em}mjx-container [rspace="2"]{margin-right:.167em}mjx-container [rspace="3"]{margin-right:.222em}mjx-container [rspace="4"]{margin-right:.278em}mjx-container [rspace="5"]{margin-right:.333em}mjx-container [size="s"]{font-size:70.7%}mjx-container [size=ss]{font-size:50%}mjx-container [size=Tn]{font-size:60%}mjx-container [size=sm]{font-size:85%}mjx-container [size=lg]{font-size:120%}mjx-container [size=Lg]{font-size:144%}mjx-container [size=LG]{font-size:173%}mjx-container [size=hg]{font-size:207%}mjx-container [size=HG]{font-size:249%}mjx-container [width=full]{width:100%}mjx-box{display:inline-block}mjx-block{display:block}mjx-itable{display:inline-table}mjx-row{display:table-row}mjx-row>*{display:table-cell}mjx-mtext{display:inline-block}mjx-mstyle{display:inline-block}mjx-merror{display:inline-block;color:red;background-color:#ff0}mjx-mphantom{visibility:hidden}mjx-assistive-mml{top:0;left:0;clip:rect(1px,1px,1px,1px);user-select:none;position:absolute!important;padding:1px 0 0!important;border:0!important;display:block!important;width:auto!important;overflow:hidden!important}mjx-assistive-mml[display=block]{width:100%!important}mjx-math{display:inline-block;text-align:left;line-height:0;text-indent:0;font-style:normal;font-weight:400;font-size:100%;letter-spacing:normal;border-collapse:collapse;overflow-wrap:normal;word-spacing:normal;white-space:nowrap;direction:ltr;padding:1px 0}mjx-container[jax=CHTML][display=true]{display:block;text-align:center;margin:1em 0}mjx-container[jax=CHTML][display=true][width=full]{display:flex}mjx-container[jax=CHTML][display=true] mjx-math{padding:0}mjx-container[jax=CHTML][justify=left]{text-align:left}mjx-container[jax=CHTML][justify=right]{text-align:right}mjx-mi{display:inline-block;text-align:left}mjx-c{display:inline-block}mjx-utext{display:inline-block;padding:.75em 0 .2em}mjx-mn{display:inline-block;text-align:left}mjx-mo{display:inline-block;text-align:left}mjx-stretchy-h{display:inline-table;width:100%}mjx-stretchy-h>*{display:table-cell;width:0}mjx-stretchy-h>*>mjx-c{display:inline-block;transform:scaleX(1)}mjx-stretchy-h>*>mjx-c::before{display:inline-block;width:initial}mjx-stretchy-h>mjx-ext{overflow:clip visible;width:100%}mjx-stretchy-h>mjx-ext>mjx-c::before{transform:scaleX(500)}mjx-stretchy-h>mjx-ext>mjx-c{width:0}mjx-stretchy-h>mjx-beg>mjx-c{margin-right:-.1em}mjx-stretchy-h>mjx-end>mjx-c{margin-left:-.1em}mjx-stretchy-v{display:inline-block}mjx-stretchy-v>*{display:block}mjx-stretchy-v>mjx-beg{height:0}mjx-stretchy-v>mjx-end>mjx-c{display:block}mjx-stretchy-v>*>mjx-c{transform:scaleY(1);transform-origin:left center;overflow:hidden}mjx-stretchy-v>mjx-ext{display:block;height:100%;box-sizing:border-box;border:0 solid transparent;overflow:visible clip}mjx-stretchy-v>mjx-ext>mjx-c::before{width:initial;box-sizing:border-box}mjx-stretchy-v>mjx-ext>mjx-c{transform:scaleY(500) translateY(.075em);overflow:visible}mjx-mark{display:inline-block;height:0}mjx-c::before{display:block;width:0}.MJX-TEX{font-family:MJXZERO,MJXTEX}.TEX-B{font-family:MJXZERO,MJXTEX-B}.TEX-I{font-family:MJXZERO,MJXTEX-I}.TEX-MI{font-family:MJXZERO,MJXTEX-MI}.TEX-BI{font-family:MJXZERO,MJXTEX-BI}.TEX-S1{font-family:MJXZERO,MJXTEX-S1}.TEX-S2{font-family:MJXZERO,MJXTEX-S2}.TEX-S3{font-family:MJXZERO,MJXTEX-S3}.TEX-S4{font-family:MJXZERO,MJXTEX-S4}.TEX-A{font-family:MJXZERO,MJXTEX-A}.TEX-C{font-family:MJXZERO,MJXTEX-C}.TEX-CB{font-family:MJXZERO,MJXTEX-CB}.TEX-FR{font-family:MJXZERO,MJXTEX-FR}.TEX-FRB{font-family:MJXZERO,MJXTEX-FRB}.TEX-SS{font-family:MJXZERO,MJXTEX-SS}.TEX-SSB{font-family:MJXZERO,MJXTEX-SSB}.TEX-SSI{font-family:MJXZERO,MJXTEX-SSI}.TEX-SC{font-family:MJXZERO,MJXTEX-SC}.TEX-T{font-family:MJXZERO,MJXTEX-T}.TEX-V{font-family:MJXZERO,MJXTEX-V}.TEX-VB{font-family:MJXZERO,MJXTEX-VB}mjx-stretchy-h mjx-c,mjx-stretchy-v mjx-c{font-family:MJXZERO,MJXTEX-S1,MJXTEX-S4,MJXTEX,MJXTEX-A!important}@font-face{font-family:MJXZERO;src:url("lib/fonts/mathjax_zero.woff") format("woff")}@font-face{font-family:MJXTEX;src:url("lib/fonts/mathjax_main-regular.woff") format("woff")}@font-face{font-family:MJXTEX-B;src:url("lib/fonts/mathjax_main-bold.woff") format("woff")}@font-face{font-family:MJXTEX-I;src:url("lib/fonts/mathjax_math-italic.woff") format("woff")}@font-face{font-family:MJXTEX-MI;src:url("lib/fonts/mathjax_main-italic.woff") format("woff")}@font-face{font-family:MJXTEX-BI;src:url("lib/fonts/mathjax_math-bolditalic.woff") format("woff")}@font-face{font-family:MJXTEX-S1;src:url("lib/fonts/mathjax_size1-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S2;src:url("lib/fonts/mathjax_size2-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S3;src:url("lib/fonts/mathjax_size3-regular.woff") format("woff")}@font-face{font-family:MJXTEX-S4;src:url("lib/fonts/mathjax_size4-regular.woff") format("woff")}@font-face{font-family:MJXTEX-A;src:url("lib/fonts/mathjax_ams-regular.woff") format("woff")}@font-face{font-family:MJXTEX-C;src:url("lib/fonts/mathjax_calligraphic-regular.woff") format("woff")}@font-face{font-family:MJXTEX-CB;src:url("lib/fonts/mathjax_calligraphic-bold.woff") format("woff")}@font-face{font-family:MJXTEX-FR;src:url("lib/fonts/mathjax_fraktur-regular.woff") format("woff")}@font-face{font-family:MJXTEX-FRB;src:url("lib/fonts/mathjax_fraktur-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SS;src:url("lib/fonts/mathjax_sansserif-regular.woff") format("woff")}@font-face{font-family:MJXTEX-SSB;src:url("lib/fonts/mathjax_sansserif-bold.woff") format("woff")}@font-face{font-family:MJXTEX-SSI;src:url("lib/fonts/mathjax_sansserif-italic.woff") format("woff")}@font-face{font-family:MJXTEX-SC;src:url("lib/fonts/mathjax_script-regular.woff") format("woff")}@font-face{font-family:MJXTEX-T;src:url("lib/fonts/mathjax_typewriter-regular.woff") format("woff")}@font-face{font-family:MJXTEX-V;src:url("lib/fonts/mathjax_vector-regular.woff") format("woff")}@font-face{font-family:MJXTEX-VB;src:url("lib/fonts/mathjax_vector-bold.woff") format("woff")}mjx-c.mjx-c1D464.TEX-I::before{padding:.443em .716em .011em 0;content:"w"}mjx-c.mjx-c31::before{padding:.666em .5em 0 0;content:"1"}mjx-c.mjx-c1D465.TEX-I::before{padding:.442em .572em .011em 0;content:"x"}mjx-c.mjx-c2B::before{padding:.583em .778em .082em 0;content:"+"}mjx-c.mjx-c32::before{padding:.666em .5em 0 0;content:"2"}mjx-c.mjx-c2E::before{padding:.12em .278em 0 0;content:"."}mjx-c.mjx-c1D45B.TEX-I::before{padding:.442em .6em .011em 0;content:"n"}mjx-c.mjx-c2217::before{padding:.465em .5em 0 0;content:"∗"}mjx-c.mjx-c2212::before{padding:.583em .778em .082em 0;content:"−"}mjx-c.mjx-c1D44F.TEX-I::before{padding:.694em .429em .011em 0;content:"b"}mjx-c.mjx-c3D::before{padding:.583em .778em .082em 0;content:"="}mjx-c.mjx-c30::before{padding:.666em .5em .022em 0;content:"0"}</style><div class="markdown-preview-sizer markdown-preview-section"><h1 class="page-title heading inline-title" id="zero-shot">zero-shot</h1><div class="el-p"><p dir="auto"><a href="?query=tag:%E9%A1%B9%E7%9B%AE/%E7%9F%A5%E8%AF%86%E5%82%A8%E5%A4%87" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a><br>
零样本学习或零shot学习(Zero-Shot Learning)是一种机器学习任务,其目的是识别训练集中没有出现过的类别。</p></div><div class="el-p"><p dir="auto">具体来说:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">训练样本只包含有限类别,但测试样本可能包含未见过的新类别。<br>
</li>
<li data-line="2" dir="auto">零样本学习的模型需要利用已有类别信息,才能推理新类别的概念并进行分类。<br>
</li>
</ul></div><div class="el-p"><p dir="auto">主要思路是:</p></div><div class="el-ol"><ol>
<li data-line="0" dir="auto">为每一个类别学习一个独立的语义特征向量。</li>
<li data-line="2" dir="auto">训练一个映射函数,能将样本映射到语义特征空间中。</li>
<li data-line="4" dir="auto">测试时,直接根据新类别的语义向量进行分类,而无需实际训练样本。</li>
</ol></div><div class="el-p"><p dir="auto">优点是能够识别学习过程完全没有看到的新类别。这对实际应用很重要,因为新类别总是不断出现。</p></div><div class="el-p"><p dir="auto">实现零样本学习的主要方法有:</p></div><div class="el-ul"><ul>
<li data-line="0" dir="auto">基于属性的方法(Attribute-based)<br>
</li>
<li data-line="2" dir="auto">基于关系的方法(Relational)<br>
</li>
<li data-line="4" dir="auto">密度比例进行匹配(Density Ratio Matching)<br>
</li>
</ul></div><div class="el-p"><p dir="auto">它打破了传统分类算法依赖大量标注数据的限制,在语义学习上取得了重要进展。</p></div><div class="el-p"><p dir="auto">通俗解释如下:</p></div><div class="el-h2 heading-wrapper"><h2 data-heading="零次学习（zero-shot learning）基本概念" dir="auto" class="heading" id="零次学习（zero-shot_learning）基本概念"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>零次学习（zero-shot learning）基本概念</h2><div class="heading-children"><div class="el-p"><p dir="auto">每次在实验室做工作汇报的时候，总会把ZSL的基本概念讲一遍，但是每次的效果都不是很好，工作都讲完了，提的第一个问题依然是：ZSL到底是什么？这让我一度认为我的表达能力有问题。。。。。。不过回忆起我第一次接触这个题目的时候，也花了挺长的时间才搞清楚到底在做一件什么事情，那篇入门的文章[1]看了很久才基本看懂。因此，我尽量用最简单的，不带任何公式的方式来讲一下这到底是个什么问题。</p></div><div class="el-p"><p dir="auto">假设小暗（纯粹因为不想用小明）和爸爸，到了动物园，看到了马，然后爸爸告诉他，这就是马；之后，又看到了老虎，告诉他：“看，这种身上有条纹的动物就是老虎。”；最后，又带他去看了熊猫，对他说：“你看这熊猫是黑白色的。”然后，爸爸给小暗安排了一个任务，让他在动物园里找一种他从没见过的动物，叫斑马，并告诉了小暗有关于斑马的信息：“斑马有着马的轮廓，身上有像老虎一样的条纹，而且它像熊猫一样是黑白色的。”最后，小暗根据爸爸的提示，在动物园里找到了斑马（意料之中的结局。。。）。</p></div><div class="el-p"><p dir="auto">上述例子中包含了一个人类的推理过程，就是利用过去的知识（马，老虎，熊猫和斑马的描述），在脑海中推理出新对象的具体形态，从而能对新对象进行辨认。（如图1所示）ZSL就是希望能够模仿人类的这个推理过程，使得计算机具有识别新事物的能力。</p></div><div class="el-p"><p dir="auto"><img src="https://pic3.zhimg.com/v2-d8efa9870a3ce5ee028277ec57033036_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"></p></div><div class="el-p"><p dir="auto">图1 ZSL概念图[17]</p></div><div class="el-p"><p dir="auto">如今深度学习非常火热，使得纯监督学习在很多任务上都达到了让人惊叹的结果，<em>但其限制是：往往需要足够多的样本才能训练出足够好的模型，并且利用猫狗训练出来的分类器，就只能对猫狗进行分类，其他的物种它都无法识别。</em> 这样的模型显然并不符合我们对人工智能的终极想象，我们希望机器能够像上文中的小暗一样，具有通过推理，识别新类别的能力。</p></div><div class="el-p"><p dir="auto">ZSL就是希望我们的模型能够对其从没见过的类别进行分类，让机器具有推理能力，实现真正的智能。其中零次（Zero-shot）是指对于要分类的类别对象，一次也不学习。这样的能力听上去很具有吸引力，那么到底是怎么实现的呢？</p></div><div class="el-p"><p dir="auto">假设我们的模型已经能够识别马，老虎和熊猫了，<em>现在需要该模型也识别斑马，那么我们需要像爸爸一样告诉模型，怎样的对象才是斑马，但是并不能直接让模型看见斑马。</em> 所以模型需要知道的信息是马的样本、老虎的样本、熊猫的样本和样本的标签，以及关于前三种动物和斑马的描述。将其转换为常规的机器学习，这里我们只讨论一般的图片分类问题：</p></div><div class="el-p"><p dir="auto">（1）训练集数据X<em>{tr}&nbsp;及其标签&nbsp;Y</em>{tr}&nbsp;，包含了模型需要学习的类别（马、老虎和熊猫），这里和传统的监督学习中的定义一致；</p></div><div class="el-p"><p dir="auto">（2）测试集数据X<em>{te}及其标签Y</em>{te}&nbsp;，包含了模型需要辨识的类别（斑马），这里和传统的监督学习中也定义一直；</p></div><div class="el-p"><p dir="auto">（3）训练集类别的描述&nbsp;<img alt="A_{tr}" src="https://www.zhihu.com/equation?tex=A_%7Btr%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，以及测试集类别的描述&nbsp;<img alt="A_{te}" src="https://www.zhihu.com/equation?tex=A_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;；我们将每一个类别&nbsp;<img alt="y_{i}\in Y" src="https://www.zhihu.com/equation?tex=y_%7Bi%7D%5Cin+Y&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，都表示成一个语义向量&nbsp;<img alt="a_{i}\in A" src="https://www.zhihu.com/equation?tex=a_%7Bi%7D%5Cin+A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;的形式，而这个语义向量的每一个维度都表示一种高级的属性，比如“黑白色”、“有尾巴”、“有羽毛”等等，当这个类别包含这种属性时，那在其维度上被设置为非零值。对于一个数据集来说，语义向量的维度是固定的，它包含了能够较充分描述数据集中类别的属性。</p></div><div class="el-p"><p dir="auto">在ZSL中，我们希望利用&nbsp;X<em>{tr}&nbsp;和Y</em>{tr}&nbsp;来训练模型，而模型能够具有识别X<em>{te}的能力，因此模型需要知道所有类别的描述&nbsp;![A</em>{tr}](<a rel="noopener nofollow" class="external-link" href="https://www.zhihu.com/equation?tex=A_%7Btr%7D&amp;consumer=ZHI_MENG" target="_blank">https://www.zhihu.com/equation?tex=A_%7Btr%7D&amp;consumer=ZHI_MENG</a>)&nbsp;和&nbsp;<img alt="A_{te}" src="https://www.zhihu.com/equation?tex=A_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;。ZSL这样的设置其实就是上文中小暗识别斑马的过程中，爸爸为他提供的条件。</p></div><div class="el-p"><p dir="auto"><img src="https://pic2.zhimg.com/v2-33a9764b792911eedce07dd4974e46f5_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"></p></div><div class="el-p"><p dir="auto">图2 ZSL设置图[16]</p></div><div class="el-p"><p dir="auto">如图2，可以较为直观地了解ZSL的设置。</p></div><div class="el-p"><p dir="auto">讲到这，很多同学可能会问：</p></div><div class="el-p"><p dir="auto">（1）类别的描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;到底是怎么获取的？</p></div><div class="el-p"><p dir="auto">答：有人工专家定义的，也有通过海量的附加数据集自动学习出来的，但前者的效果目前要好很多。</p></div><div class="el-p"><p dir="auto">（2）这样做让人觉得有点失望呀！我希望模型能够在没有斑马样本的情况下，识别斑马，而现在，虽然我不需要为模型提供斑马的样本，但是却要为每一个类别添加一种描述，更离谱的是我还需要斑马（测试集）的描述，这个过程并没有想象中智能诶！</p></div><div class="el-p"><p dir="auto">答：的确，在我们的想象中，我们期待的智能是：只给机器马、老虎和熊猫，然后它就可以识别斑马了，这样多爽，多神奇。但我们回过头去，再想想小暗的思考过程，如果爸爸不告诉小暗关于斑马的任何信息，那么当小暗看见斑马的时候，并不会知道它是什么，只是小暗能够描述它：“这是一匹有着黑白颜色条纹的马。”这里，有同学可能又会说：至少我们可以不用告诉小暗类别的描述呀，但是ZSL就不行。其实，我们是需要告诉小暗类别描述的，或者说小暗在之前就学习到了类别描述，比如怎样的图案是“条纹”，怎样的颜色称为“黑白色”，这样的属性定义。对于一个模型来说，它就像刚出生的婴儿，我们需要教会它这些属性的定义。</p></div><div class="el-p"><p dir="auto">（3）就算是这样，需要实现定义这个描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;还是很蛋疼的一件事情。</p></div><div class="el-p"><p dir="auto">答：（1）中就有提到，描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;可以自动学习，我们将小暗已经掌握的知识描述为一个知识库，这个知识库里就有对各种属性的定义；而能够模仿人类知识库的最好东西就是“百度百科”，“维基百科”等等各种百科，我们可以利用百科中的各种定义，生成类别的定义，这方面侧重于NLP，因此不进一步讨论。</p></div><div class="el-p"><p dir="auto">在此，我们小小总结一下ZSL问题的定义。<strong>利用训练集数据训练模型，使得模型能够对测试集的对象进行分类，但是训练集类别和测试集类别之间没有交集；期间需要借助类别的描述，来建立训练集和测试集之间的联系，从而使得模型有效</strong>。</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="目前的研究方式" dir="auto" class="heading" id="目前的研究方式"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>目前的研究方式</h2><div class="heading-children"><div class="el-p"><p dir="auto">在上文中提到，要实现ZSL功能似乎需要解决两个部分的问题：第一个问题是获取合适的类别描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;；第二个问题是建立一个合适的分类模型。</p></div><div class="el-p"><p dir="auto">目前大部分工作都集中在第二个问题上，而第一个问题的研究进展比较缓慢。个人认为的原因是， 目前<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;的获取主要集中于一些NLP的方法，而且难度较大；而第二个问题能够用的方法较多，比较容易出成果。</p></div><div class="el-p"><p dir="auto">因此，接下来的算法部分，也只介绍研究分类模型的方法。</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="数据集介绍" dir="auto" class="heading" id="数据集介绍"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>数据集介绍</h2><div class="heading-children"><div class="el-p"><p dir="auto">先介绍数据集，是因为希望在算法介绍部分，直接给出实例，让大家能够直接上手，这里顺便插个沐神&nbsp;<a data-tooltip-position="top" aria-label="https://www.zhihu.com/people/13fd0fce2affd948bfd821a8f7ed10f3" rel="noopener nofollow" class="external-link" href="https://www.zhihu.com/people/13fd0fce2affd948bfd821a8f7ed10f3" target="_blank">@李沐</a>&nbsp;的感悟。</p></div><div class="el-blockquote"><blockquote dir="auto">
<p>虽然在我认识的人里，好些人能够读一篇论文或者听一个报告后就能问出很好的问题，然后就基本弄懂了。但我在这个上笨很多。读过的论文就像喝过的水，第二天就不记得了。一定是需要静下心来，从头到尾实现一篇，跑上几个数据，调些参数，才能心安地觉得懂了。例如在港科大的两年读了很多论文，但现在反过来看，仍然记得可能就是那两个老老实实动手实现过写过论文的模型了。即使后来在机器学习这个方向又走了五年，学习任何新东西仍然是要靠动手。——李沐（MXNet开发者）</p>
</blockquote></div><div class="el-p"><p dir="auto">（1）<strong>Animal with Attributes（AwA）</strong>官网：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//cvml.ist.ac.at/AwA/" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//cvml.ist.ac.at/AwA/" target="_blank">Animals with Attributes</a></p></div><div class="el-p"><p dir="auto">提出ZSL定义的作者，给出的数据集，都是动物的图片，包括50个类别的图片，其中40个类别作为训练集，10个类别作为测试集，每个类别的语义为85维，总共有30475张图片。但是目前由于版权问题，已经无法获取这个数据集的图片了，作者便提出了AwA2，与前者类似，总共37322张图片。</p></div><div class="el-p"><p dir="auto">（2）<strong>Caltech-UCSD-Birds-200-2011（CUB）</strong>官网：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=http%3A//www.vision.caltech.edu/visipedia/CUB-200-2011.html" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=http%3A//www.vision.caltech.edu/visipedia/CUB-200-2011.html" target="_blank">Caltech-UCSD Birds-200-2011</a></p></div><div class="el-p"><p dir="auto">全部都是鸟类的图片，总共200类，150类为训练集，50类为测试集，类别的语义为312维，有11788张图片。</p></div><div class="el-p"><p dir="auto">（3）<strong>Sun database（SUN）</strong>官网：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=http%3A//groups.csail.mit.edu/vision/SUN/" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=http%3A//groups.csail.mit.edu/vision/SUN/" target="_blank">SUN Database</a></p></div><div class="el-p"><p dir="auto">总共有717个类别，每个类别20张图片，类别语义为102维。传统的分法是训练集707类，测试集10类。</p></div><div class="el-p"><p dir="auto">（4）<strong>Attribute Pascal and Yahoo dataset（aPY）</strong>官网：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=http%3A//vision.cs.uiuc.edu/attributes/" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=http%3A//vision.cs.uiuc.edu/attributes/" target="_blank">Describing Objects by their Attributes</a></p></div><div class="el-p"><p dir="auto">共有32个类，其中20个类作为训练集，12个类作为测试集，类别语义为64维，共有15339张图片。</p></div><div class="el-p"><p dir="auto">（5）<strong>ILSVRC2012/ILSVRC2010（ImNet-2）</strong></p></div><div class="el-p"><p dir="auto">利用ImageNet做成的数据集，由ILSVRC2012的1000个类作为训练集，ILSVRC2010的360个类作为测试集，有254000张图片。它由 4.6M 的Wikipedia数据集训练而得到，共1000维。</p></div><div class="el-p"><p dir="auto">上述数据集中（1）-（4）都是较小型（small-scale）的数据集，（5）是大型（large-scale）数据集。虽然（1）-（4）已经提供了人工定义的类别语义，但是有些作者也会从维基语料库中自动提取出类别的语义表示，来检测自己的模型。</p></div><div class="el-p"><p dir="auto">这里给大家提供一些已经用GoogleNet提取好的数据集图片特征，大家可以比较方便地使用。<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/29807635" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/29807635" target="_blank">Zero-Shot Learing问题数据集分享（GoogleNet 提取）</a></p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="基础算法介绍" dir="auto" class="heading" id="基础算法介绍"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>基础算法介绍</h2><div class="heading-children"><div class="el-p"><p dir="auto">在此，只具体介绍最简单的方法，让大家可以快速上手。我们面对的是一个图片分类问题，即对测试集的样本X<em>{te}进行分类，而我们分类时需要借助类别的描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，由于每一个类别&nbsp;![y</em>{i}\in Y](<a rel="noopener nofollow" class="external-link" href="https://www.zhihu.com/equation?tex=y_%7Bi%7D%5Cin+Y&amp;consumer=ZHI_MENG" target="_blank">https://www.zhihu.com/equation?tex=y_%7Bi%7D%5Cin+Y&amp;consumer=ZHI_MENG</a>)&nbsp;，都对应一个语义向量&nbsp;<img alt="a_{i}\in A" src="https://www.zhihu.com/equation?tex=a_%7Bi%7D%5Cin+A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，因此我们现在可以忘掉&nbsp;<img alt="Y" src="https://www.zhihu.com/equation?tex=Y&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，直接使用&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;。我们把&nbsp;<img alt="X" src="https://www.zhihu.com/equation?tex=X&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;（利用深度网络提取的图片特征，比如GoogleNet提取为1024维）称为特征空间（visual feature space），把类别的语义表示&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，称为语义空间。<strong>我们要做的，其实就是建立特征空间与语义空间之间的映射</strong>。</p></div><div class="el-p"><p dir="auto">对于分类，我们能想到的最简单的形式就是<a data-href="岭回归" href="project/知识储备/岭回归.html" class="internal-link" target="_self" rel="noopener nofollow">岭回归</a>（ridge regression），俗称均方误差加范数约束，具体形式为：</p></div><div class="el-p"><p dir="auto"><img alt="min||X_{tr}W - A_{tr}||^{2}+\eta\Omega(W)" src="https://www.zhihu.com/equation?tex=min%7C%7CX_%7Btr%7DW+-+A_%7Btr%7D%7C%7C%5E%7B2%7D%2B%5Ceta%5COmega%28W%29&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;(1)</p></div><div class="el-p"><p dir="auto">其中，&nbsp;<img alt="\Omega()" src="https://www.zhihu.com/equation?tex=%5COmega%28%29&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;通常为2范数约束，&nbsp;<img alt="\eta" src="https://www.zhihu.com/equation?tex=%5Ceta&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;为超参，对&nbsp;<img alt="W" src="https://www.zhihu.com/equation?tex=W&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;求导，并让导为0，即可求出&nbsp;<img alt="W" src="https://www.zhihu.com/equation?tex=W&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;的值。测试时，利用&nbsp;<img alt="W" src="https://www.zhihu.com/equation?tex=W&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;将&nbsp;<img alt="x_{i}\in X_{te}" src="https://www.zhihu.com/equation?tex=x_%7Bi%7D%5Cin+X_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;投影到语义空间中，并在该空间中寻找到离它最近的&nbsp;<img alt="a_{i}\in A_{te}" src="https://www.zhihu.com/equation?tex=a_%7Bi%7D%5Cin+A_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，则样本的类别为&nbsp;<img alt="a_{i}" src="https://www.zhihu.com/equation?tex=a_%7Bi%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;所对应的标签&nbsp;<img alt="y_{i}\in Y_{tr}" src="https://www.zhihu.com/equation?tex=y_%7Bi%7D%5Cin+Y_%7Btr%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;。</p></div><div class="el-p"><p dir="auto">简单写一个matlab实现。</p></div><div class="el-pre"><pre class="language-matlab" tabindex="0"><code data-line="0" class="language-matlab is-loaded">regression_lambda <span class="token operator">=</span> <span class="token number">1.0</span><span class="token punctuation">;</span>
W <span class="token operator">=</span> <span class="token function">ridge_regression</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>train_set<span class="token punctuation">,</span> param<span class="token punctuation">.</span>train_class_attributes<span class="token punctuation">,</span> regression_lambda <span class="token punctuation">,</span> <span class="token number">1024</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
S_test <span class="token operator">=</span> param<span class="token punctuation">.</span>test_set <span class="token operator">*</span> W<span class="token punctuation">;</span>
<span class="token punctuation">[</span>zsl_accuracy<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">zsl_el</span><span class="token punctuation">(</span>S_test<span class="token punctuation">,</span> param<span class="token punctuation">.</span>S_te<span class="token punctuation">,</span> param<span class="token punctuation">)</span><span class="token punctuation">;</span> 
<span class="token function">fprintf</span><span class="token punctuation">(</span><span class="token string">'AwA ZSL accuracy on test set: %.1f%%\n'</span><span class="token punctuation">,</span> zsl_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-p"><p dir="auto">我们使用AwA数据集，图片事先利用GoogleNet提取了特征（1024维），在测试集上可以得到59.1%的准确率。</p></div><div class="el-p"><p dir="auto">这样一个岭回归之所以有效，是因为训练集类别语义&nbsp;<img alt="A_{tr}" src="https://www.zhihu.com/equation?tex=A_%7Btr%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;与测试集类别语义&nbsp;<img alt="A_{te}" src="https://www.zhihu.com/equation?tex=A_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;之间存在的密切联系。其实任何ZSL方法有效的基础，都是因为这两者之间具体的联系。</p></div><div class="el-p"><p dir="auto">仅仅利用如此naive的方式，得到的结果显然不能满足我们的要求，那么建立更好的模型，则需要进一步了解ZSL问题中，存在着哪些和传统监督分类的差异。</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="ZSL中存在的问题" dir="auto" class="heading" id="ZSL中存在的问题"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>ZSL中存在的问题</h2><div class="heading-children"><div class="el-p"><p dir="auto">在此，介绍一些目前ZSL中主要存在的问题，以便让大家了解目前ZS领域有哪些研究点。</p></div><div class="el-p"><p dir="auto"><strong>领域漂移问题（domain shift problem）</strong></p></div><div class="el-p"><p dir="auto">该问题的正式定义首先由[2]提出。简单来说，就是同一种属性，在不同的类别中，视觉特征的表现可能很大。如图3所示，斑马和猪都有尾巴，因此在它的类别语义表示中，“有尾巴”这一项都是非0值，但是两者尾巴的视觉特征却相差很远。如果斑马是训练集，而猪是测试集，那么利用斑马训练出来的模型，则很难正确地对猪进行分类。</p></div><div class="el-p"><p dir="auto"><img src="https://pic3.zhimg.com/v2-733de891fa7f478740b35228dad776c2_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"></p></div><div class="el-p"><p dir="auto">图3 domain shift示意图，图中的prototype表示类别在语义空间中的位置[2]</p></div><div class="el-p"><p dir="auto"><strong>枢纽点问题（Hubness problem）</strong></p></div><div class="el-p"><p dir="auto">这其实是高维空间中固有的问题：在高维空间中，某些点会成为大多数点的最近邻点。这听上去有些反直观，细节方面可以参考[3]。由于ZSL在计算最终的正确率时，使用的是K-NN，所以会受到hubness problem的影响，并且[4]中，证明了基于岭回归的方法会加重hubness problem问题。</p></div><div class="el-p"><p dir="auto"><strong>语义间隔（semantic gap）</strong></p></div><div class="el-p"><p dir="auto">样本的特征往往是视觉特征，比如用深度网络提取到的特征，而语义表示却是非视觉的，这直接反应到数据上其实就是：样本在特征空间中所构成的流型与语义空间中类别构成的流型是不一致的。（如图4所示）</p></div><div class="el-p"><p dir="auto"><img src="https://pic3.zhimg.com/v2-869ec7e6e0f91229f8f66997ce59123a_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"></p></div><div class="el-p"><p dir="auto">图4 流型不一致示意图[8]</p></div><div class="el-p"><p dir="auto">这使得直接学习两者之间的映射变得困难。</p></div><div class="el-p"><p dir="auto">还有其他的，比如semantic loss[5]问题，样本通过映射坍塌到一点[6]等，由于还不常研究，在此就不再讨论。</p></div><div class="el-p"><p dir="auto">在此，我们给出解决上述三个问题的基本方法，从而更加深度地了解这三个问题。</p></div><div class="el-p"><p dir="auto">（1）领域漂移</p></div><div class="el-p"><p dir="auto">由于样本的特征维度往往比语义的维度大，所以建立从&nbsp;<img alt="X" src="https://www.zhihu.com/equation?tex=X&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;到&nbsp;<img alt="S" src="https://www.zhihu.com/equation?tex=S&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;的映射往往会丢失信息，为了保留更多的信息，保持更多的丰富性，最流行的做法是将映射到语义空间中的样本，再重建回去，这样学习到的映射就能够得到保留更多的信息。因此，在原来简单岭回归[1]的基础上，可以将目标函数改为：[7]</p></div><div class="el-p"><p dir="auto"><img alt="min||X_{tr} - W^{T}A_{tr}||^{2}+\lambda ||WX_{tr} - A_{tr}||^{2}" src="https://www.zhihu.com/equation?tex=min%7C%7CX_%7Btr%7D+-+W%5E%7BT%7DA_%7Btr%7D%7C%7C%5E%7B2%7D%2B%5Clambda+%7C%7CWX_%7Btr%7D+-+A_%7Btr%7D%7C%7C%5E%7B2%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;(2)</p></div><div class="el-p"><p dir="auto">从目标函数可以看出，这其实完成的是一个简易的自编码器过程，我们简称这个算法为SAE，利用matlab可以轻松对其实现。</p></div><div class="el-pre"><pre class="language-matlab" tabindex="0"><code data-line="0" class="language-matlab is-loaded">lambda1 <span class="token operator">=</span> <span class="token number">800000</span><span class="token punctuation">;</span>
W <span class="token operator">=</span> <span class="token function">SAE</span><span class="token punctuation">(</span>param<span class="token punctuation">.</span>train_set<span class="token operator">'</span><span class="token punctuation">,</span> param<span class="token punctuation">.</span>train_class_attributes<span class="token operator">'</span><span class="token punctuation">,</span> lambda1<span class="token punctuation">)</span><span class="token punctuation">;</span>
S_test <span class="token operator">=</span> param<span class="token punctuation">.</span>test_set <span class="token operator">*</span> <span class="token function">NormalizeFea</span><span class="token punctuation">(</span>W<span class="token operator">'</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token punctuation">[</span>zsl_accuracy<span class="token punctuation">]</span><span class="token operator">=</span> <span class="token function">zsl_el</span><span class="token punctuation">(</span>S_test<span class="token punctuation">,</span> param<span class="token punctuation">.</span>S_te<span class="token punctuation">,</span> param<span class="token punctuation">)</span><span class="token punctuation">;</span> 
<span class="token function">fprintf</span><span class="token punctuation">(</span><span class="token string">'AwA ZSL accuracy on test set: %.1f%%\n'</span><span class="token punctuation">,</span> zsl_accuracy<span class="token operator">*</span><span class="token number">100</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
</code><button class="copy-code-button"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon lucide-copy"><rect x="8" y="8" width="14" height="14" rx="2" ry="2"></rect><path d="M4 16c-1.1 0-2-.9-2-2V4c0-1.1.9-2 2-2h10c1.1 0 2 .9 2 2"></path></svg></button></pre></div><div class="el-p"><p dir="auto">依然是在AwA上进行测试，可以得到83.2%的准确率，比简单的岭回归(1)提高了24.1%。自编码器的这个结构目前在ZSL方法中非常流行，稍后我们还会提到。</p></div><div class="el-p"><p dir="auto">（2）枢纽点问题</p></div><div class="el-p"><p dir="auto">目前对于枢纽点问题的解决主要有两种方法：</p></div><div class="el-p"><p dir="auto">a. 如果模型建立的方式为岭回归，那么可以建立从语义空间到特征空间的映射，从而不加深hubness problem对结果的影响[4]，也就是说将目标函数（1）改为：</p></div><div class="el-p"><p dir="auto"><img alt="min||X_{tr} - A_{tr}W||^{2}+\eta\Omega(W)" src="https://www.zhihu.com/equation?tex=min%7C%7CX_%7Btr%7D+-+A_%7Btr%7DW%7C%7C%5E%7B2%7D%2B%5Ceta%5COmega%28W%29&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;(3)</p></div><div class="el-p"><p dir="auto">在AwA数据集上，这种简单的改变能够得到76.5%的正确率，比原本提高了17.4%。</p></div><div class="el-p"><p dir="auto">b.可以使用生成模型，比如自编码器、GAN等，生成测试集的样本，这样就变成了一个传统的监督分类问题，不存在K-NN的操作，所以不存在hubness problem的影响。</p></div><div class="el-p"><p dir="auto">（3）语义间隔问题</p></div><div class="el-p"><p dir="auto">语义间隔问题的本质是二者的流形结构不一致，因此，解决此问题的着手点就在于将两者的流形调整到一致，再学习两者之间的映射[8]。最简单的方法自然是将类别的语义表示调整到样本的流型上，即用类别语义表示的K近邻样本点，重新表示类别语义即可。</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="有关ZSL的一些其他的概念" dir="auto" class="heading" id="有关ZSL的一些其他的概念"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>有关ZSL的一些其他的概念</h2><div class="heading-children"><div class="el-p"><p dir="auto">这里将提到一些ZSL涉及到的其他概念。</p></div><div class="el-p"><p dir="auto">（1）直推式学习（Transductive setting）</p></div><div class="el-p"><p dir="auto">这里的直推式学习其实是指在训练模型的时候，我们可以拿到测试集的数据，只是不能拿到测试集的样本的标签，因此我们可以利用测试集数据，得到一些测试集类别的先验知识。这种设置在迁移学习中很常见。</p></div><div class="el-p"><p dir="auto"><img src="https://pic4.zhimg.com/v2-7a2f3465bcf020ccb2f0375d86fd4943_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"></p></div><div class="el-p"><p dir="auto">图5 非直推式（inductive）和直推式学习的区别[16]</p></div><div class="el-p"><p dir="auto">（2）泛化的ZSL（generalized ZSL）</p></div><div class="el-p"><p dir="auto">上文中提到的ZSL，在测试时使用K-NN进行正确率的评估时，只在测试类别中找最近邻的类别，但是在现实的问题中，拿到的样本也可能属于训练集类别，因此在测试时，同时加入训练集类别。[9]现在的很多方法都开始测试模型在这种设置下的能力。</p></div></div></div><div class="el-h2 heading-wrapper"><h2 data-heading="推荐阅读的论文" dir="auto" class="heading" id="推荐阅读的论文"><div class="heading-collapse-indicator collapse-indicator collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon right-triangle"><path d="M3 8L12 17L21 8"></path></svg></div>推荐阅读的论文</h2><div class="heading-children"><div class="el-p"><p dir="auto">我一直不想写ZSL的发展史，因为据我的经验，写了一大段发展史之后，往往大家的兴致不高，而且看完之后一般都不会有什么特别的感觉，基本也记不得什么东西。所以倒不如给大家推荐一些论文，从最早的到目前最新的，使得大家在短时间内能对ZSL的发展有一个大概的概念。</p></div><div class="el-p"><p dir="auto">（1）Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer[1]</p></div><div class="el-p"><p dir="auto">ZSL问题的开创性文章，当然是必读的喽，而且可以顺便看看别人是如何阐述一个新问题（挖坑）的。</p></div><div class="el-p"><p dir="auto">（2）An embarrassingly simple approach to zero-shot learning[10]</p></div><div class="el-p"><p dir="auto">有着很强的理论基础，算法简单、有效，虽然已经过去很多年了，但还是目前新工作需要进行对比的方法之一。</p></div><div class="el-p"><p dir="auto">（3）Transductive Multi-View Zero-Shot Learning[2]</p></div><div class="el-p"><p dir="auto">第一次定义了domain shift问题。</p></div><div class="el-p"><p dir="auto">（4）Zero-shot recognition using dual visualsemantic mapping paths[11]</p></div><div class="el-p"><p dir="auto">解决semantic gap问题的简单做法。</p></div><div class="el-p"><p dir="auto">（5）Predicting visual exemplars of unseen classes for zero-shot learning[12]</p></div><div class="el-p"><p dir="auto">从本质的角度出发，将ZSL问题，看作聚类问题，用最简单的方法直接建立映射。</p></div><div class="el-p"><p dir="auto">（6）Semantic Autoencoder for Zero-Shot Learning[7]</p></div><div class="el-p"><p dir="auto">引入自编码器结构的第一篇文章，直接导致现在出现的新方法大都具有这种结构。</p></div><div class="el-p"><p dir="auto">（7）Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly[14]</p></div><div class="el-p"><p dir="auto">综述性的文章，总结了17年底以前的方法，提出了新的评价标准，对当时领域发展比较混乱的地方做出了一些更标准的评估。</p></div><div class="el-p"><p dir="auto">（8）Zero-Shot Learning via Class-Conditioned Deep Generative Models[6]</p></div><div class="el-p"><p dir="auto">将[7]改造为深度模型，并加上一些其他的约束。</p></div><div class="el-p"><p dir="auto">（9）Preserving Semantic Relations for Zero-Shot Learning[13]</p></div><div class="el-p"><p dir="auto">在自编码器结构的基础上，显示地加入语义类别之间的关系约束。</p></div><div class="el-p"><p dir="auto">（10）Recent Advances in Zero-shot Recognition[15]</p></div><div class="el-p"><p dir="auto">综述性的文章，读起来很顺畅，可以看看别人是怎么写综述，中顶刊的。</p></div><div class="el-p"><p dir="auto">以上几篇文章，是我认为较有代表性，比较值得读的工作。</p></div><div class="mod-footer mod-ui"></div></div></div></div></div></div><div class="sidebar-right sidebar"><div class="sidebar-handle"></div><div class="sidebar-topbar"><div class="topbar-content"></div><div class="clickable-icon sidebar-collapse-icon"><svg xmlns="http://www.w3.org/2000/svg" width="100%" height="100%" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="3" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><path d="M21 3H3C1.89543 3 1 3.89543 1 5V19C1 20.1046 1.89543 21 3 21H21C22.1046 21 23 20.1046 23 19V5C23 3.89543 22.1046 3 21 3Z"></path><path d="M10 4V20"></path><path d="M4 7H7"></path><path d="M4 10H7"></path><path d="M4 13H7"></path></svg></div></div><div class="sidebar-content"><div class="graph-view-wrapper"><div class="sidebar-section-header">Interactive Graph</div><div class="graph-view-placeholder">
		<div class="graph-view-container">
			<div class="graph-icon graph-expand" role="button" aria-label="Expand" data-tooltip-position="top"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="svg-icon"><line x1="7" y1="17" x2="17" y2="7"></line><polyline points="7 7 17 7 17 17"></polyline></svg></div>
			<canvas id="graph-canvas" class="hide" width="512px" height="512px"></canvas>
		</div>
		</div></div><div class="tree-container mod-root nav-folder tree-item outline-tree" data-depth="0"><div class="tree-header"><span class="sidebar-section-header">Table Of Contents</span><button class="clickable-icon collapse-tree-button" aria-label="Collapse All"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></svg></button></div><div class="tree-scroll-area tree-item-children nav-folder-children"><div class="tree-item mod-tree-folder nav-folder mod-collapsible is-collapsed" style="display: none;"></div><div class="tree-item" data-depth="1"><a class="tree-link" href="project\知识储备\zero-shot.html#zero-shot"><div class="tree-item-contents heading-link" heading-name="zero-shot"><span class="tree-item-title">zero-shot</span></div></a><div class="tree-item-children nav-folder-children"><div class="tree-item" data-depth="2"><a class="tree-link" href="project\知识储备\zero-shot.html#零次学习（zero-shot_learning）基本概念"><div class="tree-item-contents heading-link" heading-name="零次学习（zero-shot learning）基本概念"><span class="tree-item-title">零次学习（zero-shot learning）基本概念</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\知识储备\zero-shot.html#目前的研究方式"><div class="tree-item-contents heading-link" heading-name="目前的研究方式"><span class="tree-item-title">目前的研究方式</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\知识储备\zero-shot.html#数据集介绍"><div class="tree-item-contents heading-link" heading-name="数据集介绍"><span class="tree-item-title">数据集介绍</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\知识储备\zero-shot.html#基础算法介绍"><div class="tree-item-contents heading-link" heading-name="基础算法介绍"><span class="tree-item-title">基础算法介绍</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\知识储备\zero-shot.html#ZSL中存在的问题"><div class="tree-item-contents heading-link" heading-name="ZSL中存在的问题"><span class="tree-item-title">ZSL中存在的问题</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\知识储备\zero-shot.html#有关ZSL的一些其他的概念"><div class="tree-item-contents heading-link" heading-name="有关ZSL的一些其他的概念"><span class="tree-item-title">有关ZSL的一些其他的概念</span></div></a><div class="tree-item-children nav-folder-children"></div></div><div class="tree-item" data-depth="2"><a class="tree-link" href="project\知识储备\zero-shot.html#推荐阅读的论文"><div class="tree-item-contents heading-link" heading-name="推荐阅读的论文"><span class="tree-item-title">推荐阅读的论文</span></div></a><div class="tree-item-children nav-folder-children"></div></div></div></div></div></div></div><script defer="">let rs = document.querySelector(".sidebar-right"); rs.classList.add("is-collapsed"); if (window.innerWidth > 768) rs.classList.remove("is-collapsed"); rs.style.setProperty("--sidebar-width", localStorage.getItem("sidebar-right-width"));</script></div></div></body></html>