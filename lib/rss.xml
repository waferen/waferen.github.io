<?xml version="1.0" encoding="UTF-8"?><rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0"><channel><title><![CDATA[note]]></title><description><![CDATA[Obsidian digital garden]]></description><link>http://github.com/dylang/node-rss</link><image><url>lib\media\favicon.png</url><title>note</title><link></link></image><generator>Webpage HTML Export plugin for Obsidian</generator><lastBuildDate>Sun, 12 Jan 2025 03:29:24 GMT</lastBuildDate><atom:link href="lib\rss.xml" rel="self" type="application/rss+xml"/><pubDate>Sun, 12 Jan 2025 03:21:40 GMT</pubDate><ttl>60</ttl><dc:creator></dc:creator><item><title><![CDATA[比较教育学]]></title><description><![CDATA[ 
 <br><br>有兴趣做这个选题是因为前段时间做教育哲学作业的时候读《理想国》，里面苏格拉底认为算数、平面几何、立体几何、天文学是能让灵魂转身的学科，这里的转身是指洞穴之喻里的转身，也就是看清事物的本质。不难看出，前面的三个概括起来就是我们如今的数学。而我们也常听到一个理论，说国内的学生考试分高，但是数学思维会比美国学生差，这在科研阶段会体现出来。<br>比如下面是一位电子工程师的抱怨：<br>
作为一名工作十多年的电子工程师，想再提高自己的专业水平时，深感数学能力的重要。随便打开一篇论文或一部专著，满纸的向量、矩阵、微分方程词汇扑面而来。竭力迎头而上，每每被打得灰头土脸、晕头转向。我天生就不是搞数学的?我的智力有问题吗?在高校、科研院所或大型企业里工作，可能还有专家、教授级的导师指引着进行理论上的研究，但大部分的大学生一毕业就进入了各类中小企业，在这些企业里的研发工作，基本上都是低级模仿，想弄点理论研究常无从下手，感觉大学是白上了。找点资料看看吧，大多是数学公式满篇，解释抽象模糊、思维之断崖重重。茫然之中仿佛看到专业作者们高深莫测、神龙无尾、高傲自去的背影。太失望了，太伤自尊了。扭头看看周围的同行，莫不雷同。大多的工程师们靠经验来工作，经验靠时间或试验来积累。数学应用的层次多是高中水平。也有硕士博士级的牛人，但也少见把数学工具在工作中应用的得心应手、手到擒来的。数学工具在科技实践中缺失的严重，导致我们的企业科技创新能力的严重不足。普遍现象，绝对的。<br>所以，这种差别到底出现在哪儿呢？可能与从小的数学思维培养就有关，但是这样这个话题就太大了，我们单从本科阶段的数学教育来作比较，中美两国学生都是从这个阶段开始接触高等数学，也就是现代科研的数学基础。<br>前面那个电子工程师还写了一本书，叫《线性代数的几何意义》，刚刚的话是他前言里的话。后面还有一段：<br>
“为啥没有在四年的大学阶段学好“线性代数”呢?要知道，学生是通过高考百里挑一录取的，智力应是足够正常的。思来想去，得到几个原因:教材编的大多不好，老师教的大多乏味，学生大多有些偷懒。<br>
学生偷懒原因不只一个，但我觉得主要一个原因是他们学起来困难--因为他们大多不知道这些内容有啥用，概念为啥这么叫，定理为啥那样推，老师为啥像刘谦的魔术一样七推八导就证毕了--郁闷多了导致了无语的偷懒。太多的为啥了。<br>
既然错不在学生那就是老师的问题了?其实老师也很委屈:教学大纲要求在几十个学时学习如此多的内容，不填鸭行吗?在如此短的时间内讲完就不错了，哪里还有时间给你释疑解惑--韩愈定义的传道授业解惑的师道中的解惑被迫取消了，自己悟道吧。殊不知，惑之不解则道难传而业无授也。”<br>其实这里就说明了几个最重要的因素了，教材的防自学能力，老师赶进度的填鸭式教学，学生听不懂干脆摆烂的心理。这里放两张教材对比图。<br><br>国内教材和国外教材这里有一个比较。<br>图注：国内教材，基本全部是定义加例题形式，没有一张图。<br>
<img alt="扫描件_第三章组织局再次二次盟_001.jpg" src="\lib\media\扫描件_第三章组织局再次二次盟_001.jpg"><br>图注：明确的重点<br>
<img alt="{9921F2B1-8D33-424C-8863-4EE5A4B90E76}.png" src="\lib\media\{9921f2b1-8d33-424c-8863-4ee5a4b90e76}.png"><br>
图注：辅助理解的图示<br>
<img alt="{BCA3188C-C064-4AE0-8F4A-C9509476B9FF}.png" src="\lib\media\{bca3188c-c064-4ae0-8f4a-c9509476b9ff}.png"><br>
图注:学科交叉与应用<br>
<img alt="{930D1A4D-D85C-4194-93A6-C7FF7C5C675C}.png" src="\lib\media\{930d1a4d-d85c-4194-93a6-c7ff7c5c675c}.png"><br><br>不仅是教材上的差距，还有整个教学方案上的差距，这是OCW上MIT的线性代数课程，从课程视频到考试题目，到课件，练习讲解都是有的，所以对于自学能力强的学生他完全可以自己学，整个学习路径都是完备的，你按照这个路走就可以了。<br>这种自学资源的缺失导致即使是想要去学的学生也无从下手。美国中学数学教育中的一些AP课程（Advanced Placements，俗称大学先修课程）实际上已经涉及到高等数学教育的内容。他们搭建好了一个对于自学能力强的学生的一个自学通道。这点很重要。<br>当然这些年国内也在去做这些事，比如MOOC，Bilibili，有一些老师为爱放电。南大有一门非常有名的课ICS，计算机系统基础。为什么这个课有名，就是它有非常完备的自学文档，这些就是自学的脚手架。而我们学校，或者说大多数的院校的大多数课程自学辅助是缺失的，即使有，大多数是老师为了完成任务录的水课，纯念PPT。当然也有比较负责的老师，有比较细致的习题课，比如我们的概率论老师，但是也只有习题课资源。<br>图注：MIT线性代数课程<br>
<img alt="{2D9E845E-E3C3-47BF-B809-119D684DFB4C}.png" src="\lib\media\{2d9e845e-e3c3-47bf-b809-119d684dfb4c}.png"><br>图注：南大ICS课程<br>
<img alt="{EE8AF69A-D189-434D-915E-6C109F7DAD16}.png" src="\lib\media\{ee8af69a-d189-434d-915e-6c109f7dad16}.png"><br>图注：南师大概率论课程资源<br>
<img alt="{704AB1F8-0F6A-412B-99B8-42CD07F6C692}.png" src="\lib\media\{704ab1f8-0f6a-412b-99b8-42cd07f6c692}.png"><br><br>我们很多时候会说是中国人多，老师少，教学资源不够，这是导致教学效果差的根本原因。其实这不成立。<br>美国有一种所谓的TA（teaching assistant）师资，由在读的研究生组成。国内很多申美国硕士或者博士的都会兼职TA，即在读的研究生可以申请TA，承担一些大学数学课程或习题课的教学，而中国的研究生助教在校是不能进行正规数学课程教学的。大部分只做一些收作业批作业整理成绩的机械性工作。美国数学研究生毕业找工作的时候需要写一个Teaching Statement，因此也要求他们在研究生阶段从事TA的工作。<br>另外一个差别，美国的大学除了本校数学教师和其正在培养的研究生（硕士、博士都有）作为数学课程的任课教师，有时还会通过支付一定薪酬的方式短期或长期招聘一些毕业生或其他学校教师担任数学课程的任课教师。相比而言，中国的大学数学教师都必须是已经毕业且获得从教资格的本校教师。现在的一个默认的规定，在大学上讲坛讲授数学课程的必须博士毕业，具有博士学位是最低且必须满足的条件。<br>从表面的对比来看，美国的大学对数学教学的师资要求不如中国的严格。但这个表面只停留在学位及毕业证书和教师资格证等等本本的有无上，实质上美国大学对大学数学课程的任课教师的要求重在教学能力以及教学能力的培养（后者主要是针对承担教学的研究生而言），而不在于是否有上岗必需的一些证书。这是中美大学数学教师的本质差别所在。<br>国内近些年来似乎默认了，大学老师必须是博士毕业。这点其实很奇怪，国内硕士人数已经比美国多了，但博士人数还差一些。相对于硕士，博士脱离基础学科时间更久，他们在自己的一个小领域内更专业，但要说对比如线性代数，比如计算机组成原理等专业基础课程，其实不见得他们就比本硕毕业的人更熟悉，理解得更透彻。而造成这种本科教育问题的根本原因可能还是高校以论文数量为目的而不是以教学为目的，他们招更多的博士也不是为了让他们教学生的，而是让他们来产论文的，教学成了附属品，自然效果就差了。]]></description><link>culture\教育学\比较教育学.html</link><guid isPermaLink="false">Culture/教育学/比较教育学.md</guid><pubDate>Mon, 11 Nov 2024 03:13:32 GMT</pubDate><enclosure url="lib\media\扫描件_第三章组织局再次二次盟_001.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\扫描件_第三章组织局再次二次盟_001.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[毕业论文]]></title><description><![CDATA[ 
 <br><br><br>今天正好趁着教育研究方法开题，顺便开始构思毕业论文，今天读了很多论文，也算有所得。今天需要把大概的框架搭出来，把几个有意思的点列出来，之前的文献综述废弃，写一篇新的。<br>
<br>读15篇论文
<br>想个题目
<br>论文框架
<br>主要论点
<br>文献综述
<br><br><br><br><br>“我们以言说和行动让自己嵌入人类世界”阿伦特将这种嵌入称作人的第二次诞生。正如《公共人的衰落》一书所讲，在当代社会，人们日益陷入了以自我为中心的个体化生存状态:"人们越来越关注自我的同时，与陌生人的交往却越来越少了"；人们虽穿行于街道、广场、办公区域等公共场所，但是“人们相互看见又彼此隔离”。在现代生活中，人们的公共关怀意识、公共责任观念及公共道德精神等遭受了严重的阻抑，其最终后果就是如桑内特所言的“公共人走向了衰落”。<br><br><br>思辨研究<br><br>界定研究范围，即是什么，我们需要讨论我们所研究的是哪一种具体的群体？<br>
即这样一种群体：<br>
节能：<br>
<br>他们给人一种冷感，对任何事情表示漠不关心
<br>有着比较强的个体边界敏感性
<br>以一种节能，低压的状态生活
<br>避免与他人发生联系，拒绝社交
<br>不发言、不争辩<br>
内耗：
<br>追求个体主体性，有比较强的精神内耗。这种对主体性的追求有一种很强的个体边界感，而这种边界干阻隔了他者，但其实没有他者在场的主体性没有任何意义，反而无法满足其主体性被肯定的需求。也就是越不愿意在主体性上退一步，越得不到主体性的肯定。
<br>但其实其并不知道自己要什么
<br>存在一种孤独感、缺失感
<br>认同心之壁，认为人与人之间的情感无法互通
<br>我们通过否定一些范围来缩小我们的研究范围。<br>
他们不是什么：<br>
<br>不同于佛系、躺平等概念，而是一种更隐形的、更深层的精神世界迷茫的群体。
<br>佛系、躺平等概念是源于内卷，源于一种解构主义对主流的反抗
<br>不同于丧文化，其本质上并不是消极的，也不具有强烈的反抗精神。
<br>不同于单向度的人，其没有丧失批判性能力。其往往不再在意消费主义需求，以够用就行的态度生活，这点类似佛系青年。佛系青年在其语义还没有延异的时候所代表的群体与我所说的节能群体类似，但是节能青年多了一种排他性的特点，二者的底色都是冷漠的。
<br><br>我们基于的理论又是哪些？这些理论与该研究问题的联系。<br><br>阿伦特区分了对于人的境况来讲最为根本性的 三种不同形式的人类活动，即劳动（ｌａｂｏｒ）、工作（ｗｏｒｋ）和行动（ａｃｔｉｏｎ）<br>“我们以言说和行动让自己嵌入人类世界”阿伦特将这种嵌入称作第二次诞生，它是人在与他人共享的公共世界中的诞生。“可以表明他们是谁，主动地解释他们显示的个人身份”，，从而才能在公共<br>
世界中显现出来。一个人只有在这一公共世界中才 能成为全人（ｆｕｌｌｙ ｈｕｍａｎ），只有通过行动才能显示 自我的主体身份，个人的身份彰显只能出现在纯粹 的人类归属感（ｔｏｇｅｔｈｅｒｎｅｓｓ）当中。在行动中，（复 数的）个体从不同角度同他者分享人类世界的共同经 验，发展出一种共享的共同感（ｃｏｍｍｏｎ ｓｅｎｓｅ），才能 塑造出一个共同世界（ｃｏｍｍｏｎ ｗｏｒｌｄ）。而这种塑造 的本质，在阿伦特看来，是政治的。这也可以看出， 阿伦特对人类社会的解读是一种事实上的政治人类学。——把儿童“领入世界”：阿伦特式教育思考<br><br>“此在的世界是共同世界。” 与他人共同存在是海德格尔生存论的构成因素。海德格尔的“共在”与主体间性哲学有着某种亲缘性，它们均源于一种对 主观主义的反思。从某些意义上说，“共在”就是一种主体间性理论，它以一种生 存论的“此在”为根本。人活着的过程不可避免地总有他人“在场”。这并不是说预 先具有一个主体性的此在来打量、审视他者，而是“我”与“他”的相遇。“他”不是自我之外的整体的余数，而是自我的复制品，是在我们之中、与我本身并无差别的人。 ——让儿童与世界美好相遇<br><br><br><br><br><br>价值研究<br><br>
<br>生存空间的转变：被动社交———&gt;主动社交
<br>单向度社会产生的劳动异化
<br>如何行动教育的缺失
<br>节能青年无法意识到自己缺失的是什么，或者他们认定的自己所缺失的是一种具体的人生意义，但这种无限追问式的寻找最终只能导向虚无。
<br>其真正缺失的是阿伦特所说的“行动”，缺乏的思想是海德格尔的“共生”。
<br>站在这个视角，认为应该进行什么样的教育？<br><br><br><br>
<br>补全教育中的行动缺失，教师帮助儿童参与到公共空间中。
<br><br>
<br>自我教育，如寻找身边的小共同体，寻找社群。
<br>从诺丁斯关怀理论理解他人，打破心之壁。
<br><br><br>题目：<br>
“节能”与“内耗”——论当代青年的行动教育缺失<br>
——基于阿伦特的“行动”理论<br><br>近些年来，随着第一代在信息时代成长起来的二十一世纪儿童成为青年，出现了诸如佛系、躺平等对当代青年的评价，这本质上是一种解构主义对主流的反抗，是正常的下行经济周期下，青年对环境的一种逃避和反抗。而我认为佛系与躺平本质上还是积极的，其看似消极，但本质上还在追求一种与生活或者社会的和解，他们本身是想过好生活的，而被掩盖在这之下的正在蔓延在整个青年群体中的且是这个时代青年所独有的一种冷感才是我们应该警惕的，我称之为节能。所谓的“节能”，指的是一种冷漠、逃避、低压的生活态度，个体在社交和行动上极力避免“能量”的消耗，认为与他人相处是一种对个人能量的消耗；他们对外界的一切都持拒绝姿态，且有很强的个体边界敏感性。而这种将自己围起来的方式，造成了一种内耗，这种内耗区别于所谓的精神内耗，其并不是说感觉自己如何不够好，这种内耗更多是跟内心孤独感的对抗，即一方面其不愿于世界交流，而另一方面这种封闭让他们备受孤独煎熬，缺乏生命的支点。<br>这种现象反映了当代青年在教育过程中可能存在的严重缺失——行动教育的缺失，即他们没有能力或者没有意识人要与世界建立连接。根据阿伦特的“行动是人的第二次诞生”思想，行动是人类社会的核心，通过与他人共同参与公共世界的建设，个体才能实现自我认同和主体性。然而，当代青年似乎无法有效参与这一过程，且在公共话语的影响下更加深了个体的隔阂，现实社交中更表现出信任缺失等问题，形成了一种现实世界与公共话语的相互塑造，恶性循环。他们在生活中表现出的“节能”和“内耗”正是这种缺失的体现。而我认为行动本身如技能一般是可以通过实践、示范等直接方式进行教育的。如老师有意地组织学生组建同好团体等。<br>从存在主义教育框架出发，本研究旨在探讨“节能”与“内耗”现象背后的教育缺失问题，分析教育如何影响个体的自由、选择、责任感和自我实现，进而为当前教育体系提供可能的改进方向。<br><br>界定研究范围，即是什么，我们需要讨论我们所研究的是哪一种具体的群体？<br>
即这样一种群体：<br>
节能：<br>
<br>他们给人一种冷感，对任何事情表示漠不关心
<br>有着比较强的个体边界敏感性
<br>以一种节能，低压的状态生活
<br>避免与他人发生联系，拒绝社交
<br>不发言、不争辩<br>
内耗：
<br>追求个体主体性。这种对主体性的追求让他们有一种很强的个体边界感，而这种边界干阻隔了他者，但其实没有他者在场的主体性没有任何意义，反而无法满足其主体性被肯定的需求。也就是越不愿意在主体性上退一步，越得不到主体性的肯定。
<br>但其实其并不知道自己要什么
<br>存在一种孤独感、缺失感
<br>认同心之壁，认为人与人之间的情感无法互通，这一部分可以讨论濠梁之辩
<br>我们通过否定一些范围来缩小我们的研究范围。<br>
他们不是什么：<br>
<br>不同于佛系、躺平等概念，而是一种更隐形的、更深层的精神世界迷茫的群体。
<br>佛系、躺平等概念是源于内卷，源于一种解构主义对主流的反抗
<br>不同于丧文化，其本质上并不是消极的，也不具有强烈的反抗精神。
<br>不同于单向度的人，其没有丧失批判性能力。其往往不再在意消费主义需求，以够用就行的态度生活，这点类似佛系青年。佛系青年在其语义还没有延异的时候所代表的群体与我所说的节能群体类似，但是节能青年多了一种排他性的特点。
<br><br>本研究旨在回答以下核心问题：<br>
<br>
什么是“节能”？

<br>
“节能”这一现象与“行动”的内在联系？<br>
论证“节能”这一现象是源于行动缺失。

<br>
基于海德格尔共在的存在主义反思，思考“行动”的必要性。

<br>
存在主义教育如何为解决“节能”与“内耗”提供理论依据？<br>
如何通过教育帮助学生面对精神迷茫？

<br>
论证“行动”的可教性<br>
我认为“行动”需要的东西与杜威所说的判断力，敏感性，性格力量类似，但不同的地方在于杜威的这三点分别针对道德认知、道德情感和道德行为，而我认为行动也需要这样一种对内在动力，

<br>
批判基于有用之用的现代教育所丧失的学生对于真正的真理即海德格尔“原始之真”的真实感受，丧失了实际的生命体验，而只活在人为构建的抽象化后的符号世界。

<br>
原始之真是人与存在感遂通所产生的直观印象。他是对自行这笔、混沌不分的存在本身的一种去蔽。于是直观地敞显出一种未经理性侵染的原现象。这种原现象根本上是存在使用人来本质现身，而任何通过人的现身都是情绪的现身，唯有在情绪的现身作为原现象发生之后，对事物及情绪的理性反思和逻辑判断才有可能。<br>
所以海德格尔强调：真理更优先更深邃的本质是主客未分，心物未立状态时的感通和去蔽，而不是之后才进行的真假对错，符合与否意义上的逻辑判断。<br>
原始之真意味着海德格尔所说的实际生命经验，意味着胡塞尔所说的比理性世界更根本的生活世界。
<br><br>本研究基于存在主义教育框架，结合阿伦特的“第二次诞生”思想和海德格尔的“共在”理论，探讨教育如何影响个体的行动力、主体性以及与他人和世界的关系。<br>
<br>
存在主义与教育<br>
存在主义认为，教育应帮助个体面对生命的根本问题，理解自我存在的意义，并促使个体通过自由选择和承担责任来实现自我。萨特（Jean-Paul Sartre）强调个体的自由选择和自我创造，而海德格尔（Martin Heidegger）则提出“此在”与“共在”的思想，强调个体总是与他人共同存在，人的存在无法脱离他人的关系和社会环境。

<br>
阿伦特的“第二次诞生”理论<br>
阿伦特将人的“第二次诞生”定义为个体通过与他人分享公共世界中的经验而实现自我认同。她认为，行动是人的根本，人只有在与他人共同的公共世界中，才能显现出完整的自我。因此，教育应该关注个体如何通过行动建立自己的人际关系，参与到公共世界的建设中去。

<br>
海德格尔的“共在”理论<br>
海德格尔强调，人类的“此在”并非孤立存在，而是与他人共同构成“共在”的世界。教育不应仅仅关注知识传授，更应帮助学生理解如何与他人共同存在，如何通过与他人的互动来实现自我认同。

<br><br>本研究的主要目的是通过存在主义教育的视角，探讨“节能”与“内耗”现象的教育学根源。具体目的如下：<br>
<br>
揭示“节能”与“内耗”的教育学本质：分析当代青年为何在行动和主体性上陷入困境，教育缺失如何导致他们的自我认同迷失、社会参与缺乏。

<br>
探索存在主义教育对个体自我实现的启示：通过存在主义的核心理念（自由、选择、责任、共在），为青年提供解决“节能”和“内耗”的教育对策。

<br>
为教育改革提供理论支持：从存在主义教育角度提出改进大学教育的建议，尤其是如何帮助学生重建自我认同，激发行动力，打破内心的困境。

<br><br>本研究主要围绕以下内容展开：<br>
<br>
“节能”与“内耗”现象的理论分析<br>
分析“节能”与“内耗”背后的心理机制和社会背景，探讨这些现象与个体行动能力和社会参与能力的缺失之间的关系。

<br>
存在主义教育视角下的行动教育缺失<br>
探讨教育如何未能有效促进学生的自我实现、主体性以及与他人的互动。结合存在主义的自由、选择、责任等概念，分析教育中的不足之处。

<br>
基于阿伦特和海德格尔的教育实践建议<br>
提出针对“节能”和“内耗”群体的教育干预策略，探索如何通过行动教育、共生教育等手段，帮助学生克服内心的困境，重新获得自我认同和行动力。

<br><br>
<br>
文献分析法<br>
通过分析现有的教育学、心理学、社会学文献，尤其是存在主义相关理论文献，结合“节能”和“内耗”现象进行理论归纳，探讨教育的缺失和不足。

<br>
质性研究法<br>
通过深度访谈、焦点小组讨论等方式，收集青年关于“节能”与“内耗”的真实经历与感受，分析其背后的教育原因。

<br>
案例分析法<br>
选取典型的青年群体或教育实践案例，探讨在实际教育环境中，如何通过存在主义教育理念来应对“节能”和“内耗”问题。

<br><br>
<br>
阐明“节能”与“内耗”现象的教育学根源：通过存在主义教育框架，分析青年的行动缺失及其心理机制，提出教育应如何关注个体的自我实现和主体性培养。

<br>
提出教育对策：结合阿伦特和海德格尔的思想，提出具体的教育改进措施，帮助学生重新获得行动力，摆脱内心的困境。

<br>
为教育改革提供参考：为当代教育改革，特别是在大学教育中，提供理论支持和实践指导，推动教育更好地服务于学生的全面发展。

<br><br><br><br>“我们以言说和行动让自己嵌入人类世界”阿伦特将这种嵌入称作人的第二次诞生。正如《公共人的衰落》一书所讲，在当代社会，人们日益陷入了以自我为中心的个体化生存状态:"人们越来越关注自我的同时，与陌生人的交往却越来越少了"；人们虽穿行于街道、广场、办公区域等公共场所，但是“人们相互看见又彼此隔离”。在现代生活中，人们的公共关怀意识、公共责任观念及公共道德精神等遭受了严重的阻抑，其最终后果就是如桑内特所言的“公共人走向了衰落”。这种衰落随着信息时代的到来让我们感觉更加明显。<br>近些年来，随着第一代在信息时代成长起来的二十一世纪儿童成为青年，出现了诸如佛系、躺平等对当代青年的评价，孙桂香在“躺平的佛系青年”——互联网时代结构主义思潮的符号嬉戏一文中表示：这本质上是一种解构主义对主流的反抗，是在历史上的每一个社会转型期都会出现的解构主义思潮。<br>还有一些学者，如卜建华在“佛系青年”群像的社会心态诊断与支持中认为：佛系青年的“无所谓，一切随缘”的态度并不是看破社会的指挥，而是当面对自身童话世界和残酷现实世界的对立时，对社会压力的逃避和生活的妥协。并认为中国孕育“佛系青年”的社会环境与日本的低欲望社 会具有本质性区别，日本低欲望社会的出现是人们从 追求物质生活向追求精神生活转变，是由于文化程度 的普遍提高而导致的理念变化，这种转变是主动式 的。而中国“佛系青年”现象更像是一种对现实的被 动接受，是在看到了“草根逆袭”的不现实性后，对生活的无奈与逃避，其实质是一种遁世消极的文化。而连进承在“佛系青年”青年的思想特点及其原因分析中提出：佛系青年看似乐观知足常乐，其实是消极逃避的人生态度，得过且过不在乎他人看法和眼光，其实是“利己”主义和懒惰的表现。<br>再如陈玉娇在硕士论文社会变迁中的“佛系青年”研究一文中表示“佛系青年”的出现是社会 现实与 90 后群体的应对策略带来的青年角色紧张、角色退出、角色表演互动的 结果，基于话语、身份和精神三个维度的认同则是“佛系青年”群体稳定和壮大的前提。<br>这些学者整体对佛系、躺平持反对态度，或认为这是一种解构主义的嬉戏，或认为这是一种遁世消极文化是懒惰的表现，或认为是一种角色紧张。总体认为认为佛系青年是一种消极符号。<br>而我认为佛系与躺平本质上还是积极的，其看似消极，但本质上还在追求一种与生活或者社会的和解，他们本身是想过好生活的，而被掩盖在这之下的正在蔓延在整个青年群体中的且是这个时代青年所独有的冷感才是我们应该警惕的，我称之为节能。<br>所谓的节能指的是一种封闭，低压的生活态度；个体在社交和行动上极力避免"能量"的消耗，认为与他人相处是对个人能量的消耗；他们对外界持拒绝姿态，且有很强的个体边界敏感性。而这种自我封闭必然导致了一种内耗，这种内耗区别于我们所认为的精神内耗，其并非觉得自己哪里不够好，而是一种缺失感与迷茫感，这种缺失感并非娱乐至死，繁华尽去之后的虚无，而是没体验过人与人之间深刻联系，生长在一种冷漠、个人主义环境中而产生的一种缺失感。而这种迷茫感则体现在其不知道自己缺失的是什么，而认为其缺失的是一种本真的自我，而这种对自我本真的极端追求表现出来就是一种很强的个体边界敏感性，不容冒犯。而这种排他性的主体性会加重其与社群的脱离，因而产生恶性循环。<br>李文静在当代学生人际交往冷漠症的教育伦理分析及其引导中提出，学生间人际交往的冷漠症是教育中忽视学生人际交往重要性的消极后果，而这种现状又使学生间的人际交往关系变得更加冷漠。著名社会学家舒茨认为人类个体间在人际交往的活动中必须满足包容、 支配和情感这三种需要。而这三种需要也是构成人际交往的最基本部分。”，但当前学生间存在的人际交往冷漠症使得他们在人际交往活动中并不能获得以上三种最基本的需要，这会使他们更加拒绝与他人产生相互关系。我认为其洞察到了这种“节能”现象，但我认为不应该称之为冷漠，即他们不是道德意义上的冷漠，而是社交层面上的冷感。<br>也有人将这种现象归于发达资本主义工业社会下所产生的单向度的人，如林樱枝在论当代青年价值观的异化与重塑——基于马尔库塞异化理论中提到当代青年价值感异化的表现体现在生命价值观——视如草芥，理想信念观——胸无大志，消费价值观——享乐主义。我认为不同于单向度的人，节能青年没有丧失批判性能力。其往往不再在意消费主义需求，以够用就行的态度生活。<br>而我认为这是一种"行动"能力的缺失导致的。阿伦特将"行动"看作是人的第二次诞生，认为通过与他人共同参与公共世界建设，个体才能实现自我认同及主体性。而我认为这种"行动"能力是后天塑造的，即行动的可教性。类似杜威将个人品德分为性格力量、敏感性、判断力，行动的能力也需要对"行动"重要性的意识，对如何"行动"的能力，与实施"行动"的动力。<br>而高德胜认为在论教育的行动性一文中提到：相对而言，教育与行动的关系最为密切，或者说教育具有行动性，教育就是一种行动。首先，行动是自由的，即超越了生存必然性和必需品的限制。获得自由，意味着一个人必须让自己从生存必然性中解放出来。但我认为如果仅限于学校教育，如今的现代教育还谈不上一种行动，其没有超越生存必然性，即学生受教育已经带着一种生存必然性了，而无法想象不上学的生活，即其上学就是为了未来的生存。所以我们追求一种教育的行动性，即教育回归到一种超越了生存必然性和必需品的限制的状态。<br>项继发在把儿童“领入世界”：阿伦特式教育思考中提到：在《人的境况》中，阿伦特发展了自己关于人 的存在的哲学人类学思想。阿伦特之前的哲学传统，将人一直看作思考性的存在。根据这一传统，人 类的本质是“沉思”（ｖｉｔａ ｃｏｎｔｅｍｐｌａｔｉｖａ）［３］１４。但在阿伦特看来，这种传统已经不适用于描述现代人。 相反，她将“积极生活”（ｖｉｔａ ａｃｔｉｖａ）看作现代人的特征。现代人的生活模式理当是一种行动式的生活。行动式的生活摆脱 了生物性生命过程的束缚，不再将生活看作在世界中的简单谋生或者生存，而是在开放性、复数的世界中，进入社会公共领域，展现自己的个性。<br>而在现代教育的困境与“行动”的教育中章乐提出解决现代教育的困境，需要构建“行动”的教育，因为“行动”的教育直面人诞生的事实，并承担起“新人”成长和维护“世界”存续的重大责任。<br>王鑫在让儿童与世界美好相遇 ———基于海德格尔“本源之思”的教育美学诠释中提到：在“共在”中，自我与他者是对称的、平等的交互关系，其典型特征便是双方可以互换位置。<br>基于海德格尔的“共在”理论，我们能解释“行动”的必要性。]]></description><link>culture\教育学\毕业论文.html</link><guid isPermaLink="false">Culture/教育学/毕业论文.md</guid><pubDate>Wed, 25 Dec 2024 12:55:03 GMT</pubDate></item><item><title><![CDATA[德育原理复习]]></title><description><![CDATA[ 
 <br><br><br>此类题答题要求：写出相应的要点。<br><br>1.简述古代德育与现代德育的区别。<br>古代德育： 范围广泛，涵盖政治、思想、道德、法律、宗教等社会意识教育，与习俗、传统紧密相连，缺乏理性基础。<br>现代德育： 主要指道德教育，强调培养学生的道德意识和道德行为，关注学生的品德发展，并逐渐具有理性化特征。<br><br>古代有德育之实,但无德育之名。今天既有德育之实,又有德育之名。<br>
古代不存在独立形态的“德育”​。所谓“古代德育”,实际上是范围广泛的“习俗教育”或“社会意识教育”,包括今天所说的“政治教育”​、​“思想教育”​、​“法制教育”​、​“礼仪教育”等。它相当于今天所谓广义的“思想教育(ideological education)”​。<br>
在西方教育理论中,道德教育与政治教育、思想教育有严格的界线,它们分属不同的概念,并未被笼统地称作“德育”​。在近现代西方语言和观念中,所谓“德育”指的是“道德教育”,它的外延远远小于古代的“社会意识教育”​。<br><br>2.教育的各项标准。<br>
一种活动或影响若要称得上是“教育”,必须满足一定的标准。根据上面的分析,可以把“教育”的标准分为两类:一类是认知标准,另一类是道德标准。<br>
找不到“{112515BA-A799-4366-9E2A-96F3D8427C84}.png”。<br><br>3.道德的学与教同知识和技能的学与教的区别何在？<br>道德的学与教： 核心是态度学习或情感学习，难以用直接的口授和训练方式教授，需要通过间接的方式渗透在知识和技能教学中。<br>知识和技能的学与教：&nbsp; 主要指间接经验的学习，可以通过口授和训练等方式直接教授。<br><br>找不到“{A4DACBF0-BFD4-4139-8DAA-72C66F62798D}.png”。<br>
作为间接经验的知识,这种知识的学习实际上是一个“知什么”的问题,不一定要落实到行动上,因而可以用口授的方式直接教。<br>
技能却是一种直接经验,技能的学习除了有“知什么”的问题,更多的是“知如何”的问题。​“知如何”的实质是“会”,所以技能的学习必须落实到行动上,在实践中摸索,在做中学,通过不断练习达到熟练。与此相应,教的方式主要是示范和训练。<br>
美德的核心是态度问题。一个人在道德上“知”和“会”固然重要,但是“知之”​、​“会之”并不保证“为之”​。欲使人自觉“为之”,须先使人“信之”​，就是说,使人在情感或态度上倾向于“所知”​、​“所会”​。这种认同感的形成,需要诉诸学生在学与用中对于所学和所用的知识和技能的价值一种亲身体验。一般认为,道德对个人而言是一种有倾向的直接经验,难以用直接的方式加以教授,广泛而有效的道德教育,是渗透在知识和技能教学及学校集体生活各个层面的道德影响,即间接的德育。<br><br>4.简述品德结构中知、情、意、行四者的关系。<br>
知：&nbsp; 对道德规范的认识和理解。<br>情：&nbsp; 对道德规范的情感体验和态度倾向。<br>意：&nbsp; 对道德规范的意志力和行为动机。<br>行：&nbsp; 外显的道德行为。<br>四者相互联系，相互影响，共同构成一个人的品德。<br><br>主行说，持这种观点的人认为品德归根结底是合乎道德要求的行为。<br>
主知说(intellectualism) 知善方能行善,知恶必不为恶,人决不做自认为不对的事情。可见,对善或道德的认识是品德的基础,美德即知识。道德教育中心任务是使人“知善”,即提高学生对善或道德的认知水平。<br>主情说(emotionalism)知善却不行善的现象随处可见,个中原因在于人们往往缺乏行善的动力,所以，英国道德哲学家舍夫茨别利认为,道德的基础不在理智而在情感。道德起源于情感,情感是人行为的动力,人的情感取向是道德评价的基本标准。<br>主意说( volitionalism)持这种主张的人特别反对把道德与情感联系起来。他们认为，道德与情感不相干,不为个人情感所左右的行为才可能是道德行为。这就意味着意志才是品德的根本,坚强意志的培养和锻炼才是德育的核心内容。<br>品德是知情行的和谐结合，按照杜威的意思,性格 力量、敏感性、判断力是个人品德的三位一体,缺一不可。可以说,品德由道德认知、道德情感、道德行为等三个因素构成,缺少其中任何一个因素都不构成品德。<br><br>5.奖赏与惩罚的要点<br>
奖赏：&nbsp; 对道德行为的强化，目的是鼓励和巩固学生的良好行为。<br>惩罚：&nbsp; 对失范行为的抑制，目的是纠正学生的错误行为，帮助他们形成正确的道德观念和行为习惯。<br><br>(一)奖赏与道德行为的强化<br>
奖赏与表扬相配合,常可以强化受嘉奖的行为。<br>(二)惩罚与失范行为的抑制<br>
“惩罚”有三条基本标准:第一,它必须是学生违反规则的后果;第二,它必须对违反规则的学生有意施加某种痛苦或不快;第三,它必须由权威执行。<br>
<br>
惩罚的理由，他们为学校惩罚辩护的理由各不一样。概括起来说,大致可以分为三类理由:一类可以叫做“报应论”,一类叫做“改造论”,一类叫做“惩戒论”​。

<br>
学校惩罚的伦理原则，第一,必须按正当的程序实施惩罚。第二,必须结合改造和教育实施惩罚。第三,惩罚必须仅针对学生的道德过失。第四,必须以恰当的方式惩罚学生。

<br><br>6.简述说服与说教的区别。<br>说服：&nbsp; 通过讲道理、摆事实等方式，引导学生理解并接受正确的道德观念和行为规范，注重学生的理性思考和情感体验。<br>说教：&nbsp; 单纯地灌输道德教条，忽视学生的理性思考和情感体验，容易造成学生的逆反心理。<br><br>说服法强调对学生讲道理,但说理不等于说服。证据充分,推理合乎逻辑,并不足于使学生心服。若要使学生接受,陈述的道理以及说理的方式必须能为学生所理解。<br>脱离学生的生活经验,超越学生的认识水平,说理就会变成空洞的说教。不顾学生的接受能力,一味地向他们讲述远远高于其发展水平的人才能理解的道理,这些大道理即使被学生背得烂熟,也不会被他们的认知结构同化,自然也不能作为一种内在的道德价值观体现在学生的实际行动上。<br><br><br>此类题答题要求：写出要点，并展开论述。<br><br>1.请分析美德是否可教。<br>
(1) 伦理学的观点：<br>美德即知识：&nbsp; 苏格拉底认为美德就是知识，知识可教，故美德可教。<br>美德最终落实在行动上：&nbsp; 亚里士多德认为美德必须通过实践才能获得，并通过行动体现。<br>道德主要诉诸情感或态度：&nbsp; 一些学者认为道德的关键因素是情感和态度，通过培养学生的情感和态度可以促进其道德发展。<br>道德归根结底是意志的体现：&nbsp; 康德认为道德是意志的体现，意志不可改变，故美德不可教。<br>美德是理智与情意的综合表现：&nbsp; 包尔生认为美德是理智、情意和意志的综合表现，通过理性训练可以培养美德。<br>(2) 教学论的观点：<br>知识的学与教：&nbsp; 通过口授和训练等方式直接教授。<br>技能的学与教：&nbsp; 通过观察、模仿、练习、实践等方式直接教授。<br>态度的学与教：&nbsp; 核心是态度学习或情感学习，难以用直接的口授和训练方式教授，需要通过间接的方式渗透在知识和技能教学中。<br>(3) 语言学的观点：<br>意向之“教”与成功之“教”：&nbsp; 语言学的观点认为“教”有“意向之教”和“成功之教”之分，“意向之教”是指有意识地树立好榜样，“成功之教”是指无意识地对学生产生潜移默化的影响。<br><br>（1）伦理学的观点<br>(一)美德是可教的知识<br>
在苏格拉底看来,美德就是知识或智慧。人只做自己认为善的事情,不会故意作恶。作恶是出于对善的无知,错把恶当作善。明知故犯是一种假象,其实作恶者并非真正知道自己在作恶。人知恶必不作恶,知善必行善。而且,在智慧的指导之下,人的一切努力和禀赋的结局都是幸福的。所以说,美德即知识。知识可教,故美德可教.<br>
(二)美德可教但无需专门教师<br>
对于苏格拉底的迷惑,普罗塔哥拉解释说:学习美德类似于学习母语。希腊婴儿不像天生蓝眼睛那样天生就有希腊语知识和技能，他们必须通过后天学习,才能掌握自己的母语。<br>
(三)美德可以通过榜样示范和批判性指导下的训练来教<br>
亚里士多德认为美德像技能那样,不能单独通过讲述来教,但能通过榜样示范和批判性指导下的实践来教。<br>
(四)美德可学不可教<br>
根据赖尔的意思,从“教”的日常语义上说,美德是可教的;从“教”的严格意义上说,美德是不可教的。就是说,如果把人们无意之间对年轻人品德潜移默化的影响称作“教”的话,美德是可教的;如果“教”限指有意识地树立好榜样之类的活动的话,美德就不可教。所以,与其讨论美德是否可教,不如讨论美德是否可学。<br>
(五)美德可间接教不可直接教<br>
赖尔认为美德不能单纯通过口授和训练的方式来教,这个论点总的来说是可取的。杜威认为美德可教,但不能直接地教,而只能通过直接的教间接地渗透道德影响。从“教”的间接意义上说,学校教师和家长等都是教美德的“专家”​。<br>（2）教学论的观点<br>
知识的学与教：&nbsp; 通过口授和训练等方式直接教授。<br>技能的学与教：&nbsp; 通过观察、模仿、练习、实践等方式直接教授。<br>态度的学与教：&nbsp; 核心是态度学习或情感学习，难以用直接的口授和训练方式教授，需要通过间接的方式渗透在知识和技能教学中。<br>现在，人们逐渐认识到，​“美德学习”或“道德学习”虽不免涉及知识和技能问题，但其核心是“态度学习”或“情感学习”​。这是一种有别于“知识学习”和“技能学习”的特殊学习类型。如果说“口授式教”和“训练式教”是“直接的教(directteaching)”​，那么，有意识地在知识和技能的教学过程中间接地渗透道德影响就是“间接的教(indirect teaching)”​。从“教”的直接意义上说，道德是不可教的;从“教”的间接意义上说，道德是可教的。<br>（3）语言学的观点<br>(一)意向之“教”与成功之“教”<br>
意向之“教”只意味着教的努力。成功之“教”,意味着“教会”,而不同于成功地“告诉”​。<br>(二)成功之“教”的行动性解释与非行动性解释<br>
成功的道德教学,并不必然导致道德的行为。我们开始时认为好行为的习得是成功的道德教学的必要条件,也就是,以“教”的行动性解释来讨论道德是否可教这个问题。可是,教学之后,我们可能发现,要评判道德教学是否成功(如欠债要还的道理是否可教),是一件非常困难的事。因为,要做到这一点,就必须判别学生在需要表现出这种品质的情境中是否真地做到了欠债还钱。面对这种难题,我们最后放弃对“道德是否可教”采取行动性解释,而改用非行动性解释。<br>(三)“美德是否可教”争论中的语言问题<br>
认为道德可教的人,也承认道德不一定教得会;而认为道德不可教的人,并不反对教师和家长教孩子以做人的道理。他们的分歧,不在观点上,而在语言上。前者所用的是意向性的“教”,后者用的是成功性的“教”​。总之,从语言学分析上看,以往关于美德是否可教的争论,观点上的分歧并不多,即使有,分歧也不大。许多激烈的争论,大部分原因都在于争议各方所使用的“教”含义不同。<br><br>2.试论直接道德教学。<br>(1) 什么是直接道德教学：&nbsp; 直接道德教学是指教师通过专门的道德课程或活动，直接向学生传授道德知识和规范，并进行道德训练的教学方式。<br>(2) 直接道德教学优点：<br>目的性强，针对性强，内容集中。<br>可以系统地进行道德知识的教学，帮助学生建立完整的道德知识体系。<br>可以有效地进行道德训练，帮助学生养成良好的道德行为习惯。<br>(3) 直接道德教学缺点：<br>容易脱离学生的生活实际，导致学生缺乏道德体验。<br>容易造成学生死记硬背，忽视学生的理性思考和情感体验。<br>容易造成学生逆反心理，抵触道德教育。<br><br>(1) 什么是直接道德教学：<br>直接道德教学是指教师通过专门的道德课程或活动，直接向学生传授道德知识和规范，并进行道德训练的教学方式。<br>(2) 直接道德教学优点：<br>
<br>在学科教学日益智育化,且未寻找到有效的办法通过学科教学实施德育的形势下,单独设立道德课,至少可以使学校德育的实施在课程和时间上得到最低限度的保证。
<br>开设单独的道德课，有利于系统地全面地向学生传授道德知识和道德理论,提高学生的道德认识。通过其他途径,则难以取得类似的效果。学校各科教学虽然都承担了道德教育的任务,但是,它们的重点在于知识和技能的授受,不会有太多时间专门处理道德事务,因而不可能充分引导学生去探讨较为复杂的道德问题。
<br>之所以要进行直接的道德教学,一个更为重要的理由是,道德教育是一种道德事业,必须奉行诚实原则。既然教育工作者的职责就是使学生成为有道德的人,就应该坦诚地向学生表明自己对道德教育目的、理性地解决道德难题所需要的品质、应当怎样形成这些品质的看法。对学生隐瞒自己在道德教育上的意图和观点,既不诚实,又很愚蠢。英国教育哲学家威尔逊(J.Wilson)甚至断言:如果我们不直接向学生传授道德知识,就是“根本不把学生当人看待”。
<br>(3) 直接道德教学缺点：<br>
<br>设置独立的道德课，本意是为了加强学校德育。但把道德教育与学科相提并论，实际上贬低了学校德育的价值和地位，使德育由学校教育的道德目的转变为学校教育的一项工作(教学)。这在观念上是一种倒退。
<br>德育领域宽泛而弥散,无明确界限,不能限制在一套固定的课程里进行教学。
<br>道德课实为关于道德知识的教学,与其说是在实施德育,不如说是在实施智育。而道德不仅仅是知识,难以用像讲授科学知识那样的方法讲授道德。安排一门独立的课程实施德育,道德教学不免流于宗教式的说教或劝诫,沦为道德灌输。
<br>难以确定谁有资格担任道德课教学。在传统的学科教学领域,教师的资格源于教师对所教学科的知识一定程度的了解。数学老师之所以为数学老师,是因为他对数学知识有一定程度的了解;历史教师之所以有资格教历史课,是因为他对历史知识有一定程度的了解。但是,谁能够决定哪个人在道德方面已经好到了足于向别人提供某种道德教学的程度呢?一个教师未必比一个清洁工更有资格从事道德教育。
<br>现代学校学科教学的任务繁重,教师和学生的大部分时间必须放在发展智力上,留给道德教学的时间非常有限。如果仅仅通过道德课进行道德教育,学校教育的道德目的就极有可能落空。
<br>学生从直接的道德教学中获得的主要是关于道德的知识,而不是美德。这正是道德课作用有限、效果不佳的原因。
<br>3.试论述间接道德教育。<br>(1) 什么是间接道德教育：&nbsp; 间接道德教育是指教师在传授知识和技能的过程中，有意地渗透道德影响，培养学生道德意识和道德行为的教学方式。<br>(2) 间接道德教育优点：<br>符合学生的认知规律，注重学生的道德体验。<br>可以将道德教育融入到学生的日常生活中，使道德教育更具实效性。<br>可以有效地培养学生的道德情感和道德意志。<br>(3) 间接道德教育缺点：<br>难以控制道德教育的内容和效果。<br>需要教师具有较高的道德素养和教育水平。<br>需要学校营造良好的道德氛围。<br><br>此类题答题要求：按题目要求分析<br><br><br>回答两个问题：<br>
<br>直接道德教育与间接道德教育的内涵
<br>直接道德教学的利与弊<br>
可参考文献
<br>德育原理——黄向阳
<br>道德教育原理——杜威
<br><br>我们这次主讲的主题是道德教育的途径。我主要回答两个问题，直接道德教育与间接道德教育的内涵与直接道德教学的利与弊。<br>
直接道德教育与间接道德教育是黄向阳德育原理中第八章的内容。<br><br>什么是直接道德教育呢，相信大家都不陌生。比如我们从小学到大的思政课。这些是我们以前公认的写作业课，老师上课在上面讲孔融让梨，问学生，如果是你会怎么做，学生在下面，我直接回屋写作业，乖乖写作业不比让个梨更让父母开心？<br>当然为什么我们的道德教育会成这样不是我今天要深究的事，但我们可能有一个直观的感受，这种直接道德教育对我们人格发展产生的影响似乎很小。其实不仅是感觉是，实际上也真的没用。1928-1930年,美国的一项实验研究表明:美国中小学开设的品德教育课和宗教教育课对儿童的道德行为没有影响,直接的道德教学并未培养出道德品质或道德良心之类的东西。50年代和60年代,美国的另两项调查也表明:美国一些大学单独开设的“美国政府课”和“公民课”与学生的民主态度基本不相关。正如杜威所言,直接的道德教学对学生行为即便有所改善,其数量也是有限的,其程度也是比较轻微的。<br><br>那么既然它似乎很没用，为什么会产生这样的直接道德教育课程呢？黄向阳给出了一个理由。通过古典人文学科的教学,自然地渗透道德教育,可谓学校德育的传统。然而,随着自然科学知识大量涌入学校和教室,学科教学逐渐与德育疏远,仿佛成了专门实施智育的途径,教育界不得不另辟蹊径实现学校教育的道德目的。<br>他认为自然科学知识的大量涌入导致学校逐渐成了专门实施智育的地方，导致人文学科式微，而道德教育总是渗透在人文学科的教育之中，而道德教育又是学校非常重要的教学目的，迫使它专门为其开设道德教育学科。我们思考下是不是这样，我们想想除了语文我们还有什么人文学科？似乎就历史政治了，但是如果你高中不选这两门人文学科，你的高中的人文学科似乎就剩下语文了。<br>我的高中语文老师对我影响很大，而我是在高中开始思考什么人生的意义之类的哲学话题的，当时面对很多比如虚无主义啊，价值真空啊等令我深夜emo的问题。但我那个老师，年近六十岁，每天工作到晚上一两点，自己经营一个公众号，我们的作业每一份他都批注有的批注比我们原文都多，写得好他就夸上天，写得差他就会批评，而且他字特别好看。我发现他热爱语文教学，他有激情，他有passion，对他来说这不是工作这是享受。当时我们上高中的时候正赶上疫情，然后那段时间的语文作业就是比如写诗给抗疫一线的工作人员，比如抨击一些社会上的现象的议论文，比如当时有人就是不戴口罩。其实现在想想这就是杜威讲的间接的道德教育，这种道德教育渗透在学科教育之中。<br><br>1872年,日本颁布《学制》,要求小学开设“修身”课,中学开设“修身学”课。算是历史上第一门道德课，到如今已经一百余年，这期间产生了很多对直接道德教育的质疑。<br>
<br>设置独立的道德课，本意是为了加强学校德育。但把道德教育与学科相提并论，实际上贬低了学校德育的价值和地位，使德育由学校教育的道德目的转变为学校教育的一项工作(教学)。这在观念上是一种倒退。
<br>德育领域宽泛而弥散,无明确界限,不能限制在一套固定的课程里进行教学。
<br>道德课实为关于道德知识的教学,与其说是在实施德育,不如说是在实施智育。而道德不仅仅是知识,难以用像讲授科学知识那样的方法讲授道德。安排一门独立的课程实施德育,道德教学不免流于宗教式的说教或劝诫,沦为道德灌输。
<br>难以确定谁有资格担任道德课教学。在传统的学科教学领域,教师的资格源于教师对所教学科的知识一定程度的了解。数学老师之所以为数学老师,是因为他对数学知识有一定程度的了解;历史教师之所以有资格教历史课,是因为他对历史知识有一定程度的了解。但是,谁能够决定哪个人在道德方面已经好到了足于向别人提供某种道德教学的程度呢?一个教师未必比一个清洁工更有资格从事道德教育。
<br>现代学校学科教学的任务繁重,教师和学生的大部分时间必须放在发展智力上,留给道德教学的时间非常有限。如果仅仅通过道德课进行道德教育,学校教育的道德目的就极有可能落空。
<br>学生从直接的道德教学中获得的主要是关于道德的知识,而不是美德。这正是道德课作用有限、效果不佳的原因。
<br><br>人们对直接道德教学的批评意见,在实践中不断得到验证。可是,当今世界几乎没有哪个国家的中小学撤销了道德课。<br>
<br>在学科教学日益智育化,且未寻找到有效的办法通过学科教学实施德育的形势下,单独设立道德课,至少可以使学校德育的实施在课程和时间上得到最低限度的保证。
<br>开设单独的道德课，有利于系统地全面地向学生传授道德知识和道德理论,提高学生的道德认识。通过其他途径,则难以取得类似的效果。学校各科教学虽然都承担了道德教育的任务,但是,它们的重点在于知识和技能的授受,不会有太多时间专门处理道德事务,因而不可能充分引导学生去探讨较为复杂的道德问题。
<br>之所以要进行直接的道德教学,一个更为重要的理由是,道德教育是一种道德事业,必须奉行诚实原则。既然教育工作者的职责就是使学生成为有道德的人,就应该坦诚地向学生表明自己对道德教育目的、理性地解决道德难题所需要的品质、应当怎样形成这些品质的看法。对学生隐瞒自己在道德教育上的意图和观点,既不诚实,又很愚蠢。英国教育哲学家威尔逊(J.Wilson)甚至断言:如果我们不直接向学生传授道德知识,就是“根本不把学生当人看待”。<br>
针对是否隐瞒自己在道德教育上的意图和观点是否正确这一价值判断问题。我们可以思考。
<br><br>随着德育研究的不断深入,新德育模式的不断涌现,上述信念开始遭到挑战。认知性道德发展模式、体谅模式、社会行动模式等表明,确有一些比较直接的教学方法,可以迅速地促进学生道德思维能力、道德敏感性、道德行动能力的发展(详见第九至十一章)。但是,这些直接的道德教学方法都是非常专业化的教学方法,有赖于教师对人类道德事务的深刻理解,有赖于教学方法上的专业培训。传统的道德课的教师确实未必比品德高尚的普通劳动者更有资格教道德,品德高尚者也未必有能力培养人的道德思维能力、道德敏感性和道德行动能力。因此,直接道德教学的问题不在于它的可能性,关键在于形成一套专门方法,并使道德课教师掌握它们。<br>
这里我找了一段视频，就是那个之前很火被骂的那个副教授郭继承，来没来，如来。<br>
看完是否有一种情绪被带动的感觉？如果有可能是因为有背景音乐。如果没有可能是我剪得太多了。我们到底是国运托起来的一代还是像日本一样失落的一代我们未知。但是里面有句话说得不错，直接道德教育是有可能在人心底埋下一颗种子的。但是呢这颗种子是要持续浇灌的，杜威说，直接的道德教学的影响即使在最好的情况下,在数量上相对而言也是比较少。这种视频可能会激起我们几天的热血，然后过几天就回归到生活的蝇营狗苟中去了，所以为什么基督教要做礼拜呢？每周都去接受直接道德教育。这种直接道德教育的精神力量是强大的。<br><br>而间接道德教育才是杜威所认为道德教育的主要部分。<br>他是这么说的无需讨论所谓的直接的道德教学(或更好的关于道德的教学)的局限性或价值,我们或许可得出这样的盖棺之论:如果把借助于教育的道德成长的全部领域考虑在内,直接的道德教学的影响即使在最好的情况下,在数量上相对而言也是比较少、在影响上则比较轻微。<br>在杜威看来任何学科教育最终都要落实到其与社会的联系中去，比如学了受力分析你应该让学生理解现实中的桥为什么那样造，我们当时是自己用纸手工做桥然后看谁做的桥承重更好。<br><br>杜威举了个例子，有人对我说,在某个城市里有一所游泳学校,这所学校没有到水中教青年如何游泳,而只是一味地反复训练各种各样为游泳所必需的动作。当一个接受如此训练的年轻人被问到他进入水中做了什么时,他简短地回答道:“下沉。​”这个故事碰巧是真实的;倘若不是真实的,它似乎是一个特意编造的寓言,旨在典型地说明学校与社会之间的伦理关系。<br>学校不能是社会生活的准备,除非它能在自身之内复制社会生活的典型条件。目前,它大半在像西西弗斯那样从事艰苦而无尽头的工作。它正在努力使儿童养成在社会生活中有用的习惯,然而它几乎好象谨慎而果断地防止训练中的儿童与这些习惯进行必不可少的接触。<br>为社会生活作好准备的惟一途径是参与社会生活。脱离直接的社会需要和动机以及现存的社会环境,欲形成有益于和有用于社会的习惯,不折不扣地说就是通过水外的动作教儿童游泳。最不可或缺的条件没有被考虑在内,其结果也就相应是片面的。<br>除了参与社会生活之外,学校就没有道德目的,也没有什么目标。只要我们把自己封闭在学校,一个孤立的机构之内,我们就没有指导原则,因为我们缺乏目标。<br>譬如,据说教育的目的是个体的全部能力的和谐发展。这里没有明显提到社会生活或社会成员身份,然而许多人认为我们已经充分而彻底地给教育目的下了定义。但是假如这一定义独立于社会关系,我们就无法说出任何一个所使用的名词的意思。我们不知道能力是什么;我们不知道发展是什么;我们不知道和谐是什么。能力只有依据其所能派上的用场及其必须发挥的作用,才不失为能力。倘若我们避而不谈社会生活所提供的用途,我们就只能让老一套的官能心理学来说明能力的意思和特定能力的意思。原则沦为列举许多能力,如知觉、记忆和推理等,然后指出这些能力中的每一种都有待发展。<br>简单的事实是，正如没有原始的做铁匠、做木匠或操作蒸汽机的能力一样,也没有任何孤立存在的观察能力、记忆能力或推理能力。能力只是表明,特定的冲动和习惯是为了完成某些确定的工作而协调一致或组织起来的。我们有必要知道个体在其中将不得不运用观察、回忆、想像和推理等方面的能力的社会环境,以期有可能说明精神训练的实际涵义。<br><br>说学校的道德训练是形式上的,我的意思是,普遍为学校所强调的道德习惯在某种程度上是被专门创设出来的习惯。即使是敏捷、恒常、勤勉、不干涉他人的工作、忠于被强加给的任务等尤其为学校反复灌输的习惯,它们之所以必不可少,只因为学校制度本来就是这样,而且必须保持完整无损。如果我们承认学校制度是神圣不可侵犯的,这些习惯便代表着恒久不变、必不可少的道德观念;但是仅就学校制度本身是孤立的和机械的而言，坚持这些道德习惯或多或少是不真实的,因为与它们有关的理想本身并非必要。换而言之,这些责任显然是学校的责任,而不是生活的责任。<br><br>教学方法的问题--不在于它们的具体细节,而在于它们的一般精神。重点于是落在构造和贡献上,而不是落在吸收和单纯的学习上。我们没有认识到后面的方法从本质上讲是多么具有个人主义的特点,它们是多么无意识却又是那么肯定而有效地反应到儿童的判断和行为方式中去。<br>
设想40名学生每天都在忙于读同样的书,准备和背诵同样的功课,假设这一过程构成了他们工作的绝大部分,人们一再按照他们在一个上课时间内所能吸收的内容和在一个背诵课时内所能复述的内容的观点来对他们作出判断。几乎没有机会进行任何社会分工。每一个儿童都没有机会生产出他自己的可以贡献给普通股(com-mon stock)的特殊产品,而他却转而分享他人的产品。所有的人都预先被规定做完全一样的工作,生产出同样的产品。社会精神并没有被培养-事实上,只要纯粹个人主义的方法进入他的工作之中,它就因缺乏使用而萎缩。学校里的朗读之所以效率低下,原因之一是,使用语言的真正动机一一与人交流和学习的愿望---并没有被利用。儿童完全清楚,教师以及他的一切同学在他们面前有着与其完全相同的事实和观念;他根本没有给他们任何东西。人们可以置疑,道德上的缺失是否不及智力上的缺失严重。儿童天生就期望有所贡献、行动和服务。当这种倾向没有被利用时,当情形变得如此,以至于被其他动机取而代之时,一种累积起来的不利于社会精神的影响远非我们的想像所能及,一一尤其是当工作的压力,一周又一周,年复一年地落在这一边的时候。]]></description><link>culture\教育学\德育原理.html</link><guid isPermaLink="false">Culture/教育学/德育原理.md</guid><pubDate>Sun, 12 Jan 2025 02:56:10 GMT</pubDate></item><item><title><![CDATA[教育概论]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/教育学" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/教育学</a> 
 <br><a href=".?query=tag:文化\教育学" class="tag" target="_blank" rel="noopener nofollow">#文化/教育学</a><br><br><br>
<br>教育两字的连用，第一次起源孟子，得天下英才而教育之，三乐也。
<br>![[IMG_20240307_192636_edit_120618660210237.jpg
<br><br>
<br>家庭教育：重要但具有随机性
<br>社会教育
<br>学校教育
<br><br><img alt="IMG_20240307_203625_edit_121309524278882.jpg" src="\lib\media\img_20240307_203625_edit_121309524278882.jpg"><br><br><img alt="IMG_20240307_204543_edit_121534404368952.jpg" src="\lib\media\img_20240307_204543_edit_121534404368952.jpg"><br>school：希腊文schok，意为闲暇<br><br>
<br>夸美纽斯，创立学校制度，建立班级授课制。提出自然性、直观性、确切性等教育教学原则。奠定了近代教育的理论基础，被称之为“教育科学之父”
<br>洛克，教育漫话中阐述了绅士教育。绅士应具备“德行、智慧、礼仪和学问”四种精神品质。
<br>卢梭，《爱弥儿》阐述了理想的教育。《社会契约论》阐述了理想的社会，《新爱露伊丝》阐述了理想的家庭。
<br>赫尔巴特：写出《普通教育学》世界上第一个具有科学体系的教育学。提出三中心论：教师中心、教材中心、课堂中心。是传统教育学的代表人物。现代教育学之父。
<br>杜威 《民主主义与教育》提倡实用主义教育。主张教育即生活，教育即生长，学校即社会。强调新三中心论：学生中心、活动中心、经验中心。
]]></description><link>culture\教育学\教育概论.html</link><guid isPermaLink="false">Culture/教育学/教育概论.md</guid><pubDate>Thu, 21 Mar 2024 12:07:08 GMT</pubDate><enclosure url="lib\media\img_20240307_203625_edit_121309524278882.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\img_20240307_203625_edit_121309524278882.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[教育社会学]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/教育学" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/教育学</a> 
 <br><a href=".?query=tag:文化\教育学" class="tag" target="_blank" rel="noopener nofollow">#文化/教育学</a><br><br><br>教育学关注人，关注人有不同视角：<br>
<br>哲学视角下的人：关注人类意义上的人，关注人的意义
<br>心理学视角下的人：处于发展序列的个体，关注人的成长
<br>社会学视角下的人：处于社会结构或社会组织中的某类人，关注人群的属性<br>
社会学有三大不平等：族群不平等、性别不平等
<br><br>规范学科论
事实学科论
兼有论
<br>
<br>涂尔干：学校的架构、课程表、方法、传统、管理、倾向，等等所有这些都是事实，社会学应该努力取发现他们为什么会成为这个样子原因。

<br>我也有这种想法，应该


<br><br>事实判断/价值判断
演绎型模式——从规则到现象
解释性模式——从现象到规则
定量分析/定量分析
<br><br><br>
<br>
十八十九世纪近代资本主义迅速发展

<br>
西方社会巨变

<br>
社会学

<br>功能论
<br>冲突论
<br>解释论


<br><br><br>
<br>性质：社会进步/社会停滞/社会倒退
<br>规模：整体/局部
<br>激进程度：改良/革命
<br>运行方式：自发变迁/计划变迁
<br><br>
<br>自然环境
<br>人口
<br>科学技术
<br>文化
<br>经济
<br>政治
<br><br>
<br>社会进化论
<br>循环论
<br>结构-功能论
<br>冲突论
<br><br>
<br>教育促动社会变迁
<br>教育适应社会变迁

<br>社会渐变与教育微调
<br>社会剧变与教育重构
<br>社会混变与教育失范


<br>]]></description><link>culture\教育学\教育社会学.html</link><guid isPermaLink="false">Culture/教育学/教育社会学.md</guid><pubDate>Sat, 27 Apr 2024 02:56:59 GMT</pubDate></item><item><title><![CDATA[教育心理学]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/教育学" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/教育学</a> 
 <br><a href=".?query=tag:文化\教育学" class="tag" target="_blank" rel="noopener nofollow">#文化/教育学</a><br>
主讲：傅明忱<br>
邮箱：<a data-tooltip-position="top" aria-label="mailto:fumingchenLL@163.com" rel="noopener nofollow" class="external-link" href="mailto:fumingchenLL@163.com" target="_blank">fumingchenLL@163.com</a><br><br><br>
<br>是应用心理学的一个分支。
<br>荣格的mbti基于八大人格，基于人组的基础理论，这个理论无法被证明，玄学。
<br>作文题：如果人可以不睡觉，这个世界会变成怎么样？放在几年级合适？

<br>皮亚杰提出11、12岁以后，儿童认知水平上才进入形式运算阶段，可以对没有现实基础的事件进行逻辑推理。
<br>但是现在个体发展差异大，理论不一定适用。


<br>我们是否应该鼓励特别聪明的孩子跳级或提前进入大学？

<br>个人不建议，但是可以整体跳级，如少年班。
<br>跳级学生对环境的适应与不跳级的学生对环境的适应是一样的。


<br>成绩较差同学完成作业过程中，作为老师应该如何提供帮助？

<br>倾向于主动帮助
<br>如果教师在学生寻求帮助前去帮助他，可能会让学生把失败归因为能力问题，而不是缺乏努力。


<br>教育不仅仅是科学。

<br>需要遵循基本规律，能被系统的描述和研究
<br>创造性地反复实践、灵活应对不同情境。


<br>教师像是医生，但诊断的病症并不是显性的。
<br>不断思考希望学生达到的目标，思考自己的决策对学生达到这些目标的作用。
<br><br>
<br>学生

<br>年龄
<br>智力水平
<br>思维方式
<br>社会文化背景


<br>教师
<br>教学媒体和环境
<br><br>
<br>发现儿童观看暴力行为电视节目和暴力行为倾向有正相关。因此，禁止儿童观看暴力节目可以降低儿童暴力倾向。

<br>不正确，相关设计无法得到因果结论。只有实验设计可以得到因果结论。因为可能存在反向因果，暴力倾向高的儿童更喜欢看暴力电视节目。


<br>让婴儿对比实验看暴力影片，对比暴力倾向变化。

<br>可能暴力影响只是暂时的。只能得出在实验室的行为。
<br>可能有些儿童本身暴力倾向，所以暴力电视节目对这部分儿童影响更高。


<br><br><br><a data-tooltip-position="top" aria-label="https://zh.wikipedia.org/wiki/%E8%AE%93%C2%B7%E7%9A%AE%E4%BA%9E%E5%82%91" rel="noopener nofollow" class="external-link" href="https://zh.wikipedia.org/wiki/%E8%AE%93%C2%B7%E7%9A%AE%E4%BA%9E%E5%82%91" target="_blank">让·皮亚杰 - 维基百科，自由的百科全书 (wikipedia.org)</a><br>主要内容：年龄对于人认知的局限性<br>
<br>
图式(schemes)：个体表现出的思维或者行为模式<br>
eg."运动的事物都是活的"这就是一种图式，以这种思维模式去理解世界

<br>
同化：用当前的认知图式来解释新的经验

<br>
顺应：修改图式以适应世界

<br>
平衡：指以后的知识与新经验之间维持认知平衡的过程

<br>主要阶段：<br>
<br>感觉运动，0-2

<br>知识是直接运动行为的产物：行动=知识
<br>最初的图式：反射图式，代表认知发展的开始
<br>动作图式经历从探索自身到探索外部世界的过程
<br>8-12月：开始获得客体永久性概念(即知道物体从眼前消失时也存在)
<br>18-24月：发展心理表征能力，指对过去见过物体的心理图片，预示着思维的产生


<br>前运算阶段，2-7

<br>象征性符号功能的出现，一种使用心理符号表达不在场物体的能力
<br>语言能力发展
<br>该阶段的思维缺陷：中心化：将注意力集中于刺激的一个有限方面，因为忽略其他方面的过程。所以很好忽悠。


<br>具体运算阶段，7-12

<br>守恒思维
<br>关系推理
<br>对于具体的问题具有推理运算能力


<br>形式运算阶段，12-18

<br>可以对没有现实基础的假设过程和事件进行逻辑推理
<br>可以进行假设演绎推理


<br>但个体认知发展个体差别很大，并且人的发展不是阶段性的质变，而是持续性的量变。<br><br>
<br>强调认知发展中共同构建的过程：高级心理过程首先在人和人之间的协作活动中产生，然后再被儿童内化为自己认知发展的一部分。
<br>最近发展区理论：儿童的实际发展水平和潜在发展水平间的差异。
<br>脚手架理论：一种暂时性的社会支持，帮助儿童完成不熟悉的任务。教学是一种引导。
<br>强调社会文化环境对个体认知发展的影响
<br>强调教学在人的发展中的作用。
<br><br><br><img alt="Pasted image 20240624194024.png" src="\lib\media\pasted-image-20240624194024.png"><br>
<img alt="Pasted image 20240624194434.png" src="\lib\media\pasted-image-20240624194434.png"><br>
<img alt="Pasted image 20240624194445.png" src="\lib\media\pasted-image-20240624194445.png"><br>
<img alt="Pasted image 20240624194458.png" src="\lib\media\pasted-image-20240624194458.png"><br>
<img alt="Pasted image 20240624194528.png" src="\lib\media\pasted-image-20240624194528.png"><br>
<img alt="Pasted image 20240624194541.png" src="\lib\media\pasted-image-20240624194541.png"><br>
<img alt="Pasted image 20240624194556.png" src="\lib\media\pasted-image-20240624194556.png"><br>
<img alt="Pasted image 20240624194605.png" src="\lib\media\pasted-image-20240624194605.png"><br>
<img alt="Pasted image 20240624194615.png" src="\lib\media\pasted-image-20240624194615.png"><br><br><img alt="Pasted image 20240624194654.png" src="\lib\media\pasted-image-20240624194654.png"><br>
<img alt="Pasted image 20240624194713.png" src="\lib\media\pasted-image-20240624194713.png"><br>
<img alt="Pasted image 20240624194732.png" src="\lib\media\pasted-image-20240624194732.png"><br>
<img alt="Pasted image 20240624195152.png" src="\lib\media\pasted-image-20240624195152.png"><br><br><img alt="Pasted image 20240624195211.png" src="\lib\media\pasted-image-20240624195211.png"><br>
<img alt="Pasted image 20240624195232.png" src="\lib\media\pasted-image-20240624195232.png"><br><br><br>
<br>认知成分：判断是非的推理过程，以及对如何行事做出决策。
<br>行为成分：指当个体受到违背道德行为规范诱导时的行为表现。(比如考试作弊，知道作弊是错的，做出什么样的行为)
<br>情绪情感成分：做出正确或者错误的行为后的感受。
<br><br>
<br>
前道德阶段：

<br>对胜负没有概念。


<br>
他律道德阶段：

<br>把规则看作理所应当的存在，是恒定不可变通的。


<br>
自律道德阶段：

<br>开始意识到社会规则是主观的协议，是可以变通的
<br>开始基于意图理解行为
<br>不再相信内在公平


<br>
皮亚杰道德理论在自立道德阶段中划分不够。

<br>
引导儿童的时候不要倾向于扮演绝对公平，而要让他们理解没有绝对的公平

<br><br>
<br>前习俗道德：

<br>阶段1：惩罚和顺从取向：坚持规则是为了避免惩罚，为了服从而服从。
<br>阶段2：奖赏取向：只遵守对自己有利的规则，为了奖赏而服从。


<br>习俗道德：

<br>阶段1：人际权威取向：希望保持他人对自己的尊敬，并作出他人期望自己做的事。
<br>阶段2：社会权威取向：重视决定法律和行为规则的社会系统，认为社会系统发公约具有绝对权威。


<br>后习俗道德：超越简单的外部权威，此时个体建立了关于对错的内部信念。

<br>阶段1：社会契约取向：把法律和社会规约看作是反应大多数人意志和促进人类幸福的工具，可以被质疑和修改。
<br>阶段2：个人原则取向：个人内心具有关于道德原则的稳定信念，关注更高的道德系统。


<br><br>
<br>鼓励观点采择，即鼓励换位思考
<br>让儿童参与公约制定的过程
<br>组织讨论两难问题
<br>树立榜样
<br><br><br>
<br>比奈单因素说
<br>智力多因素说，多维度的能力构成
<br>智力的二因素理论
<br><br>
<br>创造智力
<br>分析智力
<br>实践智力
<br><br><img alt="Pasted image 20240624200043.png" src="\lib\media\pasted-image-20240624200043.png"><br><br>
<br>场独立型风格和场依存型风格
<br>决策风格：沉思型和冲动型
<br>学习风格：表层学习和深层学习
<br><br><br><br>伦祖利的天才三环模型：<br>
<br>超常的能力
<br>创造力
<br>任务承诺：实干能力
<br><br>大多数超常儿童的学业适应障碍在幼儿园到小学四年级之间浮现出来，并且半数在十岁左右成为“精神上的辍学者”。<br>如果只和自己同龄的伙伴待在一起，超常儿童会表现出社会融入问题。<br><br>加速：跨级<br>
充实：开拓<br><br>学习障碍和ADHD<br><br>在某一学科表现与其整体智力水平相比明显要差。<br><br>
<br>阅读字词顺序混乱，多字漏字
<br>写作困难
<br>对语句复述、理解困难
<br><br>
<br>看数困难
<br>估算困难
<br><br>在七八岁显现，百分之五<br>
<br>难以集中注意力
<br><br><img alt="Pasted image 20240624200518.png" src="\lib\media\pasted-image-20240624200518.png"><br>
<img alt="Pasted image 20240624200726.png" src="\lib\media\pasted-image-20240624200726.png"><br>
<img alt="Pasted image 20240624200854.png" src="\lib\media\pasted-image-20240624200854.png"><br>
<img alt="Pasted image 20240624200904.png" src="\lib\media\pasted-image-20240624200904.png"><br>
<img alt="Pasted image 20240624200912.png" src="\lib\media\pasted-image-20240624200912.png"><br><br><br><img alt="Pasted image 20240624201122.png" src="\lib\media\pasted-image-20240624201122.png"><br>
<img alt="Pasted image 20240624201135.png" src="\lib\media\pasted-image-20240624201135.png"><br><br><img alt="Pasted image 20240624201422.png" src="\lib\media\pasted-image-20240624201422.png"><br>
<img alt="Pasted image 20240624201653.png" src="\lib\media\pasted-image-20240624201653.png"><br><br><img alt="Pasted image 20240624201731.png" src="\lib\media\pasted-image-20240624201731.png"><br>
<img alt="Pasted image 20240624201750.png" src="\lib\media\pasted-image-20240624201750.png"><br>
<img alt="Pasted image 20240624201801.png" src="\lib\media\pasted-image-20240624201801.png"><br><br><img alt="Pasted image 20240624201933.png" src="\lib\media\pasted-image-20240624201933.png"><br><br><img alt="Pasted image 20240624201829.png" src="\lib\media\pasted-image-20240624201829.png"><br>
<img alt="Pasted image 20240624202040.png" src="\lib\media\pasted-image-20240624202040.png"><br>系统性地运用表扬和关注是教师最有力的刺激和课堂管理工具。<br><br><img alt="Pasted image 20240624202459.png" src="\lib\media\pasted-image-20240624202459.png"><br><br><img alt="Pasted image 20240624202307.png" src="\lib\media\pasted-image-20240624202307.png"><br>
<img alt="Pasted image 20240624202316.png" src="\lib\media\pasted-image-20240624202316.png"><br><br><img alt="Pasted image 20240624202348.png" src="\lib\media\pasted-image-20240624202348.png"><br><br><img alt="Pasted image 20240624202542.png" src="\lib\media\pasted-image-20240624202542.png"><br>
<img alt="Pasted image 20240624202616.png" src="\lib\media\pasted-image-20240624202616.png"><br>
<img alt="Pasted image 20240624202632.png" src="\lib\media\pasted-image-20240624202632.png"><br>
<img alt="Pasted image 20240624202638.png" src="\lib\media\pasted-image-20240624202638.png"><br><img alt="Pasted image 20240624202643.png" src="\lib\media\pasted-image-20240624202643.png"><br><br><img alt="Pasted image 20240624202742.png" src="\lib\media\pasted-image-20240624202742.png"><br>
<img alt="Pasted image 20240624202800.png" src="\lib\media\pasted-image-20240624202800.png"><br><br><br><img alt="Pasted image 20240624203056.png" src="\lib\media\pasted-image-20240624203056.png"><br>
<img alt="Pasted image 20240624203107.png" src="\lib\media\pasted-image-20240624203107.png"><br>
<img alt="Pasted image 20240624203112.png" src="\lib\media\pasted-image-20240624203112.png"><br>
<img alt="Pasted image 20240624203136.png" src="\lib\media\pasted-image-20240624203136.png"><br><br><img alt="Pasted image 20240624203308.png" src="\lib\media\pasted-image-20240624203308.png"><br><br><img alt="Pasted image 20240624203451.png" src="\lib\media\pasted-image-20240624203451.png"><br>
<img alt="Pasted image 20240624203510.png" src="\lib\media\pasted-image-20240624203510.png"><br>
<img alt="Pasted image 20240624203517.png" src="\lib\media\pasted-image-20240624203517.png"><br>
<img alt="Pasted image 20240624203521.png" src="\lib\media\pasted-image-20240624203521.png"><br><br><br><img alt="Pasted image 20240624203852.png" src="\lib\media\pasted-image-20240624203852.png"><br>
<img alt="Pasted image 20240624203859.png" src="\lib\media\pasted-image-20240624203859.png"><br><br><img alt="Pasted image 20240624203913.png" src="\lib\media\pasted-image-20240624203913.png"><br><br><img alt="Pasted image 20240624203936.png" src="\lib\media\pasted-image-20240624203936.png"><br>
<img alt="Pasted image 20240624203956.png" src="\lib\media\pasted-image-20240624203956.png"><br>
<img alt="Pasted image 20240624204034.png" src="\lib\media\pasted-image-20240624204034.png"><br><img alt="Pasted image 20240624204106.png" src="\lib\media\pasted-image-20240624204106.png"><br><br><img alt="Pasted image 20240624204152.png" src="\lib\media\pasted-image-20240624204152.png"><br><img alt="Pasted image 20240624204303.png" src="\lib\media\pasted-image-20240624204303.png"><br>
<img alt="Pasted image 20240624204310.png" src="\lib\media\pasted-image-20240624204310.png"><br><br><img alt="Pasted image 20240624204542.png" src="\lib\media\pasted-image-20240624204542.png"><br>
<img alt="Pasted image 20240624204548.png" src="\lib\media\pasted-image-20240624204548.png"><br>
<img alt="Pasted image 20240624204608.png" src="\lib\media\pasted-image-20240624204608.png"><br>
<img alt="Pasted image 20240624204619.png" src="\lib\media\pasted-image-20240624204619.png"><br><img alt="Pasted image 20240624204626.png" src="\lib\media\pasted-image-20240624204626.png"><br><br><br><img alt="Pasted image 20240624204804.png" src="\lib\media\pasted-image-20240624204804.png"><br><img alt="Pasted image 20240624204844.png" src="\lib\media\pasted-image-20240624204844.png"><br><img alt="Pasted image 20240624204856.png" src="\lib\media\pasted-image-20240624204856.png"><br>
<img alt="Pasted image 20240624204932.png" src="\lib\media\pasted-image-20240624204932.png"><br><br><img alt="Pasted image 20240624205050.png" src="\lib\media\pasted-image-20240624205050.png"><br><img alt="Pasted image 20240624205154.png" src="\lib\media\pasted-image-20240624205154.png"><br>
<img alt="Pasted image 20240624205159.png" src="\lib\media\pasted-image-20240624205159.png"><br><img alt="Pasted image 20240624205231.png" src="\lib\media\pasted-image-20240624205231.png"><br><br><img alt="Pasted image 20240624205330.png" src="\lib\media\pasted-image-20240624205330.png"><br>
<img alt="Pasted image 20240624205345.png" src="\lib\media\pasted-image-20240624205345.png"><br><img alt="Pasted image 20240624205447.png" src="\lib\media\pasted-image-20240624205447.png"><br><br><img alt="Pasted image 20240624205600.png" src="\lib\media\pasted-image-20240624205600.png"><br>
<img alt="Pasted image 20240624205619.png" src="\lib\media\pasted-image-20240624205619.png"><br><img alt="Pasted image 20240624205649.png" src="\lib\media\pasted-image-20240624205649.png"><br>
<img alt="Pasted image 20240624205706.png" src="\lib\media\pasted-image-20240624205706.png"><br><img alt="Pasted image 20240624205740.png" src="\lib\media\pasted-image-20240624205740.png"><br><br><br><img alt="Pasted image 20240624210020.png" src="\lib\media\pasted-image-20240624210020.png"><br>
<img alt="Pasted image 20240624210044.png" src="\lib\media\pasted-image-20240624210044.png"><br>
<img alt="Pasted image 20240624210110.png" src="\lib\media\pasted-image-20240624210110.png"><br><br><img alt="Pasted image 20240624210141.png" src="\lib\media\pasted-image-20240624210141.png"><br><img alt="Pasted image 20240624210232.png" src="\lib\media\pasted-image-20240624210232.png"><br>
<img alt="Pasted image 20240624210237.png" src="\lib\media\pasted-image-20240624210237.png"><br><img alt="Pasted image 20240624210302.png" src="\lib\media\pasted-image-20240624210302.png"><br><br><img alt="Pasted image 20240624210326.png" src="\lib\media\pasted-image-20240624210326.png"><br>
<img alt="Pasted image 20240624210330.png" src="\lib\media\pasted-image-20240624210330.png"><br><br><img alt="Pasted image 20240624210510.png" src="\lib\media\pasted-image-20240624210510.png"><br><br><img alt="Pasted image 20240624210623.png" src="\lib\media\pasted-image-20240624210623.png"><br><img alt="Pasted image 20240624210648.png" src="\lib\media\pasted-image-20240624210648.png"><br><img alt="Pasted image 20240624210654.png" src="\lib\media\pasted-image-20240624210654.png"><br><img alt="Pasted image 20240624210702.png" src="\lib\media\pasted-image-20240624210702.png"><br><br><img alt="Pasted image 20240624210739.png" src="\lib\media\pasted-image-20240624210739.png"><br>
<img alt="Pasted image 20240624210746.png" src="\lib\media\pasted-image-20240624210746.png"><br>
<img alt="Pasted image 20240624210750.png" src="\lib\media\pasted-image-20240624210750.png"><br><br><img alt="Pasted image 20240624210805.png" src="\lib\media\pasted-image-20240624210805.png"><br>
<img alt="Pasted image 20240624210808.png" src="\lib\media\pasted-image-20240624210808.png"><br><br><img alt="Pasted image 20240624210850.png" src="\lib\media\pasted-image-20240624210850.png"><br>
<img alt="Pasted image 20240624210858.png" src="\lib\media\pasted-image-20240624210858.png"><br>
<img alt="Pasted image 20240624210908.png" src="\lib\media\pasted-image-20240624210908.png"><br><img alt="Pasted image 20240624210918.png" src="\lib\media\pasted-image-20240624210918.png"><br><br><img alt="Pasted image 20240624210943.png" src="\lib\media\pasted-image-20240624210943.png"><br>
<img alt="Pasted image 20240624211005.png" src="\lib\media\pasted-image-20240624211005.png"><br><br><img alt="Pasted image 20240624211159.png" src="\lib\media\pasted-image-20240624211159.png">]]></description><link>culture\教育学\教育心理学.html</link><guid isPermaLink="false">Culture/教育学/教育心理学.md</guid><pubDate>Mon, 24 Jun 2024 13:12:01 GMT</pubDate><enclosure url="lib\media\pasted-image-20240624194024.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240624194024.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[教育学]]></title><description><![CDATA[ 
 <br><br><br><a data-href="教育概论" href="\culture\教育学\教育概论.html" class="internal-link" target="_self" rel="noopener nofollow">教育概论</a><br>
<a data-href="教育社会学" href="\culture\教育学\教育社会学.html" class="internal-link" target="_self" rel="noopener nofollow">教育社会学</a><br>
<a data-href="教育心理学" href="\culture\教育学\教育心理学.html" class="internal-link" target="_self" rel="noopener nofollow">教育心理学</a><br>
<a data-href="中国教育史" href="\culture\教育学\中国教育史.html" class="internal-link" target="_self" rel="noopener nofollow">中国教育史</a><br>
<a data-href="比较教育学" href="\culture\教育学\比较教育学.html" class="internal-link" target="_self" rel="noopener nofollow">比较教育学</a><br>
<a data-href="德育原理" href="\culture\教育学\德育原理.html" class="internal-link" target="_self" rel="noopener nofollow">德育原理</a><br>
<a data-href="教育研究方法" href="\culture\教育学\教育研究方法.html" class="internal-link" target="_self" rel="noopener nofollow">教育研究方法</a><br>
<a data-href="教育哲学" href="\culture\教育学\教育哲学.html" class="internal-link" target="_self" rel="noopener nofollow">教育哲学</a><br><br><a data-href="教育自传" href="\culture\教育学\教育自传.html" class="internal-link" target="_self" rel="noopener nofollow">教育自传</a><br>
<a data-href="毕业论文" href="\culture\教育学\毕业论文.html" class="internal-link" target="_self" rel="noopener nofollow">毕业论文</a><br>
<a data-href="文献综述：当代青年“节能”与“内耗”现象的教育困境" href="\culture\教育学\文献综述：当代青年“节能”与“内耗”现象的教育困境.html" class="internal-link" target="_self" rel="noopener nofollow">文献综述：当代青年“节能”与“内耗”现象的教育困境</a>]]></description><link>culture\教育学\教育学.html</link><guid isPermaLink="false">Culture/教育学/教育学.md</guid><pubDate>Sun, 12 Jan 2025 02:51:16 GMT</pubDate></item><item><title><![CDATA[教育研究方法]]></title><description><![CDATA[ 
 <br><br>我想要研究的主题很多，人性论、海德格尔的原始之真、当下感知的丧失、生命记忆、信息上瘾、凝视、与人正面交流能力的丧失，在公共环境中与人对话的能力的丧失。上课低头族，公共空间如图书馆跟别人隔开坐，不想被注视，沉浸在自己的世界。<br>教育的本质是什么？教育回答的是一个应然的问题，即人应该是怎么样的？我们应该通过教育将人塑造成什么样？教育回答的是往哪里去的哲学问题。<br>基于这个问题我们展开。<br>海德格尔在学术讨论时遇到这样的问题<br><br><br>当代教育面临的一个显著问题是学生与现实世界之间日益加深的隔阂。在知识传播与学术研究的标准化、机械化趋势下，学生的教育体验逐渐脱离了生活本身，导致学生与社会、环境、文化的关系变得愈发疏离。教育的功能不仅仅局限于传授知识，更在于培养学生与世界的深度连接与互动。约翰·杜威和马丁·海德格尔的思想为此提供了深刻的哲学启示。杜威提出的“教育即生活”和海德格尔关于“原始之真”的思考，都强调教育过程中的经验、存在与现实世界的关系。这篇文献综述将基于杜威和海德格尔的哲学思想，结合王鑫《让儿童与世界美好相遇——基于‘本源之思’的教育美学诠释》的相关观点，探讨当代教育中学生与现实世界交流缺失的原因及其可能的教育应对策略。<br><br>约翰·杜威认为，教育不仅是为了学生未来的职业或社会角色做准备，而是生活的一部分。他提出“教育即生活”的核心思想，主张教育应该关注学生的经验，并将这种经验与现实世界相结合。然而，随着社会对教育的认知逐渐向“知识传授”偏移，学生的教育体验愈发远离生活的实际经验，尤其在以应试教育为主的体制下，学生被迫离开了自然、社会和文化的语境。学校中的知识内容往往过于抽象、孤立，缺乏对学生日常生活、兴趣和实践的关注。这种教育模式导致学生在认知世界的过程中缺乏真实感知和情感投入，从而产生了教育与生活之间的割裂。<br>杜威提倡通过“做中学”（learning by doing）来打破这种割裂，他认为，学生通过实际的行动、项目和体验来学习知识和技能，而不是简单地被动接受。这一思路本应为教育提供更加生动和贴近现实世界的途径，但当前的教育体系和课程安排往往忽视了这一点。<br><br>海德格尔的“原始之真”（die Wahrheit als Unverborgenheit）强调真理不仅仅是符合或反映客观现实的事实，而是事物的“显现”过程，是真理作为存在本身的显现。换句话说，真理是“揭示”或“开显”的过程，而不是固定的、客观的知识。因此，教育的真正目标并不应当是单纯的知识传递，而是帮助学生通过经验与世界互动，揭示事物的本质和存在。<br>在传统教育中，知识的获取往往被看作是一种客观事实的传递，而学生与世界的互动性和存在体验则被忽视。海德格尔认为，现代教育的一个重要问题是它没有引导学生回到“存在”的体验上，学生被困于符号和抽象的框架中，无法真正与世界和他人建立深刻的联系。因此，教育应当让学生在体验和存在中“揭示”世界，而不仅仅是在概念和知识的表面上游走。<br><br>在现代教育发展中，儿童与世界的相遇问题具有重要意义，尤其是在当前教育系统逐渐脱离儿童真实生活的背景下。根据海德格尔的“原始之真”思想和杜威的“教育即生活”理念，儿童的教育不仅仅是知识的传递，更是通过与世界的多维度相遇来实现自身的成长。以下三种儿童与世界的相遇情境为教育实践提供了新的视角和实践方向：<br><br>海德格尔认为，人在“世界”中自我显现，是通过对周围世界的相遇来理解自己。这种“相遇”不仅是人与外部世界的对接，更是对自身存在的领会。具体到儿童教育中，儿童总是通过与世界的互动来“领会自身”。例如，在海德格尔的“讲台实验”中，学生的课堂行为如坐位与讲台的安排，是他们对教室环境的自然理解，但来自不同文化背景的学生可能面临不同的理解障碍。教育中的“领会自身”问题，反映了儿童在过度被技术化、功利化教育方式束缚下，往往忽视了世界对自身存在的深层次反馈。因此，教育者应帮助儿童在真实世界的互动中发现自我，承担责任，面对不完美，从而形成完整的自我认知。<br><br>海德格尔提出，人与物的关系有“在手状态”和“上手状态”之分，后者即是人与物的直接互动、操劳。教育中的“面向操劳”强调通过物的使用和操作来实现儿童对世界的深刻理解。这种方式不仅仅是让儿童完成任务，而是通过与物的接触，让儿童在实际操作中理解其意义和功能。例如，海德格尔对梵高《农鞋》的解读表明，鞋子在农妇的日常操劳中是活的物件，是与世界的深层次连接。教育中的“操劳”不仅是操作，更是让儿童通过手、眼、耳等多感官的协作，将抽象知识转化为具象经验。这种方式可以通过实践活动、劳动体验等形式帮助儿童建立与世界的直接联系。<br><br>海德格尔的“共在”概念强调人的生存是与他人共同进行的，是一种互相交织、相互依存的存在状态。在教育中，这种“共在”不仅体现在师生关系中，更应扩展到同伴之间的关系。教育不应仅仅看作是教师传授知识的单向过程，而是应鼓励师生、同伴之间的互动与共同成长。教师不应仅是知识的传递者，而应在教育过程中成为学生存在的“表率”，与学生一起成长。尤其是在儿童的社会化过程中，同伴关系的重要性日益突出。教育应关注和引导同伴关系的发展，帮助学生在与他人交往中获得情感的支持与社会的认同，从而形成健康的社会性人格。<br><br>从杜威、海德格尔和王鑫的哲学思考出发，我们可以看到当代教育中学生与现实世界交流的缺失，主要表现在以下几个方面：<br>
<br>
知识与生活的脱节<br>
许多学校教育内容偏离了学生的日常经验和实际生活，学生学习的知识和技能往往缺乏实际应用性。学生在学习过程中没有机会与现实世界建立直接的联系，导致其知识的“生活化”不足。

<br>
抽象化的教育模式<br>
当前许多教育体系仍然偏重于理论和抽象知识的传授，忽视了学生的实践经验和情感体验。海德格尔认为，教育应当是“显现”的过程，而不仅仅是符号的学习；然而，在许多教育场景中，学生的经验和感知并未得到充分的尊重和展现。

<br>
教育中的存在性缺失<br>
当代教育越来越倾向于知识的标准化和形式化，学生的个体经验和与世界的存在性联系被忽略。王鑫提到，教育的真正目的是让学生通过“本源之思”回归自身的存在与体验，而非简单地传递事实和知识。

<br>针对这些问题，杜威、海德格尔与王鑫的教育理念为现代教育改革提供了宝贵的参考。首先，教育应该重新关注学生的经验，让知识与现实生活紧密相连，教学内容不应只停留在书本上，而应通过实践、体验、感知和反思来深化学生的学习。其次，教育应该强调“存在性”——让学生不仅是知识的接受者，更是世界的探索者与创造者，教育应帮助学生揭示世界的本质。最后，教育的目的是促使学生与世界发生真正的联系，不仅是在认知层面，更在情感、文化与存在层面与世界实现“美好相遇”。<br><br>综上所述，杜威的“教育即生活”、海德格尔的“原始之真”和王鑫的“本源之思”提供了有力的理论框架，帮助我们思考如何解决现代教育中学生与现实世界交流缺失的问题。教育不应当仅仅是知识的传递，更应成为一个引导学生与世界、与他人、与自我建立深度联系的过程。在这一过程中，教育应当回归到学生的经验与实践中，关注学生的“存在”与“显现”，通过真实的体验和反思让学生与世界进行美好而深刻的相遇。]]></description><link>culture\教育学\教育研究方法.html</link><guid isPermaLink="false">Culture/教育学/教育研究方法.md</guid><pubDate>Thu, 05 Dec 2024 13:02:04 GMT</pubDate></item><item><title><![CDATA[教育哲学]]></title><description><![CDATA[ 
 <br><br>——教育的作用是想办法让灵魂转身<br>在第七卷，苏格拉底想要探讨这样一个问题，教育对我们的天性到底有什么影响呢?<br>洞穴之喻是这样说的,想象这样一个地穴它有一条长长的通道向上通往地面,在地穴中有一群人从小就生活在这里他们被脖子和脚上的镣铐固定在同一位置不能转头。因此，只能看见面前的事物。因为他们过的跟囚徒差不多我们就叫他们囚徒。地穴中的光源来自于囚徒上后方的火堆在火堆与囚徒之间有一道矮墙，在矮墙的另一边有人举着各种各样的木偶这些举着木偶的人会来回走动，有时也会说话。<br>囚徒们唯一能看见的是我就是他们面前墙壁上的木偶的投影，他们甚至看不见周围的人，也看不见那些被举起的木偶本身。如果这些囚徒可以彼此讨论他们肯定会把他们面前的投影人做各种事物的本体，对着他们谈天说地。如果举物人的话语通过墙壁传到他们的耳朵里他们也会认为这是面前的投影在说话。<br>综上所述，地穴中囚徒会把眼前的这些木偶的投影当作真实，那如何才能把它们从这种愚昧天真中解放出来呢？<br>假设我们把他们的镣铐解开，强制他们站起来转头行走并向火焰的方向看去，他们一定会感到不适甚至痛苦。因为火焰的光芒闪烁而强烈他们习惯昏暗的双眼甚至都无法看清楚投影的来源，也就是木偶。我们这时候就可以对他们说你们之前都生活在胡扯之中，现在的你们才离真实更近一步，你们现在所看见的木偶比墙上的投影更加贴近真实，但当我们指着那些被举起的木偶让囚犯们试图辨认的时候，他们一定会因为看不清楚而感到困惑，并对我们之前所说的话存疑。如果我们进一步强迫他们的视线聚焦在地穴中光的来源，也就是火焰本身上，他们一定会觉得被闪瞎了双眼想要立马转身重新面向自己所熟悉的墙壁并认为上面的投影才是更加清晰的东西。如果我们从这群人中抓一个张三强拉硬拽的拖着他爬上那陡峭的向上通道，累死累活的来到地面之上，张三肯定会因为受到这样的虐待而感到痛苦和愤怒，忽然曝露在阳光之下张三的双眼再次被耀眼的阳光所亮瞎。我们现在指着各种花草树木对他讲看这才是真实的事物。张三需要一些时间来适应强光首先他会看得清影子，然后慢慢的可以看见水中的倒影，然后才能去看那些花草树木本身，再到天空中的云彩晚间的星光月光，最后才能张目对日看清太阳本身的样子，这时张三也能知到是太阳造成了四季变幻岁月轮转，统治了整个可见世界。张三再回想起不堪回首的地穴生活一定会为自己现在的认知升级而感到庆幸，对他还被蒙在鼓里的狱友们感到同情。<br>地穴人中有这样的竞赛，谁能更快速的指认投影或者通过借助投影的排列组合来预知下一个投影，谁就能获得奖赏并且受到其他狱友的尊敬，之前的张三可能会羡慕那些得奖的狱友，而现在的她简直毫无波澜甚至觉得可笑就像Achills的魂魄在奥德赛中所说，宁愿在现世当牛做马。<br>我们换一个角度想就算张三再次回到地穴，已经适应了日光的他定会感到眼前一片漆黑。如果这样的他跟一直在地下生活的囚徒们一起参加投影便识大赛他一定会一败涂地。在张三的眼睛再次适应黑暗之前他都会被其他的地穴人所耻笑，如果胆敢跟他们讲这些投影都不是真实的之类的话语，他们非要笑掉了大牙不可。张三上去一趟不但眼变瞎了还净说胡话，上去有什么好处啊？这些囚徒不但不会愿意去地面，甚至还会使任何想把他们从黑暗中解放出来的人为敌人。<br>如果我们把地穴比作可视事件，那可见世界中太阳的能力就与地穴中的火光相对应，而这从地穴向上看见地面真实事物的旅程就可以比作灵魂向上探寻可知世界的旅程。就如同比喻中初次来到地面的张三费了不少力气才能看见太阳。在可知世界中我们所探寻的最终目标就是善的理念，这是我们需要通过无数磨练与挫折才能看见的，但是，人们一旦看见了善的理念就一定会明白，这是所有正确美丽事物的源泉，它是真实与理解的来源才能做出合适的统治。<br>我们再深入这个比喻，看见了太阳的张三不再愿意回到地穴与之相似，一个看到了善的理念的人肯定不愿意再去管俗世的纷纷扰扰，这样一个人习惯了注视神圣的事物在他的目光还没有适应黑暗的时候又让他去参与到对世俗罪恶的讨论，与那些看惯了正义幻影的人在法庭上对抗，他就难免会表现得尴尬可笑。但是我们不该因此嘲笑他因为他的灵魂是从光明之处忽然降到黑暗之处而变得无法适应的，与之相比，一个从无知的黑暗中进入到光明而无所适从反而想要逃离的灵魂才更值得同情。<br>我们再回到苏格拉底讲洞穴之喻的初衷，探讨教育对灵魂的影响。他先否定了一些现有的看法，有些人认为教育可以把知识硬塞进缺少他的灵魂里就好像可以把视力给予失明的双目一样，苏格拉底不赞成这种观点，他认为学习能力是在所有人的灵魂中存在的，而这个从事学习的器官与眼睛类似。身处地穴的人只有转过身才能看见火光，来到地面上的人也只有面向太阳才能看见太阳，这个学习的器官必须同整个灵魂一起转向存在的真实事物才能达到教育的目的，也就是使灵魂看见真实继而看见善的理念。所以说教育并不是像一些人所说的那样，把视力塞给盲人，因为视力本来就在那里，只是看错了方向，教育的作用是想办法让灵魂转身让其中从事学习的器官看向正确的方向。<br>学习的器官我们叫它virtual wisdom——智慧的美德。苏格拉底认为智慧属于一种神圣的能力，一开始就在灵魂中存在，能力大小因人而异。但从不会消失，它或有用有益或无用甚至有害，这完全取决于他所专注的对象。如果灵魂中的学习器官从小就专注于正确的真实的事物，他的灵魂就会变得神圣，而那些变幻莫测的事物，都是与享乐相关，这些累赘会把灵魂向下拖入地穴。所以说没受过教育的人，没有看见真实的经历，没有找到自己生活与行为应当遵循的神圣目标，就无法好好地统治城邦。<br>但那些一生都在接受教育的人也不行，这是为什么呢？苏格拉底认为作为城邦的建设者，我们必须让走出洞穴看见真实以及善的理念的人再次回到黑暗的地穴里。问，这样不就对他们不公平了吗？他们本来可以在地面过更好的生活的。苏格拉底说你又忘了，我们之前不是说了吗？我们建成的目的不是想让城邦中的哪一个阶级过得特别好，我们专注的是城邦整体的和谐与繁荣，我们训练这些哲学家不是为了让他们随意做自己想做的事，而是让他们去凝聚整个城堡而且我们也没有不公正的对待他们，让他们去照顾守护居民其实是正义的行为，他们如果出生在其他的城邦，倒是可以不必再回到地穴，那是因为在其他的城邦中哲学家是自主成长的，他们不亏欠谁的养育，那他们不去回报任何人，也是正义的。但是在我们的城邦中，是城邦培养了哲学家，给予了他们，教育目的就是使他们成为领导者，同时参与哲学研究与城邦守护。所以作为回报为了承包整体的利益他们必须回到地穴中，再次适应在黑暗中事物，因为他们见过真实的正义与善的美好事物，再次适应黑暗后也就会比其他人更能清晰地辨认阴影以及这些阴影到底是何物的影像，这样的城邦才是一个清醒的城邦，而现在的大多数城邦都是在梦游的状态中，他们被一些为阴影而争执的人所统治，好像统治本身才是好事是善，是他们的最终目的，他们不明白的是，一个城邦只有被那些并不向往统治的人统治，才能达到和谐避免摩擦。<br>那么要教育出这样的哲学家我们应当为他们准备什么学科的教学呢？把灵魂从地球带到地面向真实存在上升这就是哲学我们教育者要做的，是去寻找什么学科有这样的能力能把灵魂从关注变化的事物转向事物的本质。数字计算可能就是我们所找的促进我们产生理解，把我们影像真实存在事物的学科，此话怎讲呢？苏格拉底首先想帮我们区分一下什么事物会把我们引向正确的方向，而什么事物不会，有些感官知觉不会唤起灵魂中掌管理解的部分，因为这些感觉本身的判断就已经足够了。而另一种感官知觉会促使我们灵魂中的理解部分来参与判断，因为这些感觉本身无法产生合理的解释。苏格拉底举起三根手指来举例说明，你看我这三根手指小指头无名指中指，他们不管近了看远了看从哪个角度看，不管它是从中间还是两边，黑还是白，粗还是细，看上去都是手指。大多数人的灵魂在看到这些手指的时候不会强迫自己去问掌管理解的部分手指是什么？因为视力不会告诉灵魂，只是手指又不是手指，所以说当感官不会同时向灵魂传达相反的信息时，他就无法唤起我们灵魂中掌管理解的部分。这种判断是关于可见事物的，但是如果我们问到手指的大与小呢？我们看无名指，你说它大也行他比小指大，你说它小也行他比中指小，这是掌管大小识别的感官，对同一件事物的判定可大可小，大与小被混在一起处理，当他把这个信息传递给灵魂的时候，灵魂就会疑惑，就会唤起掌管计算和理解的部分。首先它会分辨出感官传递给我的大与小是两个独特的概念，而后他就会去区分大与小分别有什么性质，这种情况下，我们就会先考虑到底大是什么，小又是什么呢？能做到这样都是那种可以同时传递相反信息的感觉，这样的感觉就会召唤思考，能召唤思考的事物，苏格拉底叫他们召唤师。我们可以看出，这些判断是与不可见的理念有关的，视觉在这里无法进行判断的原因是大与小的理念都是属于可知世界的。苏格拉底继续说，明白了这两种分类之后，我们再来看数字，显然数字也是召唤师我们的视力并不能看见一或二本身，于是我们的灵魂就会发问什么是一什么是二？也就是说，要了解数字的本性，必须要激发灵魂中掌管理解的部分，让我们的灵魂转向去看真实的存在。而数字计算就是专注于数字的学科，但它显然就是引领灵魂面向真实的学科。<br>综上所述数字计算符合我们办学宗旨里的两个要求，要潜心钻研直到通过理解本身看见了数字的本质这不仅仅是为了战争的用途更是为了把他们的灵魂从变化的事物转向不变的真理。<br>我们该重视的是对不变真理的研究，通俗一点讲，就是对那些只存在于脑海中的完美立体的性质的研究，这样的研究才能使灵魂转身。苏格拉底认为按顺序的话下一门科目是天文学，这里所说的天文学指的是对三维物体运动的研究。我们的灵魂中有一个部分比1万只眼睛加起来都重要，只有通过这双灵魂的眼睛我们才能看见真理。灵魂的眼睛会被一些盲目的俗世的追求所遮蔽，只能被我们所说这些学科所进化并重新点燃。有些人不明白这个道理就会问学微积分有什么？用买菜用得到吗？买菜可能真的用不到？但是这并不能说明他没用，可能问问题的人要想想自己对有用的定义是不是太狭隘了。目前为止看，苏格拉底已经定下了四门学科：算术、平面几何、立体几何以及天文学这些学科，都能帮助灵魂从地穴上升到地面，为了让灵魂最终能够面向可知世界的太阳，也就是善的理念。<br>除了这些还应当设立哪些学科呢？苏格拉底接着说，天文学研究的是物体的运动，但运动不仅限于天体的运动。这是我们肉体可以看见的，而耳朵可以听见的，和谐的音律也是一种运动这样看来研究音律的声学与天文学是相关的他们都是对运动的研究，所以学习声学时，也要避免只专注于能听见的和弦，现在的声学家与现在的天文学家一样总是试图从可以听到的声音中寻找音律的高低好坏，但他们不会向上寻找问题的源头，不会用理性去思考为什么音律有和谐不和谐之分。这种对声学的研究是要避免的使用理性去思考音律的真谛，才是对寻找善与美有用的研究方式。<br>以上这几门学科的共同点就是能促进灵魂的转身可以使灵魂从地穴上升到地面。但是，要达成我们的最终目的，看见善的理念，这些学科只能算是序曲。而我们这个灵魂转身大乐章的主题曲是辩证讨论，那这个辩证讨论具体是指什么呢？为什么他的地位这么高呢？苏格拉底说道，当一个人不惜借助任何感官的帮助，只使用理性的辩证讨论，去达到对每个事物本质的认识，他在这条探求的道路上不中途放弃直到通过理解本身认识到善的本质，这时，我们就可以说他旅行到了可知世界的尽头，这就像我们的张三来到地面之后历经千辛万苦终于能够看见太阳一样，由此可见，在苏格拉底看来辩证法是通往可知世界尽头的必备工具。<br>为什么只有辩证讨论有通向可知世界尽头的能力呢？苏格拉底解释道，这是因为查究的技艺中，只有辩证讨论的目的在于获得对事物本质。系统完全的掌握很多其他的技艺，建立在人的信仰欲望之上，还有许多技艺专注于种植与建造或者对这些不断变化的事物或人造物的保养与管理，还有一些其他的技艺只能对事物本质有一定程度的掌握。我们之前讲过的算术几何之类的序曲学科就属于这一类，这些技艺是建立在假设的第一原则上的，所以最终的结论也不能说是知识只能叫做思考。虽然他们并不能带给我们对事物本质的完全认识，但是对于我们的灵魂转身是必要的，就像我们洞穴中的张三也不是一开始就能看见太阳，灵魂看见善的理念也需要一个过程。来到地面上的张三必须先从水中的倒影看起，才能慢慢地看向真实的事物本身，最后才能看见太阳。这些序曲学科让我们的灵魂产生了思考，就是可知世界中真实事物的倒影，是灵魂看向真实存在的必经之路，要想看见真实事物及善的理念本身就需要我们的主题曲辩证法出马了。辩证法是唯一不需要假设目的在于达到对第一原则本身的认识的查究方法。这样得出的结论才能被称作知识，建立在此之上一个能通过这样的辩证法去掌握所有真实存在事物本质的人，我们才能叫他辩证家。<br>那怎样就算是达到了可知世界的尽头呢？对于了解善的理念，苏格拉底也有一套标准，如果一个人可以给出对善的理念的详尽描述，能清楚的把它与其他事物区分开来，他对善的理念的理解能够经受住各种检验与反驳的挑战，而他所进行回击的武器是真理而不是什么个人的信仰或意见，这样我们就可以说他知道了善为何物。综上所述，苏格拉底认为理想城邦必须立法只有这门学科才能让他们正确的以获取知识为目的的提出问题，并回答辩证讨论可以作为我们这一系列学科的顶石，没有任何学科能在他之上。<br><br>《俄狄浦斯王》是古希腊剧作家索福克勒斯创作的一部经典悲剧，它通过展现俄狄浦斯这一悲剧英雄的命运，深刻探讨了人类命运、知识、道德以及神的力量等主题。此剧通过一系列出人意料的情节反转，揭示了人类在命运面前的无力感以及对自我认知的局限性。<br><br>《俄狄浦斯王》讲述的是一个关于命运、知识和人类局限性的故事。俄狄浦斯是底比斯的国王，他一生致力于解救自己的城市免受灾难。在故事的开始，底比斯遭遇瘟疫，民众哀求俄狄浦斯解决这一危机。通过神谕的指引，俄狄浦斯决定追查真相，寻找杀害前任国王拉伊俄斯的凶手。然而，在逐步揭开真相的过程中，俄狄浦斯逐渐意识到一个震惊的事实——他自己就是凶手，而且他所犯的罪行更加骇人听闻，他杀死的正是他的父亲拉伊俄斯，而他所娶的妻子约卡斯塔，恰恰是他的母亲。<br>剧中的情节展开紧凑，层层推进。最初，俄狄浦斯通过神谕的指引得知，他将杀父娶母。为了逃避这一命运，他离开了科林斯，远赴底比斯。但他却未曾意识到，这一行为反而成就了预言的实现。俄狄浦斯没有直接杀父，而是在途中与一队人发生争执，愤怒中杀死了拉伊俄斯。随后的事件更为复杂，俄狄浦斯继承了拉伊俄斯的王位，娶了约卡斯塔为妻，却在无意间完成了那个早已注定的预言。<br>整部剧的高潮出现在俄狄浦斯发现真相的时刻。约卡斯塔在真相揭露后自杀，而俄狄浦斯也因无法承受这一发现的打击，刺瞎了自己的双眼，最终流亡至外地。悲剧的结局反映了命运的无情与人类无法摆脱的宿命。<br><br>《俄狄浦斯王》的情节发展可分为几个关键阶段。首先是俄狄浦斯作为英雄的形象建立，他勇敢、聪明且充满正义感，努力解救底比斯免于瘟疫的困扰。其次，通过神谕的揭示，俄狄浦斯得知自己有可能会成为父亲的杀手，这为剧本的悲剧命运埋下伏笔。<br>然而，俄狄浦斯并未直接面对这一命运，而是选择通过自我流亡来逃避预言，这一决定反而成为悲剧的根源之一。他的离开导致了与父亲的误会以及对自己真实身份的忽视，而他在底比斯的继位和与约卡斯塔的婚姻又为悲剧的高潮做好了铺垫。<br>随着俄狄浦斯不断追查真相，剧本的紧张感逐渐上升。人物之间的对话充满了暗示和冲突，尤其是在俄狄浦斯与德尔斐神谕使者、先知提瑞西亚斯等人物的交锋中，观众能够感受到一种无法避免的悲剧预兆。最终，俄狄浦斯通过真相的揭示，迎来了他悲剧的终局，这一揭示既是情节的高潮，也让观众看清了剧作的深刻主题——命运的不可抗拒和人类对真相的渴望。<br><br>《俄狄浦斯王》作为一部典型的古希腊悲剧，其深刻的主题与哲学探讨至今仍具有现实意义。剧中最为突出的一个主题是命运的无情与人类的无力。俄狄浦斯在剧中始终试图逃避神谕所言的悲剧结局，然而他的每一个行动、每一个决策都最终加速了悲剧的实现。命运对他来说是无法控制的，他在努力寻求真相、寻求解救的过程中，恰恰是将自己推向了毁灭的深渊。<br>这一点反映了古希腊悲剧中的“命运无法抗拒”这一核心理念。古希腊人认为，命运与神的意志是无法改变的，尽管人类可以通过行动来努力改变，但最终结果往往超出个人的控制。这种观念在《俄狄浦斯王》中表现得淋漓尽致，俄狄浦斯的“反抗命运”的努力，实际上只是命运安排的一部分。<br>另一个值得关注的主题是关于自知之明的探讨。俄狄浦斯从始至终都对自己的身份一无所知，直到最终的真相揭示，他才意识到自己所作所为的悲剧性。在剧中，俄狄浦斯为了解救底比斯而追查真相，但正是这种对“真相”的不懈追求，使他陷入了无法逃脱的悲剧。这种“追寻真相”的动机，让人反思人类对知识的渴望和对自我认知的局限。<br>同时，剧中的人物如约卡斯塔和提瑞西亚斯等，也呈现了“知识”和“预知”之间的张力。约卡斯塔试图安慰俄狄浦斯，认为命运不可信，但她自己最终也未能避免悲剧的结局；而提瑞西亚斯则早知真相，却选择沉默，这也反映了知识的不同角色与影响。<br><br>《俄狄浦斯王》作为古希腊悲剧的代表作之一，深刻地揭示了命运、知识与人类命运之间的关系。剧中的每个情节和人物的命运，都紧密交织在一起，最终以悲剧的方式向观众传递了命运的无法逃避、知识的有限性，以及人类无法战胜的宿命。这些主题不仅对于古希腊社会具有深刻意义，对于今天的我们，也依然具有启示和反思价值。]]></description><link>culture\教育学\教育哲学.html</link><guid isPermaLink="false">Culture/教育学/教育哲学.md</guid><pubDate>Sun, 10 Nov 2024 08:32:37 GMT</pubDate></item><item><title><![CDATA[教育自传]]></title><description><![CDATA[ 
 <br><br>很感谢老师能给我这个机会来梳理一遍我自己的教育经历。我如今二十岁，基本从记事起就开始做学生，与其说是教育自传倒不如说是人生自传，所以我也是借这个机会回顾下自己是如何走过来的。每个人都有故事，但不是每个人都有机会说出来。感谢老师给我这个机会，也给我这个理由让我找一块完整的时间去看一眼来时路。<br><br>2003年十月，我出生在鲁中的一座小乡村里，这里不是余光中乡愁里的永春，也不是李娟的家乡阿勒泰，它像萧红的家乡呼兰。这里没有山没有水，只有一望无垠的华北平原；这里的房屋成片，你家的东墙便是我家的西墙；人也成片，邻居不是我的亲戚便是我亲戚的亲戚。这里是山东泰安，我的家乡。<br>从我记事以来回老家的次数越来越少，到如今基本只有过年回去，所以可悲的是，我对家乡最深刻的印象永远停留在深冬。漆黑的夜色里东南方的猎户星座，因为干旱而皲裂的大地，田间被埋在积雪下的玉米秸秆，拜年时一堆叫不上名的亲戚，G15沈海高速上如红飘带般的尾灯。哦对了，还有每年除夕夜都要去拜的祖坟，祖坟在我们那叫陵上。敬酒、烧纸、磕头，似乎是一种信仰，一种与这片土地上曾经的人们跨过时空的交流。不过这些年随着青年进城，老人入土，各种乡里的习俗也逐渐消失了。<br>2007年我上小班，这段我印象不深，只记得学校的蹦床很好玩，我每次放学都要玩很久。那年父亲外出打工去了，不得不说他运气很差，因为08年经济危机。第二年，母亲带我去了他们外出务工的地方——常熟。我在这里上了中班，在我的印象中那不是段很好的回忆，我似乎受过老师针对，但也似乎有很好的朋友，我在梦中时常见到他们，可是一觉醒来却又都不记得了。我妈说当时有个很好的阿姨很喜欢我，帮我织了好几岁的毛衣。我去到那儿大概上了半年学，父亲下岗了，因为工厂要降本增效。他开始卖起了水果，我似乎还有些印象，那时候他经常开着他那个三轮车带着我去批发市场买水果。<br>大概也是不稳定，大班和一年这两年，我又回到了老家，这段时间我跟我爷爷奶奶度过，也真正开始有了记忆。我开始记得我生活的那个庭院，记得我那个幼儿园的王老师对我很好，午觉起来总是给我零嘴吃。我记得夏天纳凉时一群奶奶拿着蒲扇在村口唠家常，我就跑出来看月亮、看星星、吹晚风。<br>到了一年级，我到隔壁村子的小学读，每天坐着我奶奶的自行车上下学，座位上用布和棉花绑了个坐垫，倒也不硌屁股。记得我们当时还有国学课，不同于语文课，每天上课就咿呀咿呀地读：天对地雨对风大陆对长空，山花对海树，赤日对苍穹......我挺喜欢这门课，现在我都还能背上几句，虽然当时什么都不懂，不知道什么是海树什么是苍穹。但是老师上课摇头晃脑地读，我们下面摇头晃脑地跟，有种韵味在里面。数学课给我的压迫感我现在还记得，我们那个一年级老师很严，每次上课写四面黑板的算术题，密密麻麻让学生上去做。<br>那时候感觉每天都很快乐，我在村子里还认识个很好的朋友叫李锐，是个很野的小男孩，这是我记住的第一个朋友的名字，我很遗憾我之前的朋友连个名字都没在我的生命中留下。那时候他经常跟我一放学就满村子跑，我们夏天从玉米地的一头窜入，玉米很高，即使他把我抬起来我也探不出头。跑着跑着就迷了方向，等我们跑出来已经从村这头跑到了村那头。那时候浇灌田野的水渠是有一个水房管理的，是一个黑乎乎的小屋子，机器轰隆隆，水声哗啦啦。我们当时特别喜欢在水房的出水口冲脚，刚从地底上来的水，冰凉凉的。有时候我们还会偷偷挖个萝卜，当然是李锐“指使”的，青萝卜，用水渠里的水冲一下，外面是青色的，咬开里面是紫色的，甜甜的又有点微辣。后来去爬泰山时，竟然有人卖，叫心里美，<br>我是个胆小的学生，至少小时候是。作业从不敢拖欠，那个周末却赶上了岱北集，奶奶说我写完作业就带我去。但我是真想去，但我也是真没写完作业。我记得我撒了慌，但是我觉得那是我撒的很正确的一个慌，因为那天我第一次看见狮子、第一次玩套圈、第一次看动画片。那次集会很大，竟然来了马戏团，我还在一家店里忘我地看了一段动画片，具体是什么我不记得了，但是那天我奶奶以为我丢了，找了我半天，很着急，回家我应该被教训得不轻。<br>现在想来那就是我的童年。<br>在我印象里在一年级还有件重要的事，那就是我第一次看书，这个看书与学校要看的教材不一样，也与我姑姑逼我背的三字经不一样，那些书我都不懂，或者懂了也不见得感兴趣。但那一次不一样。那天，学校门口来了一些小贩，卖的是各种各样的杂书，应该是收来的可能某个书店处理的旧书，很便宜，我也就挑了两本，当然全凭书名和封面，一本是木偶奇遇记，一本是八十天环游地球。当时字都认得不全，好在书上都有拼音，我手边也有字典。我其实现在挺不理解当时的想法的，或许是当时没现在这么多诱惑，一个一年级的小孩，字都不认得多少，突然没人逼迫，自主地看起了书。我当时很快就读完了，甚至意犹未尽，开始了二刷三刷。这在我后面的读书经历里也存在，我一旦喜欢上一本书，我就是喜欢反复读，或许我喜欢的不是书本身，而是流连于那个不存在于世间的另一个世界。木偶奇遇记这本书我一直留着，十几年了，但我每每翻开，看到扉页上一板一眼地写着我的名字都不禁莞尔，那讲究的是横平竖直，他一定很认真，我很喜欢那股认真劲儿。<br>一年级末，村头突然有一天多了一座沙子做的山，听说之后要建楼，人们就要搬到楼上去住了。那座楼建成了，但我只有在每年过年的时候去住上几天，那座楼最近又被拆了，就在去年，当时我妈站在废墟上我还给她拍了张照。<br>一年级的暑假，我又要离开了，我不记得是怎么告别的了，反正是在那座沙山上，我们经常在上面捉迷藏，每次玩完都一鞋子沙子。李锐最后有没有跟我说再见，我们有没有许下什么天翻地覆慨而慷的誓言，我都不记得了，我只记得他留着清鼻涕挥了挥手，从此我们再没相见。<br><br>二年级我来到了浙江嘉兴，那个县叫海盐，这里走出了余华，走出了三毛。我来到这里住的是当地一个农村的小宅子。这里的农村跟北方不一样，一户人家一片地，与邻居至少隔一条路，也没有围墙，院子连着田野，田野里都是油菜花，一到三四月份开的满眼都是。院子前有一口井，栽着几棵橘子树，我记得结的橘子总是很酸。那个小村子旁边是杭州湾跨海大桥，当时还没有港珠澳大桥，那应该是中国最长的桥之一，是G15沈海高速的一部分，我跟这条高速有着很深的缘分，因为这条路的那头是家乡，中间连着常熟、苏州，而路的这头就是海盐。<br>当时父母三班倒(即晚上十二点到早上八点为夜班，早上八点到下午四点为白班，下午四点到晚上十二点为中班)，他们之间的时间刚好错开以照顾我，但是这样让他们成为了两条平行线，你工作时我在睡觉，你回家时我去工作了，同居不同时，如车轮的两头永远无法交汇。但是总有他们都没有时间的时候，那时候我上学怎么办呢？这个村头的小卖铺家的小孩刚好是我同学，父母给他们钱，每天早上的时候我就到他们家蹭个车上学。南方村落的小路总是碎石子路，走上去像踩在雪地里，沙沙的，每天早上我迎着朝阳走过那条路，石子被染成红色，像是在燃烧。南方有个很不好的地方，家里的狗都不拴绳，我从路上走过，两边院子里的狗都喜欢朝我乱吠，有时候还追出来，我很不理解我一个路过的追我干嘛，难道它能嗅出来我是个北方人？我每次都要盯着那些狗倒退着走，因为我怕一转身它们就追上来咬我一口。这也是我不喜欢狗的原因。我当时就定更早的闹钟，七点钟去，狗还在，就六点半去，六点半去狗还醒着就六点就去。所以我当时总是提前到我那同学家在门口看着他们洗漱吃饭，倒也怪尴尬的。但是起的再早也没狗早。这件事我后来跟我妈说了，她抱着我哭得厉害。我爸告诉我看见狗就弯腰假装捡石头，狗就会跑，这一招果然有用。<br>二三年级我都是在海盐度过的，我遇到了我另一个朋友航航，是一个文静的小男孩。我不知道他的全名，因为都叫他航航，他比我小两岁，是我的小弟。当时他家买了电脑，我经常到他家玩一个盗版的植物大战僵尸。也算是我第一次接触电脑。我们一起拿着钳子，扳手当枪(因为扳手倒过来像一把枪)，去油菜花田里探险。在我搬走的时候我在他手臂上咬了一口，或许是从电影上看来的，或许是被他家狗追得太勤，但我希望他记住我，不过他哇哇大哭地跑回家去了。<br>至于海盐的学校里，我只记得我那个很严格的班主任，同学却一点都不记得了。但我记得一件事，我不会跳绳。这可能在南方是件很奇怪的事，但是是体育课的一个考试项目，但我从来没接触过跳绳，也不知道把一根绳子甩起来再跳过去有什么意思。而且当时我有个比较大的心理障碍，每次绳子甩到后面到我的视野盲区的时候我总担心它会打到我，所以我总是跳一下就像个乌龟一样缩一下头，这个动作一定很滑稽，当时一定也收获了不少笑声。但是后来我还是学会了跳绳，甚至还参加初中的双飞(指跳一下甩两圈)比赛，中考跳绳这一项也给我了个满分。其实现在来看，我最大的缺点在那时就显现出来了，就是缺乏勇气，这在之后学滑板的时候也体现出来了。<br>当时，我二年级，我爸经常骑着他那个紫色的小电瓶车带我去他们厂生活区玩，因为那里有乒乓、台球和他的朋友，他当时很爱玩这些。当时生活区路上总是有一群大一点的小孩滑着荧光轮的滑板，对当时的我来说就跟现在骑摩托炸街一样，觉得很帅。很快我也有了我的滑板，但是有一个很大的问题，我始终不敢上去，更谈不上练了。那种滑板，需要一只脚在地上加速，另一只脚在板子上，加速时自然以地上的脚做重心，但是总不能一直总是一只脚在地上，当地上那只脚离地的时候，重心就要移到板子上的脚上，重心容易不稳，这就是我当时的顾虑。怕，是我最大的障碍。<br>二年级下学期吧，大概，父亲又下岗了，应该是工作失误之类的原因。他买了辆推车，去菜市场门口卖起了炒饭，现在想想他是没有什么商业头脑，人们去菜市场是买菜的，是要准备正餐的，自然不会买炒饭炒粉这些快餐小吃，倒不如卖些凉菜熟食说不定人们还愿意给自己餐桌上添道菜。我们当时有一批主要客户是菜市场旁边网吧的网瘾少年，他们没什么钱也不愿意浪费上网的时间出去吃饭，我和我妈当时就一起去网吧里卖盒饭，还有人预订。<br>可能没算好收支，我爸的这次小贩经历应该是失败了。他颓废了一段时间，然后玩起了老虎机(一种博彩游戏机)，那时候我记得父母经常吵，吵得很凶，记得有一次我记得是在夜晚的公路上，前因和后果我都不记得了，但我记得昏黄的路灯下我妈在电话里声嘶力竭，她给我了家里的钥匙，让我独自回家，而她要去嘉兴火车站，那对我来说是个遥远的名字，连接着更遥远的地方。我独自走在那条公路上，没有人行道，货车从我面前经过，扬起的沙尘扑在我的脸上，我逆着车流不记得走了多远，走了多久，也不记得是怎么回到家的。<br>那个暑假我爸给我妈买了人生第一枚金戒指，送我到了上海，我二姨家。<br>我回来的时候应该他们就不吵了。我记得当时一起去了乍浦的一条街上玩，不知是庙会还是什么，但是当时算了算卦，我爸和我妈都算了，我没算。还请了个菩萨回家，说是要让我爸往东去发展。但海盐那边基本就是中国沿海最东边了。思来想去，我爸还是走了，去了苏州太仓。我和我妈租了另外的地方，生活区旁边的一个小区，因为这里有他们的同事，上学时可以把我捎过去。我在这里认识了我海盐的第二个朋友侯墨涵，他是个很阳光的人，是个活宝。也是在这里我开启了我的造梦西游之路。<br>后来母亲也走了，留下我一个在海盐上学，但是奶奶过来了，奶奶的性格是很爱玩的那种，我能想象把她叫到一个人生地不熟的地方，每天的事情就是接送我放下学，整个白天连个说话的人都没有是多么无聊。这样的生活大概持续了半年，我来到了苏州太仓。<br>三年级那个暑假我来到了太仓一个小镇上，又是租的一个离学校近的一户农家小院，类似北京的四合院，但这里的人家更多。这家人一共有三个院子，我们住的那个院子有片竹林，挺幽静的。中间的主院是房东的住所，一个二层小洋房，门口的院子种满了玫瑰、月季和各种认不出的花，还有几棵樱桃树。我在那个暑假在当地的一个补习班上课，因为学的教材不一样，也因为那个老师是旁边那所小学的代课老师，父母希望通过这层关系插班进去。她开了一家视力矫正的店面，叫护眼郎，顺便给学生补习。那老师姓钟，我们叫她钟老师。在那里挺开心的，还遇到了我之后的同学，每天在那里学习，其实更像是在那里跟一群孩子玩。我记得我们当时一到课间就在旁边的会所门口你追我赶地跑着玩，却一次都没有进去过。我记得南方的大雨来的很快，黑压压的一片云过来，大中午仿佛变成了黑天，我们一股脑涌进那个小店面，拉上玻璃门，看外面雨点从小变大，在逐渐升腾起气泡，一股混杂着尘土和雨水的气息传来，我很喜欢闻那个味道。我记得我们当时还捡到过一大笔钱，反正对于当时的我们来说应该是从没见过那么多红钞票，应该是去会所的人掉的，出于捡到钱要交给老师的原则，我们交给了钟老师。我记得我有时到点了会在那里赖着不回家，钟老师就会给我按摩眼睛，她问我为什么不回家，我说家里没人。<br>临近暑假结束，我遇到了一个问题，我没有学上了，由于我属于外来人口，太仓又是个外来人口很多的县级市，很多外地的学生需要来这上学。我当时一来没有信息，甚至入学考试都是补习班老师通知我去考的；二来没有关系，直到8月30号报道当天，我都没有收到入学的通知，到那时候我都是没有学上的，可能这在没有gap year经历的父母眼里是件大事，这意味着我落后于同龄人。我还去考了一个很远的小学，那个小学人比较少，我考完试很容易就过了，但是他们不让我上四年级只能上三年级，至于为什么是三年级，因为我是提前一年上学的，苏州这边年龄卡的比较死，9月1号以后出生的只能跟下一届。但其实家里人还是想让我上离家近一点的学校，于是那天，我爸妈带着我去了学校，我爸给保安递了根烟跟他说起了我们的来因，没想到那保安直接带我们去了校长办公室，没有想到我的关系是一名保安。所幸的是我小时候比较胆小，老师说的一般都照做，所以我从一年级到三年级是全三好生，这其实钻了个漏洞，因为在浙江还有个全优生一学期一个，而三好生一学期六个。校长是个和蔼的老奶奶，调了我的入学考试成绩后便让我下午报道了，我就成了三年级六个班唯一一个插班生，我在六班，学号是四十一号。但其实一直到入学考试选年级我父母还没有明确告诉我该考哪个年级，最后我自己选的考三年级，因为这样我更有把握一些，也是因为我很守规矩，我知道这里的规矩不会因为自己破例的，怀着侥幸去考四年级或许我反而连学都上不了。很多年后，我爸又遇到了那个保安，但他已经换了个学校，因为被开除了。<br>小学的剩下几年我都是在这个学校度过的，我很喜欢这个小学，我甚至觉得它的教育很前卫，教导主任也是我见过最温柔的。因为我多上了一年，也是因为我本来成绩就还行，所以小学我学得很轻松。<br>我的三年级语文老师名叫崔静倩，她是个很好的老师，有一手很漂亮的黑板字。我为什么对她印象深刻呢？那是一个中午吧，管纪律的两个同学会记午休说话的学生，那天中午我没说一句话，但我听到了他们的对话，“今天用什么理由？”我知道她们指的是我。我当时坐得板正，眼泪却哗的一下从眼睛里奔了出来，身体止不住地颤抖。我从不在学校里哭，那是第一次。崔老师没有把我叫到办公室，而是自己从办公室赶来，蹲在我桌子边安慰我的，我至今仍非常思念她。我至今想不明白那一个小委屈为什么就让我哭得厉害，甚至我只是自己以为，事后她们告诉我她们要记的不是我。那或许是一种压抑了很久的情绪在最后一次委屈中爆发。<br>我是个很胆小的人，但我却一直不断地进入新的环境，所以我变得和光同尘，我变得不善袒露心思。那天我是第一次向一个老师袒露心思。<br>很遗憾的是，我自打四年级开始就换了个语文老师，崔老师在我人生中离开了。新老师叫沈健，头发根根直立，像鲁迅，衣冠整齐，一丝不苟。认真在大多数情况下是个好品格，尤其是对于学生和老师来说，认真的老师总会教出认真的学生，认真的学生老师也往往喜欢。沈老师就是这样一个认真的老师，可能我也不知不觉受到了他的影响，往后的学习中我最大的武器就是认真。<br>我总是喜欢背一个很重的书包，里面有我全部需要的书和教材，我是那种怕自己忘带东西的人，所以我一般全部带上。每天从小院出发，路过一片竹林，一片油菜花地，一座小桥就到了学校，庆幸的是苏州这边养狗的人家比较少。<br>我的小学过得很充实，课后有合唱团，有书法课，有编程兴趣班，还有教拉二胡的，有很多兴趣班可以报，当然是免费的，一般是放学后有两节兴趣课。我被同学拉着进了合唱团，被老师拉进了编程小组。每天五点多，校门口门可罗雀了我才会走，早上检查红领巾的还没上岗我就到教室了。我会带些零钱但从来不买东西，除了忘带红领巾。我不知道什么时候变成了个典型的好学生，我现在觉得我当时真的是严于律己，现在的我肯定做不到，但我当时并不觉得劳累，只觉得充实。<br>如果成绩还不错，老师会喜欢你，同学会喜欢你，家长会喜欢你，但或许不是因为我成绩好他们才喜欢，而是因为我想被他们喜欢所以我要求我成绩好。所以我其实很快就融入了新的群体。<br>五年级下学期我搬家了，住进了 离之前学校十几公里的商品楼里，楼很高，大概有近百米，也很宽，我想如果这是古代的城墙应该没有军队能攻破。但现在我觉得那像一个火柴盒。周围没了邻居，只有不断的装修声。从此我的上学路程更长了，我坐起了公交，但由于我是插班进来的，没办学生卡，当时我还是借的我妈一个同事孩子的学生卡，她甚至不是个男孩。<br>在这条公交线上，我认识了李岩，认识了黎凡。说来也奇怪我总是忘记学校里的同学，却忘不掉放学后的朋友。李岩，嘴很欠但是人挺好，我跟他打过架，他妈还过来找过我，黎凡是个典型的老好人，我很喜欢老好人。后来他们一个回东北了，一个不知去了哪儿。直到我后来的升学宴上，黎凡的妈妈认出了我，我才恍如隔世，六年没见，如今又加了两年。其实如果是现在的我的话我会去跟她打听些黎凡的消息，说不定还能约着再见一面，但当时的我还没有突破一个心理障碍，那就是主动。<br>我当时喜欢在公交车上背单词、想问题，我很享受公交车的摇晃，像是一艘大船，窗外不断倒退的房屋是漆黑的礁石，映红的流云是连绵的海浪，远处的火柴盒是遥远的灯塔。似乎这段一年半的公交车上下学经历让我对交通工具产生了不一样的情感。往后的日子我离家越来越远，每次坐上交通工具我总是有种特殊的情怀，感伤、平静，还是孤独？我也说不清那种感觉。看着窗外的景色不断倒退，像是在看一卷倒退的胶卷。我能感觉到那种空间的流动，我能感觉那些朋友在我的记忆里也离我越来越远，可能这就是命运吧。<br><br>六年级的某天班会，班主任提到了我们的班长都已经开始准备择校了，名字叫苏州中学园区校，隔壁班的史儒同学更是早在五年级就去考了天一中学，用来激励一些贪玩的同学。鬼使神差的，我去问了我那个班长是怎么报的择校，回家后我跟我爸提了一嘴。他接下来的行动可能改变了我的人生。在那之前我们家从来不知道择校是怎么一回事，只知道学校是按学区划分的，住哪儿便上就近的中学。这打开了一扇大门，一扇通往另一个世界的大门。<br>不知道当时为什么我爸那么上心，或许是比较相信我？一个乡镇小学的学生没有什么音乐才艺的等级证书，没有奥赛奖牌，没有去多少城市旅过游，纯粹的三无少年。但是他当时依然毅然决然地帮我报了名。递交材料需要去学校交，但当时太仓没有直达园区的车，而我们那里离太仓市里还有一个小时的车程，他需要坐公交去太仓汽车站一个多小时，再从太仓汽车站坐一个多小时大巴去苏州市区，再从市区折返回园区中间还要转两趟公交，总时间超过四小时。我不明白当时他为什么心甘情愿做这些，但是他去了一次又一次。很巧的是那天他回来的时候刚巧遇上我班长的父母，搭了个顺风车回来了。我爸回来跟我说我得的校级奖项基本都不作数，交材料的地方满地的各种奖状，很巧的是我五年级的班主任是个体育老师，名字叫马东方，有一天他给我带来了一张太仓好少年的奖状，我没有参加竞赛，没有参加什么校外活动，我也不是那种天天找老师跟老师打成一片的学生。所以我很纳闷也很感谢他，因为我除了全三好，学校只收了那张奖状，或许是他给了我一张入场券。<br>六年级下学期的某个周末，五六点钟，我和我爸从家里出发，那天天灰蒙蒙的下着小雨，我不记得是坐公交还是骑着摩托去了我班长家，因为那天班长和我一起要去苏州中学园区校(以下简称园区校)考试，我们去蹭车。班长的父亲是个不善言辞的人，有些严肃，一路上都没怎么说话，气氛很尴尬。其实我爸是个很在意面子的人，我不知道他当时承受了多少压力才能去蹭班长家的车，因为即使是六年级的我当时也显得拘束。当时才买房装修不久，父亲手里应该没什么钱，甚至欠着一些亲戚的钱，但是他一年后就全款买了辆车，我觉得自尊有时候的确是一种力量。<br>我们大约六点半从班长家出发，八点钟到校，是九点的考试，我从来没见过这么大的学校，六栋宿舍楼，是我现在大学都没有的上床下桌，400米的操场和超大的体育馆，四栋教学楼由H长廊串起，隔壁便是德威国际学校，甚至还有湿地，一片湖泊，一个小岛，一座小亭，即使教学楼很多仍显得空旷。我现在都觉得那简直就像一所大学。<br>我坐在后来我走过六年的A1楼的大厅里等待着考试，就像图书馆一样，旁边的架子上都是书，我随手拣起一本看，自然是不可能看得下去的。可能是那种电视看多了，总觉得自己的一言一行都是在考试范围，心不静，自然读不进书，只能是装装样子。但未来的几年这里却成了我闲暇时的好去处。<br>我记得是在机房考的试，题目似乎也不是很难，一些奥数问题，一些英语阅读理解，一些古诗文，一些历史典故甚至还有些天文地理方面的问题，内容很杂，但是很巧，我学的也比较杂。<br>某个下午，小学学校里，班长叫住了我，他有点激动、有点兴奋，或许眼神里还透露着点小骄傲，他说他过了，问我过了吗？我不知道，但我想马上回家上网查。那天我一放学就往外走，红领巾都反着戴了也浑然不知，我走得越来越快，我知道我马上就要知道那个答案了。学校的香樟树很多，它们会落下很多黑色的小果子，有的掉落在我的发间，有的滚落到我的脚底。那天阳光正好，微风不燥，放学欢快的背景音乐伴着我的步伐，我感觉我似乎呼吸急促，不知道是因为书包太重，还是走得太快。<br>校门口，我爸在等我，他没跟我说过今天来接我，我第一句话问的就是我过了吗？有些刻意地不在意，但声音有些颤抖。我看见我爸开心的笑我就知道了结果，那天我很高兴。其实有些东西没有那么遥远，伸手够一够便能碰到。<br>我有时候会想，如果那天我没有在操场上问我班长关于择校的事，没有跟父亲说起这件事，把那当作一个遥远的触不可及的事情，一笑而过，那么我的人生会怎么样呢？如果我爸没有那么强的执行力去交材料去报名，那么又会怎么样呢？在以前我会觉得这是一种命运的转折点，但现在看来也不会怎样，任何一种选择都无关好坏，对我来说只是换一批过客，换一种风景。<br>这是又一次离别，不过这次不是被动，而是我主动的，初中开始住宿，每周末回家，周日晚上回学校。学校由于本来就是从苏州各地收割的生源，配备校车，会送到太仓市里。初一那年我都是蹭车回来的。直到一年后我爸买了车。<br>初中，入学前要求学新概念英语，要求提前了解初中数学，要求读英文故事书《书虫》。我爸给我报了个衔接班，巧的是当时辅导我的那个老师是那年刚考上南师大的高三生，比我大六岁。他是靠着奥数竞赛加分进的，但是这到六年后我们的高考就完全变化了，取消了自主招生转为综测和强基，如果我那个老师晚生个六年，他或许就进不了南师了。<br>三年的初中其实有非常多可以说的东西，老师都很好，同学也大都不错。因为我基本都记得了，反而不好挑。但真要我说有什么令我印象深刻，我觉得是几个人。语文老师章艳，她有时候自称章半仙，最喜欢跟我们唠家长里短。英语老师也是我们的班主任李畅。还有一个女孩，我不愿提起她的名字。<br>我的第一场数学考试考得比较好，晕头转向地当了数学课代表，但后来我那个班级走出了两个剑桥，一个南大人工智能绩点第一，能当他们的数学课代表是我的荣幸。可能也是因为这个原因我那数学老师比较器重我，班主任也比较重视我，但我每每到期中成绩尚可，到期末总是会考得不好。那数学老师带了我们一学期就走了，去了其他学校当校长，他一直觉得我能考西交大少科班(初三考取，不需要中考高考)，或者走德威奖学金出去留学。但是这两条路我都没走，我一直觉得有些愧对他的期望。或许由于那离我太遥远了，一个在西安，一个更是远在英国。如今看来，我至少应该去尝试，应该去准备，因为我从初一就知道这个信息了。也许是因为褪去了光环，我变得普通了，或许也自卑了，变得不再敢尝试往更高的地方走。如今我判断一件事要不要去争取我只会考量我得到了会不会开心，不去争取会不会遗憾，如果是肯定的回答我就会去争取。<br>现在看来，当时从小学的尖子生到了初中，发现大家都是小学的尖子生，未免有些感觉落差。这些人的家庭不一样，喜欢的东西不一样，但是都是一样的人，我们都在一个时代长大，会遇到同样的烦恼。<br>初高中给我带来的最大的一个收获是，人与人之间并无根本差别，这种意识是能与人产生共鸣的基础。<br>初高中各式各样的人很多，有感觉不用怎么学就能学得很好的天才，他们提前进少年班比我们早很多便进了大学。有在国内卷不下去的，出国的，成绩还行的就去英美，不行的就去澳洲加拿大。有亿万富豪的孩子，有市长的孩子，有家里卖大闸蟹的孩子，有家里开出租的孩子，有工人的孩子。各种各样的人，来自各种各样的家庭，我曾经或许自卑或许虚荣，但其实我后来发现人都是一样的，开心了会笑，悲伤了会哭，都会有一些小虚荣心，都会有一些不如意的地方，都会带一些小自卑，然后或许随着成长他们都会获得一个能包容那一切的大心脏。人的情感和思想是相通的，即使不同家庭，但整个社会环境是一致的，我所经历的想法或许每个人在不同时刻不同地点都会或多或少地感受过，其实一想到这，人便不孤单了，人便不虚无了。<br>其实不止情感和思想，所谓的智商情商都不是不可逾越的天堑。有很聪明的人吗？自然是有的，就学习来说，有的人就是学得快些。但这个差别足以影响一个人的命运吗？为什么同样的教室最后学出来能差到上百分？就学习而言，习惯远远比智商更重要，或者说智商更像是一个人思维习惯的综合体现。而因为是习惯，所以真正的天才往往并不觉得劳累。这种习惯非常多，学了一个知识点总是习惯性地去想想与它有关的知识，这种都算是具体的，甚至上课什么时候该集中注意什么时候休息，这都是习惯。人的注意力是有限的，很多时候并不是别人比你更专注，而是别人在应该专注的时候比你更专注。这一点我直到高考结束才想明白。<br>那要说情商这种东西总归不是习惯上的东西，是人与人天生的区别，这对也不对。现在很多人把人情世故当做情商，那么我们就先说人情世故。难道人情世故就比数学题难？就圆滑之人知道该什么时候溜须拍马？我认为并不是，对于一个人来说，人情世故是开卷考试，人人都懂，但并不是人人都愿意做，人人都做得自然。一个人得到什么东西的时候必然失去了什么东西，我觉得很多时候人情世故也是这样，很多人不是不愿意人情世故，他们也知道那样带来的好处，但是他们却承担不起失去的东西，你奉承上级必然让你的同僚不开心，你送一个朋友东西，没有得到东西的朋友必然认为这是一种疏远。但那些通过阿谀奉承获得利益的人说这是嫉妒，怎么能是嫉妒呢？是你在这套价值体系里用了不正当手段获得了利益，那必然受人诟病，这是千百年来的话语体系，生长在这个环境下的人必然有这个思想，所以大部分人都是不屑于去讲人情世故的，是不愿面对那种风险，是不愿面对这种话语体系下的道德谴责。不过近些年来，我们的社会环境在吹捧披着情商皮的人情世故，刻意拉高人情世故的价值，却忽视其中的风险，这不见得是件好事。<br>而我认为的情商是感知别人情感的能力，这种能力每个人天生就有。托尔斯泰在在《战争与和平》里有这样一句话，“如果你能感受痛苦，那么证明你还活着。如果你能感受到别人的痛苦，那么证明你还是个人。”每个人都可以感受到别人的情感，有些人看起来在笑你也能看出他其实很伤心，有些人说着不在意其实心底在意，这些真实情感是一定会在一个眼神，一个肢体动作，或者一句话中体现出来的。有些时候我们觉得我们想多了，往往并不是想多了，而是我们没有能理解那些我们不经意间感知出来的情感。所以我一直认为人都是一样的，起码在情感感知上不存在十分巨大的差异，即使是瞎子也能从别人粗重的喘息声中听出生气的意味。所以人的情商差别不大，差别在于对感知的解读。<br>感知和理解是不同的，感知是天生的，而理解别人的情感的能力受后天的影响。因为人经历过越多，感受过越多，就越能理解别人的情感。一个十分能理解别人情感的人即使不屑于人情世故但依然会让人亲近，这是我向往的境界。<br>我们那班主任是个刚毕业的香港理工的英语硕士，她跟我们一起上下学，因为新老师有分配的教师宿舍。她经常叫我去她办公室晚自习，她管不住嘴，冰箱里零食多。而且我都怀疑她小名是不是叫落落，因为她很大方，我吃了她不少零嘴。后来她还在我生日时请我去校外吃了顿长寿面。有一次隔离期还带我们一些同学去吃了火锅。<br>我的所有语文老师都是我的恩师，我觉得中国现在教育存在对德育的缺失，我们的思政课更多的是政治，而不是道德和思想，它们往往带来的不是价值层面的景仰而是生理层面的抵触。而这部分缺失只能由语文老师来填补，所幸我的语文老师都很好，都有值得我学习和敬仰的品质。语文作为母语的教学其实一直以来受到实用主义的诟病。且不说语文的德育作用。真正的语文培养的能力是最基础也是最不可或缺的——表达和理解的能力。<br>章半仙是个很有意思的老师，个子不高没有行政岗位，没有职称，是个典型的一线教学老师，写了一本书，叫做《卓越可以自我打造》，是一本班主任语录。她还开了个公众号章子恬园，但是近几年没看到她更新了，可能长草了。我们当时每周要写一篇散文随笔，一篇摘抄评论。三年下来，我有两三本散文随笔和评论。我很喜欢那段时光，虽然有时候写不出来憋半天很难受。她给我们开辩论赛，玩角色扮演，即兴演讲，当时的语文课对我们来说就是玩。当然文言文是例外，学起来很痛苦。我很感谢我的语文老师给我带来了这些宝贵的经验和回忆。<br>我的高中也在园区校度过的，我的确很喜欢这个学校。当我第一天迈入高中教室的时候，一切又是那么熟悉，与我初一的教室就隔了两堵墙，因为当时是4班如今变成了2班。最让我惊讶的是在教室讲台登记学生的是我的初三数学老师，姓马。我们是她带的第一届高中。虽然我承认她是个勤奋上进的老师，不爱说话，即使说话也是低声细语。这样的老师没法跟学生打到一块，虽说她是班主任，但是存在感很低。听说她也是高中早恋，但是在方方面面她却表现得传统得很，或者说是胆小得很。我数学底子一般，初中就一直在换数学老师，而且这些老师大多佛系，直到初三遇到个马老师，每周一叠卷子，疯狂刷题。到了高中，又是马老师，题目一样多，但是其实咀嚼的时间越来越短。高一高二的两年我的数学底子都没打好。直到高三重新分班，彻底按成绩分班，所有老师全换了一遍，数学才开始有体系地再学了一遍。<br>我高中的语文老师叫孙晋诺，是个正高级教师，算是在中学教师这个行业中走到了尽头，我很奇怪这样一个语文老师远不如我初中语文老师话多。上课时他话很少，他的口头禅是要沉潜。我们的课上大多是学生上去讲自己的理解，语文这种东西除了试卷不需要正确答案。这种做法让学生能在公共场合快速整理思绪并表达出自己的想法，但任何事情都有两面性，对于不喜欢表达的同学可能是一种折磨。<br>跟章半仙比起来他都显得有些嘴笨，还有些山东的乡音。我却在他身上看到了我小学语文老师的影子，他很认真，很勤奋，比高中的我们还勤奋的那种。每天只睡四五个小时便能精力充沛，他喜欢布置很多写作作业，而这些作业他都会一个字一个字看，并用他那只红墨水钢笔写下洋洋洒洒许多批注。他的公众号能基本维持日更，这是一个五六十岁的老人了。是这样一位老人让我开始去思考生命的意义的，这样一个在这个行业走到尽头，该颐养天年的老人为什么为什么每天还在奋斗？<br>我们那时候疫情，上网课，那段时间，我们写了许多东西，有针砭时事的议论，有为医护人员写的诗词，有对现状的反思。他还会把我们的文章发在他的公众号上，有一种一群少年在向社会发声的感觉，现在想想，那时真是一腔热血，总是希望再深刻一些，事情的本质还没有被我看透的感觉。比如大概高二时，衡水中学的一名学生在我是演讲家节目里那段很经典的“我是来自乡下的土猪，也要立志去拱大城市里的白菜”，我记得那天老师让我们去写这段演讲的评论时，他很惋惜，甚至眼圈有些红。当时班里有夸这是少年热血，我命由我不由天的，也有反对的。可能是性格原因，我不大喜欢这种有些盲目的热血。他给自己的定位是一只来自乡下的土猪，这就和我的价值观相悖，我是来自乡下，但我不觉得自己是土猪，我与城市里的白菜不存在种族隔离。他描绘了一种美好的场景，说他高考答完题目，看窗外阳关灿烂，接着引用全球高考的一句话“世界灿烂盛大，欢迎回家”。可惜的是，我高考时最后一场考完天已经快黑了，而且世界一直都灿烂盛大，不需要高考后才能回家。而且当时要排队等做完核酸才能出去。高考很公平，是普通人改变命运的机会，这没错，但也别神话它，别让生命里只有它，高考完一样要做核酸，一样要吃喝拉撒，人的生命最好不要挂在一件具体的事上，这会让人变得脆弱。<br>我那老师当时难得给出了自己的观点，他觉得可惜，可惜的是少年热血珍贵，却扑在了一个小小的高考上。少年热血常有，老年热血不常有，但是孙老师有，他是个顽强对抗应试教育的斗士，他认为基础能力有了高考不过是简单的事。与他相反的是我的高三语文老师，张红。<br>她是我见过最严的语文老师，作业量一下从数学那里抢来了半壁江山。我们的初次见面在网络上，也是写一篇议论文，她说我写的不是议论文，毫无章法，我装得耿直顶了几嘴，后面我跟她关系一直不是很好，因为我不喜她，她也不喜我，她跟我的价值相悖。但是我最终高考语文还不错。<br>高三那一年是应试的一年，时间像个滚动的车轮，一天也不会停下，考试作业接踵而至，可能对于底子好的是查漏补缺，但我底子较差，我会产生一种漏洞越补越多的感觉。那真不是一种很好的感觉，像陷入泥潭，越陷越深，找不到自己的节奏就找不到爬出泥潭的支点。<br>我的高中同桌就是那种学习上的天才，他叫皮陈澄，他是苏州市一模的第十五名，照这个排名是必然进清北的。我很感谢他，有一次我脚崴了，崴得厉害，我要去医院。我记得那天我叫了徐涵，是我五年的同学，他没有应我，可能他没有听到，其实那时候我有些尴尬，是皮老板毛遂自荐，从教室到校门口的这段距离，就是他架着我出去的，当然他很瘦，很难一个人架得动我，当时刚巧碰上了姚之杰，他很壮，是我们班高考最好的一个。两个人把我又背又架，我很开心有这样两个朋友。人在关键的时刻需要有人站出来帮一把，这一帮就会记一辈子。<br>高三下学期我们封校了，大概三个月没回家，头发长到了鼻尖。期间学校有爆发过冲突，有请人来做过集体活动纾解心情，那当然只是我们那个高三新数学老师兼教导主任应付上层的活动。我不喜欢那个教导主任，整过牙齿，每天都化妆，喜欢骂人，但是她护短，自己班的骂的少其他班的骂的多，所以可能这个学校除了我们班都对她恨之入骨。晚上查寝，因为有人顶嘴直接把人骂回家，晚自习走廊上时不时就有她的训话声。一个学校的风气很大程度上由它的教导主任决定，她完美符合人们对教导主任的刻板印象。但就数学教学而言，她是个好老师。<br>高考，我记得那几天还去苏高旁边的文庙拜了拜，住了几天酒店。要说有多么惊心动魄、刻骨铭心，似乎也没有，就是写几张卷子，除了数学让我万万没想到，其他与平常无异。考了个中规中矩的分数，除了数学那年很难考得很低外，其他都算正常发挥。我有一种信念，我付出时间的大型考试我一般都考得还行，不会出现紧张半路掉链子的事。这点我很自信，也或许正是因为这种自信，让我不会变得神经紧张，也不会生怕自己做错了什么影响了运势。正应了那句话，把每一次考试当做高考，把高考当做一场平常的考试。<br>查高考成绩的那天是我和我爸妈一起查的，我点开那网址，网页转了半天都出不来，我其实感受不到自己是否在紧张。或许对于一个苦学十二年等待结果的学生来说太平静了些，但我就精神不起来，甚至有些无精打采，高考后的那段时间其实我想了很多，我开始变得什么都不在意，那分数不管多少我都能接受，这是我当时对自己说的，所以我表现得就像在刮一个刮刮乐。分数出来的时候我爸很开心，因为一来在我成绩出来前有个跟我一起上下学的同学妈妈来问了我的分数。二来我一直在降低他的预期。不渴望得到就不会失望，比预期高就会开心。我爸很高兴，抱住了我，他那天赤着上身，身上有些粘。<br><br>我一直有个愿望，当老师。可能是十几年来我一直与老师朝夕相处，这个职业我最清楚，这个职业面对的对象，也就是学生，我更清楚。也可能是对于父母那种劳累的工作有些抵触。当然还因为有寒暑假。或许每一个想当老师的都是那么想的，但我确实是经过深思熟虑的。<br>但现实总不是那般如意，填报志愿的老师不建议我填师范，我的亲戚长辈们不包括我父母不建议我填师范。为什么？说到底最关键的就一个原因，如果学个地理学个生物当个老师，出来基本只能当老师，这便经不起风险。学个计算机选择多些。我生命中的很多决策最后的原因都是可以选择多些，因为我担不起风险，所以我也不把鸡蛋放在一个篮子里。有时候不禁思考这种决策的正确性，选择是越来越多，但同时迷茫也越来越多，而迷茫越来越多，我义无反顾的勇气便越来越少了。<br>高考的志愿填报在江苏是这样的，它可以选很多个专业组，然后每个专业组里可以报其中的六个专业，我当时大概填了十几个专业组。这些专业组是某个大学几个专业的打包，当然大学普遍都会将好专业和差专业放在一个专业组里。对于每一个专业组都有一个服从调剂选项，如果你过了这个专业组最低的分数线却没有达到你所选专业的最低分数线，那么如果你不服从调剂就只能去上专科了。毕竟那些大学也不想自己的差专业招不到人，这是可以理解的。但是不服从调剂无法进入下一个专业组而只能掉到专科是我不能理解的。这无疑是在增加学生的选择成本，让学生默认填服从调剂。<br>我的父母其实很支持我，所以最后的志愿填报全是我自己填的。最后我前面三个志愿填的全是计算机相关的专业组，后面几个填了些师范类的专业组。我觉得那是我的妥协，我最后还是没有坚持我的老师梦，因为我当时按往年位次认为我一定能进前几个志愿，后面的志愿我只是兜底。我当时填报志愿的原则是，只有这个专业组里的所有专业我全能接受我才会报，这自然是比较少的，一般如果一个大学专业组里只有几个好专业那么一般都是这个大学的王牌专业，用来提高生源质量的。我当时没有这方面的经验，我前几个填的全是一个专业组就几个的王牌专业，而这种专业组那一年录取位次都涨了很多，包括武汉理工的电子信息，苏大的软件工程，南理工的大数据。我的志愿滑到了第五个，南京师范大学。我在南师大和华中师大之间换了一下顺序，如果不换我就在华中师大学地理了，那我大概率就一定会成为一个标准的地理老师，可以课上跟学生吹吹牛，偶尔出差做几次名为实地考察的旅游。其实我很向往那种生活。<br>南师大我是读不到师范的，我当时很清楚，但我听说南师大好转专业，也就不是很在意。我本来就偏科，副科好，语数英差，到了大学也是，专业课好，数学英语差。而面试我也经历过挺多，所以我觉得转专业不成问题。但是半年后，我决定不转专业了。<br>我挺喜欢南师大的，在我见到它的宿舍前。可能和初高中宿舍对比差距太大了，南师大的宿舍像条走廊。但其实半个学期也就习惯了，都说由俭入奢易，从奢入俭难，其实都一样，时间一长，自然就适应了。我也混过好几个社团，发现文学社里全是男生。开学前我就认识了一堆学长学姐，有卖卡认识的，有新生群水群认识的。但这些后来我都没有再维系了，刚刚高中毕业的我对大学充满了好奇心，觉得这里是同好者的聚集地，是理想主义的堂。但事实并非如此，社团是十几个人的小圈子，他们会跟其他圈子暗暗较劲，说话要同仇敌忾不然就不合群，有活动要参加不然时间久了，你就离开了这个圈子。经营这样的圈子很累，更不用说我们那个社长经营着好几个社团的圈子。我半个学期后就离开了那里，那里有网哲秀优越感的，有针砭时事站边的，有日常水群的，就是没有真正聊文学的。我感到很悲哀。后来我在电影社待的时间较长，那个社团活跃的人不多，因为电影选得比较小众，圈子自然也就比较小众，他们好不容易办了一场电影节，我很遗憾那段时间我在打数模没有能去。<br>我大一也呆过学生会，我每周去龙江那边去给老人上门服务，教老人怎么用手机之类的。我当时真的是想去为社会做贡献的，但是时间久了，就会发现，人去的越来越少，老人也越来越不待见你，认为这是一种打扰。但我在学生会的确认识了很多很好的朋友，不是因为一起工作的原因，是因为一起游戏的原因，我们在每周值班的后一个小时会玩一些桌游，玩着玩着也就认识了。<br>学生会和社团的经历让我认清了两个现实，大学的社团和学生会从来不是同好者和理想主义的天堂，他们大多是怀着目的而来，有的是去找对象的，有的是去混志愿时长的，有的是去刷综测的，有的是害怕孤单找人聊天的，总之很少人是真正为了爱好的，很少人是真正想要做志愿服务的。<br>网上有个梗，叫”大人时代变了“。这就是我入学后的感受，在2022年底，也就是我入学后的半个学期，OpenAI推出了基于GPT-3.5的ChatGPT产品，并向公众开放了访问，于是，时代变了,我放弃了转专业，我并不是看到了AI的前景，而是看到了时代的末路。<br>在这个时代，学校教育逐渐走向全民化、义务化，但同时也走向职业化。我们教育的目的是培养人才，什么是人才，在我们这个时代即有深厚专业知识和专业能力的技术人才，因为这种人代表了更高的生产力。我们义务教育阶段学的是基础的科学知识，到了大学学的是专业知识、专业软件，不同的人成了相同的产品，出厂时打上对应大学的标签。但就如工厂会产能过剩，学校也一样，市场需求少了，便扩招研究生，就像对产品再加工，但再加工它仍然存在，牛奶过剩了会被倒掉，人过剩了呢？这自然不是一年两年的问题。没有那么多岗位给大学生，就逐渐往自由职业的池子里挤，送外卖快递，跑滴滴，开店，自媒体。但这终究也在逐渐饱和，而且随着人越来越多，人的市场价格也自然越来越低，待遇也自然越来越低。我觉得这个时代的人悲哀的一件事是，这个时代的每个人都有个价格，而且随着越临近毕业这种感觉便会越强烈，每年都有更多的人涌入这个市场，就像通货膨胀一样，自己的这个价格还在不断地变低。而且我对这件事的好转持悲观态度，既然产生就业的速度已经及不上劳动力的产出速度，那么自然会不断地积累更多的待就业人群。还有什么行业可以突然产生一大批就业吗？<br>如果说AI我不认同，因为AI革的就是这些专业人才的命。大学分专业之后，行业之间形成无形的壁垒。我们都学习了一套新的语言，一套自己专业的语言。在过去这是技术人员安身立命的堡垒，如今这道壁垒被无情地打破了。在这个世界上所有的知识都可以通过自然语言描述，自然语言就是人类世界的源代码，而为了专业领域的方便，人们在自然语言的体系上定义出来一系列独属于该专业的语言，它可能是某个软件，某种术语，某种表示方法，它们就是这个行业的壁垒，而他们的本质都是自然语言，或者至少可以通过自然语言表示，而AI就像那个可以将所有语言翻译成自然语言的翻译官，任何人只要看得懂自然语言，想了解什么专业内容，AI都可以帮你解释清楚。到了现在，已经不只是可以解释了，它已经可以操作了。它可以写文章做海报，它可以写论文，它可以编代码，因为它读得懂人类的语言了，所以所有的指令只要够明确它都可以做。而且这几年人形机器人发展也很快，基本的行走、上楼梯、抓取都是可以做的了，那一旦这些量产，一个还需要公司培养的应届生与它相比还有什么竞争力？<br>农业革命人们将太阳能变成化学能储存，工业革命内燃机将内能转化成机械能，发电机将机械能转化为电能，而如今，计算机将电能转化为了智能，独属于生命的智能。你可以像与人交流一样与AI交流，或许给它个摄像头加上一个针对人类微表情的图像识别模型，它或许也能获得感知人类情感的能力。那这样一个机器，它是否是生命呢？可能现在谈伦理问题太早，就说AI是否能缓解就业问题我是持悲观态度的。网上有一种观点是把AI当作工具，不会使用的人才会被淘汰，在我看来这是一种自我安慰，AI对于人的取代与历史上任何机器都不同，它不是一种必须由人来使用的工具，它是一个可以实现端到端任务的智能体。比如写一个网页，不是你使用它的各种功能来做出一个网页，而是它直接按照你的需求做出一个网页，你需要做的只是提需求，甚至如果你的需求不明确，它还可以帮你想一些需求。这不是从马车到汽车的变化，这是从马车到任意门的变化。那如果资本一定是逐利的，则必然所有AI涉及的岗位全部被横扫，只会保留零星的几个研发岗，与调试AI的运维岗。其他人去做什么呢？难道都去发电吗？<br>不仅是这些专业人员，老师以后又会何去何从呢？就现在的老师，包括初高中及大学老师，基本以知识性的教学为主，老师的工作是将抽象知识转化为容易理解的自然语言，用图形啊，例子啊去辅助学生记忆和理解，他们将某些专业语言，比如数学语言，物理语言，那一条条公式，推导过程，用更容易理解的自然语言表达出来。我们评价一个好老师的标准也有讲得透彻，讲得通俗易懂。而AI最擅长的就是这个。我在这样一个时代上了大学我很幸运，因为这相当于有了一个全天无休的全能老师，所有专业课的问题基本都可以问。当然也有限制，比如最好以文本形式问，比如有时候会犯错，但是这些问题我觉得会随着它包含的各种工具模型越来越多而得到解决。<br>那么如果出现一个完美掌握所有人类现有知识的人工智能，那么老师作为知识传递者的职能是否就丧失了，那么是否教师这个职业就会回归一开始的德育作用，回归该如何培养一个人而不是一个工具呢？<br>可能那时候脑机接口都完善了，但是与脑机接口那种纯粹的知识灌输不一样，人要真正地将知识内化必须有一个理解的过程，他需要别人的循循善诱，那么只是脑机接口是无法代替教师的作用的。<br>就如狄更斯在双城记中所言，这是最坏的时代，这是最好的时代。章老师之前经常喜欢说这句话，在当下，似乎更是如此。AI兴起，各国隐藏的矛盾随着逆全球化逐渐浮现，仇恨和战争四起……<br>人一旦选定了一个专业，人就被局限了，他会变得只关心自己专业的东西，只学习自己专业相关的东西。为什么呢？一来是因为网络上的电视剧、动漫、小说、短视频等等太有吸引力，他们的闲暇时间都会被这些吸走，而课内知识有绩点压力，考试压力，所以起码会学。二来是大学工科的课程压力很大，他们需要一面卷绩点一面卷竞赛，一面又要卷科研，绩点卷不过还要去准备考研，他们的心思全都在自己眼前的专业上，自然难以去自学自己喜欢的方面或者企业需要的技术。我也遇到过这种问题，我的精力需要全部扑在本专业上，甚至还不够，一些我认为重要的东西我却来不及学。加之又觉得卷这些也没用，过个一年就忘了。未来的变化谁都不知道，四年出来风向又变化了。<br>人一旦往大里看，往远里看，就会变得迷茫。对未来迷茫，对世界迷茫，对当下迷茫。这是我大一一年的状态，这是我的第一次精神危机。<br>迷茫时多看书，一般不会错。后来在纳瓦尔宝典里看到一句话感觉被点醒了，大概意思是说宏观经济的影响因素是非常多的，突然流行的大流感，某个领导人一拍脑袋的决策，某家银行的突然破产等等，所以现实是个混沌系统，而我们的宏观经济体系建立在人都是理性人的基础上，而现实往往不是，所以我们对宏观的东西往往只能解释而难以预测。的确，谁知道2019年会有新冠，谁知道2022年AI会大火，谁知道内塔尼亚胡为什么在如今这个世界还非要围困加沙造成人道主义灾难。<br>感觉高中的时候跟着孙老师心里还满是为天地立心，为生民立命，为往事继绝学，为万事开太平的思想，觉得自己未来一定要改变世界，即使改变一个人也好，这也是我想当老师的初心。到了大学我反而不那么去关注社会了，全是些糟心事，不是初中生虐杀同学，就是哪里又打仗了，哪里又裁员了……这种事情不胜枚举，越关注这些，越觉得世界正在滑向不好的方向，似乎信任危机越来越严重，这与我心意相悖，我还是觉得人与人之间朴素些好，要多些信任，在这世上才能活得安心。<br>既然外部世界无法决定，我决定向内求索。<br><br>向内求索不是件简单的事，我遇到了第二次精神危机——价值真空。可能人不愁吃喝的时候就会胡思乱想，初高中我其实就有些虚无主义的苗头，但是那时候生活很充实，没时间想。如今这种感觉越来越强烈了，我不知道人为什么活着。我需要一个人生信仰，即要找到一个对我来说确实的真理，找到一个我能够为此而生、为此而死的信念。我认为在现代社会找到人生信仰是比过去时代要难的，这个时代没有宗教，没有礼教，没有从我生下来就告诉我一定是对的真理，却有无数不同的生活，有无数不同的思想每天对你进行信息轰炸。<br>现代人在接受一种信仰之前，往往要求确认这个信仰是真实、可靠可信的。但是我们如何才能确认呢？现代人倾向于求证，需要理由来论证确认。信仰对人生的意义越是重大，论证信仰是真理的要求就越是强烈。只有真实的信仰才能让人真诚与坚定地信奉。于是现代人把“信与真”越来越紧密地关联起来，这样就带来了难以担负的论证负担，因为信与真之间存在逻辑裂痕。信仰在本质上是一种价值，接受信仰需要做出价值判断，而真假是一个事实问题，辨别真假是一个事实判断。前者不具有客观的理性基础，而后者原则上可以依据科学理性的证据和逻辑。也就是说，在信仰问题上，如果用审核事实判断的标准去审核一个价值判断，就相当于用短跑比赛的快慢标准去评价一幅画美不美，是行不通的。<br>你不得不勇敢地“纵身一跃”，才有可能越过这道鸿沟。这完全是一种冒险。因为我们并不能知道这纵身一跃的结果是抵达拯救的彼岸还是跌入虚空的深渊。我们甚至无法计算这个风险的概率。信仰需要极大的勇气。<br>如果说信仰是心灵的故乡，那么对于找不到信仰的我来说，就陷入了心灵无家可归的困境。<br>这可能说起来有些矫情，但是这在哲学上有个专有名词“终极关怀”，起码不是我一个人有过这个问题。<br>或许有人会说，我干吗要不断去追问目标的意义呢？我知道为了能过更好的日子要努力工作，这就足够了。我就到此为止，不会去费神继续追问，去理会什么终极关怀的问题。所以，我也不需要依靠信仰来生活。<br>这个质疑听上去挺有道理的。许多人并没有什么明确的人生理想，照样能正常地饮食起居，过好每天的日常生活。这样好像就能避开对人生终极性问题的追问，就能摆脱信仰问题的麻烦。可是，许多哲学家认为：这只是假装解决了信仰问题，实际上你无法真正摆脱。你可以回避这个问题，但信仰问题像幽灵一样，总会在某个时刻与你不期而遇。<br>我在高中的时候就多次与这个幽灵相遇，我也曾与我的高中室友在深夜畅聊生死。很遗憾，我并没有找到我的答案。直到高三，在一篇文科班学生的作文中我找到了一句话，作为我那一个阶段的一个答案。那篇文章的题目叫手推巨石的西西弗斯，里面提到了一句罗曼罗兰的话”这个世界上只有一种英雄主义，那就是得知生活的真相后依然热爱它。“我当时很爱那句话，觉得这句话那样豪气，我当时也很喜欢西西弗斯，喜欢那种生命不息运动不止的力量感，这在我当时的文章中应该用到很多。<br>有时候人们会说要找到奋斗的目标，以前我觉得这句话是句大空话，现在想来这句话其实有它的哲学内涵，奋斗的目标不断向深处指去，指向的就是终极关怀的问题，或者说人的所有行为的最终目的，指向的就是你对终极关怀的回答，指向的是你的人生信仰。我没有找到那个具体的目标，但我找到了奋斗的理由，奋斗是一种生命的本能，人需要奋斗不是因为想得到什么，而是因为这种本能被抑制人就会不适，本能被发展人就有成就感，就会感到充实，与之相比，成就本身反而不重要了。<br>后来看了刘擎的《西方现代思想讲义》才知道这些其实就是一些对尼采思想的通俗理解，不禁感叹，现代人遇到的终极问题是一致的，人与人之间的思想是想通的。尼采说上帝死了，是我们杀死了上帝。西方失去了传统的精神故乡。尼采非常欣赏古希腊神话的精神。在希腊神话中，有太阳神阿波罗和酒神狄俄尼索斯。阿波罗代表一种理性的精神，而酒神狄奥尼索斯注重生命本能的创造力，带有否定理性的反叛精神。在尼采看来，希腊神话中这两种精神之间的张力与平衡，能够焕发出一种生机勃勃的创造性。<br>尼采将虚无主义分为消极与积极。什么是消极的虚无主义呢？就是面对虚无的真相，陷入悲观和绝望。可是你想过没有，为什么没有上帝的世界就会让人悲哀？为什么没有意义的人生就会令人绝望呢？虚无这个真相并不直接导致消极。从虚无到消极，有一个必经的中间环节，那就是一种虚幻的信念：认为在世界的表象背后还存在绝对的本质，并且认为人生必须依靠这个绝对的本质才能找到价值和意义。如果你相信了这种虚幻的信念，那么虚无的世界对你来说就是毁灭性的，你就会感到悲观绝望。这就是消极的虚无主义。但如果你从幻觉中醒来，看到从来就不存在什么绝对的本质或者真理，人生的意义也并不依赖于它，那就没有什么好绝望的。而且，认识到世界本无意义，这恰恰带来了创造的自由。在尼采看来，价值不是现成在哪里等你“发现”，所有的价值都是人主观创造出来的，生命活动的标志就是能够自己确立价值，这是生命本身的力量。所以，尼采认为：面对无意义的世界和无意义的生命，人应该立足于现实，直面无意义的荒谬，以强大的生命本能舞蹈，在生命活动中创造出价值。用尼采的话说，就是“成为你自己”。这样一来，虚无不再会让你沮丧和绝望，反倒会给你最广阔的创造自我意义的空间，虚无让人变成了积极的创造者，这就是积极的虚无主义。<br>那如果我认同尼采所说，将尼采之言奉为圭臬，我是不是又是依赖于尼采的理论而活了呢？尼采在《查拉图斯特如是说》中有一段：”你们说相信扎拉图斯特拉，但扎拉图斯特拉算什么？你们说是我的信徒，但所有的信徒又算得了什么？你们没有探索自己，却发现了我……现在我要你们丢开我去发现自己，只有当你们全部否定我的时候，我才会回到你们身边。“<br>历史上所有的先知都呼吁信徒“听从我，追随我”，而尼采却说，你否定了我才是真正理解了我，才是深刻的追随，我才会回到你们身边。所以，如果你相信尼采，那就不该盲从尼采，因为如果你真的理解了他的思想，就不应该相信任何人包括尼采本人写下的教条，而是去探索自己的生命。<br>人应该自由地探索自己的生命，去找到属于自己的价值，那价值的好坏如何评判，什么是属于自己的价值呢？尼采留下来了很多问题，目前最困扰我的就是价值真空。难道所有的世俗价值都是枷锁，都没有好坏之分，必须要将之全部打破？难道如果我为了自我的价值就要发动二战，把人丢毒气室炼肥皂？人越崇尚自己的价值，便与这个世界走得越远，与世间的人们走得越远，他会越来越与这个世界疏离，走向自己的世界。当看到布林肯在美国国会上被反加沙战争的抗议者打断时的厌烦神色，那是有意无意透露的一种冷漠，他自由地信奉着自己的一套价值，所以他并不会与遥远的加沙人形成共鸣，所以他感受不到别人的痛苦。我不想像那样孤独且冷漠地活着，我想与这个世界产生联系。<br>对于这个价值，我已经找了很久。我从原本的找到人生信仰变成了找到人生的价值，这似乎是一回事，但其实不是。人生信仰是人所有行为的目的，是为了抵抗虚无的绝望。当我开始寻找人生的价值时我就已经不再认为虚无是绝望的了。过去我认为永恒的东西才是有意义的，所以我的绝望是生命不可能永恒，文明也不可能永恒，甚至能量都不可能永恒。世界上没有永恒的东西，但为什么意义一定要附加到一个永恒的存在上呢？为什么一定要永恒的罗兰，不能是瞬间的光景呢？有这个想法的人可能是海子，可能是安娜卡列尼娜，他们往往带着些自毁的倾向，像烟花，绚丽而短暂。但我比较怕死，所以我虽然不相信永恒，但我也不喜欢瞬间。<br>我还是挺留恋这个世界的，我喜欢与这个世界产生联系，那么与世界交流就是我的价值。我喜欢摄影写作，那创作就是我的价值，我喜欢山河湖海，那与自然产生共鸣就是我的价值。甚至，我承认价值的多变，如今我向往的不一定是未来我所向往的，跟随当下的心意走便是。活得义无反顾，活得洒脱自在，把我之前遗落的勇气全部捡起，撑起一个强大的内心世界。<br>
后记<br>
这篇自传前前后后写了一两周，由于不是一气呵成，所以总会有不连贯之感。这次我梳理了我人生的几个重要的大阶段，小学多以叙事，因为我不是所有的事都记得，我想趁此机会将记忆里的一些遥远的星星摘下来，我怕它们哪天真的离我而去了。<br>初高中我多议论，其实大部分事我都记得了，但因为清晰，却没有了儿时那种朦胧的美感。这可能也是一个问题，年龄越大我的记忆应该越清楚，而让我印象深刻的事情却越来越少了。但我至少需要记录一些老师，这些老师的言传身教成为了我生命的一部分，我感谢他们。<br>大学的部分我一开始想写点大学教育的一些矛盾，但越往后写越觉得写一些社会问题于我没有意义，我要写的是我自己的问题，以及我是怎么解决这些问题的。我觉得思考这些事不是闲的没事干，我觉得这些才是大学应该需要做的事情。我不希望当我不知道多少年之后回首往昔，觉得自己白活了。<br>找到为什么活着的理由，找到如何活着的方式，找到那个可以为之而生，为之而死的信念。]]></description><link>culture\教育学\教育自传.html</link><guid isPermaLink="false">Culture/教育学/教育自传.md</guid><pubDate>Sat, 12 Oct 2024 11:11:41 GMT</pubDate></item><item><title><![CDATA[文献综述：当代青年“节能”与“内耗”现象的教育困境]]></title><description><![CDATA[ 
 <br><br>近年来，随着信息化时代的到来，许多学者开始关注当代青年的社会心态和行为模式，尤其是“佛系青年”和“躺平”现象的兴起。这些现象虽然被普遍认为是消极的社会现象，但也有学者提出其背后反映的是青年群体在现代社会中对过度消费主义和社会压力的反思与逃避。本文试图通过整理相关学术观点，探讨这一现象的深层次原因，并结合教育理论分析如何应对这一挑战，尤其是在教育的“行动性”方面的思考。<br><br>在当代社会，随着经济压力、就业压力和社会竞争的加剧，越来越多的青年开始表现出一种“放弃”或“顺其自然”的生活态度。孙桂香在其文章中认为，佛系、躺平等现象本质上是一种解构主义对主流社会观念的反抗，是社会转型期的一种思想反应（孙桂香，2020）。然而，卜建华在对“佛系青年”群体的分析中指出，这种态度更像是一种对社会现实的妥协和逃避，反映出的是青年对生活的无力感和对社会压力的回避（卜建华，2021）。<br>尽管学者普遍将这一现象解读为消极的表现，但也有学者提出，佛系和躺平并非完全的负面现象。李文静认为，这种冷漠症并不是道德层面的冷漠，而是现代青年社交中的冷感，即他们在信息过载和社会压力下产生的社交疲倦（李文静，2021）。这种冷感是“节能”的一种表现，是青年对自我能量的保护性行为。<br><br>“节能”是指个体在社交和行动上极力避免“能量”的消耗，认为与他人交往是对个人能量的浪费。这种行为背后反映的不是人际关系的道德冷漠，而是社交层面的疏离与封闭。个体倾向于减少与他人之间的深度交往，形成了一个孤立的个人主义空间。这种现象的根源在于现代社会中对个体自由和个人空间的过度强调，以及人际关系和社会责任感的缺失（桑内特，2019）。<br>舒茨的社会学观点指出，人与人之间的交往必须满足包容、支配和情感这三种需求，而这些需求的缺失会导致人与人之间的关系变得冷漠（舒茨，1995）。在节能现象中，个体不仅感到缺失感，还往往对自己缺失的东西感到迷茫，无法明确自己的需求和目标。这种冷漠感并非源自对社会的拒绝，而是源自无法在充满社会压力和竞争的环境中找到与他人产生深层联系的途径。<br><br>从教育的角度来看，“节能”现象也与教育体系的困境密切相关。阿伦特认为，教育的核心是培养个体的“行动能力”，即通过与他人的互动参与公共世界的建设，从而实现自我认同和主体性（阿伦特，1958）。然而，现代教育面临的最大问题之一就是将教育局限于生存必然性层面，使得学生的教育变成了为生存和未来的职业竞争而被迫进行的过程，而不是培养自由行动和自主生活的过程（高德胜，2018）。<br>项继发提出，现代教育的困境在于未能有效地“领入世界”，即未能帮助学生真正理解和参与到公共世界的建设中去（项继发，2017）。这使得当代学生缺乏必要的行动能力，无法在社会和文化中找到自己真正的定位。因此，他们对“行动”产生了疏离感，而这种疏离感正是节能现象的社会根源之一。<br><br>为了解决现代教育中的行动性困境，学者们提出了一系列教育改革的建议。章乐指出，要应对教育困境，教育需要回归到行动的层面，即超越生存必然性和物质需求的限制，帮助学生发展自我主体性和公共责任感（章乐，2020）。在这一过程中，教育应当鼓励学生通过实际的行动参与社会实践，培养他们的社会责任感和公共关怀意识。<br>海德格尔的“共在”理论也为教育的“行动性”提供了理论支持。王鑫认为，在教育中应当通过“共在”的实践，让学生在与他人的互动中体验并理解个体与集体、自由与责任之间的关系（王鑫，2019）。这种共在关系不仅能够帮助学生树立正确的社会观和人生观，还能为他们提供行动的动力和方向。<br><br>综上所述，当代青年的“节能”现象不仅反映了他们对现代社会复杂性的逃避，也揭示了教育体系中行动性的缺失。虽然这一现象表面上看似消极，但它实际上揭示了当代教育和社会环境的深层问题：现代教育未能培养学生的行动能力和公共责任感，导致了个体的自我封闭和社会责任的逃避。为此，教育改革应当着重于提升学生的行动能力，鼓励他们通过实际参与社会建设来实现自我认同和社会归属感。通过重视“行动性”的教育，能够帮助青年走出“节能”的困境，重新构建起与他人、社会的深度联系，进而实现个人和社会的共同发展。<br><br>
<br>阿伦特, H. (1958). 《人的境况》. 译林出版社.
<br>高德胜. (2018). 《论教育的行动性》. 教育学报.
<br>李文静. (2021). “当代学生人际交往冷漠症的教育伦理分析及其引导”. 教育研究杂志.
<br>孙桂香. (2020). “躺平的佛系青年——互联网时代结构主义思潮的符号嬉戏”. 社会科学评论.
<br>项继发. (2017). “把儿童‘领入世界’：阿伦特式教育思考”. 教育哲学与社会研究.
<br>卜建华. (2021). “佛系青年群像的社会心态诊断与支持”. 青年研究. 
<br>桑内特, R. (2019). 《公共人的衰落》. 社会学出版社.
<br>舒茨, A. (1995). 《人际交往的三种需求》. 社会学文献. 
<br>王鑫. (2019). “让儿童与世界美好相遇——基于海德格尔‘本源之思’的教育美学诠释”. 教育学报.
]]></description><link>culture\教育学\文献综述：当代青年“节能”与“内耗”现象的教育困境.html</link><guid isPermaLink="false">Culture/教育学/文献综述：当代青年“节能”与“内耗”现象的教育困境.md</guid><pubDate>Wed, 25 Dec 2024 12:45:07 GMT</pubDate></item><item><title><![CDATA[中国教育史]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/教育学" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/教育学</a> 
 <br><a href=".?query=tag:文化\教育学" class="tag" target="_blank" rel="noopener nofollow">#文化/教育学</a><br>
主讲：赵冬冬<br>
手机/微信：15900605289<br>
<br>研究对象：制度史、思想史、活动史
<br><a data-tooltip-position="top" aria-label="Culture/阅读/中国教育史-孙培青" data-href="Culture/阅读/中国教育史-孙培青" href="\culture\阅读\中国教育史-孙培青.html" class="internal-link" target="_self" rel="noopener nofollow">中国教育史-孙培青</a><br><br>
<br>巫山人算起，中国有两百万年的教育史
<br>氏族公社末期产生了文字，文字的产出提出新的教育需要
<br>教育产生的源头在于生产生活和家庭
<br>-教育手段局限于言传身教
<br>男女教育有别，根源在分工
<br><br>
<br>教育目的一致，教育权利平等
<br>以生活经验为教育内容
<br>教育活动在生产生活中进行
<br>教育手段局限于言传身教
<br>男女教育有区别，根源在分工
<br><br>
<br>世袭制的兴起某种程度上让贵族阶级不再重视教育，王权衰落，教育向下普及，士阶级的崛起，私学出现，百家争鸣思想活跃。
<br><br>
<br>政教分离，自由办学
<br>教学与学术研究相结合
<br>没有固定教育场所
<br>学生自由就学，来去自由
<br>多学派开办私学，自由竞争
<br>孔子：君子<br>
孟子：大丈夫<br>
荀子：礼法兼治的贤能之士<br><br><br>
<br>礼、乐、射、御、书、数各代表什么内容？ 礼：礼仪<br>
乐：音乐<br>
射：射箭<br>
御：驾车<br>
书：书法<br>
数：数学	
<br>古代教育为什么强调这些科目？ 古代教育强调这些科目是为了培养全面发展的士大夫，使其具备礼仪、音乐、武艺、书法和数学等方面的技能，符合当时社会的需求和价值观。
<br><br>•	什么是百家争鸣？ 百家争鸣是指战国时期诸子百家争相发表各自学说的现象。<br>
•	墨家的“兼爱”思想内容是什么？ 墨家的“兼爱”思想主张无差别的博爱，即所有人之间应该相互爱护和帮助，不分亲疏远近。<br><br>•	仁爱在儒家道德体系中的地位？ 仁爱是儒家道德的核心，被视为道德的最高境界。<br>
•	孔子如何解释“仁爱”？ 孔子认为仁爱代表人与人之间的相互关爱和尊重，是一种推己及人的道德情感和行为。<br><br>•	《道德经》的主要内容和思想？ 《道德经》主要阐述了道家的基本哲学思想，如“道法自然”、“无为而治”等，强调顺应自然、无为而治的生活态度和治理理念。<br>
•	老子的核心哲学理念是什么？ 老子的核心哲学理念包括“道法自然”、“无为而治”、“上善若水”等，强调顺应自然规律、以无为的方式进行治理和生活。<br><br>•	科举制度的起源和发展过程？ 科举制度起源于隋朝末期，在唐朝正式确立并发展，通过考试选拔官员，逐步取代了世袭制。<br>
•	科举制度对中国社会的影响？ 科举制度提供了公平竞争的机会，打破了世袭制，促进了社会流动，提升了教育在社会中的地位，对中国历史和社会产生了深远影响。<br><br>•	清代官学体系的特点？ 清代官学体系包括中央和地方各级官学，设有专门的教育行政机构，注重儒家经典的教育。<br>
•	书院的作用和影响？ 书院作为清代重要的教育机构，不仅承担了高级教育和学术研究的功能，还培养了大量人才，对中国古代教育的发展有重要影响。<br><br>•	蔡元培的教育理念是什么？ 蔡元培的教育理念强调思想自由和兼容并包，主张“大学者，研究高深学问者也”，注重学术自由和独立。<br>
•	蔡元培在北大的改革措施？ 蔡元培在北大推行了一系列改革措施，如废除旧有的八股文考试制度，引入现代学科，鼓励自由讨论和学术研究。<br><br>•	孔子的教育思想对科举制度的影响？ 孔子的教育思想强调德行和才能的培养，对唐朝科举制度的建立和发展有重要影响。<br>
•	科举制度如何体现儒家思想？ 科举制度通过考试选拔人才，体现了儒家的公平、公正和择贤用能的思想，促进了儒家文化在社会中的传播和发展。<br><br>•	陶行知的“生活即教育”理念？ 陶行知提倡“生活即教育”，认为教育应与生活实际结合，强调动手实践和社会服务。<br>
•	晓庄学院的办学特色和影响？ 晓庄学院注重实践教育和社会服务，培养了大量实践能力强的学生，对中国现代教育改革有重要影响。<br><br>•	《新教育大纲》的主要内容？ 《新教育大纲》提倡马克思主义教育思想，强调教育与社会变革的关系，主张通过教育推动社会进步和变革。<br>
•	杨贤江的教育思想和影响？ 杨贤江作为马克思主义教育家，主张教育应服务于无产阶级革命和社会主义建设，对中国现代教育理论的发展产生了深远影响。<br><br>•	陈鹤琴的“活教育”理论的核心内容？ 陈鹤琴的“活教育”理论强调教育要与儿童的生活实际相结合，注重儿童的全面发展，包括身体、智力、品德等方面。<br>
•	“活教育”理论在实践中的应用？ “活教育”理论在实践中通过游戏、动手操作、社会实践等方式进行教育，取得了显著效果，推动了中国幼儿教育的发展。<br><br>•	定县实验的内容和成果？ 定县实验由晏阳初在河北定县开展，主要内容包括农村教育、社会改革、卫生保健等，取得了显著成果，改善了当地人民的生活水平。<br>
•	晏阳初的教育改革思想？ 晏阳初的教育改革思想强调教育应服务于农村发展和社会进步，主张通过教育推动社会的全面进步和发展。<br><br>•	名词解释：西周教育制度的高度概括，封建奴隶制的特征，由贵族把握，民间没有学术活动，“官师不分”“政教合一”，礼不下庶人，官学合一<br>
•	什么是“学在官府”？ “学在官府”是对西周教育制度的概括，强调教育由贵族控制，民间缺乏学术活动，教育与政治、礼仪紧密结合。<br>
•	西周教育制度的特点？ 西周教育制度的特点包括“官师不分”“政教合一”，礼不下庶人，教育由贵族掌握，平民很少有受教育的机会。<br><br>有教育不分类，孔子私学教育对象，不分门第血缘出生，都有接受教育的权利机会不分等级，事实上扩大了受教育者的范围，前瞻性，打破奴隶主受教育垄断<br>
•	孔子的“有教无类”思想的内容？ 孔子的“有教无类”思想主张教育不分贵贱、血缘，每个人都有接受教育的权利。<br>
•	“有教无类”对教育普及的意义？ “有教无类”打破了奴隶主对教育的垄断，扩大了教育的普及范围，使更多人有机会接受教育。<br><br>明德亲民止于至善，格物致知、诚意正心修身齐家治国平天下朱熹<br>
•	朱熹的三纲领八条目的具体内容？ 三纲领：明德、亲民、止于至善<br>
八条目：格物、致知、诚意、正心、修身、齐家、治国、平天下<br>
•	三纲领八条目在儒家思想中的地位？ 三纲领八条目构成了儒家修身治国的完整体系，是儒家思想的重要组成部分，强调个人修养和社会责任。<br><br>•	董仲舒的三纲五常内容？ 三纲：君为臣纲、父为子纲、夫为妻纲<br>
五常：仁、义、礼、智、信<br>
•	三纲五常对中国传统伦理的影响？ 三纲五常构成了儒家伦理的基本框架，对中国传统伦理和社会秩序有深远影响，强调家庭和社会的等级关系和道德规范。<br><br>•	什么是“教学相长”？ “教学相长”指的是教师和学生在教学过程中共同进步，教和学相互促进。<br>
•	“教学相长”在教育实践中的体现？ 在教育实践中，教师通过教学不断提高自己的学术水平，学生通过学习不断深化对知识的理解，两者相辅相成，共同进步。<br><br>立志克己、言行一致、中庸内省改过自新，克己复礼<br>
•	孔子的教育思想具体内容？ 孔子的教育思想包括立志克己、言行一致、中庸内省、改过自新和克己复礼，旨在培养全面发展的人才。<br>
•	孔子教育思想对后世的影响？ 孔子的教育思想对中国传统文化和教育体系产生了深远影响，成为后世教育的重要指导思想。<br><br>•	秦朝焚书坑儒政策的内容和影响？ 秦朝焚书坑儒政策包括焚毁儒家经典书籍和坑杀儒生，旨在加强思想控制，巩固统治，导致文化的巨大损失。<br>
•	书同文行同轮的意义？ 书同文行同轮指统一文字和度量衡，有助于文化和行政的统一，推动了国家的中央集权和社会发展。<br><br>•	朱熹的读书方法具体内容？ 朱熹的读书方法强调循序渐进，逐步深入理解和掌握知识，提倡“读书要先立志，然后有恒，循序渐进”。<br>
•	朱子读书法对学习的影响？ 朱子读书法对后世学子的学习方法产生了深远影响，强调持之以恒和循序渐进的重要性。<br><br>•	洋务运动的办学内容和目的？ 洋务运动通过兴办新式学校，学习西方的科学技术，以期实现自强求富，增强国家实力。<br>
•	洋务运动的进步性和局限性？ 洋务运动在引进西方技术、推动现代化方面有一定进步，但由于封建地主阶级的保守性，改革的进步性有限，未能从根本上改变社会制度。<br><br>•	五四运动的核心思想？ 五四运动提倡开民智，推动思想解放，强调“德先生”（民主）和“赛先生”（科学），倡导民主和科学精神。<br>
•	德先生和赛先生的内容和影响？ 德先生代表民主思想，赛先生代表科学精神，两者共同推动了中国社会的现代化进程，对中国近代思想文化产生了深远影响。<br><br>未直接提出，中国传统文人的想法，学得好当官，当官一定要学好，反对不学为官的世袭制，贤人治邦，功利化思想局限，突出了教育的政治思想或略了其他方面的功能，以名利为诱饵，形成两耳不闻窗外事一心只读圣贤书的局限性，创新性的狭隘<br>
•	“学而优则仕”的思想内容？ “学而优则仕”指的是通过学习提高才能，以便获得仕途机会，强调学术和政治的紧密联系。<br>
•	“学而优则仕”对教育和政治的影响？ “学而优则仕”推动了教育在社会中的重要性，但也带来了功利化的倾向，使得教育过于注重仕途，忽略了其他方面的发展。]]></description><link>culture\教育学\中国教育史.html</link><guid isPermaLink="false">Culture/教育学/中国教育史.md</guid><pubDate>Mon, 02 Dec 2024 14:17:35 GMT</pubDate></item><item><title><![CDATA[2024-10-19]]></title><description><![CDATA[ 
 <br>
And let each day be a loss to us on which we did not dance once! And let each truth be false to us which was not greeted by one laugh!<br>
每一个不曾起舞的日子,都是对生命的辜负。                                                       ——尼采《查理斯图拉如是说》
<br>很早以前就有写日记的想法，一直没试试。写日记是在给自己的日子留痕，时间过去便过去了，但记忆无法把所有琐碎又有意思的事情留下，日记便有了它存在的意义。<br>
Se:今天明明说要去红庙吃泡芙烤鸭的。<br>
Ni:没办法嘛，今天天气实在太糟糕了，刚刚想洗澡出门，拿个浴巾风直接把卫生间里的沐浴液吹掉了。而且还下着雨。<img alt="{124A07F3-9E1D-4545-8DA8-630EDDE1E44B}.png" src="\lib\media\{124a07f3-9e1d-4545-8da8-630edde1e44b}.png"><br>
Fi:明天去吧，反正没约人一个人就是自由。<br>
Ni:今天是你的生日，21岁的生日。你在20岁生日时立志要培养跑步和看书的习惯。如今21岁，有什么具体的事是你一直想做的？<br>
Fi:我想写点日记，哪怕每天就几行，几个字也好。<br>
Ni:嗯，这是个好事，你能做到。那我们安排下具体每天写点什么，天气，做的事，遇到的人等等都可以。我们要不要列个表，然后每天去填呢？<br>
Fi:这不就变成任务了吗？不要，每天想到什么就写什么，比如现在我想跟你——我的另一个人格聊天，那我就聊天好了，不用想太多，像理想国那样。<br>
Ni:你说的对，我是你内心的Ni，你是Fi，我们要控制好Te，让它不要让我们变得太世俗。<br>
Te:但你们都无法逃避，接下来的一年必然要靠我，你们想要去读研吗？<br>
Fi:我只知道我不想直接就业，我还想有点自由的生活，我想要的更像是大学老师那种生活，没有固定的工作场所，每天做着一样的事。<br>
Te:你呢？Ni<br>
Ni:就当下社会，我觉得迟早要对大学老师开刀，至少是对学阀开刀，学术圈乱象太多了，本科生教育断层，之后的教学可能就不会有现在那么水了，加上AI，教学任务如果大量缩水，那么这个行业只会更卷。况且你也不是为了当什么科学家，你只是想要足够的时间给你写写书，表达表达自己，你不是真的像做科研。最近天天做GCN_For_Audio，你不是都有点受不了了吗，拉着Se就想往外面跑，但是很遗憾今天天气太差了些，下午又有讲座，我们推迟到明天行吗，宝？<br>
Fi:看在你叫我宝的份上，原谅你了。可是你说还有什么办法吗？你又不敢彻底放开，找个贫困点的景观城市，租个小房子彻底躺平。我一直想去大理躺平，你又非在你你那世俗的欲望带着Te，每天累得不行。当大学老师是你最好的选择了，不然你还想找个大厂赚个几年就跑路，且不说你能不能赚到，即使赚到了，你那时还忍心舍弃高薪吗？你就是在意别人的眼光，怕别人提你你来的时候觉得你是个losser。<br>
Ni:是的。你说的没错，但是你没办无视这些，只要你在这个社会中，只要你还与人联系。你向往的那种生活真的有人陪你吗？你不会被孤独折磨吗？你所鄙视的人际交往就真如你觉得那样不堪吗？在世俗中获得肯定满足感就比你在大理做文艺青年低吗？不见得吧。西西弗斯你也看了，加缪你也看了，萨特你也看了，每一个不曾起舞的日子都是对生命的辜负，你要定义什么是起舞的日子。我觉得如今我充实我自己也是一种起舞，也是一种首推巨石。而你，我的朋友，你一直不敢真正地踏出那一步是因为你害怕吧，你害怕你的决定是错误的，你之所以会有这种害怕是你根本没有体验过那种生活，你不知道它的真实样貌，它只存在于你的臆想中，你从未实践，又怎么知道那是否是你想要的。而我，我一直都在实践，我推动你跑步，推动你看书，推动你做科研，推动你写作，如今，你起码知道这几件事有哪些是你真正喜欢的。做你喜欢的事，追逐你想要的东西，这本身就是一种起舞，不一定非要那么特立独行。<br>
Fi:你想想，你产生这些实践的原动力在哪儿，你为什么买相机去拍照？你为什么想去跑步？你为什么看书？直视你的内心，是不是出奇地一致，都是因为一个人，你想要变成更好的自己。所有的行为都是你的情感左右，你的情感才是你的原动力，我一直没有踏出那一步是因为我一直没找到那个人，那个有足够的勇气浪迹天涯的人。<br>
Te:别说了，说说怎么安排读研吧。考，保两条路都要准备。当下最重要的是先把论文的新思路跑通，开始着手写论文了。还需要重新整理代码，到kaggle上跑通。尽量在这个月结束。十一月份还有操作系统的期中考试，课程进度要加快了。操作系统和计算机组成原理需要继续学。然后作业也别忘了，今天的作业需要完成明天才能玩得开心，不然deadline让人很烦玩得不开心的。你们看得太远，会容易迷失。等会去吃个饭，休息一下，然后下午开始工作，今天上午这么一聊已经有点久了。<br>
Ni&amp;Fi:遵命老大。<br>
Fi:但有些事我想说下，我今天有进步，我对爸妈表达感谢了。昨天晚上还有人祝我生日快乐，她不是那种QQ自动提示的，是真的自己来祝我生日快乐的。我很开心。<img alt="{01C4B4C7-5831-4DDA-9242-B638AFD72E49}.png" src="\lib\media\{01c4b4c7-5831-4dda-9242-b638afd72e49}.png">]]></description><link>culture\日记\2024-10-19.html</link><guid isPermaLink="false">Culture/日记/2024-10-19.md</guid><pubDate>Sun, 20 Oct 2024 08:05:13 GMT</pubDate><enclosure url="lib\media\{124a07f3-9e1d-4545-8da8-630edde1e44b}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{124a07f3-9e1d-4545-8da8-630edde1e44b}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-20]]></title><description><![CDATA[ 
 <br>今天天气是个大晴天，天气预报日常谎报。因为昨天没能去成红庙，今天决定自己一个人出去玩。<br>
早上差点又打消了这个念头，但其实今天我感觉真的很放松，如果今天早上又觉得算了我不会有以下这些经历。<br>
一大早，没吃饭，留着肚子到红庙吃。在达记斩了1/4只鸭子，去一味米线(有点怀念火影里的一乐拉面了)吃了碗番茄鱼片米线，这个烤鸭可能是早上烤的，已经凉了，味道一般，皮比较好吃，米线也一般，但卖相很好看，可能我本来就不喜欢吃米线。但有个窗边的位置很有感觉，我在那边呆了挺久。<br>
<img alt="{73E94D00-5ABA-4A73-AC17-4FC2AC3F5945}.png" src="\lib\media\{73e94d00-5aba-4a73-ac17-4fc2ac3f5945}.png"><br>
<img alt="{BACFED63-9722-44A1-AA77-13230EED9405}.png" src="\lib\media\{bacfed63-9722-44a1-aa77-13230eed9405}.png"><br>
然后去了元宝泡芙，听后面排队的说有美团有劵，可以盲盒抽口味。运气不错抽到了提拉米苏口味的，这口味血贵，8个要35，我花了20买的劵，变相省了15，味道不错。<br>
<img alt="{917A55C5-07CD-407A-B5B5-A8B40789598E}.png" src="\lib\media\{917a55c5-07cd-407a-b5b5-a8b40789598e}.png"><br>
然后我就漫无目的地走啊走啊，走到了南京图书馆，路上路过了国民政府的国民大会堂，总统府，江宁织造博物馆，那条路应该是国民政府时期的政治中心吧。<br>
<img alt="{6CA917EE-AC5B-49A8-B2EE-14D29F34C049}.png" src="\lib\media\{6ca917ee-ac5b-49a8-b2ee-14d29f34c049}.png"><br>
<img alt="{BA86E1AE-1F9C-43A1-BFB5-09CBAF7F8E42}.png" src="\lib\media\{ba86e1ae-1f9c-43a1-bfb5-09cbaf7f8e42}.png"><br>
<img alt="{658FEE50-1ACF-4767-A2C8-F608ECFFE2B5}.png" src="\lib\media\{658fee50-1acf-4767-a2c8-f608ecffe2b5}.png"><br>
<img alt="{6181A395-41BB-415D-B44F-D2108CF477E7}.png" src="\lib\media\{6181a395-41bb-415d-b44f-d2108cf477e7}.png"><br>
在图书馆坐了会儿感觉口渴，在美团上点了一杯奶茶，店名叫拾叁茶，味道就跟霸王茶姬的栀子飘飘差不多，但是奶油没那个浓。姑姑们请我的时候我没好意思点，自己出来就随意了，其实我一直挺好奇这种奶茶上加一堆奶油的好不好喝，其实挺一般。我坐在店里喝着奶茶，看店员忙碌、麻木，就一个人在做奶茶。<br>
<img alt="{8DE7C39C-B44D-4A82-A089-AF75824CE5B7}.png" src="\lib\media\{8de7c39c-b44d-4a82-a089-af75824ce5b7}.png"><br>
那家奶茶店在1912，我从奶茶店出来准备回学校了，在一个小巷子里看到一位教学生的美术老师，应该在教学生国画工笔。这时候一个人旅游的好处就体现出来了，我想在那儿待多久就待多久，我在那儿跟着一群孩子上了节美术课。非常感谢这位老师，教得很好，教构图，教调色，教手法。<br>
<img alt="{D1DF6361-3113-42D3-A415-514D8A1AE886}.png" src="\lib\media\{d1df6361-3113-42d3-a415-514d8a1ae886}.png"><br>
回来的地铁站口看到了一位老人，在乞讨，往常我就离开了，今天我走过之后又回来了，我给他了5块。即使说有那种装惨骗钱的，我认为那种不多，即使很多，只要100个中有1个是真实需要这点钱的，那我做的事就有意义。我改变了些。]]></description><link>culture\日记\2024-10-20.html</link><guid isPermaLink="false">Culture/日记/2024-10-20.md</guid><pubDate>Sun, 20 Oct 2024 08:28:24 GMT</pubDate><enclosure url="lib\media\{73e94d00-5aba-4a73-ac17-4fc2ac3f5945}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{73e94d00-5aba-4a73-ac17-4fc2ac3f5945}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-26]]></title><description><![CDATA[ 
 <br>有一个星期没有写了，这习惯怎么刚开始就夭折了呢？今天下雨，这两天都下雨，周五是运动会多放了一天。已经玩了两天了，Apex还是没上铂金2，炉石上了酒馆5000分。今天其实工作了挺长时间，把德育原理的汇报写了，PPT做了。<br>
明天需要继续学一些课内的东西了，推进计算机组成原理的进度到cache那里。<br>
操作系统我已经把进度赶上来了，然后接下来跟班上课，课后再跟王道学一遍当巩固。<br>
距离ICME截稿还有一个半月，但是老师的那些想法都没有使结果变得更好，该怎么办呢？我觉得需要找一个新的GNN代码了，熟悉代码的过程本来就是一种提升。<br>
买了三菱um-100的笔，不知道是不是和juice up 一样不好用。等笔到了试试吧。我还买了个台灯，是一个夹子灯，这样宿舍学习的必备设施就剩下笔了。书的话就用新航道的就可以了。<br>
单词从明天开始背。十二月份又要考六级了，要开始多读多写英文了，东蒙卡英语70分。研究生要刷刷绩点，需要拿钱，东蒙的竞争应该相对没那么激烈。日常跟海螺多用英文说说话，提高自己的英语口语水平。<br>
打游戏可能已经到瓶颈了，昨晚吹吹口琴，弹弹吉他也似乎还是不熟。我需要一个肯定，无论哪种形式的肯定，这是必须的。明天的汇报好好讲。<br>
可是我吉他弹了一会儿就明显更好了，这不是一种进步吗，炉石上了5000，十月份代码github提交量应该是我之前最多的。我在变得更好，干嘛内耗呢？<br>
邪不压正里，姜文讲正经人谁写日记啊，日记上记得不是真心话。如果日记上是真心话，那其实每个人都应该写下，现实中还有什么地方是可以随便讲真心话的？]]></description><link>culture\日记\2024-10-26.html</link><guid isPermaLink="false">Culture/日记/2024-10-26.md</guid><pubDate>Sun, 27 Oct 2024 02:22:25 GMT</pubDate></item><item><title><![CDATA[2024-11-10]]></title><description><![CDATA[ 
 <br>今天继续念叨一会儿吧，这一段时间又了解了几所大学，作业实验好多，感觉快写不完了。<br>
这周周二去了明故宫遗址，真是遗址除了个城门什么都没了。了解了一段历史，南航明故宫校区原本就是明故宫，日军来了后把那边造成了机场，然后后来几经转折变成了南京航空工业专科学校，后来才成了如今的南航。<br>
听说国防七子的学生是无法在美国得到绿卡的，当然这也不是我要考虑的事。<br>
下周周末去一趟上海，其实我对法国留学不是那么向往，但是我想出去玩。]]></description><link>culture\日记\2024-11-10.html</link><guid isPermaLink="false">Culture/日记/2024-11-10.md</guid><pubDate>Sun, 10 Nov 2024 00:26:49 GMT</pubDate></item><item><title><![CDATA[关于大学生的孤独感]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想/个人思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想/个人思想</a> 
 <br><a href=".?query=tag:文化\思想\个人思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想/个人思想</a><br><a rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/675537267" target="_blank">https://zhuanlan.zhihu.com/p/675537267</a><br>最近了解到自己所在的大学出现了自杀案件。这并不少见，基本每个大学或多或少都有。我们可以理解高中生自杀的原因，或是原生家庭的原因或是因为学业压力，再或者是同学的排挤。而这些到了大学理应消散，原生家庭已经远在天边，学业压力小了不止一点，同学排挤可以申请换宿。<br>我过去认为这种自杀的大学生大概率是家里压力很大的穷学生，他们身上背着一家人阶级跃迁的希望，他们不堪重负，又前途无望，选择在考上大学这个时间点自杀。但是我发现并非如此，并不是所有的自杀时间点都是考上大学的那个新学期，并且如果仅仅是因为不堪重负为何在大学自杀呢？按道理完全可以在家里自杀来表示对家庭的反抗。<br>另外一个观察，大学里有两批人，一种是每天发朋友圈发空间的现充，一种是窝在宿舍天天网上冲浪打打游戏的死宅。在我们的价值观里，总是认为现充是令人羡慕的，而死宅是对大学生活的浪费，他们虚度人生，大学四年一场恋爱都没谈过。<br>在此，我想为自杀的大学生和窝在宿舍的死宅进行辩护。<br>我觉得这两者出现的本质原因在于从初高中到大学社交环境的剧烈改变。我们可以回想，在初高中的社交环境，它大多数是将固定的几十个人放到一个朝夕相处的教室里，他们每天同吃同住，一起学习同样的内容，上同样的课，前后左右的同学更是抬头不见低头见。这样的社交环境中，每个人都一定有充分的社交机会的。几十个同学中你至少全部认识，并且熟悉里你最近的几个同学，也就是说你的社交是有基础的保障的，当然被孤立的学生可能没有。<br>我时常听父辈回忆，说是初高中的同学才是真正的友谊，后面的朋友关系都很浅。是因为初高中同学就纯真，关系就铁吗？我想是因为你们一起呆的时间足够的长，你们的社交关系才更紧密。而在大学，后面工作时，你很难找到与你朝夕相处的人了。即使是同寝室的人，课不一样，所在课题组不一样，社交圈子不一样是常有的事。<br>大学里的人虽然看起来很多，但是并不提供社交机会。虽然你也有你所在的班级，但是你们上完课就立刻离开，虽然有班级活动，但基本是看几个班委在活动，虽然也有社团，但是几百人的社团基本只是几个人的小圈子。这样的例子还有很多，人们就像运行在自己特定轨道的行星，看着似乎绕着同一个恒星公转，却很少有相遇的可能。这些给我们带来的直观感受就是，大学似乎比初高中更加孤独。<br>在宿舍打游戏网上冲浪的死宅和现充只是用了不同的手段去克服孤独感。我们如今可以通过很多方式去代替社交，如看书，网上和人对线，打游戏等等，但这并不能彻底替代社交。这个视频讲解了人的社交与孤独感。(【超深度】和哈佛脑科学博后聊聊孤独与社交 ft. 刘鼎｜TIANYU2FM - E088_哔哩哔哩_bilibili)。<br>初高中那种饱和的社交环境让你没有注意到自己的社交需求，而到了大学的社交环境，社交机会少了，他们自然而然的感到孤独。而社交需求与吃饭喝水一样是人的基本需求，就像不吃饭会饿一样，不社交就会孤独。而大学的环境很难提供给你被动社交的环境，你不主动找别人，不主动混入圈子，别人不会主动找你。而这对从小就没有培养主动社交的学生是十分不友好的，没有学会吃饭的孩子就会挨饿。<br>这种孤独催生出了什么呢？我认为这种孤独会导致抑郁，自我否定，病态地渴望爱情，缺乏安全感，容易走极端。我觉得自己结束掉自己的生命这件事并不会是一件事就能决定的，它必然是日积月累的悲伤或者孤独，在生物角度上看，是一系列激素导致了大脑产生了自我了结的想法。而过度的孤独我觉得就是其中很大的一个原因。现代抑郁症已经从病理上证实，抑郁症患者体内激素水平与常人有差异。但是这里涉及到一个因果的问题，究竟是先出现的激素问题导致人的抑郁，还是先被抑郁的思想侵袭，无法抵挡那种巨大的孤独感，而感到强烈的悲伤与厌世，这种精神的错乱导致了激素的不平衡。我更倾向于后者。<br>人类在被自然赋予了可以思考的能力后，也背上了注定需要以一生面对虚无和孤独的诅咒。这种诅咒在正是在大学这个开始思考生命意义的人生阶段开始浮现，而大学的客观环境与心之壁的存在注定了他们无法真正彻底的倾诉，从而对这个孤独的世界彻底绝望，走向自毁的道路。](&lt;最近了解到自己所在的大学出现了自杀案件。这并不少见，基本每个大学或多或少都有。我们可以很轻易地理解高中生自杀的原因，或是原生家庭的原因或是因为学业压力，再或者是同学的排挤。而这些到了大学理应消散，原生家庭已经远在天边，学业压力小了不止一点，同学排挤可以申请换宿。<br>
我过去认为这种自杀的大学生大概率是家里压力很大的穷学生，他们身上背着一家人阶级跃迁的希望，他们不堪重负，又前途无望，选择在考上大学这个时间点自杀。但是我发现并非如此，并不是所有的自杀时间点都是考上大学的那个新学期，并且如果仅仅是因为不堪重负为何在大学自杀呢？按道理完全可以在家里自杀来表示对家庭的反抗。<br>
此外，我还感觉大学里只有两批人，一种是每天发朋友圈发空间的现充，一种是窝在宿舍天天网上冲浪打打游戏的死宅。在我们的价值观里，总是认为现充是令人羡慕的，而死宅是对大学生活的浪费，他们虚度人生，甚至可能大学四年一场恋爱都没谈过。<br>
在此，我想为自杀的大学生和窝在宿舍的死宅进行辩护。<br>
我觉得这两者出现的本质原因在于从初高中到大学社交环境的剧烈改变。我们可以回想，在初高中的社交环境，它大多数是将固定的几十个人放到一个朝夕相处的教室里，他们每天同吃同住，一起学习同样的内容，上同样的课，前后左右的同学更是抬头不见低头见。这样的社交环境中，每个人都一定有充分的社交机会的。几十个同学中你至少全部认识，并且熟悉里你最近的几个同学，也就是说你的社交是有基础的保障的，当然被孤立的学生可能没有。<br>
我时常听父辈回忆，说是初高中的同学才是真正的友谊，后面的朋友关系都很浅。是因为初高中同学就纯真，关系就铁吗？我想是因为你们一起呆的时间足够的长，你们的社交关系才更紧密。而在大学，后面工作时，你很难找到与你朝夕相处的人了。即使是同寝室的人，课不一样，所在课题组不一样，社交圈子不一样是常有的事。<br>
而我们反观大学的社交环境。这里的人们虽然看起来很多，但是并不提供社交机会。虽然你也有你所在的班级，但是你们上完课就立刻离开，虽然有班级活动，但基本是看几个班委在活动，虽然也有社团，但是几百人的社团基本只是几个人的小圈子。这样的例子还有很多，人们就像运行在自己特定轨道的行星，看着似乎绕着同一个恒星公转，却很少有可能相遇。给我们的直观感受就是，大学似乎比初高中更加孤独。<br>
初高中那种饱和的社交环境让你没有注意到自己的社交需求，而到了大学的社交环境，社交机会少了，他们自然而然的感到孤独。而社交需求与吃饭喝水一样是人的基本需求，就像不吃饭会饿一样，不社交就会孤独。而大学的环境很难提供给你被动社交的环境，你不主动找别人，不主动混入圈子，别人不会主动找你。而这对从小就没有培养主动社交的学生是十分不友好的，就像没有学会吃饭的孩子就会挨饿。<br>
这种孤独催生出了什么呢？我认为这种孤独会导致抑郁，自我否定，甚至病态地渴望爱情，且缺乏安全感，容易走极端。我觉得自己结束掉自己的生命这件事并不会是一件事就能决定的，它必然是日积月累的悲伤或者孤独，在生物角度上看，是一系列激素导致了大脑产生了自我了结的想法。而过度的孤独我觉得就是其中很大的一个原因。<br>
而在宿舍打游戏网上冲浪的死宅和现充只是使用了不同的手段去克服孤独感。我们如今可以通过很多方式去代替社交，如看书，网上和人对线，打游戏等等，但这并不能彻底替代社交。这个视频讲解了人的社交与孤独感。<a data-href="孤独与社交" href="\culture\思想\孤独与社交.html" class="internal-link" target="_self" rel="noopener nofollow">孤独与社交</a>(<a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1Yg4y1y72n/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">https://www.bilibili.com/video/BV1Yg4y1y72n/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea</a>)。那么现充是否就是高枕无忧，不会被孤独困扰了呢？我觉得不会，一个现充喜欢发空间的目的有两个，一个是立人设，一个是告诉别人也告诉自己，自己一点也不孤独，自己是在群体中的。正因为社交在大学是奢侈的，是稀有的，我们才会喜欢将它们装裱起来，而立人设的本质也是为了社交。&gt;)]]></description><link>culture\思想\自我审视\关于大学生的孤独感.html</link><guid isPermaLink="false">Culture/思想/自我审视/关于大学生的孤独感.md</guid><pubDate>Sun, 19 May 2024 01:36:40 GMT</pubDate></item><item><title><![CDATA[关于考试的方法论]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想/个人思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想/个人思想</a> 
 <br><a href=".?query=tag:文化\思想\个人思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想/个人思想</a><br>
这么多年应试教育，我大概对考试这件事有了一个比较流程化的方法论。这一套工作流有几个部分，分别是学习，练习，复习与考试。<br>
我们可以把考试看做一场在黑暗中抵达目的地的游戏。知识点的学习可以说就像点亮远处的灯塔。]]></description><link>culture\思想\自我审视\关于考试的方法论.html</link><guid isPermaLink="false">Culture/思想/自我审视/关于考试的方法论.md</guid><pubDate>Sun, 19 May 2024 01:33:26 GMT</pubDate></item><item><title><![CDATA[关于自我的思考]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想/个人思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想/个人思想</a> 
 <br><a href=".?query=tag:文化\思想\个人思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想/个人思想</a><br>
我将在下面对我自己进行剖析，我的缺点主要有三个：<br>
<br>不善于主动社交
<br>缺乏内源性动力，遇到问题容易放弃
<br>优柔寡断<br>
这三个问题从小到大一直困扰着我。
]]></description><link>culture\思想\自我审视\关于自我的思考.html</link><guid isPermaLink="false">Culture/思想/自我审视/关于自我的思考.md</guid><pubDate>Tue, 09 Jan 2024 02:27:47 GMT</pubDate></item><item><title><![CDATA[小说中的pov视角]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想/个人思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想/个人思想</a> 
 <br><a href=".?query=tag:文化\思想\个人思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想/个人思想</a>]]></description><link>culture\思想\自我审视\小说中的pov视角.html</link><guid isPermaLink="false">Culture/思想/自我审视/小说中的pov视角.md</guid><pubDate>Tue, 09 Jan 2024 02:27:50 GMT</pubDate></item><item><title><![CDATA[自我审视介绍]]></title><description><![CDATA[ 
 <br>今天是2024-5-19，我在两个星期前遇到了我大学的第二次精神危机，昨天我又一次出现了这种苗头，我想我需要一些改变，由此我开了这次自我审视，我以后会在这个文件夹下写一些思考，一些诗情，一些感动。]]></description><link>culture\思想\自我审视\自我审视介绍.html</link><guid isPermaLink="false">Culture/思想/自我审视/自我审视介绍.md</guid><pubDate>Sun, 19 May 2024 01:37:47 GMT</pubDate></item><item><title><![CDATA[多劳多得的数量关系被模糊]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想</a> 
 <br><a href=".?query=tag:文化\思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想</a><br>
<a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1c94y177XC/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1c94y177XC/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">“多劳多得”的人造骗局与共产主义社会的初步设想||《德意志意识形态》逐句详解 P8_哔哩哔哩_bilibili</a>]]></description><link>culture\思想\多劳多得的数量关系被模糊.html</link><guid isPermaLink="false">Culture/思想/多劳多得的数量关系被模糊.md</guid><pubDate>Sat, 30 Dec 2023 07:09:06 GMT</pubDate></item><item><title><![CDATA[俄罗斯历史]]></title><description><![CDATA[ 
 <br>主讲：李冠群<br><br>
<br>列宁所领导的布尔什维克并不认为十月革命是必然的。
<br>列宁接受了德国人的支援。他们期望一战失败，以证明沙俄体制的腐朽。
<br>在生产力不足的时候建立社会主义就是乌托邦思想。
<br>鲁登道夫与列宁和希特勒都有关系。鲁登道夫是当时攻打俄国的指挥官。同时架空德国总指挥官，是当时实际上的德国总指挥。希特勒曾经崇拜列宁。
<br>沙俄跟德国打仗，但内部各地兴起自治，形成各种苏维埃，即委员会。这种自治演变成打土豪分田地，士兵丧失斗志，前线溃散。
<br>列宁说俄国是当时最自由的国家。
<br>布尔什维克类似汪精卫，主张抗战必败，抗战必亡。布尔什维克承诺上台停止战争。十月革命打响，布尔什维克围攻克里姆林宫，克伦斯基逃跑。
<br>布尔什维克没有兵权，只能挖战壕。列宁强硬求和，签订耻辱条约。
<br>十月革命后，大清洗。1917年成立最早的集中营和劳改营，本质上是生产力不足，布尔什维克未能完成上台前的政治承诺，以内部有捣乱分子为由，进行大清洗转移矛盾。
<br>战前苏俄人口约两亿，进入劳改营和集中营的就有两千万。
<br>推荐电影契卡。
<br>]]></description><link>culture\思想\俄罗斯历史.html</link><guid isPermaLink="false">Culture/思想/俄罗斯历史.md</guid><pubDate>Wed, 06 Mar 2024 05:54:03 GMT</pubDate></item><item><title><![CDATA[房产是期权]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想</a> 
 <br><a href=".?query=tag:文化\思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想</a><br>
房产不是商品，更像是以城市为企业的期权。<br>
<a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1uj411W7kV/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1uj411W7kV/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">不要再拿供需关系看经济，不好使了_哔哩哔哩_bilibili</a>]]></description><link>culture\思想\房产是期权.html</link><guid isPermaLink="false">Culture/思想/房产是期权.md</guid><pubDate>Sun, 24 Dec 2023 01:58:59 GMT</pubDate></item><item><title><![CDATA[高等教育改革]]></title><description><![CDATA[ 
 <br>昨天讲完其实感觉很多点还是没说透。现在研究生据我了解]]></description><link>culture\思想\高等教育改革.html</link><guid isPermaLink="false">Culture/思想/高等教育改革.md</guid><pubDate>Wed, 13 Nov 2024 04:52:49 GMT</pubDate></item><item><title><![CDATA[孤独与社交]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想</a> 
 <br><a href=".?query=tag:文化\思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想</a><br>
<a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1Yg4y1y72n/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1Yg4y1y72n/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">【超深度】和哈佛脑科学博后聊聊孤独与社交 ft. 刘鼎｜TIANYU2FM - E088_哔哩哔哩_bilibili</a>]]></description><link>culture\思想\孤独与社交.html</link><guid isPermaLink="false">Culture/思想/孤独与社交.md</guid><pubDate>Sun, 24 Dec 2023 01:58:53 GMT</pubDate></item><item><title><![CDATA[关于电影]]></title><description><![CDATA[ 
 <br>电影作为一种艺术形式，是与小说，绘画有本质的不同的。<br>
我们应该都听说过或者或多或少感受过这样一个理论，小说擅长描写动，而绘画或者摄影擅长描写静。小说可以很容易地将一件事情的起因经过结尾表达出来，而图片形式的绘画和摄影则不行。但绘画和摄影能将一瞬间的画面中所有的信息保留，这是小说这种以文字为载体的艺术形式使用再繁杂的语言也无法描述清楚的。所以文字形式天然擅长于动，图片形式天然擅长于静。<br>
我们思考电影呢？电影是连续的图片，它有这两方的优点，但同时它的信息量会过多，它一秒钟有至少24张图片，还有人物对话、环境声音等等。导致观众不知道导演想要表达的东西，尤其是比较文艺的小众电影，每一个空镜头，每一个特写，每一个前景都是有隐喻的，这种信息量难以在一瞬间让观众处理完，所以我建议看拉片。]]></description><link>culture\思想\关于电影.html</link><guid isPermaLink="false">Culture/思想/关于电影.md</guid><pubDate>Tue, 02 Jul 2024 07:56:10 GMT</pubDate></item><item><title><![CDATA[年轻人“冷感”，“节能”状态的解读]]></title><description><![CDATA[ 
 <br>刘擎老师提出了一个问题，我们的那种似乎很艰苦的12小时的刷题的教育到底是让学生变得坚韧了还是变得更脆弱了？<br>我发现当代年轻人身上的一种冷感，如果各位看过冰菓里面的男主就是那种，节能，低耗，拒绝无用社交，比如合作中，我将自己的任务完成，绝不进行多余的社交，你不烦我就是谢天谢地了。比如前些年b站的评论区我还看看评论，近些年我发现评论区大部分是对骂和阴阳。所以近些年我基本不发评论，也不开弹幕了。就是一种你们吵去吧，我不想参与，有些时候是有想说的，但是想了下，可能等会儿有人又要批斗你，然后一包火，就算了吧。你现在在这种公共社区评论，说话要注意加语气词，还要加狗头保命，这一点应该各位感觉很明显，我们的网络交流会很注重表达方式，我们似乎对这种表达变得很敏感，比如说话不加语气词，嗯嗯，只说嗯，聊天不用表情包，似乎我们在网络上接受这种信息的时候第一步是要先判断他的表达方式，之前有个说法是语言的通货膨胀，似乎我们对他人的表达语气变得越来越敏感。我觉得这种冷感和敏感是相互作用的，因为觉得人与人之间的相处越来越多的时间在线上，而线上的这种交流由于其本身的只有文字的局限性，加上文字的引申义太强，网络上对文字的解构又太多，再正常的话也会被扭曲，导致它越来越让人敏感，而这种对文字的敏感进一步加强了人与人之间的隔阂，觉得社交太费事了，进一步加强冷感。还有很多老师提到，学生上课越来越愿意回答问题，越来越不愿意跟老师互动，也是一种冷感的表现。年轻人使用一种最低耗能的状态去生活，仿佛是为了保护真正的自我而与世界进行隔离，但是这种隔离真的能找到真正的自我吗？相反，这种隔离会导致确切的孤独感。<br>再比如说大学生自杀的很多，很多人不明白，会觉得你十二年的苦都吃过来了，为什么到了大学，苦尽甘来，反而会自杀。这里有两个问题，一个是这种艰苦的12小时刷题的教育是否会让人变得坚韧？还有一个问题是大学真的是苦尽甘来了吗？我在知乎上之前发过一篇文章，就是讲第二个问题的，我认为从中学到大学后是一种被动社交到主动社交的过渡，而且中间没有缓冲地带，教给学生如何进行主动社交，如何融入同好圈子。在中学，你总会跟邻座的同学产生交集，因为你们一天十二小时都在一块儿，而到了大学，更多的是需要主动社交，主动找到同好的圈子。回到刚刚我们讲的年轻人的冷感问题上，他们不愿意去社交，又对他人敏感，最终导致的就是一种沉默中的毁灭。]]></description><link>culture\思想\年轻人“冷感”，“节能”状态的解读.html</link><guid isPermaLink="false">Culture/思想/年轻人“冷感”，“节能”状态的解读.md</guid><pubDate>Thu, 12 Dec 2024 06:57:02 GMT</pubDate></item><item><title><![CDATA[思想]]></title><description><![CDATA[ 
 <br><a data-tooltip-position="top" aria-label="https://www.bilibili.com/medialist/detail/ml1742749569?type=1&amp;spm_id_from=333.999.0.0" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/medialist/detail/ml1742749569?type=1&amp;spm_id_from=333.999.0.0" target="_blank">思考审美</a><br><br><a data-href="多劳多得的数量关系被模糊" href="\culture\思想\多劳多得的数量关系被模糊.html" class="internal-link" target="_self" rel="noopener nofollow">多劳多得的数量关系被模糊</a><br>
<a data-href="俄罗斯历史" href="\culture\思想\俄罗斯历史.html" class="internal-link" target="_self" rel="noopener nofollow">俄罗斯历史</a><br>
<a data-href="孤独与社交" href="\culture\思想\孤独与社交.html" class="internal-link" target="_self" rel="noopener nofollow">孤独与社交</a><br>
<a data-href="资本定价权" href="\culture\思想\资本定价权.html" class="internal-link" target="_self" rel="noopener nofollow">资本定价权</a><br>
<a data-href="自我审视" href="\culture\思想\自我审视.html" class="internal-link" target="_self" rel="noopener nofollow">自我审视</a><br>
<a data-href="如何活着" href="\culture\思想\自我审视\如何活着.html" class="internal-link" target="_self" rel="noopener nofollow">如何活着</a><br>
<a data-href="关于电影" href="\culture\思想\关于电影.html" class="internal-link" target="_self" rel="noopener nofollow">关于电影</a><br>
<a data-href="关于大学生的孤独感" href="\culture\思想\自我审视\关于大学生的孤独感.html" class="internal-link" target="_self" rel="noopener nofollow">关于大学生的孤独感</a>]]></description><link>culture\思想\思想.html</link><guid isPermaLink="false">Culture/思想/思想.md</guid><pubDate>Sun, 12 Jan 2025 02:44:41 GMT</pubDate></item><item><title><![CDATA[王朝更替背后的经济原理]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想</a> 
 <br><a href=".?query=tag:文化\思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想</a><br>
<a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1VG411a7Ji/?spm_id_from=333.1007.tianma.1-2-2.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1VG411a7Ji/?spm_id_from=333.1007.tianma.1-2-2.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">卢麒元‖百年大变局·形成··局势·演化·策略·应对（完整版）_哔哩哔哩_bilibili</a><br>很有意思的观点，唐朝真正走向衰败的本质原因不是杨国忠杨贵妃，而是经济上以李林甫为首的利益集团通过自由主义，放弃金融国有，而导致的土地兼并，国力衰弱。如今经济下行的很大原因也同样在于80年代撒切尔和里根的新自由主义。<br>
近些年经济增速放缓是因为我们开始走资了。生产的财富并未在国内继续形成资本积累，而是资本外流了。]]></description><link>culture\思想\王朝更替背后的经济原理.html</link><guid isPermaLink="false">Culture/思想/王朝更替背后的经济原理.md</guid><pubDate>Fri, 22 Dec 2023 06:56:40 GMT</pubDate></item><item><title><![CDATA[资本定价权]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想</a> 
 <br><a href=".?query=tag:文化\思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想</a><br>
<a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1Lb4y157g1/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1Lb4y157g1/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">★温铁军：什么男权女权？问题本质，是资本的定价权【新字幕】_哔哩哔哩_bilibili</a>]]></description><link>culture\思想\资本定价权.html</link><guid isPermaLink="false">Culture/思想/资本定价权.md</guid><pubDate>Sun, 24 Dec 2023 01:58:49 GMT</pubDate></item><item><title><![CDATA[自我审视]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想</a> 
 <br><a href=".?query=tag:文化\思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想</a><br>
<a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1uN4y1e7Xm/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1uN4y1e7Xm/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">破除迷茫，建立信心，一条切实可行的办法助你走向正轨！_哔哩哔哩_bilibili</a>]]></description><link>culture\思想\自我审视.html</link><guid isPermaLink="false">Culture/思想/自我审视.md</guid><pubDate>Fri, 22 Dec 2023 05:10:19 GMT</pubDate></item><item><title><![CDATA[A股的问题]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想</a> 
 <br><a href=".?query=tag:文化\思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想</a><br>
<a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV11u4y1u7w7/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV11u4y1u7w7/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">【刘纪鹏教授】A股为何15年不涨总在3000点徘徊？一针见血！_哔哩哔哩_bilibili</a>]]></description><link>culture\思想\a股的问题.html</link><guid isPermaLink="false">Culture/思想/A股的问题.md</guid><pubDate>Fri, 22 Dec 2023 05:07:28 GMT</pubDate></item><item><title><![CDATA[大纲]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/小说" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说</a> 
 <br><a href=".?query=tag:文化\小说" class="tag" target="_blank" rel="noopener nofollow">#文化/小说</a> ]]></description><link>culture\小说\流星交汇\大纲.html</link><guid isPermaLink="false">Culture/小说/流星交汇/大纲.md</guid><pubDate>Sun, 24 Mar 2024 04:23:29 GMT</pubDate></item><item><title><![CDATA[流星交汇]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/小说" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说</a> 
 <br><a href=".?query=tag:文化\小说" class="tag" target="_blank" rel="noopener nofollow">#文化/小说</a> <br><a data-href="世界观" href="\culture\小说\流星交汇\世界观.html" class="internal-link" target="_self" rel="noopener nofollow">世界观</a><br><a data-href="主题" href="\culture\小说\流星交汇\主题.html" class="internal-link" target="_self" rel="noopener nofollow">主题</a><br><a data-href="主要设定" href="\culture\小说\流星交汇\主要设定.html" class="internal-link" target="_self" rel="noopener nofollow">主要设定</a><br><a data-href="主要人物" href="\culture\小说\流星交汇\主要人物.html" class="internal-link" target="_self" rel="noopener nofollow">主要人物</a><br><a data-href="大纲" href="\culture\小说\流星交汇\大纲.html" class="internal-link" target="_self" rel="noopener nofollow">大纲</a>]]></description><link>culture\小说\流星交汇\流星交汇.html</link><guid isPermaLink="false">Culture/小说/流星交汇/流星交汇.md</guid><pubDate>Sun, 24 Mar 2024 04:20:22 GMT</pubDate></item><item><title><![CDATA[世界观]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/小说" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说</a> 
 <br><a href=".?query=tag:文化\小说" class="tag" target="_blank" rel="noopener nofollow">#文化/小说</a> ]]></description><link>culture\小说\流星交汇\世界观.html</link><guid isPermaLink="false">Culture/小说/流星交汇/世界观.md</guid><pubDate>Sun, 24 Mar 2024 04:23:30 GMT</pubDate></item><item><title><![CDATA[主题]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/小说" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说</a> 
 <br><a href=".?query=tag:文化\小说" class="tag" target="_blank" rel="noopener nofollow">#文化/小说</a> ]]></description><link>culture\小说\流星交汇\主题.html</link><guid isPermaLink="false">Culture/小说/流星交汇/主题.md</guid><pubDate>Sun, 24 Mar 2024 04:23:32 GMT</pubDate></item><item><title><![CDATA[主要人物]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/小说" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说</a> 
 <br><a href=".?query=tag:文化\小说" class="tag" target="_blank" rel="noopener nofollow">#文化/小说</a> ]]></description><link>culture\小说\流星交汇\主要人物.html</link><guid isPermaLink="false">Culture/小说/流星交汇/主要人物.md</guid><pubDate>Sun, 24 Mar 2024 04:23:33 GMT</pubDate></item><item><title><![CDATA[主要设定]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/小说" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说</a> 
 <br><a href=".?query=tag:文化\小说" class="tag" target="_blank" rel="noopener nofollow">#文化/小说</a> ]]></description><link>culture\小说\流星交汇\主要设定.html</link><guid isPermaLink="false">Culture/小说/流星交汇/主要设定.md</guid><pubDate>Sun, 24 Mar 2024 04:23:35 GMT</pubDate></item><item><title><![CDATA[小说]]></title><description><![CDATA[ 
 <br><br><a data-href="小说技巧思考" href="\culture\小说\小说技巧思考.html" class="internal-link" target="_self" rel="noopener nofollow">小说技巧思考</a><br>
<a data-href="流星交汇" href="\culture\小说\流星交汇\流星交汇.html" class="internal-link" target="_self" rel="noopener nofollow">流星交汇</a>]]></description><link>culture\小说\小说.html</link><guid isPermaLink="false">Culture/小说/小说.md</guid><pubDate>Sun, 24 Mar 2024 04:18:58 GMT</pubDate></item><item><title><![CDATA[小说技巧思考]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化/阅读/思考" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/阅读/思考</a> <a class="tag" href="?query=tag:文化/小说/技巧" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说/技巧</a> 
 <br><a href=".?query=tag:文化\阅读\思考" class="tag" target="_blank" rel="noopener nofollow">#文化/阅读/思考</a><br>
<a href=".?query=tag:文化\小说\技巧" class="tag" target="_blank" rel="noopener nofollow">#文化/小说/技巧</a> <br>
<br>小说的展开，可以用视野较小的小人物，从低处窥探，更加能体现整个作品的宏伟。如刘姥姥进大观园。
<br>如何写死一个人物。<a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1eu4y1J72k/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1eu4y1J72k/?spm_id_from=333.880.my_history.page.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">编剧在什么情况下会杀死一个角色？_哔哩哔哩_bilibili</a>
]]></description><link>culture\小说\小说技巧思考.html</link><guid isPermaLink="false">Culture/小说/小说技巧思考.md</guid><pubDate>Tue, 10 Sep 2024 12:17:37 GMT</pubDate></item><item><title><![CDATA[心理游戏]]></title><description><![CDATA[ 
 <br><br>我第一部看的小说或者说长篇童话就是木偶奇遇记，最后也是从鲸鱼肚子里出来的设定，所以看到最后他们冲出鲸鱼肚子还蛮感动的。<br>
你说回忆是不一定真实的，的确，每个人都体验过。栾屹想说的过去的可能性应该是先验的，他不好举例子应该是因为这不是一种现实生活的体验。我理解的是，如果把当下看成一个节点，未来有无限平行宇宙的可能性，那么与之相对的过去也有无限个达到现在的可能。<br>理解了！以当下为基点，确实也有很多个过去的可能。诶感觉转世论的美好情结可能也是在这，还有一种宿命感。兜兜转转，但还是要交错相遇在这个节点。看来我十分善于找糖点（）<br>
噢而且我现在也还会想，原来奋不顾身是这样的感觉，有目标是一件如此热切的事。我虽然可以说是情感浓郁吧，但大多在对人上，自己在做事的时候很平淡，和无谓。所以现在觉得主角好棒，他身上带有那种不顾一切和随时出走的勇气，还有幼稚但趣味的童真！<br>
你会有这样的感受吗，会喜爱这样的人吗？这个社会好像喜欢情绪稳定、理性稳重的人，我也觉得这样的人很棒，但内心还是期待着这种人格的身边一定要有感性人格互补，后者也同样值得被当做榜样。<br>
参考《纳尔齐思和歌尔德蒙》😼<br>哈哈哈哈对，转世论这种回答我从哪里来的哲学理论应该才是他想表达的，回忆不可靠更多是生物上的理论。命运交织的节点的确很浪漫。<br>
我也觉得现在时代是缺乏感性而宣扬理性的。里面不仅男主是热切的，女主和女主姐姐也是同样的。女主姐姐是第一个敢于面对被吞进鲸鱼肚子的现实的人，她割头发时也很帅。女主最后要逃出鲸鱼肚子的船上拥抱她姐姐的时候也是十分令人感动的。再说男主，男主与女主的情愫和新海诚在秒五里描绘的男女主的情愫是很像的。但是在新海诚里是一种不可得的距离感，一种日式的含蓄，但并非新海诚这种男主就是理性的，他也冒雪攒了半学期零花钱去见女主。<br>
我看文艺片是比较少的，但是我看汤浅在男主从死到生穿过隧道最后突破的一个屏障和深海里女主突破屏障回到现实是类似的。可能田晓鹏借鉴了汤浅，不过深海里它的屏障的质感是不一样的，它会撕裂，撕裂牵连的细线会割伤女主的皮肤，在这部电影里那个屏障就突破的简单。表达重点不同。<br>
男主的感性和不现实大多数都是内心描写。是复生后他才放飞自我，直接开车逃跑被鲸鱼吞掉的。现实中的人也一样，一定有复杂的情绪在心里，而不会直接表达出来。<br>情感上的自我认知体验才是每个人生命的目标。]]></description><link>culture\影视\心理游戏.html</link><guid isPermaLink="false">Culture/影视/心理游戏.md</guid><pubDate>Thu, 28 Mar 2024 03:43:46 GMT</pubDate></item><item><title><![CDATA[冰与火之歌]]></title><description><![CDATA[ 
 <br><br>《冰与火之歌（全五卷）》<br>乔治·R.R.马丁<br>
197个笔记<br>第四章 序幕<br>◆ 人人都说当时积雪深达四十尺，北风跟玄冰似的，但真正要命的却是低温。它会无声无息地逮住你，比威尔还安静，起初你会发抖、牙齿打颤、两腿一伸，梦见滚烫的酒，温暖的营火。很烫人，是的，再也没什么像寒冷那样烫人了。但只消一会儿，它便会钻进你体内，填满你的身体，过不了多久你就没力气抵抗，只渴望坐下休息或小睡片刻，据说到最后完全不觉痛苦。你只是浑身无力，昏昏欲睡，然后一切渐渐消逝，最后，就像淹没在热牛奶里一样，安详而恬静。<br>◆ 暮色渐沉，无云的天空转为淤青般的深紫色，然后没入黑幕。<br>第七章 丹妮莉丝<br>◆ 韦赛里斯经常这么对她承诺，有时他边说手还会无法克制地颤抖<br>◆ 韦赛里斯之所以活着就是为了那一天，丹妮却只想重回那栋有红漆大门的宅院，想要她窗外的那株柠檬树，还有她失去的童年。<br>◆ 自由城邦潘托斯名义上没有奴隶制度，即便如此，握有实权的人们却能够逾越体例。<br>◆ 。洗浴水滚烫无比，但丹妮莉丝没有吭声。她喜欢这种热，让她有干净的感觉。更何况哥哥常对她说，坦格利安家族的人是不怕烫的。“我们是真龙传人，”他常说，“血液里燃烧着熊熊烈焰。”<br>◆ 只要我能得到那支军队，就算得让他卡拉萨里的四万人通通把你操上一遍，我也会同意，必要的话，连他们的马一起上也行。现在你只给卓戈一个人干，已经该偷笑了。<br>第八章 艾德<br>◆ 一时之间，艾德·史塔克心中充满了一种山雨欲来的恐惧，毕竟寒冷的北国才是真正属于他的故乡。他看看四周石像，吸了口墓窖的冰冷空气。他隐约可以感觉得出身旁历代先祖的目光，他知道他们正侧耳倾听，他知道凛冬将至。<br>第一十一章 艾莉亚<br>◆ “本来他衣服绣上王族的家徽就够了，但是他却把母亲那边的家徽也绣了上去，而且还和王室的纹章平起平坐。”<br>第一十四章 琼恩<br>◆ 2023/12/18发表想法<br>感觉马丁对每个人物都刻画的纯粹，cat对John有一种纯粹的恶毒。<br>原文：“琼恩。”她说。他实在就应该这么继续走下去，但她从没有用他的名字称呼过他。于是他转过身，发现她正盯着他的脸，仿佛这辈子第一次见到。<br>
“什么？”他问。<br>
“今天躺在这里的应该是你才对。”她告诉他。<br>◆ “没想到离别这么难。”<br>◆ 殊途不见得不能同归，谁知道将来怎么样呢？<br>◆ “你难道猜不出来？”琼恩揶揄，“就是你最心爱的东西呀。”艾莉亚乍听之下满头雾水，但随即恍然大悟，她的反应就是这么迅捷。于是两人再度异口同声道：“缝衣针！”记忆中她的笑声，在后来北行的漫长路上，始终温暖着他的心房。<br>第一十五章 丹妮莉丝<br>◆ 然而丹妮无暇他顾，置身这片广大人海之中，她只感到前所未有的孤独。<br>◆ 于是，这几个小时以来，她第一次忘却了恐惧。或许，是她这辈子第一次。<br>◆ 银色的马载她穿越熊熊烈焰，仿佛为她插上了翅膀。她在伊利里欧总督面前停下，说：“请告诉卓戈卡奥，他给了我风的力量。”这位肥胖的潘托斯人捻捻黄胡子，把她的话译为多斯拉克语，接着丹妮头一次看到她的新婚丈夫露出微笑。<br>◆ 卓戈翻身下马，然后把她抱下来。在他手里，她觉得自己脆弱得好像玻璃，四肢无力犹如溺水似的。<br>◆ 卓戈卡奥看着她的泪水，脸上奇怪地毫无表情。“不。”他抬起手，用长茧的拇指粗鲁地抹去她的泪水<br>◆ 卓戈轻触她的头发，一边用手抚弄她亮银色的发丝，一边用多斯拉克话喃喃自语。丹妮听不懂他在说些什么，然而话中有种温暖的感觉，一种她原本不期待会在这个男人身上找到的温柔。<br>◆ 卓戈卡奥仍旧双腿盘坐，定定地望着她，用眼睛享受她的躯体。<br>◆ 这时他停了下来，把她拉进怀里。丹妮面红耳赤，喘气不止，心脏狂跳。他用那双巨掌托起她的脸，两人四目相交。“不？”他说。她听懂这是个问句。<br>第一十六章 艾德<br>◆ 奈德愤怒地抿嘴道：“以后也不会告诉你。劳勃，不要再说了，就算是看在我俩的情分上罢。我当着诸神和世人的面羞辱了我自己，也羞辱了凯特琳。”<br>◆ 东升旭日的金黄指头探进清晨的朦胧白雾，一片辽阔原野在两人眼前展开，其中除了长而低缓的零星小丘，尽是片片光秃秃的褐色平地。<br>◆ 乔拉爵士为增加收入，打算把抓到的盗猎者卖给泰洛西的奴隶贩子。由于莫尔蒙是史塔克的封臣，如此一来等于玷污了整个北方的名声。于是奈德千里迢迢西行前往熊岛，却发现乔拉早已搭船潜逃，逃到“寒冰”和国王的法律制裁之外的番邦异地去了。事发至今一转眼已经五年。<br>◆ 当年泰温·兰尼斯特献上雷加妻儿们的尸体以示效忠时，两人所发生的激烈口角。<br>◆ 我早该动手了，但琼恩跟你一样坏心眼。不过我更傻，我听了他的话。”“琼恩·艾林是个英明睿智的首相。”<br>◆ “他有能力，也不缺勇气，这毋庸置疑。”他小心翼翼地说，“但是劳勃，他父亲是世袭的西境守护，詹姆爵士迟早要继承父职，东西诸国的大权不应落入同一个人手里。”他没把真正想说的话说出来：如此一来王国一半的兵力将会落入兰尼斯特家族的手中。<br>◆ 但凡事毕竟不可能尽如人意。艾德·史塔克心意已决，便一踢马肚，朝国王奔去。<br>第一十七章 提利昂<br>◆ 2023/12/19发表想法<br>这本书景色描写一直翻译得不错<br>原文：然而好景不长，离开临冬城三日之后，农田退去，只见茂密深林，国王大道也越来越人迹罕至。丘陵则日益陡峭，到了第五天，已经成了山脉，宛如肩负陈雪和陡峭岩峰的灰蓝巨人。当北风吹起，长长的冰针像旗帜一般从高耸的峰峦间飞溅而下。<br>◆ 然而好景不长，离开临冬城三日之后，农田退去，只见茂密深林，国王大道也越来越人迹罕至。丘陵则日益陡峭，到了第五天，已经成了山脉，宛如肩负陈雪和陡峭岩峰的灰蓝巨人。当北风吹起，长长的冰针像旗帜一般从高耸的峰峦间飞溅而下。<br>◆ 提利昂为那孩子难过，他选择的是一条艰难的道路……或者应该说，别人为他选择了这条艰难的道路。<br>◆ “说不定他以为你就是古灵精怪哟。”提利昂瞪了他一眼，接着放声大笑，那是一股他全然没有预期的原始笑意。“噢，诸神在上，”他笑得差点岔了气，不住摇头，“我想我看起来确实蛮像的嘛！<br>◆ 琼恩·雪诺神情肃穆地抿抿嘴。“那我就既来之则安之。”提利昂朝他嘿嘿一笑。“私生子，真有你的。大部分的人宁可否认事实，也不愿面对真相。”<br>◆ 只见男孩站在营火边，面色坚毅凝重，深深望进跳跃的熊熊火焰。<br>◆ 提利昂·兰尼斯特哀伤地笑了笑，返身进入营帐就寝。<br>第一十八章 凯特琳<br>◆ 说到这里他突然停了下来，像他小时候习惯的那样咬咬下嘴唇。“妈，我也需要你啊。我很努力在尝试，可我……我一个人做不来啊！”随着这突如其来的情绪激动，他的声音陡地沙哑，凯特琳这才想起他不过十四岁。<br>◆ 思及此处，她泣不成声，不顾一切地自他掌中抽出双手，捂住耳朵，不愿再听外面那骇人的狼嚎。“叫他们别叫了！”她喊，“我受不了，叫他们别叫了，别叫了，就算杀了他们也没关系<br>第一十九章 珊莎<br>◆ 艾莉亚专门结交哪些人，珊莎太清楚了：侍从、马夫与女仆，老头子和不穿衣服的小孩，还有满嘴粗话，出身低贱的自由骑手。艾莉亚跟任何人都能做朋友，<br>第二十一章 布兰<br>◆ 飞，都是从坠落开始的，乌鸦说，往下看。<br>◆ “我怕……”<br>往下看！<br>布兰往下看，觉得五脏六腑简直都要融化。地面正朝他迎面袭来，整个世界摊在下方，如同一幅五颜六色的织锦。每一件事物都清晰无比，他甚至暂时忘却了恐惧。王国全境和行走其间的形色人事尽收眼底。<br>他以翱空翔鹰之姿俯瞰临冬城，高处观之，原本高耸的塔楼竟显得矮胖，城墙则成了泥地上的线条。他看到阳台上的鲁温师傅，一边用擦得晶亮的青铜管子观测天象，一边皱着眉头在记事本上涂涂写写。他看见哥哥罗柏在广场上练习剑术，手中拿着精钢打造的真正武器，个头比记忆中更高壮。<br>◆ 布兰抬起头，一脸安详地说：“我要叫它‘夏天’。”<br>第二十二章 凯特琳<br>◆ “我早知道他会大有发展。”凯特琳说，“他打小就很机灵。可机灵和睿智是两回事，真不知道这些年他有多大改变。”<br>第二十三章 琼恩<br>◆ 琼恩看着叔叔牵马走进隧道，向北而去，不禁想起提利昂·兰尼斯特在国王大道上告诉过他的事，脑海里接连浮现出班扬·史塔克倒卧雪地，血迹斑斑的情景。这个念头令他反胃。我究竟成了个什么人？<br>◆ 黑城堡没有神木林，只有一间小小的圣堂和醉醺醺的修士，但琼恩实在无心向神明祷告，管他是新神还是旧神。他心里认为，倘若诸神真的存在，想必也是和这里的严冬一样残酷无情罢。<br>第二十五章 提利昂<br>◆ 他是我们中的巨人，一个来到世界尽头的巨人。<br>◆ “我说的可是真心话。”提利昂竟无言以对。他只有礼貌性地低头说：“伊蒙师傅，您太客气了。”<br>◆ 如今的守夜人部队不过是群郁闷不乐的小伙子和身心俱疲的老头子组成的乌合之众罢了。<br>◆ 暴露在外的双颊被冻得通红，双脚也早就在抗议，但他不加理会。狂风在他耳际怒吼，碎石在他脚下嘎吱作响，长城在他前方沿丘陵蜿蜒，有如白色蝴蝶结般，渐渐升高，最后消失于西边的地平线。<br>◆ 等琼恩·雪诺重新戴上手套，他突然转身走到北面冰冷的低矮城垛边。城墙以外高度骤降，只剩一片暗黝寒荒。提利昂跟了过去，两人便这么肩并肩站在世界的尽头。<br>第二十六章 艾莉亚<br>◆ 2023/12/20发表想法<br>米凯从没有反抗<br>原文：“他是我朋友呀。”艾莉亚对着餐盘低语，声音低到无人听见。<br>◆ “他是我朋友呀。”艾莉亚对着餐盘低语，声音低到无人听见。<br>◆ 她发现自己好希望琼恩此刻在自己身边，那样她就不会觉得这么孤单了。<br>◆ “啊，艾莉亚，我的孩子，你有股特别的野性，你的祖父称之为‘奔狼之血’。莱安娜有那么一点，我哥哥布兰登则更多，结果两人都英年早逝。”<br>◆ 当初若是你祖父答应，莱安娜大概也会舞刀弄剑。有时候看到你，我就想起她，你甚至长得都跟她有几分神似。”<br>◆ 都是我的错，是我……”<br>◆ 突然间，父亲的双臂抱住了她，她转过头，埋在他胸口啜泣，他则温柔地拥着她。“别这样，我亲爱的孩子。”他低语道，“为你的朋友哀悼吧，但不要自责。屠夫小弟不是你害的，该为这桩血案负责的是‘猎狗’和他残酷的女主人。”<br>◆ 我打中她两次，她边哀嚎边看着我，我觉得好羞耻，但这样做是正确的对不对？不然王后会杀她的。”<br>◆ “真的。”他微笑着说。“我要是把它给拿走了，只怕没两个星期就会在你枕头下找到流星锤罢。算啦，无论你多生气，别拿剑刺你姐姐就好。”<br>第二十八章 布兰<br>◆ 2023/12/20发表想法<br>很真实的孩童描写<br>原文：灰风总是抢先一步，跨步截断他的路，瑞肯看到他，兴奋地尖叫，然后又朝另一个方向奔去。<br>◆ 灰风总是抢先一步，跨步截断他的路，瑞肯看到他，兴奋地尖叫，然后又朝另一个方向奔去。<br>第三十章 琼恩<br>◆ 大部分人宁可否认事实，也不愿面对真相。这个世界有太多逞英雄的胆小鬼，能像山姆威尔·塔利这样自承怯懦还真需要点古怪的勇气。<br>◆ 繁星在头顶的夜幕中燃烧，澄澈而锐利<br>第三十二章 凯特琳<br>◆ 她记得饱溢湿气的神木林，枝干低垂；记得弟弟追着她跑过一堆堆湿叶，笑声清脆。她也记得和莱莎玩泥巴的种种情景，记得泥团在手中的重量，记得滑溜的褐色泥泞在指间流动的感觉。后来，她们咯咯笑着把做好的泥饼端给小指头吃，他竟当真吃了一堆，事后足足病了一个星期。啊，记得当时年纪还小。<br>◆ 凝视雨滴溜下窗棂。玻璃模糊不清，水珠密布，<br>第三十八章 凯特琳<br>◆ 峡谷在他们面前绵延，直至氤氲弥漫的东方，这乃是一个祥和恬静的国度，四面受群山庇护，内中是肥沃的黑土，宽阔而舒缓的河川，还有在阳光下明亮如镜、数以百计的大小湖泊。<br>第四十五章 琼恩<br>◆ 2023/12/26发表想法<br>像是调查军团<br>原文：然而游骑兵才是守夜人部队中真正的战斗主力。只有他们会骑马北出长城，扫荡影子塔以西鬼影幢幢的森林和冰雪覆盖的崇山峻岭，与野人、巨人和怪物般的雪熊作战。<br>◆ 世界在路的彼端……而他却在这里。<br>第四十六章 提利昂<br>◆ 提利昂抬头仰视星空。这是个清朗的寒夜，群星的光辉洒在山间，明亮无情有如真理。“我遇见她的那晚就和现在一模一样，”<br>◆ ”浓烟刺痛了他的眼睛。提利昂清清喉咙，从火边转开，朝黑暗的夜空望去。“泰温大人让我最后一个上。”他轻声说，“他还递给我一枚金币，因为我是兰尼斯特家的人，身价不同。”<br>◆ 他用山猫皮披风裹住身子，闭上眼睛。地面凹凸不平，又冷又硬，但没过多久，提利昂·兰尼斯特竟真的睡着了。他梦见了天牢，但这回他是狱卒，并非犯人，而且他身躯高大，手握皮带，正抽打着父亲，逼他后退，逐渐靠近无尽深渊……<br>第四十七章 艾德<br>◆ 透过红堡深广王座厅的狭窄高窗，夕阳余晖遍洒地面，为墙壁挂上暗红色的条纹。<br>◆ 他高高坐在“征服者”伊耿宽大而古老的座位上。那是张钢铁铸成、满是狰狞尖刺利角和诡异扭曲金属的椅子，它正如劳勃所警告的那般，是张天杀的不舒服的椅子。<br>第四十九章 艾德<br>◆ 在权力的游戏之中，你不当赢家，就只有死路一条，没有中间地带。<br>第五十章 丹妮莉丝<br>◆ 韦赛里斯微笑着放下剑。将来最教她伤心、最让她撕心裂肺的一件事……就是他微笑的模样。“我要的就只是这个，”他说，“他答应要给我的。”<br>◆ 半液态的金块滴落他的胸膛，鲜红的丝衣嘶嘶冒烟……但他没有流出一滴血<br>第五十一章 艾德<br>◆ 2023/12/27发表想法<br>小指头知道奈德绝对不会这么做才这么说的<br>原文：你既是首相，又是全境守护者。史塔克大人，你是大权在握，只需伸手便可夺取天下。与兰尼斯特家和好，释放小恶魔，让乔佛里和你的珊莎结婚，<br>第五十二章 琼恩<br>◆ 无论他算不算懦夫，山姆威尔·塔利都像个男子汉一样有了接受命运的勇气。<br>第五十四章 艾莉亚<br>◆ “我的嘴巴骗人，我的眼睛和手说的可是真话，只是你视而不见。”“我哪里看不见，”艾莉亚说，“我每秒钟都盯着你看！”“死掉的小妹妹，‘观看’不代表‘洞察’。<br>◆ 艾莉亚的脚步发出轻轻的回音，抢在她身前，朝黑暗的深处迈去。<br>第五十七章 布兰<br>◆ 不愿倾听的人自然什么也听不到。”<br>第五十八章 丹妮莉丝<br>◆ “至于卓戈之子雷戈，骑着世界的骏马，我也要送他一件礼物。我要送他那张他母亲的父亲曾经坐过的铁椅子，我要送他七大王国。我，卓戈，卡奥，要做这件事。”他的音量渐高，举起拳头对天呼喊，<br>第五十九章 凯特琳<br>◆ “你父亲并非无所畏惧，”凯特琳指出，“而是勇敢，这是完全不一样的。”<br>第六十一章 珊莎<br>◆ 启禀陛下，我要为家父，亦即前首相艾德·史塔克大人请愿，求您慈悲为怀、法外开恩。”这句话她已经练习过几百遍了。<br>第六十二章 艾德<br>◆ 为何在你们这些王公贵族的权力游戏里面，永远是无辜的人受苦最多？<br>第六十四章 琼恩<br>◆ 不过都是虚幻，都是空谈罢了。我们身为凡人，天上诸神使我们有能力去爱，那是对我们最美好的恩赐，却也是我们最深沉的悲哀。<br>◆ 当一个人无所畏惧时，即便懦夫也能展现不输于人的勇气。当我们无须付出代价时，自然都能尽忠职守。行走在这条荣耀的大道上，似乎是那么的容易。然而每个人的生命中迟早会遇到考验，那便是他必须抉择的时刻。<br>◆ 你必须自己做出这个抉择，然后一辈子与之相伴，就像我一样<br>第六十五章 丹妮莉丝<br>◆ 2023/12/28发表想法<br>这就很奇怪干嘛要杀了他们<br>原文：那多斯拉克人摔在泥地上，翻身跳起，手握短刀，旋即被阿戈一箭封喉。<br>第七十五章 凯特琳<br>◆ 2023/12/29发表想法<br>黄袍加身迫使萝卜必须参与权力的游戏为手下谋利<br>原文：自从龙王伊耿一统六国，这个称号首度堂皇重现，响彻于她父亲的木造殿堂：<br>
“北境之王万岁！”<br>
“北境之王万岁！”<br>
“北境之王万岁！”<br>第七十六章 丹妮莉丝<br>◆ “在这里，我更看到幼儿、妇女和满是皱纹的老人的脸孔。昨天我尚为幼儿，今夕我已成为女人，明日我便将衰老。我告诉你们中每一个：把你们的双手和你们的心灵交给我，这里永远有你们的一席之地。”<br>◆ 感谢你教会我的一切。”<br>◆ 丹妮只需看看他们的眼睛，便知他们已经臣服于她，今日如此，明日亦然，直到永远，不是惧于卓戈威势的臣服，而是打从心底的心悦诚服。<br>◆ 于是，龙族齐声高鸣的乐音响彻夜空，数百年来，这是头一次。<br>第七十七章 跋<br>◆ 这么厚的一本书，自然有着许多许多的恶魔，稍不注意，每个都会咬你一口。幸运的是，我也认识许多天使<br>第八十三章 序幕<br>◆ 彗星的尾巴划过清晨，好似紫红天幕上的一道伤口，在龙石岛的危崖绝壁上空汩汩泣血。<br>第八十九章 琼恩<br>◆ 武器匠沉吟片刻。“如果说劳勃是真钢，那史坦尼斯就是纯铁，又黑又硬又坚强，却也容易损坏，和铁一样，弯曲之前就会先断掉。至于蓝礼嘛，他像是闪闪发光的亮铜，看起来漂亮，实际却不值几个钱。”<br>◆ “继续困扰，”琼恩道，“但坚守誓言。”<br>第九十一章 提利昂<br>◆ 有人说知识即力量，也有人说力量源于天神，更有人说力量来自律法。然而那天，在贝勒大圣堂的台阶上，我们信仰虔诚的大主教、合法的摄政太后，以及您眼前这位见多识广的公仆却和下面随便一个鞋匠桶匠一般无能为力。您觉得到底是谁杀了艾德·史塔克？是下达命令的乔佛里，执行死刑的伊林·派恩爵士，还是……另有其人？<br>◆ 力量存在于人心，人相信什么是力量，什么就是力量，不多也不少。”<br>◆ “力量就像墙上的影子，”瓦里斯喃喃道，“但影子却能杀人。而且，即便是矮小人物，也能投射出硕大的影子。”<br>第九十二章 艾莉亚<br>◆ 独臂女死于当日黄昏，詹德利和凯杰克在山坡上帮她掘了个坟，就在一棵柳树下。寒风吹起，艾莉亚仿佛听见长长的柳枝低语着“求求你！求求你！求求你”，听得她颈背汗毛直竖，差点没拔腿就跑。<br>第九十三章 戴佛斯<br>◆ 好个英雄之红剑，看起来可真是一块废铁，戴佛斯心想。<br>◆ 我手下一半以上的骑士连她的名字都不敢念，就算她除此之外别无所长，仅仅作为一个散播恐慌的女巫便已很有价值。人一胆寒便先输了一半。更何况她说不定真有本领，我打算查个清楚。”<br>◆ 既然七神连只麻雀都不曾给我，现在是我换只猎鹰的时候了，戴佛斯，换一只红色的猎鹰<br>第九十四章 席恩<br>◆ 2024/01/04发表想法<br>掠夺是西方历史的主旋律<br>原文：席恩父亲的名号之一便是“掠夺者之首”，而葛雷乔伊家族的族语则傲然宣称“强取胜于苦耕”。<br>◆ 席恩父亲的名号之一便是“掠夺者之首”，而葛雷乔伊家族的族语则傲然宣称“强取胜于苦耕”。<br>◆ 艾德公爵每每试图扮演父亲的角色，然而席恩总提醒自己，对方正是为派克城带来血腥杀戮，并迫使他远离家园的人。他小时候一直活在史塔克的严峻面容和那把恐怖巨剑的阴影中。史塔克的妻子则更是疏离而猜疑。<br>◆ 我好像成了这里的陌生人啊，席恩心想，明明什么都没变，却又好像什么都不一样了<br>第九十七章 艾莉亚<br>◆ 绿色的湖水温暖得一如热泪，却没有咸味，尝起来是泥土、植物和夏天的味道。艾莉亚把脸伸进水中，洗去旅途尘土和汗水。抬头时，小水滴滑下脖颈，流进衣服，感觉很是舒服。<br>第九十八章 提利昂<br>◆ 拔下一个人的舌头，非但不能证明他是骗子，反而让全世界知道你有多害怕他想说的话。<br>第一百零章 提利昂<br>◆ 2024/01/05发表想法<br>这不就代表了欧洲的资产阶级吗<br>原文：金龙币仿佛自行繁衍般不断膨胀增加。小指头放款出去，连本带利收回来。<br>
与此同时，他也逐渐培养自己的心腹。四库总管全是他的人，王家会计和王家度量员，就连三间铸币厂的负责人，也都是他提名的人选。除此之外，港务长、包税人、海关人员、羊毛代理商、道路收费员、船务长、葡萄酒代理商人等等，十个里面也有九个是小指头的人。他们大都家世普通，包括商人之子、小贵族，甚至有外国人，但以成就而论，这些人的能力远超前任的贵族事务官。<br>第一百一章 珊莎<br>◆ 桑铎·克里冈嗤之以鼻。“瞧瞧你，长得虽漂亮，却根本不会说谎。你知道，狗是可以嗅出谎话的。你好好瞧瞧这地方，再闻个仔细，他们全都是骗子……而且每一个都比你高明。<br>第一百二章 艾莉亚<br>◆ 他本来要带我回家呢，他们一边为老人挖墓，她心里一边想。庄里死人太多，无法全部埋葬，但艾莉亚坚持无论如何都该为尤伦挖个坟。他本来向我保证，要把我安全带回临冬城呢。她很想哭，却又很想用力踢他。<br>◆ 她把那双破烂不堪的鞋子丢了。赤脚走路起初很痛苦，但水泡会破，割伤会愈合，最后她的脚底硬得跟皮革一样。脚趾间满是湿泥的感觉很舒服，她喜欢肌肤与大地相连的悸动。<br>第一百三章 提利昂<br>◆ 很好。瑟曦等得越久，就会越恼怒，越恼怒就会越犯蠢。与其在她好整以暇、狡计盘算的时候见她，不如等她恼怒犯蠢以后。<br>◆ 艾德·史塔克可没有都城守备队撑腰，提利昂心想，也没有高山氏族，更没有波隆招募的佣兵，我却三者皆有。至少他心里这么希望，因为这意味着信任瓦里斯、杰斯林·拜瓦特爵士和波隆三人。史塔克大人当初可能也抱着同样的感觉。<br>第一百四章 布兰<br>◆ 他咽下酒汁，只觉无数热辣而弯曲的手指在胸腔蜿蜒，放下杯子，脑袋一片眩晕。<br>◆ 他来来回回地巡视长凳上那些或快乐或忧伤的脸庞，心里却不知在明年、在未来还能不能见到他们。他应该要哭的，然而却忍住了。他是临冬城的史塔克，是父亲的儿子，是哥哥的继承人，几乎就要长大成人了。<br>◆ 当他吹灭床头的蜡烛，黑暗便像一张柔软而熟悉的毯子盖住了他。<br>第一百六章 琼恩<br>◆ 卡斯特是个自由人，他没有对我们宣誓，并不需遵从我们的律法。你有一颗高贵的心，琼恩，但你得学会这一课：我们不能按自己的想法来塑造这个世界，这并非我们的目的，咱们守夜人军团的职责只是战斗<br>第一百七章 席恩<br>◆ “在这个世界上，大家都是互相倾轧，只有傻瓜才会自己贬低自己。”<br>第一百八章 提利昂<br>◆ 他们个性如此迥异，本质却又那么相似，两人均不可能容忍对方。<br>◆ 我爱上一位美如夏日的姑娘，阳光照在她的秀发<br>◆ 征服者伊耿的铁王座布满凶险的倒钩和尖锐的铁齿，只有傻瓜才以为可以舒舒服服地坐在上面。上阶梯时，他发育不良的双腿不断抽筋，他非常清楚，这是一幅多么荒谬可笑的景象。好在它有一点值得称道，它很高。<br>第一百一十章 丹妮莉丝<br>◆ 2024/01/13发表想法<br>龙妈身上的王的气息是最强烈的，但是来自哪里呢？天生的吗？<br>原文：“真龙会死。”她踮起脚尖，轻吻他未曾修刮的脸颊，“但屠龙者也会。”<br>◆ “真龙会死。”她踮起脚尖，轻吻他未曾修刮的脸颊，“但屠龙者也会。”<br>第一百一十一章 布兰<br>◆ 啊，必须指出的是，世上不为人知的事还很多很多。历史的洪流奔过百年千年，而一个人短暂的一生不就是几个仓促的夏季，几个渺小的冬天么？我们仰望着高山，便称其为永恒，因为它们看来是这样……然而在时间的长河里，高山升起又倒塌，江河改变了途径，繁星坠下了天幕，雄城没入了汪洋。若我们所断不假，连神灵也在生死轮替。沧海桑田，世事变迁。<br>第一百一十二章 提利昂<br>◆ 也许秘密就在于此：我们做什么并不重要，重要的是我们为何而做。<br>◆ 2024/01/14发表想法<br>溢于言表的自卑<br>原文：她怎会抱怨呢？她所有的守卫加起来还没有我可怕，而她从没有抱怨过我。或许，她根本不知道什么是丑吧。<br>◆ 她怎会抱怨呢？她所有的守卫加起来还没有我可怕，而她从没有抱怨过我。或许，她根本不知道什么是丑吧。<br>◆ 2024/01/14发表想法<br>提利昂的自卑的突破口在雪伊。雪伊给了他以价值。<br>原文：这是真的，所有这一切都是真的，他心想，战争，阴谋，壮丽而血腥的游戏，还有处于这一切中心的我……我！一个侏儒，一个怪物，一个他们轻蔑和取笑的对象，凭着我与生俱来的本领，掌握了所有……权力，都城，女人。诸神宽恕我，我爱这一切……<br>
还有她。尤其是她。<br>◆ 这是真的，所有这一切都是真的，他心想，战争，阴谋，壮丽而血腥的游戏，还有处于这一切中心的我……我！一个侏儒，一个怪物，一个他们轻蔑和取笑的对象，凭着我与生俱来的本领，掌握了所有……权力，都城，女人。诸神宽恕我，我爱这一切……还有她。尤其是她。<br>第一百一十六章 凯特琳<br>◆ 2024/01/14发表想法<br>这句话好美<br>原文：晨光用修长的指头抚摸着原野，带回世界的色彩。<br>◆ 晨光用修长的指头抚摸着原野，带回世界的色彩。<br>第一百一十七章 琼恩<br>◆ 远方的地平线上，山脉好似雄浑的阴影，一片接一片，直至变得灰白模糊。参差的峰峦上终年积雪，纵然遥遥相望，它们依旧那么庞大、冰冷、寂寞而荒凉。<br>◆ 朔风吹起，他听见远比他年迈的枝叶在呻吟叹息。千百片树叶集体舞蹈，一时之间，森林似乎化为深绿的海洋，风暴流转，不得宁息，恒同日月，难以揣测。<br>第一百二十一章 艾莉亚<br>◆ 艾莉亚接过单子，跑了出去。军械库跟铁匠房毗邻，那铁匠房是一栋长条状的建筑，高高的屋顶，墙里嵌了二十个火炉，还有长长的石水槽，用来给钢铁淬火。她进去时，一半火炉都在运作。墙壁间回响着铁锤的敲打声，发出共鸣。魁梧结实的人们围着皮裙，俯身站在风箱和铁砧前，在滞闷的热气中挥汗如雨。她斜眼瞥见詹德利，他裸露的胸膛因汗水而显得光亮平滑，浓密黑发下的蓝眼睛仍有记忆中的固执。都是因为他，他们才全部被抓，艾莉亚不确定自己是否还想跟他说话。“哪位是卢坎？”她将纸递出去，“我要为莱昂诺爵士取一把新剑。”<br>第一百二十二章 凯特琳<br>◆ 2024/01/18发表想法<br>这么说，不仅在中国古代商人地位不高，中世纪欧洲商人地位也不高吗？<br>原文：不过从父亲这么激烈的反应看来，也许只是个商人之子或低贱的学徒一类，甚至是个歌手。<br>◆ 不过从父亲这么激烈的反应看来，也许只是个商人之子或低贱的学徒一类，甚至是个歌手。<br>第一百二十五章 戴佛斯<br>◆ 您感觉到寒风有多凄冷吗？在这样的夜里，卫兵们会挤在火炬边。一点点的温暖，一丝丝的亮光，就是他们所能希求的唯一慰藉。然而火把也令他们盲目，因此他们将不能发现我们的行迹。<br>第一百二十九章 布兰<br>◆ 夜雨唤起千百种沉睡的味道，使它们成熟鲜活。青草和荆棘，地上的黑莓，泥土，蠕虫，腐叶，钻过灌木丛的老鼠……一切都清晰可辨。他还捕捉到弟弟那身茸茸黑毛的气味，以及他刚猎杀的松鼠所散发的浓烈血腥。很多松鼠在头顶枝头流窜，用小爪子抠挖树皮，湿润的毛皮，无边的恐惧。一如外面的噪声。<br>第一百三十四章 琼恩<br>◆ 风声峡是一长串名副其实的峡谷，漫长而曲折，时而环绕连绵起伏的风雪群山，时而成为不见天日的隐蔽峡道。<br>◆ 身下为无尽黑暗，头顶是皓月繁星，天地之间，别无他物。<br>第一百四十九章 席恩<br>◆ 在他身后，残塔矗立，很久以前，烈火焚尽了它的上层，留下锯齿状的尖端，犹如一顶王冠。太阳移动，高塔的阴影亦步亦趋，逐渐拉长，如一只黑手伸向席恩。日头还没落到墙后，他已完全落入黑手掌握。<br>第一百五十一章 琼恩<br>◆ 2024/01/27发表想法<br>牺牲总是需要信仰的依托<br>原文：长夜将至，我从今开始守望，至死方休。我将不娶妻，不封地，不生子。我将不戴宝冠，不争荣宠。我将尽忠职守，生死于斯。我是黑暗中的利剑，长城上的守卫，抵御寒冷的烈焰，破晓时分的光线，唤醒眠者的号角，守护王国的坚盾！我将生命与荣耀献给守夜人，今夜如此，夜夜皆然。<br>◆ 长夜将至，我从今开始守望，至死方休。我将不娶妻，不封地，不生子。我将不戴宝冠，不争荣宠。我将尽忠职守，生死于斯。我是黑暗中的利剑，长城上的守卫，抵御寒冷的烈焰，破晓时分的光线，唤醒眠者的号角，守护王国的坚盾！我将生命与荣耀献给守夜人，今夜如此，夜夜皆然。<br>◆ 即使白灵用牙齿狠狠撕扯游骑兵的小腿，科林还是踏稳了脚步。但在那一瞬间，当他扭身时，露出了破绽。琼恩一剑递出，反手一撩。游骑兵向外让开，似乎这一击未起作用，但紧接着喉头浮现一连串朱红的泪滴，明亮鲜活，犹如红宝石的项链。最后血如泉涌，断掌科林倒了下去。白灵的口鼻也在滴血，但长柄剑只锋尖有染，在最后的半寸。琼恩把冰原狼赶开，跪下来搂住兄弟。最后一丝光芒正从科林眼中褪去。“……锋利。”他说，伤残的手指举起又落下。他死了。<br>第一百五十七章 序幕<br>◆ 2024/01/31发表想法<br>这章就像单独的一篇短篇小说<br>原文：<br>第一百六十一章 提利昂<br>◆ 2024/02/01发表想法<br>这段矛盾写得真好<br>原文：<br>第一百六十五章 丹妮莉丝<br>◆ 实恰恰相反，茅屋里往往生出大个子，城堡中住的却是矮子<br>第一百六十九章 提利昂<br>◆ 太阳落山以后，蜡烛无法代替。<br>第一百七十一章 凯特琳<br>◆ 那一夜……那一夜，她……她安慰我，母亲。<br>第一百八十章 丹妮莉丝<br>◆ 丹妮回到甲板上时，黄昏已降临到奴隶湾的海面上。凭栏而立，眺望阿斯塔波，一眼望去，它的确十分美丽。天上繁星点点，而下方正如克拉兹尼的翻译所言，砖头金字塔上挂满了丝绸灯笼，沐浴在光辉之中。但底层的街道、广场和竞技场却是一片漆黑，而在那最最黑暗的兵营里，有些小男孩正拿剩饭喂小狗，这是他们在被阉割那天得到的宠物。<br>第一百八十一章 布兰<br>◆ 他闻到烤肉的香味，听到笑声和传令官嘹亮的喇叭声。一场比武大会即将展开，全国各地的勇士们都来参与。国王带着儿子龙太子亲自莅临。白袍剑客们也都来了，以欢迎他们新加入的弟兄。风暴领主和玫瑰领主通通到场，统治岩山的大狮子跟国王起了争执，没有前往，但他的许多臣属还是来了。泽地人没见过如此华丽壮观的场景，他知道自己或许永远也不会再有这个机会。当时他一心只想成为这幅宏伟画面中的一份子。<br>◆ 有时候骑士就是怪兽，布兰<br>◆ 狂野的头狼，沉默的二狼，以及最年轻的幼狼。<br>◆ 2024/02/08发表想法<br>分别是布兰登，奈德和班扬吧<br>原文：狂野的头狼，沉默的二狼，以及最年轻的幼狼。<br>第一百九十八章 琼恩<br>◆ 我懂，你打骨子里是个十足的野人。当他们一起欢笑、一起接吻时，这点很容易忘记。但随后其中一人会说些什么，做些什么，于是他会突然记起他们的世界之间隔着一堵墙。<br>◆ 2024/02/23发表想法<br>琼恩和耶哥蕊特思想分歧来源于不同的文明形式。<br>原文：我懂，你打骨子里是个十足的野人。当他们一起欢笑、一起接吻时，这点很容易忘记。但随后其中一人会说些什么，做些什么，于是他会突然记起他们的世界之间隔着一堵墙。<br>第一百九十九章 丹妮莉丝<br>◆ “不是凄惨，不是，但……雷加王子有一种忧郁，一种……”老人再度踌躇。“说，”她催促，“一种……？”“……一种毁灭的感觉。他生于悲哀之中，女王陛下，一生都有阴影笼罩。<br>第二百一章 詹姆<br>◆ 无数讥笑浮现在脑海，一个比一个残忍，但最终詹姆只耸耸肩：“因为我梦见了你。”说完他扬长而去。<br>第二百四章 艾莉亚<br>◆ 2024/02/25发表想法<br>这段对大雨的描写十分传神。<br>原文：雨水从铁黑的天空中降落，仿佛万把利剑直刺进棕绿色的湍流。它定有一里之宽，艾莉亚心想。上百棵树的顶端从盘旋流水中伸出，枝条如溺水者的胳膊盲目地抓向天空。岸边积着厚厚一层树叶，好比潮湿的垫子，远处河中央某些苍白肿胀的物体迅速顺流漂下，也许是鹿，或者是马。耳际有种低沉的轰鸣，好像无数恶狗即将发出咆哮。<br>◆ 雨水从铁黑的天空中降落，仿佛万把利剑直刺进棕绿色的湍流。它定有一里之宽，艾莉亚心想。上百棵树的顶端从盘旋流水中伸出，枝条如溺水者的胳膊盲目地抓向天空。岸边积着厚厚一层树叶，好比潮湿的垫子，远处河中央某些苍白肿胀的物体迅速顺流漂下，也许是鹿，或者是马。耳际有种低沉的轰鸣，好像无数恶狗即将发出咆哮。<br>第二百五章 琼恩<br>◆ 2024/02/25发表想法<br>这一章看得热泪盈眶，琼恩耶哥蕊特背誓的矛盾痛苦，身体上的痛苦，长城艰难处境的痛苦，亦师亦父莫尔蒙的死，朋友山姆的不知所踪，两百个兄弟就剩十几个的痛苦，临冬城精神故乡的失去，两个弟弟被杀的痛苦。琼恩此时的痛苦太揪心了。<br>原文：<br>◆ 我不会尖叫，琼恩看见烧得泛红光的尖刀时告诉自己，但这个誓言他也没能守住。唐纳·诺伊将他按紧，克莱达斯引导学士的手。琼恩没动，只是用拳头捶桌子，一下一下又一下。疼痛如此剧烈，他感到自己渺小、虚弱而无助，就像黑暗中呜咽的小孩。耶哥蕊特，他心想，烧焦皮肉的臭味充满鼻腔，自己的尖叫回响在耳际，耶哥蕊特，我没有办法，我有难处……痛苦开始减退，但紧接着钢铁再次触碰，他晕了过去。<br>第二百一十二章 琼恩<br>◆ 西方的天空变成血色的瘀青，头顶却依然是钴蓝，并渐渐转深，化为紫色，然后星星出来了<br>◆ 他发现耶哥蕊特仰面躺在司令塔底一片陈雪之上，双乳之间中了一箭。冰晶撒在她脸庞，月光照耀下，仿佛戴了个闪闪发光的银色面具。箭是黑色，琼恩发现，但带着白色的鸭毛。不是我的，他告诉自己，不是我的箭。但一切都没有分别了。<br>◆ 对此，她只微笑了一下：“还记得那个山洞吗？不要离开那山洞，我告诉过你的。”“我们回那山洞去，”他说，“我不会让你死，耶哥蕊特，不会让你死……”“噢，”耶哥蕊特捧起他的脸颊，“你什么都不懂，琼恩·雪诺。”她幽幽地叹口气，死了。<br>第二百四十五章 侍卫队长<br>◆ 奥芭娅·沙德总是走得太快。她总是在追赶永远追不上的东西<br>第二百四十八章 山姆威尔<br>◆ “你也一样，山姆。祝愿你们的旅途迅捷而又平安，替我好好照顾她和伊蒙，还有孩子。”琼恩那奇妙的微笑中透着悲哀。“拉起兜帽吧，山姆，瞧，雪花在你发际融化呢。”<br>第二百五十七章 布蕾妮<br>◆ 上次来女泉城，镇子是一片死气沉沉的废墟，空荡荡的街道，焚毁的房屋。现在街上到处是猪和儿童，大多数焚毁的建筑已被推倒，空地有的种上蔬菜，有的被商人和骑士们的帐篷占据。房屋也在兴建，石头客栈代替了被烧的木客栈，圣堂新添了石板屋顶，秋日凉爽的空气中充斥着锯子和锤子的声响。人们肩扛木材穿过街道，采石工的马车沿泥泞的小巷前进，许多人胸口佩戴着健步猎人标记。“士兵们在重建城镇。”她惊讶地说。<br>第二百五十八章 山姆威尔<br>◆ 雨滴在脸上，这感觉很好，山姆。犹如眼泪。请让我再多待一会儿吧，距离我上一次哭泣已经很久了。<br>第二百六十三章 布蕾妮<br>◆ “信任跟金币一样，要靠行动来挣取。”<br>◆ 夏格维一声也没笑，所有的抽泣都是布蕾妮自己发出的。她扔下匕首，浑身颤抖。<br>第二百六十五章 艾莉亚<br>◆ 表面上，奴隶是在向上百个不同的神灵哭喊，其实那是同一个神，有着上百张不同的脸孔而已……而他即是这个神的工具。<br>◆ “格雷果爵士，”她一边念诵，一边踏上四拱石桥。在桥中央，她看到旧衣贩码头的船桅。“邓森，‘甜嘴’拉夫，伊林爵士，马林爵士，瑟曦太后。”雨水哗啦啦地下，艾莉亚仰头望天，让雨点落在脸颊上，犹如愉快的舞蹈。<br>第二百六十九章 山姆威尔<br>◆ 我不能这样，没有我，伊蒙学士会死的，吉莉也将无人依靠。我一定要游起来，一定要……<br>第二百七十四章 布蕾妮<br>◆ 鹳鸟在潮水坑中跋涉，留下许多脚印，螃蟹则在浅滩表面疾走。空气带有海盐和腐败的味道，泥巴吸住人们的脚，直到人们用力，才“啪”的一声不情不愿地放开，伴随着吱吱嘎嘎的叹息。<br>第二百八十三章 高塔上的公主<br>◆ “复仇。”他声音很轻，仿佛害怕会有人听见，“正义。”道朗亲王用肿胀发炎的手指将一头玛瑙龙塞入她掌中，低语道：“血与火。”<br>第二百八十八章 山姆威尔<br>◆ 旧镇是座迷宫，而他没时间迷路。<br>◆ 他一定是打了瞌睡，因为接下来，他听到高台后的看门人在叫名字。山姆一下子站起来，然后意识到那不是他的名字，就又坐了回去。<br>◆ 去码头。魔法师向来雷厉风行，痛恨浪费时间。<br>第二百九十三章 序章<br>◆ 于是他就像白痴一样等着，回想着哈根、小肿和他漫长的一生里犯下的其他无数过错。<br>◆ 正如他母亲。她为小肿哭泣，却从未为我掉眼泪。那天早上，父亲把他从床上抓起来交给哈根时，她甚至没看他一眼。他被拖进森林，一路尖叫、踢打，直到父亲给了他一巴掌，叫他安静。“让你的同类料理你吧。”父亲把他丢到哈根脚边，扔下这么一句狠话。他没说错，瓦拉米尔颤抖着想，哈根教会了我太多东西。他教我如何打猎捕鱼，如何处理动物尸体，如何剔除鱼骨，如何在林间穿行。他还教会我狼灵之道和易形者的秘密，虽然我的天赋远在他之上。<br>◆ 真正的死亡来得很突然，他感到如波涛来袭般的寒冷，好似一头扎进结冻湖泊下的冰水。接着他发现自己已在月光照耀的雪地上游荡，他的族群紧跟在后。半个世界是黑的。<br>第二百九十四章 提利昂<br>◆ 八爪蜘蛛瓦里斯的任何朋友，都只有制得住才称得上朋友。<br>第二百九十五章 丹妮莉丝<br>◆ 没人知道哪条法律成立，于是大家统统恳求女王裁决。<br>第二百九十六章 琼恩<br>◆ 白狼终于开始奔跑，化为冰上的白箭，冲向夜之洞穴、那保存着阳光和暖意的地方，奔跑之中呼吸结霜。在无星的夜里，这面巨大悬崖犹如漆黑的石壁，笼罩在世界之上，但月亮出来，它又如结冻的溪流一般，放出冰冷苍白的光。<br>第二百九十八章 提利昂<br>◆ “她怎么过世的？”提利昂知道她已经死了，男人决不会深情地赞美抛弃自己的女人。<br>◆ 农民和劳工，他们被束缚在土地上。这里有果园、农场和矿藏……其中许多就在我名下，但我很少亲自打理。<br>◆ 他们用金子代替长剑打仗，公爵评价，钱固然有用，但战争还是要靠铁来赢得。<br>◆ 睡梦犹如不可见底的深井在身下展开，他拽着自己跳下去，任由黑暗吞没……<br>第三百零章 琼恩<br>◆ “放上去。”杀死心中的男孩。“快。”<br>第三百二章 戴佛斯<br>◆ 闪电撕裂了北方的蓝白色天空，镂刻出夜灯台漆黑的塔楼。六次心跳之后传来雷鸣，犹如遥远的鼓点。<br>第三百三章 琼恩<br>◆ 其实女人比男人坚强<br>◆ 火焰每次上蹿，都有更多枝条化为樱红色火焰，再变成焦黑灰烬。“光之王派来太阳、月亮和群星为我们指引照明，赐予火焰让我们穿越黑夜。”梅丽珊卓对野人们宣讲，“他的火焰无可匹敌。”“无可匹敌！”后党齐声应和。<br>◆ 红袍女的深红长袍迎风飞舞，红铜色头发犹如围绕她头部的光环。她的指尖射出长条的黄色火焰，犹如伸展的利爪。“自由民们！你们的伪神毫无威能。那只虚假的号角拯救不了任何人。而僭越的国王带来的唯有死亡、绝望和失败……但真正的王者此刻正站在你们面前。请看他的荣耀！”史坦尼斯·拜拉席恩拔出光明使者。<br>]]></description><link>culture\阅读\冰与火之歌.html</link><guid isPermaLink="false">Culture/阅读/冰与火之歌.md</guid><pubDate>Sat, 01 Jun 2024 02:42:12 GMT</pubDate></item><item><title><![CDATA[当我谈跑步时，我谈些什么]]></title><description><![CDATA[ 
 <br><br><br> [日]村上春树<br> 60个笔记<br><br>
<br>Pain is inevitable.Suffering is optional.这便是他的真言。其微妙的含义难以准确翻译，明知其不可译而硬译，不妨译成最简单的“痛楚难以避免，而磨难可以选择”。  
<br><br>
<br>持之以恒，不乱节奏。这对长期作业实在至为重要。一旦节奏得以设定，其余的问题便可以迎刃而解。然而要让惯性的轮子以一定的速度准确无误地旋转起来，对待持之以恒，何等小心翼翼也不为过。<br>

<br>就是这种微不足道、比比皆是的小事件，在我而言却自有意味，是有用的回忆。也许我在回忆这种种琐碎时，会不知不觉地面露微笑，抑或表情严肃。于是，在这些比比皆是的鸡零狗碎的尽头，我方才有今日，方才滞留在这考爱岛的北海岸。<br>

<br>头脑变得朦胧恍惚，无法完整地思考任何一件事情。可是当你不顾一切地坚持跑完，便觉得仿佛所有的东西都从躯体最深处挤榨了出来，一种类似自暴自弃的爽快感油然而生。<br>

<br>但不知何故，跟别人一决雌雄，我自小就不太在乎胜负成败。这种性格在长大成人后也大致未变。无论何事，赢了别人也罢输给别人也罢，都不太计较，倒是更关心能否达到为自己设定的标准。在这层意义上，长跑才是与我的心态完全吻合的体育运动。<br>

<br>换言之，对长跑选手而言，在跑完全程时能否感到自豪或类似自豪的东西，可能才是最重要的。<br>

<br>书的销量、得奖与否、评论的好坏，这些或许能成为成功与否的标志，却不能说是本质问题。写出来的文字是否达到了自己设定的基准，这才至为重要，这才容不得狡辩。<br>

<br>别人大概怎么都可以搪塞，自己的心灵却无法蒙混过关。在这层意义上，写小说很像跑全程马拉松，对于创作者而言，其动机安安静静、确确实实地存在于自身内部，不应向外部去寻求形式与标准。<br>

<br>我询问过眼科医生：“世上难道没有不会得老花眼的人吗？”他觉得颇为好笑似的回答：“这种人，我至今还一个也没见过呢。”<br>

<br>跑步不再像从前那样，是无限的乐事一桩。在我与跑步之间，这样一种徐缓的倦怠期前来造访了。其间有付出的努力得不到报偿的失望，有理应敞开的门户不知何时却被关上的茫然。我称这些为“跑者蓝调”。<br>

<br>整理好从日本带来的行李，办妥各种各样的事务性手续，一旦布置好此处的生活场所，我便再度热心地开始了跑步。敞开胸怀呼吸清晨那清冽的空气，蹬踏着跑惯了的地面，奔跑时的喜悦重又苏醒过来。脚步声、呼吸声与心脏的鼓动交织一处，营造出独特的交响节奏。<br>

<br>我跑步，只是跑着。原则上是在空白中跑步。也许是为了获得空白而跑步。即使在这样的空白当中，也有片时片刻的思绪潜入。这是理所当然的，人的心灵中不可能存在真正的空白。人类的精神还没有强大到足以坐拥真空的程度，即使有，也不是一以贯之的。<br>

<br>而首次经历就不那么简单了。我唯有将细微的判断暂且留待后日，先将眼前的东西照单全收，姑且与它一同生存下去，就好比对待天空、云朵和河流的态度。这些东西中无疑有某种滑稽可笑的成分，而根据心境的变化，它们未必一文不值。<br>

<br>仔细想一想，正是跟别人多少有所不同，人才得以确立自我，一直作为独立的存在。<br>

<br>我就是我，不是别人，这是我的一份重要的资产。心灵所受的伤，便是人为了这种自立性不得不支付给世界的代价。<br>

<br>就结果而言，在某种程度上，我也许是主动地追求孤绝。<br>

<br>唯其如此，我才必须不断地物理性地运动身体，有时甚至穷尽体力，来排除身体内部负荷的孤绝感。说是刻意而为，不如说是凭着直觉行事。<br>

<br>我在自制的小巧玲珑的空白之中、在亲切美好的沉默之中，一味地跑个不休。这是相当快意的事情，哪还能管别人如何言说？  
<br><br>
<br>老实说，连我都不觉得自己有经营才干，只是觉得一旦失败了便是穷途末路，才不顾一切拼命努力。勤勉耐劳、不惜体力，从前也罢现在也罢，都是我仅有的可取之处。<br>

<br>而我下决心“对啦，写篇小说试试”，便是在这个瞬间。我还清晰地记得那晴朗的天空，刚刚恢复了绿色的草坪的触感，以及球棒发出的悦耳声响。在那一刻，有什么东西静静地从天空飘然落下，我明白无误地接住了它。<br>

<br>然而，如果因为模棱两可、三心二意以失败告终，懊悔之情只怕久久无法拂去。<br>

<br>这一年的秋天，为了采集小说素材，去北海道旅行了约一个星期。这样在翌年四月之前，完成了长篇小说《寻羊冒险记》。我已孤注一掷，因此使出了浑身解数。我甚至觉得连自己身上没有的解数也来了个总动员。这是一部比《且听风吟》和《1973年的弹子球》篇幅长得多、架构宏大得多、故事性也强得多的作品。<br>

<br>“喏，跑起来！”逼迫我在不喜欢的时间去做不喜欢的事情，我从小就无法忍受这一点。反之，倘若是我自己想做的事情，在自己想做的时间爱做多少就做多少，我会做得比别人更加卖力。<br>

<br>我知道对感兴趣的领域和相关的事物，按照与自己相配的节奏，借助自己喜欢的方法去探求，就能极其高效地掌握知识和技术。比如说翻译技艺，也是这么无师自通的，说来就是自掏腰包，一点一<br>

<br>只是我想，年轻的时候姑且不论，人生中总有一个先后顺序，也就是如何依序安排时间和能量。到一定的年龄之前，如果不在心中制订好这样的规划，人生就会失去焦点，变得张弛失当。和与周遭的人们交往相比，我宁愿先确立能专心创作小说的稳定和谐的生活。<br>

<br>读者的脸庞无法直接看到，与他们构筑的人际关系似乎是概念性的。然而我始终将这种肉眼看不见的概念性的关系当作最有意义的东西，从而度过自己的人生。“人不可能做到八面玲珑，四方讨巧。”说白了，就是此意。<br>

<br>。什么才是公平，还得以长远的眼光来看才能看明白。阅读此文的读者，也许有人抱有这样的苦恼：“啊呀呀，一不小心体重马上就增加……”应当动用积极正面的思考，将这件事视为上天赐予的好运：容易看清红灯就够幸运了。不过，这么去思考问题也不容易。<br>

<br>然而长年累月地坚持这种生活，久而久之，就技术或体力而言，我都能高效地找寻到新的水源，在坚固的磐石上凿穴钻孔；感觉一个水源变得匮乏时，也能果决而迅疾地移到下一个去。而习惯仅仅依赖一处自然水源的人，冷不丁地这么做，只怕轻易做不来。<br>

<br>人生基本是不公平的。这一点毋庸置疑。即便身处不公之地，我想还是可以追求某种“公正”。也许得费时耗力，又或许费了时耗了力，却仍是枉然。这样的“公平”是否值得刻意追求，当然要靠各人自己裁量了。<br>

<br>。人生来如此，喜欢的事自然可以坚持下去，不喜欢的事怎么也坚持不了。意志之类恐怕也与“坚持”有一丁点瓜葛，然而无论何等意志坚强的人、何等争强好胜的人，不喜欢的事情终究做不到持之以恒；就算做到了，也对身体不利。<br>

<br>那些丝毫不想跑步的人，或者体质不适合跑步的人，不分青红皂白让他们统统去长跑，这是何等无意义的拷问。我很想发出忠告：趁着还没有出现问题，赶快取消让初中生和高中生一律长跑的做法。<br>

<br>我们在学校里学到的最重要的东西，就是“最重要的东西在学校里学不到”这个真理。  
<br><br>
<br>老人们坐在咖啡馆前的桌子旁，一边用小小的杯子喝早晨的咖啡，一边无言地用目光追逐着我奔跑的身姿，仿佛在目击历史某个不起眼的细节。<br>

<br>任凭积累了多少经验，增添了多少岁，还是一再重复相同的旧事。<br>

<br>是的，这种模式无论如何都不接受改变。我以为。如果必须同这种模式和平共处，我只能通过执着的反复改变或扭曲自己，将它吸收进来，成为人格的一部分。哈哈。  
<br><br>
<br>肌肉也同有血有肉的动物一般无二，它也愿意过更舒服的日子，不继续给它负荷，它便会心安理得地将记忆除去。想再度输入的话，必须得从头开始，将同样的模式重复一遍。<br>

<br>当然不能让它超负荷，但一定得和它维持着绝不松懈的紧张关系。处理个中的钩心斗角，有经验的跑者自然得心应手。<br>

<br>直到今日，我清晨跑在神宫外苑或赤坂御所周边的跑道上时，还不时想起他们来。转过弯道时，有时觉得他们好像呼着白气，正从对面默默跑过来。经受了那般残酷训练的他们，胸怀的希望、梦想和计划究竟都消失到了哪里呢？人的思绪也会伴随着肉体的死亡，草草消逝无踪么？<br>

<br>坐在书桌前，将神经如同激光束一般集于一点，动用想象力从“无”的地平线上催生出故事来，挑选出一个个正确的词语，让所有的情节发展准确无误——这样一种工作，与一般人想象的相比，更为长久地需要远为巨大的能量。这固然不必运动身体，劳筋动骨的劳动却在体内热火朝天地展开。当然，思索问题的是脑子，小说家却要披挂着叫“故事”的全副装备，动用全身进行思考，这要求作家无情地驱使（许多时候是奴役）肢体能力。<br>

<br>世上时时有人嘲笑每日坚持跑步的人：“难道就那么盼望长命百岁？”我却觉得因为希冀长命百岁而跑步的人大概不太多。怀着“不能长命百岁不打紧，至少想在有生之年过得完美”这种心情跑步的人，只怕多得多。<br>

<br>呼哧呼哧地短促喘气的是新手，呼吸安静匀称的则是老手。他们心跳徐缓，一面沉湎于思考之中，一面铭刻下时间的痕迹。  
<br><br>
<br>大小不同形状各异的云朵随兴所至，突然现身遂又逝去。河流沐浴着太阳的光辉，将那白色光影的去来忽而鲜明忽而暧昧地映在水面上。根据季节的不同，简直有如切换开关，风向会发生变化。而根据触感、气味和风向，我们能明确地感受到季节推移的刻度。在这样一种伴随着真实感的流移变幻之中，我认识到自己在自然这巨大的马赛克当中，只不过是一块微小的彩片；亦如河里的水，不过是流过桥下奔向大海的、可以置换的自然的一部分。<br>

<br>所谓艺术行为，从最初的缘起就含有不健康的、反社会的要素。  
<br><br>
<br>独自跑完一百公里究竟有何意义，我不得而知。然而，它虽不是日常之为，却不违为人之道，恐怕会将某种特别的认知带入你的意识，让你对自身的看法中添进一些新意。你的人生光景可能会改变色调和形状——或多或少，或好或坏。我自己就有这样的改变。<br>

<br>“自己”这一存在的确在这里，与之相伴，“自我”这一意识也在。然而我努力将它们看作“便宜的形式”。这是一种奇妙的思考方式、一种奇妙的感觉，因为这是拥有意识的人试图去否定意识。我不得不将自己驱赶进无机的场所里去，即便只是一小步。我本能地悟出，唯有如此，才是存活下去的唯一出路。<br>

<br>不管奔跑速度降低了多少，我都不能走，这是原则。违背了自己定下的原则，哪怕只有一次，以后就将违背更多的原则，想跑完这场比赛就难上加难了。<br>

<br>我大约超越了二百多号人。至少我数到了二百人。而被别人从背后赶超上来，仅有一两次。我逐一计算超越的跑者人数，乃是因为无所事事。自己处于这深度的疲劳中，将这疲劳全盘接纳，还能扎扎实实地继续奔跑——对我来说，在这个世界上，没有比这更高的愿望了。<br>

<br>跑到最后，不仅是肉体的苦痛，甚至连自己到底是谁、此刻在干什么之类，都已从脑海中消失殆尽。这理当是十分可笑的心情，可是我连这份可笑都无法感受到了。在这里，跑步几乎达到了形而上学的领域。仿佛先有了行为，然后附带性地才有了我的存在。我跑，故我在。<br>

<br>跑过七十五公里，疲劳感突然销声匿迹后，那段意识的空白之中甚至有某种哲学或宗教的妙趣。其中有强迫我内省的东西。也许是因为这个，我再也无法以从前那种不顾一切、单纯积极的态度面对跑步了。  
<br><br>
<br>这个世界需要一个特定的恶人，可以供人们指名道姓，千夫所指：“全都怪你！”<br>

<br>许多时候，要想实实在在地掌握什么，肉体的疼痛必不可缺。<br>

<br>哪怕成绩大幅下降，我也会朝着跑完全程马拉松这个目标，如同从前一样（有时还会超过从前）继续努力。是啊，不管别人说什么，这是我与生俱来的性格，就好似蝎子天生要螫人，蝉天生要死叮着树一般，又好比鲑鱼注定要回到它出生的河流，一对野鸭注定要相互追求一样。<br>

<br>突然有一天，我出于喜欢开始写小说。又有一天，我出于喜欢开始在马路上跑步。不拘什么，按照喜欢的方式做喜欢的事，我就是这样生活的。纵然受到别人阻止，遭到恶意非难，我都不曾改变。这样一个人，又能向谁索求什么呢？<br>

<br>我仰望天空。能看到一丝一毫的爱心么？不，看不到。只有太平洋上空悠然飘来浮去、无所事事的夏日云朵。云朵永远沉默无语。它们什么都不对我说。或许我不该仰望天空，应当将视线投去我的内部。我试着看向自己的内部，就如同窥视深深的井底。那里可以看到爱心么？不，看不到。看到的只有我的性格。我那个人的、顽固的、缺乏协调性的，每每任性妄为又常常怀疑自己的，哪怕遇到了痛苦也想在其中发现可笑之处的性格。我拎着它，就像拎着一个古旧的旅行包，走过了漫长的历程。我并不是因为喜欢才拎着它。与内容相比，它显得太沉重，外观也不起眼，还到处绽开了线。我只是没有别的东西可拎，无奈才一直拎着它。然而，我心中却对它怀有某种依依不舍的情感。<br>

<br>换言之，我依然拎着那只旧包，向着恐怕更甚的“虎头蛇尾”，向着沉默寡言的巴洛克式的圆熟——表达得更为谦虚点，便是“进化的尽头”——前行。  
<br><br>
<br>诸位恐怕熟知，十六岁是一个让人极不省心的年龄：会一一在意琐细的小事，又无力客观地把握自己的位置；为了微不足道的理由便莫名地扬扬自得，也容易产生自卑感。随着年龄的增长，经历了形形色色的失误，该拾起来的拾起来，该抛弃掉的抛弃掉，才会有这样的认识：“缺点和缺陷，如果一样样去数，势将没完没了。可是优点肯定也有一些。我们只能凭着手头现有的东西去面对世界。”<br>

<br>一旦无法自然地呼吸，恐惧就会支配全身，肌肉变得僵硬，胸口无缘无故地怦怦乱跳，手脚不听使唤，脸不敢沉入水里去。这就是所谓的惊慌失措。<br>

<br>不论到了多大年龄，只要人还活着，对自己就会有新的发现。不论赤身裸体地在镜子前站立多长时间，都不可能映出人的内面来。  
<br><br>
<br>我敬爱的作家雷蒙德·卡佛的短篇集的标题What We Talk About When We Talk About Love，<br>

<br>最后，我愿意将这本书献给迄今为止，在世界各地的路上与我交臂而过的所有跑者。如果没有你们，我一定不会如此坚持跑步。  
<br> 来自微信读书<br>]]></description><link>culture\阅读\当我谈跑步时，我谈些什么.html</link><guid isPermaLink="false">Culture/阅读/当我谈跑步时，我谈些什么.md</guid><pubDate>Mon, 09 Sep 2024 11:42:53 GMT</pubDate></item><item><title><![CDATA[机器学习-周志华]]></title><description><![CDATA[ 
 <br><br>《机器学习》<br>周志华<br>
149个笔记<br>点评<br>◆ 2024/04/14 认为一般<br>其实我觉得作为教材还是有点跳跃了，有些式子的推导很跳跃让人很疑惑。比如BP算法里的gj突然出现，其实就是少了一个令字，让人很不解。但总体来说它构建了一个完整的机器学习知识框架。<br>1.1 引言<br>◆ 机器学习正是这样一门学科，它致力于研究如何通过计算的手段，利用经验来改善系统自身的性能，在计算机系统中，“经验”通常以“数据”形式存在，因此，机器学习所研究的主要内容，是关于在计算机上从数据中产生“模型”(model)的算法，即“学习算法”(learning algorithm)。<br>1.2 基本术语<br>◆ 由于空间中的每个点对应一个坐标向量，因此我们也把一个示例称为一个“特征向量”(feature vector)。<br>◆ 从数据中学得模型的过程称为“学习”(learning)或“训练”(training)，这个过程通过执行某个学习算法来完成<br>◆ 将“label”译为“标记”而非“标签”<br>◆ 我们需获得训练样本的“结果”信息，例如“（（色泽=青绿；根蒂=蜷缩;敲声=浊响），好瓜）”。这里关于示例结果的信息，例如“好瓜”，称为“标记”(label)；拥有了标记信息的示例，则称为“样例”(example)。<br>◆ 用(xi,yi)表示第i个样例，其中yi∈[插图]是示例xi的标记，[插图]是所有标记的集合，亦称“标记空间”(label space)或“输出空间”。亦称“负类”。<br>◆ 若我们欲预测的是离散值，例如“好瓜”“坏瓜”，此类学习任务称为“分类”(classification)；若欲预测的是连续值，例如西瓜成熟度0.95、0.37，此类学习任务称为“回归”(regression)。<br>◆ 学得模型后，使用其进行预测的过程称为“测试”(testing)，被预测的样本称为“测试样本”(testing sample)。<br>◆ 我们还可以对西瓜做“聚类”(clustering)，即将训练集中的西瓜分成若干组，每组称为一个“簇”(cluster)；<br>◆ 需说明的是，在聚类学习中，“浅色瓜”“本地瓜”这样的概念我们事先是不知道的，而且学习过程中使用的训练样本通常不拥有标记信息。<br>◆ 根据训练数据是否拥有标记信息，学习任务可大致划分为两大类：“监督学习”(supervised learning)和“无监督学习”(unsupervised learning)，分类和回归是前者的代表，而聚类则是后者的代表。<br>◆ 学得模型适用于新样本的能力，称为“泛化”(generalization)能力。<br>◆ 通常假设样本空间中全体样本服从一个未知“分布”(distribution)[插图]，我们获得的每个样本都是独立地从这个分布上采样获得的，即“独立同分布”<br>1.3 假设空间<br>◆ 归纳(induction)与演绎(deduction)是科学推理的两大基本手段。前者是从特殊到一般的“泛化”(generalization)过程，即从具体的事实归结出一般性规律；后者则是从一般到特殊的“特化”(specialization)过程，即从基础原理推演出具体状况。<br>◆ 。概念学习技术目前研究、应用都比较少，因为要学得泛化性能好且语义明确的概念实在太困难了，现实常用的技术大多是产生“黑箱”模型。<br>◆ (A∧B)∨(C∧D)的析合范式。<br>◆ “记住”训练样本，就能力。如果仅仅把训练集中的瓜“记住”，是所谓的“机械学习”[Cohen and Feigenbaum,1983]，或<br>◆ 可以有许多策略对这个假设空间进行搜索，例如自顶向下、从一般到特殊，或是自底向上、从特殊到一般，搜索过程中可以不断删除与正例不一致的假设、和（或）与反例一致的假设。<br>◆ 可能有多个假设与训练集一致，即存在着一个与训练集一致的“假设集合”，我们称之为“版本空间”(version space)。<br>2.3 性能度量<br>◆ [插图]查准率P与查全率R分别定义为[插图]查准率和查全率是一对矛盾的度量。一般来说，查准率高时，查全率往往偏低；而查全率高时，查准率往往偏低。<br>◆ 以信息检索应用为例，逐条向用户反馈其可能感兴趣的信息，即可计算出查全率、查准率。<br>◆ 2024/03/19发表想法<br>以预测概率排序，划分临界值不断降低，每下降一次求一次P,R。最后平滑连接得到PR曲线。<br>原文：在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在最后的则是学习器认为“最不可能”是正例的样本。按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率。<br>◆ 在很多情形下，我们可根据学习器的预测结果对样例进行排序，排在前面的是学习器认为“最可能”是正例的样本，排在最后的则是学习器认为“最不可能”是正例的样本。按此顺序逐个把样本作为正例进行预测，则每次可以计算出当前的查全率、查准率。<br>◆ 以查准率为纵轴、查全率为横轴作图，就得到了查准率-查全率曲线，简称“P-R曲线”<br>◆ 若一个学习器的P-R曲线被另一个学习器的曲线完全“包住”，则可断言后者的性能优于前者<br>◆ “平衡点”（Break-Even Point，简称BEP）就是这样一个度量，它是“查准率=查全率”时的取值<br>◆ 但BEP还是过于简化了些，更常用的是F1度量：[插图]F1是基于查准率与查全率的调和平均(harmonicmean)定义的：[插图]<br>◆ F1度量的一般形式――Fβ，能让我们表达出对查准率/查全率的不同偏好，它定义为[插图]Fβ则是加权调和平均：[插图]与算术平均[插图]和几何平均[插图]相比，调和平均更重视较小值。<br>◆ β＞0度量了查全率对查准率的相对重要性[Van Rijsbergen,1979]。β=1时退化为标准的F1；β＞1时查全率有更大影响；β＜1时查准率有更大影响。<br>◆ “宏查准率”(macro-P)、“宏查全率”(macro-R)，以及相应的“宏F1”(macro-F1)：[插图]<br>◆ 分别记为[插图]，再基于这些平均值计算出“微查准率”(micro-P)、“微查全率”(micro-R)和“微F1”(micro-F1)：[插图][插图]<br>◆ 很多学习器是为测试样本产生一个实值或概率预测，然后将这个预测值与一个分类阈值(threshold)进行比较，若大于阈值则分为正类，否则为反类。<br>◆ ROC全称是“受试者工作特征”(Receiver Operating Characteristic)曲线，它源于“二战”中用于敌机检测的雷达信号分析技术，二十世纪六七十年代开始被用于一些心理学、医学检测应用中，此后被引入机器学习领域[Spackman,1989]<br>◆ ROC曲线的纵轴是“真正例率”（True Positive Rate，简称TPR），横轴是“假正例率”（False Positive Rate，简称FPR），基于表2.1中的符号，两者分别定义为[插图]<br>◆ 2024/03/19发表想法<br>增加正例正确率时向上移动，增加反例错误率时往右移。<br>原文：绘图过程很简单：给定m+个正例和m-个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为0，在坐标(0,0)处标记一个点。然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例。设前一个标记点坐标为(x,y)，当前若为真正例，则对应标记点的坐标为[插图]；当前若为假正例，则对应标记点的坐标为[插图]，然后用线段连接相邻点即得。<br>◆ 绘图过程很简单：给定m+个正例和m-个反例，根据学习器预测结果对样例进行排序，然后把分类阈值设为最大，即把所有样例均预测为反例，此时真正例率和假正例率均为0，在坐标(0,0)处标记一个点。然后，将分类阈值依次设为每个样例的预测值，即依次将每个样例划分为正例。设前一个标记点坐标为(x,y)，当前若为真正例，则对应标记点的坐标为[插图]；当前若为假正例，则对应标记点的坐标为[插图]，然后用线段连接相邻点即得。<br>◆ 2024/03/19发表想法<br>上底加下底乘高除二<br>原文：此时如果一定要进行比较，则较为合理的判据是比较ROC曲线下的面积，即AUC(Area UnderROC Curve)，如图2.4所示。<br>
从定义可知，AUC可通过对ROC曲线下各部分的面积求和而得。假定ROC曲线是由坐标为{(x1,y1)，(x2,y2)，...，(xm,ym)}的点按序连接而形成(x1=0,xm=1)，参见图2.4(b)，则AUC可估算为<br>
[插图]<br>◆ 此时如果一定要进行比较，则较为合理的判据是比较ROC曲线下的面积，即AUC(Area UnderROC Curve)，如图2.4所示。从定义可知，AUC可通过对ROC曲线下各部分的面积求和而得。假定ROC曲线是由坐标为{(x1,y1)，(x2,y2)，...，(xm,ym)}的点按序连接而形成(x1=0,xm=1)，参见图2.4(b)，则AUC可估算为[插图]<br>◆ 2024/03/19发表想法<br>往右走的时候产生了一个正方形即1的损失，分母为m+m-。即ROC曲线上半部分面积。<br>原文：给定m+个正例和m-个反例，令D+和D-分别表示正、反例集合，则排序“损失”(loss)定义为<br>
[插图]<br>◆ 给定m+个正例和m-个反例，令D+和D-分别表示正、反例集合，则排序“损失”(loss)定义为[插图]<br>◆ [插图]rank对应的是ROC曲线之上的面积：若一个正例在ROC曲线上对应标记点的坐标为(x,y)，则x恰是排序在其之前的反例所占的比例，即假正例率。因此有AUC=1-[插图]rank。　(2.22)<br>2.4 比较检验<br>◆ 在很多时候我们并非仅做一次留出法估计，而是通过多次重复留出法或是交叉验证法等进行多次训练/测试，这样会得到多个测试错误率，此时可使用“t检验”(t-test)。假定我们得到了k个测试错误率，[插图]1,[插图]2,...,[插图]k，则平均测试错误率μ和方差σ2为[插图]考虑到这k个测试错误率可看作泛化错误率[插图]0的独立采样，则变量[插图]服从自由度为k-1的t分布，如图2.7所示。<br>◆ [插图]e01=e10通常很小，需考虑连续性校正，因此分子中有-1项。若我们做的假设是两学习器性能相同，则应有e01=e10，那么变量|e01-e10|应当服从正态分布。McNemar检验考虑变量[插图]中文称为“卡方分布”。<br>2.5 偏差与方差<br>◆ 泛化误差可分解为偏差、方差与噪声之和。<br>◆ 回顾偏差、方差、噪声的含义：偏差(2.40)度量了学习算法的期望预测与真实结果的偏离程度，即刻画了学习算法本身的拟合能力；方差(2.38)度量了同样大小的训练集的变动所导致的学习性能的变化，即刻画了数据扰动所造成的影响；噪声(2.39)则表达了在当前任务上任何学习算法所能达到的期望泛化误差的下界，即刻画了学习问题本身的难度。<br>3.1 基本形式<br>◆ 2024/03/26发表想法<br>在多元线性回归中，3.1式子中w和x都是向量，x代表不同特性向量，w则是权重向量。<br>原文：f(x)=w1x1+w2x2+...+wdxd+b,　(3.1)<br>
一般用向量形式写成<br>
f(x)=wTx+b,　(3.2)<br>◆ f(x)=w1x1+w2x2+...+wdxd+b,　(3.1)一般用向量形式写成f(x)=wTx+b,　(3.2)<br>◆ 许多功能更为强大的非线性模型(nonlinear model)可在线性模型的基础上通过引入层级结构或高维映射而得。<br>3.2 线性回归<br>◆ “线性回归”(linear regression)试图学得一个线性模型以尽可能准确地预测实值输出标记。<br>◆ 均方误差亦称平方损失(square loss)。<br>◆ 试图让均方误差最小化，即[插图]w,b表示w和b的解。最小二乘法用途很广，不仅限于线性回归。<br>◆ 令式(3.5)和(3.6)为零可得到w和b最优解的闭式(closed-form)解[插图][插图]其中[插图]为x的均值。<br>◆ f(xi)=wTxi+b，使得f(xi)[插图]yi。亦称“多变量线性回归”。这称为“多元线性回归”(multivariate linear regression)。<br>◆ 我们把w和b吸收入向量形式[插图]=(w;b)，相应的，把数据集D表示为一个m×(d+1)大小的矩阵X，其中每行对应于一个示例，该行前d个元素对应于示例的d个属性值，最后一个元素恒置为1，即[插图]再把标记也写成向量形式y=(y1;y2;...;ym)，则类似于式(3.4)，有[插图]令上式为零可得[插图]最优解的闭式解，但由于涉及矩阵逆的计算，比单变量情形要复杂一些。下面我们做一个简单的讨论。当XTX为满秩矩阵(full-rank matrix)或正定矩阵(positive definite matrix)时，令式(3.10)为零可得[插图]*=(XTX)-1XTy,(3-11)其中(XTX)-1是矩阵(XTX)的逆矩阵。令[插图]i=(xi;1)，则最终学得的多元线性回归模型为[插图]<br>◆ 现实任务中XTX往往不是满秩矩阵。<br>◆ 2024/03/26发表想法<br>岭回归在最小二乘法后面加了个L2范数的平方，让XTX始终可逆，而Lasso回归则是在最小二乘法后面加了个L1范数。ps:L1范数即绝对值之和。L2范数即平方和开根号。是否有同时加两种范数的回归方法呢，有，Elastic回归。<br>原文：选择哪一个解作为输出，将由学习算法的归纳偏好决定，常见的做法是引入正则化(regularization)项。<br>◆ 2024/03/26发表想法<br>岭回归<br>原文：选择哪一个解作为输出，将由学习算法的归纳偏好决定，常见的做法是引入正则化(regularization)项。<br>◆ 选择哪一个解作为输出，将由学习算法的归纳偏好决定，常见的做法是引入正则化(regularization)项。<br>◆ 2024/03/26发表想法<br>广义线性回归<br>原文：可否令模型预测值逼近y的衍生物呢？譬如说，假设我们认为示例所对应的输出标记是在指数尺度上变化，那就可将输出标记的对数作为线性模型逼近的目标，即<br>
lny=wTx+b.　(3.14)<br>
这就是“对数线性回归”(log-linear regression)，它实际上是在试图让ewTx+b逼近y。<br>◆ 可否令模型预测值逼近y的衍生物呢？譬如说，假设我们认为示例所对应的输出标记是在指数尺度上变化，那就可将输出标记的对数作为线性模型逼近的目标，即lny=wTx+b.　(3.14)这就是“对数线性回归”(log-linear regression)，它实际上是在试图让ewTx+b逼近y。<br>◆ 但实质上已是在求取输入空间到输出空间的非线性函数映射，<br>◆ 2024/04/01发表想法<br>在线性模型的基础上套一个单调可微的函数<br>原文：考虑单调可微函数g(·)，令<br>
y=g-1(wTx+b),　(3.15)<br>◆ 考虑单调可微函数g(·)，令y=g-1(wTx+b),　(3.15)<br>◆ 其中函数g(·)称为“联系函数”(link function)。显然，对数线性回归是广义线性模型在g(·)=ln(·)时的特例。<br>3.3 对数几率回归<br>◆ 只需找一个单调可微函数将分类任务的真实标记y与线性回归模型的预测值联系起来。亦称Heaviside函数。<br>◆ 最理想的是“单位阶跃函数”(unit-step function)[插图]即若预测值z大于零就判为正例，小于零则判为反例，预测值为临界值零则可任意判别，如图3.2所示。<br>◆ 2024/03/26发表想法<br>这里的z就是y(x)，把原本的回归问题得到的结果转化为分类的依据。<br>原文：对数几率函数(logistic function)正是这样一个常用的替代函数：<br>◆ 对数几率函数(logistic function)正是这样一个常用的替代函数：[插图]<br>◆ Sigmoid函数即形似S的函数。对率函数是Sigmoid函数最重要的代表，在（第5章 神经网络）将看到它在神经网络中的重要作用。<br>◆ 2024/03/26发表想法<br>好瓜的概率比上坏瓜的概率取对数<br>原文：[插图]<br>◆ [插图]<br>◆ 若将y视为样本x作为正例的可能性，则1-y是其反例可能性，两者的比值[插图]称为“几率”(odds)，反映了x作为正例的相对可能性。对几率取对数则得到“对数几率”（log odds，亦称logit）<br>◆ 式(3.18)实际上是在用线性回归模型的预测结果去逼近真实标记的对数几率，因此，其对应的模型称为“对数几率回归”（logisticregression，亦称logit regression）。特别需注意到，虽然它的名字是“回归”，但实际却是一种分类学习方法。<br>◆ 我们可通过“极大似然法”(maximum likelihood method)来估计w和b。给定数据集[插图]，对率回归模型最大化“对数似然”(loglikelihood)<br>◆ 2024/03/26发表想法<br>为什么要求积再取对数变成加和形式，我怎么不直接对似然求和？<br>原文：[插图]<br>
即令每个样本属于其真实标记的概率越大越好。<br>◆ [插图]即令每个样本属于其真实标记的概率越大越好。<br>3.4 线性判别分析<br>◆ 线性判别分析（Linear Discriminant Analysis，简称LDA）<br>◆ 2024/03/26发表想法<br>不同类中心距离越大越好，同类协方差越小越好<br>原文：LDA的思想非常朴素：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。<br>◆ LDA的思想非常朴素：给定训练样例集，设法将样例投影到一条直线上，使得同类样例的投影点尽可能接近、异类样例的投影点尽可能远离；在对新样本进行分类时，将其投影到同样的这条直线上，再根据投影点的位置来确定新样本的类别。<br>3.5 多分类学习<br>◆ 最经典的拆分策略有三种：“一对一”（One vs.One，简称OvO）、“一对其余”（One vs.Rest，简称OvR）和“多对多”（Many vs.Many，简称MvM）。<br>◆ 为什么称为“纠错输出码”呢？这是因为在测试阶段，ECOC编码对分类器的错误有一定的容忍和修正能力。例如图3.5(a)中对测试示例的正确预测编码是(-1,+1,+1,-1,+1)，假设在预测时某个分类器出错了，例如f2出错从而导致了错误编码(-1,-1,+1,-1,+1)，但基于这个编码仍能产生正确的最终分类结果C3。一般来说，对同一个学习任务，ECOC编码越长，纠错能力越强。然而，编码越长，意味着所需训练的分类器越多，计算、存储开销都会增大；另一方面，对有限类别数，可能的组合数目是有限的，码长超过一定范围后就失去了意义。<br>◆ 对同等长度的编码，理论上来说，任意两个类别之间的编码距离越远，则纠错能力越强。因此，在码长较小时可根据这个原则计算出理论最优编码。然而，码长稍大一些就难以有效地确定最优编码，事实上这是NP难问题。<br>3.6 类别不平衡问题<br>◆ 类别不平衡(class-imbalance)就是指分类任务中不同类别的训练样例数目差别很大的情况。<br>◆ [插图]无偏采样意味着真实样本总体的类别比例在训练集中得以保持。然而，当训练集中正、反例的数目不同时，令m+表示正例数目，m-表示反例数目，则观测几率是[插图]，由于我们通常假设训练集是真实样本总体的无偏采样，因此观测几率就代表了真实几率。于是，只要分类器的预测几率高于观测几率就应判定为正例，即[插图]但是，我们的分类器是基于式(3.46)进行决策，因此，需对其预测值进行调整，使其在基于式(3.46)决策时，实际是在执行式(3.47)。要做到这一点很容易，只需令[插图]亦称“再平衡”(rebalance)。这就是类别不平衡学习的一个基本策略――“再缩放”(rescaling)。<br>◆ 主要因为“训练集是真实样本总体的无偏采样”这个假设往往并不成立，也就是说，我们未必能有效地基于训练集观测几率来推断出真实几率。<br>◆ 第一类是直接对训练集里的反类样例进行“欠采样”(undersampling)，即去除一些反例使得正、反例数目接近，然后再进行学习；第二类是对训练集里的正类样例进行“过采样”(oversampling)，即增加一些正例使得正、反例数目接近，然后再进行学习；第三类则是直接基于原始训练集进行学习，但在用训练好的分类器进行预测时，将式(3.48)嵌入到其决策过程中，称为“阈值移动”(threshold-moving)。<br>◆ 需注意的是，过采样法不能简单地对初始正例样本进行重复采样，否则会招致严重的过拟合；过采样法的代表性算法SMOTE[Chawlaet al.,2002]是通过对训练集里的正例进行插值来产生额外的正例。另一方面，欠采样法若随机丢弃反例，可能丢失一些重要信息；欠采样法的代表性算法EasyEnsemble[Liu et al.,2009]则是利用集成学习机制，将反例划分为若干个集合供不同学习器使用，这样对每个学习器来看都进行了欠采样，但在全局来看却不会丢失重要信息。<br>◆ “再缩放”也是“代价敏感学习”(cost-sensitive learning)的基础。在代价敏感学习中将式(3.48)中的m-/m+用cost+/cost-代替即可，其中cost+是将正例误分为反例的代价，cost-是将反例误分为正例的代价。<br>3.7 阅读材料<br>◆ 多分类学习中虽然有多个类别，但每个样本仅属于一个类别。如果希望为一个样本同时预测出多个类别标记，例如一幅图像可同时标注为“蓝天”、“白云”、“羊群”、“自然场景”，这样的任务就不再是多分类学习，而是“多标记学习”(multi-label learning)<br>4.2 划分选择<br>◆ “编号”将产生17个分支，每个分支结点仅包含一个样本，这些分支结点的纯度已达最大。然而，这样的决策树显然不具有泛化能力，无法对新样本进行有效预测。<br>4.3 剪枝处理<br>◆ 剪枝(pruning)是决策树学习算法对付“过拟合”的主要手段<br>◆ 预剪枝是指在决策树生成过程中，对每个结点在划分前先进行估计，若当前结点的划分不能带来决策树泛化性能提升，则停止划分并将当前结点标记为叶结点<br>◆ 如何判断决策树泛化性能是否提升呢？这可使用2.2节介绍的性能评估方法。本节假定采用留出法，即预留一部分数据用作“验证集”以进行性能评估。<br>◆ 在划分之前，所有样例集中在根结点。若不进行划分，则根据算法4.2第6行，该结点将被标记为叶结点，其类别标记为训练样例数最多的类别，假设我们将这个叶结点标记为“好瓜”<br>◆ 预剪枝基于“贪心”本质禁止这些分支展开，给预剪枝决策树带来了欠拟合的风险。<br>◆ 对结点②，若将其领衔的子树替换为叶结点，则替换后的叶结点包含编号为{1,2,3,14}的训练样例，叶结点标记为“好瓜”。此时决策树的验证集精度提高至71.4%。于是，后剪枝策略决定剪枝。<br>◆ 一般情形下，后剪枝决策树的欠拟合风险很小，泛化性能往往优于预剪枝决策树。但后剪枝过程是在生成完全决策树之后进行的，并且要自底向上地对树中的所有非叶结点进行逐一考察，因此其训练时间开销比未剪枝决策树和预剪枝决策树都要大得多。<br>4.4 连续与缺失值<br>◆ 我们需解决两个问题：(1)如何在属性值缺失的情况下进行划分属性选择？(2)给定划分属性，若样本在该属性上的值缺失，如何对样本进行划分？<br>5.1 神经元模型<br>◆ 在这个模型中，神经元接收到来自n个其他神经元传递过来的输入信号，这些输入信号通过带权重的连接(connection)进行传递，神经元接收到的总输入值将与神经元的阈值进行比较，然后通过“激活函数”(activation function)处理以产生神经元的输出。[插图]<br>5.2 感知机与多层网络<br>◆ 感知机(Perceptron)由两层神经元组成，如图5.3所示，输入层接收外界输入信号后传递给输出层，输出层是M-P神经元，亦称“阈值逻辑单元”(threshold logic unit)。<br>◆ 更一般地，给定训练数据集，权重wi(i=1,2,...,n)以及阈值[插图]可通过学习得到。阈值[插图]可看作一个固定输入为-1.0的“哑结点”(dummy node)所对应的连接权重wn+1，这样，权重和阈值的学习就可统一为权重的学习<br>◆ 感知机学习规则非常简单，对训练样例(x,y)，若当前感知机的输出为[插图]，则感知机权重将这样调整：[插图]xi是x对应于第i个输η通常设置为一个小正数，例如0.1。其中η∈(0,1)称为学习率(learning rate).从式(5.1)可看出，若感知机对训练样例(x,y)预测正确，即[插图]=y，则感知机不发生变化，否则将根据错误的程度进行权重调整<br>◆ 感知机只有输出层神经元进行激活函数处理，即只拥有一层功能神经元(functional neuron)，其学习能力非常有限。事实上，上述与、或、非问题都是线性可分(linearly separable)的问题。<br>◆ “前馈”并不意味着网络中信号不能向后传，而是指网络拓扑结构上不存在环或回路；<br>5.3 误差逆传播算法<br>◆ 误差逆传播（error BackPropagation，简称BP）算法就是其中最杰出的代表，它是迄今最成功的神经网络学习算法。<br>◆ BP算法不仅可用于多层前馈神经网络，还可用于其他类型的神经网络，例如训练递归神经网络<br>6.1 间隔与支持向量<br>◆ 换言之，这个划分超平面所产生的分类结果是最鲁棒的，对未见示例的泛化能力最强。<br>◆ 2024/04/14发表想法<br>在支持向量机（SVM）中，超平面被用作决策边界以区分不同的类别。在n维空间中，超平面可以定义为n-1维的子空间，即一个维度比整个空间少的子集。<br>
超平面通常用线性方程来表示，在二维空间中，超平面就是一条线，可以由方程 y = ax + b 表示；在三维空间中，超平面是一个平面，可由方程 z = ax + by + c 表示。<br>
对于更高维度的空间，超平面可由以下线性方程来表示：<br>
<br>
其中，向量 w = (w1, w2, …, wn) 是超平面的法向量，决定了超平面的方向；x = (x1, x2, …, xn) 是空间内的任意一点；b 是偏置项，决定了超平面沿法向量方向的位置。变量 w 和 b 是SVM训练过程中要学习的参数。根据这个线性方程，我们能够判断一个点位于超平面的哪一侧，因此可以用来进行分类。<br>原文：在样本空间中，划分超平面可通过如下线性方程来描述：[插图]<br>◆ 在样本空间中，划分超平面可通过如下线性方程来描述：[插图]<br>◆ 其中w=(w1;w2;...;wd)为法向量，决定了超平面的方向；b为位移项，决定了超平面与原点之间的距离。<br>◆ 任意点x到超平面(w,b)的距离可写为[插图]<br>6.2 对偶问题<br>◆ 其中w和b是模型参数。注意到式(6.6)本身是一个凸二次规划(convex quadratic programming)问题，能直接用现成的优化计算包求解，但我们可以有更高效的办法。参见附录（B.2 二次规划）。对式(6.6)使用拉格朗日乘子法可得到其“对偶问题”(dual problem)。<br>◆ KKT(Karush-Kuhn-Tucker)条件，即要求[插图]如[Vapnik,1999]所述，支持向量机这个名字强调了此类学习器的关键是如何从支持向量构建出解；同时也暗示着其复杂度主要与支持向量的数目有关。<br>6.5 支持向量回归<br>◆ 对样本(x,y)，传统回归模型通常直接基于模型输出f(x)与真实输出y之间的差别来计算损失，当且仅当f(x)与y完全相同时，损失才为零。与此不同，支持向量回归（Support Vector Regression，简称SVR）假设我们能容忍f(x)与y之间最多有[插图]的偏差，即仅当f(x)与y之间的差别绝对值大于[插图]时才计算损失。<br>6.6 核方法<br>◆ 给定训练样本{(x1,y1)，(x2,y2)，...，(xm,ym)}，若不考虑偏移项b，则无论SVM还是SVR，学得的模型总能表示成核函数k(x,xi)的线性组合。<br>◆ 表示定理对损失函数没有限制，对正则化项Ω仅要求单调递增，甚至不要求Ω是凸函数，意味着对于一般的损失函数和正则化项，优化问题(6.57)的最优解ℎ*(x)都可表示为核函数k(x,xi)的线性组合；这显示出核函数的巨大威力。<br>7.1 贝叶斯决策论<br>◆ 对分类任务来说，在所有相关概率都已知的理想情形下，贝叶斯决策论考虑如何基于这些概率和误判损失来选择最优的类别标记。<br>◆ 假设有N种可能的类别标记，即[插图]={c1,c2，…，cN}，λij是将一个真实标记为cj的样本误分类为ci所产生的损失。基于后验概率P(ci|x)可获得将样本x分类为ci所产生的期望损失(expected loss)，即在样本x上的“条件风险”(conditional risk)[插图]<br>◆ 我们的任务是寻找一个判定准则h:x[插图]y以最小化总体风险<br>◆ 首先要获得后验概率P(c|x)。然而，在现实任务中这通常难以直接获得。<br>7.2 极大似然估计<br>◆ 极大似然估计是试图在θc所有可能的取值中，找到一个能使数据出现的“可能性”最大的值。<br>7.4 半朴素贝叶斯分类器<br>◆ 半朴素贝叶斯分类器的基本想法是适当考虑一部分属性间的相互依赖信息，从而既不需进行完全联合概率计算，又不至于彻底忽略了比较强的属性依赖关系。<br>8.1 个体与集成<br>◆ 集成学习(ensemble learning)通过构建并结合多个学习器来完成学习任务，有时也被称为多分类器系统(multi-classifier system)、基于委员会的学习(committee-based learning)等。<br>◆ 例如“决策树集成”中全是决策树，“神经网络集成”中全是神经网络，这样的集成是“同质”的(homogeneous)。同质集成中的个体学习器亦称“基学习器”(base learner)，相应的学习算法称为“基学习算法”(base learning algorithm)。集成也可包含不同类型的个体学习器，例如同时包含决策树和神经网络，这样的集成是“异质”的(heterogenous)。<br>◆ 集成学习通过将多个学习器进行结合，常可获得比单一学习器显著优越的泛化性能。这对“弱学习器”(weak learner)尤为明显，因此集成学习的很多理论研究都是针对弱学习器进行的，而基学习器有时也被直接称为弱学习器。<br>◆ 集成学习的结果通过投票法(voting)产生，即“少数服从多数”。在图8.2(a)中，每个分类器都只有66.6%的精度，但集成学习却达到了100%<br>◆ ；在图8.2(b)中，三个分类器没有差别，集成之后性能没有提高；在图8.2(c)中，每个分类器的精度都只有33.3%，集成学习的结果变得更糟<br>◆ 要获得好的集成，个体学习器应“好而不同”，即个体学习器要有一定的“准确性”，即学习器不能太坏，并且要有“多样性”(diversity)，即学习器间具有差异。<br>◆ 假设集成通过简单投票法结合T个基分类器，若有超过半数的基分类器正确，则集成分类就正确：[插图]参见习题8.1。假设基分类器的错误率相互独立，则由Hoeffding不等式可知，集成的错误率为[插图]上式显示出，随着集成中个体分类器数目T的增大，集成的错误率将指数级下降，最终趋向于零。<br>8.3 Bagging与随机森林<br>◆ 2024/05/07发表想法<br>放回采样是为了防止出现偏执<br>原文：Bagging[Breiman,1996a]是并行式集成学习方法最著名的代表。从名字即可看出，它直接基于我们在2.2.3节介绍过的自助采样法(bootstrap sampling)。给定包含m个样本的数据集，我们先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过m次随机采样操作，我们得到含m个样本的采样集，初始训练集中有的样本在采样集里多次出现，有的则从未出现。<br>◆ Bagging[Breiman,1996a]是并行式集成学习方法最著名的代表。从名字即可看出，它直接基于我们在2.2.3节介绍过的自助采样法(bootstrap sampling)。给定包含m个样本的数据集，我们先随机取出一个样本放入采样集中，再把该样本放回初始数据集，使得下次采样时该样本仍有可能被选中，这样，经过m次随机采样操作，我们得到含m个样本的采样集，初始训练集中有的样本在采样集里多次出现，有的则从未出现。<br>◆ 我们可采样出T个含m个训练样本的采样集，然后基于每个采样集训练出一个基学习器，再将这些基学习器进行结合。这就是Bagging的基本流程。<br>8.6 阅读材料<br>◆ Boosting主要关注降低偏差，而Bagging主要关注降低方差<br>9.3 距离计算<br>◆ p=2时，闵可夫斯基距离即欧氏距离(Euclidean distance)<br>10.6 度量学习<br>◆ 在机器学习中，对高维数据进行降维的主要目的是希望找到一个合适的低维空间，在此空间中进行学习能比原始空间性能更好。事实上，每个空间对应了在样本属性上定义的一个距离度量，而寻找合适的空间，实质上就是在寻找一个合适的距离度量。那么，为何不直接尝试“学习”出一个合适的距离度量呢？这就是度量学习(metric learning)的基本动机。<br>14.1 隐马尔可夫模型<br>◆ 但推断远超出预测范畴，例如在吃到一个不见根蒂的好瓜时，“由果溯因”逆推其根蒂的状态也是推断。<br>◆ 机器学习最重要的任务，是根据一些已观察到的证据（例如训练样本）来对感兴趣的未知变量（例如类别标记）进行估计和推测<br>◆ 概率模型(probabilistic model)提供了一种描述框架，将学习任务归结于计算变量的概率分布。<br>◆ 若变量间存在显式的因果关系，则常使用贝叶斯网；若变量间存在相关性，但难以获得显式的因果关系，则常使用马尔可夫网。<br>◆ 第一类是使用有向无环图表示变量间的依赖关系，称为有向图模型或贝叶斯网(Bayesian network)；第二类是使用无向图表示变量间的相关关系，称为无向图模型或马尔可夫网(Markov network)。<br>◆ 箭头表示了变量间的依赖关系。在任一时刻，观测变量的取值仅依赖于状态变量，即xt由yt确定，与其他状态变量及观测变量的取值无关。<br>◆ 这就是所谓的“马尔可夫链”(Markov chain)，即：系统下一时刻的状态仅由当前状态决定，不依赖于以往的任何状态。<br>◆ 基于这种依赖关系，所有变量的联合概率分布为[插图]<br>◆ 隐马尔可夫模型还需以下三组参数：• 状态转移概率：模型在各个状态间转换的概率，通常记为矩阵A=[aij]N×N，其中[插图]表示在任意时刻t,若状态为si，则在下一时刻状态为sj的概率。• 输出观测概率：模型根据当前状态获得各个观测值的概率，通常记为矩阵B=[bij]N×M，其中[插图]表示在任意时刻t,若状态为si，则观测值oj被获取的概率。• 初始状态概率：模型在初始时刻各状态出现的概率，通常记为π=(π1，π2,...，πN)，其中πI=P(y1=si),1≤i≤N表示模型的初始状态为si的概率。<br>B 优化<br>◆ 从几何角度看，该问题的目标是在由方程g([插图])=0确定的d-1维曲面上寻找能使目标函数<a class="internal-link" data-href="[插图]" href="\[插图]" target="_self" rel="noopener nofollow">插图</a>最小化的点。此时不难得到如下结论。<br>◆ 若梯度∇<a class="internal-link" data-href="[插图]*" href="\[插图]*" target="_self" rel="noopener nofollow">插图</a>与约束曲面不正交，则仍可在约束曲面上移动该点使函数值进一步下降。<br>◆ 对等式约束，λ可能为正也可能为负。对于约束曲面上的任意点[插图]，该点的梯度∇g([插图])正交于约束曲面。在最优点[插图]，目标函数在该点的梯度∇[插图]([插图])正交于约束曲面。<br>后记<br>◆ 图灵奖得主E.W.Dijkstra曾说“计算机科学并不仅是关于计算机，就像天文学并不仅是关于望远镜”。<br>-- 来自微信读书<br>]]></description><link>culture\阅读\机器学习-周志华.html</link><guid isPermaLink="false">Culture/阅读/机器学习-周志华.md</guid><pubDate>Mon, 09 Sep 2024 11:46:23 GMT</pubDate></item><item><title><![CDATA[将夜]]></title><description><![CDATA[ 
 <br><br>《将夜》<br>猫腻<br>
338个笔记<br>第一章 开头<br>◆ 天气还很寒冷，树下那三个人穿的衣服却不多，似乎并不怎么怕冷，就这样专注地看着，不知道看了多久，其中一人忽然开口低声说道：“俗世蚁国，大道何如？”<br>◆ 以骁勇著称的宣威将军林光远，因为得罪了帝国第一骁勇大将夏侯，于是再也不复骁勇<br>◆ 离此地不远处的柴房内，一名浑身是血的将军府管事，望着身前两名四五岁大小的男孩儿，枯唇微微翕动，声音沙哑的极为难听，满是皱纹黑泥的脸上写满了绝望和挣扎，一直挣扎到老泪挤出眼角，浑浊的厉害。<br>◆ 两个世界的悲欢离合从来都不相通。　　若能相通，便是圣贤。<br>◆ 高大男子重重放下酒碗，恼火咕哝道：“真他妈的黑。”　　……<br>第二章 渭城有雨，少年有侍<br>◆ 干燥时节土墙上的浮土被西北的风刀子一刮便会四处飘腾，然后落在简陋的营房上，落在兵卒们的身上，整个世界都将变成一片土黄色，人们夜里入睡抖铺盖时都会抖起一场沙尘暴。　　正在春旱，这场雨来的恰是时辰，受到军卒们的热烈欢迎，从昨夜至此时的淅淅沥沥雨点洗涮掉屋顶的灰尘，仿佛也把人们的眼睛也洗的明亮了很多。<br>◆ 马士襄怔了怔，想起某个可恶的家伙，沉默片刻后低头回应道：“有现成的人选。”<br>◆ 宰相门房、贵人近婢、亲王清客，这是官场上极令人头痛的角色，近则惹人怨，远之惹麻烦，最是麻烦。<br>◆ 2024/07/02发表想法<br>主角身上要有矛盾的地方，人物才立体。<br>原文：那少年约摸十五六岁，身上穿着一件军中常见的制式棉衫，棉衫襟前满是油污，一头黑色的头发不知道是天然生成还是因为几年未曾洗过的缘故有些发卷，也有些油腻，偏生那张脸却洗的极为干净，从而显得眉眼格外清楚，脸颊上那几粒雀斑也格外清楚。<br>◆ 那少年约摸十五六岁，身上穿着一件军中常见的制式棉衫，棉衫襟前满是油污，一头黑色的头发不知道是天然生成还是因为几年未曾洗过的缘故有些发卷，也有些油腻，偏生那张脸却洗的极为干净，从而显得眉眼格外清楚，脸颊上那几粒雀斑也格外清楚。<br>◆ 那里有一个十一二岁的女童正在地搬动水桶，身材矮小瘦削，肤色黝黑，眉眼寻常，身上那件不知她主人从哪儿偷来的侍女服明显有些过于宽松，下摆在地上不停拖动，搬着可能比自己还要重的水桶，明显非常吃力。<br>◆ 虽说昨夜下了一场雨，但雨水不够大，门窗上积着的黄土没有被冲涮干净，反而变成了一道道难看的泥水痕迹，这些泥水痕迹在小侍女的抹布下迅速被清除，屋宅小院顿时变得干净明亮起来。<br>第三章 能书能言穷酸少年<br>◆ 宁缺认真回答道：“只要将军您需要，我随时可以不要这张脸。”<br>◆ “贵人不喜欢你？”马士襄厉声训斥道：“你好像忘记了你的身份，要知道你现在还不是书院的学生，身为帝国军人必须服从上级军令，服从老子我的命令！贵人喜不喜欢你，不是你该操心的事情！至于你喜不喜欢那位贵人，是没有人会在乎的事情！你只需要接受命令，然后完成命令！”<br>第四章 唐人的朴素是非观<br>◆ 因为从开国到现在，生活在这片土地上的人们始终坚持信奉并守卫一个朴素的道理：我不欺负你，但你也别想欺负我，就算是我欺负了你，但你……依然别想欺负我！　　谁欺负我，我就打谁。　　这就是大唐帝国的立国之本。　　这就是大唐帝国的强国之路。　　这也正是为什么这个世界上最强大的国度叫做唐。<br>◆ 我不欺负你，但你也别想欺负我，就算是我欺负了你，但你……依然别想欺负我！　　谁欺负我，我就打谁。<br>第五章 非典型唐人的前路探讨<br>◆ 马襄生目光骤然变得凌厉起来，“无论是书院，还是那位姓吕的老人家，你都必须抓住，也一定要抓住。”<br>第六章 睹无月思怀<br>◆ 桑桑扶着膝头站起身，瘦小的身躯在微凉的春日夜风里显得格外单薄，她看着宁缺，用认真而没有夹杂任何其余情绪的声音细声说道：“就算我们走了，可这房子还是会有人住，他们还是会开门啊。”<br>◆ 桑桑脸上流露出若有所思的情绪。因为年龄还小的缘故，小侍女的眉眼并未长发，又因为边城风沙的关系，小脸蛋儿黝黑粗糙，加上那一头童年营养不良造成的微黄细发，实在谈不上好看，就连清秀都说不上。　　但她有一双像柳叶似的眼睛，细长细长的，眸子像冰琢似的明亮，加上很少有什么太明显的神色，所以不像是个出身凄苦将将十一二岁的小侍女，倒像是个什么都知道，看透世情心无所碍的成熟女子，这种真实年龄相貌与眼神之间的极度反差，让她显得格外冷酷有范儿。<br>◆ 在田里干活儿的农妇闲唠，总想着东宫娘娘在烙肉饼，西宫娘娘在剥大葱，肉饼似海，大葱似山。<br>◆ 看着木盒里的散银，两个人都没有数，桑桑低声说道：“老规矩五天数一次，前儿夜里刚刚数过，七十六两三钱四分。”<br>◆ “看来去长安后必须想法子多挣些钱。”宁缺神情认真说道。　　“嗯，我会争取把自己女红水平再提高一些。”桑桑神情认真回答道。<br>◆ 宁缺应了声，目光落在炕边地面像白霜般的星光上，心头无来由微紧，很多年前那种空落落的感觉再次袭来，回头望向窗外深青色的夜空，看了眼满天星光，然后开始低头思念故乡，喃喃念道：“今天还是没有月亮啊……”<br>第七章 此去长安混人样<br>◆ 从门后取出一把黑伞，用剩下的最后那截哈绒草绳系紧绑在桑桑的背上，这把黑伞不知道是什么材料制成，总感觉上面蒙着一层黑黑的油污，并不反光，显得有些厚重。而且这把伞看得出来很大<br>◆ 就在车队将要驶出这座小小边城前，宁缺从马车上站了起来，向四周拱手一礼。　　少年身后背着三把旧刀，站在雨中拳掌相搭行礼，竟陡然生出几分豪壮之气。　　“老少爷们儿，大姐大婶儿们，感谢的话不多说。”　　说完这句话，他在雨中张开双臂，握紧双拳向上分开，展露自己并不强悍的胸肌和手臂，摆出一个特傻.逼的姿式，大声喊道：“此去长安，要是混不出个人样儿，我就不回来了！”<br>◆ 洗完脚，宁缺钻进羊毛褥子，然后把对面伸过来的那双冰冰的小脚搂进自己怀里，发出一声不知道是享受还是痛苦地呻吟，打了两声呵欠后说道：“睡吧。”<br>第八章 夜饮，梦了一片海<br>◆ 思考分析不得其解，宁缺把注意力收了回来，这才发现怀里那双小脚始终没有被捂暖，还是像冰疙瘩一样寒冷，连带着自己的胸腹间也冰冷一片，不由忧虑地蹙起了眉头。<br>◆ 满室烈酒香，怀中冰冷的小脚渐渐变暖，宁缺看着她鼻尖上渗出来的几滴汗珠，终于放下心来，抹了抹自己额头上的汗。<br>第九章 北山道外，一箭南来<br>◆ “桑桑，你永远要记住这一点，我们是很辛苦很辛苦……甚至是拼了这条命才能够继续在这个世界上活着。既然我们这么辛苦才活下来，那我们就不能轻易去死。”<br>第一十章 心如磐石的侍卫们<br>◆ 隐约猜到将会发生什么事情，华丽冷酷新世界掀开帷幕将要来到的现实，让他的情绪紧张到了极点，头皮有些发麻，中食二指不停无声摩娑弓弦，过了片刻，他的呼吸反而很奇妙地变得缓慢下来，脸上神情竟比先前更加冷静沉着。<br>第一十四章 青衫红花湿<br>◆ 他自己本姓为夏，却不允许自己的子女姓夏，而是把自己的全名变成了他们的姓，长子夏侯敬，次子夏侯畏，诸如此类，当朝中某学士提出疑问时，夏侯桀傲应道：“吾当开创一流传万世之姓氏，吾当为祖，故当以我名为姓。”　　“是为夏侯氏。”　　……<br>第一十五章 我有三把刀<br>◆ 他知道夏侯麾下的刺客组惯常是三个人一起行动。　　所以从很小的时候开始，他的后背上一直背着三把刀<br>第一十六章 他是梳碧湖的砍柴者<br>◆ 那位权重一方的大唐骁勇大将根本不知道，在遥远的边塞小城中，有一个少年每天刻苦练刀砍柴，在分析他麾下所有的强者战斗风格，总结出了无数套对策。<br>第一十九章 怪你过分美丽<br>◆ 公主李渔缓缓站起身来。　　于是听故事的婢女便不复存在。　　二人臂膀间残留的温度被晨风迅速吹走。<br>第二十章 雪山里什么都没有<br>◆ 小侍女认真看着他的眼睛，说道：“你有没有觉得有时候你很无聊？”　　宁缺偏偏头表示默认。<br>◆ 看着那名骑兵的背影，桑桑抹了抹额头上那三两颗汗珠，眯着那双柳叶细眼说道：”少爷，我们好像被嫌弃了。”　　“嫌弃这个词用的好，如果用被人遗忘这四个字，就会显得太过酸涩骚情。”<br>第二十四章 我以为你知道我的异禀……<br>◆ 少年抬起头来，眼睛显得异常明亮，声音微颤问道：“您是不是看出来我天赋异禀，所以才会对我另眼看待？”　　吕清臣老人愕然望着他，嘴唇微张，片刻后犹疑问道：“你的异禀……在何处？”<br>◆ “如果我知道自己有什么天赋异禀……何必还来问先生。”　　老人伸出枯瘦的手指着他的鼻子微微颤抖，实在是不知道此时该说些什么。<br>第二十五章 好家伙<br>◆ 生命这个好家伙，让他猛回头比让他一直走其实更需要勇气。<br>第二十六章 第一个梦<br>◆ 三道黑色的烟尘稳定地悬浮在荒原前方，冷漠地看着这方，就像是有生命一般。　　“天要黑了。”　　“我说过，天要黑了，但从来没有人相信我。”<br>◆ 他冲着那个高大背影高声喊道：“喂！是你吗？这是怎么回事！”　　那个高大男子没有转身，离开人群的背影极其萧索，直至消逝不见，而宁缺的喊声却惊动了荒原上抬头看天的人们，有人埋怨道：“天都要黑了，你不好好看着，非要打扰我们最后时刻的安宁，真是令人厌恶的小东西。<br>第二十八章 我与长安相见欢<br>◆ 桑桑背过手去握住大黑伞的中段，仰着小脸冷冷看着这名军士，说道：“伞在人在，伞亡人亡。”　　军士望着这个小黑丫头，竖起大拇指称赞道：“这个说法……有新意。”<br>◆ ”　　“可是有骄傲不表现出来，换谁都会憋的慌，那长安人怎么办？……他们说话！从马车行到部衙门子，所有长安人都极擅长的闲唠，上到皇室秘闻下到青楼佚事，仿佛天底下就没他们不知道的，当然他们最喜欢的就是以一种风轻云淡的口气去说天下诸国或是大唐诸郡的战争人事，好像他们每个人都是宰相一般。”<br>◆ “只不过有时候人，尤其是男人很容易变白痴的，比如为了女人啊爱情啊尊严啊这些乱七八糟的东西发狂的时候。”<br>第二十九章 <br>◆ 左手边那家却显得要衰败很多，门上漆皮脱落，两道封条颓然无力地在风中飘中残余的片段，石狮只剩下了一个，另一个不知道被搬去了何处，即便剩下的这一个也已残破，缺耳漏爪，基座后方积着黑糊糊的老泥，有些像凝固的血。<br>◆ 都说福祸相倚，可谁敢设想，家有悍妻杀妾灭子，到最后竟能成就男人的一世功名？”<br>第三十章 重逢七年间<br>◆ 老人拿起筷尖戳破碟中咸蛋，就着那抹滋味饮了口便宜的莲花白，啧啧叹息道：“你们都没亲眼见过，我那天刚好在，将军府里杀声震天，人头落地就像西瓜落地般迸迸直响，那血啊……从大门下边漫了出来，真是惨啊。”<br>◆ 桑桑大概很少看见比自己还要黑的人，忍不住抬头好奇地看了两眼，又觉得这样显得有些不礼貌，<br>◆ 宁缺心不甘情不愿地张开双臂，在这间破饭馆的阴暗角落里和对方拥抱了一下。　　黑瘦年轻人叫卓尔，是他在这个世界上第一个朋友。<br>第三十一章 我见朱雀多肃杀<br>◆ 直通往北方皇宫的朱雀大街本是灰色，被雨丝浸润后却变成了黑色，宁缺和桑桑站在道旁望去，只觉得像是一道又黑又长又直的缎带，佩在壮阔长安城的胸口，清丽庄严而又令人心悸，<br>第三十二章 一文钱难死主仆俩（上）<br>◆ 要不然少爷你自己梳一下试试，往年在渭城都是随意梳拢个髻就好，你今天却要学那些书生，我可没学过。<br>◆ 宁缺看着桑桑比原本更黑的小脸，笑着说道：“好了好了，办完正事儿了我带你去陈锦记。”<br>◆ 宁缺接过刀走进客栈后方的小庭院，开始伴着晨光练刀，动作精准看上去剽悍强劲，只是那乱糟糟蓬松的头发也随着动作一抖一抖，看上去不免有些滑稽。<br>◆ 　　“三十两？”桑桑下意识提高音量，尖声喊道：“那还读什么读！”<br>第三十三章 一文钱难死主仆俩（下）<br>◆ 大黑伞的面积似乎大到足够为整整一支马球队遮风蔽雨，但不知为何，站在黑伞下的宁缺和桑桑依然觉得自己被淋了个透心凉，身体寒冷快要变成冰雕。<br>◆ “我堂堂大唐帝国……”此时宁缺说出堂堂大唐帝国这六字时的口气，全然没有往常的自信骄傲，反而带着些许幽怨，“……居然还靠教育挣钱，实在是令人不耻，即便你不包食宿，难道收费不能便宜些吗？而且要知道我可是救了你家公主，就喊人传句话便罢了？也不说打赏我们千八百两银子用用，一点儿都不大气！”<br>◆ 桑桑细声细气责怪道：“我当时就说过你杀的太狠了，结果梳碧湖那边的马贼派人成天盯着渭城，只要发现你带队进草原，他们立马收拾金银细软逃跑，这种搞法哪里还能抢到钱？结果弄得去年整整一年都没进帐。”　　“当时年纪小，经验不是太足。”<br>◆ 宁缺很痛恨自己的小侍女在需要展现记忆力的时候总显得憨拙懒散，而在不需要表现记忆力的时候又总是表现得聪慧善记像极了天才儿童，他恼火说道：“那你说怎么办？又要能挣钱又不能让书院知道，那只能去当杀手了！”<br>◆ 在岷山在渭城在草原，无论身逢怎样艰难贫苦的局面，他和桑桑都能撑过去，而如今到了繁华胜锦富庶冲天的长安城，生存对他们来说反而成了很严重问题，一文钱能够难倒英雄好汉，也把这对主仆二人难得头痛不已。<br>◆ 桑桑回答道：“少爷你字写的那么好，咱们卖字儿吧。”　　宁缺表情一僵，看着她很认真地说道：“桑桑，你变丑了。”　　“嗯？”桑桑很迷惑。　　宁缺恼火教训道：“什么叫卖字儿？那叫书法！书法懂不懂？读书人的事儿怎么能拿来卖呢！这东西我是宁肯卖身也不卖它的！”<br>◆ 桑桑愤怒喊道：“少爷，你不是读书人，你就是一个砍柴的，你不是常说自己写字儿比杀人更在行吗？既然你愿意靠杀人挣钱，为什么不能靠写字儿来挣钱！”　　宁缺很没有底气地弱弱反驳道：“说了那不叫写字儿，叫书法。”　　他低下头看着自己被雨水打湿的靴子，看着脚边自己刚刚用黑伞淌落雨水写的字儿，知道自己的人生再一次败给了小侍女。　　那行雨水写就的潇洒字迹如下：不患贫，患家有悍婢。　　……<br>第三十四章 笔落临四十七巷<br>◆ 这一竖粗墨重锤，像是某浓眉大汉慨然挑起的眉梢<br>◆ “山高水长，物象千万，非有老笔，清壮可穷。”<br>第三十五章 老笔斋的第一位客人<br>◆ 痛苦煎熬的时间总是度日如年，幸福享受的时间才叫逝水流年<br>◆ “老笔斋。”<br>◆ 他滋滋啜了口茶，站在槛内看着槛外风雨，慨然道：“茶香醉人，墨香醉人，真可谓宏图霸业谈笑中，不胜人生一场醉啊。”<br>◆ 面容稚嫩的少年穿着一身书生青衫，怎样也穿不出潇洒之气，反而显得有些滑稽，又捧着茶壶做老态，用老气横秋的口吻说着这样的话，就显得更可爱了。<br>第三十六章 那一场微凉的春雨<br>◆ 既然是闲人，宁缺自然懒得起身招待，双手捧着微温的劣质红泥茶壶，望着店外雨帘，眼帘微睁像是惬意地要睡着般，实际上那颗急着挣钱的心脏早已急到肿了。<br>第三十七章 贯心肝，静容颜<br>◆ “追惟酷甚，号慕摧绝，痛贯心肝，痛当奈何奈何。未获奔驰，哀毒益深，奈何奈何。临纸感哽，不知何言……小宁子顿首顿首。”<br>第四十章 简大家红袖怒招<br>◆ 我是月轮国人，但在长安城里也住了二十多年，当然知道你们这些唐男是怎样的禀性，说的好听一点讲疏阔大方，说的难听一点就叫热情过度，太爱面子。<br>第四十一章 溪畔翩翩一少年<br>◆ 好在丑人滑稽令人厌，但滑稽若是加上稚嫩便变成了可爱。<br>第四十六章 御史张贻琦之死亡<br>◆ 丫头嘛，笨点儿也应该，人不都说笨丫头笨丫头？”<br>第四十八章 竹竿空空两头响<br>◆ 那汉子微微一怔后竟认真地解释了起来：“在你家铺子门口倒了几车垃圾，半夜扔砖头，这种事情总是难免的，如果真把大家弄急眼了，偷偷进你家铺子把后宅那道机井污了也说不定，小老板你也知道，我们就是靠这个挣饭吃。”<br>第五十二章 天能容我，我便能活<br>◆ 中年男子右手放在房门上，沉默片刻后说道：“只要天能容我，我便能活。”　　……<br>◆ 是啊，天能容我人不能容我，那我只好杀人了。”　　……<br>第五十三章 春风亭，老朝小树<br>◆ 等雨停的时候往往雨不会停，等人来的时候往往人不会来。<br>◆ 不过我不喜欢蹲在地上和站着的人说话，因为高度有差距。”　　“你可以站起来。”　　“为什么不是你蹲下来。”<br>◆ 桑桑在收拾厨灶，洗涮锅碗和笔砚，小脸上没有任何表情，柳细般细长的眸子里隐约有些孩子气的烦躁，不知道为什么，小侍女今天搁碗涮笔的动作很大，时不时发出砰砰闷响，抹布用力擦着锅底竟似要把黑糊糊的锅底擦穿。<br>第六十三章 杀人锄田别样累<br>◆ “杀人能不能杀的有点儿诗意？你杀人的时候更像是在锄田。”<br>第六十四章 一世人，两碗煎蛋面<br>◆ “是。”朝小树回头望向少年青稚的脸，微笑说道：“从今以后就是兄弟了。”　　宁缺眉梢微挑，笑着回答道：“会不会太儿戏了些？”　　朝小树笑了起来，说道：“一世人两兄弟，这种事情本来就这么简单。”　　“一世人，不过两碗煎蛋面。”<br>◆ 原来生活的意义就是生活。<br>第六十八章 花开彼岸天（上）<br>◆ 朝小树微微一笑，说道：“但江湖够远，所以自由。”　　李渔摇了摇头，说道：“能有怎样的自由呢？”　　朝小树像看晚辈般疼惜看着她，道：“不选择的自由。”　　……<br>◆ 找着好借口，宁缺快活叫了声，冲至案前像大口吃肉喝酒的好汉那般化墨捉笔铺新纸，将心中积了数息的痒尽数化为快意，一挥而就淋漓尽致五个墨字。　　“花开彼岸天。”　　……<br>第六十九章 花开彼岸天（中）<br>◆ 我要做一木鸟告诉那厮飞机的雏形是这样嘀，我要酿一壶美酒告诉那厮亡国的佳酿是这样嘀，我要写几篇唠叨话告诉那厮这才是心灵高汤，我要续写几个字告诉那厮什么样的字才叫字——纵使你是人皇天帝，也要给我乖乖听着。<br>第七十章 花开彼岸天（下）<br>◆ 行至那片叫离海的大湖畔，朝小树若有所思，负手于青衫之后静静看湖，看着湖中金鲤欢快游动，忽然间唇角微微一翘，绽出个阳光透柳荫的清爽笑容。<br>◆ 朝小树喃喃念道：“久在樊笼里，复得返自然。”　　天地是樊笼人被困，心是樊笼身被困，把心上樊笼破了，天地樊笼自也破了。<br>◆ 潇洒笑声之中，他青衫飘飘走出皇城正门。　　今日之后的长安城少了位叫春风亭老朝的领袖。　　这个世间多了位观湖鱼而入知天命境界的强者。　　……<br>第七十一章 告别的长街<br>◆ 桑桑仰着小脸看着他，很坚定认真地摇摇头，表示银子这种东西一点都不硌人。<br>第七十七章 第一卷清晨的帝国 第七十六章 黑色闪电以及弓弦的奏鸣<br>◆ 那真是隐忍低调却忍成了悲伤的D小调小夜曲—<br>第八十一章 第一卷清晨的帝国 第八十章 青春啊青春<br>◆ “宁缺，这个世界出问题了，我想不明白，所以在红袖招里疯了一夜。”　　宁缺想起先前遇见的那书生，身体微僵，问道：“出了什么问题？”　　“我居然考进了书院，就是这个世界出现的最大问题。”<br>◆ 宁缺无言以对，无颜以对。<br>第八十三章 第一卷清晨的帝国 第八十二章 旧书楼<br>◆ “我知道你们很好奇，为什么这幢楼叫做旧书楼，其实原因很简单，因为这幢楼负责替书院收藏书籍，而书之一物，只是用来记载我们的思想，思想这种东西，一旦跃出脑海用文字记于纸上，便不再新鲜，只是旧物，所以任何书都是旧书。”<br>◆ 书便是书，它只是工具，绝不神圣，只有我们的思想才是新鲜的<br>第八十八章 第一卷清晨的帝国 第八十七章 书中有纸，不知何言<br>◆ 面对那些必须跨越过去的山峰，任何小聪明都会显得非常愚蠢，其时其境，你所需要的是那种近于憨拙的大智慧。<br>◆ “再上层楼，再上层楼，先前诸般愁，此时俱休，我本是那梳碧湖畔的打柴少年，何必强要学人说天凉，须知今日并未入秋。”<br>第八十九章 第一卷清晨的帝国 第八十八章 伟大无耻笔友的诞生<br>◆ 客观存在的事物当然就是真实的，比如这本书上的那些字迹，比我这时候的骄傲自负还要真实，虽然神符师在这些字迹上动了手脚，但你必须相信它是真实的，如果你自己都无法相信，那么你的眼自然更不会相信。”<br>◆ 春光映在纸上已经是一道解释，你眼看见它又是一道解释，你试着去理解它又是一道解释，解释往往就是误会，你解释的越多，事物便会与原初的模样不一样。<br>第九十一章 第一卷清晨的帝国 第九十章 一部叫做小王子的童话<br>◆ “殿下如果不是好人，那她当年为什么要去草原？她为什么对小蛮那么好？”　　宁缺静静看着她，忽然开口说道：“如果她是好人，那她当年为什么要去草原？她为什么要对小蛮这么好？我并不认为世间所有后妈都是坏人，但我也从未见过哪个后妈像她一样把小蛮看的比自己生命还重要。”<br>第九十三章 第一卷清晨的帝国 第九十二章 以血洗血<br>◆ 希望可能很虚妄，但有希望总比没希望要强，所以总得努力努力。<br>第九十四章 第一卷清晨的帝国 第九十三章 谁动了朕的御书房？<br>◆ “鱼跃此时海终究是朕的海，花开彼岸天那才是真正的自由天，朕既已困了那厮十余年，放他离去也不过是还债罢了，予人自由何不也是予己自由？”<br>第九十六章 第一卷清晨的帝国 第九十五章 永字八法<br>◆ 那个世界的东晋年间，那位史上最生猛书家王羲之先生认为永字八笔刚好具备楷书八法，正所谓点为侧、横为勒、竖为弩、钩为跃、提为策、撇为掠、短撇为啄、捺为磔，这便是著名的永字八法。<br>第一百零章 第一卷清晨的帝国 第一百章 神符师的传人<br>◆ 所以他怎么也想不明白一个小侍女和一碗剩鸡汤有甚值得如此记挂之处。<br>第一百一章 第一卷清晨的帝国 第一百零一章 关于天地之箫的留言<br>◆ 所谓希望，只是对绝望的偶尔否定。<br>第一百六章 第一卷清晨的帝国 第一百零五章 留书不知暑已至<br>◆ 桑桑接过毛巾在凉水桶里沁了沁，低声说道：“少爷，难道你就因为他家凉快些就要去把他杀了？报仇这种事情……真那么有意思吗？”<br>第一百七章 第一卷清晨的帝国 第一百零七章 暑夜一碗面，湖畔一茶师<br>◆ “这本来就是件有意思无关的事情。”<br>第一百一十章 第一卷清晨的帝国 第一百一十章 朱雀、黑伞以及光明的夜<br>◆ 他的视线越来越模糊，街畔的拴马柱、坊市口里的门坊，在眼中逐渐变形扭曲，变成张牙舞爪的怪物；他的呼吸越来越急促，肺叶挤压出来的气息像岩浆般滚烫，拼命吸进来的气息却像冰川般酷寒；他的脚步越来越虚浮缓慢，时常被地面突起的青石板绊住；他的思维越来越紊乱，竟渐渐忘了自己当下的处境。<br>第一百一十四章 第一卷清晨的帝国 第一百一十四章 生命不可承受之重<br>◆ 基于内心深处坚信的某种因果律，宁缺并不相信自己自己会就此死去，<br>第一百一十五章 第一卷清晨的帝国 第一百一十五章 那是你我想不明白的事<br>◆ 所谓理由其实都不过是说服自己的借口<br>第一百一十六章 第一卷清晨的帝国 第一百一十六章 温暖至滚烫的湿毛巾<br>◆ 但知道他肯定受了极重的伤，可能暗自藏身书院某处养伤，所以她不敢去问书院里的教习和学生，她只能等待。　　蹲在草甸青树旁，看着书院的石门被黑夜笼罩，被朝阳唤起，看着里面书舍的灯火点亮又熄灭，听着那些学生们朗声诵书，看着小小旧鞋前的蚂蚁来了又去去了又来，看着有人走进书院，有人走出书院，但就是没有看到那个家伙。<br>◆ 书院学生乘坐马车前来，看到宁缺的小侍女蹲在道旁，难免好奇，有人曾经上前问过几句，但她却是理都不理，倔犟地闭着小嘴不发一言，只是看着书院门口。　　看了整整一夜，仿佛看了整整一辈子那么久，桑桑终于看到了那个身影。<br>◆ “最近这些天我和你提过那个叫陈皮皮的书院学生……你帮我记一下，我欠这家伙一条命，以后合适的时间合适的地点……提醒我想办法还给他。”<br>◆ 这个世界上就没有比你我的命更重要的事情，既然如此，那么将来无论花多大代价去报答他都理所应当。”<br>◆ 桑桑被他这句话说的鼻头一酸，心想我只是个小侍女，难道还敢天天苛扣你不成，还不是想着日后少爷你要娶少奶奶，总得替你攒些银钱。　　“我给了车夫十两银子……”　　她低着脑袋轻声说道：“先前少爷你昏睡的时候，我去隔壁古董店寻他家老板娘要了碗泡萝卜，已经倒进锅里和鸭子一起炖了，再过会儿便能好。”<br>◆ 给了车夫十两银子——桑桑就是要通过这句话告诉少爷，自己虽然年纪小，虽然节俭，但却不是个不分轻重的小侍女，该花银子的时候，可没有什么舍不得。　　宁缺躺在床上看着窗外那个忙碌的小小身躯，想着先前她那句话里隐着的恚恼味道，忍不住笑了起来，却没想到桑桑看见他在床头支着身子，竟是迅速走到窗边，没好气说了句好生休息，便把外窗紧紧关住。<br>第一百一十七章 第一卷清晨的帝国 第一百一十七章 世间最美妙的声音<br>◆ 房间内死寂一般的沉默，宁缺像月轮国那位著名花痴少女样痴痴看着自己的手指，不敢呼吸，不敢眨眼，用尽全身力气保证颤抖的手指没有抖成残影，以前所未有的小心谨慎保持着这个姿式，如同一个被冻僵了的鹌鹑。<br>◆ 顾不得抓一件单衣披在身上，没有把鞋倒穿，因为根本没有穿鞋，宁缺猛地跳下了床，双腿一软险些摔倒，强行撑住向屋外跑去，撞翻了床边的水桶，腰被桌角狠狠撞了下，然而被巨大幸福感冲击的快要昏厥的少年根本没有感觉到疼痛。<br>◆ 推开房开，冲进小小庭院，站在正在砍柴的桑桑身前，他看着佝偻着小小身躯的小侍女，张了张嘴想要说些什么，却发现自己声音有些沙哑，快要说不出话来。　　桑桑疑惑看了他一眼，发现他脸上的表情极为怪异，像是在哭又像是在笑。　　“少爷，你没事儿吧？”　　她站起身来，习惯性踮脚抬臂，想知道宁缺是不是被捂到发烧，烧到神智有些不清，却发现如今自己一踮脚居然能摸到他的头顶，不由高兴地笑了起来。　　宁缺伸出右手抓住她的细胳膊，把她小小的身躯用力搂进怀里，搂在自己赤裸的胸怀间，就像很多年前那样，喃喃念道：“你活着很好，我现在……也很好。”　　柴刀见血逃离长安城后，他很多年都没有哭过，今天依然没有流泪，但不知道为什么，他觉得自己的眼眶有些湿热，鼻头有些酸涩。　　桑桑艰难地抬起头来，看着宁缺眼眸里淡淡的湿意，吓了一跳，然后她猜到了一些什么，小脸上满是震惊神情，两行眼泪涮的一下便从柳叶眼里流了出来。　　无语凝噎绝对不足以渲泄主仆二人此时此刻的情绪。　　桑桑张开细细的胳膊，用力搂住宁缺的腰，痛声大哭起来：“呜呜……少爷这可是大喜事，晚上你可得多吃几块鸭肉。”<br>◆ “少爷，以后再出去……做这些危险的事情，一定要记得带上我，在铺子里等你不好受。”<br>◆ 他已经极少做这些事情，但毕竟小时候做过太多次，所以动作非常熟练。<br>◆ 巨大的幸福感与激动兴奋就在圆蒲扇的摇晃之间渐趋平静，他开始默默思考自己身上究竟发生了什么事情，目光下意识落在桑桑小脸边的那把大黑伞上。<br>第一百一十八章 第一卷清晨的帝国 第一百一十八章 大黑伞的故事<br>◆ 拣到大黑伞的过程很寻常无奇，就像他拣到桑桑一样。　　很多年前，宁缺抱着小女婴走在官道上，看着天色好像快要下雨，刚好又看到道旁有把被人丢弃的黑伞，就顺便拣了起来。<br>◆ 然而很奇妙的是，大概在是抱着大黑伞睡了太长时间的缘故，还是个瘦小女婴的桑桑发现怀里没有大黑伞后便开始哭泣，无论宁缺怎么哄都没办法哄着，甚至就连偷来的糖水都没有效果，他只好万般无奈地又去把大黑伞拣了回来。<br>第一百二十章 第一卷清晨的帝国 第一百二十章 自幼杀蛮，故蛮不讲理<br>◆ “你说他们小屁孩儿嘛，长安十几座青楼里的姑娘都能证明我不是小屁孩儿，所以我并不觉得你那番话伤害到了我。”<br>◆ “书院里的人都知道咱俩关系不错，如果你和他们闹翻我就舍你不顾，也得被那些酸才点评为无情无义，你知道我不爱读书，也见不惯那些家伙的酸腐模样。”<br>第一百二十一章 第一卷清晨的帝国 第一百二十一章 能修行之后你会去做什么？<br>◆ 肤色微黑的小侍女表情也很紧张，她右手提着个沉沉的匣子，把身子缩在少年身后，听着昏暗灯光里传出来的嘈杂吵闹声，颤声说道：“少爷，我更担心的是你想的那法子管不管用，感知天地元气就能看到骰子上面的点数？你有没有把握？呆会儿如果把银子都输光了，你可不能急红了眼把我押上去啊。”<br>◆ “这说的什么胡话？再说……把你押上去，人赌坊也不见得肯收。”宁缺紧张地搓了搓手，说道：“至于把握，昨天夜里我不是给你表演过很多次了？少爷我这辈子向来不打无把握之仗，赢是肯定赢的，关键是赢之后怎么跑。”<br>第一百二十三章 第一卷清晨的帝国 第一百二十三章 少年爱财，取之无道<br>◆ 大掌柜没有接他的话，只是盯着桌上骰盅残片在看，看着骰盅残片里夹着的软金，看着那些符纹，越想心里越不痛快，喃喃说道：“大唐开国这么多年，就没听说过几次修行者靠欺负赌场挣钱，因为对那些人来说这么干实在是太跌份儿。”<br>第一百二十四章 第一卷清晨的帝国 第一百二十四章 谁的赌坊？<br>◆ 听到齐四爷三个字，推门而入果然看到那个青衣竹竿般的男人，宁缺的脸色也瞬间变昨极为精彩，心想怎么闹到熟人头上了，说道：“我说咱们熟归熟……实际上也不怎么熟……这样，看在朝小树面子上，先前所有帐目我给你打个对折。”<br>◆ “他说你这些年过的太苦，穷的时间太长，早就已经穷红眼了，那天夜里为了五百两银子就敢不管不顾跟着他去杀人，实在是太过可怕……英雄豪杰岂能为五斗米折腰，又担心你穷疯了之后傻逼到去当杀手，所以给你备了些产业。”<br>第一百二十五章 第一卷清晨的帝国 第一百二十五章 穷人乍富岂能安？<br>◆ 这些年里每次开家庭会议时她都是这副作派，他说过多次也没有什么效果，拿她实在没办法，不去理会，继续自己的说话，只求这唯一的听众不要溜走就好。<br>◆ “其实有一句是这样说的——环境改变人的气质，奉养改变人的体质。这句话是什么意思呢？就是告诉我们，你手里有两千两银子的时候，做事就不能还像只有二十两银子时那样抠门吝啬，不能总是吃剩饭剩菜……”<br>第一百二十六章 第一卷清晨的帝国 第一百二十六章 感知，感动知交也<br>◆ 陈皮皮看着地上这些吃食，根本不肯坐下来，不可思议说道：“我知道你有求于我，但真没想道你有求于人居然就只带了几个冷馒头和咸菜，这哪里是求人的态度？我说你至少也得带几碗蟹黄粥过来吧？”　　“灶堂里的蟹黄粥要单算钱，不包在食宿费里，何必浪费。”<br>◆ 宁缺脸上没有流露出悻悻之色，微微一怔后笑着说道：“总比一窍不通要强不少。”<br>第一百二十七章 第一卷清晨的帝国 第一百二十七章 本命，看桑桑！<br>◆ 自幼生活在地位崇高的西陵神国不可知之地里，离家后便在书院后山里天天冥想修行，十六年间不问世间俗事，不知勾心斗角阴谋为何物，天才的陈皮皮除了骄傲得瑟之外，圆滚滚的身躯里那颗心脏是那般的晶莹剔透干净的令人心动。　　自幼生活在凄风苦雨的岷山草原难苟活之地里，四岁后便在血雨腥风间天天砍人杀人，十六年间经历无数生死，清新可喜下隐着警惕冷漠，不幸的宁缺这个夜晚他并未如何动容，直到多年以后回忆起来，才明白当时自己是何其幸运。<br>第一百二十八章 第一卷清晨的帝国 第一百二十八章 书院里的天才们<br>◆ 宁缺强行压抑住心头得意，揉了揉因为念力输出过猛而发闷的眉心，尽可能语气平静毫不在意说道：“我这可不是贪财，银子兄是知道我怜惜他们。”　　“换句话说，这些银子是知道你抠门舍不得把它们花出去，所以才会对你的感知投以欢欣雀跃的回应？你这不止是弱，简直是弱爆了！”<br>第一百四十四章 第一卷清晨的帝国 第一百四十四章 善饮者无赫赫之言<br>◆ 国之贫弱暂无计，我唯有更加骄傲一些。”<br>◆ 片刻后，身材瘦小穿着侍女服的桑桑，捧着空空的酒碗从宁缺身后膝行而出，然后她愕然发现，自己变成了万众瞩目的焦点，不知道为什么，场间所有人都像看着神仙一样看着他。　　桑桑发现那么多道目光盯着自己在看，感到极为不习惯，抬起右手袖子擦了擦嘴，小心翼翼把酒碗搁在宁缺身前的案几上，然后重新悄悄退回宁缺身后。<br>第一百四十六章 第一卷清晨的帝国 第一百四十六章 你真的很美<br>◆ 2024/07/11发表想法<br>但其实拓扑学里袜子这样的结构和一个球一个饼是同胚的，所以其实袜子是没有拓扑意义上的洞的。<br>原文：“笨死的。”<br>
桑桑说道：“少爷你那天说的对，长的太好看的男子大多脑子都不大好使。”<br>
然后她望向席上的隆庆皇子，认真解释道：“袜子如果没有洞，那怎么穿进去呢<br>第一百四十七章 第一卷清晨的帝国 第一百四十七章 希望在人间<br>◆ 宁缺笑着回应道：“人缘这个东西说起来很奇怪，就像城墙上面长着的那些野草，风往哪边刮，它就往哪边跑，人缘不好其实有时候只说明你吹出来的风不够大。”<br>第一百四十九章 第一卷清晨的帝国 第一百四十九章 开楼<br>◆ 世间之事很多不在于你有没有能力做到，而在于你敢不敢想，如果你连想都不敢想，被自我怀疑控制，那你就是一个虚弱的人。我只需要知道你想入二层楼的想法究竟有多强烈，或者说多强大？<br>◆ 想就是关键，只要人想做什么事情，往往就能做成，人的想法或者说野心，本来就是这个世界上最美丽的事物，你能坚持是正确的选择。<br>◆ 想法、执着、自我、野心、剑。<br>第一百五十二章 第一卷清晨的帝国 第一百五十二章 十四年，去年夏天，今日拾阶<br>◆ 对于意志不坚定、心思容易摇晃的人来说，目光是有重量的，<br>◆ 谢天？应该先谢谢自己嘛，你这么不容易这么能干，这些都是你应得的。”<br>第一百五十三章 第一卷清晨的帝国 第一百五十三章 一纸，一帖，云后的两记雷<br>◆ “师弟此言差矣，当年心急入妙符之道立了那个毒誓，我便悔了半生。如今不敢破誓真个亲近女子，眼神作派何不尽量放荡些，也好求个道心无碍？”<br>第一百五十四章 第一卷清晨的帝国 第一百五十四章 银道与柴门，入雾<br>◆ “我活下来就是奇迹，所以我活着的每一天，我都会让它变成奇迹。”<br>第一百五十五章 第一卷清晨的帝国 第一百五十五章 杀破道<br>◆ 你是不想我离开，所以才会哭吧？<br>第一百五十七章 第一卷清晨的帝国 第一百五十七章 绝顶风光<br>◆ 只有登临绝顶，才能看到如斯美景。　　“这个世界是平的。”　　他抬头向远处望去，只见繁星之下的世界边缘，隐隐能够看到山脉破开云层露出的绝峰，不知道是岷山还是什么山。　　十七载颠沛流离，生死相见，才终于迎来此刻，怎能不思绪万千。<br>◆ 然后他抹掉泪水和鼻涕，认真说道：“真他妈好看。”　　……<br>第一百五十八章 第一卷清晨的帝国 第一百五十八章 咔嚓！咔嚓！<br>◆ 灭情绝性，说明性情之中本来便有恐惧，<br>◆ 隆庆皇子听懂了这句话，眉梢猛然飞起，问道：“你是说宁缺没有信仰。”　　二师兄回答道：“也许如此。<br>◆ 颜瑟看着他的神情，心中大感后悔，暗道自己已经忍了这么长时间，怎么偏生在这关键时刻没有忍住，遂即决定破罐子破摔，冷哼一声说道：“是又如何？他是我先看中的。”<br>◆ 黄鹤教授大感欣慰，得意道：“商量自然是有商有量，如果所有商量都有预先结果，那何必商量。”　　颜瑟怒道：“你无赖无耻！”　　黄鹤笑道：“向师叔学习。”<br>第一百五十九章 第一卷清晨的帝国 第一百五十九章 大唐国师很了不起吗？<br>◆ 黄鹤叹息说道：“师叔你德高望重，不要总耍赖成不成？”　　颜瑟呸了一口，怒道：“你看看师叔我这样子，天天泡青楼抱姑娘，我浑身上下每根毛孔里都透着猥琐下流四个字，你从哪儿看到我德高望重了？”<br>◆ 房间里一片安静，教习们没有再次重新争论，因为他们强烈感觉到，二师兄的小书童过不了多长时间便会回来，然后继续问那些很二的问题。<br>◆ “我不需要服众，我只需要服从。”<br>◆ “尊重宁缺自己的选择？我为什么要尊重他？至于大唐国师……”　　说到这里时，小书童刻意做了一个很长的停顿，然而仰起微尖的下颌，对着屋顶翻了一个白眼，从小鼻子里笨拙憋出一声冷哼，把山上那位傲骄男子的神情学的可爱无比。　　“很了不起吗？”　　……<br>第一百六十章 第一卷清晨的帝国 第一百六十章 春晨之风光<br>◆ 君陌啊君陌，你要世人如何看你？真不明白像你这般骄傲这般二的人，怎么还活了这么多年。”<br>◆ 挣扎了很长一段时间或者是很短一段时间，颜瑟终于做出了一个艰难的决定，他望向山崖下方的白云和远处的长安雄城，在心中默默叹息一声：“师弟，我对不起你。”<br>◆ 来到熟悉的环境，在熟悉的湿地旁，宁缺看到了自己最熟悉的那个瘦小身影。　　他走上去，看着桑桑脸上的疲倦，看着她微黄发丝里夹着的草屑碎叶，伸手细细拣落，温和说道：“等了这么长时间，你辛苦了。”　　桑桑仰着脸看着他，认真说道：“少爷才是真正辛苦。”<br>第一百六十一章 第一卷清晨的帝国 第一百六十一章 自今日始，你我不再命如纸<br>◆ 颜瑟大师看着身前的这个干干净净的年轻人，三角眼里神彩飞扬，哪有平日里的那些猥琐之意，像极了一位临终前终于抱上孙子的老祖父般慈爱，感慨说道：“想必你已经知道了最后的结果，日后你若有空闲时，便跟着我学些鬼画符的小本事吧。”<br>◆ 颜瑟大师忽然沉默了下来，脸上叠在一起的皱纹里既有觅到传人的喜悦恬淡，又有些说不清道不明的感慨，他看了黄鹤教授一眼，转头静静看着宁缺，缓声说道：“我很老了。”<br>第一百六十二章 第一卷清晨的帝国 第一百六十二章 最鲜不过一碗鸡汤<br>◆ “这暗侍卫未免也太暗了些，居然连我本人都不知道。<br>◆ 大唐国师李青山看着身前的师兄，目光幽幽有若深宫里的怨妇，平日里对师兄的尊敬早已全然化作了失望和恼怒。<br>第一百六十三章 第一卷清晨的帝国 第一百六十三章 御宴<br>◆ 2024/07/12发表想法<br>儒林外史<br>原文：怎么又点了三盏！赶紧给我灭了。”<br>◆ 怎么又点了三盏！赶紧给我灭了。”<br>第一百六十四章 第一卷清晨的帝国 第一百六十四章 宫门宅的夜话<br>◆ 在宁缺看来这世间最高雅最美妙的物事便是银子，至于金子那已然能够归类到神圣之中<br>◆ 宁缺拱手一揖，诚恳说道：“陛下乃千古明君。”　　皇帝笑了笑，打趣道：“此乃千古马屁。”<br>◆ 猜到和知道终究是两回事。”<br>◆ “大唐威震天下，靠的是铁骑勇士和不言败之精神，不是靠长安里的这几个天天流连勾栏青楼的人质。”皇帝微嘲说道：“当年燕皇遣太子入长安城为质，不是为了安朕的心，而是要安他自己的心，若朕不收他的儿子，他岂不是每夜都要担心朕的铁骑随时会攻破成京，杀进他的寝宫？为了让那个老家伙能睡的好些，能多活几天，朕只好勉为其难应了”<br>第一百六十六章 第一卷清晨的帝国 第一百六十六章 此间的师兄师姐们（上）<br>◆ 陈皮皮看着他，不知道他是不是猜到了自己的来历，沉默片刻后说道：“庄严、肃穆或者神圣，其实都不是美丽。”<br>第一百六十七章 第一卷清晨的帝国 第一百六十七章 此间的师兄师姐们（下）<br>◆ 2024/07/12发表想法<br>陈长生加秋山君<br>原文：你很骄傲，我很骄傲，二师兄更骄傲，但即便是二师兄在大师兄面前也没有任何骄傲的资格，最有趣的事情在于，如果你看到大师兄就会发现他这个人根本不知道什么是骄傲。”<br>◆ 你很骄傲，我很骄傲，二师兄更骄傲，但即便是二师兄在大师兄面前也没有任何骄傲的资格，最有趣的事情在于，如果你看到大师兄就会发现他这个人根本不知道什么是骄傲。”<br>◆ 是因为这两个特质，所以没有人会缠着他下棋或是做别的事情。”　　“什么特质？”宁缺好奇问道。　　“大师兄做事情很认真，非常认真。所以他的动作很慢，非常慢。”　　“有多慢？”　　“你想像不出的慢。”　　……<br>第一百六十九章 第一卷清晨的帝国 第一百六十九章 兄妹<br>◆ “人的感情需求总是隐隐指向自己最缺憾的部分，所以你这个性情怯懦的大胖子想找一个清新可爱，身材小巧，性格强悍的小女生，是很可以理解的事情。”<br>第一百七十二章 第一卷清晨的帝国 第一百七十二章 几年之后神符师？<br>◆ “这不是大浪淘沙，而更像是在攀登一座永远攀不到顶的山峰。有人在山脚下就被迫停下了脚步，有人登到了山腰，却被山风吹落悬崖，而符道传承到今日，已是到了现时现刻的峰顶，只是若你往未来望去，才会知道这座山峰还有无限高。”<br>◆ “我能成为那样的人吗？”　　“你必须成为那样的人。”　　宁缺看着颜瑟大师苍老而感伤的面容，忽然开口说道：“大师，请教学生最基本的东西。”<br>◆ 宁缺遗憾说道：“我知道，阅卷老师姓天名地，是个文盲。”<br>◆ 宁缺听出颜瑟大师对夫子的尊敬，沉默片刻后笑着说道：“那叫师傅行不行？”　　颜瑟大师微微一笑，心想这真是一个聪明的孩子。　　……<br>◆ 桑桑回过头来，看着他说道：“少爷，那是十年后的事情，而我们今天就必须把铺门修好。”<br>第一百七十四章 第一卷清晨的帝国 第一百七十四章 人生如题，各种痴（下）<br>◆ “你读的到底是书还是感觉？”　　“蠢货！读书当然要有感觉才能读的高兴！”<br>◆ 那就是书。　　数之不尽的书。　　整整一面崖壁的书。　　漫山遍野的书。<br>◆ 因为以有涯之生阅无尽之书，终究是不可能完成的任务。<br>◆ “以前我曾经痴过，这些天却忘了痴的本质是喜欢。不存在虚妄的希望，自然也就没有虚妄的失望，更没有什么绝望。人生如题各种痴，就是各种喜欢，喜欢做什么便做下去，那么我想这道题目总会有答案的。”<br>第一百七十六章 第一卷清晨的帝国 第一百七十六章 不听话的小东西<br>◆ 不贪无以成事。”<br>第一百七十七章 第一卷清晨的帝国 第一百七十七章 再见朱雀<br>◆ 陈皮皮看着七师姐没好气说道：“二师兄的性情大家谁不知道？他说不会撒谎就是不会撒谎，那天夜里我请他帮忙，缓隆庆一缓，说的话也不算虚假，你没见二师兄当时紧张成啥样了，面部表情倒是挺镇定，但树下面那几块硬石头全被他捏成了粉末。”<br>◆ 那是走雨线。”颜瑟大师指着檐线说道：“雨水落在乌瓦之上，顺着瓦片叠加处向下流淌，并没有经过走雨线，但走雨线的形状，却暗符雨落积滑之势，所以你会觉得顺滑。”<br>◆ “师傅，你怎么不说话了呢？其实吧，依我看来以您游戏人间看红粉如白骨却偏要去摸两把的绝顶气质，扮演心灵导师这种角色，实在是不合适。”<br>◆ 师傅，资质与能力就在身体里，不需要证明其实它也是一直存在的。”<br>第一百七十八章 第一卷清晨的帝国 第一百七十八章 长安城是一座阵<br>◆ “……师傅，我明白了，以后我一定会对您和二师兄更尊敬一些。”<br>第一百七十九章 第一卷清晨的帝国 第一百七十九章 盛夏的一场雨<br>◆ 昊天究竟有没有像人类一样的意志，无论是道门佛宗还是书院那些前贤，一直以来都还存在争论，我们今日暂且不提。”<br>◆ “所以佛宗不像一般修行流派那样，用对天地规律的了解控制程度来划分境界，没有什么不惑洞玄，以有涯之生去学习无尽之天地，怎能不惑？既然乃天地玄义，怎能洞彻？”<br>◆ 原来这些看似宁静理所当然的期盼，也是一种焦虑，对修行来说也是一道障碍。<br>第一百八十四章 第一卷清晨的帝国 第一百八十三章 裁决大神官的安排<br>◆ 只要有人确定能够击败你们，你们便没有资格骄傲，因为这种没有绝对实力保证的骄傲，对你们的道心修行会有极大障碍。”<br>◆ ：“书院那位夫子当年曾经说过一句话，叫求仁方能得仁。而关于失败，求败往往才能不败，所以让你去求败，是希望你日后能真正不败。”<br>第一百八十五章 第一卷清晨的帝国 第一百八十四章 放着我来<br>◆ 2024/07/15发表想法<br>想起风姿物语里的小草<br>原文：小草<br>◆ 宁缺睁着眼睛看着屋顶，明明冷玉在怀，却觉得越来越热，根本无法入睡。　　街巷青树上的蝉儿也不知为何失眠了，声声喊着热。　　……<br>第一百八十七章 第一卷清晨的帝国 第一百八十六章 一，二，三，符箭！<br>◆ “失败是成功的妈妈。”　　“小师弟这句话很有道理，但不要忘记有很多妈妈生出来的小孩子也很失败。”<br>第一百九十章 第一卷清晨的帝国 第一百八十九章 现在和当年的一些小事情<br>◆ 有人的地方就有事，有人事的地方就有麻烦。人类解决这种麻烦的手段其实很贫乏，除了战争和暴力，便只有开会这一条路可以走。<br>◆ 世间有很多刚强勇敢的人，在他们在第一次妥协之后，便会一直不断的妥协，最后甚至会形成某种畸形的心理状态，从妥协变成主动的配合，从受害者变成加害者，而他们自己都不明白这是为什么。<br>第一百九十一章 第一卷清晨的帝国 第一百九十章 同步<br>◆ “任何把眼光放的太远的想法，其实都过于死板。”<br>第一百九十二章 第一卷清晨的帝国 第一百九十一章 公主府里的卖艺者<br>◆ “因为你有野心有想法，和书院后山里的那些师兄师姐们不一样，而父皇正是看中你有野心有想法，对我帝国而言，年轻人有没有野心是件很重要的事情。”　　“我真不知道自己有什么野心。”　　“或者换一个词……理想？”　　“我的理想殿下应该清楚，都是很简单的一些东西。”<br>◆ 世间任何事情想要做成，首先便要敢想。如果不去想那便永远做不成，所谓野心欲望理想其实说到底还是要依靠勇气二字。”<br>第一百九十三章 第一卷清晨的帝国 第一百九十二章 这里是人世间<br>◆ 稻米不知道被她搓掉了多少层，身形越来越瘦削黯然<br>◆ 四师兄看着她身后那两个人，微微揖手行礼，然后不知想到什么，微笑望向熟睡中的宁缺说道：“我终于明白为什么那些符师先贤没能做出符箭来。让两个知命境界大修行者来当铁匠，除了小师弟谁还能有这等待遇？”　　二师兄面无表情走了过来，抢过沉重的铁锤。　　陈皮皮笑着走了过来，站到炉火前缓缓闭上眼睛。<br>第一百九十五章 第一卷清晨的帝国 第一百九十四章 晨光<br>◆ 老笔斋后院内，桑桑盯着咯咯叫的老母鸡发呆，心想昨天应该把你也宰了，好让他多吃点，不然路上饿了怎么办？<br>第二百六章 第二卷凛冬之湖 第十一章 假如光明来临<br>◆ 在落日的陪伴下，桑桑一个人有滋有味地吃着煎蛋面。　　面里一颗葱花都没有，因为她不喜欢吃葱，以前之所以放葱，那是因为某人喜欢。　　她一个人对着镜子尽情地涂陈锦记的脂粉，不会再有某人总在在旁边嘲笑。　　她一个人睡，从左边滚到右边从右边滚到左边，床显得大了很多。　　在床上，她想蹬腿就蹬腿，想伸胳膊就伸胳膊，再也不担心踢着谁打着谁硌着谁。　　一个人在长安城的的生活很舒服，很不舒服。<br>◆ 桑桑躺在床上，看着窗外那棵树，看着树叶里的繁星，心里想着怎么还是没有月亮呢？少爷说的月亮究竟是什么呢？少爷这时候又在哪里呢？　　可能是因为床忽然变大，所以有些不习惯的缘故，桑桑像前些天一样整整一宵都没有睡好，一直折腾到了天亮，她打着呵欠揉着小脸起床，推门去巷口买了碗酸辣面片汤，然后坐到老笔斋的门槛上。　　在清晨来临的明亮光线里，她一个人没滋没味地吃着。　　……<br>第二百八章 第二卷凛冬之湖 第十三章 举世之敌<br>◆ 我时常在想，是不是你们这些有大智慧大毅力的人物有大自信，所以才会坚持认为自己看的才是真实的，而且是唯一的真实，从而与真正真实的世界越走越远？”<br>◆ 唐帝和首座的想法，和我又有什么关系呢？<br>◆ 他带着悲悯的情绪缓声说道：“桃山，唐国，整个世界都腐朽了。”　　“不是我要与整个世界为敌，而是整个世界都在与黑夜为伴，与光明为敌。”<br>第二百九章 第二卷凛冬之湖 第十四章<br>◆ 光明大神官应道：“樊笼困的是心，天罗困的是身，心脱困自然要难过身脱困。”<br>第二百一十一章 第二卷凛冬之湖 第十六章 机缘<br>◆ “要说命运机缘这种事情……谁都不知道自己会看到什么，遇到什么，谁也不知道看到遇到的对于自己又意味着什么。想法和现实常常是相反的两个世界，比如前些天我们在渭城里看到的将军和那位大婶，也许他们会永生不老，也许明年他们就回撤回中原，但无论怎样发展，他们都不见得如表面那般欢喜。”<br>第二百二十二章 第二卷凛冬之湖 第二十七章 不画眉，火焰与海水<br>◆ 荒原的天空就像他熟悉的那样干净，但此时在夕阳的照耀下，自然分成了两片截然不同的世界，近夜的那面幽蓝似海，近日的那面燃烧似火。<br>第二百二十三章 第二卷凛冬之湖 第二十八章 马车上<br>◆ 她很认真地请教道：“欢喜厌憎都是情绪，如何能够压抑？”<br>第二百二十七章 第二卷凛冬之湖 第三十二章 大黑与小雪（下）<br>◆ 白马背上的神殿骑士听着身后的蹄声越来越清晰，凭借多年的经验知道被对手追近，他回头向后望去，被那个硕大的黑色马头吓了一跳。　　因为这头陌生大黑马的眼睛实在是太奇异，明亮的眼眸里满是疯狂暴躁的情绪，还带着几抹血丝，看上去仿佛恨不得把自己咬死一般。事实上……大黑马这时候真的咧开嘴，露出满口白牙，疯癫一般对着空气狠狠地咬了一口！<br>第二百三十章 第二卷凛冬之湖 第三十五章 小密探的前途<br>◆ 但我知道兰花生长在幽谷中是自然之事，当你把花搬到我面前细心裁剪时，自然就不再自然。”<br>第二百三十七章 第二卷凛冬之湖 第四十二章 笔乱<br>◆ 想到棒槌，他眼珠一转，忽然生出把身后大黑伞顶到头顶上的荒谬想法，暗道那样似乎会和二师兄更像一些。<br>◆ 酌之华看着案几纸上那歪歪扭扭的一横，忍不住笑了起来，旋即轻声叹息说道：“你明知道我想说的不是这个意思。”　　莫山山看着纸上如蚯蚓般难看的字迹，心头微恼，，回头看着她说道：“那你究竟想说什么？”　　酌之华看着她带着几丝恼意的如漆眼眸，微笑说道：“我想说的是，既然你已经偷偷喜欢这位宁大家这么长时间，如今既然看见了真人，为什么不去说明白？”<br>第二百三十八章 第二卷凛冬之湖 第四十三章 那些放不下的事<br>◆ 2024/07/23发表想法<br>感觉山山的对宁缺的幻想更像陈长生。<br>原文：那个人就在她的身后，看着她手里的书帖，看着水面倒映着她的脸，没有说话，也不需要说话，只是这样安静地在墨池畔看着。<br>
……<br>◆ 薄薄的鸡汤帖拓本还在案几上，淡淡的身影还在墨池水面上，千里同行并肩战斗的默契还在回忆里，又哪里是送还行李便能两清的事情？<br>◆ 心意不是行李，因为没有重量，所以才难提起，更难放下。<br>第二百四十一章 第二卷凛冬之湖 第四十五章 黄泥砚，白雪地<br>◆ 宁缺看着她看了很长时间，有些感慨于少女的心境。只是他这在臭水沟里浮沉太多年，每个汗孔都透着铜臭气和渴求心，实在是无法理解这种淑静的心态，就如同码头上的搬运工，怎样也无法理解某些酸文人宁肯饿死也不愿意去写些应景文章，即便他能理解一二，也不知道该找怎样的话来表示赞赏。<br>◆ 希望和失望接踵而至，尤其是这种涉及春风情愫的微妙微酸心意期待，会让每个青春少女都觉得羞且恼之。　　莫山山虽然不是普通少女，但她终究是位少女。　　就如同宁缺虽然不是普通无耻，但他终究就是无耻。<br>◆ “我喜欢你的字。”　　莫山山抬头看着宁缺平静说道，这句话中间没有一点停顿和不自然。<br>◆ 天猫女看着那处，细细的眉尖蹙了起来，明亮眼眸里全是不满，愤愤不平说道：“世间男子多负心，没想到宁师兄也是这样的人。”　　酌之华微微一怔，心想真不该把那些事情告诉这个小姑娘，笑着说道：“十三先生又不知道山主对他的情意，根本无心何来负心？”　　天猫女把奶片塞进嘴里用力嚼着，哼了一声说道：“没心没肺更可恶。”<br>第二百四十四章 第二卷凛冬之湖 第四十九章 睽违千年的裁决<br>◆ 心想或许不是荒人的特殊体质适合修行魔宗法门，而是当年那位开创魔宗的光明大神官，正是因为荒人的特殊体质才创造了这样一种修行法门。<br>第二百四十六章 第二卷凛冬之湖 第五十一章 白雪墨眉不相欺<br>◆ 2024/07/23发表想法<br>其实我一直不觉得山山对宁缺有爱慕之情，她爱慕的是她通过宁缺的字幻想出的完美形象。真实的宁缺与她的思想是不和的。和桑桑那种少爷说得都对是不一样的。<br>原文：莫山山的眼眸里忽然闪过一抹羞意，说道：“我要你抄录的那份。”<br>第二百四十八章 第二卷凛冬之湖 第五十三章 一场修行的开端<br>◆ “究竟是结果重要还是过程重要？”　　莫山山微微一怔，回答道：“我认为是过程。”　　宁缺摇头说道：“我以前认为是结果，<br>第二百五十八章 第二卷凛冬之湖 第六十三章 不知命，知命，宁缺的命<br>◆ 桑桑不是宁缺的命门。　　桑桑是宁缺的命。<br>第二百六十四章 第二卷凛冬这湖 第六十九章 何以浇块垒（下）<br>◆ 他才明白原来所谓块垒，便是胸腹间那股不知因何而生的不平意，那些不平意最终凝结成石，不得畅快。<br>◆ “何以浇心中块垒？”<br>◆ 虽时常沉默却从无自锁之意，一味尽情释放，好不潇洒慷慨，稍有不满便要直起腰身捅上一剑，不说的时候是不屑说，他一旦说便要让整个上苍都知道。<br>◆ 何以浇块垒？　　凭胸中一股浩然气足矣。　　……<br>第二百七十二章 第二卷凛冬之湖 第七十七章 入魔（二）<br>◆ 2024/07/23发表想法<br>照这说法岂不是太阳能就是魔宗😂<br>原文：若任由这些妖孽强盛，天地气息渐涸，世界毁灭，再何以言之？这等功法亵渎昊天，颠倒天地，是为大不敬，故而为魔。”<br>◆ 2024/07/23发表想法<br>所以任何事情都有利有弊，独立思考自然能看得更透彻，但也容易固执己见。<br>原文：这种经过思考的所得，比些庸碌的修行者心中理念要坚定千万倍<br>第二百七十三章 第二卷凛冬之湖 第七十八章 入魔（三）<br>◆ 2024/07/23发表想法<br>现代人的人类中心主义<br>原文：世间万物都可以用来怡人也可以用来杀人，而万物无罪，唯人类乃万物之灵，赋予万物灵魂和用途，所以罪之一字只可适用于人。<br>◆ 世间万物都可以用来怡人也可以用来杀人，而万物无罪，唯人类乃万物之灵，赋予万物灵魂和用途，所以罪之一字只可适用于人。<br>◆ 2024/07/23发表想法<br>这就是现代化的弊端，宁缺是现代人的思维，没有信仰，只能将活下去的动力寄托在仇恨和桑桑身上，失去这两个东西就失去了立身之本。<br>原文：对当年灭门惨案的仇恨在他心中其实早已渐淡，但他恐惧于这种淡漠，所以愈发要把仇恨深深地刻进自己的骨中，这道已经隐隐变了味道的仇恨，已经成为宁缺生命里最重要的精神支撑，而这道支撑和先天对力量的贪婪追求混在一处，便变成了难以抑止的最强烈的诱惑。<br>◆ 对当年灭门惨案的仇恨在他心中其实早已渐淡，但他恐惧于这种淡漠，所以愈发要把仇恨深深地刻进自己的骨中，这道已经隐隐变了味道的仇恨，已经成为宁缺生命里最重要的精神支撑，而这道支撑和先天对力量的贪婪追求混在一处，便变成了难以抑止的最强烈的诱惑。<br>第二百七十五章 第二卷凛冬之湖 第八十章 入魔（五）<br>◆ 2024/07/23发表想法<br>择天记也有个想要吸徐有容血的老头<br>原文：老僧抬起头来看着掌心间的少女，眼神温和里透着怜悯，淡而精湛的佛门气息在他脸上浮现，便是干裂唇角的那滴朱血也透着慈悲的意味。<br>第二百七十八章 第二卷凛冬之湖 第八十三章 入魔（八）<br>◆ 把你手脚斫了腌到屎坛子里你大概也不能撑太长时间<br>第二百七十九章 第二卷凛冬之湖 第八十四章 入魔（九）<br>◆ 2024/07/23发表想法<br>资本主义本质世界毁灭与我无关，就是相信下一代人的智慧，不断向未来借债，然后未来科技爆发去还债。<br>原文：僧平静说道：“世界毁灭与我何干？”<br>◆ 他简单却善变，孤独而脆弱，复杂又讨厌，有时嫉妒有时阴险，喜好争夺偶尔埋怨，自私无聊却又变态冒险，爱诡辩爱幻想，善良博爱却又怀恨报复，专横责难，他辉煌时得意，默淡时伤感，他矛盾而虚伪，欢乐却痛苦，伟大却渺小。<br>第二百八十二章 第二卷凛冬之湖 第八十七章 入魔（十二）<br>◆ 旅人要看世间更多风景，要忘却旅途间的疲劳痛楚，便应该手舞足蹈且走且歌之。　　大山独立尘世间，要无视庶民的膜拜才能自在，便应该如此骄傲凛然。　　流云在碧空里停留或飘荡，都是它在追随着风的方向。　　溪水在涧谷里流淌而下，必然要把与石块的每一次撞击当成游戏，轻快随着大地的吸引奔腾而下，激出无数美丽的水花，这样才叫雀跃。　　繁星在夜空里静止或者流转，只是按照它自己的想法微笑看着世间。　　所有的事情都是理所当然。　　这是一种叫做理所当然的畅快。　　因为理所当然，所以哪怕千万人在前，我要去时便去。　　我有一股浩然气，便当自由而行。　　这就是天地之间的至理。　　……<br>◆ 似乎思考挣扎了整整一生那么长。　　事实上只思考了三十粒葱花从小手心里落在煎蛋面上的时间那么短。　　他要活下去。　　他要和某人一起活下去。　　这是最重要的事情。<br>第二百八十五章 第二卷凛冬之湖 第九十章 入魔（十五）<br>◆ 他才明白原来自己一直在只是在等待死亡。　　当年那个雨夜，他没有勇气掘开那座墓。　　自此以后，世界对他来说便是一座凄清的孤坟。　　他是走火入魔的掘墓人。　　他是墓中早已死去的人。　　……<br>第二百八十九章 第二卷凛冬之湖 第九十四章 燃烧的黑眸<br>◆ 先前说你眼力不错，能看出桑桑潜质，但那只是表面，因为直到现在你依然没有看明白，桑桑对我有多重要，她蹙起眉头不喜时，我眼中的世界便不再光明。”<br>第二百九十一章 第二卷凛冬之湖 第九十六章 该谁走？<br>◆ 桑桑睁大眼睛看着他，心想这人长的真是有意思，明明鞋底跳离地面没有超过两寸，但落下来时的动静真大，弄得自己竟有些担心新买的瓮会不会被震裂。<br>第二百九十二章 第二卷凛冬之湖 第九十七章 来相见<br>◆ 老人说道：“他瞎了，估计神智也要过些时日才能清醒。”　　这句话的语气平静寻常，陈皮皮听着却是倒吸一口凉气，恼怒地挠着头，盯着老人颤声愤怒说道：“瞧瞧！瞧瞧！寺里的人你说弄瞎便瞎了，我就算是从观里来的又怎样？我命歹遇着你你还偏要我不要怕，这不是调戏人吗？<br>第二百九十三章 第二卷凛冬之湖 第九十八章 何如下棋聊天吃碗面？<br>◆ 时间只是事件发生的顺序，对于利用时间的我们而言，我们需要利用时间完成应该完成的事件，如果无法完成，那么时间也就没有意义。”<br>第二百九十四章 第二卷凛冬之湖 第九十九章 偷偷的，在一起<br>◆ “冥王之子……听起来好像是很可怕的东西。”　　桑桑的小脸贴着冰冷的枕头轻轻蹭了蹭，看着落在窗前的冬日星光，喃喃自言自语说道：“但已经和你一起活了这么多年，还是只能一起偷偷地活下去吧。”　　……<br>第二百九十五章 第二卷凛冬之湖 第一百章 围巷<br>◆ 老人看着桑桑的小脸，停顿片刻后微笑说道：“把那个新瓮带着，还没有燉过鸡汤，没有油污，待会儿用来装灰应该合适。”　　颜瑟大师听着这话，说道：“如果有旧瓮也带着，说起来你这小丫头靠老道的鸡汤帖也挣了不少银子，我却还没喝过你燉的鸡汤。”　　桑桑低着头轻声说道：“如果你们不出去，我今天给你们燉鸡汤喝。”　　老人怜爱看着她，摇了摇头，又望向颜瑟说道：“旧瓮有油，灰容易粘在壁上。”　　颜瑟大师轻拂道袖，大笑着向老笔斋外走去：“我这辈子道袍上总是油污一片，从来没有嫌弃过，难道还会在意死后变成的几捧灰会不会被油污弄脏？”　　……<br>第二百九十六章 第二卷凛冬之湖 第一百零一章 一步山崖<br>◆ 原来那是因为坐在光明神座上的人……信的是光明。”<br>◆ 信奉光明，昊天并不一定代表光明。<br>第二百九十八章 第二卷凛冬之湖 第一百零三章 新瓮，旧瓮，灰如雪<br>◆ 颜瑟大师指向北方某处，对身旁的老人说道：“我看到了一道前所未有的大符，那道大符只有简单的两笔，起于荒原北方，一笔落于西，一笔落于东。”　　然后他回头望向自己默默守护多年的长安城，感慨说道：“于此间相会。”<br>◆ 2024/07/23发表想法<br>猫腻写悲写得是真好<br>原文：桑桑跪在地上，伸出双手捧着灰往瓮里盛放。<br>
“老师住新瓮，他喜欢干净。”<br>
“少爷的老师住旧瓮，他不怕油。”<br>
她轻声提醒自己，一捧一捧把两个老人的骨灰往瓮里装。<br>
恼人的山风不时前来打扰，吹的那些灰到处都是，甚至吹到她的棉裙和小脸上。<br>
桑桑抬起手背擦了擦脸，然后低头继续往瓮里捧灰。<br>
……<br>
……<br>◆ 桑桑跪在地上，伸出双手捧着灰往瓮里盛放。　　“老师住新瓮，他喜欢干净。”　　“少爷的老师住旧瓮，他不怕油。”　　她轻声提醒自己，一捧一捧把两个老人的骨灰往瓮里装。　　恼人的山风不时前来打扰，吹的那些灰到处都是，甚至吹到她的棉裙和小脸上。　　桑桑抬起手背擦了擦脸，然后低头继续往瓮里捧灰。　　……　　……<br>第二百九十九章 第二卷凛冬之湖 第一百零四章 药酒传人土豆灰<br>◆ 二师兄和陈皮皮走上山顶，第一眼看到便是这样的画面，这幕画面将长久地存在于他们的心里，让他们以后在某些方面全无理由地选择支持这幅画的主角。<br>第三百一十八章 第二卷凛冬之湖 第一百二十三章 痴于花者，默然随之<br>◆ 2024/07/24发表想法<br>宁缺的无耻和唐三十六还不一样，宁缺是真无耻，是经历过尸山血海完全没有道德底线的无耻。<br>原文：宁缺有些尴尬，不知道该怎么接话来掩饰自己的无耻，于是干脆闭上了嘴。<br>第三百一十九章 第二卷凛冬之湖 第一百二十四章 在荒原的北方呼唤爱<br>◆ 这些日子以来，隆庆皇子的脸上终于露出了一丝微笑，他看着东方熹微的晨光，轻轻嗅着脸畔传来的气息，哑声说道：“你难道不觉得自己抱着的是一具尸体？”　　陆晨迦低着头，微笑说道：“如果你肯回头看看我，就会知道我现在也很难看。”<br>第三百二十一章 第二卷凛冬之湖 第一百二十六章 王子与乞丐<br>◆ 他抬起头来继续眯着眼睛看向北方的黑夜，然后缓慢地转过身，看着数十丈外的陆晨迦，声音沙哑说道：“我饿了。”　　陆晨迦眼眶一湿，险些哭出来，强行平静心思，用颤抖的手取出干粮，用每天都暗中备好的温水化软，然后捧到他的面前。　　隆庆没有再说什么话，就着她不再娇嫩有些粗砺的掌心，慌乱吞咽干净食物，然后满意地揉了揉咽喉，重新上路。　　只不过这一次他不再向北，没有任何征兆，没有任何理由，没有任何言语，自认被昊天抛弃的他，不再试图投奔黑夜的怀抱，而是落寞转身，向南方中原而去。<br>◆ 一个瘦弱的乞丐可能会引发民众的同情心，一百个瘦弱的乞丐就只可能引发民众的厌恶与恐惧<br>第三百二十二章 第二卷凛冬之湖 第一百二十七章 血馒头<br>◆ 车窗窗帘被掀起一角，车厢里的宁缺看着城门墙下一名乞丐，不知想起了什么，沉默片刻后说道：“当年无论我和桑桑过的再艰难，我们都没有想过去要饭。”　　大师兄望着他微异问道：“为什么？”　　宁缺看着那名乞丐身前的破碗，说道：“因为乞讨来的东西总是容易被人抢走，而且要来的饭不香，与之相比较，我宁肯去抢。”<br>◆ “理解和同情是一种很廉价的情绪，这个世界总是凶险的，如果要活下去便要学会拒绝这些情绪，不能让自己沉浸在这种情绪中无法自拔。我一向以为那些遇着些挫折便冒充孤独、模仿绝望、哭天喊地、伤害自己伤害亲人、以为全世界都对不起自己的家伙，都是废物中的废物。”<br>第三百二十四章 第二卷凛冬之湖 第一百二十九章 汝虽未老，但请归老<br>◆ 这种日子真的很苦闷，陛下始终不肯完全信任我，神殿更是对我戒心十足，而像唐那样的明宗子弟，一旦出世第一次事情就是要杀我。”<br>第三百三十八章 第二卷凛冬之湖 第一百四十三章 鸽子汤（下）<br>◆ 曾静夫人非常直接、甚至显得有些粗鲁无礼地将书房里那些来拜见大学士的下属官员赶走，然后走到他的身前，还没有来得及说些什么，眼圈一红便流下两行泪水。<br>第三百三十九章 第二卷凛冬之湖 第一百四十四章 没有你，我困不着觉<br>◆ 2024/07/24发表想法<br>皮皮是宁缺的贵人，他让宁缺能走上修行道路。宁缺拜托那么多人照顾桑桑，最在意的也是皮皮。<br>原文：陈皮皮艰难迈过门槛，揉了揉疲惫的圆脸颊，看着铺子里的情形，大乐说道：“难道你这里又有麻烦？本天才还正愁那些人被我吓住就不好玩了。”<br>第三百四十章 第二卷凛冬之湖 第一百四十五章 新友故旧，重逢初看<br>◆ 看到那个家伙，桑桑哪里还能记得吃面条这件事情，素如白指的汤面挂在唇边，柳叶眼笑的眯了起来，含着食物口齿不清憨喜说道：“宁缺……”<br>◆ 宁缺笑着看着她，眼睛也笑的眯了起来，就像这个世界不存在的月牙儿<br>第三百四十二章 第二卷凛冬之湖 第一百四十七章 书院之直<br>◆ 少爷我真有件事情要和你说。”　　“先不慌。”宁缺想起一件事情，从怀里摸出一个小盒子，“我在土阳城里花了半个月时间，给你精心挑选了件礼物，你看看喜欢不？”<br>◆ 就算他是冥王之子，对桑桑而言也没有任何影响，更何况是什么魔宗余孽，难道修了魔宗功法的少爷就不是少爷<br>◆ 仿佛猜到他在想什么，二师兄沉默片刻后缓声说道：“我对大师兄向来尊敬，但我尊敬的是他的修为、心境乃至德行，至于他信奉的那些宽恕之道，处世之法，我却是与他有不一样的想法，若真以德报怨，那我们用什么来报德？”　　听着这番话，宁缺想会儿后认真问道：“那何以报怨？”　　二师兄说道：“当然是以直报怨。”<br>第三百五十七章 第二卷凛冬之湖 第一百六十一章 苦孩子<br>◆ 他在桌边沉默了很长时间，脸上的神情显得有些僵硬，巷子里不时有人经过，当那些人影映上铺门时，他便会抬起头，然而始终没有人推门进来。　　没有人推门回来。　　宁缺一直沉默等到快要近午的时候，他忽然起身推开铺门走了出去。<br>◆ 宁缺满意地看着桌上的饭菜，双手扶膝，然后继续等待。　　然而等了很长时间，依然没有人回来吃饭。　　还是两双筷子，却只有一个人，而米饭和菜都已经冷了。　　宁缺盯着桌上的饭菜看了很长时间，然后伸手拿起筷子开始吃饭。　　然而不知道为什么，他的手有些颤抖，夹了半天竟是连一根青菜都夹不起来。　　他抓起筷子便想扔出去，却又强行压抑住，缓缓搁到桌上。<br>◆ 他知道桑桑应该没有什么危险，但他清楚这会是自己这辈子所面临的最艰难的战斗，所以带上了自己所有最重要的东西，似乎只有这样他才能安慰自己，自己一定能够找回自己生命中最重要的那件东西。　　如果找不回来，那他也不用回来了。<br>第三百五十八章 第二卷凛冬之湖 第一百六十一章 寻人<br>◆ “你们不用怕他。公主殿下肯定会向着我，而且我要回来住，他根本没有任何办法，至于书院那边，二先生对我说过不会让他欺负我，如果他敢把这座宅子烧了，我就去向二先生告状，二先生肯定会把他的人给烧了。”<br>第三百五十九章 第二卷凛冬之湖 第一百六十三章 不喜欢<br>◆ 这关我什么事？这关我什么事？你的事情凭什么不关我的事？宁缺越想越是生气，气的像隔壁吴老板一般浑身发抖，卷起袖子便在学士府书房里四处寻摸起来，像极了一只热锅上的蚂蚁。<br>◆ 桑桑的小脸上没有任何情绪，没有生气没有愤怒也没有哭泣，她看着他面无表情说道：“我饿了，要睡了，你走吧。”　　饿了所以要睡，这句话说的毫无逻辑。<br>◆ 宁缺看着她说道：“你不在家我睡不好。”　　桑桑不说话。　　宁缺说道：“那我饿了谁给我煮面吃啊？”　　桑桑不说话。　　宁缺忽然说道：“我给你煮面吃好不好？”　　桑桑还是不说话。　　宁缺沉默很长时间后说道：“我先去静一静，明天我再来接你。”　　说完这句话，他转身向书房外走去。　　桑桑走到书房门旁，看着向花圃里走去的宁缺，说道：“鸡蛋在灶房米缸里，煎的时候你少放点油。”　　……<br>第三百六十章 第二卷凛冬之湖 第一百六十四章 骂湖<br>◆ “你长的真的很难看。”　　桑桑看着镜中的自己说道。　　从昨天夜里听到宁缺那句话，到清晨离开老笔斋，再到下午与宁缺重新相见，她一直都没有哭，甚至没有流露出任何悲伤的神情，因为那是她一直在提醒自己不要哭，无论如何都不要哭。　　那些弱质纤纤的大小姐扶着花儿可以流泪，因为她们 好看，而你虽然也很弱，但生的这般难看，又哪里有资格哭呢？　　……<br>◆ “我是想给他结婚腾地方。”　　“但你明明知道他不会把你扔下不管，所以你这就是逼着他做选择，他对你已经够好了，你怎么能这么残忍？”　　“可他说过要过一辈子的。既然说好要一起过一辈子，多一个人也能叫一起吗？多一个人还能过一辈子吗？”　　“你为什么非要和人抢呢？”　　铜镜里的桑桑难过回答道：“可是那本来就是我的呀。”　　铜镜外的桑桑沉默说道：“可是他会很难过。”　　“我从来没有抢过东西，但这次不一样，就算他会难过，就算我变成讨人厌的小孩子，就算我变得更丑，我还是要抢。”　　铜镜内外，桑桑抹掉脸上的泪水，满是小孩子气倔强说道。　　……<br>第三百六十四章 第二卷凛冬之湖 第一百六十八章 佛首与肉包<br>◆ 因为桑桑离家出走，他身上的这股杀意从昨日清晨酝酿至日幕，随着他在长安城里的寻找而逐渐凝练恐怖，当时便险些要将整座长安城给掀翻，昨夜在湖畔又被夜风风干至腊肠一般辛辣干硬。　　可以佐酒，可以杀人。<br>第三百六十六章 第二卷凛冬之湖 第一百七十章 剪烛<br>◆ 宁缺摇了摇头，说道：“已经做了决定，就不再需要什么感动，那除了让我自己高兴没有别的任何意义，甚至那很下作。”<br>第三百六十七章 第二卷凛冬之湖 第一百七十一章 松鹤楼纪事（上）<br>◆ 醉酒之人分很多种，有所谓武醉，那便是要借着酒意发泄打人踢树砸墙，也有所谓文醉，那等人要借着酒意写诗抄诗卖弄诗，宁缺不属于这两种，因为他不会写诗，所以他只是借着酒意不停喃喃自言自语。<br>◆ “这是用来贮酒，又不是用来磨墨写字的，怎么能用黄州泥呢！”<br>◆ 如果没有我那她该怎么办啊，然后又变成，如果没有她我该怎么办啊？我依然能活着，说不定还能活的更轻松，但什么才是轻松？习惯了，如果习惯被打破，就不可能轻松，因为你总会觉得你生命里少了一些很重要的东西，总觉得你的身体少了很重要的一部分。”<br>◆ 老人闻言大怒，训斥道：“姜是老的辣！”　　宁缺不屑应道：“韭菜还是嫩的香。”<br>第三百六十八章 第二卷凛冬之湖 第一百七十二章 松鹤楼纪事（下）<br>◆ 老人手中握着根极粗的短木棒，看着他恼怒说道：“废话真多！说的我头皮发胀，就凭你这副模样，居然也想杀夏侯。”　　宁缺没有听清楚这最后一句话，两眼一翻便晕了过去。<br>第三百七十章 第二卷凛冬之湖 第一百七十四章 粥与信，从前和以后<br>◆ 看着老笔斋里对桌吃饭的宁缺和桑桑，莫山山终于确信这两个人在很多年前，便已经是一个单独的世界，对于他们来说，世间其余的任何人都是世外之人，任何事都是世外之事，很难在那个世界里留下自己的影子。　　就像是眼睛和睫毛，只不过平时眼睛看不到睫毛，睫毛也刺不到眼睛，而当外界吹来一阵劲风时，两者才会注意到彼此的存在。　　“但我是山，不是风。”<br>第三百七十七章 第二卷凛冬之湖 第一百八十一章 崖洞囚徒的第一次越狱<br>◆ 那个洞口仿佛准备着吞噬掉走进去所有人或物，甚至包括光线，春夏，秋冬，时间以及附着在时间上的所有感受。<br>第三百八十章 第二卷凛冬之湖 第一百八十四章 解决问题有三种方法，或者一种<br>◆ 居移体，养移气，<br>第三百八十二章 第二卷凛冬之湖 第一百八十六章 三本书（下）<br>◆ 君子不器，是指人不能拘泥于一些固有的规则。<br>◆ 不器二字，便是对规则禀持着居高临下，骄傲而散漫的态度。<br>◆ 碗是器物，石缝是器物，便是天穹原野也只不过是个尺度极大的器物。　　水落在碗中，便是半圆形，落在石缝间便是透明蚯蚓，被云层释出，便是珠帘，润进原野，便是无数的细小颗粒。　　水本身没有任何形状，只是因为承载它的器物才有了形状。　　这便是真正的不器。　　天地元气就是这种像水一般的存在？<br>◆ 用针尾挠了挠有些发痒的鬓角<br>◆ 最关键的是，他自幼穷困怕了，养就了吝啬抠门的性子，如今不再发愁没钱，却依然下意识里想要贪些小便宜。<br>第三百八十五章 第二卷凛冬之湖 第一百八十九章 旧崖生新绿<br>◆ 原来空虚寂寞这些东西，永远与风景无关，只与人有关。<br>第三百八十八章 第二卷凛冬之湖 第一百九十二章 跳瀑布，说禽兽<br>◆ 陈皮皮终于听明白宁缺在说什么，胖乎乎的身躯像弹性十足的鱼丸般，嗖的一声从地面弹起，满脸通红指着洞里的宁缺，破口大骂道：“欣赏！你懂不懂什么叫欣赏！你这人脑子里怎么尽是这些污秽的东西！”<br>第三百九十六章 第二卷凛冬之湖 第二百章 夫子论夜<br>◆ 从而可以自在快乐地和桑桑一起在人世间白头到老，但只要是能够思考的人，总想知道时间的尽头是什么，为什么会发生这一切。<br>第四百九章 第二卷凛冬之湖 第二百一十三章 不好糊弄的男人们<br>◆ 2024/07/26发表想法<br>其实感情线变化是很清晰的。从小相依为命的兄妹之情，到如吃饭喝水一般的相濡以沫之情，到山山出现，桑桑出走，桑桑逼迫宁缺做出抉择，这相当于桑桑做出要嫁宁缺的选择，让宁缺正视与桑桑的感情。而如何让这种原本相濡以沫的类似亲情的感觉转变成男女之情，就是通过山山，没有山山宁缺和桑桑的感情线就会一直拖下去。你如果拿自己的一套价值观去约束小说里的人物，那几乎没有人物是完美的。<br>原文：“等她过了十六，我就娶她。”<br>◆ 曾静捋须的手指一抖，胡子掉了三根。<br>第四百一十二章 第二卷凛冬之湖 第二百一十六章 借剑（下）<br>◆ 她很清楚所有挫折都是昊天的考验，只要自己道心足够坚定强大，便能把所有这一切变成漫漫修行道畔最美丽的风景。<br>第四百一十四章 第二卷凛冬之湖 第二百一十九章 走吧，走吧<br>◆ 朝小树看着她说道：“我只会给一种女人银子。”　　妇人脸色苍白，凄楚说道：“原来如此，可惜我虽然是个不守妇道的寡妇，想把身子给你，但要靠身子挣你的钱，却是不愿意的。”　　朝小树静静看着她的眼睛，温和说道：“你误会了，我是说我只会给妻子家用，却不知道你愿不愿意拿家用。”<br>第四百一十九章 第二卷凛冬之湖 第二百二十四章<br>◆ 老将军没有穿朝服，没有穿官服，没有穿盔甲，而是穿着一件很普通的布衣，没有种白菜，没有磨刀，而是在捧着饭碗吃饭。<br>◆ 你就是一个寡廉鲜耻冷酷无情贪婪好杀的无耻小人。<br>第四百二十章 第二卷凛冬之湖 第二百一十五章<br>◆ 2024/07/27发表想法<br>那这样万恶的世间又有什么理由活着呢<br>原文：之所以无恶不作，那是因为他所处的人间有万般罪恶。<br>
为了在万恶的人间活下去，他必须无恶不作。<br>◆ 2024/07/27发表想法<br>虽然宁缺是个很复杂的人物，但又是个很固定的人物，看不到人物的改变人物的成长，从小到大一直都是如此，这样人物就单调了。<br>原文：时时如此，时时不如此。<br>
如此才是宁缺。<br>◆ 时时如此，时时不如此。　　如此才是宁缺。<br>第四百二十一章 第二卷凛冬之湖 第二百一十六章 朱雀认主<br>◆ 他喜欢这片土地，喜欢这个国度，喜欢平静喜乐的生活，喜欢生活在此间的人们，所以他愿意承担这种责任。　　他愿意用除了生命之外的任何事情，来维护大唐的安宁，但这并不代表他便要因此失去自己的人生。　　左手握着阵眼杵，是握着大唐的将来。　　右手握着黑伞，是握着自己的人生。　　两手都要握，两手都要握紧。<br>第四百二十五章 第二卷凛冬之湖 第二百三十章 不要脸之争，以及吹牛<br>◆ 陈皮皮说道：“夫子曾经说过，如果本心向善，只是为大势而在局部稍作退让，那么只能说其人锋锐有失，却不能妄言其伪。”<br>第四百四十章 第二卷凛冬之湖 第二百四十五章 举伞<br>◆ 盛夏，草长，鹰飞。唐身上有无数道伤口，鲜血还在淌落，落在草上，便开始燃烧。夏侯以拳堵唇，开始咳嗽，有血从指间溢出，如岩壁上一只受伤的鹰。鹰一般都叫老鹰。只是鹰可以老，人却不能老。……<br>第四百四十一章 第二卷凛冬之湖 第二百四十六章 熬鹰<br>◆ 自古名将如美人，不许人间见白头，然而他的头已然白了。<br>第四百四十五章 第二卷凛冬之湖 第二百五十章 粉笔，粉冰，粉遗憾<br>◆ 宁缺压低声音说道：“喂我口。”　　桑桑看了眼夫子，低着头说道：“这是给我的。”　　宁缺大感恼怒，冷笑说道：“好吃你就多吃点。”<br>◆ 宁缺开心地笑了起来，说道：“我也很遗憾……能知道为什么吗？”<br>第四百四十六章 第二卷凛冬之湖 第二百五十一章 总有群星坠落的那时<br>◆ 陈皮皮不待他回话，毫不客气地坐到桌旁，轻击桌上那只瓷碗，对旁边的布衫少女说道：“给爷盛碗粥。”<br>第四百五十五章 第二卷凛冬之湖 第二百六十章 当年事，如今如何？<br>◆ 2024/07/28发表想法<br>宁缺杀夏侯向来是为了自己，它通过杀死夏侯来斩断过去。那个他为自己活下来让将军儿子死去的过去。存在主义看来自由选择要背上绝对的责任。宁缺无法说服自己说是自己是被迫让将军儿子死去的，因为他完全可以选择自己牺牲，所以他只能自己背起这份责任。宁缺选择将这种责任转化为复仇。<br>原文：“敌人可以死于天灾人祸海啸河溃，只要他不再拦在我们的身前，阻挡我们前进的道路，破坏我们的事情，他就算吃饭噎死，上厕所臭死，都无所谓。”<br>
“但仇人不同。”<br>
“复仇这种事情，如果时间拖的太久太长，往往会逐渐发酵演化成另外一种味道，比起要让对方死，为当年的故事付出代价而言，更重要的事情，仿佛是要通过杀死对方让自己忘记当年的故事，从此得到真正的解脱。”<br>◆ “敌人可以死于天灾人祸海啸河溃，只要他不再拦在我们的身前，阻挡我们前进的道路，破坏我们的事情，他就算吃饭噎死，上厕所臭死，都无所谓。”　　“但仇人不同。”　　“复仇这种事情，如果时间拖的太久太长，往往会逐渐发酵演化成另外一种味道，比起要让对方死，为当年的故事付出代价而言，更重要的事情，仿佛是要通过杀死对方让自己忘记当年的故事，从此得到真正的解脱。”<br>第四百六十一章 第二卷凛冬之湖 第二百六十六章 小道观，真自在<br>◆ 那名有些瘦的道人，看着二人无奈叹息一声，说道：“我买了二十几坛酒，才召集了这么些信徒来听宣讲，结果……全部让你们给逼走了，我实在是不明白，你们究竟是来做什么的？来闹场的吗？”<br>◆ “过去种种，譬如昨日死。”<br>第四百六十二章 第二卷凛冬之湖 第二百六十七章 秋意浓<br>◆ 轻仇之人每多寡恩<br>◆ 2024/07/28发表想法<br>这不可能杀完的，人与人之间是普遍联系的，杀了夏侯还要杀皇后吗，杀了皇后还要杀皇帝吗，夏侯没有忠心耿耿的下属？就像夏侯无法杀完宣威将军府的人，宁缺也不可能斩草除根。所以冤冤相报的确无法了。<br>原文：二师兄沉声应是，望向大师兄正色说道：“师兄，若不想冤冤相报何时了，那便应该将仇人尽数杀死，斩草除根，如此一来，世间便只剩下几缕无力复仇的冤魂，仇恨的故事便到此为止。”<br>第四百六十七章 第二卷凛冬之湖 第二百七十二章 观雪怅然<br>◆ 有的人能够做到极端无耻，其实本身就需要很大的勇气。<br>◆ 夏侯轻轻咳嗽两声，说道：“他能伤我，我能伤他，都是理所当然的事情，只不过想要杀死他，需要投入更多条命才行，荒原上的那些铁骑，都是跟随我很多年的忠诚下属，何必让他们拿命去换？”<br>第四百七十二章 第二卷凛冬之湖 第二百七十七章 这不是书上写的故事<br>◆ 桑桑没有害怕，只是感受着他此时的感受，悲伤着他此时的悲伤，寒冷着他此时身心的寒冷，下意识里伸手握住他的手，想要给他一些温暖。<br>◆ “凭什么书上怎样写，我就要怎样做？”　　“凭什么将军的儿子要活着，门房的儿子就要去死？”　　“凭什么我要去死？”<br>第四百七十三章 第二卷凛冬之湖 第二百七十八章 旗展<br>◆ “所谓自由，便是选择的权利。选择去生，选择去死，或者选择不选择，当年你小师弟选择拿起那把柴刀，杀死管家和自己最好的玩伴，在那一刻，他便向自由的彼岸迈出了第一步。”<br>第四百八十二章 第二卷凛冬之湖 第二百八十七章 明枪<br>◆ 2024/07/28发表想法<br>这很不合理，大黑伞当时杀大剑师的设定不是只能挡元气不能挡力道吗？这一枪宁缺入魔都得重伤，桑桑怎么可能接的下。而且宁缺把桑桑的命看得很重，杀夏侯这种事本就不可能带桑桑才对。<br>原文：她知道宁缺不会回头来救自己，因为宁缺来不及救自己，因为宁缺相信她能救自己，因为此时此刻她必须自己救自己。<br>第四百八十七章 第二卷凛冬之湖 第二百九十二章 你死以后<br>◆ 你死以后，我就可以不用再想着要杀死你，这样我才能得到真正的自由，去做我想做的事情。<br>第四百九十二章 第二卷凛冬之湖 第二百九十七章 新生、落石以及崖畔的春游<br>◆ 没有亲身经历，再如何动人的选择都也许只是虚假的煽情……不过如果是现在的我，我大概会选择什么都不做。”<br>第五百一章 第三卷多事之秋 第八章 此去拜佛好不好<br>◆ 夫子看着他微笑说道：“冥王之子需要定义，却不能由人类来定义，只能由你自己定义，正如人之所以为人，是因为我们相信我们是人，只有我们才能给出人的定义，而不能由昊天或别的存在来定义。”<br>第五百一十九章 第三卷多事之秋 第二十六章 没有屁股的道士<br>◆ “你虽然双膝跪在我的身前，但在你的心里，你却还是站着的。”<br>第五百二十四章 第三卷多事之秋 第三十一章 青山不得出<br>◆ 2024/07/29发表想法<br>这个反派的确让人讨厌得厉害。<br>原文：中年道人看着渐渐被流云吞噬的那个人形空洞，默然想着，如果这样你都没有死，那么你或许真的便是传说中的天谕之人。<br>第五百五十一章 第三卷多事之秋 第五十七章 不识真佛在眼前<br>◆ 桑桑看着他认真说道：“冥界听着很可怕，但我可以在那里等你。”<br>◆ 宁缺把她抱的更紧了些，说道：“不管是黑桑桑还是白桑桑，只要能还像从前那样贪财凶悍，那就是能让少爷高兴起来的好桑桑。”<br>◆ 那是因为她以前觉得没有必要在宁缺面前扮可爱，她更不需要在别人面前扮可爱，而现在她想让宁缺觉得自己可爱一些。<br>第五百七十四章 第三卷多事之秋 第七十九章 悬空寺的因果<br>◆ 桑桑这辈子最大的愿望就是变白。<br>第一千一百六十章 第六卷忽然之间 第一百三十章 结尾<br>◆ 真实的宇宙，是那样的荒凉又危险，而且寒冷，和冥界有什么区别？<br>]]></description><link>culture\阅读\将夜.html</link><guid isPermaLink="false">Culture/阅读/将夜.md</guid><pubDate>Mon, 09 Sep 2024 11:50:28 GMT</pubDate></item><item><title><![CDATA[刘擎西方现代思想讲义]]></title><description><![CDATA[ 
 <br><br>《刘擎》<br>Administrator<br>
481个笔记<br>现代思想路线图<br>◆ 人类从古代到现代发生了重要的历史转变，这种转变首先发生在17世纪的西方。现代社会在取得巨大成就的同时，也带来了严峻的问题。<br>◆ 在前言之后的导论中，我们会解释“现代”的概念，阐述古代到现代的转变特征，让你对“现代性问题”的基本轮廓能有初步的把握。 	之后，我们开始进入第一章，核心人物是马克斯•韦伯。我们的旅行以韦伯为起点，因为他透彻地阐明了现代世界的基本特征——“理性化”。同时，韦伯敏锐地指出，理性化的现代世界将会瓦解传统社会的原则与规范，这对个体的人生信仰以及公共的社会政治秩序都形成了严峻挑战。由此，你会更为清晰地看到现代性问题的面貌，理解这一问题所包含的相互交织的两个维度：人生难题与社会困境。此后的三章沿着这两个维度分别展开。 	第二章以尼采、弗洛伊德与萨特的思想为主线，从人生难题的维度，探讨了“现代人的精神危机”的来由和应对这种危机可能有的困难。 	第三章转向社会困境的主题，讲解鲍曼、波普尔、哈耶克、伯林、阿伦特和马尔库塞这六位思想家，从多个方面考察体现为社会政治灾难的现代性危机，反思“20世纪的教训”为我们带来的启示意义。 	第四章仍然着眼于社会政治领域，阐述了罗尔斯、诺齐克、德沃金、沃尔泽、桑德尔、泰勒和哈贝马斯这七位思想家的理论要义。他们主要针对20世纪后期的社会秩序问题，在同时面对多元化、平等和自由这三种现代诉求的压力下，探讨作为西方主流思想的自由主义的回应方案，以及由此引发的批评争论。 	最后在“尾声”一章中，我们进入了当代的“后冷战时期”，通过了解亨廷顿和福山这两位思想家的主要论述，思考全球化时代的挑战与希望。<br>启程的意义<br>◆ 在回答了“学什么”的问题之后，我再来说“为什么学”的问题。 	“西方现代思想”这个主题听上去有点高冷，会有什么吸引力值得你上路呢？我的邀请可以有许多理由，如果只讲一个，我想应该是，学习现代思想能够帮助你学习怎么做一个“清醒的现代人”。<br>◆ 举一个和个人生活有关的例子：在整个古代，你要和谁结婚，首要条件就是门当户对。到了20世纪，两情相悦变成了理所当然，要先有感情，再谈婚姻。近几年，天经地义的标准又松动了，许多年轻人开始疑惑：结婚真的好吗？<br>◆ 我在上大学时，听过一位美国历史学家的讲座。他说，1900年元旦的时候，西方人也很乐观，相信现代化的力量会带来光辉灿烂的前景。但没几年过去，第一次世界大战就爆发了，然后是第二次世界大战，紧接着核危机、冷战、反反复复的经济危机，各式各样的文化危机、精神危机随之而来，这些危机到今天也没有结束。<br>01 思想有什么现实意义<br>◆ 这本介绍西方现代思想的讲义有一个突出的特点，就是格外关注思想观念对社会实践的塑造作用，强调思想与现实的内在关联。<br>思想内在于现实<br>◆ 最常见的误解，就是把思想和现实看成两种分离的东西。<br>◆ 把思想和现实对立起来，看成两种分离的东西，虽然很流行，却是完全错误的。你可能会说，我知道“思想离不开现实”，但我要强调的观点比这还要深入一步，是说“现实离不开思想”。如果离开了思想，根本不存在“社会”现实，当然也谈不上去理解现实。<br>利益并不是物质性的<br>◆ 说人是“自利的”，这听上去很实在很正确，但我们追求的“利益”这个概念本身，并不是单纯物质性的，其实涉及行为的复杂动机结构。<br>◆ “重要”是需要解释和判断的，必须依据一个思想观念的框架，你才能确定什么是重要的。<br>◆ 从小处说，假设你的男朋友或者女朋友偶然出轨了，从单纯“物质”的意义看，其实你毫发未损啊，怎么就会觉得自己的利益被损害了呢？因为这里有一个思想观念，“爱情必须有排他性的忠诚”。正是依据这个观念，你才会感到利益受到损害。<br>人类行为的复杂动机结构<br>◆ 思想观念是人的社会实践行动的驱动要素，这在经济领域之外表现得更为复杂多样。比如，有人为爱情可以放弃许多物质利益，还有人为某种理想或信仰可以牺牲很多世俗的利益。这是简单的“自利”和“理性”概念无法解释的。<br>◆ 人对利益的认知有非常丰富的层次。生存与安全以及基本饮食居住保障，是基本的利益；人与人之间的交往，包括亲密、友爱和归属感也是对生活的重要需求，当然也是利益。人希望获得肯定、承认或者尊重，获得工作的成就感、创造的满足感，以及身份认同感等，这些都是人生重要的需求，因此构成了利益的要素。<br>“现代”是一种新的时间意识<br>◆ 在古代人的历史观念中，“当下的时代”不过是以往时代的延续和重复，没有什么新奇之处，也就不值得特别的关注。在古代世界，包括中国，人们感知到的时间是不断在循环的。许多直接的自然经验都和人们的这种感受相吻合，比如日复一日的太阳升起又落下，年复一年的春夏秋冬四季轮回，王朝的由兴而盛、盛极而衰的更替……这些都对应着循环的时间意识，它们在学术界被称为“循环历史观”。 	但到了文艺复兴，特别是在启蒙时代和工业革命之后，西方社会发生了剧烈变动，上述的“循环历史观”被改变了。这在很大程度上是因为，人们对“当下的时代”表现出了越来越强的敏感。“当下的时代”不再是以往的延续和重复，而是前所未有的，是崭新的。因此，时间不再是循环往复的，而是线性展开的——从过去、到现在，然后通向未来，时间成为一个有方向的矢量概念。<br>◆ 马克思和恩格斯在《共产党宣言》中写过这样一句话，“一切固定的东西都烟消云散了，一切神圣的东西都被亵渎了”。这句话生动地表达了“现代”的含义：现代就意味着崭新的重大变革，也可以被称作“古今之变”。<br>03 古今之变：古代和现代到底哪里不一样<br>◆ 如果我们做出选择的最高基准是主观意愿的话，“选择”就成了孤证。除了“我的意愿”，不存在任何同等有力的旁证。选择变得脆弱、变得不稳定。我们可能自己都无法坚信自己的选择。<br>◆ 于是，我们一方面处在解放的轻松与兴奋当中，另一方面又处在不确定的、没有把握的焦虑当中；一面习惯于“轻率的傲慢”，一面又常常感到惶恐和不安。<br>◆ 简而言之，过去我们更重视事物内在的客观价值，主观意见不能轻易动摇这种客观价值。而现在，个人主观赋予的价值变得极其重要，有时甚至能压倒其它一切标准。古今之变，这是其一。<br>◆ 这种“正义”是指，每个事物都有自己确定的意义。我们应该依照这个意义行事。而这个意义是自然给定的，也就是理所当然的。<br>◆ 共同的神话束缚了我们，却也让我们有了共同的准则。摆脱这个神话之后，我们有了自由，却又陷入混乱和茫然之中。 	这就是古今之变的第二点，人们观念中的自然秩序被理性给打破了。<br>◆ 自然的秩序被打破了，我们建立起了理性的新秩序，这就是古今之变的第三点。 	现代工商业因此而发展，但新的问题出现了。理性计算的逻辑会一直向前推进，导向一些我们不喜欢的后果，比如“工作996，生病ICU”，人变成了工业链条上可磨损的零件。<br>古今之变的思想动力<br>◆ 推动古今之变的主要思想动力是“理性”的观念，更确切地说，是启蒙运动主张的理性主义。可以说，启蒙理性主义就是现代社会在思想层面上的发动机，这股巨大的力量推动着现代变革，而转变的结果又反过来强化了启蒙理性主义的主导地位，成为支配现代世界的思想观念。<br>◆ 你首先要意识到，一般谈论的理性和这里所说的“启蒙理性主义”有相当大的区别。古代社会当然也重视理性，但古代同时也注重人的其它各种能力，包括信念、情感、感受、直觉、冥想、猜测和灵感等。理性与人类其它的能力处在比较平衡的相互联系之中。只有到了欧洲的启蒙时代，西方社会才把理性推到了至高无上的地位，理性成为划分“光明”与“黑暗”的决定性标准。<br>◆ 启蒙的英语单词是“Enlightenment”，其中的词根“light”是光的意思“lighten”就是光照，“enlighten”就是赋予光明。启蒙字面上的意思就是赋予光明。把理性视为光明，是启蒙理性主义的特征。但这种思想不是突然来临的，它早在西方文明的源头，也就是古希腊哲学中就埋下了伏笔。<br>◆ 因此，启蒙就是用理性的光芒打破黑暗，让人摆脱非理性的蒙昧，走向成熟。理性成为区分真理与蒙昧的决定性标准，成了衡量一切的准绳；理性甚至取代了神的位置，具有近乎上帝一般的神圣地位。这是启蒙理性主义的确切含义。在思想层面上可以说，启蒙理性主义是西方古今之变的核心。<br>古今之变后的两个观念转变<br>◆ 古代人有一种整体性的宇宙观，把人类看作是自然世界的一部分，人类与自然是不可分割的整体，这很接近中国人说的“天人合一”的观念。那么，现代人看待世界的方式发生了什么转变呢？就是把人类与自然分离开来，人类从整体的宇宙中脱离出来，变成了与自然世界相对的“人类主体”，这在思想史上被称为“人类中心主义的转向”。<br>◆ 要注意，这种转变是思想观念的转变。人类总是生活在地球上的，在物理意义上，我们当然不可能脱离地球这个自然世界。但在观念上，人类可以用不同视角来看待自然世界。<br>◆ 在科学研究中，人类是考察者，是主体，是英文中的“subject”，而自然世界成为我们考察的对象，是客体，对象和客体的英文都是“object”。人类身处自然之中，但在科学主导的思想观念中，人类从自然之中脱离出来，站在了自然世界的对面，形成了面对面的关系，而且人类处在积极主动的主体地位，自然处在消极被动的客体位置，人类与自然变成了主体与客体的关系。<br>◆ 古代人看自己的方式是群体性的，个人与群体是不可分割的整体。你可能常听人说，中国文明是集体主义的，西方文明是个人主义的，这是错误的俗见。古代的西方文明同样是群体优先的，个人首先是群体的一部分。而现代人看待自己的方式，是把个人与群体分离开来，个人从传统的、非常牢固的社群关系中脱离出来，成为具有高度自主性的个体。这在思想史上被称为“个人主义的转向”。 	这个转向也是观念性的。个人当然永远生活在群体关系之中，人不可能脱离社会，变成与世隔绝的孤立个体。但是，古今之变的一个重要变化就是人口的流动，对个体的直接影响就是，你不是被绑定在某个特定的群体之中过完这一生的。在古代社会中，大部分人从出生到死亡，都生活在一个特定的社群之中。因此，你根本不能想象，离开这个社群你自己的生活会变成什么样，因为你的物质生活依赖这个群体的供给，你的精神生活也是亲朋好友邻居塑造的。在这种处境中，个人深深地嵌入在社群之中，“个人主义”的观念是匪夷所思的。<br>◆ 你会发现，那种无法离开的所谓“血肉相连”的有机共同体是一个神话，只有你和你自己才是血肉相连的。个人的重要性和优先性就突显出来。人首先是一个独立的个体，可以脱离任何一个群体，进入别的群体。这就是“个人主义的转向”。<br>◆ 但个人主义的自由也是有代价的，因为个人失去了与一个特定群体的久远、厚重和牢固的纽带关系，这带来了孤独感、漂泊感和乡愁。这也是现代性困境的一部分。<br>◆ 第一个改变和挑战与个人生活的意义有关。如果人们不再相信神、不再相信传统、不再相信天道，那么该信仰什么呢？换句话说，人生活的意义是什么呢？我们用理性去回答这个问题，会发现非常困难，甚至无能为力，所以我们时常感到焦虑和空虚。我们该怎么面对这些精神困境呢？怎么找到生活的意义和理由？这是一个难题。 	第二个改变和挑战是社会生活的秩序。在以理性为基础的新秩序中，自然等级已经被瓦解，我们相信人人都是自由平等的，那么谁应当来统治谁呢？这时候统治和服从都需要理由，那么这个理由经得起理性的质疑和讨论吗？社会秩序就建立在我们对这些问题的回答之中。这是另一个难题。<br>韦伯的人生<br>◆ 德国在第一次世界大战战败之后，韦伯写信给德军的实际指挥官鲁登道夫，要求他向协约国献上自己的头颅，挽回德国的荣誉。鲁登道夫当然不会就这样自杀了，但他同意和韦伯见面。结果两个人唇枪舌剑，辩论了好几个小时。我很难想象，世界上有哪个学者能和一个将军展开这样的辩论。<br>◆ 在56年的生命中获得如此卓越的成就，让人惊叹，也令人敬畏。我想起韦伯的墓志铭，那是来自《浮士德》的一句话：“我们将再也见不到他的同类，尘世的一切莫不如此。”这句话用在韦伯身上再恰当不过。<br>看清理性化的世界<br>◆ 人到了怎么样的境界可以称为真正的成年？我认为大概有两个标志：第一是明白自己，对自己的过往有真正的理解；第二是反思自己，能看透自己存在的问题。一个人成年的决定性标志就是开始自觉的自我反思：你不只是在过自己的生活，而且能够有意识地反观自省你的生活。这有些像是孔子说的“四十不惑”。<br>反思理性化的后果<br>◆ 我们满以为韦伯会告诉大家科学有多么伟大的意义，值得年轻人去献身。然而，我们却听到他说：认为科学是通向幸福之路，这是“天真的乐观主义”，只有书呆子才会相信。科学根本就无法回答什么是“幸福”、什么是“意义”这一类的问题。<br>魅惑的古代世界<br>◆ 无论是在哪个文明中，古人都相信有各种神仙、鬼怪、精灵。不只是人有灵魂，动物也有灵性，石头草木也有灵，万物都有灵。古希腊的那些神灵你肯定听说过。中国也有各种神仙，在道教里面，最高规格的普天大醮仪式中，会恭请3600位神仙。日本的神道教说有800万神灵。印度教中说有3300万神灵。其实这些也不是确切的数量，它所传达的是世界一切现象的背后都有神灵。 	你可能会说，这不就是迷信吗？对，但是说到底，为什么会这样呢？一个到处都是神灵的世界对那个时代的人到底意味着什么呢？ 	意义非常重大。它意味着人和世界之间是可以建立起某种联系的，甚至是可以沟通和互动的。<br>◆ 这些冥冥之中难以言说的神秘事物，组成了古代精神极为重要的一部分，让人类与整个宇宙紧密相连为一个整体，构成宇宙秩序（cosmos）。古代人从这种整体秩序中确立了生存的意义，获得所谓“安身立命”的根据。在这个意义上，古代的人类是“嵌入”在整体宇宙之中的。<br>理性化与祛魅<br>◆ 我们中国人习惯把“宗教”和“迷信”连在一起说，“宗教迷信”。但在西方历史里，宗教和迷信其实并不是一回事。对应到祛魅这件事情上，祛魅其实分了两步，先针对迷信，再针对宗教。<br>◆ 祛魅的第一个阶段叫“宗教的理性化”，就是驱逐原始宗教中的各种巫术，用哲学理性来论证宗教的合理性，论证它的救赎意义。就好像中国人也会区分江湖迷信和真正的佛法高僧，祛魅的第一个阶段就是去除那些装神弄鬼的事情，让宗教走到理性思辨的道路上来。在这个阶段，祛魅并没有瓦解宗教，反而使宗教获得了理性化的发展。<br>◆ 但是祛魅作为一种理性化的取向，要考问的是所有超验的、神秘的东西，这个逻辑链条一旦展开，是不会停止的。所以袪魅的第二阶段很快就转向了宗教本身。<br>清澈之后的荒凉<br>◆ 还记得我前面用的那个词吗，在古代社会，人是“嵌入”这个世界里的，是和世界连为一体的。而到了现代社会，他从那么大的“母体”中被剥离出来，从此孤独地、无依无靠地存活在这个世界上。<br>◆ 一方面，他知道，这个祛魅的“梦醒时分”对许多人来说，在精神上是格外“荒凉”的，会让人茫然若失。信仰失去了以往神秘的根基，而理性主义的科学并不能为生命的意义提供新的根本依据。 	另一方面，韦伯也知道，世界的祛魅是现代的真相，你高兴也好，失落也罢，我们都必须直面这个真相。<br>◆ 祛魅的世界怎么才能不成为冰冷荒凉的世界呢？这回，科学和理性能帮我们做什么呢？ 	这就牵涉到韦伯的第二个命题了——“诸神之争”。<br>06 | 韦伯II 现代的“诸神之争”是怎么发生的<br>◆ 但是，这带来了一个问题，也是韦伯的第二个重要命题：“诸神之争”。注意，这里的“诸神”并不是指多种神灵，而是指人们各自信奉的价值观。诸神之争就是价值观之间的冲突。这个比喻很形象，我们现在信奉某种价值观，有一点像古人信奉神；观念的冲突，就像是神灵之间的战争。<br>事实判断与价值判断<br>◆ 价值判断的问题就在这里。对事实判断，我们很容易达成一致，客观现实摆在那里，是就是，不是就不是。价值判断不一样，我说上海更好，你说北京更好，我们都有自己的理由，很可能谁也说服不了谁。<br>◆ 真是一种事实判断，完全可以依靠科学研究来获得客观的判断标准。而善与美都属于“应然”领域的价值判断，科学对此很难有所作为。而且善和美之间也没有统一性。韦伯说过，善的事物不一定是美的。韦伯举的一个例子，是波德莱尔诗集《恶之花》，恶的东西竟然可以绽放出美的花朵，似乎令人不可思议。但如果你经常去博物馆，熟悉千姿百态的所谓“现代派”作品，就不会为此感到惊奇了。<br>价值多元的困境<br>◆ 我在导论部分提到，现在很多时候“我喜欢”变成了最重要的标准。这何尝不是一种无奈？有些问题我们自己也给不出确定无疑的回答，最后只能说我喜欢。但建立在“我喜欢”上的选择是脆弱的，个人意愿是一件善变的事。其实，选项不一定就糟糕；糟糕的是，我选了，但永远也不知道选得对不对。这种长期存在于内心的动摇和不确定感，是现代人最显著的精神特征之一，几乎成了一种“时代的病症”。<br>◆ 在更基础的政治问题上，价值冲突也不会缺席。比如，是安全和秩序更重要，还是个人的自由和权利更重要呢？如果是前者，就应该有一个强有力的国家来保障秩序；如果是后者，政府的权力就应该受到严格的限制。在美国政坛，这个话题争吵了几百年，目前看，不仅没有“真理越辩越明”，反而是政治分裂和派系对立变得越来越严重。<br>◆ 理解了多元价值冲突的困境，对我们有什么用呢？我想，面对自己和身边时而发生的激烈争论，我们可以变得更加平和与从容，而不是急躁和焦虑，不是简单地指责别人不可理喻。对话与沟通总是有益的，但也总有无法沟通的时刻、无法化解的分歧。韦伯给我们的启发在于，坦然面对这种困境，与此共存，这也是智性成熟的标志。<br>工具理性与价值理性<br>◆ 工具理性的关键就在于“计算”：针对确定的目标，计算成本和收益，找到最优化的手段。工具理性不关心目的，只关心达成目的的手段是不是最优的。<br>◆ 2024/07/22发表想法<br>比如选专业就是个价值理性的问题<br>原文：还是同一个例子，在外地开会，家里人让我赶紧回家。但这次，订机票之前我突然想：不对，还是得先问一下到底是什么事，看看值不值得为这事回一趟家。这时，我考虑的不是手段，而是目的。我需要决定要不要去做这件事。<br>
<br>
显然，价值理性的权衡要比做工具理性的计算困难得多。你可能感到，这两种理性的关系，很像是上一节讲到的事实判断和价值判断的关系。没错，工具理性的计算就是一种事实判断，因为成本和收益基本上是一个事实，而价值理性的权衡是一种价值判断，虽然你也在用理性思考和权衡，但其中有许多主观的因素，因此没有标准答案。<br>◆ 还是同一个例子，在外地开会，家里人让我赶紧回家。但这次，订机票之前我突然想：不对，还是得先问一下到底是什么事，看看值不值得为这事回一趟家。这时，我考虑的不是手段，而是目的。我需要决定要不要去做这件事。 	显然，价值理性的权衡要比做工具理性的计算困难得多。你可能感到，这两种理性的关系，很像是上一节讲到的事实判断和价值判断的关系。没错，工具理性的计算就是一种事实判断，因为成本和收益基本上是一个事实，而价值理性的权衡是一种价值判断，虽然你也在用理性思考和权衡，但其中有许多主观的因素，因此没有标准答案。<br>◆ 也就是说，工具理性问题有客观标准，我们容易达成一致；价值理性问题标准不一，很难找到确定的答案。在社会层面，这一点更明显：价值观念问题我们有许多分歧；但在具体方法上，我们都认同工具理性计算出来的方案。 	那么结果是什么呢？工具理性的计算有客观公认的标准，所以可以普遍化，成为一种通用逻辑。而价值理性的权衡没有公认的标准，是多元化的，所以在现代社会难以普遍化。结果就是，在现代化的过程中，工具理性大行其道’压倒了价值理性。<br>工具理性塑造的社会制度<br>◆ 我们高度重视理性计算、永无止境地追求高效率。韦伯认为，这导致了一个显著的后果，就是社会制度的官僚化：不仅是在政府，而且在社会的各个领域，包括学校、军队、公司……官僚制这种组织形式占据了重要地位。<br>◆ 你可能会说，不对吧，我们经常在批评官僚主义，就是因为官僚制度的效率低下、办事拖沓、不通情达理、繁文缛节。你的个人直觉可能有道理，但这不是官僚制的必然结果。对个人来说，这可能僵硬、机械，但个人体验和全局效益不同，有时个人体验不佳恰恰是系统追求高效的结果。 	一个理想的官僚系统规则合理，纪律严明，人尽其责，照章办事；系统运转精确、稳定，具有很高的可预测性，效率高，执行力极强。<br>◆ 德军参谋部曾经制订过一个著名的军事计划，施里芬计划（Schlieffen Plan）。这个计划的核心思想是打“时间差”，先西后东，快速拿下法国以后，集中力量对抗俄罗斯。在这个计划中，时间极为重要，精确到了每一天：第12天打开比利时战略通道，第22天跨过法国国境线，第31天占领巴黎。有人说，这简直就是一个“剧本”。 	德军参谋部敢于做出这样的计划，底气就是德国统一之后建立的一套完整的官僚制度，就像一台庞大而精密的机器，可以控制整个国家的行政体系和工业体系，一切为军事活动服务。有这种执行力，如此高精度的军事计划才有实现的可能性。这就是官僚制的强大能力。<br>◆ 对外如此，对内也是一样。官僚制的自我组织同样遵循“非个人化”的原则：原则上，安排一个职位，只看这个人能不能行使这个职位的功能。一个程序员，就看你写程序的能力；一名销售，就看销售业绩。这有一个明显的好处：就是排斥任人唯亲，倾向任人唯贤，因此也倡导绩效制（meritocracy），以工作成绩来决定职位的任免升降。遵循这种原则，能够从大规模人群中相对快速、有效地选出需要的人才。因此，官僚制的普及扩展了人力资源，提高了人才的利用率，也推动了公平竞争，成为现代社会迅速发展的一个动力。<br>片面的理性化<br>◆ 就像现在流行说：先实现“财务自由”，再去追求“诗和远方”。但在实现财务自由的漫长过程中，我们关心的都是成本收益计算、效率最大化这些问题。结果是，这个漫长的过程会反过来塑造我们自身，最后我们变得只会赚钱。赚钱这件事，本来是手段，但我们为了找到实现目标的最优手段花费了太多的时间精力，陷入太深，以至于忽视了，甚至放弃了最初的目标。<br>◆ 这就回到了开头的话题：为什么现代人的价值取向是多元的，但是对金钱的态度又很一致。并不是因为现代人都是拜金主义者，而是因为按照工具理性的逻辑，金钱就是一个最通用的工具。<br>铁笼是禁锢也是庇护<br>◆ 首先是造就了一种片面的社会文化。<br>◆ 拿假冒伪劣现象举个例一这当然是一个与诚信道德有关的问题。但我们发现，要处理它，最有效的方式是罚款——当然，是广义上的罚款。总之就是要让假冒伪劣者付出巨大的代价，让假冒伪劣这件事在经济上变得不划算。这很实际，也很有效。但你有没有想过，这背后隐藏的逻辑是“用功利得失解决道德问题”。这当然立竿见影，但本质上，它把道德问题变成了利益计算。按照这个逻辑，只要能找到办法规避惩罚、提高收益，人还是会选择违背道德。用利益计算解决道德问题，永远是治标不治本，有时能解决问题，有时却会让问题更严重。<br>◆ 第二个弊端则是造就了片面的社会关系：人与人、人与组织之间，逐渐变成了一种商业的“供求关系”。<br>韦伯思想的启示<br>◆ 伯对现代性的四个重要论断我们都讲完了：第一个是“世界的祛魅”，第二个是“诸神之争”，第三个是“工具理性的扩张”，最后一个则是“现代的铁笼”。<br>◆ 在韦伯看来，悲观主义恰恰是盲目乐观主义造成的。我们最需要担心和警惕的那种悲观，隐藏在对现代化和理性化的盲目乐观之中：我们曾经相信理性可以无所不知，科学可以无所不能。然而事实并非如此。这种盲目的乐观被现实打碎之后引发出的那种极度悲观才是我们要警惕的。<br>◆ 这一切，毫无疑问地，乃是我们的历史处境的一项既成事实，无法逭避，而只要我们忠于自己，亦无从摆脱。<br>◆ 罗曼•罗兰说过一句话：“世界上只有一种英雄主义，那就是在看清生活的真相之后，依然热爱生活。”我们现在做的，就是“看清生活的真相”。在这本书之后的旅途中，我希望你能记住这句话。<br>09 | 路标 现代人的“精神危机”<br>◆ 我真正缺少的东西就是要在我内心里弄清楚：我到底要做什么事情？问题在于，要找到一个对我来说确实的真理，找到一个我能够为此而生、为此而死的信念。写下这段话的大学生是丹麦人克尔凯郭尔，后来他成为著名的哲学家，是西方存在主义思想的源头。<br>◆ 确立一个具体的目标并不难。每个人在生活的每个时刻，都会有一个当下的具体目标，但是如果进一步追问这个具体目标的意义，就需要一个更大的目标来回答。如果一直追问下去，最终就会遇到终极关怀的问题：生活到底是为了什么？人生究竟有什么意义？终极关怀之所以“终极”，是因为它追寻的是所有答案背后的根本答案。回应终极关怀的依据，就是所谓“人生信仰”或者“人生理想”。所以，我们需要信仰来支撑生活的根本意义。<br>◆ 但我猜肯定有人会说，我干吗要不断去追问目标的意义呢？我知道为了能过更好的日子要努力工作，这就足够了。我就到此为止，不会去费神继续追问，去理会什么终极关怀的问题。所以，我也不需要依靠信仰来生活。这个质疑听上去挺有道理的。许多人并没有什么明确的人生理想，照样能正常地饮食起居，过好每天的日常生活。这样好像就能避开对人生终极性问题的追问，就能摆脱信仰问题的麻烦。可是，许多哲学家认为：这只是假装解决了信仰问题，实际上你无法真正摆脱。你可以回避这个问题，但信仰问题像幽灵一样，总会在某个时刻与你不期而遇。这是因为，人在精神层面上总会面对两个根本性的人生难题，一个是死亡，一个是贪欲。<br>◆ 现代人在接受一种信仰之前，往往要求确认这个信仰是真实、可靠可信的。但是我们如何才能确认呢？现代人倾向于求证，需要理由来论证确认。信仰对人生的意义越是重大，论证信仰是真理的要求就越是强烈。只有真实的信仰才能让人真诚与坚定地信奉。于是现代人把“信与真”越来越紧密地关联起来，这样就带来了难以担负的论证负担，因为信与真之间存在逻辑裂痕。<br>◆ 信仰在本质上是一种价值，接受信仰需要做出价值判断，而真假是一个事实问题，辨别真假是一个事实判断。我们在讨论韦伯的那一章讲过，前者不具有客观的理性基础，而后者原则上可以依据科学理性的证据和逻辑。也就是说，在信仰问题上，如果用审核事实判断的标准去审核一个价值判断，就相当于用短跑比赛的快慢标准去评价一幅画美不美，是行不通的。用学术语言说，在信仰与真理之间存在一个逻辑断裂<br>◆ 最后他发现，你是无法完全依靠逻辑和推理来求证信仰为真、来确证它的可靠性。因此，你不得不勇敢地“纵身一跃”，才有可能越过这道鸿沟。这完全是一种冒险。因为我们并不能知道这纵身一跃的结果是抵达拯救的彼岸还是跌入虚空的深渊。我们甚至无法计算这个风险的概率。信仰需要极大的勇气。<br>10 | 尼采I “上帝死了”究竟是什么意思<br>◆ 我今天和你讲尼采很危险，不是要说他的拥徨如何，而是要说尼采思想本身的危险性。尼采自己说过：“总有一天，我的名字将会和某种可怕的记忆连在一起。因为我不是人，我是炸药，我是真理之身。但是我的真理是可怕的，因为迄今为止的所有真理都是谎言”<br>可怕的宣言：“上帝死了！”<br>◆ ？实际上，尼采在宣告“上帝死了”之后，下一句话就是“是我们杀死了上帝！”他说：“这个世界上最神圣、最万能的上帝，现在已经倒在我们的刀下”。他还质问：“我们这些最残忍的凶手，如何才能洗清我们身上的血迹啊？”<br>虚假的形而上学<br>◆ 虚假思想虽然能带来安慰，但最终会带来恶果。比如说，尼采认为人为了生命的欲望奋力拼搏是一种生命的本能。但在奋斗中，人总会遭遇挫折与痛苦，感到无力和卑微。为了缓解痛苦与自卑感，基督教就造出了禁欲主义，宣称禁欲是高尚的。于是，人就可以通过否定生命欲望来逃避拼搏，继而逃避那些负面的感受。这就好比一个人本来很爱钱，但因为贫穷感到自卑，于是他就去信奉一套所谓“高尚的人应该视金钱如浮云”的说辞来躲避自己的自卑感。<br>◆ 生命欲望是真实的，也是正当的。即使因为挫折而痛苦，我们也应当直面它们。就像鲁迅说过的，“真的猛士，敢于直面惨淡的人生，敢于正视淋漓的鲜血”。按照尼采的观点，这就是诚实的英雄主义。但如果我们按照禁欲主义的说法，用否定生命欲望去逃避痛苦，就只会陷入自欺欺人的虚假人生。<br>◆ 但在尼采看来，古老而典雅的形而上学才是虚无主义真正的根源。<br>11 | 尼米II “超人”究竟是什么人<br>◆ 就是人们失去了绝对可靠的信念，陷入了虚无主义的困境。这是很悲剧、很可怕的处境吗？尼采的回答是，未必！如果能直面虚无主义的真相，那就不会陷入绝望，反而会激发出一种积极的创造力量。这就是他的“超人学说”。<br>◆ 如果形而上学的思想是虚假的，那什么是真实的呢？人类精神处境的真相是一片虚无，那人面对虚无该怎么办呢？尼采给出的答案是：“超人”掌握的生命本身的强健力量，是人唯一拥有的真实的东西，也是人战胜虚无的武器。<br>虚假的理论掩盖了生命的真相<br>◆ 尼采喜欢一希腊神话，说人间最好的事情就是你没有生出来；第二好的事情就是你生下来以后快快地死掉；最糟糕的就是你继续活着。这听上去是不是很悲观？但是不是悲观，主要取决于你怎么看。尼采的意思是说，人生并不存在什么客观的真理或者意义，等你去探索，然后发现出来。这本来就是一种幻觉。如果你带着这种幻觉去探索，那么你注定会幻灭，然后你会感到悲观。但是，如果你从来就不相信这种幻觉，也就无所谓悲观了。<br>◆ 在希腊神话中，有太阳神阿波罗和酒神狄俄尼索斯。阿波罗代表一种理性的精神，而酒神狄奥尼索斯注重生命本能的创造力，带有否定理性的反叛精神。在尼采看来，希腊神话中这两种精神之间的张力与平衡，能够焕发出一种生机勃勃的创造性。但是，从苏格拉底之后，希腊人开始用理性的方式来论证生活。到了近代，更有高度理性化的科学理论试图用因果规律来解释一切现象，包括人生意义。上一节讲到的形而上学当中的所谓世界的目的性、统一性和表象之后有一个本质，这些“理论文化”掩盖了“生命本身虚无”的真相，让人陷入一种幻觉，在幻觉中获得虚假的安慰。这就是理论虚假。<br>积极的虚无主义<br>◆ 什么是消极的虚无主义呢？就是面对虚无的真相，陷入悲观和绝望。可是你想过没有，为什么没有上帝的世界就会让人悲哀？为什么没有意义的人生就会令人绝望呢？虚无这个真相并不直接导致消极。从虚无到消极，有一个必经的中间环节，那就是一种虚幻的信念：认为在世界的表象背后还存在绝对的本质，并且认为人生必须依靠这个绝对的本质才能找到价值和意义。就像前面说的那个不存在的奖杯。如果你相信了这种虚幻的信念，那么虚无的世界对你来说就是毁灭性的，你就会感到悲观绝望。这就是消极的虚无主义。但如果你从幻觉中醒来，看到从来就不存在什么绝对的本质或者真理，人生的意义也并不依赖于它，那就没有什么好绝望的。而且，认识到世界本无意义，这恰恰带来了创造的自由。在尼采看来，价值不是现成在哪里等你“发现”，所有的价值都是人主观创造出来的，生命活动的标志就是能够自己确立价值，这是生命本身的力量。<br>◆ 所以，尼采认为：面对无意义的世界和无意义的生命，人应该立足于现实，直面无意义的荒谬，以强大的生命本能舞蹈，在生命活动中创造出价值。用尼采的话说，就是“成为你自己”。这样一来，虚无不再会让你沮丧和绝望，反倒会给你最广阔的创造自我意义的空间，虚无让人变成了积极的创造者，这就是积极的虚无主义。<br>◆ 西西弗斯用自己的选择创造出了意义，用无尽的斗争精神去对抗虚无。所以加缪写道：“登上顶峰的斗争本身足以充实人的心灵。应该设想，西西弗斯是幸福的。”<br>奴隶道德与主人道德<br>◆ 你们说相信扎拉图斯特拉，但扎拉图斯特拉算什么？你们说是我的信徒，但所有的信徒又算得了什么？你们没有探索自己，却发现了我……现在我要你们丢开我去发现自己，只有当你们全部否定我的时候，我才会回到你们身边。想想看，历史上所有的先知都呼吁信徒“听从我，追随我”，而尼采却说，你否定了我才是真正理解了我，才是深刻的追随，我才会回到你们身边。所以，如果你相信尼采，那就不该盲从尼采，因为如果你真的理解了他的思想，就不应该相信任何人包括尼采本人写下的教条，而是去探索自己的生命。<br>◆ 尼采极端的否定精神，也会带来巨大的问题：如果所有价值都是人创造的，那价值与价值之间还有好坏对错之分吗？虽然尼采用积极的虚无主义代替了消极的虚无主义，但又带来另外一个巨大的问题：我们凭借什么创造，自我创造是否有一个评判标准，怎么判断我们的创造是好是坏？<br>后真相的时代<br>◆ 比如，硅谷的程序员说，全球化推动了美国经济的发展，这是事实。这时失业的重工业区的就业者就说出了另一个事实：全球化是推动了你们这些互联网公司的发展，可是制造业却衰退了，这可是国家的立身之本。所以他们的事实是全球化损害了国家经济的基础。再比如，有的宗教信徒说，人工堕胎就是杀人，扼杀了一个本来能成为人的生命。这是事实。但反对的一方可能会说，胚胎发育到一定阶段之前甚至不能算是一个完整的生物，更别说是人了。堕胎就是一个怀有身孕的人自主地对待自己的身体，这才是事实。这些都是典型的“后真相”现象。<br>◆ 这些例子当中产生分歧的地方其实不是观点，而是事实真相本身。很多激烈的争论往往都是这样，双方不是对同样的事实真相抱有不同观点，而是看到的真相本身就不同。<br>◆ 其实，尼采在一个多世纪前，就已经看到了这件事的本质：客观的事实真相可能根本不存在。<br>◆ 尼采在一个多世纪之前就在挑战事实真相的客观性了。他这个观点在哲学界非常有名，被称为“视角主义”。<br>视角决定事实<br>◆ 视角主义究竟是怎么回事呢？用一句话来概括，就是“视角决定事实”。<br>◆ 传统认知模式有一个前提假定：认为存在一个客观的真相或者真理。我们去认知它，就是努力地去理解这个真相，再把它表达出来，只要不断向前推进，就可以越来越接近这个真相，最终完全认识和掌握真相。就好像苏东坡的庐山，身在此山中的时候，看不到庐山真面目，但如果远近高低绕着它看一圈，就能认识到庐山真面目。声音也是一样，虽然人的耳朵只能听到某些频率的声音，但我们用科学工具不断探测、研究，就能了解到声音本质上是一种声波。但尼采的视角主义和这些完全不同，它是完全颠覆了传统的认知模式。视角主义不是说不同的视角会对同一个客观真相得出不同的主观认知，而是要说根本就不存在一个客观真相。尼采认为，“存在一个客观真相”不过是一厢情愿的假设。没有任何人能确定是否存在这个所谓的“客观真相”。如果说有谁能看到这个绝对的客观真相，那只能是全知全能的上帝。但别忘了，上帝已经“死了”。不管怎样，人类不可能确定存在一个绝对真相。人能得到的，就是一个个不同的视角看到的不同真相。更准确地说，人不是“看到”真相，而是“制造”了真相。<br>◆ 在尼采看来，外部世界虽然是存在的，但在人出现之前，它没有任何意义，也没有任何属性，只是一团混沌而已。是人把概念和意义赋予到它上面，才让它变成了“事物”。打个比方，比如一堆“木头”，在人登场之前，它只是一团混沌，甚至连“木头”这个名字都没有。然后人出现了：要取暖的人把它看作是“燃料”，要造房子的人把它看作“建筑材料”，而一个极端饥饿的人，甚至把它当作“食物”……燃料、建筑材料、食物，都是人制造出来的真相。我们以为我们在“认知”真相，其实我们是在制造真相。<br>还存在客观性吗<br>◆ 这种“客观性”不过是一种合理的错觉。因为人们在这些问题上具有共同的视角，得出了一致的解释，才造成了这种错觉。其实客观事实也会变，它会随着“共同视角”的变化而变化。比如说在过去，月食的真相就是天狗吃月亮。但现在，月食的真相是，太空中月球运行到了地球的影子里。对月食这件事，过去的共同视角是一种神话的视角。而现在，我们共享的是一种天文学的视角。<br>◆ 概括地讲，视角主义认为事实有没有所谓的“客观性”，其实取决于人们对这件事有没有“共同视角”。“客观”只是一种错觉。但这种错觉很重要，因为我们需要一些稳定的事实认知，很多人类活动只有在此基础上才能正常展开。<br>◆ 于是，人与人之间的分歧越来越深，甚至会出现整个社会的意见分裂。这就是开头说到的“后真相”现象。后真相这个词，甚至被《牛津词典》选为了2016年的年度词语。<br>◆ 我们越是运用更多的眼睛、不同的眼睛去观察同一个东西，我们对这个东西的“概念”就越“完整”。我们也能越“客观”。<br>◆ 也就是说，视角主义教给我们的，不是分裂的必然，而是谦逊的必要。一个人的视角并不是天生固定的，而是在自身经历中形成的。改变自己的视角绝非易事，但这仍然是有可能的，它取决于我们的选择。我们应该做的是，试着去改变自己的视角，超越自己的视角去理解他人，寻找让不同视角互相理解、融合出共同视角的可能性。理论勾勒了某种灰暗的前景，不意味着我们只能心灰意冷；它恰恰给了我们改变这个前景的机会。<br>勘探精神结构的黑暗区域<br>◆ 用一句话概括，弗洛伊德颠覆了对于人的理解，这个颠覆的关键点是“人的理性”。在这之前，启蒙主义继承古希腊罗马的思想传统，认为人之所以是万物之灵，就是因为人是理性的动物，能够主宰自己的生命。但在弗洛伊德之后，这种“理性人”观念遭到了根本的质疑。可以这样说，如果尼采宣告了“上帝的死亡”，那么弗洛伊德就宣告了“理性人的死亡”，成为现代思想史上的另一个里程碑。<br>◆ 弗洛伊德的理论经历过一个大反转，在心理学界和思想文化界遭遇了截然不同的命运。这里我先埋一个伏笔，我们先来看这个反转的前半部分，也就是弗洛伊德如何反叛理性主义传统，颠覆理性人这个观念，改变了西方文化的面貌。<br>◆ 伊德提出了一个观点非常关键：在精神意义上，没有人是绝对健康的，正常与不正常之间并不是泾渭分明的。而且，精神上的病人和正常人的心理结构其实是相同的。就像一个心脏不好的人，他的生理结构和普通人仍然是相同的。因此，通过对精神疾病患者的分析、诊断和治疗，就能够发现人类普遍的心理结构，具有普遍性的意义。<br>◆ 简单地说，他发现人类心理结构中存在一个黑暗地带，叫作“无意识”。说它是黑暗地带，是因为我们无法在意识中觉察到这个区域。无意识，就是颠覆“理性人”这个观念的要点。<br>◆ 无意识部分不仅巨大，而且生猛有力。弗洛伊德认为，无意识中暗藏着巨大的能量，是人的欲望本能，主要是性欲本能和攻击本能。这是人内在最基本的冲动，是生命的驱动力。潜藏在无意识中的欲望本能往往比表层意识中的理性思考更有力量。有一句玩笑话说“不管嘴上怎么说，身体总是很诚实”，这种说法其实就彰显了弗洛伊德思想的影响。<br>以科学的名义<br>◆ 要理解“无意识”究竟怎么影响我们，我要带你看一下精神分析学说中最重要的一个内容：人格结构三元说。你可能听说过这“三元”的名字：本我、自我和超我，但它们到底是什么意思呢？先说本我。本我就是“最根本的我”，是人格的最底层。这里就是“无意识”的领域，主要是人本能的原始欲望。这些与生俱来的欲望要寻求即刻的满足，不论是非对错，只要满足了欲望就会很快乐。本我之上是自我，这就是我们能够意识到的那个自己。自我不是天生的，而是在成长过程和适应社会的过程中形成的。自我有理性，会正视社会现实，重视常识和规则。它能够感受到本我的欲望，但自我会用理性来甄别本我的要求。如果说本我是人心中的一个小婴儿，只知道追求满足和快乐，那么自我就像是小婴儿的监护人，会用理性来考虑这些要求，根据对现实情况的考量，有选择地去满足那些欲望。自我再往上，就是超我。顾名思义，是超越自我的那一部分，这是我们心中的理想化人格。它是在人与“道德”的接触和理解中形成的，我们把来自家庭和社会的种种道德权威内在化成心灵的一部分，最终就形成了这个理想人格。都说每个人心中都有一个天使和一个魔鬼，超我就有点像是那个天使；但我们的实际行动常常达不到天使的标<br>◆ 准，超我就会通过内疚感和罪恶感来影响我们的心理和行动。了解了这个三元结构，你就明白了，无意识的真相也并没有那么可怕。弗洛伊德说，本我和自我的关系，有点像马和骑手。马是强劲的驱动力，而骑手需要驾驭这股力量。骑手能够正常指挥马的时候，人的精神状况就很健康。但如果这种关系出了问题，骑手反而被马拖着走，走上了自己不想去的路途，这就偏离了正常的精神状况。如果这种偏离严重而且持久，就成了人们说的精神疾病。<br>◆ 你可以看到，弗洛伊德的精神分析学说特别强调无意识的重要性，强调本能欲望是生命的驱动力。他认为，人格结构中的本我和自我，也就是我们心中的小婴儿和监护人，二者处在永恒不断的冲突当中。理性的自我无法完全控制非理性的欲望，只能不断地去应对这些欲望。它可能成功，也可能失败，失败的时候人就陷入了精神疾病状态。<br>14 | 弗洛伊德II 精神分析学说真的是科学吗<br>◆ 在心理学界，弗洛伊德的精神分析学说走向了衰落，今天美国最大的两个心理学专业协会中，属于精神分析流派的专家学者只占不到10%。而在思想文化界，弗洛伊德的影响却源远流长，至今仍然塑造着我们的精神生活。<br>弗洛伊德的原创性<br>◆ 问题是，弗洛伊德的学说真的是一种科学理论吗？它经得起现代科学标准的检测吗？学术界对此有过非常热烈的争论。不过，主流观点是明确否定的。<br>◆ 什么样的理论才能叫作科学理论呢？科学理论有一个重要的特征叫作“可证伪性”，这一点我们以后说到哲学家波普尔时会展开讲解，这里先简单说一说。“可证伪”，就是有可能被经验证据证明是错误的。一个科学理论需要直面不符合理论的事实，直面对自身不利的证据。说得直白一点，如果你提出一个科学理论，那么这个理论不能宣称自己永远正确、能够解释所有的经验证据。如果能解释一切，这就成了伪科学，伪科学就是永远能够自圆其说。<br>欲望不再令人羞耻<br>◆ 这首先体现在艺术领域。当代的文学、电影、绘画和音乐作品中，本能欲望成为一个突出的主题。欲望被看作是不可否认、不可抹杀的生命驱动力。欲望不再是可耻的，它是正当的，甚至是值得赞美的，是充满生命力的真实人性。在欲望和理性、道德的冲突中，反倒是压抑欲望的理性好像很残忍，而道德内疚感可能是虚伪的或者愚昧的<br>◆ 我们说过，人生意义的两大难题就是面对死亡和欲望。如何超越欲望的卑微，走向人性的崇高，这是现代精神危机中的一个重要问题。而弗洛伊德的影响不是解决了这个问题，而是取消了这个问题：如果我们接受了欲望的正当性，欲望本身不再是卑微可耻的，也就用不着去“超越欲望”了。<br>◆ 现在，越来越多的人能够公开地谈论欲望、表达欲望。比如，在日常生活中，我们可以毫不愧疚地说自己是个“吃货”。再比如，“性感”慢慢成了一种可以公开表达的赞美。在大众文化中，性也不再是一个高度禁忌的话题，这在过去是非常难以想象的。这种观念变化至今都在塑造着我们的精神生活和道德生活。<br>15 | 萨特I 为什么如此特立独行<br>◆ 对我个人来说，萨特这个名字有特殊的意义。在我年轻的时候，社会上出现过一段时间的“文化热”，尼采、弗洛伊德和萨特就是其中的热门人物。他们的著作探讨人性本质、生命意义这些问题，尤其受到年轻人的追捧，相当于是那时候年轻人的“爱豆”。<br>◆ 这三位思想家彼此之间其实有相通之处，但他们给我留下的感受又有所不同：尼采是横空出世的天才，简直像个外星人；弗洛伊德的理论很有趣，但他的生平实在很乏味；最后还是萨特最能让我产生共鸣。萨特不仅是存在主义思想的代表人物，而且有着非常精彩的人生，是一个“有故事的男同学”。<br>◆ 萨特的思想中有两个重要的观念：一个是自由选择，另一个是积极行动。对于人生，萨特会说人就是自由本身，人必须做出选择，去行动，并且绝对地承担行动的后果。<br>◆ 19岁那年，萨特考进了巴黎高等师范学院。“师范学院”听上去好像不起眼，其实这是法国最精英的学校。这类学校在法国叫作“大学院”，每年招生名额极少，巴黎高师是其中最古老的一所。<br>传奇般的终身伴侣<br>◆ 萨特的伴侣是法国作家西蒙娜•波伏娃，她是20世纪70年代女权运动的重要理论家和先驱者，现代女权主义的奠基之作《第二性》就是她的作品。<br>◆ 但他们都认为人是绝对自由的，不必受到习俗制度的约束，于是签订了一个奇特的爱情契约，作为彼此的伴侣，但永不结婚。他们的爱情是开放的，不排除与其他人发生亲密关系；但彼此坦诚，不会隐瞒。而且这个契约的有效期只有两年，每过两年双方就要确认一次是否还继续这段伴侣关系。<br>◆ 这听上去非常不靠谱，对吧？但结果是，这个契约足足延续了51年，从萨特24岁直到75岁去世，两人真正做到了相伴一生。这51年中并不都是甜蜜浪漫的故事。萨特有过许多情人，有一次还差点和别人结婚。波伏娃也有过好几位情人，曾经写过一本小说献给其中一位，小说后来还获得了法国的最高文学奖龚古尔奖。<br>◆ 波伏娃并不是萨特的附庸，而是一位特立独行的作家。她没有与萨特过同居厮守的生活，他们都有各自的公寓，保持着自己独立的空间。但令人寻味的是，在萨特去世六周年的前一天，波伏娃去世了。她选择与萨特合葬在一起，彼此永不分离。<br>公共知识分子<br>◆ 当时正是越南战争期间，萨特本人反对美国的这场军事行动，于是在1967年，他和罗素等人组织了这个国际战争罪法庭，要对越南战争中美国的所作所为做出调查和审判。他们引用了纽伦堡审判中首席检察官罗伯逊法官的一句话：“如果某些暴行是罪恶的，无论暴行的实施者是美国还是德国，它们都是罪恶的。”<br>◆ 萨特在政治上倾向左翼，常常被人看作社会主义者，他支持过苏联，还曾经受邀到中国参加1955年的国庆观礼活动。<br>◆ 但萨特的政治立场其实有些复杂，他对自己的定位是无政府主义者。不论如何，政治立场都为他带来了很多争议，甚至导致他与一些亲密的朋友疏远乃至绝交。我们之前提到过的《西西弗斯神话》的作者加缪，曾经就和萨特是好友，但后来两人决裂了。萨特说，“让我们走到一起的因素很多，让我们分开的因素很少，但是那样的很少也已经是太多了”。还有一位是法国重要的思想家雷蒙•阿隆，曾经是萨特的密友，最早鼓励萨特去德国学习哲学。他和萨特也因为政治分歧而疏远。这方面推荐你读一本书，非常有意思又有深度，是思想史家托尼•朱特写的《责任的重负》。<br>◆ 几年前我到巴黎访问，专程去寻访了安葬萨特的蒙帕那斯公墓。站在萨特和波伏娃合葬的墓地前，我回想他们一生的故事，忽然明白，他们不只是写下了存在主义，而且一生都在实践存在主义。<br>◆ 在萨特的存在主义学说中，最重要的就是这两点：自由选择，积极行动。不过你知道吗，这两个信念的起点却是“虚无”。<br>◆ 萨特认为，人的存在本质上就是一片虚无。<br>16 | 萨特II 为什么可以从“虚无”推出“自由”<br>◆ “存在就是虚无。”这句话出自萨特的哲学巨著《存在与虚无》。<br>“存在就是虚无”是什么意思<br>◆ 1941年到1945年的四年间，萨特几乎每天都在这里工作10个小时。就是在这家咖啡馆里，他完成了《存在与虚无》这本书。 	花神咖啡馆现在还在，是巴黎的一个著名文化景点，我自己去过两次，点菜的时候还看到菜单上印着萨特的一句话：“通向自由之路，经由花神。”<br>◆ 人的存在和物的存在究竟有什么区别？我们都知道，人是有意识的，而物品没有。但有意识的人和没有意识的物，究竟不同在哪里呢？<br>◆ 我们说“这个服务员是一个服务员”和说“这个杯子是一个杯子”，这两种说法是同一回事吗？他感到大不相同！说这个服务员是一个服务员并不是注定的。如果这个人下班了，或者离职了，他就不再是一个服务员了。<br>◆ 就是意识有对象性，总是对于某个事物产生的意识。那么纯粹的意识本身究竟是什么呢？他突然有了灵感，如果“意识总是对某物的意识”，那么意识本身呢，就什么都不是！纯粹的意识本身就是虚空！<br>◆ 有点像空空荡荡的容器，需要被填充之后才能成为什么。一个杯子里只有倒进了什么东西，我们才能说它是一杯水、一杯酒、一杯牛奶或者一杯咖啡。人的意识本身就是空无一物，只有当有什么内容填充进来之后，人才会获得自己的本质。所以人并没有什么预定的本质，人的存在原本就是虚无，它的本质是“有待形成”的。<br>◆ 简单地说，如果人的存在就是意识，而意识本身是虚无，那么人的存在就是虚无，这就得出了“存在就是虚无”这个命题。<br>◆ 他把物的那种被决定的、不能改变的存在，叫作“自在”的存在。把人的这种“有待形成”的、不固定的存在，叫作“自为”的存在，就是自己“为自己”而存在。你可以记住这一点：自在的存在有一个固定不变的本质；而自为的存在没有固定的本质，它的本质是可以变化的。<br>◆ 都不是。萨特会说，人的存在根本上是虚无，这赋予了人一个永恒的需求。你可能听过一句话，说“大自然厌恶真空”，同样地，人也厌恶虚无，厌恶虚无背后的缺失和不确定性。所以我们总是需要去填满自己的虚无，去获得某种本质。<br>◆ 打个比方，假如你是一名演员，现在站在舞台上，你第一个最迫切的渴望就是要找到自己的角色，因为在舞台上如果没有角色，那你就什么也不是。这里的“角色”就是我们想要获得的本质。这就是为什么萨特说“存在先于本质”，先有了虚无的存在，然后我们才要去找到自己的本质。演员可以扮演很多不同的角色，人的本质也是不固定的。<br>徒劳的激情<br>◆ 所以我们看到，人总是要去占有某种东西。有的人喜欢集邮，有的人喜欢买包包，有的人喜欢在游戏里收集奖励和成就。占有这些物的时候，我们好像得到的不仅仅只是物品的功能或者效用，通过“占有”这些东西，我们还获得了一种“存在感”。通过占有“物的存在”，我们可以得到确定的本质，甚至给自己一个定义：我是一个收藏家，我是一个游戏高手，等等。<br>◆ 萨特把这种欲望叫作“生存者与存在物的复合”，就是渴望与对象合二为一，来解决人的虚无状况。<br>◆ 萨特说，这种做法注定要失败。因为这只是局部地、暂时地满足了对确定性的渴求，根本上的虚无是无法改变的。<br>◆ 人是自为的存在，不断为自己寻找本质，不断变化。换句话说，人有无限的潜在可能性。人想通过占有物去获得确定性，但有限的、固定不变的东西没有办法填满无限的可能性。<br>◆ 比如，即使你成为世界第一的收藏家，你也无法确保从此就永远满足了。你一定会问自己：“这就是全部了吗，我就到此为止了吗？”无论你是一个多么成功的收藏家，收藏家这个身份也不会是你的全部。就像一位演员，无论他曾经扮演过多么成功的角色，这个角色也不会是这位演员的全部。<br>◆ 作家王尔德有句名言，“生活中只有两种悲剧：一个是没有得到我们想要的，另外一个是得到了我们想要的”。<br>◆ 因为人拥有无限的潜在可能性，这种潜能总是会逃到占有的对象之外，直到死去，人才能获得固定的、填满的、不变的本质。所以萨特说，“人是一种徒劳的激情”，总是有一种激情推动我们去占有、去追求，但我们希望得到的那种满足其实永远无法实现。<br>人被判定为自由<br>◆ 萨特说，正是在这种状态中，人类特有的尊严诞生了。存在就是虚无，这不错，但这恰恰是人类行动意志的基础，正是因为存在没有预先的本质，所以我们才能够自由地行动。<br>◆ 2024/07/27发表想法<br>世界上没有命运，每个人的人生都由自己书写。<br>原文：因为存在先于本质，那么就没有什么预先给定的东西把我们固定住、束缚住，就意味着我们永远可以超越“过去的本质”“现在的本质”去追求“未来”。<br>
<br>
换句话说，人永远不会“是”什么，而是永远都正在“成为”什么。在这个意义上，人是自由的，甚至人就是自由本身。<br>◆ 因为存在先于本质，那么就没有什么预先给定的东西把我们固定住、束缚住，就意味着我们永远可以超越“过去的本质”“现在的本质”去追求“未来”。 	换句话说，人永远不会“是”什么，而是永远都正在“成为”什么。在这个意义上，人是自由的，甚至人就是自由本身。<br>◆ 萨特最有创见、也是最精彩的观点，就是从“存在就是虚无”出发，最终推出了“人的自由”。<br>◆ 这种自由不是建立在强大能力的基础上，而是建立在人的存在之上、建立在最根本的虚无之上。<br>◆ 所以萨特说，人是被判定为自由的，自由就是人的命运。人唯一的不自由就是不能摆脱自由。不论你是多么渺小，不论你受到多少外在的限制，在根本上你都是自由的。<br>◆ 举一个例子，二战结束很久以后，一个在逃的纳粹高级军官被抓捕了，他叫艾希曼。在接受审判时，他这样为自己开脱：当时屠杀犹太人我是别无选择，因为我是军人，军人的天职就是服从命令，我没有选择的自由。 	萨特认为，这是自欺欺人，你当然有选择，你可以选择叛乱谋反，你也可以选择当逃兵，你还可以选择自杀，实际上在纳粹官兵中确实有人做出了这些选择。艾希曼选择了服从命令，这是自由选择的结果，而不是别无选择。声称自己没有选择的自由，只是自欺欺人，只是因为不愿意承担选择的责任。<br>◆ 萨特的存在主义哲学，最突出的一个导向，就是呼唤人们面对存在的真相。存在的真相是什么呢？萨特说，存在就是虚无，存在先于本质。如果“本质”决定了命运，那么，先于本质而存在的人就不被任何命运所限定，也就是说，人在根本上是自由的。 	但是，在这种自由中又隐藏着非常沉重和严酷的一面。为什么自由会变得沉重和严酷呢？<br>17 | 萨特III 为什么自由是一种沉重的负担<br>◆ 自由选择，这当然是一件好事，这意味着人具有掌握自己命运的自主性，因此获得了作为人的尊严。 	可是自由的命运不是轻轻松松的好事，它还有非常严酷的一面。这一节我们就要看萨特两个著名的观点：第一，自由选择是很沉重的负担；第二，“他人就是地狱”。<br>自由是独自承担的重负<br>◆ 自由选择为什么会成为负担呢？因为，选择必定会带来后果。 	那么谁来为这个后果负责？ 	萨特说，没有任何别人可以承担这份责任，你做出了选择，你就要独自承担责任。<br>他人就是地狱<br>◆ 因为只要你做出了某个选择，背后就会有一个评判标准。你的标准是从哪里来的呢？只能是你自己给自己确立的。每个人的生活都充满大大小小的选择，比如毕业之后继续深造还是直接工作，选择什么职业，要不要结婚，要不要孩子……所有的选择都会有后果，我们就生活在自己选择的后果之中，这些后果也在塑造我们自己。<br>◆ 但萨特却说，你所有的选择，依据都只是你自己。<br>◆ 俄罗斯大作家陀思妥耶夫斯基的小说《卡拉马佐夫兄弟》里面有一句名言：“如果上帝死了，那么一切都被允许了。”萨特说，这句话就是存在主义的起点。<br>◆ 你不能说“因为父母让我这么做”，因为是你自己把顺从父母当成了标准；你也不能说“因为宗教让我这么做”，因为是你自己把宗教教义当成了标准。<br>◆ 开个夸张点的玩笑，假如你和你的伴侣分手了，朋友来安慰你，说“这不是你的错”。但萨特可能就会说，这就是你的错，是你自己选择的人，是你自己谈的恋爱，这个结果当然是你的责任。<br>◆ 独自承担责任是什么意思？因为不存在客观的评价标准，判断一项选择是好是坏、是对是错，没有任何现成的、普遍有效的标准。你就是你自己的标准，你做了选择的同时就确立了选择的判断标准，这是评价的唯一标准。换句话说，你自己就是自己的立法者，为自己做出的每一个选择承担绝对的责任。<br>◆ 捷克作家米兰•昆德拉最有名的小说叫作《不能承受的生命之轻》，英文叫“The Unbearable Lightness of Being”，这个标题让很多人感到“不明觉厉”。但如果你理解了萨特的存在主义，就很容易看懂这个标题。 	“生命之轻”是什么呢，这个“轻”来自人的存在方式，人的存在有着无限展开的可能性，不被任何本质所限定。这是一种自由而轻盈的体验。但这种轻盈的自由又是孤独而沉重的，因为你必须独自承担你所有的选择，独自承担自己的生命，你是自己“生命的孤证”，这会让人感到难以承受。结果，我们就体验到“不能承受的生命之轻”。这个书名深刻地揭示出现代人的精神困境，也许你也曾经有所感触。<br>◆ 我们已经知道了，人能够自由地掌握自己的生命，哲学上把这叫作人的主体性。我是主体，就意味着我有主导权。那问题来了，你是自由的，我也是自由的；我们俩在一起的时候，到底谁是主体，谁有主导权呢？<br>◆ 萨特认为，人总是要维护自己的主体性，所以人与人之间一定会为了争夺主体性而斗争。每个人在和他人相处的时候，都想把他人变成客体，以此来维护自己的主体性和自由。<br>◆ 爱情的常见情节就是如此，一个人去追求另一个人，去讨好、迎合对方，变成对方喜欢的样子，失去自己的主体性。而被追求的一方呢，则要努力表现出自己迷人的魅力，通过追求者的奉献去获得自己的主体性。在这样的关系中，爱情越热烈，双方就越接近受虐狂和施虐狂。<br>◆ 想想看，你会恨一个杯子或者一把椅子吗？憎恨只能指向人。因为人有自由，只有人能出于自主意识对你做些什么。在他人作为主体的行动中，你就沦为了客体，沦为了物，你的主体性就被否定了。所以你会憎恨，因为你不甘于被当成物品。在这个意义上，憎恨就意味着你承认了对方的主体性，承认了对方的自由。<br>◆ 我们没办法既承认别人的自由，又让别人承认我们的自由，或者说把人的主体性和人的对象性调和起来。因此，人与人之间只有永恒的斗争。在这个意义上，萨特是一个悲观主义者，他不相信自由主义所向往的那种主体与主体之间的相互承认、平等尊重的关系。<br>◆ 他和尼采一样，否认普遍客观的价值判断标准，但是他似乎放弃了尼采的超人学说，强调人只能孤独地面对自己的选择。<br>绝望与希望<br>◆ 聆听萨特的哲学，你是否会感到一种绝望呢？起点是虚无，终点是孤独；在这其中，我们还要承担沉重的责任。<br>◆ 但萨特又说，存在主义也是希望的哲学。希望在何处？就在我们的自由之中，在人的无限可能性之中，我们永远有改变的潜能，不必服从任何注定的命运。<br>◆ 我们永远都可以做出改变。用什么去改变？行动。<br>◆ 我们最根本的自由和可能性都在行动中实现，它们并不只属于尼采式的超人，而是根植于每个人的存在之中。<br>◆ 我认为就是八个字：看清真相，继续战斗。人是徒劳的激情，人注定孤独，但那又如何？既然可以选择，那么就去选择，然后为选择负责，其它没有什么可说的。我们都是手推巨石的西西弗斯，但我们知道“西西弗斯是幸福的”，因为“登上顶峰的斗争足以充实人的心灵”。<br>18 | 路标 20世纪的灾难为什么不可思议<br>◆ 2024/07/28发表想法<br>现代社会产能过剩，并不资源匮乏，反而是因为当权者自利导致分配不均。<br>原文：资源匮乏与人性自利这两个假设，是社会现实状况的反映，这也意味着公共秩序无法自然形成，需要某种具有强制性的政治权威建立和维护。<br>◆ 资源匮乏与人性自利这两个假设，是社会现实状况的反映，这也意味着公共秩序无法自然形成，需要某种具有强制性的政治权威建立和维护。<br>◆ 对于政府或国家的特征，马克斯•韦伯提出过一个著名的定义：在特定的领土之内对暴力的合法垄断。这就是说政府的强制力是唯一合法的暴力。在这个意义上，警察实施的强制才有可能是合法的，个人才有服从的义务，而国家以外的暴力就是不合法的私刑。<br>◆ 所谓“政治合法性”（political legitimacy， 也译为“政治正当性”）.是指一个政治权威实施统治的根本依据。在古代社会，政治合法性的问题并不突出。因为古代的统治依赖于自然等级结构，人们相信自己天生处在高低贵贱的不同等级之中。比如，中国古代的所谓“君臣父子”“男尊女卑”，西方古代有国王、贵族、平民和奴隶等。这些等级结构被视为天经地义，而等级结构中的上层对下层具有正当的权威，最高层也成为当然的统治者。因此，那时候的统治者并不需要费力解释自己统治的根本依据，只需要做简单的宣称（claim）就够了，比如“君权神授”或者“朕即天下”<br>◆ 统治与服从需要一套理由，这是现代政治权威的特殊性所在。<br>◆ 社会契约论对现代的政治合法性做出了重要的理性论证，在西方成为主导性的政治理论，也塑造现代政治的理性主义特征：将政治秩序视为理性建构的人造之物。<br>◆ 20世纪带给我们的将是科学进入社会和私人生活。科学将赋予我们行为的准则。它将是一种光辉灿烂的前景……我们希望哺育了我们的19世纪，把那愚蠢的仇恨、无意义的争斗和可笑的诽谤统统带走，抛进世纪的无底深渊！<br>文明时代的野蛮，理性时代的疯狂<br>◆ 2024/07/28发表想法<br>但本质上还是少数人掌权和决策。<br>原文：德国的纳粹主义、苏联式的社会主义和英美的资本主义，是三种不同的现代性规划，它们都有各自的危机或困境，但都与现代理性主义的社会构想密切相关。<br>◆ 德国的纳粹主义、苏联式的社会主义和英美的资本主义，是三种不同的现代性规划，它们都有各自的危机或困境，但都与现代理性主义的社会构想密切相关。<br>19 | 鲍曼 大屠杀是因为疯狂吗<br>◆ 2024/07/28发表想法<br>我觉得并不是，大屠杀自古就有，甚至人类不存在时便有。古代也有杀俘。<br>原文：大屠杀是现代性本身固有的一种潜在可能，它只有在现代文明中才可能实现。<br>现代性与大屠杀<br>◆ 比如，纳粹政府一开始说，特殊人才可以留下来，很多人就开始找各种渠道证明自己是特殊人才。你可以想象，有了可能的求生渠道，大规模反抗就很难组织起来。纳粹还设立“犹太人委员会”，招募犹太人警察，任命犹太人来管理犹太隔离区。<br>◆ 大屠杀不是历史上野蛮状态的重现，也不是一场偶然的悲剧。大屠杀的许多关键要素都内在地蕴藏于现代理性之中。这场灾难，是现代理性如何变得与道德和人性完全背道而驰的一个历史力证。<br>◆ 在鲍曼看来，要防范像大屠杀这样的灾难，关键在于要坚守一种不可让步的、无条件的道德感，保持对他人的道德感知。<br>◆ 简单地说，就是永远别忘了你面前的人是一个人。<br>◆ 这话听着简单，但我们前面讲过，现代社会的底层机制中就存在着一种非个人化或者非人格化的特性。如何在这种特性中保持我们的道德感，这是现代人需要思考的严肃问题，也是现代社会要面对的一个艰巨的挑战。<br>极端之恶与平庸之恶<br>◆ 原文是“banality of evil”。“banality”是平庸这个词的名词形式，所以这个词最准确的翻译应该是“恶的平庸性”。你注意到区别了吗？其实，阿伦特并不是说大屠杀是一种“平庸的”罪恶，她很明白地说过，纳粹的暴行是一种“极端之恶”。而阿伦特在纳粹军官艾希曼身上看到的，是一种“恶的平庸性”。<br>◆ 而纳粹大屠杀令人震惊的地方在于，纳粹不仅没有把犹太人看成是目的，甚至都没有把他们当作工具、当作手段。<br>理解不可理解的恶<br>◆ 在她看来，艾希曼并不是戏剧和小说中那种复杂而有魅力的反派角色，比如莎士比亚戏剧中的伊阿古、麦克白或者理查三世。艾希曼并不残暴，也不是恶魔。但他有“一种超乎寻常的浅薄”，“不是愚蠢，而是匪夷所思地、非常真实地丧失了思考能力”。这就是艾希曼身上的“平庸性”，实质上是一种“无思状态”（thoughtlessness），就是不思考。<br>◆ “极端之恶”和“平庸之恶”，其实是一体两面。纳粹大屠杀是一种极端的恶，但这种极端的恶，是经由一些“平庸”的罪犯犯下的。这些罪犯身上的这种“恶的平庸性”，其实质是不去思考，是丧失了思考能力。这从另一个角度解释了大屠杀研究中的难题：为什么寻常之人会犯下非同寻常的罪行。<br>思考的含义：独立判断<br>◆ 这里我们就发现，阿伦特说的思考能力，实际上是积极思考、获得独立判断的能力，我们依靠这种思维品质才能摆脱套话和陈词滥调，对是非对错做出自己的判断。<br>◆ 但你是否明白，独立判断的重要性究竟何在呢？阿伦特的回答是，因为在现代社会，只是月艮从主流规则，已经不再能够防止人们作恶。<br>独立判断的艰巨性<br>◆ 首先，“独立”不等于“正确”。循规蹈矩是有章可循，但如果你要独立判断，就得抛弃对既定规则的服从，自己确立标准，自己给自己立法。而在前面的章节中我们已经知道，现代性的根本困境之一是它瓦解了传统的价值规范，却无法建立起新的普遍有效的价值标准。因此，盲从是危险的，但独立判断也无法担保正确，还要面临巨大的风险。阿伦特对尼采的思想有非常透彻的理解，但她不是道德虚无主义者。她明确指出，道德思考没有通则可循，独立的道德判断是艰巨的任务。<br>◆ 结果，独立判断就成了一件责任风险极大的事。如果你循规蹈矩，做对了当然好；做错了，你也能很方便地为自己辩护：“这不怪我，规矩就是这样定的”或者“大家都是这样做的”。<br>◆ 2024/07/31发表想法<br>这跟萨特所说的自由选择与绝对责任是一致的。<br>原文：可是如果坚持独立判断呢？你就是面目清晰的个体，你无法将判断的责任推诿给众人，也无法诉诸通用法则；因此你的责任是可辨识的，也是可追究的。做对了，那是应该的；做错了，就是你自己导致的。你没有任何托词，没办法推给规矩，也没办法躲到“法不责众”的后面，你必须为自己承担全部责任。<br>◆ 可是如果坚持独立判断呢？你就是面目清晰的个体，你无法将判断的责任推诿给众人，也无法诉诸通用法则；因此你的责任是可辨识的，也是可追究的。做对了，那是应该的；做错了，就是你自己导致的。你没有任何托词，没办法推给规矩，也没办法躲到“法不责众”的后面，你必须为自己承担全部责任。<br>◆ 阿伦特认为，施密特和卢卡斯这样的人始终要求“忠实于自己”，他们做出独立判断的前提是始终保持“与自己相处、与自己交谈的倾向”。他们选择不作恶，不是为了服从于纳粹之外的某个戒律，而是因为他们无法接受作为杀人犯的自己，他们不愿意与这样一个自己共存。为此，他们甘愿承受危险、甚至付出生命。<br>◆ 2024/07/31发表想法<br>生，亦我所欲也；义，亦我所欲也。二者不可得兼，舍生而取义者也。——孟子<br>原文：在阿伦特看来，这种独立判断的典范在西方思想的源头中就存在，那就是苏格拉底。苏格拉底说过“宁可自己遭受冤屈，也不愿行不义”，这样他至少能够与自己和睦相处。<br>◆ 在阿伦特看来，这种独立判断的典范在西方思想的源头中就存在，那就是苏格拉底。苏格拉底说过“宁可自己遭受冤屈，也不愿行不义”，这样他至少能够与自己和睦相处。<br>◆ 阿伦特曾经说，“就各种特殊情况做出判断而言，没有什么恒常的通行标准，也不存在什么确定无疑的规则”。我们只能在具体的处境中，冒着风险，真诚地去做出自己独立的判断，并为此承担责任。这是现代社会的公民格外艰巨的道德任务。<br>22 | 波普尔I 科学是怎么被重新定义的<br>◆ 人类是容易犯错的物种，这是人类固有的特征。不管是在科学还是在政治经济活动中，我们都摆脱不了“可错性”（fallibility），就是说人永远可能会犯错。这在今天已经是常识了。<br>什么是证伪主义<br>◆ 先来讨论波普尔最著名的“证伪主义”理论，它可以概括为一句话：科学理论的标志不是它能够被证明是对的，而是它可以被证明为错的。<br>◆ 科学中所谓“正确”究竟是什么意思？ 	波普尔给出了回答：科学的正确永远是一种不彻底的正确。要理解这个“不彻底”，我们可以回到波普尔思想的起点，看看他是怎么思考这个问题的。<br>◆ 在实验之前，爱因斯坦明确表示：首先，如果观察的结果和理论预测不符合，那广义相对论就错了。而且，即使观察结果符合理论预测，也不意味着广义相对论就是绝对正确、无法超越的理论。 	爱因斯坦当然不希望自己的理论被否定，但他不仅没有回避经验检测，还明确提出了被经验证伪的可能，而且他绝不言称自己的理论是真理。这种态度与精神分析学派的理论家形成了鲜明的反差，让波普尔无比钦佩。他认为这种理性批判精神才是科学家的典范。<br>◆ 他说有两种关于地震的理论：根据第一个理论，大地被一头大象驮在背上，大象一崴脚，人间就会发生地震。这个理论很离谱吧？但这个理论是可以被证伪的：只要挖到地底下，看下面是不是有一头大象就行了。这当然是一个错误的理论，但却符合科学理论的条件。而根据第二个理论，说地震是阴阳失调引起的，而且它有一套非常系统的论述，能讲出很多道理。但是呢，你就是没办法检测这个理论。这个理论哪怕是正确的，也不是一个科学的理论。<br>◆ 所以，一个理论算不算科学理论，首先不是看它的对错，而是要看它是否能够接受事实的检测，是否可能被证伪。波普尔认为，这才是区别科学与非科学理论的试金石，他把这叫作“可证伪性”。<br>科学发现的逻辑<br>◆ 刚才讲到爱因斯坦还表达了一个想法：即使观察结果和理论一致，也不能证明理论就是绝对正确的。波普尔从中得到了启发，意识到证实和证伪是不对称的。什么意思呢？你看，一个理论被证实一百次、一千次、一万次，也不能证明它绝对正确，但只要被证伪了一次，它就被推翻了。<br>◆ 这个问题其实由来已久，从哲学家休谟到罗素都质疑过归纳法的可靠性。罗素很幽默，他说，一只每天被主人喂食的鸡，怎么也归纳不出有一天自己会被拧断脖子。维特根斯特也曾说过，我们之所以采用归纳法，是因为它是和我们的经验相协调的最简单的规律，但它并“没有逻辑基础，只有心理学的基础”。<br>◆ 其实并非如此，科学发现的逻辑应该是这样：先提出问题，然后针对问题提出理论猜想，再用事实证据来检测这个猜想。如果检测和猜想相符，就保留这个猜想。如果一直没有反面的证据，就一直维持这个猜想的暂时有效性。如果出现了反面的证据，我们就放弃这个猜想，构想新的理论，进入下一轮检测。科学发展就是一个猜想与反驳的不断试错的过程。<br>◆ 用“问题—猜想—反驳”的“试错机制”代替“观察—归纳—证实”的“实证机制”，这就对科学发展提出了新的解释。<br>◆ 这也意味着，科学无法达到绝对真理。很简单，如果一个理论始终都没有被证伪，能不能说它就是真理了呢？不能。因为没有人能保证未来不会遇到反例，不会遇到那只黑天鹅。所以，就算某个理论猜想碰巧是永恒正确的，我们也无法确认这一点，因为未来有待检验的案例是无限的。在这个意义上，科学永远只能获得暂时的正确性，这就是“不彻底的正确”的深层含义。<br>◆ 科学理论不是真理的代名词，只是一些尚未被证伪的假设。<br>23 | 波普尔II 为什么人类不能创造出完美社会<br>◆ 人类有理性，理性有局限。<br>乌托邦社会工程与历史决定论<br>◆ 2024/08/01发表想法<br>基于这个思想出现了1984，美丽新世界等书<br>原文：什么是“乌托邦社会工程”呢？简单来说，就是认为人类可以依靠自己的理性，按照某种预定的蓝图去改造整个世界，创造出完美的社会。波普尔认为，将这种社会工程的理念付诸实践，往往会导致灾难性的后果。<br>◆ 什么是“乌托邦社会工程”呢？简单来说，就是认为人类可以依靠自己的理性，按照某种预定的蓝图去改造整个世界，创造出完美的社会。波普尔认为，将这种社会工程的理念付诸实践，往往会导致灾难性的后果。<br>◆ 波普尔当然不是反对一切社会工程，他批判的乌托邦社会工程有一个鲜明的特点，就是“整体主义”。这是一种空间维度和时间维度上的全方位规划：在空间上涵盖了所有社会领域，大到国家制度的设计，小到一个家庭的形态，几乎无所不包；而在时间上则是由近到远地设计长久的规划，延伸到遥远的未来，直到人类社会最终的理想状态。乌托邦社会工程具有这种全面而久远的整体性特征，所以他有时候也称其为“整体主义社会工程”。<br>◆ 比如，你想为一场考试做一个复习计划，那当然没问题。因为这是个局部的、短期的计划，出了错也很容易变通调整。今天进度没完成，明天少玩一会儿手机，就补上了。但如果你要制定一个整体的人生计划表，从毕业工作到事业发展，从恋爱结婚到孩子教育，把一辈子的大事小事全都安排好，这种环环相扣、万无一失的规划肯定就行不通了。<br>◆ 想要覆盖一切、规划一切的乌托邦社会工程不可能成功。但为什么还有人会去信奉这种不切实际的规划工程，甚至付诸实践呢？ 	因为这背后有一种观念非常迷人，叫作“历史决定论”。就是认为历史是被一套规律所决定，向某个确定的目标发展，最终会实现这个确定的目标。也就是说，历史发展是被一套铁的规律所决定的，因此被称为“历史决定论”。<br>◆ 而按照历史决定论看法，主观努力只能发挥有限的作用，只能促进或者拖延这个历史进程，但无法改变历史发展的规律。那么，社会科学的任务就是去发现这种规律，并且预测历史发展的未来，从而制定最完美的蓝图来整体性地改造社会。<br>◆ 这是什么意思呢？举个有趣的例子，有人说，如果马克思把自己的著作都藏起来不发表，说不定现在资本主义已经灭亡了。可惜马克思把他的理论公布于世，资本主义的内在矛盾就完全被揭露了，成了全人类的知识。工人阶级去学习，但资本家也可以学习。他们意识到了改良资本主义的必要性和紧迫性，提高工人的工资和福利，改善他们的劳动和生活条件，这样一来就缓解了劳资矛盾，改变了，或者说至少是延缓了资本主义灭亡的进程。<br>◆ 所以在波普尔看来，一方面，我们并不能找到历史发展的绝对规律，另一方面，人类知识的增长本身也会改变历史的进程。历史决定论在根本上就是无法成立的。<br>◆ 2024/08/01发表想法<br>一个是贪心，一个是动规。冰汽时代里的社会工程就是渐进社会工程。<br>原文：我们来对比一下，波普尔支持的渐进社会工程，和他反对的乌托邦社会工程有三个重要的区别：<br>
<br>
第一，前者着眼于克服最紧迫的恶，而后者是要追求最终极的善。<br>
<br>
第二，前者要寻求改善人们命运的合理方法，而后者也许有着极其善良崇高的意愿，但在实践中却可能加重了现实的苦难。<br>
<br>
第三，从历史上看，渐进式的改良基本上能够成功，而试图整体性地创造乌托邦的规划，基本上都会引发悲剧，最终背离了自己当初的蓝图目标。<br>◆ 我们来对比一下，波普尔支持的渐进社会工程，和他反对的乌托邦社会工程有三个重要的区别： 	第一，前者着眼于克服最紧迫的恶，而后者是要追求最终极的善。 	第二，前者要寻求改善人们命运的合理方法，而后者也许有着极其善良崇高的意愿，但在实践中却可能加重了现实的苦难。 	第三，从历史上看，渐进式的改良基本上能够成功，而试图整体性地创造乌托邦的规划，基本上都会引发悲剧，最终背离了自己当初的蓝图目标。<br>◆ “缔造人间天堂的企图，结果总是造就了人间地狱”。他认为20世纪历史留下最深刻的教训之一，就是要警惕历史决定论的神话，防范“乌托邦社会工程”的实践。<br>卓越而速朽的思想家<br>◆ 在我看来，如果说波普尔的名字被遗忘了，他的思想被看成是人尽皆知的常识，那么这种遗忘恰恰体现出他成就的卓越。<br>自发秩序<br>◆ 首先，一个最直观的、最“纯天然”的例子，就是“乡间小路”。一开始，田野上并没有路，每个通过这里的人，都会走一条自己认为最好的路线。一条路线只要有人走过，别人就更有可能沿用这条路线，当然后来的人也可能选择自己喜欢的新路线。过路的人多了，田野上就会浮现出一条反复被人采用的路线，这条路会变得越来越清晰，最后就形成了我们看到的乡间小路。<br>◆ 2024/08/01发表想法<br>即无为<br>原文：哈耶克解释说，乡间小路的形成当然是人们有意识选择的结果，但它是许多个体分别选择、然后自然叠加形成的。它不是由哪个权贵有意设计出来的，也没有经过集体商议和规划。这条小路在许许多多的个体选择中慢慢浮现出来，是一种自然演化的结果。<br>◆ 哈耶克解释说，乡间小路的形成当然是人们有意识选择的结果，但它是许多个体分别选择、然后自然叠加形成的。它不是由哪个权贵有意设计出来的，也没有经过集体商议和规划。这条小路在许许多多的个体选择中慢慢浮现出来，是一种自然演化的结果。<br>◆ 一个是语言，这是一个特别典型的自发秩序。语言本身是人类活动的产物，其中存在着规则，就是语法。但如果要问，究竟是谁创造了语法规则呢？你几乎找不到有哪种通用语言是被人专门设计出来的。语言规则，基本上都是在自然演化的过程中逐渐形成的。<br>◆ 他指出，在法律能够被成文表达出来之前，社会中已经积累了很多不成文的规范，比如“欠债要还钱”“伤害要赔偿”等。而立法者的工作首先就是把已经自发形成的规则表达为规范而明确的法律文本。<br>◆ 2024/08/01发表想法<br>无为而治<br>原文：但每个人的选择并不是一个系统规划，而是提供多种可能的选项，然后在类似“优胜劣汰”的自然选择机制中形成了秩序。所以哈耶克把自发秩序看作是“自然演化”的结果，他并不排斥人为因素，但反对把人为设计的意图过度拔高，上升到对社会秩序的整体性规划。哈耶克的核心观点，可以概括为“有意栽花花不发、无心插柳柳成荫”。<br>◆ 但每个人的选择并不是一个系统规划，而是提供多种可能的选项，然后在类似“优胜劣汰”的自然选择机制中形成了秩序。所以哈耶克把自发秩序看作是“自然演化”的结果，他并不排斥人为因素，但反对把人为设计的意图过度拔高，上升到对社会秩序的整体性规划。哈耶克的核心观点，可以概括为“有意栽花花不发、无心插柳柳成荫”。<br>继承苏格兰启蒙传统<br>◆ 但是，启蒙传统并不是铁板一块，它还存在一个重要的分支，就是亚当•斯密和大卫•休谟代表的“苏格兰启蒙运动”。他们的观点和法国启蒙思想家有所不同——他们在承认理性的重要作用的同时，反对“理性万能论”，反对那种好像人类的理性可以扮演新的上帝，去改造和规划世间的一切的观点。苏格兰启蒙运动倾向于把理性看成一种怀疑、反省和批判的能力，而不是掌控一切的能力。<br>◆ 我们今天注重批判性思维，很少再有人相信“理性无所不能”。但是，批判理性的观念在20世纪之前都不是思想界的主流。直到20世纪，经过了一系列历史事件和思想界的一次次辩论，苏格兰启蒙这个启蒙传统的旁支反过来改造了启蒙传统的主流，形成了今天的这种常识。<br>25 | 哈耶克II “理性的自负”为什么很危险<br>◆ 我们曾提到，所谓“理性的自负”，是指对人类的理性能力抱有过度的信心，相信理性能获得几乎完美的知识，从而构建出完美的社会规划，实现理想的人类生活。<br>理性的自负<br>◆ 事实上，哈耶克用“理性的自负”来解释德国和苏联的历史，这是不同于当时主流看法的另类观点。 	在二战后期，西方主流观点认为，纳粹德国和苏联是两种截然不同的社会经济模式；苏联是超理性的，而纳粹是非理性的，两者相距甚远。但哈耶克认为这两种模式的病根是同源的，都来源于“理性的自负”。具体表现就是，在经济领域中推行计划经济，在社会规划中依赖高度理性化的系统设计。<br>◆ 哈耶克说，事实并非如此，纳粹主义有它深刻的思想起源，它其实是集体主义梦想的一个最高版本。<br>◆ 哈耶克强调指出，这种规划模式表明，纳粹德国并不是疯狂的产物，在它的思想和实践中都包含着高度理性的部分，试图用理性的现代化来铲除所有非理性的东西。甚至在对于犹太人的迫害中，纳粹的口号首先不是仇恨，而是用伪科学来证明犹太人是不符合秩序的存在，因此他们要被铲除。纳粹德国在道德和社会秩序上的“洁癖”都来自所谓科学理性，他们相信自己掌握了人类的终极知识，想要无限度地追求卓越。<br>◆ 人们追求的理想可能是极其崇高的，但“理性的自负”会让事与愿违。哈耶克说过，那些统治者“自觉地根据一些崇高的理想来缔造我们的未来，实际上却不知不觉地创造出一种和他们想要奋斗的东西截然相反的结果，人们还能想象出比这更大的悲剧吗？”<br>人类的必然无知<br>◆ 哈耶克的《致命的自负》这本书中提到，理性的自负之所以致命，是因为我们很难逃脱一种诱惑，就是想用理性去做整体设计。<br>◆ 他告诫我们，必须始终清醒地认识到“人类的必然无知”。这不是说人类什么都不知道，而是强调人类的知识总是有局限的，必然包含着无知的一面。<br>◆ 2024/08/01发表想法<br>我觉得还是因为人本身的恶导致官僚制度的腐朽，从而导致整体规划无法被彻底准确地实施。<br>原文：所以，计划经济的根本弊端，就是自负地认为人类能够获得充分的知识，设计完美的秩序。在哈耶克看来，这根本是不可行的。<br>◆ 所以，计划经济的根本弊端，就是自负地认为人类能够获得充分的知识，设计完美的秩序。在哈耶克看来，这根本是不可行的。<br>◆ 2024/08/01发表想法<br>未必不可能，掌握人类社会的所有信息，实时推算出最佳的选择。<br>原文：因为这要求计划经济的指挥者对整个社会的需求有非常充分的了解，达到一种近乎“全知全能”的状态，掌握所有知识和瞬息万变的信息——这实际上是不可能的。<br>◆ 因为这要求计划经济的指挥者对整个社会的需求有非常充分的了解，达到一种近乎“全知全能”的状态，掌握所有知识和瞬息万变的信息——这实际上是不可能的。<br>哈耶克的思想影响<br>◆ 因为当时西方资本主义刚刚经历了严重的经济危机，凯恩斯的国家干预理论更受欢迎。<br>◆ 2024/08/01发表想法<br>哈耶克太乐观了，不同阶级同时存在的社会怎么可能达到完全公平的自发秩序呢？自发秩序中最永恒不变的是弱肉强食，那么新自由主义不就是社会达尔文主义吗？<br>原文：然而，随着近三十年来西方社会的贫富差距拉大、经济增长放缓，人们又开始反思和批评以哈耶克为代表的新自由主义。<br>◆ 然而，随着近三十年来西方社会的贫富差距拉大、经济增长放缓，人们又开始反思和批评以哈耶克为代表的新自由主义。<br>◆ 康德曾经说，人类的不成熟状态就是不敢公开大胆地运用理性。哈耶克则进一步揭示出，如果妄想用理性彻底征服无知，消除所有的不确定性，这是人类的另一种不成熟。事实上，人类真正的成熟，是在勇敢运用理性的同时，直面自己永远不可能完全摆脱的无知，勇敢地与不确定性共存。<br>26 | 伯林I 是“狐狸”还是“刺猬”<br>◆ 伯林后来说，俄罗斯思想家有一个共同信念，就是相信对于人类的困境存在一个确定的答案，存在一种真理。只要找到了真理，去推动激烈的社会变革，就可以终结人间的苦难。<br>◆ 但伯林又亲眼看到了激烈变革的惨烈状况，他意识到这种“拯救的信念”其实有很危险的一面，它可能会导致暴政。<br>◆ 伯林在牛津大学的时候是一个标准的学霸，23岁的他就被牛津大学的万灵学院录取为研究员（fellow）。万灵学院是牛津大学最特殊的学院，自己不招收学生，而是每年从牛津大学最优秀的学生中邀请一部分人来考试，再从参加考试的人当中挑选出两个人，成为万灵学院的研究员。这相当于从整个英国的精英里再挑选最好的尖子生，而伯林是历史上第一个通过这个考试的犹太人。<br>◆ 为什么有许多政治实践，原本出于非常美好的愿望，却在某些观念的指导下，造成了灾难性的后果。<br>27 | 伯林II 价值一元论错在了哪里<br>◆ 这就要说到伯林一生的研究中最重要的两个主题：第一，他主张的价值多元论；第二，他澄清了“自由”这个概念，提出了著名的“两种自由”的理论。<br>价值一元论的吸引力<br>◆ 那价值多元论是什么意思呢？就是主张人们追求的价值不是单一的，而是多种多样的。而对于“什么是美好的生活”这个问题，价值多元论者认为，理性无法给出唯一正确的答案。<br>◆ 要理解价值多元论的高明之处，首先要理解它的对手，也就是价值一元论，究竟说了什么。 	价值一元论并不是说世界上只有一种价值，或者人只能追求一种价值，它主张的是，表面上有丰富多样的价值，但这些价值在本质上是和谐统一的。 	也就是说，虽然价值多种多样，但它们可以用同一个评价尺度来比较，排出高低上下。价值虽然有很多，但尺子只有一把。有了这把尺子，就能给价值排序——低级的价值就应当服从高级价值，我们最终能找到一个最高的价值，所有其它价值都是从最高价值派生出来的。<br>◆ 比如，我们假设最高价值是幸福，那么你追求的所有其它价值，无论是事业成就、家庭美满，还是身体健康，原则上都可以用“幸福”这把尺子来衡量。<br>◆ 于是从价值一元论就可以引申出一个推论，就是对于“什么是美好的生活”这个问题，存在唯一正确的答案，能让你做出最好的选择。<br>◆ 在哲学方法论的意义上，价值一元论要求“透过现象看本质”，所以持有这一观点的人们才会去主张，价值多样的表面现象并不等于价值在“本质上”是多元的。<br>◆ 理性主义有一种倾向，就是质疑一切直观的经验现象，试图借助理性在表象之后找到一个本质。你看，这和价值一元论是不是很一致？<br>◆ 至于价值一元论为什么会有巨大的吸引力，你想，无论在古代还是现代，世界总是充满矛盾。但如果我们相信，不管世界怎么乱，必定有一个最高的天道、神意或者真理，就算我们自己没法把它弄明白，还有圣人、哲人、科学家，甚至神仙有机会能搞懂。只要掌握了终极的价值，表面的纷争最终会归于和谐。这是不是让人觉得心里很安慰？其实，不光你这么认为，很多聪明人也是这样想的。要不然牛顿也不会总想着用几个公式来为世界立法，就连爱因斯坦，后半辈子不也是一直想找到一个“统一场论”吗？<br>◆ 因此，一元论的魅力就在于给出了一个最和谐美好的图景：我们可以用一种特定的价值去统领一切，摆脱多元价值的冲突，这会大大缓解生活的不确定性。伯林说，无论对于理智还是情感，这种观念都是一种深刻的满足。<br>伯林的反驳<br>◆ 有一个真实的案例：几年前在某个大学，一个学生在宿舍的饮水机里投毒，导致他的室友中毒身亡。死者的家属要求判投毒者死刑，而投毒者的父母百般希望获得被害者家人的宽恕，说死者已死，让另一个年轻人偿命也无济于事一两对父母依赖的出发点就是两种价值。一种是正义，杀人偿命嘛；另一种，是仁慈，宽恕我们吧，人死不能复生。<br>◆ 如果让伯林来面对这个问题，他会怎么说？他会说，原则上无法解决。正义与仁慈都是人类的终极价值，但这两种价值不可公度，也常常无法调和：如果实现了正义，就无法同时满足仁慈；而如果用仁慈来宽恕凶手，那么就必须牺牲正义。<br>◆ 我们要在同等终极的目的、同等绝对的要求之间做出选择，且某些目的之实现必然无可避免地导致其它目的之牺牲&nbsp;&nbsp;&nbsp;&nbsp;所以，（我们）需要选择，需要为了一些终极价值牺牲另一些终极价值，这就是人类困境的永久特征。<br>◆ 注意，这不只是说“三观不合”的人才会发生冲突，即便是价值观完全相同的一群人，甚至一个人与自己，也可能陷入这种左右为难的局面。这才是价值冲突最深刻的困境。<br>价值是主观的和相对的吗<br>◆ 有很多人信奉价值多元论，但他们信念的基础是主观主义，认为物理世界有客观性，而人类重视和珍惜的价值并不客观存在，它们只是来自个人或特定文化的主观偏好。由于大家的偏好不同，所以价值自然是多元的。所有价值都只对特定的个人或文化才有效，“你喜欢番茄，我喜欢土豆”，除此之外没有什么好说的。<br>◆ 但伯林反对这种主观主义的立场。他的价值多元论有一个与众不同的特点，就是价值客观论，他反对价值主观主义和相对主义。伯林强调，价值虽然是多元的，但仍然是客观存在的，不是主观想象的随意构造。<br>◆ 伯林坚持认为，人类具有某种最低限度的“共通性”。即使双方价值追求不同，甚至可能会因此开战，但你我仍然可以想象、可以理解对方为什么会追求这种价值。<br>◆ 比如，中国人说“忠孝不能两全”。有人会选择忠，有人则偏向选择孝，但两个人都会理解对方的选择。<br>◆ 伯林的价值多元论很容易和主观主义、相对主义混为一谈，但伯林自己一直在努力澄清，他的主张不是主观主义，也不是相对主义。 	总结一下，伯林认为，人类的生活世界存在着多种不同的终极价值，这些价值是客观的或真实的，但它们之间常常无法公度，不能彼此兼容，甚至可能发生严重的冲突，导致某种无可挽回的损失，这是深刻的人类困境。价值一元论试图克服这种困境，但它本质上是一种概念错误。<br>28 | 伯林III 你想要的是哪种“自由”<br>◆ “自由”的含义需要澄清吗？其实自由这个词，说简单好像也很简单，就是不要管我。<br>◆ 可是等小孩再长大一点就会发现：要理解自由没那么简单。比如父母要送他去上兴趣班，小孩说，不，我不要去，我要自由地待在家里。父母不会答应，孩子还是得去。但他去的可能是一个足球兴趣班，他发现在球场上飞奔踢球的感觉太好了，好像体验到了真正的自由。 	在球场上奔跑的自由和爸妈别管我的自由，是同一回事吗？<br>消极自由与积极自由<br>◆ 伯林说，在思想史上，自由可能有过两百多种定义，但有两种核心的自由概念贯穿了整个人类历史。伯林把这两种自由叫作“消极自由”和“积极自由<br>◆ 消极自由是什么呢？简单来说就是我不想要什么、就可以不要什么，英文是“free from”。而积极自由就是我想做什么、就可以去做，英文是“free to”。换句话说，一个是摆脱障碍的自由，一个是实现目标的自由。<br>◆ 举个很简单的例子，你不想被抢劫，并不等于你已经决定了要把手上的那笔钱花在哪里。你要摆脱一种外来的干涉，并不需要你必须有一个明确的目标。 	消极自由强调的是维持一个不受干涉的领域。在这个意义上，消极自由更像是一种机会，只要保留了这个机会，就算什么都不做，你也保持了你的消极自由。 	但积极自由就不一样了，它是“实现某个目标”的自由，你要是什么都不做，那就麻烦了。也许你会说，我的目标就是“什么都不做”，不可以吗？这就要说到积极自由的一个特别之处。首先你要知道，自由必定有一个行动主体。但在积极自由的概念里，主体常常有内部的划分：有一个是“真正的”“高级的”“理性的”自我，还有一个是“虚假的”“低级的”“非理性的”自我。积极自由的目标往往是指，那个理性的自我能够主导自己，去实现高级的目标。<br>◆ 现在有一句很流行的话，叫“自律给我自由”，这里说的自由，就是克服自己非理性的一面，实现积极自由。<br>◆ 2024/08/02发表想法<br>PUA<br>原文：一个月之后，你厌倦了这份需要“996”的工作，想要辞职不干了。你的朋友又出现了，他劝导你说，这个工作最符合你的长远利益，你现在太年轻、不懂事，必须听他的教导，他甚至每天早上亲自来把你绑上车送到公司。他说，这个工作才是你真正想要的，虽然现在你还不明白。那么现在，表面上他强制了你，但在本质上是帮助你实现你一时还不明白的、却是你真正想要的目标，让你得到了更高的自由。<br>
<br>
说到这里，你会不会觉得像是在看恐怖片，有点毛骨悚然了呢？<br>
<br>
其实，这个“朋友”是一个隐喻，可以代表任何一种权威，他用积极自由的理论，把“强制”变成了“真正的自由”。<br>◆ 一个月之后，你厌倦了这份需要“996”的工作，想要辞职不干了。你的朋友又出现了，他劝导你说，这个工作最符合你的长远利益，你现在太年轻、不懂事，必须听他的教导，他甚至每天早上亲自来把你绑上车送到公司。他说，这个工作才是你真正想要的，虽然现在你还不明白。那么现在，表面上他强制了你，但在本质上是帮助你实现你一时还不明白的、却是你真正想要的目标，让你得到了更高的自由。 	说到这里，你会不会觉得像是在看恐怖片，有点毛骨悚然了呢？ 	其实，这个“朋友”是一个隐喻，可以代表任何一种权威，他用积极自由的理论，把“强制”变成了“真正的自由”。<br>揭穿扭曲自由的“概念魔术”<br>◆ 伯林明确说过，消极自由和积极自由都是正当的终极价值，原则上没有高下之分。但这两种自由都可以被滥用和扭曲，伯林想强调的是，积极自由的扭曲和滥用更具有欺骗性，更要对其保持警惕。<br>◆ 但是，牺牲就是牺牲。当自由必须被牺牲的时候，我们就应该说“这是牺牲了自由”换来了安全、秩序或者别的什么。而不应当玩弄“概念魔术”，把牺牲改头换面变成“更高的自由”。<br>◆ 回到经验世界我们就会发现：追求自由，是因为我们能体验到自由的反面。我们有一种普遍、深刻、强烈而朴素的体验，就是强制，而强制的极端就是奴役。“强制”这种苦难的体验与自由有最根本、最切近、最直接的关联，我们对自由的渴望，最直接的来源就是对强制的不满、对奴役的反抗，所以我们会大声喊出“不要强迫我！”<br>◆ 这是一种否定性的愿望，它和强制与奴役相伴相生，跨越了文化和历史，是最为普遍的人类经验之一。所以伯林说，“自由的根本意义是摆脱枷锁、摆脱囚禁、摆脱他人奴役的自由。其余都是这个意义的延伸，或者是某种隐喻”。<br>◆ 在这个意义上，你可以说伯林更偏向消极自由。因为他认为，用消极自由的概念来理解自由，能让我们铭记自由最原初的含义，避免在眼花缭乱的概念魔术中迷失，也更有助于我们分辨出“假自由之名行反自由之实”的伪装和欺骗。<br>◆ 毕竟，在伯林看来，20世纪的政治历史中最为触目惊心的一幕，就是以自由的名义来实施强制，并宣称强制的结果是“实现了真正的自由”。这是伯林深恶痛绝的概念魔术。而伯林之所以要剖析自由的概念，一个重大的意义在于，揭露这种概念魔术，提醒人们保持警惕，防止悲剧重演。<br>29 | 马尔库塞I “舒适的”不自由是怎么一回事<br>◆ 但是马尔库塞认为，还有一种比“强制”更加危险的控制方式，会让人心甘情愿地服从于制度的控制，陷入一种“舒适的”不自由之中。<br>新左派运动的“教父”<br>◆ 但在20世纪60年代，马尔库塞可以说是名满天下。 	当时发生了席卷全球的抗议风潮，比如法国有“五月风暴”，美国有民权运动和反战运动，等等。这些运动有着共同的特点：主体是青年学生，带有明显的左翼政治倾向，批判和反抗资本主义。<br>◆ 在这场运动中，西方青年学生崇尚三位精神导师，这三位的名字都以英文字母M开头，被称为“3M”。前两位你肯定熟悉，就是马克思和毛泽东，最后一位就是马尔库塞。你看，居然可以和马克思、毛泽东齐名，这位马尔库塞究竟是何方神圣呢？这要从他本人的经历说起。<br>◆ 马尔库塞的批判很尖锐，听上去有点语出惊人，他说，美国这样的发达工业社会，是一种“新型的极权主义”。这里的极权不是集中权力的意思，它的英文是“totalitarianism”，这个词最初的意思是指一种无所不包的总体性，“totality”。在西方思想界，极权主义原本特指纳粹那样的恐怖统治。马尔库塞作为纳粹政权的受害者，应该非常了解美国与纳粹德国的区别；但他却说美国社会也是一种“极权主义”，这是不是危言耸听呢？<br>◆ 极权主义不只有纳粹这一种形态，它还有另一种截然不同的形态，马尔库塞把它叫作“非恐怖的极权主义”。<br>新型的控制方式<br>◆ 比如在他最著名的作品《单面人》（也译为《单向度的人》）中，开篇就写道：“一种舒舒服服、平平稳稳、合理而又民主的不自由在发达的工业文明中流行……”你看，一口气加了四个正面词汇，最后形容的对象却是“不自由”。<br>◆ 什么叫“舒舒服服、平平稳稳、合理而又民主的不自由”呢？就是说，在发达资本主义社会中，人们虽然享受着富裕的生活，实际上却处在一种总体性的控制之中，不知不觉地丧失了自由。因为这种不自由太舒适了，人们很难察觉，也就无从反抗，结果深陷在控制之中却无法自拔。<br>◆ 马尔库塞说，这是因为这种新型的控制有两个特点：第一，它很隐秘，不需要暴力和强制，你也就不会觉得恐怖。第二，它能够有效应对自己的敌人，能够排斥、化解甚至“招安”反叛者，让总体性的控制生生不息地延续下去。<br>◆ 这种控制看起来也太强大了吧，这是怎么做到的呢？马尔库塞展开了非常复杂的分析。但我认为，其中关键可以归结为两个字：贿赂。这不是说一个人去贿赂另一个人，而是说社会去贿赂人民大众。资本主义让你享受舒适的生活，特别是满足你的消费欲望，用这种方式收买了你，换取了你的服从。而你甚至不知道自己被收买了，就心甘情愿地被它支配和操纵。<br>◆ 你可能会说，这是因为美观的需要啊。可是“美观”本身也是可以被制造、被操纵的，广告就是主要的操纵手段。现在很多广告都是去营造一种联想，暗示你使用这个产品就能获得时尚、有品位、令人羡慕的生活，或者就有了健康、阳光、魅力十足的自我形象。<br>◆ 广告把产品和“生活方式”“自我形象”绑定在一起，通过各种媒体话语，深深地植入你的潜意识之中。于是，很多时候你不是在为功能付费，而是在为某种“生活方式”或者“自我形象”的想象付费，而且甚至是付出十倍、百倍的价格。<br>普遍的异化<br>◆ 有人会质疑就算这是贿赂，只要人们心甘情愿，愿意接受这种贿赂，这就不过是一桩你情我愿的交易罢了，又有什么不能接受的呢？ 	对此，马尔库塞的回答是，因为这桩交易根本不公平，简直就是欺诈！富裕的生活和舒适的享受本身并没有错，但我们为此付出的代价太高了，几乎是无法承受的代价。这个代价，就是我们作为“人”的身份。接受这桩交易，我们就被“物化”，或者说几乎沦为了动物，不再是完整意义上的人。<br>◆ 马克思借用了黑格尔的这个概念，探讨资本主义条件下的劳动状况，发现了“劳动异化”的现象。你上中学的时候可能学过，马克思说，劳动是人的本质特征，是人的第一需要。你当时可能会感觉，这句话很反常识吧？大家好像都不太喜欢劳动啊。但马克思接着说，在资本主义条件下，工人感到劳动是一种与自己对立的苦役，完全是异己的活动，这就是劳动的异化。<br>◆ 马克思说：“工人在自己的劳动中不是肯定自己，而是否定自己，不是感到幸福，而是感到不幸，不是自由地发挥自己的体力和智力，而是使自己的肉体受折磨、精神遭摧残……”只要肉体的强制或其它强制一停止，人们会像逃避瘟疫那样逃避劳动。<br>◆ 结果是什么呢？马克思接着说，结果是“人只有在运用自己的动物机能一吃、喝、生殖，至多还有居住、修饰等——的时候，才觉得自己在自由活动，而在运用人的机能时，觉得自己只不过是动物”。<br>◆ 可我们真的克服了“劳动异化”的问题吗？即使是在今天，又有多少人是把劳动看作自己的第一需要呢？为什么大家都喜欢周末、讨厌周一？为什么“钱多事少离家近”被看成是“最好的”工作？<br>◆ 我想，只要人的异化仍然是现代社会的现实，马克思就仍然是我们的同代人。<br>“单面人”<br>◆ 在马尔库塞看来，这份手稿中充满人道主义精神，这种精神贯穿了马克思的整个思想。他认为，马克思所说的人类解放的理想，就是要克服人的异化，这是一种人道主义的理想。<br>◆ 现代的资本主义与马克思时代相比已经很不一样了。在现代，普通工人也能过上相对富裕的生活，享受消费的快乐。但对于大多数人来说，劳动工作仍然只是赚钱的手段和工具，消费和享受才是目的。在工作中感到累得像条狗，而在吃、喝、性爱等活动中才感到自己像个人。<br>◆ 所以，马尔库塞说，资本主义社会不是真正自由开放的社会，而是“单面”，或者说“单向度”的社会，生活在这种体制中的人，也不是立体丰富的全面发展的个体，而是丧失了真正自由的“单面人”。<br>变革的必要性<br>◆ 马尔库塞相信，如果社会的进步仅仅只是越来越富裕，那就算不上是真正的进步，因为人的异化不仅没有消失，反而更深入更广泛地渗透和弥散在生活的所有领域。这是一个在经济、政治和文化等方面都被商品拜物教所支配的社会，一种平庸而单面的世界。他认为，如果社会的进步只是变得富裕或者只是财产的转变，那就是对“人的解放”这一承诺的背叛，是对马克思人道主义理想的背弃。<br>31 | 马尔库塞III “实质性的变革”是有可能的吗<br>◆ 但问题是，即便我们承认变革是必要的，可是变革真的可行吗？在马克思的时代，阶级矛盾那么尖锐，资本主义制度也没有被彻底颠覆。在当今更富裕、大众生活更舒适的资本主义社会中，变革又怎么可能发生呢？ 	这正是马尔库塞反复思考的一个难题，他发现对于这个问题，现实给出的答案并不乐观。<br>工人阶级革命意识的丧失<br>◆ 首先，革命行动需要主体。在马克思的理论中，最有潜力的革命主体是工人阶级，可如今，革命的主体似乎已经消失了。<br>◆ 当代资本主义与马克思生活的时代相比，发生了巨大的变化。新的控制方式有效地压制了社会革命的思想理念，也消解了革命所需要的行动者。革命的主体似乎消失了，至少变得难以辨识。<br>◆ 你可能还记得《共产党宣言》结尾处那句震撼人心的呼唤：“无产者在这个革命中失去的只是锁链，他们获得的将是整个世界。”但现在呢？如果发动一场革命，工人阶级可能会感到，自己会失去很多，而不只是锁链。<br>◆ 在马尔库塞看来，工人阶级已经被整合到了资本主义体系之内，这种整合甚至深入心理层面。工人阶级曾经因为饱受压迫，爆发出反抗体制的否定性力量，但现在他们更关心如何进入体制之中，获得更多的收益。他们曾经是革命的主体，但现在已经不再具有革命性，成为维护资本主义的保守力量。<br>对异端的驯服<br>◆ 我们知道，发达资本主义“标配”的政治制度是自由民主制，在这种制度下，不是有批判和反抗的空间吗？我们从各种新闻报道中常常听得到各种质疑、辩论、批判和抗议活动。那么体制的控制和整合难道真是那么充分有效吗，它似乎并没有消除这些异端思想和反抗力量啊！<br>◆ 民主政治给异端留下了空间。但他认为，所有这些质疑、批评、辩论、竞争、投票，甚至包括社会抗议运动，都只是在体制内部起作用，只能带来量变，无法突破体制本身，导致社会的质变。这就好比一个足球守门员说，足球运动需要变革。教练说，好吧，那要不换你去踢前锋，或者后卫？<br>◆ 马尔库塞甚至认为，这些表面上热闹的批评、抗议，它们的存在本身就是社会控制模式的一部分。这些表面上喧嚣的“异端”并不能改变社会体制，反而造成一种假象，让这个单面的社会披上了自由多元的外衣。<br>◆ 20世纪60年代的摇滚乐有一个醒目的特征，就是激进的反叛性。他们不仅抵抗传统价值，追求个性解放，而且鲜明地针对政治，积极介入各种政治运动之中，包括民权运动、女权运动和反战抗议，等等。摇滚乐有着广泛的大众影响力和号召力，又如此激进地反抗体制，照理说，应该会形成强大的反体制力量吧？ 	但我们看到结果是什么呢，结果是资本主义体制把摇滚乐给商业化了。给你舞台，给你排行榜，给你巡演，给你发唱片；摇滚乐手成了大明星，获得巨大财富，进入上流社会，最终被这个体制吸纳。而那些商业化失败的摇滚乐手，则被边缘化，慢慢消亡；有的人陷入颓废和绝望，甚至自杀。 	我们看到，资本主义体制的控制力量如此强大，它能够灵活地应对任何寻求反抗和解放的挑战，极其有效地“收编”反抗力量，把异端改造成主流，最终成为体制的一部分。<br>◆ 在这种新的控制模式中，违背或超越主流的另类观念、愿望和目标，只有两种命运：要么被排斥消灭掉；要么就是按照主流世界的原则被转化，转化为现存体制能接受的方式继续存活。<br>解放的幽灵<br>◆ 2024/08/02发表想法<br>Trump的当选是否是这类人群也开始被收买了呢<br>原文：可是，在工人阶级被收买之后，变革的主体在哪里呢？马尔库塞把希望寄托于体制的边缘人群，包括青年学生、失业者、流浪汉以及其他被压迫的社会底层。他们不是体制的既得利益者，还没有被收编。他们的抗争虽然缺乏自觉意识，但这些被压迫者的抗争，最有可能撕开体制伪善的一面。<br>◆ 可是，在工人阶级被收买之后，变革的主体在哪里呢？马尔库塞把希望寄托于体制的边缘人群，包括青年学生、失业者、流浪汉以及其他被压迫的社会底层。他们不是体制的既得利益者，还没有被收编。他们的抗争虽然缺乏自觉意识，但这些被压迫者的抗争，最有可能撕开体制伪善的一面。<br>◆ 但是，尽管怀抱如此宏大的期望，对于运动的最终结果，马尔库塞并不乐观。他说批判理论并不许诺成功，但仍然怀有希望。在《单面人》的最后，马尔库塞引用了本雅明写下的一句话：“只是因为有了那些不抱希望的人，希望才赐予了我们。”<br>◆ 到这里，你可能也发现了，马尔库塞一直说要变革，但却没有指明变革之后该怎么办。他展开了全面的批判，却没有给出具体的建设性目标。还记得前面的例子中，那个要求变革足球运动的守门员吗？马尔库塞可能会说，守门员变成前锋，这不是实质性的变革。那怎样才算实质性的变革呢？大概在足球场上游泳才算吧？但这根本不可能实现。实际上，马尔库塞也没有提出任何可实现的制度性方案。<br>◆ 2024/08/02发表想法<br>Trump走的就是里根的保守主义路径。<br>原文：站在今天，我们来回看那场席卷世界的青年抗议运动，它并没有在根本上改变资本主义的政治经济制度，甚至后来还引发了保守主义的强劲反弹，尤其体现在里根切尔时代的经济政策上。<br>◆ 站在今天，我们来回看那场席卷世界的青年抗议运动，它并没有在根本上改变资本主义的政治经济制度，甚至后来还引发了保守主义的强劲反弹，尤其体现在里根切尔时代的经济政策上。<br>32 | 路标 自由主义为什么会不断遭到挑战<br>◆ 自由主义不断被宣告死亡，恰恰表明它还活着，仍然具有很强的生命力，但同时也表明，人们对于自由主义的主导地位心存许多深刻的不满。这是为什么呢？原因可能有很多，但主要的原因是自由主义在现代的发展中遭遇了越来越强的平等主义的压力。也就是说，自由面对着来自“平等”的挑战。<br>从“特权”到普遍的自由<br>◆ 2024/08/03发表想法<br>这就是儒家所讲的各司其职<br>原文：那自由和特权又有什么关系呢？在古代，特权与等级制联系在一起。等级结构中，每个阶层都有自己的特权：领主有领主的特权，商人有商人的特权，农民也有农民的特权。比如，领主有权向佃农收税收粮，而佃农有权要求领主保护他们。这里的“特权”，实际上是指“你能够如何自主行动”的意思。换句话说，根据等级位置，你有特定的不受侵犯的自主空间，这就是你的自由。<br>◆ 那自由和特权又有什么关系呢？在古代，特权与等级制联系在一起。等级结构中，每个阶层都有自己的特权：领主有领主的特权，商人有商人的特权，农民也有农民的特权。比如，领主有权向佃农收税收粮，而佃农有权要求领主保护他们。这里的“特权”，实际上是指“你能够如何自主行动”的意思。换句话说，根据等级位置，你有特定的不受侵犯的自主空间，这就是你的自由。<br>◆ 但是你稍微想想就能发现，自由和平等之间很容易产生冲突。比如让一个健硕的小伙子和一位天生腿部残疾的人赛跑，让他们自由竞争，结果怎么可能平等呢？那么为了平等，是不是要让竞争的优胜者，把赢得的奖品交出一部分来补贴失败者呢？但这是不是侵犯了优胜者的自由呢？<br>◆ 。 	在自由主义的发展中，确实出现了这样的变化。如果把我们熟悉的自由主义思想看成一个大家族，家族里辈分最高的，理应是17世纪英国思想家约翰•洛克所代表的自由主义，强调个人自由和基本权利，限制国家的干预，这被称为古典自由主义。而到了19世纪，约翰•密尔这一代人提出了所谓的现代自由主义，在坚持自由的同时非常重视平等的价值，也就特别关注社会正义和政治民主的问题。<br>◆ 再比如，最初的平等诉求主要是公民权利的平等，像是投票权和宗教自由的权利，后来就延伸到了经济和文化领域的平等。平等的范围一直扩张，自由主义就需要不断地面临新的挑战，不断做出新的回应。 	而且自由权利的内涵本身也在发展演变。比如今天有人主张，我们应该有权自由选择自己的性取向，甚至自己的性别。这恐怕是三百多年前的约翰•洛克做梦也想不到的自由问题。<br>◆ 在政治实践的历史上，自由主义被用来指称许多不同的治理体制：法国有过自由放任的“重农学派”，德国有过秩序自由主义，英国有过“福利国家”制度，美国有过强调国家干预的“罗斯福新政”。并且，在里根一撒切尔时代，英美两国都出现了新的放任自由主义。<br>◆ 自由主义思想确实像一个大家族，成员之间血统相近，但每个人又不太一样。<br>自由主义的家族特征<br>◆ 事实上，自由主义倡导一种特定的自由，是个人自由，特别重视保障个人权利，视其为优先甚至首要的价值。这可以作为这个家族的共同相似特点。<br>◆ 第一个维度是从空间上看地域差别的类型，主要是英美自由主义和欧洲大陆自由主义的传统，前者的代表人物是休谟和洛克，后者的代表人物是法国的卢梭和德国的康德。前者有很强的经验主义取向，强调免于强制的消极自由；后者有很强的理性主义取向，强调自我主导的积极自由。当然，这个说法是比较粗线条的。<br>◆ 我认为第二个维度更重要，它是从时间上看代际差别，你可以把它理解为自由主义家族不同辈分的特性。我们曾在前文提到，这个家族辈分最高的成员是17世纪英国思想家洛克，他强调个人自由和基本权利，主张国家最少干预，在政治上提倡宪政自由原则，被称为古典自由主义。后来到了19世纪，英国的约翰•密尔那一代，出现了所谓现代自由主义，他们非常注重社会公正和平等的价值，转向强调政治民主。<br>◆ 所以，现代自由主义的一个特点，就是必须认真对待平等问题，兼顾自由和平等这两种价值。伴随着现代转变，平等的自由权利带来更多样化的人生理想和生活方式。<br>现代的“三全其美”<br>◆ 当然，自由主义成为主流思想，不仅仅因为内部的多样性。更重要的原因是，西方社会很难找到另一个方案去替换它。这是因为，进入现代社会，人们追求普遍的自由平等，而在现代世界已经祛魅的大背景下，一旦有了普遍的自由平等，就一定会衍生出第三种诉求，那就是生活理想的多样化。<br>◆ 比如，激进主义可能更注重平等和多元，但很可能忽视了权利的自由；保守主义强调自由，但可能忽视了平等，也压制了多元性。相比之下，现代自由主义或许最有潜力来同时回应自由、平等和多元这三种诉求，兼顾三种价值。<br>33 | 罗尔斯 怎么才能实现社会正义<br>◆ 这一节我要向你介绍的人物约翰•罗尔斯，是20世纪最伟大的政治哲学家，甚至可以不加之一。美国前总统克林顿说，罗尔斯“几乎以一人之力，复活了政治和道德哲学”。<br>◆ 最著名的当然就是他在1971年发表的《正义论》。这本书正文开篇是这样一句话：“正义是社会制度的首要价值，正像真理是思想体系的首要价值一样。”<br>“无知之幕”遮蔽了什么<br>◆ 罗尔斯提出了一个天才性的构想。他化身成一个发明家，拿出一件神器，是一道大幕布，名字叫作“无知之幕”。 	这面无知之幕有什么神奇的功用？很简单，你站到无知之幕的后面，就看不见自己了。不仅看不见，而且遮蔽了你的一切个人特征，不管是种族、性别、身体素质，还是年龄、智力、家庭背景，或者职业、财产、宗教信仰，这些特征你全都忘记了。 	不过，你只是对自己的特点一无所知，其它方面完好无缺。你有正常的理性能力，也知道要对自己好，知道怎么盘算才对自己最有利。你也知道一个人要正常生活，需要哪些基本条件，了解衣食住行和文化政治生活的基本状况。简而言之，你只是忘记了“自己是谁”。 	好了，现在每个人都站到了无知之幕后面，罗尔斯把这个位置叫作“原初位置”。在这个位置上，你完全不知道自己的特殊性，大家处在绝对平等的地位，每个人都是理性自利的人，而且是完全自由的，你可以用一切最有效的办法来争取自身的利益。可以说，“原初位置”上那些绝对平等、彻底自由、完全自利的理性人，一起签订了一份契约。<br>如何理解正义二原则<br>◆ 在《正义论》这本书里，罗尔斯用详细而严密的推理，考虑了各种不同的选项，得出了契约的基本内容。他六万多字的论证，最后得出来的关键原则，主要就是两条。 	第一条原则叫作“平等的自由”原则，就是每个人都平等地享有一系列基本的自由，包括言论自由、信仰自由以及拥有个人财产的自由，等等。<br>◆ 这个原则是怎么得出来的呢？很简单，在无知之幕后面，大家最关心的事情，就是签订了这个契约之后，揭开了无知之幕，这个契约会不会让我活得很惨啊？因为你是理性而自利的人，最重要的计算就是规避风险，这就会淘汰许多选择。<br>◆ 总之，为了确保自己特定的生活目标和方式不会低人一等，无知之幕后的人都会同意要保障每个人平等的基本自由。这就是第一条“平等的自由”原则。<br>◆ 当然，有人这样认为：竞争的条件已经那么公平了，输了只能怪自己啊！罗尔斯不同意。他认为，造成社会不平等最深刻的原因，并不是自由竞争，而是人们的天赋差异，以及家庭背景和社会阶级地位的差异。把起跑线拉得再平，也无法消除天赋的差异。<br>◆ 比如你可能先天残疾，可能先天智力不高，也可能天性就不适应激烈的竞争，或者你的天赋才能可能是打猎，但你生错了时代，现代社会不需要靠打猎谋生……你看，你生活在什么时代，以及你有什么样的天赋因素，都是自己无法选择、无法控制的。<br>◆ 所以，罗尔斯认为，社会经济的不平等分配，还需要满足第二个限制条件。罗尔斯把它叫作“差异原则”，就是这种不平等，能够让处境最糟糕的人改善状况。也就是说，除非不平等的分配能使得最弱势群体的处境得到改善，否则，不平等在道德上就是不可接受的，是不公平的，也是无知之幕背后的人不会接受的。<br>◆ 因为不只是你，每个人都可能会成为最弱势的群体。在竞争中出现的优胜者，他们获得的优势如果能够改善最弱势者的处境，那么就是可以接受的。<br>◆ 到这里，我们来做一个总结：罗尔斯通过无知之幕的思想实验，推理论证了一个正义的社会契约中最关键的两条原则。第一条原则是要保障平等的基本自由，第二条原则是，社会经济的不平等分配，必须满足两个限定条件，一个是“公平的机会平等”，一个是要满足差异原则。<br>◆ 罗尔斯的正义理论中，有一个符合我们道德直觉的思想，就是应当尽可能排除那些偶然的和天生的运气因素对命运的影响。正因如此，我们才会把废除奴隶制和封建等级制，把克服种族主义和男权主义的历史过程看作通向公平正义的道德进步历史。<br>两种哲学风格<br>◆ 在学术风格上，他们两人的反差也很鲜明。罗尔斯是典型的刺猬型大师，一生专注于正义问题的研究。而诺齐克却像是一只活跃的狐狸，研究主题涉及广泛的哲学领域。他在哈佛教了30多年书，一门课从来不讲第二遍，只有一个例外。那门课非常精彩，名字叫“生活中最美好的事物”，探讨“友谊、爱情、智性的理解、性快乐、成就、历险、游玩、奢侈、名望、权力、启迪以及冰激凌”，也就是所有这些事物对于生命的意义和价值，因为这门课实在太受欢迎了，所以诺齐克讲过两次。<br>对罗尔斯的挑战<br>◆ 比如，罗尔斯说，一个人天生的优势完全是偶然的运气，不应该由此获得分配的优势，除非这种优势能让处境最差的人获得改善。诺齐克说，这岂不是把个人天赋当成了公共资源来分配吗？这样就侵犯了个人自由权，完全不可接受。<br>◆ 诺齐克举了个例子，你天生有两只明亮的眼睛，而我天生双目失明，那为了公平，你是不是应该捐一只眼睛给我呢？这听上去太恐怖了，显然不符合我们的道德直觉。<br>◆ 在诺齐克看来，罗尔斯在政治权利方面坚持了自由主义原则，让每个人享有基本自由，但在社会经济领域，却没有一以贯之地坚持这个原则，而是把平等分配当作默认选项，认为唯一可以接受的不平等的分配，必须满足两个限制条件（“公平的机会平等”原则和差异原则的限制）。所以，罗尔斯被称为“平等主义的自由主义者”——在政治和文化上坚持自由主义，但在社会和经济问题上采取了平等主义的立场，这在诺齐克看来是一种不够融贯自洽的理论所以只是半个自由主义者。<br>诺齐克的正义理论<br>◆ 他支持自由放任的资本主义，主要是出于道德的理由，因为它最充分地尊重和保障了个人基本权利，所以能造就一个最为正义的社会。<br>◆ 诺齐克讲的正义不是“分配的正义”，而是“持有的正义”。他认为，首先要考虑的不是如何分配，而是我们持有（holding）的东西。核心问题是，在什么条件下，我们持有的东西在道德上才是正当的呢？ 	围绕这个核心问题，诺齐克开始了自己的论证。<br>◆ 诺齐克的论证有一个出发点：我们最初能正当拥有的是什么呢？当然就是我们自己，诺齐克称之为“自我所有权”（right of self-ownership）。我们作为人，对自身的所有权是不可剥夺的，应当免于一切外部的侵犯和干涉，这理所当然是正义的（因此，所有奴隶制肯定都是不正义的）。自我所有权的正当性是诺齐克理论的前提。 	但仅仅拥有自己是活不下去的，我们还需要获得资源和财产。这里，诺齐克就提出了他的三项正义原则。<br>◆ 拥有财产的第一步是获得财产，所以第一条正义原则就是“获取正义”。就是你所持有的财产在起点上，也就是最初获取的时候必须是正当的。要么通过劳动占有了天然资源，比如“无主之地”，或者接受了别人自愿的馈赠，比如来自父母的遗产；反正是不能侵犯任何他人所有的财产，否则就失去了“获取正义”。<br>◆ 第二条原则是“转让正义”：如果财产从一个人转移到另一个人手里，整个过程没有巧取豪夺，是通过自由自愿的交换或者馈赠，那转让就是正当的。<br>◆ 诺齐克认为，如果整个社会的财产分布都满足这两项原则，那么这个社会就是正义的社会。 	不过你肯定也想到了，哪有这么理想的事，肯定会有违背两条原则的事情发生啊。对此，诺齐克提出了第三条原则，就是“矫正正义”。对那些通过不正当的方式得来的财产持有，不管经历了多少变化，都必须予以矫正。诺齐克相信，有了这三条原则，就可以评价所有关于财产持有的正义问题。<br>最小国家理论<br>◆ 2024/08/03发表想法<br>残疾人沿街乞讨是否捐助就可以评判一个人的正义观念。罗尔斯认为就应该给予一定补偿。而诺齐克认为他们是不幸的，但是不补偿不代表不正义。<br>原文：诺齐克认为，这种贫困肯定是不幸的，但不幸并不等于不正义。正如前面提到的那位表白被拒绝的男生，他痛不欲生的困境是不幸的，但应当予以补偿吗？万一他寻了短见，那更是悲剧；但我们应当谴责谁吗？<br>◆ 诺齐克认为，这种贫困肯定是不幸的，但不幸并不等于不正义。正如前面提到的那位表白被拒绝的男生，他痛不欲生的困境是不幸的，但应当予以补偿吗？万一他寻了短见，那更是悲剧；但我们应当谴责谁吗？<br>◆ 你也许要说，这会不会太冷酷了，难道穷人就不能得到救济吗？诺齐克会认为，只能依靠慈善救助，因为慈善完全出于自愿，满足转让正义的原则，你获得的捐助无论多少都是正当的持有。但你不能要求国家提供福利救济，因为国家本身不拥有财富，国家如果要提供福利，大多通过征税来实现社会财富的二次分配，但征税是强制的而不是自愿的，因此二次分配的“转移支付”无法满足“转让正义”原则。<br>两种不同的正义理论<br>◆ 总的来说，诺齐克的正义理论关注财产是怎么获得的，又是如何转移的，这是一种“历史正义”理论。只要财产的来路清白，无论多寡都是正义的，最后社会形成怎样的财富分布都是正当的。相比之下，罗尔斯的理论是一种“模式正义”理论，就是社会经济的分配必须满足某种结构模式。<br>◆ 诺齐克的持有正义理论和哈耶克的思想一样，成为“里根-撒切尔”时代新自由主义经济政策的理论资源，受到右翼保守派的偏爱，也因此而备受争议。<br>◆ 罗尔斯出生在一个典型的美国富裕家庭，但他的理论却特别注重平等，为弱势群体说话。而诺齐克出生在纽约的布鲁克林，是第二代俄罗斯移民，家境并不富裕，学生时代曾是激进的左派，还参与过社会主义的团体。直到在普林斯顿大学撰写博士论文的时期，他才第一次深入接触为资本主义辩护的观点，被深深吸引。但诺齐克在感情上却十分抵触，他对自己说，“那些观点是不错，资本主义是最好的体制，但只有坏人才这么想”。 	最终他的情感向理智做出了让步，从一名激进的左翼青年转变成为一位支持自由至上论的哲学家。<br>35 | 德沃金 什么样的平等才合理<br>◆ 在这一章的路标中，我提到过现代社会的一个发展趋势，就是平等的压力不断上升。平等一开始只是理想，理想落实为现实需要过程。<br>平等的难题<br>◆ 社会经济领域的平等是一道特别困难的考题。且不说实践的困难，就是在理论上，都还没有找到一个比较理想的规范原则。现有的每一个分配模式都有明显的缺陷。<br>◆ 你看，平等的问题就是“随便说说挺简单，仔细想想很困难”。实现一种平等，往往会损害另一种平等。那么，你究竟要哪一种平等呢？<br>◆ 德沃金的理论很复杂，但可以从一个非常朴素的问题开始，那就是，我们研究了这么多平等，但我们追求平等到底为了什么呢？他的答案也很朴素，就是为了对每个人好嘛！更确切地说，是要一视同仁地对每个人好。<br>◆ 怎么才能对每个人好呢？德沃金提出了两个原则：平等的尊重、平等的关怀。<br>平等的尊重<br>◆ 首先，要把每个人当作人。把人当人是什么意思？就是尊重每个人的自主性。德沃金说，我们要平等地尊重每个人自己选择的生活目标和方式。这就是他的第一条原则，“平等的尊重”。<br>◆ 人和人的生活方式不一样，有人每天读莎士比亚，听“得到”App上的课程，思考哲学问题。还有的人呢，下班之后就喜欢看连续剧，刷搞笑视频，一边喝着啤酒或奶茶，一边说“这才是生活的滋味啊”，把这种时刻当作最高的享受。<br>◆ 他认为，对于各种不同的生活理想和方式，只要本人自愿而且不伤害他人，那国家就不能干涉，也不应当偏袒，应该一视同仁，保持中立。这就是德沃金说的自由主义的“国家中立性原则”。<br>平等的关怀<br>◆ 因为尊重本身可以采取消极不干涉的方式。你完全可以对一个人说，我尊重你的选择，然后就再也不理他了。但德沃金认为，尊重还应该有更积极的方式。因为实现各种不同的生活理想，都需要一定的资源，那么公平的做法就应该是，为实现这些生活理想提供平等的资源，这就是他主张的另一个原则：“平等的关怀”。<br>◆ 2024/08/03发表想法<br>就像救灾<br>原文：所以德沃金认为，平等关怀的原则不是简单地给所有人“平等的待遇”（equal treatment），而是要把每个人“当作平等的人来对待"（treating is equals）。这就要考虑处境不同造成的不同需求。<br>◆ 所以德沃金认为，平等关怀的原则不是简单地给所有人“平等的待遇”（equal treatment），而是要把每个人“当作平等的人来对待"（treating is equals）。这就要考虑处境不同造成的不同需求。<br>敏于志向，钝于禀赋<br>◆ 德沃金指出了其中的区别，对于资源的需求，有些是出于自己的选择偏好，比如对鱼子酱的需求；而有些是环境所迫，比如对口罩的紧迫需求，这两种需求不能混为一谈。<br>◆ 所以，要实现“平等的关怀”，首先要识别哪些需求是自己不能选择的处境造成的，哪些是个人自愿选择的偏好造成的。对于前一种情况，应当弥补处境造成的差别，而对于后一种情况，应当接受选择造成的差异，让个人为自己的选择负责。你喜欢吃鱼子酱，那你自己花钱去买就好了。<br>◆ 他持有的观点和罗尔斯有相似之处。他们都认为，所有自己无法选择的偶然因素不应当影响一个人的命运。因为这些先天因素和外部环境因素都是偶然任意，说白了就是运气，无论是好运气还是坏运气，对你生活造成的后果，从道德角度看，都是你不应得的。<br>◆ 在德沃金看来，一个社会如果实现了“平等的尊重与关怀”，那么社会对个人的奖赏或惩罚，就应该是针对个人的选择，或者说个人的“志向”，而不是针对那些个人无法选择的天赋因素。换句话说，我们应该敏感地回应个人的志向，也应当尽可能排除天赋因素，也就是“迟钝地”对待个人禀赋造成。这个观点有一个很典雅的中文翻译，叫作“敏于志向，钝于禀赋”。<br>◆ 我们可以试着来总结德沃金的基本思路：在现代西方社会，公民的基本自由权受到宪法保障，这已经是根深蒂固的社会共识，无论是激进派、保守派还是自由派，在原则上都没有异议。对于自由主义来说，要去处理的最突出的问题就是，确立一种恰当的平等观。所以德沃金提出了“平等的尊重和关怀”原则，他相信，这就是“自由主义的平等观”，能够同时回应现代人对于自由、平等和多元价值的三种诉求。这是德沃金对于自由主义理论的重要贡献。<br>当代人要承担前辈的历史罪责吗<br>◆ “当代人不必为历史负责”这种说法，背后的依据是一种道德理论支持，叫作“道德个人主义”。因此，、我们必须深入这种道德理论的内部逻辑，才能展开有效的批评。<br>◆ 2024/08/03发表想法<br>我有点这种倾向<br>原文：道德个人主义的主张是什么呢？就是相信每个人作为道德主体，都是自由而独立的个体。每个人自主选择自己的目标，为自己选择的结果负责，也仅仅需要承担这种责任，不受任何超出个人选择的道德纽带约束。也就是说，个人道德责任的来源只是自己的自由选择，这和自己所属的群体、习俗、传统和历史等都没有关系。<br>◆ 道德个人主义的主张是什么呢？就是相信每个人作为道德主体，都是自由而独立的个体。每个人自主选择自己的目标，为自己选择的结果负责，也仅仅需要承担这种责任，不受任何超出个人选择的道德纽带约束。也就是说，个人道德责任的来源只是自己的自由选择，这和自己所属的群体、习俗、传统和历史等都没有关系。<br>批评自由主义的个人观<br>◆ 2024/08/03发表想法<br>自我并不是凭空产生的，在它产生的那一刻其自然附带了社会关系。<br>原文：但桑德尔认为，道德个人主义是错误的理论，因为它对“何为个人”的理解有误，又或者说，它所依据的“个人主义”观念是错误的。这是桑德尔对（包括罗尔斯理论在内的）自由主义的批判要点之一。<br>
<br>
在他看来，自由主义的基础是个人主义，是将单独的个体作为所有理论出发的原点：先有个人，个人之间签订契约，形成公共道德以及社会与政治的制度等，一切都从个体延伸展开。<br>
<br>
但桑德尔追问：个体究竟从何而来呢？这就好像把“蛋生鸡”的假设倒过来问了一句“蛋从哪里来的呢”？他认为，个人并不是先于社会存在的一个“原子”。作为个体的“自我”不是凭空产生的，而是在社会关系中被造就的，是被生活的共同体塑造而形成的。共同体的英文是“community”，这个词也常常被翻译为“社群”，可以指家庭、社区，或者学校和工作团体，也可以指民族、国家这种大的社群。<br>◆ 但桑德尔认为，道德个人主义是错误的理论，因为它对“何为个人”的理解有误，又或者说，它所依据的“个人主义”观念是错误的。这是桑德尔对（包括罗尔斯理论在内的）自由主义的批判要点之一。 	在他看来，自由主义的基础是个人主义，是将单独的个体作为所有理论出发的原点：先有个人，个人之间签订契约，形成公共道德以及社会与政治的制度等，一切都从个体延伸展开。 	但桑德尔追问：个体究竟从何而来呢？这就好像把“蛋生鸡”的假设倒过来问了一句“蛋从哪里来的呢”？他认为，个人并不是先于社会存在的一个“原子”。作为个体的“自我”不是凭空产生的，而是在社会关系中被造就的，是被生活的共同体塑造而形成的。共同体的英文是“community”，这个词也常常被翻译为“社群”，可以指家庭、社区，或者学校和工作团体，也可以指民族、国家这种大的社群。<br>◆ 在这里，桑德尔采取了一种不同的理论视野，就是“共同体主义”，也常常被翻译为“社群主义”（Communitarianism）。社群主义强调，“个人是社会构成的”，先有社群，社群造就了个体，而不是先有孤立的个人，然后再由个人组成社群。这对自由主义所依据的个人观念提出了挑战。<br>◆ 只有像这样讲通了自己的故事，你才能真正解释自己生活中的选择有什么“意义”。而当你面临多种不同的选项时，做出一个“有意义的选择”意味着什么呢？就是这个选择能够让你更好地、更连贯地讲明白自己的故事。但重要的是，你的故事是在社群关系中形成和展开的，也正因为如此，我们才能明白彼此的故事。所以，意义无法仅仅从个人的自由意志中产生。这就是社群主义的个人观。<br>◆ 2024/08/03发表想法<br>精美绝伦<br>原文：还记得罗尔斯的“无知之幕”吗？就是大家在无知之幕后面，会忘记自己所有的特殊性，一起来商议签订一个社会契约。桑德尔会说，无知之幕背后的人完全失去了自己的故事，是毫无个性的抽象的个人，所有的人都完全一样，其实就只是一个人，也就根本谈不上“一起商议”社会契约了。<br>◆ 还记得罗尔斯的“无知之幕”吗？就是大家在无知之幕后面，会忘记自己所有的特殊性，一起来商议签订一个社会契约。桑德尔会说，无知之幕背后的人完全失去了自己的故事，是毫无个性的抽象的个人，所有的人都完全一样，其实就只是一个人，也就根本谈不上“一起商议”社会契约了。<br>◆ 在桑德尔看来，自由主义的个人观，把个人看作是孤立的原子，完全凭借自己的自由意志来行动，他称之为“无所牵绊的个人”。他认为，这是对个人的错误理解。<br>批评自由主义的社会观<br>◆ 自由主义往往倾向于“工具性的社群观”，就是认为社群只有工具性的意义。比如，在诺齐克的理论中，国家唯一的功能就是保障个人权利，是个人追求自身福祉的工具。如果只是工具，那个人对国家就谈不上什么情感与忠诚。这就好像你不会说，我爱一把剪刀，我要忠于这把剪刀。<br>◆ 罗尔斯这样的自由主义者，可能比诺齐克要温和一些；他主张“情感性的社群观”，认为社会是一个合作互惠的体系，人们在合作中会产生善意和情感，建立共同的价值。但桑德尔认为，这种情感性的社群仍然没有真正的相互依赖，也就无法形成真正的团结。你想啊，恋人之间也有感情，但要分手还是会照样分手。<br>◆ 他认为，社群不只是工具，也不只是合作团体中的情感依赖。事实上，社群有一种纽带关系，它在根本上定义了“你是谁”，它塑造了你的身份认同、生活理想、道德感与责任意识。用桑德尔的术语说，这是“构成性的社群观”：社群是“构成性的”，社群实际上“构成”了你这个人。<br>◆ 个人当然会做出选择，但个人的目标并不是随意选择的，而是与社群紧密联系在一起。比如，作为中国人，你会更加看重对父母尽孝，你也会认同孟子说的“舍生而取义”。你还可能觉得，陶渊明诗中的生活理想也挺令人向往的。也正是在这种纽带关系中，你才具有归属感，才能完整地讲述你自己的故事。<br>◆ 这与道德个人主义所主张的义务相当不同。道德个人主义的义务是自愿同意签订契约而形成的义务，没有自愿同意就没有义务。但“作为社群成员的义务”不是你选择的结果，而是被社群所赋予的义务，是一种给定（given）的义务，它并不取决于个人的自愿同意。<br>◆ 没有自愿选择，也能带来责任和义务吗？其实你想想，你并没有选择自己的父母，但你是不是被施加了赡养父母的义务呢？这是你作为家庭这个社群成员的义务。同样，在国家这个共同体中，你继承了前辈的遗产，同时你也被施加了对于国家的特殊义务。<br>◆ 它的道德约束性源于社群主义的道德认知：你生而带有一种历史，你的生活故事是更为宏大的社会故事的一部分，也蕴含于无数他人的故事之中，包括历史上你的前辈的故事。隔断了这种联系，就割裂了你的存在。<br>◆ 2024/08/03发表想法<br>我觉得这跟社群形式的改变有关。原子化个人形式的出现是因为过去社群形式较为固定，能确切的与社群产生联系，而如今无论是无线电还是交通的发展让社群开始解体，人与人之间的接触开始变得越来越远。你可能接触的人是来自天涯海角的人，你和他本不在一个社群中，而这种社交关系需要建立在一种相对个人的关系上建立。需要遵从着一套自由平等的关系对待彼此。<br>原文：在和桑德尔交谈的最后，我还向他提出了一个问题：如果社群对个人的塑造如此深刻，那么，当下流行的那种“原子化个人观”又是从哪里来的呢？不也应当是社群造就的吗？为什么社群生活会塑造出这样一种脱离社群的个人观念呢？我并没有从桑德尔那里获得满意的回答，但我想把这个提问作为本小节的思考题留给你。<br>◆ 在和桑德尔交谈的最后，我还向他提出了一个问题：如果社群对个人的塑造如此深刻，那么，当下流行的那种“原子化个人观”又是从哪里来的呢？不也应当是社群造就的吗？为什么社群生活会塑造出这样一种脱离社群的个人观念呢？我并没有从桑德尔那里获得满意的回答，但我想把这个提问作为本小节的思考题留给你。<br>个人主义是虚构的吗<br>◆ 那个困扰我很久的大问题，就是个人主义怎么可能会出现。 	不知道你想过没有，个人主义这个观念其实非常奇怪。它假设，先有单独的个体，个体组成了社会，社会又造就了国家。但这种想法明显违背历史事实，也不符合我们的经验感知。<br>◆ 在整个人类文明史上，从来就不存在单独生活的个体。每个人一出生，就生活在家庭、邻里、社区以及更大的共同体之中。<br>◆ 对每个人来说，群体当然是在个体之前就已经存在了，个人也总是在社会关系中成长的。所以社群主义的观点似乎才更符合现实，明明是社会构成了个人，而不是个人形成了社会。<br>◆ 如果社群主义的批评击中了要害，如果所谓“原子化的个人”观念根本是虚构的，却成为自由主义的基础，那么自由主义的整个理论大厦就是建立在不可靠的沙滩上，随时都可能轰然倒塌！ 	这个问题一直让我困惑不解。直到1994年，我读到了沃尔泽的那篇文章，才一下子豁然开朗。<br>相互矛盾的两种批评<br>◆ 针对理论的批判，我们已经有所了解了——自由主义的理论根本歪曲了现实世界中的个人，把人当作脱离了所有社会义务的存在，每个人都是自己生活唯一的创造者，没有任何尺度与共同标准来指导这种创造活动。但这是对人的虚构，不存在这种“无所牵绊的个体”。 	至于针对实践的批判，自由主义创造了自我中心的社会，这是一个“非社会性的社会”。社会只是一群孤立自我的聚集地，每个人都是理性的自利主义者，受到个人权利的保护，也因为各自主张自己的权利而分裂。这就是当代西方社会（尤其是美国）的现实：到处都是相互疏远的孤独个人，对公共和政治事务十分冷漠。<br>◆ 2024/08/03发表想法<br>个人虚构的，但是有人相信这种虚构，而相信是一种力量。就像小偷虽然在故事里，但是读了故事的人就会提防自己被偷。<br>原文：如果你相信自由主义的理论虚构了不存在的个人，那你就无法谈论虚构之人的任何实践后果。或者，如果你同意自由主义的实践是有害的，那你就必须首先承认它的个人理论真实地反映了现实。换句话说，你不能既批评这种原子化个人是虚构的，同时又批评这种虚构的个人实际上造成了有害的影响。<br>◆ 如果你相信自由主义的理论虚构了不存在的个人，那你就无法谈论虚构之人的任何实践后果。或者，如果你同意自由主义的实践是有害的，那你就必须首先承认它的个人理论真实地反映了现实。换句话说，你不能既批评这种原子化个人是虚构的，同时又批评这种虚构的个人实际上造成了有害的影响。<br>高度流动中“后社会的自我”<br>◆ 2024/08/03发表想法<br>与沃尔泽的想法不谋而合，社会已经变了，社群主义没有错。孤立的个人主义是当下这个新社会与陌生人接触的必要思想。是由社会本身的变化产生的。<br>原文：他认为，自由主义的理论真实反映了现实，所谓“孤立的自我”确实存在。他们并不是脱离社会的存在，而恰恰是被现在这个社会所塑造的结果。也就是说，个人确实是被社会塑造的，社群主义的这个观点没有错。但它的错误在于，没有看到现代社会已经改变了，正是这种新型的社会造就了“孤立的个体”。<br>◆ 他认为，自由主义的理论真实反映了现实，所谓“孤立的自我”确实存在。他们并不是脱离社会的存在，而恰恰是被现在这个社会所塑造的结果。也就是说，个人确实是被社会塑造的，社群主义的这个观点没有错。但它的错误在于，没有看到现代社会已经改变了，正是这种新型的社会造就了“孤立的个体”。<br>◆ 沃尔泽分析指出，高度的流动性主要体现在以下四个方面。<br>◆ 首先是“地理上的流动”。<br>◆ 其次是“社会身份的流动”。人<br>◆ 再次是“婚姻关系的流动”。<br>◆ 最后是“政治上的流动”。<br>脆弱的自愿联合<br>◆ 在高度流动的现代社会中，社群还存在吗？人们还有社群关系吗？当然存在，但主要的类型改变了，沃尔泽把它叫作“自愿型的社群”。它和传统社群的最大差别在于它是一种“自愿的联合”，你可以把“自愿”理解为可以决裂或退出的权利。<br>◆ 2024/08/03发表想法<br>我感觉我产生强烈孤独感的原因就是因为孤立的个人主义。<br>原文：新型的社群也是如此。比如，你参加一个马拉松俱乐部，参加一个公益环保组织，参加一个读书会……这些都会构成你的社群关系，都会塑造你的身份认同或者归属感，但它们都是你自愿加入的，你也可以自愿地退出。<br>◆ 新型的社群也是如此。比如，你参加一个马拉松俱乐部，参加一个公益环保组织，参加一个读书会……这些都会构成你的社群关系，都会塑造你的身份认同或者归属感，但它们都是你自愿加入的，你也可以自愿地退出。<br>◆ 但沃尔泽指出，并没有两全其美的事情，自由总是有代价的。因为越是容易获得和改变的关系，就是越不稳定的关系。原因未必是现代人总喜欢改变主意，更重要的是整个社会都在高度流动。比如，你很喜欢自己参加的那个马拉松俱乐部，但因为你要搬家到另一个城市，就不得不退出。如果其他人也有自己的原因放弃了，那俱乐部就只好解散。<br>◆ 现代社会永远都处于运动之中，沃尔在把这种特征称作“后社会的状况”（post-social condition）。<br>◆ 从这个角度来分析，那种孤立的、近乎原子化的自我，就并不是自由主义虚构出来的“先于社会的自我”（pre-socid self）观念，而是“后社会状况”造就的。沃尔泽称之为“后社会的自我”（post-social self）观念。这种自我观念反映了自由流动社会的现实，它从根本上失去了确定性和统一性，个人不得不随时重新创造自己。<br>◆ 正是在这个意义上，沃尔泽说“社群主义不可能战胜自由主义”。但与此同时，自由流动社会造成的忧伤、失落和孤独，以及政治冷漠等后果也会如影随形。所以，社群主义对自由主义的批判不会消失，它注定会周期性地出现。<br>38 | 泰勒 如何“成为你自己”<br>◆ 但在高度流动的现代社会，个人总是可以脱离任何一个特定的地方性社群。这并不会让你变成一个完全孤立的原子，因为你总可以进入新的社群，各种自愿型的社群。你会发现，真正“血肉相连”的，只是你和你自己。于是，那种无法分离、“血肉相连”的有机共同体就此成为一个过时的神话。<br>◆ 所以在我看来，从集体主义到个人主义的转向，并不是东西文明的差别，而是古今之变所致。<br>唯我论的诱惑<br>◆ “盲人摸象”的故事，大家应该都听过。可是小时候听到这个寓言，我就觉得它是“道理很正确，编得很离谱”。 	你想过没有，现实中的盲人会犯那种“以偏概全”的错误吗？根本不会。盲人很清楚自己在视力上的缺陷，根本不会那么自大，只摸到一条象腿就说这是整头大象。他们了解自己的局限，也就很少会犯这种“以偏概全”的错误。 	实际上，恰恰是那些自以为能看清一切的明眼人才最容易犯这种错误。<br>◆ 但只有在一个问题上，几乎每个人都非常自信，认为对于这个问题，只有自己才独具慧眼，看得比别人都更清楚。这个问题是什么呢？就是每个人对自己的认识。 	绝大多数人都相信：还有谁比我更了解自己、更懂得自己呢？当然是我本人。认为只有自己才对自己具有绝对解释权，这种观点叫作“唯我论”，常常和“个人自主性”联系在一起。<br>◆ 但是泰勒认为，如果仅仅从消极自由的角度来理解个人自主性，就可能陷入“唯我论”的盲区，会带来很糟糕的后果。<br>现代性的两难困境<br>◆ 自主性意味着我们能够自由地选择和决定自己的生活。可是，你如何做出选择呢？尼采和萨特都告诉过你了，选择没有什么标准。你选择，你负责，这就是一切，其它没有什么好说的。<br>◆ 可是，没有客观标准的选择可能会错，结果可能会让自己不满甚至痛苦。这样一来，自由就变成了一个太过沉重的个人负担。于是，有人平庸无聊，有人失落迷茫，也有人孤独无助……这些都不是他人的评判，不是外在的感受，而是我们自己能够真切感受的困苦。这样的精神困境在现代社会相当普遍。<br>◆ 个人自由带来的病症是真实的，但威权式的精英主义的解药可能是毒药。这让人陷入左右为难的困境，现代人不能放弃自由，但却不知道如何解决自由带来的问题。<br>本真性的理想<br>◆ 泰勒就此提出了两个主张。首先，他不完全认可保守主义的立场。泰勒认为必须坚持个人自主性，也相信伯林主张的消极自由不可忽视。其次，泰勒想要比自己的老师往前多走一步。他要去探索，除了坚持消极自由、主张“我的地盘我做主”之外，我们还需要做些什么，去应对自由产生的问题，更好地实现自主性的理想。<br>拯救本真性的理想<br>◆ 2024/08/04发表想法<br>仅依据自己的内心难以创造生活的价值和意义。<br>原文：泰勒认为，消极自由只是本真性的必要条件，但不是充分条件。不能把本真性与消极自由画等号。他指出，自由主义的观点存在一个盲区，就是把本真性强调的“忠实于自己”等同于“唯我论”的主张。只要依据自己的内心，就足以创造出生活的价值和意义。于是，外部世界要么是多余的，要么是“自我实现”的障碍或敌人。但这恰恰是唯我论的盲区。<br>◆ 泰勒认为，消极自由只是本真性的必要条件，但不是充分条件。不能把本真性与消极自由画等号。他指出，自由主义的观点存在一个盲区，就是把本真性强调的“忠实于自己”等同于“唯我论”的主张。只要依据自己的内心，就足以创造出生活的价值和意义。于是，外部世界要么是多余的，要么是“自我实现”的障碍或敌人。但这恰恰是唯我论的盲区。<br>◆ 我对自我同一性的发现，并不意味着我独自创造了它。<br>◆ 我们的“自我”是从哪里来的？我们的道德和价值标准又来自何处呢？泰勒的回答是：来自我们和他人的对话，以及对话中的反思。我们无法单单依靠自己来构成自我，形成有意义的独特性标准。自我的理想是在对话关系和反思中塑造的。<br>◆ 泰勒举了一个例子：有个人宣称自己非常独特，因为他的头发正好是3732根！谁会赞叹这种独特性吗？不会的，这反而会让人觉得可笑。因为这种“独特性”完全不足挂齿。相反，一个人如果有钢琴演奏才华，或者能表达深刻的哲学思想，或者总是真诚友善地待人接物……那么我们会认为这些独特性是有价值的。 	为什么这两种“独特性”会让人感到这么大的差别呢？泰勒解释说，一件事情是否重要、是否有意义，需要依据一个背景框架来衡量。这个背景框架，定义了在人类活动最基本的方面，什么是重要的、什么是有意义的，并塑造了我们的“道德与精神的直觉”。 	你觉得待人友善是特别好的品质，这并不是你内心凭空产生的衡量标准，而是来自你在与他人的交往中感知到的背景框架。<br>◆ 2024/08/04发表想法<br>这里跟我想的一致，我们生活在同一个框架，所以能够相互理解。<br>原文：可是这个框架由不得我们选择，它是“给定的”，是我们共享的“无可逃离的地平线”。我们所做的选择，在最根本的意义上，恰恰要依据这个作为深度意义的背景框架。因为我们的生活是共同的生活，这个背景是我们共同生活的前提。如果离开了这个框架，个人的感觉、选择和决定会变得完全不可理喻。<br>◆ 可是这个框架由不得我们选择，它是“给定的”，是我们共享的“无可逃离的地平线”。我们所做的选择，在最根本的意义上，恰恰要依据这个作为深度意义的背景框架。因为我们的生活是共同的生活，这个背景是我们共同生活的前提。如果离开了这个框架，个人的感觉、选择和决定会变得完全不可理喻。<br>如何“成为你自己”<br>◆ 现代社会有一种很流行的看法，认为事物的价值是主观的，是“自我”赋予的。我珍视或看重某种事物，不是因为它本身内在固有的价值或意义，而恰恰是因为我看重它、珍视它，它才变得有价值。 	但是，这种价值主观论可以成立吗？你可以问问自己：“你为什么会珍视或看重它？”你当然可以回答说，“我认为”“我相信”“我感觉”或者“我决定”。 	但这类回应完全没有回答“为什么”。如果你进一步去追问来龙去脉，只要你认真给出理由来回答，那么就会显示，那个单独的“自我”实际上并没有独自赋予或创造价值。<br>◆ 那些看似“自我赋予”的价值和意义，实际上仍然是有渊源和来路的，是由许多经历和故事造就的，也是在社会生活的关系中形成的。<br>◆ 自由选择和价值判断需要依据价值尺度，而价值尺度不可能由“自我”来发明创造，我们只能“选用”和“改造”价值尺度，这正是泰勒的社群主义观点带来的启发：个人自主性的来源不可能是“唯我论”的独白，而只能来自关系性的对话。<br>◆ 2024/08/04发表想法<br>这里让我十分感动，我迷茫了很久，价值真空的许久之后的想法就是慢慢在向我们生活的背景寻找意义。<br>原文：在祛魅之后的现代世界，我们好像失去了任何标准，但泰勒告诉我们，意义和价值的标准依然存在，就存在于我们生活的共同背景之中。<br>
<br>
但现代和古代不一样，这个共同背景并不是一套清晰固定的规则或公式化教条，而是一种资源。它有着丰富的多样性，为意义和价值的选择标准提供了资源；它并没有机械地决定我们具体的生活理想和选择。正因如此，个人的选择仍然必要，对话和反思才有意义。<br>◆ 在祛魅之后的现代世界，我们好像失去了任何标准，但泰勒告诉我们，意义和价值的标准依然存在，就存在于我们生活的共同背景之中。 	但现代和古代不一样，这个共同背景并不是一套清晰固定的规则或公式化教条，而是一种资源。它有着丰富的多样性，为意义和价值的选择标准提供了资源；它并没有机械地决定我们具体的生活理想和选择。正因如此，个人的选择仍然必要，对话和反思才有意义。<br>韦伯难题<br>◆ 哈贝马斯心有不甘。他认为，在人生信仰和生活理想方面，百花齐放是好事，但如果这种多样性瓦解了公共生活的客观性原则，现代社会的道德和政治生活就失去了共同规范，那会怎么样呢？ 	没有规范的冲突是什么？就是弱肉强食、成王败寇的野蛮。 	没有规范的妥协是什么？就是迫不得已的让步。 	没有规范的宽容是什么？就是“井水不犯河水”的回避，或者“大人不见小人怪”的恩赐。 	这样下去，就会威胁到社会的正义和人的尊严。难道我们只能指望这样的公共生活吗？<br>在人间：主体间的交往行动<br>◆ 韦伯难题之所以困难，就是因为公共生活的规范性原则失去了共同依据：你不再可能诉诸高于人类的神秘存在，因为世界已经祛魅；你也无法依靠人本身，因为每个人各有主观的判断标准。<br>◆ 不能靠天，也不能靠人，那么希望在哪里？哈贝马斯说，这个希望不在天，也不在人，而是“在人间”！<br>◆ 公共生活的规范性原则为什么难以确立？就是因为许多时候人与人的想法无法达成一致，甚至不可调和。但哈贝马斯没止步于此，他继续追问：那为什么不可调和呢？因为人是主体，每个人都“主体性”，如果只讲人的主体性，就难免会变得主观。 	但是，在现实生活真是如此吗？我们都是靠自己的主体性面对世界的吗？ 	哈贝马斯发现，人不只是一个主体；我们生活在人间，通过和他人交往，继而展开社会生活。<br>◆ 如果人类所有的活动都发生在人与人之间，那么主体与主体之间就会形成一种关系，哈贝马斯称之为“主体间性”（inter-subjectivity）。<br>◆ 因为我们说话。我们无论做什么，劳动工作，娱乐游戏，亲密恋爱……所有这些活动的共同点是什么呢？就是彼此之间说话交谈，可以用有声语言、文字、手语、符号以及身体语言等交谈。人类是语言的动物，所以人不是独白的存在，而是在人间交往对话的存在。语言交流，互相交往是我们所有行动的共同基础。<br>交往理性的作用与条件<br>◆ 哈贝马斯认为，好好说话这件事本身有很深的道理。这不只是解决矛盾的调解机制，他从中发现了一种理性的类型，这种理性既不是工具理性，也不是主体性的价值理性，而是存在于人与人之间交往中的理性，哈贝马斯称之为“交往理性”。<br>◆ 那么，这副解药能有什么疗效呢？哈贝马斯发现，“交往理性”，也就是好好说话这件事，其实是我们生活中规范性共识的源头。<br>◆ 这样的例子有很多。你常常会发现：在很多情况下我们和别人达成共识，并不是某个人的“道理”振振有词，说得我们都哑口无言，而是因为在好好说话的氛围下，出于彼此的信任和平等尊重，大家一起把道理讲通了。<br>◆ 这包括两个方面。首先是“言谈的有效性”，需要四个条件：可理解、真实、正当和真诚。你可以用这四项“有效陈述”的标准来检查一下自己平时的谈话。<br>交往理性是乌托邦吗<br>◆ 交往理性也是如此。理想的交往行动在现实中非常罕见，但有了哈贝马斯确立的标准，我们能够更清晰地分辨谁在好好说话、谁更讲道理，以及在日常交往中如何改进自己的言谈行为。<br>◆ 2024/08/04发表想法<br>哈贝马斯本质上提出了一种解决办法，因为韦伯提出价值理性无法判断好坏，陷入价值真空。交往理性表示价值理性的价值观是由社会经历得来的，并不完全生发于内，那么既然在外，在人间，不同的价值就有一个可以说服或者互相理解的标准。通过人与人的交流能否解决这种价值矛盾。<br>原文：只要你知道韦伯命题的意义，你就会理解哈贝马斯的贡献有多重要。哈贝马斯认为，工具理性有自己适用的领域，在技术、经济活动和官僚体制中有不可替代的作用，他把这个领域称作“系统”。但人类活动在“系统”之外还有一块是精神生活、道德生活和政治生活的领域，哈贝马斯称之为“生活世界”。<br>
<br>
韦伯非常担忧工具理性的无限扩张，哈贝马斯也格外重视这个问题。他认为如果“生活世界”的规范原则仅仅屈从于工具理性，那就是“系统对生活世界的殖民”。而交往理性为我们的生活世界确立了理性规范的原则基础，以此能够抵御“系统的殖民”。这关乎我们的自由、尊严、爱和正义。<br>◆ 只要你知道韦伯命题的意义，你就会理解哈贝马斯的贡献有多重要。哈贝马斯认为，工具理性有自己适用的领域，在技术、经济活动和官僚体制中有不可替代的作用，他把这个领域称作“系统”。但人类活动在“系统”之外还有一块是精神生活、道德生活和政治生活的领域，哈贝马斯称之为“生活世界”。 	韦伯非常担忧工具理性的无限扩张，哈贝马斯也格外重视这个问题。他认为如果“生活世界”的规范原则仅仅屈从于工具理性，那就是“系统对生活世界的殖民”。而交往理性为我们的生活世界确立了理性规范的原则基础，以此能够抵御“系统的殖民”。这关乎我们的自由、尊严、爱和正义。<br>◆ 哈贝马斯并不是“为问题设定了一个理想的答案”，而是指出了“我们有一种讨论问题的理想方式”<br>“历史终结论”与“文明冲突论”<br>◆ 福山在冷战的末期提出了“历史终结论”。他的观点用最简单的方式来概括就是，西方的自由民主政治是最好的制度选项，历史发展到这一步就抵达了终点，在这之后不管发生什么，意识形态的竞争已经结束。他的文章发表两年之后，苏联解体了，西方赢得了冷战。“历史终结论”成为这种胜利的理论解释，福山也被视为先知般的思想人物。<br>◆ “文明冲突论”的要点是什么？最简单的概括就是，世界上有七种主要的文明类型，西方文明只是其中的一种，还有中华文明、印度文明、伊斯兰文明等。亨廷顿认为，在意识形态的冲突结束之后，“文明之间的冲突”会成为世界冲突的主要形态。“文明冲突论”最早发表在1993年，2001年的“9·11”事件发生后，它也被看作对历史发展的准确预言。<br>“制度”与“文化”之争<br>◆ 福山认为，政治上的自由民主制和经济上的市场资本主义是现代的政治经济制度，并不专属于任何特定的文化。它们只是因为起源于西方，就被误以为是西方特有的制度。但实际上，这种制度选择，虽然会受到文化因素的影响，但文化并不是决定性的。福山相信，这种制度在本质上是现代化的结果，而现代化是全人类发展的普遍逻辑<br>◆ 但亨廷顿不同意，他认为福山低估了制度对于文化和宗教传统的依赖。在他看来，自由民主政治和市场资本主义都高度依赖于西方文明，尤其是民主政治，它是基督教文化的特定产物。所以，非西方文明很难接受西方文明的制度，日本只是一个例外。<br>“正在进行时”的问题<br>◆ 他们的分歧在于，福山认为世界各国的制度会趋同，变得大同小异。而亨廷顿主张冲突不会结束，只是改换了类型，转变为文明之间的冲突。<br>历史哲学的论证<br>◆ 马克思告诉我们，历史有一个普遍的规律，这个规律可以解释所有的历史事件。历史有自己发展的过程和方向，会从低级阶段走向高级阶段，最终在全世界实现共产主义。这是马克思主义的历史观，学术名称是“普遍历史观”。<br>◆ 这就要讨论福山和马克思的观点在第二个方面的区别，就是关于“什么是历史发展的动力”。马克思说，阶级斗争是历史发展的动力。而福山认为，根本的动力是“为承认而斗争”。<br>◆ 在福山看来，人生在世有一种根本需求，就是“获得承认”，要求别人承认自己作为人的尊严和价值。人类对于承认的需要绝不亚于对经济的需求，要不然怎么会说“不为五斗米折腰”呢？因为如果你“折腰了”，你就失去了尊严，没有获得承认。但赐予你“五斗米”的那个人却因此获得了你的承认。所以，人们获得承认的过程总是蕴含着斗争。<br>争议和批评<br>◆ 2024/08/04发表想法<br>我认为这是美国的经济操控导致的被动民主化<br>原文：但到后来，韩国等东亚地区开始了民主化转型，就打破了这种例外论。<br>◆ 但到后来，韩国等东亚地区开始了民主化转型，就打破了这种例外论。<br>来自中国的挑战<br>◆ 他至今仍然没有放弃他的一个核心观点：自由主义民主体制之外的现代化模式，迟早会面临民主化的压力，会遭遇巨大的挑战而难以长期维系。在这个意义上，他表示“就长远来说”，自由民主政体具有难以抗拒的优势，仍然会在曲折发展中越来越盛行。<br>42 | 亨廷顿 “文明的冲突”是不可避免的吗<br>◆ 2024/08/04发表想法<br>这只是美国保持美元霸权的反噬，但这可能成为文明冲突的起源。<br>原文：当时《华盛顿邮报》的记者问他，“现在你是不是感觉自己得到了证明？亨廷顿断然回答，“不，我感到愤怒和惊恐！恐怖分子并不代表伊斯兰文明，这不是一场真正的文明的冲突”。但他补充说，这有可能导致一场真正的文明冲突。<br>◆ 当时《华盛顿邮报》的记者问他，“现在你是不是感觉自己得到了证明？亨廷顿断然回答，“不，我感到愤怒和惊恐！恐怖分子并不代表伊斯兰文明，这不是一场真正的文明的冲突”。但他补充说，这有可能导致一场真正的文明冲突。<br>当代世界的认知地图<br>◆ “文明冲突论”，最简单的概括就是，一张地图和一个警告。亨廷顿先画了一张新的世界地图，叫作世界“文明圈”地图，然后发出了一个警告，告诫西方注意防守，避免扩张，不要去推广那些普遍性的价值。<br>◆ 亨廷顿将世界划分为七个主要“文明圈”：西方文明、拉丁美洲文明、东正教文明、印度文明、中华文明、日本文明和伊斯兰文明。还有非洲，它有可能成为第八个文明。<br>理解文明的冲突<br>◆ 但是，他不同意福山的最后一个推论——经济发展会导致文化和政治制度的趋同。亨廷顿坚持主张，一个文明的核心价值几乎是不可改变的。比如，西方的自由、平等、个人主义、民主等价值，都是基督教文明的产物，并不是普遍性的价值。你要是认为这些东西人人都喜欢，要推广到其它文明并改变其核心价值，就会激起人们的反感和抵抗。<br>◆ 再次，他认为当今世界西方文明在相对的衰落，美国不再可能成为全球的霸主，虽然以美国为核心的西方文明仍然重要，但中华文明圈的力量随着经济发展正在增长。所以，西方再也不可能让其它文明“西方化”，必须放弃这种幻想。<br>◆ 总的来说，亨廷顿是一个政治现实主义者，他认为文明差异不可消除，冲突不可根除，只能管控；世界秩序只能建立在多种文明共存的基础之上。<br>国家内部：“精神内战”？<br>◆ 21世纪新一波的全球化造成了一条深刻的“断层线”。这条断层线不是出现在国家与国家之间，而是出现在每个国家的内部，出现在全球化的受益者和因为全球化而受挫的人群之间。<br>◆ 政治学家最近几年发现，欧美国家出现了“民主衰退”，这在过去都是在那些刚刚完成民主转型的国家才会发生的事情。到了现在，哪怕在西方国家内部，自由主义的故事也越来越难讲通了。<br>汇聚还是分离<br>◆ 人类的未来究竟会怎样？中国古话说，“天下大势，分久必合合久必分”。但这种看法，就好像在一场旅途中只是关注眼下的路面。如果我们抬起头，观察更多长远而缓慢发生作用的变量，你就会明白赫拉利在《人类简史》中说的一句话：“合久必分只是一时，分久必合才是不变的大趋势。”<br>补充讲解<br>◆ 你看，思考人生，探索终极价值、终极关怀和意义，这样的问题伴随着我们一生，是一件非常幸运而有趣的事情。如果没有这样一个“难不倒”、也做不完的题目，人生会是多么乏味啊。 	在这个意义上，我们一面铭记苏格拉底的教诲，“未经反省的人生是不值得过的”（The unexamined life is not worth living），另一面也不要陷入“过度省察的人生”（over-examined life）。<br>◆ 我自己20岁左右的时候有一个“执念”，觉得对于生命的终极目标，必须先有一个正确可靠的答案，才能开始真正的生活，否则就是虚度生命。其实不然，我们的人生都是“边想边做”的，而且想和做是分不开的。<br>◆ 美国哲学家麦金泰尔说过，“美好的人生就是一生都在追求美好人生的人生”。<br>◆ 第二，对于人生意义的问题，什么样的回答算是一个“回答”呢？其实，真正的回答不必（其实是不能，也不应该）采取一种哲学的、理论的或体系学说的形态。我们每个人的思考和心得，更可能表达为一个叙事（narrative），是不断讲述一个关于自己的故事。<br>]]></description><link>culture\阅读\刘擎西方现代思想讲义.html</link><guid isPermaLink="false">Culture/阅读/刘擎西方现代思想讲义.md</guid><pubDate>Mon, 09 Sep 2024 11:48:13 GMT</pubDate></item><item><title><![CDATA[让儿童与世界美好相遇———基于海德格尔“本源之思”的教育美学诠释]]></title><description><![CDATA[ 
 <br><br>《让儿童与世界美好相遇——基...“本源之思”的教育美学诠释_王鑫》<br>CNKI<br>
66个笔记<br>第1章<br>◆ 从本源意义来看，教育担负着尊重、发现、彰显生命存在的重要责任。但人们却在追求更高远教育目标的途中混淆了“存在”与“存在者”二者的关系<br>◆ 诚如海德格尔所主张的“回到生命本身”​，教育的本源即指向儿童与世界相遇的生命发生过程。相遇性的世界并非面向被观看的对象，而是以一种浑然的置身性与儿童共同构成“活的事件”​。教育中的本源性相遇意味着构建起教育世界与生活世界的连续性，也意味着直面教育生活的多重可能。<br>◆ 海德格尔的“本源之思”启示教育工作者思考教育的本源。教育的本源意义蕴含着尊重、发现、彰显生命存在之美的重要责任。然而，现行教育却与这种本源意蕴渐渐疏远，它在变得强大、确定、科学和可预测的同时，也变得急躁、焦虑和不安。人们在不断追寻更高、更强、更完美教育目标的途中，逐渐迷失了来时的方向与初衷。<br>◆ 海德格尔在《存在与时间》的扉页引用了柏拉图《智者篇》中的一句话：​“当你们用到‘是’或‘存在’这样的词，显然你们早就很熟悉这些词的意思，不过，虽然我们也曾以为自己是懂得的，现在却感到困惑不安。​”<br>◆ 相比之下，人们似乎更愿意将目光投在那些确定的、现成的、可预测的、易把握的“存在者”身上，而想方设法地规避世界所有的不确定性和风险性。他们习惯了栖居于自己制造出来的、由确定的存在者构成的“坚固大厦”​，却忽视了存在的根本意义。对教育来说，忽视存在是极其危险的。从教育的存在来看，教育所面对的是人的存在和成长，发展人在世界之中存在的可能性是教育不能回避的初衷。忽视存在，意味着教育忘却本源和本心，也意味着教育中的人的失落。<br>◆ “存在”是一个不容忽视的教育问题。在教育现实中，人的存在逐渐让位于一些直观确定的分数、排名、指标、重点、荣誉等存在者，以致于教育过程与结果都成为一种可预设和可计算的东西。由于这种“确定”通常只是暂时的，​“人便会感到一种摆脱不了的焦虑，而这种焦虑，会啮蚀人的一切努力”［３］。例如，近几年国内涌现的“鸡娃”养育模式便是“存在者争夺战”与教育焦虑形成恶性循环的真实写照。<br>◆ 鸡娃”并非一种全新教育现象，而是教育焦虑酝酿出的新称谓，它是整个教育系统浮躁、短视、逐利的反映，其根本在于对儿童存在的忽视。事实上，就“学习”活动本身而言，分数、答案、排名、荣誉等都不过是一些短暂的获得，它们都将随着时间的流逝不复存在，而真正留下的是对自身存在的体悟、对世界的理解以及筹划人生可能的本领，它们能够帮助儿童有勇气地做出选择、迈向未来、为自己负责。<br>◆ 雅斯贝尔斯在《什么是教育》中说道：​“一切教育的关键在于教学内容的选择，以及将学生引向事物本源的方式。​”［４］也就是说，教育的关键在于“教什么”和“怎么教”的问题。它们与儿童在教育中的生存状态息息相关。<br>◆ 海德格尔在诠释“本源”之义时也引入了“本质”概念。他说道：​“本源一词在此指的是，一个事物从何而来，通过什么它是其所是并且如其所是。某个东西如其所是地是什么，我们称之为它的本质。某个东西的本源就是它的本质之源。​”<br>◆ 如此说来，​“教育的本质”即指向“教育是什么”的问题，而“教育的本源”便在于追问教育的本质之源，即对“教育是什么”的追溯与还原。在国内，教育的本源与本质时常被混为一谈。大部分学者热衷于“教育是什么”的讨论，却遗忘了“教育何以可能”的本体追问。<br>◆ 例如，二十世纪八九十年代，曾涌现了“教育即生产力”​“教育即上层建筑”​“教育即传递”​“教育即社会化过程”​“教育即建构”等观点，以及“多重属性说”​。其中，有的观点来自哲学或社会学理论，有的与国家政策息息相关，有的则从社会现实问题出发。但大部分说法是非本源的，因为它们往往把“教育当成一种外在或超然于人的实践活动的客观事实，视为一 种 摆 在 人 们眼 前、可 以 用 理 性 或 概 念 的 方 式 予 以 静 观的 已 定 对象”［７］，甚至试图用一种外在目的框定教育。<br>◆ 教育的唯一目的（内在目的）便在于其自身———教育作为促进人的发展的活动。<br>◆ 教育的本源便是面向人最质朴的发展过程。<br>◆ 当前，也流行着“儿童幸福”​“人的发展”​“精神关怀”​“生命成长”等教育本源的阐释，但大多汇于一处：​“教育只有一个主题，那就是五彩缤纷的生活”［９］。从本源来看，​“不断发展，不断生长，就是生活”［８］５８，教育就是不断生长。海德格尔对本源的思考更进一步，他将“本源”作为一种现象学式的还原———回溯到主客尚未分化的“前理论领域”​。诚如胡塞尔现象学是“回到事实本身”​，海德格尔现象学则是“回到生命本身”​，即向生命在世界之中存在的本然面貌溯源。他将“生命之存在”诉诸“此在”​（Ｄａｓｅｉｎ）———一个未成型的、始终面向可能性筹划自身的开放者。<br>◆ 儿童看待世界的方式不同于成人，他们与世界的联系更为紧密。儿童很少将自己作为旁观者，而总以亲历者的身份保持着对自身乃至万事万物的好奇和追问。世界之中的一切对儿童来说都充满意义。这大概就是海德格尔所说的生命与世界的“相遇”模样<br>◆ 相遇性的世界不再是被认识、被给予的对象，而是达成了一种“天地与我并生，万物与我为一”​（​《庄子·齐物论》​）的存在样态<br>◆ 马丁·布伯有相似观点。他说，​“凡真实的人生皆是相遇”<br>◆ “我－你”关系的核心，它意味着一种共生共长的美好境遇。教育的本源乃是一种相遇。教育旨在帮助儿童敞开自己、领悟自己和成为自己。教育中的本源性相遇意味着构建起教育世界与生活世界的连续性，也意味着直面教育生活的多重可能。<br>◆ 相遇性的世界并非面向被观看的对象，而是以一种浑然的置身性与儿童共同构成“活的事件”​。因为“作为什么相遇”和“如何相遇”并非以一种凝固的具体形象现身，而是以一种特定的意指方式涌现，海德格尔称其为“意蕴状态”​。例如，当一个人遇到美丽的花园，第一反应通常是“花朵好美丽”​“景色好舒心”​“心情好明媚”等意义，而很少像说明文一样梳理“里面几种花”​“花有几种颜色”​“花是什么科”等内容。儿童往往生活在“意蕴世界”之中，他们首先建立起自我与世界的联系，而不是对象之物的规律或原理。因此，儿童时常表现出对世界的感同身受：小草会疼、花儿会哭、太阳会笑、星星会眨眼……所以，教育需要经历双向转化的过程：从抽象概念、原理、体系等向相遇性世界的转化，再从生活世界返回教育世界。教育者承担着建构教育世界与生活世界的连续性的重要任务，特别是向儿童还原教育世界的现实依据和生动形象。<br>◆ 就教育而言，风险与惊喜同等重要：没有经历困顿和落寞，儿童很难具备面向未来、做出选择和为自己负责的勇气；没有经历收获和喜悦，儿童也无法生成打开自己、热爱生命、拥抱世界的渴望。<br>◆ 让教育变强、使教育安全、使教育可预测和使教育免除风险的要求就是这种急躁的一种表达。​”［１３］１０但是，试图构建一种百毒不侵的教育的想法却建立在对教育本源的根本误解之上，即用“存在者”代替“存在”​。这注定了以追求升学率、高分率为目的的“快教育”模式不能胜任长远的教育发展需求。<br>◆ 儿童与世界相遇的三种情景———相遇自己、相遇万物与相遇他者，为现代教育的发展提供了“领会自身”的教育旨趣、​“面向操劳”的教育方式、​“共在共长”的教育关系等新的生长点。<br>◆ 海德格尔认为，此在总是“从‘世界’方面来领会本己的存在”［１］１９。人在相遇世界的同时，也在相遇自身。通俗地讲，人总是从他的生存活动本身来理解自己并成为自己。人总是在“周围世界”之中相遇自身。<br>◆ 这就好比一个从小生活在城市中的孩子到了农村后分不清韭菜和麦苗。所以，人与世界的相遇无形中也确证了自己的存在。<br>◆ 儿童与世界存在着一种相互生成的审美样式的关系。对儿童来说，世界是伟大的，与世界相遇的时时处处都闪烁着意义的光芒。然而，教育者却时常抛却伟大，用一种渺小的眼光注视着教育：过度倾向于“有价值”​（功利性）​，而忽视儿童在世生活对“有意义”的需求。儿童长期沉沦于被技术化手段控制的“真空世界”​，失去了从世界方面领会自身的多种可能，从而依据“真空世界”的反光解释自身，不可避免地陷入以功利为目的的存在者的游戏。<br>◆ 接受自己的不完美、直面自己的人生、对自己负责、成为自己都是领会自身的重要议题。<br>◆ 诚如海德格尔笔下的“被抛状态”​，儿童注定要面临在世存在的悲欢离合、喜怒哀乐。但就儿童而言，与世界相遇的每一步都是成长。美国存在主义教育的代表人物莫里斯曾说，​“不管我们愿意或者不愿意，我们是处在作选择与负责之下。即使我们不肯选择，这依然是一种选择，依然是一种表现我们要自己生命为我们说话的征象。​”<br>◆ 儿童与世界的每一次相遇都是选择，而每一次选择都交织着期待的实现，并向不期而遇敞开。正是在不断选择、接受与负责中，儿童才慢慢成长，最终成为自己。<br>◆ 对儿童来说，领会自身是困难的。一种萎靡的儿童生长状态正在流行：那种“初生牛犊不怕虎”的好奇、生机和勇气逐渐变得稀薄，取而代之的是一种畏首畏尾、无精打采的沉沉暮气。这大概就是所谓的“过犹不及”​。教育的过度保护不仅降低了儿童承受风险的能力，也消磨了儿童对生活的热爱与好奇，更使儿童缺乏对自身的领会。教育者应树立一种伟大的眼光———对儿童的存在方式保持一种敬畏。教育要切近儿童，首先要求建立起教育与儿童的周围世界的联系。这并不意味着对学科、课程、教材的颠覆，而是基于儿童与世界的相遇特征，将抽象的概念、特征、原则或规律向更贴近儿童的周围世界还原。其次，教育者不应全盘掩盖世界中的不完美现象，而应在可控范围内为儿童提供相遇世界可能的风险与困窘，以帮助儿童领悟真实的自己、成为有担当的自己。特别需要强调，挫折教育在当前背景下是必要且急切的，其对于实现儿童对自身的领悟具有深刻意义。<br>◆ 海德格尔表示，世界之内存在的东西大致有两种状态：一是“在手状态”​，即一种静观的现成之物的呈现，如一辆停放在路边的自行车；二是“上手状态”​，即人使用、操作物的事件状态，如我骑着自行车，我与车一同融入切身相遇的“活的事件”​。从<br>◆ 操劳并非指向单纯“做”的行为，其蕴含着更深层次的体验、言说、沉思与建构。例如，小小的婴儿喜欢将目之所及的东西抓在手里、塞在嘴里或不厌其烦地扔掉再捡起。儿童不断把玩物品的过程，是物得以显现的过程，也是世界被勾连和构建的过程。<br>◆ “器物上手论”实际上探讨了人与万物的关系问题。卢梭在《爱弥儿》中也曾谈及人与自然万物的关系。他区分了“物的隶属”和“人的隶属”​：物属于自然范畴，受自然规律的规约；人属于社会范畴，受法律和道德的约束。<br>◆ 但其本质并不相同：卢梭重在强调外在于儿童的自然秩序以及顺从自然秩序的教育；海德格尔则强调内化于儿童生命的世界本源状态———儿童与万物彼此融合、相偎相依、互相成就的相遇过程。<br>◆ 教育应当确保儿童与世界相遇的必要操劳。相较于“在手”的观看，操劳对知识的具化和强化更为深刻。近些年，教育界兴起了一些“实地化教育”［１８］的尝试，如研学旅行、劳动基地项目、综合实践活动等，它们都是操劳切入教育的具体表现。<br>◆ 但却容易陷入两个误区：一是所示图片通常为教师依据自身经历而选择，可能与儿童的周围世界有所疏远；二是将“观察”等同于“观看”​，忽视丈量、测试、触摸、计算等观察可能。<br>◆ 相比之下，​“面向操劳”的教育方式会拉近儿童与物的关系。​“面向操劳”​，并不意味着花费大量时间让儿童开展操作性任务，而是为儿童提供一个主动、自愿地融入学习的机会，其往往涉及儿童的眼睛、嘴巴、<br>◆ “此在的世界是共同世界。​”［１］１３８与他人共同存在是海德格尔生存论的构成因素。海德格尔的“共在”与主体间性哲学有着某种亲缘性，它们均源于一种对主观主义的反思。从某些意义上说，​“共在”就是一种主体间性理论，它以一种生存论的“此在”为根本。人活着的过程不可避免地总有他人“在场”​。这并不是说预先具有一个主体性的此在来打量、审视他者，而是“我”与“他”的相遇。​“他”不是自我之外的整体的余数，而是自我的复制品，是在我们之中、与我本身并无差别的人。<br>◆ 海德格尔的“共在”不是一个静止画面，其可能存在相互扶持、相互反对、相互怂恿、陌如路人、互不相关等不同的操持方式。​“共在”是人在世生存的一种必然，但发展怎样的“共在”关系则是一种智慧的选择。​“共在”关系是儿童社会性发展的重要体现。<br>◆ 他们构建了儿童与教师、儿童与儿童两对教育关系。在“共在”中，自我与他者是对称的、平等的交互关系，其典型特征便是双方可以互换位置。然而，在教育实践中，儿童与教师却很少同时“出场”​。师生关系往往维持一种单向度的给予或寄托，甚至出现一种双向的疏离。师生关系常被“教育者”与“受教育者”的责任关系所捆绑：人们容易深陷责任的控制，不假思索地将教育确定为教师的责任，提出“没有教不会的学生，只有不会教的教师”的教育口号，且对这种不对称、单向度的责任关系深信不疑。​“趋向他人的方式在于我对他或她的责任，这无理由的责任类似于人质的状态，一直走向他者，不需要互惠。​”<br>◆ 教师以自我为中心预设和把持教育教学活动，直接给予学生抽象的知识内容和学习框架，而忽视学生的操劳状态和自我表达，使学生极易陷入一种漂浮不定的游离状态。由于教师在这对关系中找不到成就感，儿童也找不到归属感，久而久之他们便会各自远离。<br>◆ 海德格尔还提出了“表率”概念，它指为他人生存的能在做出表率。倘若教师和学生能够为彼此的生存做出表率，这便是教育界常说的“教学相长”​。它实际指向教师与学生共同形成的相互促进、共在共长的交互性过程。<br>◆ 由于同伴关系对学习的影响是间接的，且条例、守则等对它的约束力十分有限，故学校教育对建设良好同伴关系所采取的教育行动寥寥可数。但同伴关系又是教育不能逾越的话题，它对儿童的心理健康影响巨大。不少儿童因为同伴关系的不当处理出现抑郁倾向，甚至酿成伤害、自残、自杀等极端事件。而且，同伴关系所产生的影响往往具有持续性，它常常是改变人生轨迹的重要因素。相较于培养一个高分的儿童，教育更应培养一个健康的儿童。教育者应引导一种共在共长的同伴关系，使其成为儿童开展学习活动的基础和动力。<br>◆ 诚如教育的本源是儿童与世界的相遇，教育之美的本源要义便在于促成儿童与世界的 美 好 相 遇。海 德格 尔 认 为，​“美 是 作 为 无 蔽 的 真 理 的 一 种现 身 方式。​”<br>◆ 无蔽真理”将教育引向一种现象学式的行动———壮丽的生命的整体展开，而非局部的、断裂的“感受”或“经验”的堆积。儿童与世界美好相遇的教育行动实质上是一种回归：使儿童重回大地。这种本源的回归或许稍显笨拙，但也是直接的、热烈的、美好的。教育者作为教育世界的转译者，要还原教育世界与生活世界的联系，让儿童在相遇中体验、思考和创造教育之美，使生命不息、学习不止、教育延绵。<br>◆ 海德格尔有两种对“体验”的论述：一种是他反对的，即传统美学意义上指向感性知觉的“体验”​，乃至从“活的体验”中被提取出来的孤立的、分裂的、客观化的对象；另一种是他认同和向往的，​“就体验乞灵于本己之物而生命只是如此存活而言，体验乃是发生事件<br>◆ ，​“生命以自身为动因，并且具有趋向性；动因化的趋向，趋向性的动因：生命的基本特征，向着某个东西的生活，进入特定的体验世界活出世界。​”<br>◆ 关于体验的认识，杜威有相似看法。杜威虽并未站在存在论的一端，但其设法超越主观主义和客观主义的对立，他坚信经验 ①是一个不可分割的整体（不承认主观与客观、动作与材料之间有何区别）​。他在《经验与自然》中写道：​“‘经验’指开垦过的土地，种下的种子，收获的成果以及日夜、春秋、干湿、冷热等等变化，这些为人们所观察、畏惧、渴望的东西；它也指这个种植和收割、工作和欣快、希望、畏惧、计划、求助于魔术或化学、垂头丧气或欢欣鼓舞的人。​”<br>◆ 对杜威来说，世界的意义并不在于事物本身，而是在事物、动作、姿势、声音发挥作用的实践经历之中。<br>◆ 说到底，海德格尔和杜威都承认一种“活的体验”​，它蕴含着人与世界相遇的动态意蕴———演绎“生命如何存在”的故事<br>◆ “活的体验”意味着儿童从事学习活动的真切性，其指向教育活动与儿童生活之间的动态连续性。​“教育”诞生之初曾与人的生活保持着直接、密切的联系，如人类始祖以狩猎、采摘等生存体验为主要教育内容。文明的发展使人类生活经验大幅膨胀，故教育活动开始归类、简化和分科。长期的分科教育淡漠了学科之间及其与生活的联系，导致人们更加关注学科内部的东西。以考试为主要手段的教育评价制度无疑使学科知识与儿童生活的联系乃至不同学习阶段的知识之间的联系变得更为疏远。<br>◆ 还原儿童的“活的体验”的教育行动旨在恢复教育世界与生活世界之间的动态连续性，主要包含两方面：一是建构学科知识与日常生活的动态连续性（保证生活体验的活性）​；二是建构不同学习阶段的学习生活的动态连续性（保证教育体验的活性）​。其中，教师是建构、成全两种连续性的主要行动者。<br>◆ 纪录片《他乡的童年》①中曾提到一种“现象式学习”模式（芬兰教育）​，与还原儿童的“活的体验”的思路十分契合。其中，有个情境令笔者印象深刻：教师将课堂带到儿童熟悉的森林中，并给予他们一些形容词（如恶心的、可爱的、丑陋的、美丽的等）​，让孩子们在森林里自行寻找与形容词相符合的东西。很快，孩子们带着“战利品”回来了，有个小男孩拿着一坨黏糊糊、透明的类似于真菌的东西，说它是恶心的；有个小女孩拿着一根彩色的鸟类羽毛，说它是美丽的；还有的拿了一块黑漆漆的树皮，说它是丑陋的……这种教学方式在知识与生活世界、自我意识之间建立起了一种连续性和交互性，使世界在儿童生命中得到活生生地展现。<br>◆ 目前，虽有不少学校在倡导“大单元”教学意识，但相较于年级、学段，单元仅作为一个极小的部分，不同年级与学段间学习活动的断裂仍相当显著。由于我国不同学段教师的培养与培训均是分开的，不同学段教师之间对彼此的课程体系并不了解，他们通常只是守着自己的“一亩三分地”​。很少有教师会提及某个知识点在之后将得到怎样的深化，或者追溯、串联某个知识点的前阶内容。这无疑导致一个恶性循环。不同阶段的学习生活的动态连续性是必要的，它需要教育者明确学科整体知识体系以及不同知识点之间的联系。教育者要有意识地向学生传达学习体验之间的联系，以便学生能够自如地构建知识网络，减少或避免认知混乱。<br>◆ 教育者应从本源上把握教育，摆脱以“存在者”为目的的浅表化竞争，构建教育活动与生活世界的联系，还原儿童的“活的体验”​，让儿童与世界美好相遇。<br>◆ “思”是海德格尔通往存在的重要路径，恰如巴门尼德的箴言———“思想与存在同一”​。​“思”不是目的，而是一种生活方式、一种走近人的本质的方式。<br>◆ 荷尔德林的 道 说，​“思 想 最 深 刻 者，热 爱 生 机盎 然”​（​《苏 格 拉 底 和 阿 西 比 亚 德斯》​）​。​“思”是人与世界美好相遇的基础。​“思”曾经占据人的生活，至少曾是古希腊人的日常生活方式；而今，​“思”却是贫困的，思想建树和文化创新上的淡漠与荒凉成为现代生活的通病，​“术”的精致和“思”的匮乏形成了强烈对比。<br>◆ 于是，很多人将“思的希冀”寄托于教育，将培养运思能力作为教育的重要任务。殊不知，儿童的运思能力从来都不是培养出来的，因为他们并不是全然无“思”的。<br>◆ 然而，随着儿童的成长，儿童的“思”被越来越多伦理、秩序所带来的恐惧感和羞耻感所挟持。例如，在初中阶段，教师会明显地感受到不同年级之间课堂互动的差异：刚入学的学生更愿意思考、回答或质疑教师所提出的问题，但过一段时间后学生便会用低头、俯身、趴桌等动作极力地回避与教师的思维碰撞或眼神交流。<br>◆ “教育的重点，在于先释放学生身上的压抑，让他恢复童年时的好奇，让他想学，其次是给他问题去想，让他看到方向。​”<br>◆ “面向思的教育是一种苏格拉底式的‘哲学的腐化’。​”［２６］从根本上看，苏格拉底的“产婆术”奠定了一种运思勇气。他在讨论或教学之时从不以智者自居，常赋予自己一个“无知之人”的头衔，以此向他人请教。从忘记一切学问、技艺开始，这本身就是对弟子的运思勇气的守护，是一种教育智慧的体现。教育者应成为儿童成长的启发者，不仅要善于抓住儿童的好奇心和兴趣点，赋予他们更多展示自我、提出质疑的机会；更要正视儿童的回答与提问，决不能敷衍和忽视，也不能直接赋予对错、真假、好坏的判断，而应帮助儿童勾连课程、学科与生活世界，使儿童将对生活的好奇转变为学习探究，以奠定“思”的可能。<br>◆ 提及“诗”​，人们常常想到文学、优美的文字、不切实际的幻想或玩物丧志的矫情。海德 格 尔 的 诠 释则 有 所 不 同，他 认 为 “诗 的 本 质 是 真 理 之创 建 （Ｓｔｉｆ－［２７］，其指向一种美的想象和创造，即诗意置造。<br>◆ ：​“具有诗意的梦想能赋予我们所有的世界中最美好的世界。​”<br>◆ 儿童无疑是最伟大的诗人，充满童真、童趣的想象与创造就是儿童最美丽的诗篇。造型奇异的涂鸦、充满趣味的游戏、天方夜谭的梦想等都是儿童诗意置造的重要体现，是儿童思维、情感、想象与创造的结晶。<br>◆ 不仅如此，儿童的诗意置造被当作不务正业的例子比比皆是。成人对教育的理解时常陷入一种功利化歧误，即指向分数、名次、荣誉等存在者的获得。故他们极易产生一种标签化的刻板印象（好学生与坏学生）​，而忽视儿童的想象力和创造力。例如，印度电影《地球上的星星》中的小伊夏就是一个典型案例。小伊夏是一个具有读写困难障碍的特殊儿童，他常常因为无法理解书本中的世界做出令老师和家长都十分恼火的事情，故“坏孩子”的标签在他身上贴得异常牢固。尽管他拥有超乎常人的想象力和创造力，并喜欢用画笔画下他热爱的美妙世界，但由于“坏学生”的标签，很少有人注意到他的独特之处，甚至把他的诗意置造当作不堪造就的标志。小伊夏是幸运的，因为他遇到了一个欣赏、鼓励他进行诗意置造的老师。最终他用充满想象力和创造力的绘画作品征服了大家。然而，现实之中又有多少个尚处于迷茫之中的“小伊夏”​。<br>◆ 也为课堂注入了欢声笑语。儿童的想象力和创造力是无限的，他们总会在意想不到的地方给出惊喜。当然，儿童的诗意置造可能是五花八门、形态各异的。因为每个儿童都有自己擅长和不擅长的东西。这需要教育者有一双善于观察和发现的眼睛：学会尊重、欣赏和鼓励儿童的诗意置造。有时，来自教师一句话、一个点头、一个眼神的肯定，可能是儿童生命里为数不多的光。<br>◆ 教育研究永远处在一个不断遮蔽和解蔽的过程中。总之，让教育从当下出发，面向本源，面向儿童的存在，让儿童与世界美好相遇。<br>-- 来自微信读书<br>]]></description><link>culture\阅读\让儿童与世界美好相遇———基于海德格尔“本源之思”的教育美学诠释.html</link><guid isPermaLink="false">Culture/阅读/让儿童与世界美好相遇———基于海德格尔“本源之思”的教育美学诠释.md</guid><pubDate>Mon, 02 Dec 2024 14:19:38 GMT</pubDate></item><item><title><![CDATA[人类简史]]></title><description><![CDATA[ 
 <br><br>《人类简史：从动物到上帝》<br>尤瓦尔·赫拉利<br>
227个笔记<br>序言 《人类简史》出版10周年<br>◆ 人类以想象来建构大规模秩序这一独特的能力现在开始转向对我们不利。<br>◆ 有没有办法创造一个并非基于民族国家，或自由市场，或个人主权，或驾驭自然的想象建构的新全球秩序呢？<br>◆ 不错，这些文字是这里一点那里一点拼凑起来的杂烩。可天下文章难道不都是这样吗？我写《人类简史》时，也阅览了许多书籍、文章和访谈录，把不同的思想和事实合并起来写成新的东西。<br>◆ 10年后，人工智能革命席卷世界。这场革命标志着我们所知的人类历史的完结。数万年来，人类发明了各种工具，使人类的力量更加强大。斧头、轮子和原子弹给了人类新的力量。人工智能却不同。有史以来第一次，力量可能会脱离人类之手。<br>◆ 以前的所有工具都使人类更强大，因为人懂得工具，而工具不懂得人。一个农夫知道一把斧头能做什么，但斧头不明白农夫的需要和感觉。很快，人工智能就能比我们更加了解我们自己。它是会继续做我们手中的工具，还是我们会成为它的工具呢？<br>◆ 童话故事里，一条神奇的金鱼或一个无所不能的精灵答应满足人的3个愿望时，通常都没有好结果。人所求的都是错的，因为他们不知道自己的苦难或幸福的真正来源。若想比童话故事里那些笨拙的人得到更好的结局，就需要知道作为人的意义。我们是谁？我们从哪里来？<br>◆ 我在书中表达的中心意思丝毫没有改变：对智人最好的描述是，他是会讲故事的动物。我们创作出了关于神、国家和公司的虚构故事，而这些故事构成了我们社会的基础和我们生活意义的源泉。为了这些故事，我们经常不惜杀人或者被杀。在黑猩猩、狼或任何其他有智能的社会性物种中，都看不到这种行为。<br>◆ 英国和德国实现了和平，不是因为它们的领土增加了（其实两国的领土比1914年时少了许多），而是因为现在它们有了一个大部分英国人和德国人都相信的共同的故事。<br>◆ 几千年前佛陀就说过，人世乃梦幻泡影。的确，国家、神祇、公司、金钱、意识形态——都是我们创造并相信的集体幻影，人类历史就是由它们统治的。在人工智能时代，我们相信的故事比以前更加重要，因为我们有了追求幻想的更强大的技术。<br>◆ 古人想象天堂和地狱时，他们的幻想深深地影响着他们的行为。他们打仗、杀死所谓的异教徒、不吃某种食物、禁止某些性行为，因为他们认为这样能够上天堂。可是，他们只能把天堂推迟到想象中的来生。在21世纪，至少有些人会忍不住使用人工智能、生物工程学和其他革命性技术来试着在今世实现自己的幻想。如果我们不谨慎地选择自己所相信的东西，很可能会被幼稚的乌托邦幻想误导，陷入技术地狱之中无路可退。<br>◆ 我们真正需要明白的是人的头脑以及头脑产生并相信的幻想。这是诗人、哲学家和史学家的任务，现如今这个任务比任何时候都更加紧迫。<br>◆ 2024/04/19发表想法<br>所以纳瓦尔说的很有道理，宏观经济的影响因素太多，根本没办法把所有人想象成绝对理性。宏观层面的变化往往是难以预测的。<br>原文：今天，塑造你命运的有北京领导人的政治决定，有旧金山工程师的技术发明，也有印度工厂的生态影响。要想了解你的未来，你需要了解整个世界的历史和全人类面临的挑战。我写此书，是想帮人们更清楚地看世界，让每个人都有能力参加我们时代最重要的辩论。<br>◆ 今天，塑造你命运的有北京领导人的政治决定，有旧金山工程师的技术发明，也有印度工厂的生态影响。要想了解你的未来，你需要了解整个世界的历史和全人类面临的挑战。我写此书，是想帮人们更清楚地看世界，让每个人都有能力参加我们时代最重要的辩论。<br>◆ 我们生活在由和我们非常不同的人在我们出生很久以前发明的思想牢狱之中。<br>第一章 人类：一种也没什么特别的动物<br>◆ 这本书，讲述的就是这三大革命如何改变了人类和其他生物。<br>◆ 此外，由于人类出生的时候尚未发育完全，比起其他动物，也就更能够用教育和社会化的方式加以改变。<br>第三章 亚当和夏娃的一天<br>◆ 泛灵论者认为，人类和其他的灵之间并没有障碍，可以直接通过言语、歌曲、舞蹈和仪式来沟通。<br>◆ 此外，就像人类和其他灵之间没有障碍一样，人类和其他灵之间也没有地位高下之别。非人类的灵之所以存在，不只是要为人提供协助，它们也不是什么把全世界操之在手的万能的神。这个世界不是为了人或是任何其他特定的灵而旋转。<br>◆ 采集社会可能有许多不同的宗教和社会结构，可以预测他们也同样有不同的暴力倾向。可能在某些时期，某些地区一片平静祥和，但在其他地区却是动乱不断。<br>◆ 这幅沉默的帷幕就这样罩住了几万年的历史。在这些年间，可能有战争和革命，有灵性激昂的宗教运动，有深刻的哲学理论，有无与伦比的艺术杰作。采集者之中可能也出过像成吉思汗这种所向披靡的人物，不过统治的帝国还没有新加坡的面积大；或许也出过天才贝多芬，虽然没有交响乐团，却能用竹笛令人潸然泪下；又或许出了像穆罕默德一样的先知，不过传达的是当地某棵栎树的话，而不是什么全宇宙的造物主。不过，这些我们全部只能靠猜测。这幅沉默的帷幕如此厚重，我们连这些事情是否曾经发生都难以断定，遑论详细描述。<br>◆ 整个动物界从古至今，最重要也最具破坏性的力量，就是这群四处游荡、讲着故事的智人。<br>第四章 毁天灭地的人类洪水<br>◆ 我们现在常常把很多事情都推给气候，但事实是地球的气候从来不会静止，而是每分每刻不断变化，史上不管哪个事件，都多少会碰上一些气候变迁的情形。<br>◆ 平均每10万年就有一次冰河期，上一次冰河期大约是75000年前到15000年前<br>◆ 类似澳大利亚这种生物大灭绝的事情，在接下来的几千年还不断上演，而时间点都是在人类又再次移居外面世界的时候。<br>第五章 史上最大骗局<br>◆ 于是，种种想让生活变得轻松的努力，反而给人带来无穷的麻烦；而且这可不是史上的最后一次。就算今天，仍然如此。有多少年轻的大学毕业生投身大企业、从事各种劳心劳力的工作，发誓要努力赚钱，好在35岁就退休，去从事他们真正有兴趣的事业？但等他们到了35岁，却发现自己背着巨额贷款，要付子女的学费，要养在高级住宅区的豪宅，每家得有两部车，而且觉得生活里不能没有高级红酒和去国外的假期。他们该怎么做？他们会放下一切，回去野外采果子挖树根吗？当然不可能，而是加倍努力，继续把自己累得半死。<br>◆ 这个关于奢侈生活陷阱的故事，告诉我们一个重要的教训。人类一心追求更轻松的生活，于是释放出一股巨大的力量，改变了世界的面貌，但结果并没有任何人料想得到，甚至也不是任何人所乐见的。并没有人在背后操纵农业革命发生，或者意图让人依赖谷类为生。一开始只是各种小事，主要就是希望吃饱一点、生活安全一点，但最后累积引起的效应，就是让远古的采集者开始花上整天的时间，在烈日之下挑水务农。<br>◆ 浮士德跟魔鬼交易，人类则跟谷类交易。<br>◆ 然而，如果从牛羊的观点而非牧者的观点来看农业革命，就会发现对绝大多数的家畜来说，这是一场可怕的灾难。这些演化的“成功”是没有意义的。<br>◆ 我们从农业革命能学到的最重要一课，很可能就是物种演化上的成功并不代表个体的幸福。<br>◆ 每当人类整体的能力大幅增加、看来似乎大获成功的时候，个人的苦痛也总是随之增长。<br>第六章 盖起金字塔<br>◆ 农业革命可能是史上最具争议的事件。有些人认为这让人类迈向繁荣和进步，也有人认为这条路终将导致灭亡。对后者来说，农业革命是个转折点，让智人抛下了与自然紧紧相连的共生关系，大步走向贪婪，自外于这个世界<br>◆ 远古狩猎采集者的活动范围可能有几十甚至上百平方公里。当时这片范围都是他们的“家”，有山丘、溪流、树林，还有开阔的天空。但对农民而言，几乎整天就是在一小片田地或果园里工作，<br>◆ 一般来说，农民就会和房屋这种构造建立起非常强烈的连接。这场革命意义深远，除了影响建筑，更影响了心理。在农业革命之后，人类成了远比过去更以自我为中心的生物，与“自己家”紧密相连，但与周遭其他物种画出界线。<br>◆ 从农业开始发展到现在，人类的家园得面对勤劳的蚂蚁、鬼鬼祟祟的蟑螂、冒险犯难的蜘蛛还有误入歧途的甲虫，于是数十亿人口也就武装起来，用树枝、苍蝇拍、鞋子和杀虫剂，迎向这场永不停止的战争。<br>◆ 人类发现自己已经很难离开这些人工岛屿了，所有的房子、田地、谷仓，放弃哪个都可能带来重大的损失。此外，随着时间过去，他们拥有的东西越来越多，不易搬运，也把他们绑得死死的。<br>◆ 农业带来的压力影响深远，这正是后代大规模政治和社会制度的基础。但可悲的是，虽然农民勤劳不懈、希望能够保障自己未来的经济安全，但这几乎从来未曾实现。不管在任何地方，都出现了统治者和精英阶级，不仅靠着农民辛苦种出的食粮为生，还几乎全征收抢光，只留给农民勉强可过活的数量。正是这些征收来的多余食粮，养活了政治、战争、艺术和哲学，建起了宫殿、堡垒、纪念碑和庙宇。<br>◆ 他们生产出来的多余食粮养活了一小撮的精英分子：国王、官员、战士、牧师、艺术家和思想家，但历史写的几乎全是这些人的故事。于是，历史只告诉了我们极少数的人在做些什么，而其他绝大多数人的生活就是不停挑水耕田。<br>◆ 第一个是大约在公元前1776年的《汉谟拉比法典》，这可以说是几十万古巴比伦人的合作手册；第二个是公元1776年的美国《独立宣言》<br>◆ 我们认为下面这些真理是不言而喻的：人人生而平等，造物者赋予他们若干不可剥夺的权利，其中包括生命权、自由权和追求幸福的权利。<br>◆ 现在已经过了超过两百年，但美国学童仍然要抄写、背诵这份宣言。<br>◆ 不管是汉谟拉比还是美国的开国元勋，心中都有个想象的现实，想象着这个世界有着放诸四海皆准、永恒不变的正义原则（例如平等或阶级），但这种不变的原则其实只存在于智人丰富的想象力里，只存在于他们创造并告诉彼此的虚构故事中。这些原则，从来就没有客观的正确性。<br>◆ 听到要把人分成“上等人”或“平民”，大概都会同意这只是一种想象。但其实，即使说的是“人人平等”，也只是虚构的概念。到底所谓人人平等是什么？除了想象中之外，有没有什么客观的事实可以说我们人人平等？人类彼此在生物学上都相等吗？<br>◆ 演化的基础是差异，而不是平等。每个人身上带的基因码都有些许不同，而且从出生以后就接受着不同的环境影响，发展出不同的特质，导致不同的生存概率。“生而平等”其实该是“演化各有不同”。<br>◆ 生命权、自由权和追求幸福的权利”其实只是“生命和追求快感”。<br>◆ 但也别忘了，汉谟拉比也可以用同样的逻辑来捍卫他的阶级原则：“我知道所谓上等人、平民和奴隶在本质上其实并没有什么不同。但如果我们这么相信，就能创造出一个稳定繁荣的社会。”<br>◆ 2024/05/04发表想法<br>法西斯不就是一种控制军队的信念吗<br>原文：。很多时候，一名牧师的效果大过一百个士兵，而且更便宜、更有效。此外，不管刺刀多有效，总得有人来刺。如果士兵、狱卒、法官和警察根本不相信某个想象建构的秩序，他们又怎么会照办？在所有的人类集体活动中，最难组织推动的就是暴力活动。如果说社会秩序是由武力来维持，立刻就会碰上一个问题：那军队秩序是由什么来维持？想靠威胁来维持军队组织显然不太可行。至少必须有某些军官和某些士兵真正相信某些事情，不管是上帝、荣誉、祖国、男子气概，或者单纯相信金钱也成。<br>◆ 。很多时候，一名牧师的效果大过一百个士兵，而且更便宜、更有效。此外，不管刺刀多有效，总得有人来刺。如果士兵、狱卒、法官和警察根本不相信某个想象建构的秩序，他们又怎么会照办？在所有的人类集体活动中，最难组织推动的就是暴力活动。如果说社会秩序是由武力来维持，立刻就会碰上一个问题：那军队秩序是由什么来维持？想靠威胁来维持军队组织显然不太可行。至少必须有某些军官和某些士兵真正相信某些事情，不管是上帝、荣誉、祖国、男子气概，或者单纯相信金钱也成。<br>◆ 而满足基本需求之后，多余的钱就可以用来盖金字塔、到世界各地度假、资助竞选活动、提供资金给你最爱的恐怖组织或投入股市再赚更多的钱，但对真正的犬儒主义者来说，这一切贪婪的事都毫无意义。创立犬儒学派的希腊哲学家第欧根尼(Diogenes)，就住在一个桶里。<br>◆ 正因如此，犬儒主义者不可能建立起帝国，而且如果人们希望某个由想象建构出的秩序能维持久远，大部分的人（特别是大部分的精英分子）就必须真正相信它。<br>◆ 如果不是大多数中国人都相信仁义礼智信，儒家思想绝不可能持续了2000多年。如果不是大多数的美国总统和国会议员都相信人权，美国的民主也不可能持续了250年。<br>◆ 如果不是广大的投资人和银行家都相信资本主义，现代经济体系连一天也不可能继续存在。<br>◆ 1.想象建构的秩序深深与真实的世界结合虽然这些想象建构的秩序只存在于我们的脑海里，但它可以与真实的世界紧紧结合、密不可分。<br>◆ 他睡觉的地方跟其他许多年轻人一样，就是在宽敞的大厅里。所以可以说他总是活在众人的目光下，总是得注意别人的观感和意见。如果在这种环境下长大，自然就会觉得：个人的真正价值是由他的社会阶级以及他人对他的看法而定。[插图]<br>◆ 2.想象建构的秩序塑造了我们的欲望<br>◆ 假。而像古埃及的法老王，也是把所有财富拿来建造金字塔，把自己的遗体做成木乃伊，而不会有人想要去巴比伦购物或去腓尼基滑雪。现代人之所以要花费大把银子到国外度假，正是因为他们真正相信了浪漫的消费主义神话。<br>◆ 浪漫主义告诉我们，为了要尽量发挥潜力，就必须尽量累积不同的经验。必须体会不同的情感，尝试不同的关系，品尝不同的美食，还必须学会欣赏不同风格的音乐。而其中最好的一种办法，就是摆脱日常生活及工作，远离熟悉的环境，前往遥远的国度，好亲身“体验”不同的文化、气味、美食和规范。我们总会不断听到浪漫主义的神话，告诉我们“那次的经验让我眼界大开，从此整个生活都不一样了”。<br>◆ 鼓励多元多样的浪漫主义又与消费主义一拍即合，两者携手前行，催生了贩卖各种“体验”的市场，进而推动现代旅游产业发展。旅游业真正卖的可不是机票和饭店房间，而是旅游中的经验。所以这样说来，巴黎的重点不是城市，印度的重点也不是国家，而是它能提供的经验；之所以要买经验，是因为据说这样就能拓展我们的视野、发挥我们的潜力，并且让我们更快乐。<br>◆ 一如古埃及精英分子，现在大多数人一生汲汲营营，也都是想盖起某种金字塔，只不过这些金字塔在不同文化里会有不同的名字、形体和规模罢了。<br>◆ 为了改变现有由想象建构出的秩序，就得先用想象建构出另一套秩序才行。<br>◆ 身为人类，我们不可能脱离想象所建构出的秩序。每一次我们以为自己打破了监狱的高墙、迈向自由的前方，其实只是到了另一间更大的监狱，把活动范围稍稍加以扩大而已。<br>第七章 记忆过载<br>◆ 所谓完整表意，指的是这套符号能够大致完整表达出口头语言；这样一来，就能表达一切人类口传的内容，包括诗歌。但另一方面，所谓部分表意，就是指这套系统只能呈现特定种类的信息，局限于特定领域的活动。<br>◆ 数学符号虽然能用来计算，但要写情诗就做不到了。<br>◆ 至今，大脑为何能做到这样仍然是一个谜，但我们都知道它的检索系统效率惊人。（只不过，找钥匙这件事可能是个例外。）<br>◆ 2024/05/05发表想法<br>从这个角度看计算机大大提高了信息的传输和检索效率，从根本上提升了文明的效率。<br>原文：每隔几年，总有考古学家又发现了其他某种被遗忘的文字，甚至有些还可能比苏美尔泥板更久远。但这些文字多半就只是些新鲜但不实用的发明，原因就在于这些文化没能找出方法来有效编目和检索数据。<br>◆ 每隔几年，总有考古学家又发现了其他某种被遗忘的文字，甚至有些还可能比苏美尔泥板更久远。但这些文字多半就只是些新鲜但不实用的发明，原因就在于这些文化没能找出方法来有效编目和检索数据。<br>◆ 只要能将信息转成数学符号，储存、传播和处理的速度和效率就能快到令人叹服。因此，如果哪个人想打动政府、组织和企业，就必须学会“用数字说话”。<br>◆ 而像物理和工程方面，几乎整个知识领域都快要和人类的口语语言脱节，而由数学符号独挑大梁。[插图]<br>◆ 他们的思考过程有很重要的一部分并不是在他们的脑子里，而是在计算机里或者教室的黑板上。<br>第八章 历史从无正义<br>◆ 《独立宣言》区分了男女，男性从中得利，但女性却被剥夺了同样的权利。《独立宣言》也区分了白人、黑人和印第安人，让白人享有自由民主，但却认为黑人和印第安人是比较劣等的人类，不该享有平等的权利。当时许多蓄奴的人也在《独立宣言》上签了名，他们签署后并未释放奴隶，但一点儿也不觉得自己言行不一。在他们看来，黑人哪有什么“人”权？<br>◆ 所谓“平等”指的只有“法律面前人人平等”这件事，而与失业救济、普及教育或健康保险无关。<br>◆ 而中国古代的《风俗通》也记载，女娲开天辟地的时候要造人，一开始用黄土仔细捏，但后来没有时间余力，便用绳子泡在泥里再拉起来，飞起的泥点也化成一个一个的人，于是“富贵者，黄土人；贫贱者，引绳人也”。[插图]<br>◆ 一切都是因为人类的法律和规范，才让某些人变成奴隶，某些人变成主人。至于黑人和白人之间，虽然有例如皮肤颜色和毛发类型之类的客观生物学差异，但没有证据显示这些差异会影响到智力或道德观。<br>◆ 但如果说的是贫富阶级，有钱人住在独立、豪华的住宅区，就读专为有钱人提供的私立名校，能进到专为有钱人提供的高档医疗机构，这一点对于许多美国和欧洲人来说，却似乎再天经地义不过。但事实已经证明，大多数有钱人之所以有钱，只是因为他出生在有钱的家庭，而大多数穷人一辈子没钱，也就只是因为他出生在贫穷的家庭而已<br>◆ 虽然说所有社会的背后都是由想象建构出来的秩序，但种种秩序却又各有不同。这些差异的原因为何？传统的印度社会是用种姓制度来分阶级，土耳其人用宗教，美国用种族，但为何如此？这些阶级制度开始时多半只是因为历史上的偶发意外，但部分群体取得既得利益之后，世世代代不断加以延续改良，才形成现在的样子。<br>◆ 。正由于定义男女角色、权利和责任的并不是生物学，而只是虚构的故事，所以每个社会认为“够男人”和“够女人”的意义也就大不相同。学者为了把概念讲清楚，通常把生物学上的区分称为“性”(sex)，而文化上的区分称为“性别”(gender)。<br>◆ 另外，要遴选埃及的法老王或天主教的教皇，也不是让大家来打一场。在采集社会里，握有政治主导权的人通常是因为社交技巧最为杰出，而不是身上肌肉最为发达。<br>第十章 金钱的味道<br>◆ 金钱并不是物质上的现实，而只是心理上的想象。<br>◆ 人们之所以愿意如此，正是因为他们接受了这个集体的想象。“信任”正是所有金钱形式最基本的原料。如<br>◆ 金钱正是有史以来最普遍也最有效的互信系统。<br>◆ 所以，就算是在宗教上水火不容的基督徒和穆斯林，也可以在金钱制度上达成同样的信仰。原因就在于宗教信仰的重点是自己相信，但金钱信仰的重点是“别人相信”。<br>第十二章 宗教的法则<br>◆ 对泛灵论者来说，人类只是地球上众多生物的一种。但对多神论者来说，整个世界就像是反映了神和人类的关系。<br>◆ 多神论与一神论真正的不同之处，在于多神论认为主宰世界的最高权力不带有任何私心或偏见，因此对于人类各种世俗的欲望、担心和忧虑毫不在意。<br>◆ 要接近这个宇宙至高的权力，就代表要放下所有的欲望、接受福祸共存的事实，坦然面对失败、贫穷、疾病和死亡<br>◆ 这些神只专精某些领域，而不是无所不包，所以有掌管福德的象神(Ganesha)、财神(Lakshmi)和智慧神(Saraswati)等等，但这些神都还是各有私心和偏见。这样一来，人类就可以和这些神谈谈交易，靠神的帮助来赢得战争、战胜疾病。像这样的低位神灵数量繁多，因为只要开始把全知全能、位阶最高的权柄分割开来，可以想见必会分出不止一位神灵。于是多神的系统由此诞生。<br>◆ 从多神教的概念向外推导，结果就是影响深远的宗教宽容。一方面，多神教徒相信有一个至高无上、完全无私的神灵；但另一方面，多神教徒也相信有许多各有领域、心有偏见的神灵，所以对于某个神的信徒来说，很容易能相信有其他神灵存在，而且也相信其他神灵同样神通广大。多神论本质上是思想开明的，很少迫害异教徒。<br>◆ 冥王奥西里斯(Osiris)、天帝朱庇特(Jupiter)或者太阳神维齐洛波奇特利<br>◆ 亚洲的赛比利(Cybele)和来自埃及的伊西斯<br>◆ 但相对的是，在接下来的1500年间，虽然基督教号称主张爱与怜悯，却仅仅因为对信仰的诠释有些许差异，就引发基督徒自相残杀，死亡人数达到数百万。<br>◆ 而天主教徒认为，虽然信仰是必要的，但光这样还不够。要进入天国，信徒还必须参加教堂礼拜，而且要多行善事。这点让新教徒无法接受，认为这样形同交易，对于神的爱和伟大是种贬抑。如果进不进天堂必须取决于自己的善行，岂不是放大了自己的重要性，而且暗示基督在十字架上为人类受的苦以及神对人类的爱都还不够？<br>◆ 为圣巴塞洛缪节大屠杀(St.Bartholomew's Day Massacre)，<br>◆ 消息从法国传到古罗马的天主教教皇耳里，叫他满心欢喜，立刻安排举行庆典，还委托瓦萨里(Giorgio Vasari)在梵蒂冈的一个房间里将这场大屠杀绘成壁画作为纪念（目前这个房间禁止游客参观）。<br>◆ 以犹太教为例，犹太教仍然认为全宇宙至高的神有私心和偏见，而且关爱的眼神全在一小撮犹太民族和以色列这蕞尔之地。<br>◆ 弥赛亚<br>◆ 一般而言，一神教徒比多神教徒更为狂热、更热衷传教<br>◆ 但由于一神教通常认为自己信奉的就是唯一的神，也认为只有自己看到了完整的真相，自然就会批评其他所有宗教都不可信<br>◆ 到了今天，除了东亚以外的大多数人不论信仰为何，多半都属于一神论的宗教，而且全球政治秩序也正是以一神论为基础而建立。<br>◆ 举例来说，在信奉基督教之前，爱尔兰的主神是女神布里吉德。等到爱尔兰被基督教化，就连布里吉德也仿佛受了洗一样，成了“圣布里吉德”。<br>◆ 二元论宗教兴盛了千余年。大约在公元前1500年到公元前1000年之间，中亚有一位名叫琐罗亚斯德（又名查拉图斯特拉）的先知，相当活跃。他的信念代代相传，最后形成了二元论宗教的代表：祆教（Zoroastrianism，又称拜火教）。祆教认为整个世界就是善神阿胡拉·马兹达(Ahura Mazda)和恶神安格拉·曼纽(Angra Mainyu)之间的战争，而在这场战争中，人类必须站在善神这方给予协助<br>◆ 然而，尽管如此不合理，人类还是很能接受这种矛盾的概念。<br>◆ 更有甚者，无数的基督徒、穆斯林和犹太人居然还能想象善神需要人类的协助，好与魔鬼对抗，由此再推导引发了圣战和十字军东征。<br>◆ 另一个关键的二元论概念（特别在诺斯替教和摩尼教），就是认为身体和灵魂、物质和精神是有清楚区隔的。<br>◆ 相信有天堂（善神的国度）和地狱（恶神的国度），这也是一种二元论的概念。《圣经·旧约全书》里从来没有提过这种概念，也从来没提到人的灵魂会在身体死去后继续存在<br>◆ 结果就是，基督徒大致上是信奉一神论的上帝，相信二元论的魔鬼，崇拜多神论的圣人，还相信泛灵论的鬼魂。<br>◆ 宗教学上有一个特别的名称：综摄(syncretism)。很有可能，综摄才是全球最大的单一宗教。<br>◆ 2024/05/15发表想法<br>为什么叫犬儒主义呢<br>原文：新型宗教信仰包括印度的耆那教(Jainism)和佛教，中国的道教和儒教，以及地中海的犬儒主义(Cynicism)和享乐主义(Epicureanism)，共同的特征就是崇拜的并非神祇。<br>◆ 新型宗教信仰包括印度的耆那教(Jainism)和佛教，中国的道教和儒教，以及地中海的犬儒主义(Cynicism)和享乐主义(Epicureanism)，共同的特征就是崇拜的并非神祇。<br>◆ 人类追求财富和权力，获得知识和财富，生儿育女，建起宫殿和房屋。但不论取得多少成就，他们永远不会满足。穷人梦想着要变富，有100万的想要200万，有200万的想要1000万。而且就算真的有钱了、有名了，他们还是不满意，还是有无尽的烦恼和忧虑，无法从生老病死中解脱。至死，一切如梦幻泡影消失，生命就像是毫无意义的追寻。然而，该怎样才能跳出这个轮回？<br>◆ 他并未绝望，决心反求诸己，直到找到彻底解决的方法为止。他入禅6年，思索各种人类苦痛的本质、原因和解决方式。最后他体会到，一切苦难并非来自厄运、社会不公或神祇的任性，而是出于每个人自己心中的思想模式。<br>◆ 释迦牟尼认为，人遇到事情通常就会产生欲念，而欲念总是会造成不满。遇到不喜欢的事，就想躲开；遇到喜欢的事，就想维持并增加这份愉快。但正因如此，人心就永远不满、永远不安。在碰上不悦的时候格外明显，比如感觉疼痛的时候，只要疼痛持续，我们就一直感到不满，用尽办法想要解决。然而，就算是遇上欢乐的事，我们也从不会真正满足，而是一直担心这种欢乐终将结束或者无法再持续或增强。<br>◆ 释迦牟尼找到一种方法可以跳出这种恶性循环。在事物带来快乐或痛苦的时候，重点是要看清事物的本质，而不是着重在它带来的感受，于是就能不再为此所困。虽然感受悲伤，但不要希望悲伤结束，于是虽然仍有悲伤，也能不再为此而困<br>◆ 通过训练，心灵专注在“我现在是什么感受”，而不是问：“为什么是我？”这种境界很难达到，但并非不可能。释迦牟尼将冥想落实在各种道德规范上，好让信众更能专注在实际的感受，而不会落入各种欲求和幻想之中。<br>◆ 。接着，佛陀一生前往各地普传佛法，希望让所有人离苦得乐。佛陀的教诲一言以蔽之：痛苦来自欲望；要从痛苦中解脱，就要放下欲望；而要放下欲望，就必须训练心智，体验事物的本质。<br>◆ 而且就算他们一心希望最后能达到这个目标，日常生活里多半还是追求着世俗的成就。<br>◆ 最成功的现代宗教：资本主义<br>◆ 2024/05/15发表想法<br>从这个角度看所谓的社会发展无非也就是人们普遍相信的东西在改变。而这种基于普遍相信而建立的权威与宗教同源。<br>原文：资本主义<br>◆ 虽然所有人文主义者都崇拜人性(humanity)，但对于人性的定义却不见得相同。就像是基督教的各个教派对于“神”会有不同定义，人文主义对“人性”的定义，大致上分成三种对立的教派。<br>◆ 如果碰上道德或政治的困境，就该内省、听听自己内心的声音，也就是人性的声音<br>◆ 举例来说，这正是自由主义者反对酷刑和死刑的原因。在近代早期的欧洲，犯下杀人罪的人会被视为违反和破坏了宇宙秩序。为了让宇宙回归平衡，对罪犯施以酷刑并公开处决，好让所有人民都看到宇宙已经重返秩序。在莎士比亚和莫里哀的时代，伦敦人和巴黎人最爱的消遣就是现场直击残忍的处决画面。但在今天的欧洲，死刑被认为侵害了人性的神圣。虽然一样是为了维护秩序，现今的欧洲不会对罪犯施以酷刑处决，反而是要以尽可能“人性化”的方式来加以惩罚，才能维护甚至重建人类的尊严。通过尊重凶手的人性，人人都想起了人性的神圣，于是秩序才得以恢复。像这样保护凶手，我们才能改正凶手做错的事。<br>◆ 人文主义的另一个重要教派就是社会人文主义。社会主义者认为所谓“人性”是个集体而非个人的概念。因此，他们认为神圣的不是每个个人心中的声音，而是由所有智人这种物种构成的整体。自由人文主义追求的，是尽可能为个人争取更多自由；而社会人文主义追求的，则是让所有人都能平等。对社会主义者来说，“不平等”就代表着偏重人类的某些边际特质，认为这比人类的普遍本质更重要，这样一来可说是对人类神圣性最严重的亵渎。举例来说，如果富人比穷人有特权，就代表重视“金钱”超过了人类的普遍本质（本质上，不论贫富，人类的本质应该全部相同）。<br>◆ 唯一不是来自传统一神论的人文主义教派，就是演化人文主义，以纳粹为最著名的代表。<br>◆ 人文主义宗教：崇拜“人性”的宗教[插图]<br>第十三章 成功的秘密<br>◆ 这正是历史成为学科的特点之一：对某个时代的了解越透彻，反而就越难解释为什么发生了这个事件而不是那个事件。<br>◆ 然而，历史就是这样的一团混沌，历史就是无法解释得斩钉截铁，无法预测得十拿九稳。在同一时间，有多方力量互相影响、互相牵制，只要某方力量有了极小的改变，结果就会有巨大的不同。不仅如此，历史还是所谓的“二级”混沌系统。混沌系统分成两级，一级混沌指的是“不会因为预测而改变”。例如天气就属于一级混沌系统。虽然天气也是受到无数因素影响，但我们可以建立计算模型，不断加入越来越多因素，让天气预报也越来越准确。至于二级混沌系统，指的是“会受到预测的影响而改变”，因此就永远无法准确预测。例如市场就属于二级混沌系统。假设我们开发出了一个计算机程序，能够完全准确预测明天的油价，情况会如何？可以想见，油价会立刻因应这个预测而波动，最后也就不可能符合预测。<br>◆ 这么说来，究竟为什么要学历史？历史不像是物理学或经济学，目的不在于做出准确预测。我们之所以研究历史，不是为了要知道未来，而是要拓展视野，要了解现在的种种绝非“自然”，也并非无可避免。未来的可能性远超过我们的想象。举例来说，研究欧洲人究竟是如何控制了非洲人，我们就知道种族歧视绝非自然或无可避免，而且知道世界大有可能是完全不同的样貌。<br>◆ 甚至还有学者认为，文化就像是精神感染或寄生虫，而人类就是毫不知情的宿主。<br>◆ 这种说法有时称为“迷因学”(memetics)。迷因学假设，就像生物演化是基于“基因”这种有机信息单位的复制，文化演化则是基于“迷因”(meme)这种文化信息单位的复制。[插图]而所谓成功的文化，就是特别善于复制其迷因，而丝毫不论这对于其人类宿主的成本或利益。<br>◆ 后现代主义。对后现代主义思想家来说，文化的基石不是迷因，而是“话语”。<br>◆ 历史的演进并不在意生物个体是否幸福。<br>◆ 2024/05/15发表想法<br>这样说三体里的科技爆炸并不一定会发生，这只是历史的一种选择，谁也不知道何时何地会突然发生科技爆炸。<br>原文：我们不难想象，历史其实很有可能就这样一代又一代地过去，而从未发生科学革命，就像即使没有基督教，没有古罗马帝国，没有金币，历史还是会继续发展下去。<br>◆ 我们不难想象，历史其实很有可能就这样一代又一代地过去，而从未发生科学革命，就像即使没有基督教，没有古罗马帝国，没有金币，历史还是会继续发展下去。<br>第四部分 科学革命<br>◆ 核物理学家罗伯特·奥本海默在看到这场爆炸之后，引述了《薄伽梵歌》(Bhagavad Gita)：“现在我成了死神，世界的毁灭者。”<br>第十四章 发现自己的无知<br>◆ 就在这一秒，美国科学家在新墨西哥州的阿拉莫戈多引爆了第一颗原子弹。从这时开始，人类不仅有了改变历史进程的能力，更有了结束历史进程的能力。<br>◆ 1.愿意承认自己的无知。现代科学的基础就是拉丁文前缀“ignoramus-”，意为“我们不知道”。从这种立场，我们承认了自己并非无所不知。更重要的是，我们也愿意在知识进展之后，承认过去相信的可能是错的。于是，再也没有什么概念、想法或理论是神圣不可挑战的。<br>◆ 科学革命并不是“知识的革命”，而是“无知的革命”。真正让科学革命起步的伟大发现，就是发现“人类对于最重要的问题其实毫无所知”。<br>◆ 这个主题也出现在现存最古老的神话里：苏美尔人的吉尔伽美什(Gilgamesh)神话。这则神话的主角是乌鲁克(Uruk)的国王吉尔伽美什，他英勇善战，无人能敌。<br>◆ 对信奉科学的人而言，死亡绝非必然的命运，而不过是个科技问题罢了。人之所以会死，可不是什么神的旨意，而是因为各种技术问题，像心脏病，像癌症，像感染。而每个技术问题，都可以找到技术性的解决方案。<br>◆ 然而，现在我们已经可以坦然承认。科学革命的一大计划目标，就是要给予人类永恒的生命。<br>◆ 。平均而言，爱德华和埃莉诺大约是每3年就有1个孩子夭折。这种丧子丧女之痛，对今天的父母而言简直难以想象<br>◆ 在18世纪之前，各个宗教仍然认为死亡和其影响是生命意义的核心。但从18世纪开始的宗教和意识形态，如自由主义、社会主义、女权主义，就已经对来世完全失去兴趣。<br>◆ 唯一一个让死亡仍然占据核心的现代意识形态就是民族主义。在那些绝望到极点但又同时充满诗意的时刻，民族主义就会向人承诺，就算你牺牲了生命，但你会永远活在国家整体的永恒记忆里<br>◆ 所费不赀<br>◆ 总之，科学研究一定得和某些宗教或意识形态联手，才有蓬勃发展的可能。意识形态能够让研究所耗的成本合理化。而代价就是意识形态能够影响科学的进程表，并且决定如何使用研究成果。<br>第十五章 科学与帝国的联姻<br>◆ 库克远征之前不久，不列颠群岛和西欧还不过就像是地中海世界荒废的偏远后院，人们从没听说过它们有任何重要性<br>◆ 欧洲人之所以能成功征服美洲、在海上称王，主因是亚洲帝国对这些地方兴趣不大。地中海的奥斯曼帝国、波斯的波斯帝国、印度的莫卧儿帝国，以及中国的明、清，在现代早期也是蓬勃发展，领土显著增长，人口及经济发展幅度前所未见。<br>◆ 就算是今天中国经济突飞猛进，很可能即将回归霸主地位，基础仍然是欧洲的生产和金融模式。<br>◆ 那究竟是为什么，最后征服澳大利亚的是库克船长，而不是康熙的水师提督万正色或者土耳其的名将帕夏(Hussein Pasha)？更重要的是，如果欧洲人在1770年面对印度人和中国人并没有什么科技优势，为什么他们能在接下来的短短一世纪间，让自己和世界其他地区拉开这么大的差距？<br>◆ 中国甚至要到1876年，才建了第一条铁路，全长25公里，由欧洲人所建；而且来年就遭到中国政府拆除。所以，就算到了1880年，中国这个庞大的帝国连一条铁路也没有。<br>◆ 中国和波斯其实并不缺乏制作蒸汽机的科技（当时要照抄或购买都完全不成问题），他们缺少的是西方的价值观、故事、司法系统和社会政治结构，这些在西方花了数个世纪才形成及成熟，就算想要照抄，也无法在一夕之间内化。<br>◆ 之所以法国和美国能够很快跟上英国的脚步，是因为他们本来就和英国共享一套最重要的故事和社会结构。而中国和波斯总是追赶不及，则是因为整个关于社会的想法和组织就是不同。<br>◆ 虽然这段时期欧洲面对亚洲在科技、政治、军事、经济上并不具有什么明显的优势，但却是在厚植累积独特的潜力，直到1850年左右才终于爆发。虽然欧洲、中国和伊斯兰世界在1750年看起来还没什么差异，但这其实只是假象。<br>◆ 究竟欧洲在现代早期培养了什么潜力，让它能在现代晚期称霸全球？这个问题有两个相辅相成的答案：现代科学和资本主义。<br>◆ 而欧洲人开采这处矿藏的能力也远胜其他。因此不难想象，在21世纪这个“后欧洲世界”，科学和资本主义就成了欧洲帝国主义最重要的遗产。<br>◆ 欧洲帝国主义和先前的所有帝国完全不同。过去的帝国主义者都认为自己已经了解了整个世界，“征服世界”只是为了要利用及传播他们自己对于世界的看法。<br>◆ 在这趟航程中，船长就这么绘制着军用地图，而达尔文也就这么收集着各种实证资料，发展各种想法，最后形成他的演化论。<br>◆ 在15、16世纪，欧洲人的世界地图开始出现大片空白。从这点可以看出科学心态的发展，以及欧洲帝国主义的动机。地图上的空白可以说是在心理及思想上的一大突破，清楚表明欧洲人愿意承认自己对于一大部分的世界还一无所知。<br>◆ 正因为我们已经太熟悉欧洲这些“探索、征服”的过程，常常忘了这件事其实非常特殊。在这之前，世界上从来没发生过这种事。要这样千里迢迢去征服别人，绝不是什么自然的举动。纵观历史，大多数人类社会光是处理地方冲突、邻里争吵就已经无暇他顾，从来没想过要前往远方探索、征服遥远的国度。绝大多数的大帝国向外侵略只着眼于邻近地区，之所以最后幅员广大，只是因为帝国不断向邻近地区扩张而已。<br>◆ 2024/05/24发表想法<br>明朝那些事儿说是朱棣没发现他侄子的全尸要郑和下西洋顺便去找。<br>原文：然而，这两者有一项关键的区别。郑和下西洋四处探访，对拥护明朝的各国君主提供协助，但并未试图攻占或殖民他国。此外，郑和的远征并没有深厚的中国政治文化基础。因此，在15世纪30年代明宣宗派郑和最后一次下西洋之后，便突然告终。曾叱咤一时的伟大舰队遭到解散，珍贵的技术和地理知识亡逸，从此再也没有具备此等眼界及资源的航海探险家从中国出航。接下来数百年间，中国的君王依循着先前数百年的做法，其兴趣和野心仅仅及于四方邻国而已。<br>◆ 2024/05/24发表想法<br>资本主义诞生后侵略就不是单单让对方臣服那么简单了，往往意味着亡国灭种。<br>原文：不到20年，整个加勒比地区的原住民几近灭绝。西班牙殖民者开始得从非洲进口奴隶来填补空缺。<br>◆ 虽然他们也痛恨阿兹特克人的统治，但他们既不认识西班牙人，更不知道发生在加勒比海地区的种族灭绝惨剧，只是天真地以为，有了西班牙人帮助，就能摆脱阿兹特克人的枷锁。他们从没想过，最后只是统治者从阿兹特克人换成了西班牙人。<br>◆ 现代科学和现代帝国背后的动力都是一种不满足，觉得在远方一定还有什么重要的事物，等着他们去探索、去掌握。<br>第十六章 资本主义教条<br>◆ 2024/05/28发表想法<br>发展被刻在骨子里是帝国主义和科技爆发之后的事。在欧洲中世纪，古代中国都是以稳定为主旋律。这种发展的滚轮一旦启动这个社会的每一分子都被迫滚动起来，适者生存、落后就要挨打等观念深入人心，人与人之间的和谐共生状态就难以达到。<br>原文：想要了解现代经济史，其实重点就只有一个词：增长<br>◆ 想要了解现代经济史，其实重点就只有一个词：增长<br>◆ 银行每次真正持有1元的时候，就能够放款10元<br>◆ 真正让银行（以及整个经济）得以存活甚至大发利市的，其实是我们对未来的信任。“信任”就是世上绝大多数金钱的唯一后盾。<br>◆ 因此，我们可以看到整个运作就是基于信任着一种想象的未来；银行家和创业者相信面包店能成功，承包商也相信银行未来一定能把钱再还给他。<br>◆ 原因就在于，当时金钱只能代表一些“实际存在于当下”的物品。这与“创业”的概念无法兼容，因此也就很难促进经济成长。<br>◆ 过去的问题不在于有没有信用的概念，或者知不知道如何使用这种概念，而在于当时的人并不相信“明天会更好”，所以并不愿意延展信用。毕竟当时的概念，总觉得黄金时代已经过去，未来顶多就是维持现况，而且可能更糟。用经济学的概念来讲，也就是他们认为财富的总量有限，而且还可能萎缩。<br>◆ 1776年，苏格兰经济学家亚当·斯密出版了《国富论》，这可以说是史上最重要的经济学著作。<br>◆ 在新的资本主义教条里，最神圣的开宗明义第一条就是：“生产的利润，必须再投资于提高产量。”<br>◆ 西装简直成了制服，看来就像一群乌鸦；<br>◆ 。比如它解释了金钱的运作模式，也认为将利润再投资生产就能带来快速的经济增长。然而，资本主义的影响范围逐渐超越了单纯的经济领域，现在它还成了一套伦理，告诉我们该有怎样的行为，该如何教育孩子，甚至该如何思考问题<br>◆ 资本主义的基本原则在于，经济增长就是至善（或至少十分接近）。因为正义、自由甚至快乐都必须依赖于经济增长，如果你找来一个资本主义者，问他该如何为津巴布韦或阿富汗这些地方带来正义和政治自由，他很可能就会滔滔不绝地告诉你，想要有稳定的民主制度，就必须要有蓬勃的经济、健全的中产阶级，所以重点就是该让当地人有自由企业、勤俭节约、自立自强这些价值概念。<br>◆ 这项研究会提高产量和利润吗？会促进经济增长吗？”研究计划如果没办法应付这些问题，想取得研究经费的可能性就微乎其微。要谈到现代科学史，资本主义绝对是不得不谈的重要因素<br>◆ 资本主义认为经济可以无穷无尽地发展下去，但这和我们日常生活观察到的宇宙现象完全背道而驰。<br>◆ 。唯一的原因，就在于科学家总是能每隔几年就取得另一项发现，提出另一项发明，像美洲大陆、内燃机引擎，或者运用基因工程的羊。印钞票的是银行和政府，但最后买单的是科学家。<br>◆ 没人喜欢缴税，但人人都乐于投资。<br>◆ 2024/05/29发表想法<br>这种探索发现或者科技发展是否都会有个尽头呢？不能总是相信后人的智慧吧。<br>原文：这就是帝国资本主义的奇妙循环：信贷资助新发现，新发现带来殖民地，殖民地带来利润，利润建立起信任，信任转化为更多的信贷。<br>◆ 为了投资人利益而发动的战争绝不只这两场而已。事实上，连战争本身都可以像鸦片一样变成商品。<br>◆ 就算是最保守的估计，从1885年到1908年之间，在刚果追求增长和利润的代价，就足足让600万刚果人命丧黄泉（至少占当时刚果人口的两成），甚至有些人估计惨死人数高达千万。[插图]<br>◆ 然而，这块经济大饼真的能无限变大吗？每块饼都需要原材料和能源。但早有先知预言警告，迟早智人会耗尽地球上所有的原料和能源。那么接下来会发生什么呢？<br>第十七章 工业的巨轮<br>◆ 工业革命最重要的一点，其实在于它就是第二次的农业革命。<br>◆ 大多数人，在生产或者消费各种奶、蛋、肉类的时候，都很少想到提供这些食物的鸡、牛或猪。就算有些人真的想过，也常认为这些动物真的和机器没什么两样，没有感觉、没有情绪，并不会感受到痛苦。<br>◆ 在历史上的大多数时候，这种文案不但无法引起消费欲望，反而还会激起极度的反感。在过去的人眼中，这种内容真是自私、堕落、道德沦丧！消费主义除了自身非常努力，还在大众心理学（像“做就对了！”）的推波助澜之下，不断说服大众“放纵对你有益，而节俭是自我压抑”。而且，这套理论已经成功了。<br>◆ 这是人类有史以来第一次，信众终于真的能够做到宗教要求的条件。只不过，我们又怎么知道它承诺的天堂是什么样子？答案是：看看电视，你就知道。<br>第十八章 一场永远的革命<br>◆ 很多人称呼这个过程是“自然的毁灭”。然而，这其实并不能算是“毁灭”，而只是“改变”。自然是无法“毁灭”的。6500万年前，一颗陨石让恐龙灭绝，但却为哺乳类动物开启了一条康庄大道。<br>◆ 或许，现在的6500万年后，会有一群高智商的老鼠心怀感激地回顾人类造成的这场灾难，就像我们现在感谢那颗杀死恐龙的陨石一般。<br>◆ 想要不知道现在几点，还真是得刻意花上一点功夫才行。<br>◆ 一般人每天会看上几十次时间，原因就在于现代似乎一切都得按时完成。<br>◆ 在工业革命之前，多数人的日常生活都逃不脱三大传统框架：核心家庭、大家庭，以及当地的密切社群<br>◆ 很多时候，王国和帝国就像是收着保护费的黑道集团。国王就是黑道大哥，收了保护费就得罩着自己的人民，不受附近其他黑道集团或当地小混混骚扰。除此之外，其实也没什么功用。<br>◆ 家庭和社群对成员的压迫绝不下于现代国家和市场，这些家庭和社群内部常常充满紧张和暴力，而且成员别无选择<br>◆ 父母和社群里的长者并不愿意放手让年轻一辈接受国民教育的洗脑，也不希望他们受征召从军，更不想让年轻人变成一个没有根的都市无产阶级。<br>◆ 于是，国家与市场找上家庭和社群的各个成员，开出了他们无法拒绝的条件。他们说：“做自己吧！想娶想嫁都随你的意，别管父母准不准。想挑什么工作都可以，别担心什么大家长说的话。想住哪就住哪，就算没办法每周和家人吃上一次饭又有什么关系呢？你不用再依赖家庭或社群了。我们，也就是国家和市场，让我们来照顾你吧。我们会给你食物、住房、教育、保健、福利和就业机会。我们也会给你退休金、保险和保障。”<br>◆ 然而，要解放个人是有代价的。现在许多人都悲叹着家庭和社群功能不再、觉得疏离，而且感觉冷漠的国家和市场对我们造成许多威胁。如果组成国家和市场的是一个又一个孤单的个人，而不是关系紧密的家庭或社群，要干预个人生活也就容易得多。现代高楼公寓，所有人各自锁在自己家里，连每户该付多少清洁费都无法达成共识，又怎么可能一起站出来抵抗国家机器？<br>◆ 个人又抱怨这两者要得太多，又给得太少<br>◆ 经过数百万年的演化，人类的生活和思考方式都预设自己属于社群。但仅仅过了两个世纪，我们就成了互相疏远的个人。这可以说是文化力量的最佳证明。<br>◆ 但到了现在，父母的权威可说大不如前。年轻人越来越不需要听从长辈的意见，而一旦孩子的人生出了任何问题，似乎看来总是可以怪在父母头上。<br>◆ 所谓想象的社群，指的是虽然成员并不真正认识彼此，却想象大家都是同一伙的。<br>◆ 现代所兴起的两大想象社群，就是“民族”和“消费大众”。所谓民族，是国家的想象社群。而所谓消费大众，则是市场的想象社群。<br>◆ 消费主义和民族主义可说是夙夜匪懈，努力说服我们自己和其他数百万人是一伙的，认为我们有共同的过去、共同的利益以及共同的未来。这并不是谎言，而是一场想象。<br>◆ 狄更斯写到法国大革命，就说“这是最好的年代，也是最坏的年代”。<br>◆ 大多数人看不到这个年代究竟有多么和平。我们毕竟都没真正看过1000年前的模样，所以很容易忘记过去的世界其实更加残暴。而且，因为战争变成少见的事，也让战争吸引了更多关注。<br>◆ 更重要的是，我们比较容易体会个人的辛酸，而不是人类整体的苦难。<br>第十九章 从此过着幸福快乐的日子<br>◆ 就算是都市中产阶级，过着舒适的生活，生活中却再也没有什么比得上狩猎采集者猎到长毛象那种兴奋和纯粹的快乐。每次出现新发明，只是让我们与伊甸园又离得更远。<br>◆ 另一项有趣的发现是疾病会短期降低人的幸福感，但除非病情不断恶化，或者症状带有持续、让人无力的疼痛，否则疾病并不会造成长期的不快<br>◆ 目前看来，对快乐与否的影响，家庭和社群要比金钱和健康来得重要。那些家庭关系紧密良好、社群互相扶持帮助的人，明显比较快乐。而那些家庭机能失调、一直无法融入某个社群的人则明显比较不快乐。<br>◆ 现在的人并不见得比1800年的人更快乐。<br>◆ 但我们越来越期望能得到舒适和快感，也越来越不能忍受不便和不适。结果就是我们感受到的痛苦程度可能还高于我们的先人。<br>◆ 在我们试着猜测或想象其他人有多快乐的时候（可能是现在或过去的人），我们总是想要设身处地去想想自己在那个情况下会如何感受。但这么一来，我们是把自己的期望放到了别人的物质条件上，结果当然就会失准。<br>◆ 就算是在富裕的社会里，小孩通常也不喜欢洗澡，得花上好几年的教育和管教，才能够养成这种理论上应该很舒服的习惯。一切都只是期望的问题而已。<br>◆ 生物学家认为，我们的心理和情感世界其实是由经过数百万年演化的生化机制所形塑。所有的心理状态（包括主观幸福感）并不是由外在因素（例如工资、社会关系或政治权利）来决定，而是由神经、神经元、突触和各种生化物质（例如血清素、多巴胺和催产素）构成的复杂系统而定。<br>◆ 快乐这件事不适用于自然选择的原则，一个快乐的孤独隐士将会绝种，而两位整天焦虑的爸妈，却能把基因再传下去。<br>◆ 快乐或痛苦在演化过程里的作用，就只在于鼓励或阻挡生存和繁衍。所以也不难想象，人类演化的结果，就是不会太快乐，也不会太痛苦。我们会短暂感受到快感，但不会永远持续。迟早快感会消退，让我们再次感受到痛苦。<br>◆ 正如尼采所言，只要有了活下去的理由，几乎什么都能够忍受。生活有意义，就算在困境中也能甘之如饴；生活无意义，就算在顺境中也度日如年。<br>◆ 所以，我们的中世纪祖先会感到快乐，就只是因为他们有着对来世的集体错觉，因而感觉生命充满意义吗？没错！只要没人去戳破他们的幻想，又为什么要不开心呢？从我们所知的纯粹科学角度来看，人类的生命本来就完全没有意义。人类只是在没有特定目标的演化过程中，盲目产生的结果。人类的行动没有什么神圣的整体计划，而且如果整个地球明天早上就爆炸消失，整个宇宙很可能还是一样这么继续运行下去。<br>◆ 我们对生活所赋予的任何意义，其实都只是错觉。<br>◆ 这么说来，所谓的快乐，很可能只是让个人对意义的错觉和现行的集体错觉达成同步而已。只要我自己的想法能和身边的人的想法达成一致，我就能说服自己、觉得自己的生命有意义，而且也能从这个信念中得到快乐。<br>◆ 从老子到苏格拉底，哲学家不断告诫人们：“认识你自己！”但言下之意也就是一般人并不知道自己真实的自我，也因此很可能忽略了真正的快乐<br>◆ 事实是，人类的主观感受没有任何实质或意义。主观感受就只是一种电光石火的波动，每个瞬间都在改变，就像海浪一样。不论你感受到的是快感或不快，觉得生命是否有着意义，这都只是一瞬间的波动而已。<br>◆ 因此，苦的根源既不在于感到悲伤或疼痛，也不在于感觉一切没有意义。苦真正的根源就在于“追求”主观感受这件事，不管追求的是什么，都会让人陷入持续的紧张、困惑和不满之中。<br>◆ 但佛教更重要也更深刻的见解在于，真正的快乐也不在于我们的主观感受。我们如果越强调主观感受，反而就越感到苦。佛教给我们的建议是，除了别再追求外在成就之外，同时也别再追求那些感觉良好的心里感受了。<br>◆ 苦真正的来源不在于感受本身，而是对感受的不断追求。<br>第二十章 智人末日<br>◆ 一个简单的例子是阉割。在英文里，未阉割的公牛称为“bull”，阉割后的称为“ox”，<br>◆ 现在计算机工程世界正当红的一个领域，就是基因程序设计(genetic programming)。这种程序设计模仿基因遗传演化。许多程序设计师都有一个梦想，希望能创造出一个能够独立于创造者、完全自行学习演化的程序。在这种情况下，程序设计师只是一个原动力(primum mobile)，程序一经发动之后，就会开始自由演化，无论创造者还是其他任何人都不再能掌握它的发展方向。<br>◆ 2005年成立了一项“蓝脑计划”(Blue Brain Project)，希望能用计算机完整重建一个人脑，用电子回路来仿真大脑中的神经网络。<br>◆ 吉尔伽美什计划<br>◆ 宇宙飞船其实只是小事，真正会惊天动地的，可能是能够永远年轻的生化人，既不繁衍后代，也没有性欲，能够直接和其他生物共享记忆，而且专注力和记性是现代人类的1000倍以上，不会愤怒、不会悲伤，而他们的情感和欲望完全是我们所无法想象的。<br>]]></description><link>culture\阅读\人类简史.html</link><guid isPermaLink="false">Culture/阅读/人类简史.md</guid><pubDate>Mon, 09 Sep 2024 11:43:44 GMT</pubDate></item><item><title><![CDATA[我的二本学生]]></title><description><![CDATA[ 
 <br><br><br> 黄灯<br> 64个笔记<br><br>
<br>他们认定个人奋斗，自动剥离个体与时代的关联，在原子化、碎片化的具体语境中，个体与时代之间的关系，被轻易转移到了个体的机遇、命运和努力程度上，个体层面学生与命运的抗争，和整体层面学生无法与命运的抗争，两者构成了触目惊心的对比。  
<br><br>
<br>他不习惯死记硬背，中考因为超常发挥，考上了平凉一中实验班，“自此就开始了我人生中悲惨的命运”。在整个高一，他的成绩一直是班上倒数第一，不好的成绩，影响到了他的行为能力，自制力逐渐变差后，老师批评增多，“就此陷入了一种恶性循环”。<br>

<br>我想起他曾向我描述的一幕，和爷爷放羊时，老人总是抑制不住内心的诗情，要教孙子古诗的平仄。在龙洞喧嚣的氛围中，这个西北老人关于诗歌的梦想，通过一个年轻人的两年努力，终于获得了延续。  
<br><br>
<br>他们和我一样，紧张，试探；他们第一次走进大学课堂，我第一次站上大学讲台；我们互相照亮，又彼此隔膜。  
<br><br>
<br>我当然更得承认，正是像《风》这样的作文，其坦率的文字，悄然照亮了我内心忽略的角落，瓦解我内心的偏见，并通过彼此的赤诚相见，一点点卸下我早已淤积的虚空，让生命的姿势一点点下蹲，并在具体的生命观照中，找到内在的充盈。<br>

<br>2008年12月27日凌晨，洁韵离开了这个世界，奇迹没有发生。<br>

<br>一个家庭的悲剧，像一出静默的黑白哑片，早已越过十年的光阴。<br>

<br>残留在作业本上的青春印记，如不显眼的水印。但我总是记起那双穿越电梯，到楼下接我的眼睛。<br>

<br>这种光芒让我牵挂，也让我着迷。  
<br><br>
<br>进到大学校园的第一天，还来不及排解中学时代内心的淤积，就被告知就业的压力、买房的压力、竞争的压力。从记事起，无形的、细密的重荷就负载在他们身上，早已将他们裁剪得规规整整，难以在生活中找到泄漏狡黠的契机。<br>

<br>我在具体的课堂中，充分感受到教育像一场慢性炎症，中小学时代服下的猛药、抗生素、激素，到大学时代，终于结下了漠然、无所谓、不思考、不主动的恶果。学生内心的疲惫和大学时代的严苛压力，成为他们精神生活的底色。<br>

<br>乌云已经酝酿着危机，雷鸣电闪而人们视而不见，暴雨将至，没人能幸免于难<br>

<br>一次普通的期末考试，不过如一面一晃而过的镜子。  
<br><br>
<br>“于连是同社会奋战的不幸的人。”<br>

<br>他们，如一个个固定的锚点，成为我对国情，最方便的观测。他们，以一个个真实的生命，成为我对时代，最真切的感知。  
<br><br>
<br>他知道自己不喜欢什么，便不会去尝试那些东西，贫瘠山村给予他的倔强，让他在进入喧嚣的城市后，依然在个体的人格中，保留了一份坚守的稀缺。他始终难以对生活做出真正的妥协，而这种不妥协的结局，落实到个体的生存上，便是看得见的漂泊，和弥散到下一代身上的和他人确定的差距。<br>

<br>“在读过了金庸所有作品后，随着年纪慢慢增长，所读的小说越来越多，其情节越来越不能满足我的欲望，于是，自己便萌生了创作的想法”。<br>

<br>他是一个真正被兴趣吸引的人，是一个有目标和梦想的人，<br>

<br>“梦想，每个人都应该拥有，但不是每个人都能实现。我在大学期间，就知道自己不能把梦想照进现实，至少短期内不可以。我很清楚地认识到，大学毕业后，我的首要任务是要解决我和家人的生活问题。”<br>

<br>佼佼者，但他毕业以后的九年经历不过证明，现实已没有多少空间和可能，让一个普通的农村年轻人，在坚守梦想的道路上，可以走得更为顺畅。<br>

<br>志勇猛然发现，现实中，他并没有太多的选择。  
<br><br>
<br>独立带来的副产品，是孤独感的滋生。<br>

<br>2024/03/26 发表想法
  不是专门被坑的八零后，是专门被坑的年轻人。父权社会的基本属性就是年长男性控制年轻男性和女性。

原文：回首自己历经媒体到机关的职业生涯，在见识了媒体的混乱和行政部门的官僚作风后，她感叹，“作为专门被坑的八零后，如何混战在这个复杂的社会，如何通过我们这一代人去改变大环境，我觉得还没能给出一个答案，我希望能在彷徨与摸爬滚打中找到答案”。


<br>回首自己历经媒体到机关的职业生涯，在见识了媒体的混乱和行政部门的官僚作风后，她感叹，“作为专门被坑的八零后，如何混战在这个复杂的社会，如何通过我们这一代人去改变大环境，我觉得还没能给出一个答案，我希望能在彷徨与摸爬滚打中找到答案”。<br>

<br>大学时光，对别的孩子而言，意味着爱情、玩耍和交际，对海燕而言，则是“一个农村孩子，开阔眼界、补缺父母陪伴的改变期”。比起外面的灯红酒绿，她更愿意待在简陋的出租屋，听父母的笑声，参与一家人的讨论，并通过劳动，帮父母减轻一点生活压力。<br>

<br>劳务派遣<br>

<br>有时哪怕掌握了再多的理，也应该给别人留个面子，因为这个世界上，只要对方不想被说服，你永远都说服不了他，人家根本不是觉得你的理不对，而是反感你这种咄咄逼人的方式<br>

<br>成熟的处事方式是，在表达自己的同时，亦要照顾对方的感受。如何在别人不难堪的情况下交往，在说理的同时也不会让对方不痛快，是一门高深的技术，也是一门艺术<br>

<br>整体上，对八零后一代孩子而言，在房价平稳、低廉、经济上行的阶段，他们通过各种努力和尝试，大都能拥有一份让人踏实的工作，并在工作的庇佑下，得以成家立业，实现读书改变命运的古老隐喻。  
<br><br>
<br>2024/03/26 发表想法
  炒房客的自我感动

原文：“环顾四周，优秀的人比我们都努力，实在没有理由懈怠，说到底，还是最努力的那一批人留下来了”。


<br>2024/03/27 发表想法
  是炒房的人富了，而不是买房的就富了，说白了就是投机的人富了。

原文：综观这个时代，可以发现，近十年内，顺着潮流，买房是个体获得巨额财富的捷径。如果信奉劳动的价值，在房价相对平稳的时机，不愿加杠杆、不愿欠债，错过一步，可能就步步皆错，几年以后，就会形成触目惊心的对比。


<br><br>
<br>2024/03/27 发表想法
  市场经济不是导致大众教育的根本原因，市场经济发展不当，导致的就业问题才是直接导致大学扩招，也就是作者所谓的大众教育的根本原因。

原文：精英教育和大众教


<br>我担心的是，世界断裂式的发展，在市场经济的洪流中，正以个人成功的名义掩盖背后更为致命的真相。借助班主任视角，我在感知自身和另一个群体的命运变迁时，能明显感到背后分化的加剧及其越来越固化的危机。在理解胜轩命运  
<br><br>
<br>但却让师生之间找回了一种隐隐约约的大学气场，在没有任何功利考核的自觉交流中，一群从应试教育走来的孩子，终于发现了学习的乐趣和尊严，发现学习的目的并不在于是否能兑换为学分或者证件。  
<br><br>
<br>“夏天的草很青，有一种毛毛草圆圆的，很茂密，又散得很开，像一把伞。我经常拔一棵，戴在头上装皇后；我哥很搞笑，配合我，他也拔一棵，戴在头上装皇上。这就是我们的快乐时光。”有时候，婉丽会和哥哥去玉米<br>

<br>童年的经历，如此真切，又如此模糊。<br>

<br>“我当时都蒙了，打死也不要辍学，我当时的念头就是，要不将我嫁人吧，让我先和婆家订婚，让婆家送我读书，等毕业了，再嫁给别人。”<br>

<br>当火车驶入南方的土地，南方的秀美、葱茏，和西北的苍茫、黯淡构成了强烈对比，这种对比让她震撼，“到处都是树木，到处都是绿色，我简直不敢相信自己的眼睛，惊讶得不知道怎么呼吸”。<br>

<br>“我决心向着有阳光的地方伸展，老天爷总会给我条路走。”  
<br><br>
<br>在我所教的学生中，和我交往较深的孩子，以农村出生的学生居多，城里的孩子，就如沐光所说，尽管文质彬彬，颇有教养，但他们与生俱来的距离感，同样也体现在和老师的交往上。<br>

<br>“通过这个机会，我迅速地逼近生活真相，对人性的丰富有了更多的体察，懂得了理解是面对生活的一种方式。”<br>

<br>在被子女的教育吸干一个家庭的水分后，干瘪的父母，正等待孩子大学毕业以后的回馈。<br>

<br>属于九零后，又不太九零后，我并不敢妄言，自己真正了解九零后，因为我是一个不太相信物理年龄的人，觉得很多东西可以跨越年龄。”<br>

<br>说到底，横亘在子然面前的现实，是在物质和精神的天平上，她并未完全平衡好，她能够意识到精神的那一段，对现实中的她，始终牵扯得太厉害。如果说，更多来自农村的孩子，大学毕业以后面临的现实，还停留在解决生存问题，那么，来自城市中产之家的子然，她的烦恼，显然更多涉及个体的发展。  
<br><br>
<br>，一种真实的“代”的感觉油然升起。尽管他们和062111班仅仅相隔九年，但这九年的岁月，足以在我的视野中，淘洗出另一个完全不同的群体。<br>

<br>我满腔惯有的热情顿时冰封，他们只需一个低头看手机的动作，就足以消解班主任角色给我带来的“权威”，凛凛的漠然中，让我意识到一种真实的尴尬。我感到此前持有的、负载在班主任身上的话语系统，已难以进入他们的频道，更让我忐忑的是，我不知道自己所持有的价值观念，在度量这个群体时，是否依然有效。<br>

<br>年轻的生命，正以越来越快的速度，被现实甩出，一个群体处境的塌陷，正越来越显示出坚硬的确定性。  
<br><br>
<br>2024/03/29 发表想法
  我每次读网文总想自己写网文。我觉得网文长板在于剧情和架空世界观，它有足够的篇幅彻底讲清楚一个新世界，讲完一个传奇人物的一生。所以剧情的整体安排，人物的成长路线如果真正写好，或许能诞生出绝佳的通俗小说。

原文：“感觉自己在浪费时间，罪恶感很重，但又欲罢不能，管不住自己”。


<br>真实面目不会从外表看出来，我们都有自己的保护壳，所有的事情，全部都自己吞”  
<br><br>
<br>单纯的知识灌输，已经不能引起学生半点兴趣，他们不会反抗，但他们会立即耷拉下脑袋，低头去看手机，连一个不屑的表情都吝于做出。脱离了高中的学习氛围，大学的老师，不再像高中班主任那样去管纪律，对这些孩子而言，这是一次集体的踏空适应。<br>

<br>相对文学史的内容要求，课时往往会被大量削减，每次拿到教材，感觉就是将一个成人拼命地塞进一套童装。<br>

<br>在新的课堂尝试中，我对他们的首要要求就是，尽可能还原语境，尽可能通过访谈、调研，进入自己的长辈、亲人、村庄、故乡去获得第一手材料。  
<br><br>
<br>村里没有孩子念书的家庭，早就建好了气派的楼房。妈妈对早亮毕业以后的处境，没有具体的感知，儿子带回来的关于广州房价的叙述，叠加上她熟知的家乡小城的房价信息，这冷冰冰的数字，不经意中瓦解了一个女人朦朦胧胧的确信。无论她如何强调，“不怕的，没有关系的”，我始终难以忘怀脑海中的一幕：在落日余晖的傍晚，在收割红薯的地里，在谈论房价不经意的叹息中，一个农家妇女，对房子和孩子命运之间关联的在意。  
<br><br>
<br>但在潮汕的学生中，和我交往更多的是女生，事实上，潮汕女孩内在的恬静、雅致、轻言细语，让我印象更为深刻。她们对经营一份笃定、安稳的生活，充满了祖辈延续下来的耐心。在固有的印象中，潮汕女孩更多要延续古老土地赋予的生儿育女使命，当下流行的女性意识、女权主义，仿佛和这个群体没有太多关系。但作为受过高等教育的女性，她们的成长、选择、困惑、出路，更能折射她们从个体层面与时代的遭遇和突围。<br>

<br>对自己的专业和职业前景有清晰的规划。在谈恋爱阶段，文妍感觉男友能理解自己，知道自己需要什么，两人能很好地沟通。“他一直问我，你自己要什么，他说，你如果找到了，就去做喜欢的事，不用考虑其他。”<br>

<br>妈妈将待人和气，和人保持良好的关系，视为最重要的教育理念。“你即使讨厌一个人，也不能对他臭脸，也要和颜悦色。”陈雪反感妈妈的这个要求，但遇见讨厌的人，还是能习惯性地做到不摆臭脸，让她别扭的是，“感觉自己整天挂着假笑”。<br>

<br>她变得不爱回家，突然发现，小时候倍感简单、温馨的家，对她并没有太大的吸引力。妈妈教给她的隐忍、随大流，在光怪陆离的大城市的冲击下，像一张褪色、错愕的脸。<br>

<br>故乡潮州的古旧、缓慢，人与人之间的距离或亲密，她只有离开这个小城后，才能感知到那种城镇日子的慵懒、黏滞。  
<br><br>
<br>对爸爸而言，工厂面对的困境，固然让他难熬，而房价非理性飙升对他财富的吞噬，更是从根本上，彻底瓦解了他坚守多年的实业梦想。冰冰面对爸爸精神的变化，也不得不承认，“不知道怎么回事，深圳这几年变了，变味了”。<br>

<br>有意思的是，三个家庭和深圳的结缘，不约而同都来自先行一步亲人的带领。由此可以看出，无论转型期中国，城市化的步伐迈得如何矫健，其背后终究会渗透来自农业文明的人伦互助。<br>

<br>如果说，经济下滑导致就业机会的减少，还只是让他们感受到了找工作的难度，他们还可以凭借青春的热血，将希望寄托在个人能力的提升上；那么，浪漫主义般飙升的房价，则彻底瓦解了他们在大城市奋斗的念头，除了“丧”，除了选择逃离，他们找不到任何留下的现实理由。<br>

<br>2024/04/02 发表想法
  我也有同感，我觉得会产生这种想法是因为他们知道父母创造的财富是几十年如一日的起早贪黑换来的，父母从未为自己活过，我一直希望我父母能拿着他们一辈子积累下来的财富在退休后去找点喜欢做的事情做做，丢下我这个担子去活出自己的人生。

原文：更让我感慨的是，不管父母创造了多少财富，没有一个孩子觉得获得父母的财产，是来自血缘的一种理所当然，他们骨子里更看重自己独立的打拼，没有半点依靠父母的念头。


<br>更让我感慨的是，不管父母创造了多少财富，没有一个孩子觉得获得父母的财产，是来自血缘的一种理所当然，他们骨子里更看重自己独立的打拼，没有半点依靠父母的念头。  
<br> 来自微信读书<br><br>这本书基本讲了八零九零后的两代人。<br>
我是个零零后，所以我特地问了我的八零后亲戚，她的大学生活是怎么样的。和书中那些学生一样，贷款，寒暑假打工，基本上了大学就没再向家里要过一分钱。我拿那篇没有贷到款的无助学生的那篇关于风的作文给她看的时候她的第一反应是表示矫情，她总觉得天无绝人之路。书中的八零后学生有两类一类是对应酬不反感，处事圆滑的，他们走金融，做生意。一类是不喜与人钩心斗角，选择考个研考个公安稳一生的。我这位亲戚就是后者。所以也算是经过实证，我认为作者是很真实地还原了八零后九零后大学生的时代困境与生活状态。<br>
但是，可能是由于视角的问题，作者写这本书是想要分析个体在时代和家庭影响下的行为与生活条件，职业情况。而文中大部分以学生自述为主，作者补充为辅，有很多地方作者补充部分就是感叹下家庭如何如何，影响了孩子如何如何，或者什么样的家庭锻炼出了什么样的孩子，再或者感叹下房价飙升让不同家庭走向了不同的道路。一来作者过于强调家庭和时代，当然它们的确最重要，但是多说无益。二来，没有点透，家庭的争吵不断是表象，家庭的贫困是表象，房价飙涨也是表象，深层的东西是什么，八零九零年代到底发生了什么剧变让两代人差异这么大，作者只是朦胧地感受到了一种改变，但是没有说透。但或许讲透了就成经济类书籍了。<br>
但是我还是很推荐这本书的，能了解这么多学生，真正去关心学生从哪里来到哪里去的老师真的不多。这可能是我喜欢教育的一点，我不一定喜欢教书，但我喜欢育人。在学生身上你能最直观地看到社会与个人的对抗，最清晰地看到理想与现实的碰撞。教育的目的在我看来只有一个，那就是赋予人找到和实现自己生命价值的能力。<br>
但很可惜，这本书只到2019年，这时候的零零后还在上高中。我觉得九零后和零零后差别更大，这种差别不只是体现在世纪之交，更主要的是外部通道的关闭让他们更愿意向内求索了。开始流行自爱，开始出现躺平，开始出现一个周末跑到几千里外爬座山的特种兵。他们开始试图从现实的泥沼里跳脱出来，做自己想做的事了。]]></description><link>culture\阅读\我的二本学生.html</link><guid isPermaLink="false">Culture/阅读/我的二本学生.md</guid><pubDate>Tue, 02 Apr 2024 05:35:55 GMT</pubDate></item><item><title><![CDATA[小说课]]></title><description><![CDATA[ 
 <br><br><br> 毕飞宇<br> 200个笔记<br><br>
<br>刘姥姥“一进”荣国府，我们这些做读者的立即感受到了《红楼梦》史诗般的广博，还有史诗般的恢宏。我们看到了冰山的一角，它让我们的内心即刻涌起了对冰山无尽的阅读遐想。如同贾宝玉“初试”云雨情一样，它让我们的内心同样涌起了对情色世界无尽的阅读渴望。这个开头妙就妙在这里，它使我们看到了并辔而行的双驾马车。<br>

<br>这里头牵扯一个悲剧美学的问题，悲剧为什么是悲剧，是因为无法回避。悲剧的美学基础就在这里，你规避不了。古希腊人为什么要把悲剧命名为“命运悲剧”？<br>

<br>那是因为他们对人性、神性——其实依然是人性——过于乐观，古希腊人不像我们东方人，他们不愿意相信人性——或者神性——的恶才是所有悲剧的基础<br>

<br>在我看来，文化是什么呢？文化就是借口。不同的人找到了不同的借口，最终成为不同的人，最终形成了不同的文化。<br>

<br>我要说，因为“宫中尚促织之戏”，又因为“岁征民间”，没有蛐蛐的地方偏偏就出现了关于蛐蛐的悲剧，这里头一下子就有了荒诞的色彩，魔幻现实的色彩。<br>

<br>。经常有人问我，好的小说语言是怎样的？现在我们看到了，好的小说语言有时候和语言的修辞无关，它就是大白话。好的小说语言就这样：有它，你不一定觉得它有多美妙，没有它，天立即就塌下来了。<br>

<br>“欲媚”是什么？从根本上说，其实就是奴性。关于奴性，鲁迅先生几乎用了一生的经历在和它做抗争。奴性和奴役是不一样的。奴役的目的是为了让你接受奴性，而奴性则是你从一开始就主动地、自觉地、心平气和地接受了奴性，它成了你文化心理、行为、习惯的逻辑出发点。<br>

<br>封建文化说到底就是皇帝的文化，皇帝的文化说到底就是奴性的文化，奴性的文化说到底就是“欲媚”的文化<br>

<br>鲁迅在他的个人思想史上一直在直面一个东西，那就是“国民性”。面对国民性，他哀，他怒，但“国民性”是什么？在我看来，蒲松龄提前为鲁迅做了注释，那就是“欲媚”。<br>

<br>如何读小说：我们要解决两个的问题，一个是关于“大”的问题，一个是关于“小”的问题，也就是我们如何能看到小说内部的大，同时能读到小说内部的小。只盯着大处，你的小说将失去生动，失去深入，失去最能体现小说魅力的那些部分；只盯着小，我们又会失去小说的涵盖，小说的格局，小说的辐射，最主要的是，小说的功能。好的读者一定会有两只眼睛，一只眼看大局，一只眼盯局部。<br>

<br>蒲松龄只给了他四个字，“为人迂讷”。“为人迂讷”能说明什么呢？什么都说明不了。没听说“为人迂讷”就必须倒霉，性格从来就不是命运。问题出就出在《促织》开头的那个“里胥”身上，里胥是谁？蒲松龄说了，“里胥猾黠”。猾黠，一个很黑暗的词，——当“迂讷”遇见了“猾黠”，性格就必须是命运。<br>

<br>在这里，“滑黠”就是一片乌云，它很轻易地罩住了“迂讷”。“滑黠”一旦运行，“迂讷”只能是浑身潮湿，被淋得透透的。<br>

<br>语言是想象力的出发点，语言也是想象力的目的地。<br>

<br>问题不在你掉进了马里亚纳海沟，问题是掉进了马里亚纳海沟是怎样的一副光景。在我看来，小说家的责任和义务就在这里。他要面对这个问题。这个地方你的处理不充分，你的笔力达不到，一切还是空话。<br>

<br>他可不可以一下子就交代成名的悲痛？不可以。因为这里头牵扯到一个人之常情，人物有人物的心理依据和心理逻辑。我常说，小说不是逻辑，但是小说讲逻辑。<br>

<br>2023/11/30 发表想法
  我觉得对于悲伤的描写要分人，对于成年人他们大多不直接表露悲伤。但有时候写那种宣泄的悲伤和大哭也让人心碎，比如兄弟里宋凡平死后两个孩子的大哭，他们是孩子所以他们表达悲伤的方式就是大哭，哭得越悲痛越真实。

原文：那么，蒲松龄的艺术才华到底体现在什么地方？是这8个字：“夫妻向隅，茅舍无烟。”这是标准的白描，没有杰出的小说才华你还真的写不出这8个字来。隅是什么？墙角。夫妻两个，一人对着一个墙角，麻袋一样发呆；房子是什么质地？茅舍，贫；无烟，炉膛里根本就没火，寒。贫寒夫妻百事哀。这8个字的内部是绝望的，冰冷的。死一般的寂静，寒气逼人。是等死的人生，一丁点烟火气都没有了，一丁点的人气都没有。这是让人欲哭无泪的景象。


<br>好的小说语言还和读者的记忆有关，有些事读者的脑海里本来就有，但是，没能说出来，因为被你一语道破，你一下子就记住了。好的小说语言你不用有意记忆，只靠无意记忆就记住了。<br>

<br>经常听人讲，小说的节奏、小说的节奏，“节奏”这个东西谁不知道呢？都知道，问题就在于，该上扬的时候，你要有能力把它扬上去，同样，小说到了往下摁的时候，你要有能力摁到底，你得摁得住。<br>

<br>无论是写小说还是读小说，它绝不只是精神的事情，它牵扯到我们的生理感受，某种程度上说，生理感受也是审美的硬道理。这是艺术和哲学巨大的区别，更是一个基本的区别。我们都知道一个词，叫“爱斯泰惕克”，（Athostic）每个人都知道，我们汉语把它翻译成“美学”。<br>

<br>2023/11/30 发表想法
  读兄弟的时候一会儿笑一会儿哭的

原文：无论是写小说还是读小说，它绝不只是精神的事情，它牵扯到我们的生理感受，某种程度上说，生理感受也是审美的硬道理。这是艺术和哲学巨大的区别，更是一个基本的区别。我们都知道一个词，叫“爱斯泰惕克”，（Athostic）每个人都知道，我们汉语把它翻译成“美学”。


<br>苛政为什么猛于虎？猛就猛在这里，孩子都傻了，但你还要去捉促织。这句很无情的话其实就是所谓的现实性。<br>

<br>它反而是不抒情的，有时候甚至相反，控制感情。面对情感，小说不宜“抒发”，只宜“传递”。小说家只是“懂得”，然后让读者“懂得”，这个“懂”是关键。<br>

<br>我想说，就因为“将献公堂，惴惴恐不当意，思试之斗以觇之”，下面的斗蛐蛐才自然，否则就是不自然。这句话是左腿，迈出去了，斗蛐蛐就是右腿，你不迈出去是不行的。这就是小说内部的“势”。<br>

<br>我想说，人的想象有它的局限，有时候，这个局限和想象本身无关，却和一个人的勇气有关。<br>

<br>我说了这么多，真正想说的无非是这一条，在小说里头，即使你选择了传奇，它和日常的常识也有一个平衡的问题。这里头依然存在一个真实性的问题。不顾常识，一味地追求传奇，小说的味道会大受影响。<br>

<br>我们都很熟悉《堂吉诃德》，公认的说法是，小说最为精彩的一笔是堂吉诃德和风车搏斗，如果堂吉诃德挑战的不是风车，而是马车，火车，汽车，我要说，《堂吉诃德》就是一部三流的好莱坞的警匪片<br>

<br>文学需要想象，想象需要勇气。想象和勇气自有它的遥远，但无论遥远有多遥远，遥远也有遥远的边界。无边的是作家所面对的问题和源源不断的现实。<br>

<br>在求知，或者说求真的这个大的背景底下，启蒙运动是向内的，工业革命是向外的。上帝死了，人真的自由了吗？他们的回答更加悲观。他们看到了一个巨大的窘境，人在寻求自我的路上遇到了比魔鬼更加可怕的东西，那就是异化。  
<br><br>
<br>施耐庵在林冲的身上体现出了一位一流小说家强大的逻辑能力。这个逻辑能力就是生活的必然性。如果说，在林冲的落草之路上有一样东西是偶然的，那么，我们马上就可以宣布，林冲这个人被写坏了。<br>

<br>第二，正因为有雪，雪把房子压塌了，林冲才无处藏身，林冲才能离开草料场。某种意义上说，雪在刁难林冲，雪也在挽救林冲，没有雪，林冲的故事将戛然而止。这是不可想象的。<br>

<br>为什么实话实说？陆虞候、富安没能与林冲见面——为什么不能见面？门打不开——为什么打不开？门后有块大石头——为什么需要大石头？风太大。这里的逻辑无限地缜密，密不透风。<br>

<br>风来了，雪来了，林冲的工作被调动了，一切都是按计划走的，一切都是必然。 别林斯基说：“偶然性在悲剧中是没有一席之地的。”这句话说到点子上了。<br>

<br>小说到了这样的地步，即使是施耐庵也改变不了林冲向东走的行为。小说写到作者都无法改变的地步，作者会很舒服的。<br>

<br>我们常说文学是有分类的：一种叫纯文学，一种叫通俗文学。这里的差异固然可以通过题材去区分，但是，最大的区分还是小说的语言。《水浒》是一部打打杀杀的小说，但是，它不是通俗小说和类型小说，它是真正的文学。只有文学的语言才能带来文学的小说。那种一门心思只顾了编制小说情节的小说，都不能抵达文学的高度。没有语言上的修养、训练和天分，哪怕你把“纯文学作家”这五个字刻在你的脑门上，那也是白搭。<br>

<br>审美的心理机制不是凭空产生的，无论是黑格尔还是康德，包括马克思，他们的美学思想里头有两个基本概念我们千万不该忽略，那就是合目的、合规律。说<br>

<br>艺术一旦失去了它的准确性，它就会走向反面，也就是错位。<br>

<br>到了这里我们这些读者彻底知道了，林冲这个人哪，他和造反一点关系都没有，他的身上没有半点革命性。这才叫“逼上梁山”。<br>

<br>说到这里我想做一个小结，我们都喜欢文学作品的思想性，我想说的是，思想性这个东西时常靠不住。思想性的传递需要作家的思想，其实更需要作家的艺术才能。没有艺术才能，一切都是空话。<br>

<br>在美学上，说空话有一个专业的名词，叫“席勒化”，把思想性落实到艺术性上，也有一个专业名词，叫“莎士比亚化”，<br>

<br>但写作就是这样，作家的能力越小，他的权力就越大，反过来，他的能力越强，他的权力就越小。<br>

<br>回到《红楼梦》的第十一回。第十一回是从贾敬的寿辰写起的，也就是一个很大的派对。在小说里头，描写派对永远重要。<br>

<br>我想说，派对其实很不好写，场面越大的派对越不好写，这里的头绪多、关系多，很容易流于散漫，很容易支离破碎。但是，如果你写好了，小说内部的空间一下子就被拓展了，并使小说趋于饱满。<br>

<br>他诗兴大发，浓墨重彩，用极其奢华的语言将园子里美好的景致描绘了一通。突然，笔锋一转，他写道：凤姐儿正自看院中的景致，一步步行来赞赏。上帝啊，这句话实在是太吓人了，它完全不符合一个人正常的心理秩序。<br>

<br>就像中国画，在我们的画面上，经常就“不画”了，不要小看了那些“飞白”，它们太讲究了，它们是距离，那可是“上下五千年、纵横八千里”的。我们的“距离”就在这一黑一白之间。  
<br><br>
<br>中国人的传统思维其实有弱者的模式，自己无能为力，那就寄希望于“报应”。<br>

<br>小说是公器。阅读小说和研究小说从来就不是为了印证作者，相反，好作品的价值在激励想象，在激励认知。仅仅从这个意义上说，杰出的文本是大于作家的。读者的阅读超越了作家，是读者的福，更是作者的福。只有少数的读者和更加少数的作者可以享受这样的福。<br>

<br>但我的游戏依然有它的理性依据：今天的中国金钱至上，今天的中国资本垄断，今天的国人太物质，今天的国人很虚荣，今天的国人爱奢侈。换言之，今天的中国和1884年——也就是莫泊桑发表《项链》的那一年——的法国很类似。既然社会背景是相似的，北京的故事和巴黎的故事当然就可以置换。<br>

<br>那么多的官员在那里搞形象工程，动辄损失几个亿、几十个亿，这样的虚荣你不管不顾，你无聊吧？你吃了药再写好不好？你的情感方式不适合做一个作家。<br>

<br>造成中国严重社会问题的因素有许多，恰恰不是女人的虚荣。<br>

<br>拿女人的虚荣来说这么大的事，只能证明你的浅薄与无知。你的理性能力远远达不到写作的要求。<br>

<br>这么好的一篇小说，什么都没动，仅仅替换了几个汉语的姓名，怎么就这样狗血了的呢？<br>

<br>2023/12/07 发表想法
  所以其实我们读书说到底还是了解那个时代那个地方的文化，很多时候我们现在所说的狗血只是因为文化底层的逻辑变了，导致人物的很多行为让读者匪夷所思。

原文：读到的是忠诚，是一个人、一个公民、一个家庭，对社会的基础性价值——也就是契约精神的无限忠诚。


<br>读到的是忠诚，是一个人、一个公民、一个家庭，对社会的基础性价值——也就是契约精神的无限忠诚。<br>

<br>契约的精神是在的，它的根基丝毫也没有动摇的迹象。《项链》有力地证明了这一点。<br>

<br>《项链》里的契约精神一点也不复杂，那就是“借东西要还”。这不是哲学的理念，而是生命的实践。<br>

<br>契约社会里，对一个“正常”的人来说，契约精神已不再是一种高高在上的国家意识形态，而是公民心理上的一个常识，是公民行为上的一个准则。<br>

<br>2023/12/07 发表想法
  我感觉这种默认的常态就像中国古代的礼一样，这些常态就跟吃饭喝水一样。我们现在也有我们这个时代默认的常态。

原文：契约社会里，对一个“正常”的人来说，契约精神已不再是一种高高在上的国家意识形态，而是公民心理上的一个常识，是公民行为上的一个准则。


<br>2023/12/07 发表想法
  我看曹刿论战时就觉得里面打仗前还要击鼓告诉对方我要攻打了很奇怪。但那是那个时代所提倡的信，是精神上的常态。就跟如今的人从小到大灌输的竞争就是常态，理性就是常态一样。

原文：可以说，离开了契约精神作为精神上的背景、常识上的背景，无论其他的背景如何相似，《项链》这部小说都不足以成立，它的逻辑将全面崩溃。


<br>可以说，离开了契约精神作为精神上的背景、常识上的背景，无论其他的背景如何相似，《项链》这部小说都不足以成立，它的逻辑将全面崩溃。<br>

<br>2023/12/07 发表想法
  这又回到悲剧的必然性上去了，任何悲剧一定不是因为巧合，它一定源于某种时代的必然。

原文：契约精神是全体民众的集体无意识，在路瓦赛夫妇的身上，这种集体无意识在延续，最关键的是，它在践行。正因为他们的“践行”，《项链》的悲剧才得以发生，《项链》的悲剧才成为可能，《项链》的悲剧才能够合理。


<br>契约精神是全体民众的集体无意识，在路瓦赛夫妇的身上，这种集体无意识在延续，最关键的是，它在践行。正因为他们的“践行”，《项链》的悲剧才得以发生，《项链》的悲剧才成为可能，《项链》的悲剧才能够合理。<br>

<br>非常遗憾，敬爱的莫泊桑先生，你全力描绘了马蒂尔德的虚荣，你全力描绘了命运对马蒂尔德的惩戒，但是，为了使得《项链》这部小说得以成立，吊诡的事情终于发生了，你不经意间塑造了另一个马蒂尔德：负责任的马蒂尔德和有担当的马蒂尔德。<br>

<br>我喜欢“心慈”“手狠”的作家。鲁迅就是这样。“心慈”加“手狠”大概可以算作大师级作家的共同特征了。用李敬泽的说法，写到关键的地方，“作家的手不能抖”。李敬泽说得对。是的，你的“手”不能“抖”。你“手抖”了，小说就会摇晃，小说就会失去它的稳固和力量。小说家是需要大心脏的。在虚拟世界的边沿，优秀的小说家通常不屑于做现实伦理意义上的“好人”。<br>

<br>2023/12/07 发表想法
  这没办法，自从市场经济引入，即使愿景是好的，市场也会把人推向效率至上，竞争至上，推向成王败寇的帝国主义。

原文：我对耐心这个东西特别敏感。之所以敏感是因为我有一个发现，这个发现想必朋友们都会同意，当代的中国是没有耐心的。我们热衷于快。我们喜爱的是“时间就是金钱，效益就是生命”。这太滑稽了，这个振奋了我们几十年的判断伤害了我们这个民族，它让高贵的生命变得粗鄙，直接就是印钞机上吐出来的印刷品。我们人心惶惶，我们争先恐后，我们汗流浃背，我们就此失去了优雅、淡定、从容和含英咀华般的自我观照。没有耐心，极大地伤害了我们这个民族的气质。


<br>我对耐心这个东西特别敏感。之所以敏感是因为我有一个发现，这个发现想必朋友们都会同意，当代的中国是没有耐心的。我们热衷于快。我们喜爱的是“时间就是金钱，效益就是生命”。这太滑稽了，这个振奋了我们几十年的判断伤害了我们这个民族，它让高贵的生命变得粗鄙，直接就是印钞机上吐出来的印刷品。我们人心惶惶，我们争先恐后，我们汗流浃背，我们就此失去了优雅、淡定、从容和含英咀华般的自我观照。没有耐心，极大地伤害了我们这个民族的气质。<br>

<br>2023/12/07 发表想法
  这里有个问题，如果按一个奢侈品要十年收入，那么无产阶级没有能力消费奢侈品，资产阶级才能消费奢侈品。健康的社会不应该存在只有一个阶级能消费的东西。资产阶级创造的财富是无法匹配他们获得的财富的。

原文：健康的、美好的社会不是不可以有奢侈，可以，但是，只能是少部分奢侈；健康的、美好的社会也不是不可以有贫穷，可以，但是，只能有少部分贫穷。


<br>2023/12/07 发表想法
  那如果在假的大环境下写真是不是也能达到同样的效果。

原文：那就是真。从接受心理的角度来说，“假”在什么条件下才会使人吃惊？很简单，“真”的环境。同样，如果环境里头到处充斥着“假”，或者说，整个环境都是“假”的，那么，这个“假”将失去它的冲击力、爆发力和震撼力。


<br>那就是真。从接受心理的角度来说，“假”在什么条件下才会使人吃惊？很简单，“真”的环境。同样，如果环境里头到处充斥着“假”，或者说，整个环境都是“假”的，那么，这个“假”将失去它的冲击力、爆发力和震撼力。<br>

<br>2023/12/07 发表想法
  我觉得这里对存在主义理解有误，并非闹鬼反而是真。存在主义强调个体存在先于意义。即人先是存在然后再去找寻意义，而不是为了某种意义而存在。世俗大众对局外人感到荒谬，而局外人面对为了意义而存在的世俗大众更感到荒谬，他是不认可世俗所赋予人的意义的，所以他母亲死他也不会悲伤。

原文：，《局外人》并不类属于现实主义，它是存在主义的代表作。存在主义的关键词是什么？荒谬。荒谬的世界是颠倒的世界，“假”盘踞在生活的中央，闹鬼的反而是“真”。


<br>“真”会使我们平静、愉悦，而“假”则会给我们带来震惊与恐慌。  
<br><br>
<br>一个诗人，沃滋沃斯，他穷困潦倒，以讨乞为生，一直梦想着完成他最伟大的诗篇，而最终，他孤独地死去了。——这就是《布莱克·沃滋沃斯》，是《米格尔大街》的第六篇。<br>

<br>小说的魅力就在这里，麻烦的地方你处理好了，所有的麻烦将闪闪发光。<br>

<br>只要铺垫到了，无论沃滋沃斯怎么“特殊”，他在小说里头都不会显得太突兀、太做作。<br>

<br>奈保尔是怎么铺垫的？在沃滋沃斯出场之前，他一口气描写了四个乞丐。这四个乞丐有趣极了，用今天的话说，个个都是奇葩。等第五个乞丐——也就是沃滋沃斯——出场的时候，他已经不再“特殊”，他已经不再“突兀”，他很平常。这就是小说内部的“生活”。<br>

<br>铺垫的要害是什么？简洁。作者一定要用最少的文字让每一个奇葩各自确立。要不然，等四个人物铺垫下来，铺垫的部分将会成为小说内部巨大的肿瘤，小说将会疼死。我要说，简洁是短篇小说的灵魂，也是短篇小说的秘密。<br>

<br>“来讨他的那份钱”只描写了一个讨乞的动作，而“来取走他的那一分钱”，却有了一个乞丐的性格塑造，<br>

<br>美学上把“寓谐于庄”叫作滑稽。<br>

<br>内容大于形式叫悲壮。——内容太大，太强，太彪悍，形式裹不住内容了，形式就要撕裂，就要破碎，火山就要爆发，英雄就得牺牲，这就是悲壮，一般来说，悲壮的英雄都是在面临死亡或业已死亡的时候才得以诞生；<br>

<br>猴子的脑袋不够大，人类的帽子不够小，这就沐猴而冠了。<br>

<br>我常说，说实话、不吹牛不只是一个道德上的问题，它首先是一个美学上的问题。<br>

<br>老实说，一看到“金鸡独立”这四个字我就闹心。无论原作有没有把女主人公比喻成“一只鸡”，“金鸡独立”都不可取。它伤害了小说内部的韵致，它甚至伤害了那位女主人公的形象。——我说这话需要懂外语么？不需要的<br>

<br>“我想看看你们家的蜜蜂。”<br>

<br>我不知道别人是怎么看待这一段的，这一段在我的眼里迷人了，一个潦倒到这个地步的人还如此在意生活里的美，还急切地渴望他人来分享美，它是鼓舞人心的。<br>

<br>审美是每一个人的事，在许多时候，当事人自己不知道罢了。审美的背后蕴藏着巨大的价值诉求，蕴藏着价值的系统与序列。可以这样说，一个民族和一个时代的质量往往取决于这个民族和这个时代的审美愿望、审美能力和审美水平。如果因为贫穷我们在心理上就剔除了美，它的后果无非就是两条：一、美的麻木；二、美的误判。<br>

<br>正如余华在《活着》的韩文版序言里所说的那样，它证明了“绝望的不存在”。它生机勃勃，有滋有味，荡气回肠，一句话，审美从未缺席。<br>

<br>你看看沃滋沃斯，都潦倒成啥样了，讨饭都讨不着，他在意的依然是一棵树的姿态。<br>

<br>天哪，难怪沃滋沃斯要在那里等待孩子，难怪他要请孩子去看芒果树，难怪他要让孩子去吃芒果，这一切都是因为他的爱情。他要看着孩子吃掉那些“红彤彤”的芒果，他要看着蜜汁一样黏稠的果汁染红孩子的“衬衫”。<br>

<br>看出来了吧，奈保尔对爱情的描绘绝对不是短短的九行，从“等待”就开始了。<br>

<br>也许我还要补充一点，在文学这个问题上，我们一定要祛魅，不要刻意地神化天赋。神化天赋是一些人的虚荣心在闹鬼，别信。你们要相信我，天赋是可以发掘的，天赋也是可以生长的，直到你吓了自己一大跳。<br>

<br>对话其实是小说内部特别具有欺骗性的一种表述方式，<br>

<br>听了这番话我很高兴。我在实践中很早就意识到对话的不易了，——对话是难的，仔细想一想就能明白其中的道理了，这里头有一个小说人物与小说语言的距离问题。<br>

<br>描写和叙述是作家的权力范围之内的事，它们呈现着作者的语言风格，它离作家很近，离小说里的人物反而远。对话呢？因为是小说人物的言语，是小说的人物“说”出来的，这样的语言和小说人物是零距离的，它呈现的是小说人物的性格，恰恰不是作家个人的语言风格，作家很难把控，它其实不在作家的权力范围之内。<br>

<br>许多作品如此热衷于对话，并不是因为作者的对话写得好，而是因为作者在叙事与描写方面不过关，没才能，怕吃苦，想偷懒，回头一想，嗨，那就用对话来替代吧，多省事呢。这样的对话其实不是对话，而是规避描写与叙事。老实说，我至今都看不上从头到尾都是对话的小说。从头到尾都采用对话，写写通俗小说是可以的，纯文学肯定不行，纯文学有它的难度要求，对对话也有特殊的要求。<br>

<br>2023/12/08 发表想法
  这里的基本面指的是什么

原文：无论阅读什么样的小说，哪怕是现代主义小说，我们首先要找到小说的一个基本面。这个基本面是由小说的叙事时间和小说的叙事空间来完成的。


<br>无论阅读什么样的小说，哪怕是现代主义小说，我们首先要找到小说的一个基本面。这个基本面是由小说的叙事时间和小说的叙事空间来完成的。<br>

<br>对小说来说，人物是目的，但是，为了完成这个目的，依仗的却是关系。关系没有了，人物也就没有了。关系与人物是互为表里的。<br>

<br>完形心理学向我们揭示了一个认知上的惊天大秘密，那就是，我们在认知的过程中，始终存在一个次序的问题：先整体，后局部。<br>

<br>你只要把大脑袋上的眼神、表情给说好了、说生动了、说准确了、说具体了，永远也不要担心读者追着你去讨要人物的大腿、小腿和脚丫子。——非故事类的短篇就是这样，结构完完整整的，未必好，东一榔头西一棒，未必就不好。  
<br><br>
<br>其实，短篇小说是要放在短篇小说集里头去阅读的。一个小说家的短篇小说到底怎么样，有时候，单篇看不出来，有一本集子就一览无余了。举一个例子，有些短篇小说非常好，可是，放到集子里去，你很快就会发现这个作家有一个基本的套路，全是一个模式。你可以以一当十的。这就是大问题。好的短篇集一定是像《呐喊》这样的，千姿百态，但是，在单篇与单篇之间，又有它内在的、近乎死心眼一般的逻辑。<br>

<br>在鲁迅看来，中国是这样的一个国家，人人都信奉“沉默是金”。一个人得了癌症了，谁都知道，但是，谁都不说，尤其不愿意第一个说。这就是鲁迅所痛恨的“和光同尘”。“和光同尘”导致了一种环境，或者说文化，那就是“死一般的寂静”。就在这“死一般的寂静”里，鲁迅用非常正常的音量说一句“你得了癌症了”，它是“于无声处听惊雷”。很冷静。这才是鲁迅式的呐喊，——鲁迅的特点不是嗓子大，是“一语道破”，也就是“一针见血”，和别人比音量，鲁迅是不干的。<br>

<br>面对一个呐喊者，我们应当感受到呐喊者炙热而又摇晃的体温，但是，读《呐喊》，我们不仅感受不到那种炙热而又摇晃的体温，相反，我们感到了冷。<br>

<br>通常，一个小说家需要很长时间的实践才能培育起自己的语言风格，更不用说美学模式了，鲁迅一出手就做到了。<br>

<br>如果我们对鲁迅有一个整体性的、框架性的阅读，结论是显性的，鲁迅的基础体温着实非常高。但是，一旦遇上小说，他的小说温度突然又降下来了。这是一个触目惊心的矛盾。<br>

<br>2023/12/09 发表想法
  热风里的一段，鲁迅体温是非常高的。愿中国青年都摆脱冷气，只是向上走，不必听自暴自弃者流的话。能做事的做事，能发声的发声。有一分热，发一分光，就令萤火一般，也可以在黑暗里发一点光，不必等候炬火。 此后如竟没有炬火：我便是唯一的光。倘若有了炬火，出了太阳，我们自然心悦诚服的消失。不但毫无不平，而且还要随喜赞美这炬火或太阳；因为他照了人类，连我都在内。

原文：如果我们对鲁迅有一个整体性的、框架性的阅读，结论是显性的，鲁迅的基础体温着实非常高。但是，一旦遇上小说，他的小说温度突然又降下来了。这是一个触目惊心的矛盾。


<br>作为一个读者，我的问题是，什么是鲁迅的冷？我的回答是两个字，克制。<br>

<br>现实主义和象征主义最大的区别就在一个基本点上，看它有没有隐喻性，或者说，延展性。通俗地说，现实主义是由此及此的，象征主义则是由此及彼的，——言在象，而意在征。<br>

<br>鲁迅先生对象征主义手法的运用，在《药》这个小说里头几乎抵达了顶点。正因为如此，在《呐喊》里头，《药》反而有缺憾，它太在意象征主义的隐喻性了，它太在意“象”背后的那个“征”了。所以，《药》是勉强的。包括小说的名字。可以说，《药》的不尽人意不是现实主义的遗憾，相反，是象征主义的生硬与局限。<br>

<br>先生用当时根本就“不算文学”的“小说”把自己“改写”了一遍，同时，也用白话把自己“翻译”了一遍。可以这样说，为了启蒙，先生放下了身段，来了一次“二次革命”，这才有了我们所知道的鲁迅。请听清楚了，——在鲁迅的时代，尤其是，以鲁迅的身份，做“小说家”可不是一件光荣的事情，连体面都不一定说得上。小说是写给谁读的？是给鲁迅妈妈那样的、“识字”的人读的。这一点我们一定要明白，不明白这个，我们根本就无法了解鲁迅，更无法了解鲁迅的小说。<br>

<br>鲁迅的小说可以当作“史诗”去读，但鲁迅个人偏偏不喜欢“史诗”。即使和茅、和巴、和老、和曹比较起来，鲁迅小说的切口也要小很多。<br>

<br>说到这里一切都简单了，小切口的小说必然在意一个东西，那就是它的延展性，也就是它的隐喻性，换句话说，鲁迅的小说必然会偏向于象征主义。<br>

<br>卡夫卡在意的是人类性，而鲁迅在意的则是民族性。<br>

<br>这里头没有高下之分。面对文学，我们不能玩平面几何，以为人类性就大于民族性，这是说不通的。请注意，考量一个小说家，要从它的有效性和完成度来考量，不能看命题的大小。<br>

<br>“豆腐西施”和“圆规”这两个绰号不只是有趣，还有它内在的逻辑性，其实是发展的，不要小看了这个发展，它其实替代了短篇小说所欠缺的性格发育。<br>

<br>鲁迅一生都在批判劣根性，这是他对国民性的一种总结。这个劣根可以分为两个部分：强的部分和弱的部分。强的部分就是鲁迅所憎恨的流氓性，弱的部分则是鲁迅所憎恨的奴隶性。<br>

<br>这一来，“圆规”这个词和科学、和文明就完全不沾边了，成了另一种意义上的愚昧与邪恶。杨二嫂和“圆规”之间哪里有什么神似？一点都没有。这就是反讽的力量。一种强大的爆发力。可<br>

<br>这一来，作者的书写角度就确定了，这就保证了对杨二嫂的描写就不再是客观描写，而成了“我”的主观感受。换句话说，“圆规”这个词并不属于杨二嫂，只属于“我”。——你去喊杨二嫂“圆规”，她不会答应你的，她不知道“圆规”是什么，她不能知道。就是这么一个角度的转换，“圆规”，这个不兼容的语词即刻就兼容了，一点痕迹都没有。<br>

<br>鲁迅先生为什么一反常态，要抒情？要诗意？他的用意一目了然了。在这里，所有的抒情和所有的诗意都在为小说的内部积蓄能量，在提速，就是为了撞击“老爷”那座冰山。这个撞击太悲伤了、太寒冷了，是文明的大灾难和大事故。在这里，我有六点需要补充——<br>

<br>第一，奴性不是天然的，它是奴役的一个结果。<br>

<br>这个黑洞里全部的内容，就是闰土如何被奴役、被异化的<br>

<br>小说家鲁迅的价值并不在于他说出了人人都不知道的东西，而是说出了大家都知道、但谁也不肯说的东西！<br>

<br>，小说一旦失去了对闰土自然性的描绘，鲁迅就无法体现“奴性是奴役的结果”这个基本的思想。<br>

<br>伏尔泰在总结启蒙运动的时候说过一句极为重要的一句话，什么是启蒙？就是“勇敢地使用你的理性”。<br>

<br>理性能力强不强其实不重要，重要的是，我有没有“勇敢地”去使用我的理性。<br>

<br>闰土的搬运的速度之快甚至是迅雷不及掩耳的，“我”都来不及左转舵和右转舵。为什么？那是闰土的本能，那是一个奴才的本能。<br>

<br>什么是“懂事”？答案很清晰，“懂事”就是喊“老爷”，就是选择做奴才，——做“做稳了”的奴才，或者说，做“做不稳”的奴才。在鲁迅的眼里，奴役的文化最为黑暗的地方就在这里：它不只是让你做奴才，而是让你心甘情愿地、自觉地选择做奴才，就像鲁迅描写闰土的表情时所说的那样。<br>

<br>这两个词就是奴才的两只瞳孔：欢喜，凄凉。<br>

<br>伟大的作家有他的硬性标志，他的伟大伴随着读者的年纪，你在每一个年龄阶段都能从他那里获得新的发现，鲁迅就是这样的作家。<br>

<br>某种程度上说，中国现代文学就是抒情的文学，中国现代文学就是向大众“示爱的文学”。鲁迅爱，但鲁迅是唯一一个“不肯示爱”的那个作家。<br>

<br>我想说，一部中国的现代文学史，其实是由两个部分组成的：一个部分是鲁迅，一个部分是鲁迅之外的作家。在我的眼里，鲁迅和他同时代的作家，同质的部分是有的，但是，异质的部分更多。<br>

<br>可是，有两个人物始终没有照应起来，那就是杨二嫂和闰土。他们的关系是重要的，他们就是人民与人民的关系。很不幸，他们的关系是通过杨二嫂的告密而建立起来的，可见人民与人民并不是当然的朋友。他们的关系要比我们想象得还要复杂、还要深邃。  
<br><br>
<br>在小说的陈述句里，陈述句的主语绝大部分都是人物的名字。这个是很好理解的。但是，太多的人名会让小说的陈述不堪重负，小说也会显得特别傻。所以呢，代词出现了，也就是他，她，他们，她们。是代词让小说的陈述变得身轻如燕的。<br>

<br>但代词也有它天然的缺陷，那就是代词的不确定性。<br>

<br>2023/12/09 发表想法
  我一直以为默认代指最近的

原文：作者突然冒出一个“他”来，——这对我们读者来说简直就是灾难，“他”是张三？李四还是王二？这就需要我们慢慢地读下去，回过头来再去找。这是一份额外的附带，同时也是一份没有任何美学价值的负担。


<br>海明威的小说有一个特点，喜欢对话，这个我们都知道。海明威的小说还有另外的一个特点，简洁，能省则省。如果把这两个问题合而为一，我们很快就会发现，在海明威的小说里头，对话往往没有名字，就是对话本身。我想说，这是海明威的伎俩，读他的短篇小说你是不能一目十行的，他想拖住你。<br>

<br>任何一部好作品都有它的言外之意，都不可能只保留在字面上，从这个意义上说，海明威其实一点也不特殊。<br>

<br>在《杀手》里，海明威是站在杀人者的角度去描写的，这是海明威的一个特点，他喜欢站在更强的那一边。这是由一个作家的性格决定了的，甚至是由一个作家的身体条件决定了的。你让卡夫卡这样写，我估计卡夫卡会晕过去，我们能做的就是帮卡夫卡掐人中。<br>

<br>简洁重要，简洁不容易。我想这样说，简洁不仅仅是一个语言上问题，它关系到一个作家的心性，一个作家的自信心。啰唆其实都是由胆怯带来的，他惧怕读者读不懂，他要解释。——判断一个小说家的能力，是否简洁是一个最好的入口。<br>

<br>无比简洁的海明威偏偏就写了一句废话。——这个废话就不再是废话，反而高级了。这句废话就是“冰山”，有太多的东西藏在“水下”了。是什么？是环境，它让人魂不守舍。<br>

<br>什么叫学习写作？说到底，就是学习阅读。你读明白了，你自然就写出来了。阅读的能力越强，写作的能力就越强。所以我说，阅读是需要才华的，阅读的才华就是写作的才华。人家的小说好在哪里你都看不出来，你自己反而能把小说写好，这个是说不通的。<br>

<br>我常说，写小说的不可能是贵族，小说家是蓝领，干的是体力活、手工活，干的是耗心费血的活。好作家哪有那么容易？你要靠百分之九十九的心血才能把你百分之一的才华送到金字塔的塔尖。<br>

<br>这个“紧凑”绝对不是你坐在那里苦思冥想的结果，不是。它需要一个作家惊人的直觉。直觉是小说家最为重要的才华之一，也是一个作家最为神奇的才华之一。老实说，直觉也许真的就是天生的，它很难培养。但是，如果你有一个良好的阅读习惯，能够读到普通读者读不到的东西，你的直觉会得到历练，慢慢地变得敏锐。<br>

<br>你会疑惑：他的运气怎么就那么好？其实，这和直觉有关，他知道关键的那个点在哪儿，所谓的运气只是一个表象罢了。  
<br><br>
<br>2023/12/10 发表想法
  这剧情

原文：常不过的爱情成了标准的“不伦之恋”。为了阻止“儿子”郭左爱上自己的妹妹，玉米以不经意的方式把玉秀被轮奸的事情告诉了郭左，绝望之中的郭左强奸了玉秀。玉秀也怀孕了。未婚先孕的玉秀在小镇上成了千夫所指的烂货。玉秀一烂到底，哪个女人得罪了自己，她就勾引哪个女人的丈夫。


<br><br>
<br>从结构上说，周作人的许多作品在主体的部分都是“跑题”的，他的文章时常跑偏了。眼见得就要文不对题了，都要坍塌了，他在结尾的部分来了小小的一翘，又拉了回来。这不是静态平衡，是一种动态的平衡，很惊险，真是风流倜傥。<br>

<br>这样的文人和严格意义上的知识分子是有区别的，他讲究的是腔调和趣味，而不是彼岸、革命与真理。<br>

<br>他平和、冲淡、日常，在美学的趣味上，这是有传承的，也就是中国美学里头极为重要的一个标准，那就是“雅”<br>

<br>雅”其实就是中庸。<br>

<br>“雅”则是“中庸”这个意识形态在美学上的具体体现。<br>

<br>关于小说的开头，格雷厄姆说过一句话：“对小说家来说，如何开头常常比如何结尾更难把握。”为什么难把握？这里头就涉及小说阅读的预期问题。<br>

<br>在“和尚”这个词出现之前，汪曾祺一口气罗列了六种职业，其实有点啰唆。但是，这个啰唆是必须的。这个啰唆一下子就把“和尚”的神圣给消解了。这里的“和尚”突然和宗教无关了，和信仰无关了，它就是俗世的营生，干脆就是一门手艺。<br>

<br>汪曾祺偏偏把这两个职业搅和在一起，这两个词的内部顿时就形成了一种巨大的价值落差——正是这个巨大的价值落差让你们笑出声来的。<br>

<br>他只是“会心”，他也能让读者“会心”，那是体量很小的一种幽默，强度也不大。我个人以为会心比幽默更高级，幽默有时候是很歹毒的，它十分地辛辣，一棍子能夯断你的骨头；“会心”却不是这样，会心没有恶意，它属于温补，味甘，恬淡，没有绞尽脑汁的刻意。不经意的幽默它更会心。<br>

<br>附带提醒大家一下，要小心幽默。如果你是一个幽默的人，你自然可以尽情地挥洒你的智慧，就像莫言那样。如果你不是，你最好不要随便追求它。<br>

<br>幽默是公主，娶回来固然不易，过日子尤为艰难，你养不活她的。<br>

<br>汪曾祺一本正经地告诉读者：“他是吃斋的，过年时除外。”说一个资深的和尚是“吃斋的”，过年的时候还要除外，你说，这样的正经是多么会心。<br>

<br>方丈”是什么意思？一方见长，一方见宽，是很小的地方，也就是领导的住处。<br>

<br>小说家往往喜欢两件事：一、理直而气不壮；二、理不直而气壮。这里头都是命运。<br>

<br>到了那个年纪你才能笑看云淡风轻，关键是，你才肯原谅。只有原谅了生活、原谅了人性的作家才能写出这样会心的语言。<br>

<br>如果作者和读者都不懂得原谅，老实说，这个地方会变得龌龊。相反，如果你通了，这些地方就很有喜感。<br>

<br>“谁是我们的朋友，谁是我们的敌人”，这个问题是汪曾祺必须面对的一个首要问题，——这是中国的问题，当然也是中国当代文学的问题，更是中国作家必须面对的问题。 汪曾祺面对了这个问题，他回答了这个问题：他的眼里却没有阶级和阶级斗争，没有好人和坏人，没有敌人和朋友。汪曾祺的眼里只有人，只有人的日常生活。由斯，汪曾祺向我们提供了他的立场，那就是基本的人道主义立场。<br>

<br>汪曾祺和雨果很像，他们的眼里都没有所谓的“坏人”，哪怕他们有毛病，甚至有罪恶，他们也是可以宽恕的。<br>

<br>他所描绘的庙宇生活是假的，他所描写的僧侣也是假的，他并没有涉及宗教和宗教的精神。那些和尚都是日常生活里的人，都是民间社会里的普通人，都是这些普通人的吃、喝、拉、撒。<br>

<br>他是不批判的，他是不谴责的，他更不是憎恨的。他中立。他没有道德优势，他更没有真理在握。因为小说人物身份的独特性，汪曾祺只是带上了些许的戏谑。既然你们的身份特殊，那就调侃你们一下，连讽刺都说不上。<br>

<br>把宗教生活还原给了“日常”与“生计”，这是汪先生对中国文学的一个贡献。要知道，那是在1980年。在1980年就能有这样的看法与态度，那是很了不起的。从这个意义上说，汪曾祺也是反对“伪崇高”的，在这一点上，后来的王朔和汪曾祺似乎很像，其实又不像。<br>

<br>汪曾祺否认的是彼岸，却坚定不移地坚守了此岸。他是热爱此岸的，他对现世有无限的热忱。王朔呢？他是把彼岸和此岸一股脑儿给端了。汪曾祺说那些人是“正经人”，是戏谑，也是原谅，也是认同，否则就是讽刺与挖苦了。在汪曾祺的眼里，他们真的就是“正经人”，是有毛病的正经人<br>

<br>我们会感受到庙宇生活的不堪，甚至是脏。那显然不是汪曾祺想要的。是戏谑消解了这种不堪，是戏谑消解了这种脏。戏谑表面上是语言的风格，骨子里是价值观：我不同意你，但是，我允许你的存在，我不会把你打倒在地，再踏上一只脚<br>

<br>对小说家来说，语言风格不仅仅是语言的问题，它暗含着价值观，严重一点说，也许还有立场。<br>

<br>以做一个语言实验，把《受戒》拿出来，大声地朗诵。只要你朗诵出来了，你自己就可以感受得到那种内在的韵律，潇洒，冲淡，飘逸，自由，微微地有那么一丝骄傲。<br>

<br>汪曾祺并不傲慢，在骨子里却是骄傲的。<br>

<br>汪曾祺的腔调就是业已灭绝的文人气，就是业已灭绝的士大夫气，这种气息在当今的中国极为稀有。补充一句，汪曾祺的腔调你们年轻人千万不能学，你学不来。我说过一句话，汪曾祺是用来爱的，不是用来学的，道理就在这里。<br>

<br>汪曾祺是一个可爱的作家，一个了不起的作家，却不是一个伟大的作家。我这样说丝毫也不影响汪曾祺的价值。我们热爱鲁迅，需要鲁迅，我们也需要汪曾祺。我说过，汪曾祺是文人，不是知识分子。这是汪曾祺的特征，也是汪曾祺的局限。<br>

<br>无论风云怎样变幻，人类的日常它坚不可摧，哪怕炮火连天，吃总要吃，睡总要睡，爱总会爱，孩子也还是要生。城可倾，爱不可倾，这就是张爱玲的孤岛哲学和孤岛史观，这是一种偷生的哲学，汪曾祺的身上多多少少也有这种哲学。——衰败的大时代、精致的小人物。<br>

<br>所以说，作家的才华极其重要。才华不是思想，但是，才华可以帮助作家逼近思想。这正是艺术和艺术家的力量，文学是人类精神不可或缺的一个维度。<br>

<br>汪曾祺的背后站立着一个人，那个人就是陶渊明。假如我们愿意，还可以把话题拉得再远一点，汪曾祺的背后其实还有人，那就是老庄，他受老庄的影响的确是很深的。<br>

<br>2023/12/10 发表想法
  小农经济导致的小国寡民思想。这在毛泽东时代就很少了，因为人民被联合在了一起。但是如今时代又开始兴起，我觉得是信任危机和个人主义兴盛导致的。

原文：《受戒》的第二章到底写了什么？是小英子的一家的世俗生活。它不是乌托邦。它是“小国寡民”，是所谓的“净土”。中国是一个人口大国，人口的大国在美学的趣味上反而向往“小国寡民”，这一点非常有意思。


<br>《受戒》的第二章到底写了什么？是小英子的一家的世俗生活。它不是乌托邦。它是“小国寡民”，是所谓的“净土”。中国是一个人口大国，人口的大国在美学的趣味上反而向往“小国寡民”，这一点非常有意思。<br>

<br>作为一个文人，他感兴趣的是乱世之中“小国寡民”的精致人生：安逸，富足，祥和，美好。可以说，在任何时候，“美”和“诗意”一直是汪曾祺的一个兴奋点。他在意的是乱世之中的“天上人间”。<br>

<br>2023/12/10 发表想法
  教员发动文革时错估了党内修正主义和走资派比例，导致文革的落实出现了极大的问题，红卫兵故意在文革落实的时候走极左路线，搞四清搞消灭所有传统文化，打着红旗反红旗，导致传统文化的断层和人民群众对中央的质疑，这是政治斗争的牺牲品，与秦始皇焚书坑儒一样。但如果教员发动文革时间再早一些，或许如今就不是这样了。

原文：道理很简单，在1980年，能写出《受戒》这种作品的中国作家没几个。我们传统文化的底子薄，写不出来的。


<br>道理很简单，在1980年，能写出《受戒》这种作品的中国作家没几个。我们传统文化的底子薄，写不出来的。<br>

<br>你给我出来！”小说的人物就出来了。不能那样。小说里的人物都是有文学尊严的，你做作家的必须把人家给请出来。如果你是一个不好的作家，小说人物会听你的；可是，如果你是一个好作家，小说人物在什么时候出场，这就要商量。<br>

<br>但问题是，第一章写的是庙宇，如何才能把小英子给“请”出来呢？这才是“写”小说的关键。——让小英子来烧香？然后，让小英子和小沙弥眉来眼去的？可不可以？当然可以。但是，那是多么猥琐。汪曾祺他怎么可能猥琐呢。<br>

<br>好小说要经得起分析，但作家在写作的时候是不会这样分析的。在写作的时候，小说家主要靠直觉。他的直觉会让他自然而然地那样写，回过头去一分析，我们会发现作家的直觉原来是如此精确。<br>

<br>我一直强调，多次强调，直觉是小说家最为神奇的才华，直觉也是小说家最为重要的才华。在作家所有必备的素质当中，唯一不能靠后天培养也许就是直觉。直觉没有逻辑过程，没有推理的过程，它直接就抵达了结果，所以它才叫直觉。所以，写小说没有大家想象得那<br>

<br>在写作的过程中，思考极为重要，但思考往往不能带来快乐，是不断涌现的直觉给作家带来了欣喜，有时候，会欣喜若狂。这是写作最为迷人的地方。<br>

<br>2023/12/10 发表想法
  对于肉欲的描写有一种汪曾祺自带的那种仙气。这里让我一次闪过言叶之庭男主给女主在雨中量脚的那一段画面，也是描写肉欲，也是有一种含蓄的美。我真感觉日本的文化有一点传承了中国的文人气韵，而国内反而这种文人气韵失传了。

原文：过小英子和明子的脚，很肉欲的。——问题是，把肉欲放在哪里写比较好呢？庙宇还是大自然？当然是大自然。所以，小和尚的故事一定要出现在世俗生活里头。


<br>过小英子和明子的脚，很肉欲的。——问题是，把肉欲放在哪里写比较好呢？庙宇还是大自然？当然是大自然。所以，小和尚的故事一定要出现在世俗生活里头。<br>

<br>这时的明子已经受戒了，小英子划船接他回去：划了一气，小英子说：“你不要当方丈。” “好，不当。” “你也不要当沙弥尾！” “好，不当。” 又划了一气，看见那一片芦苇荡子了。 小英子忽然把桨放下，走到船尾，趴在明子的耳朵旁，小声地说： “我给你当老婆，你要不要？” 明子眼睛鼓得大大的。 “你说话呀！” 明子说：“嗯。” “什么叫‘嗯’呀，要不要，要不要？” 明子大声地说：“要——！”<br>

<br>2023/12/10 发表想法
  文学的基本面的确在于生活。对思想与社会的思考理应是哲学家社会学家的事。当然小说中总会或多或少涉及思想与价值观，但是重点应该还是对人类生活的观察和记录。

原文：汪曾祺不在意所谓的重大题材，他没兴趣，他也写不动。他有他顽固的文学诉求，那就是生活的基本面。在汪曾祺看来，这个基本面才是文学最为要紧的重大题材。具体一点说，那就是日常，那就是饮食男女。


<br>汪曾祺不在意所谓的重大题材，他没兴趣，他也写不动。他有他顽固的文学诉求，那就是生活的基本面。在汪曾祺看来，这个基本面才是文学最为要紧的重大题材。具体一点说，那就是日常，那就是饮食男女。<br>

<br>它的基本器械与工具就是美。落实到小说的文本上，那就是两条：一、轻逸；二、唯美。<br>

<br>汪曾祺写小说通常不做刚性处理，相反，他所做的是柔性处理。柔性处理就是小说不构成势能，也就是无情节。汪曾祺的小说很有意思的，他很讲究结构，却没有情节。他不需要势能，还要情节干什么呢？说汪曾祺的小说是“散文化”的小说，“汪味小说”，原因就在这里。他根本不需要情节。<br>

<br>懵懂与无知很不好写，这里的分寸感非常难把握。稍不留神你就写砸了<br>

<br>汪曾祺如果这样写，“哥，人家心里头可乱了”。或者这样写，“哥，你怎么也不敢看着我？”这样写可以吗？不可以。轻佻，强度不够，远远不够。<br>

<br>在这个地方，绝不能搞暧昧、绝不能玩含蓄、绝不能留有任何余地。为什么？留有余地小英子就不够直接、不够冒失，也就是不够懵懂、不够单纯。这就是“准童年视角”的好处。<br>

<br>我要说，这一部分纯净极了，十分地干净，近乎通透。通透是需要作家的心境的，同时也需要作家手上的功夫。汪曾祺有一个很大的本领，他描写的对象可以七荤八素、不干不净，但是，他能写得又干净又透明，好本领。<br>

<br>你去卢浮宫看看那尊《胜利女神》，你的目光能透过石头，能透过女神身上的纺织品，直接可以看到女神的腹部，她的肌肤，甚至还有她的肚脐。女神圣洁，却弥漫着女人的性感。这是标准的古希腊精神，人性即神性，神性即人性，它们高度地契合。莎士比亚说，人是“万物的灵长”，注意，他这是第二次、而不是第一次把人放到了神的高度。<br>

<br>第二，在描写少女单纯的同时，我们一定要记住，单纯就是单纯，不是弱智，更不是二百五。汪曾祺不能把小英子写成一个傻□。如果她是傻□，小说的味道又变了。老实说，“我给你当老婆”这句话的强度极大，是孟浪的，如何让孟浪不浪荡，这个又很讲究。汪曾祺是怎么做的？当然是铺垫。<br>

<br>小英子能不能给明海“当老婆”呢？天知道。也许天都不知道。从这个意义上来说，《受戒》这篇小说依然是一个悲剧。它不是荡气回肠的大悲剧，它是一个轻逸的、唯美的、诗意的、令人唏嘘的小悲剧。小说早就结束了，可是，小说留给我们的，不只是鸟类欢快的飞翔，还有伤感的天空，它无边无际。<br>

<br>诗歌到语言为止，从这个意义上说，短篇小说是对诗歌的降低，可是，从另外的一个意义上说，你也可以把它理解成短篇小说是对诗歌的提升，——这取决于你的文学素养，这取决于你的文学才华，这取决于你对自己的要求有多高。  
<br><br>
<br>景”——“段落大意”——“中心思想”更接近小说。  
<br> 来自微信读书<br>]]></description><link>culture\阅读\小说课.html</link><guid isPermaLink="false">Culture/阅读/小说课.md</guid><pubDate>Mon, 01 Jul 2024 07:46:16 GMT</pubDate></item><item><title><![CDATA[新摄影笔记]]></title><description><![CDATA[ 
 <br><br>《新摄影笔记》<br>宁思潇潇<br>
181个笔记<br>序2<br>◆ 如今的摄影有两面，一面是艺术一面是生活，艺术源于生活高于生活，但生活才是最普遍的。我们的摄影想要在大众中间普及，我认为现在最需要的不是摄影技艺的普及，而是摄影最基础的“科普”工作。<br>前言<br>◆ 摄影就是记录下您到达并发现的、触动您内心的场景及瞬间。<br>◆ 这应该是您的第一个目标——有感而拍。这也是我们说的照片要有主题，而好照片自然有一个好的主题。就如同我们写作文一样，小学时让您先确定中心思想，中学时要您明确文章主旨。伟大的文学作品，自然也是有一个鲜明的主题的。艺术总是相通的。<br>◆ 看到一对情侣在接吻。这个瞬间着实打动了我，于是我举起相机连拍了3张照片。最后一张照片为两人接吻完，脸分开一点儿。这能让人更好地看到女孩脸上幸福的表情，更能表达当时给我的温馨的感受。这样的瞬间是很打动人的。<br>◆ 摄影就是记录下您到达并发现的、触动您内心的场景及瞬间。<br>◆ 1　什么是取景取景决定了画面中有什么元素，以及这些元素以什么样的状态出现。[插图]<br>◆ 取景时我们要注意取景内容、取景范围、取景时机及取景角度。取景决定了画面中有哪些元素，以及画面中每个元素的状态。取景将是您在摄影中需要一直学习的内容，是最难的和最重要的。<br>◆ 曝光简单说就是一张照片的明暗。说的复杂一点，就是控制照片中各个元素的色彩与明暗。<br>◆ 在很多照片中，我们都可以看到“虚实结合”。这个就是有关虚实的技巧了。利用这个技巧，我们可以决定哪些元素是清晰的、哪些元素是模糊的。<br>◆ 但是虚实不仅限于此，运动的物体在慢速快门的拍摄下，也会呈现虚化的效果。所以虚实不仅仅是“大光圈”，还有其他方法可以实现。<br>◆ 构图主要决定元素摆放在画面中的什么位置。<br>◆ 对于构图，我们要学会通过构图来使画面看着舒服，或者使其他要表达的内容符合照片主题。<br>◆ [插图]<br>第1节 焦距<br>◆ 焦距主要就是用于决定我们的视角，即帮助我们确定取景的范围。<br>第2节 透视<br>◆ 所以一对比您就会发现，24mm的焦距把人物的脸都拍变形了，而50mm和85mm的焦距就很好，背景虚化效果也特别明显。对圆脸的人物来说使用50mm的焦距拍摄透视效果比较好。如果是“锥子脸”的人物，那么使用85mm的焦距也许是最好的。<br>◆ 一般来说24mm或者35mm的焦距更加适合拍摄人物全身照。半身和特写拍摄这种常用的人像拍摄方式，更应该用50mm或者85mm这样的焦距拍摄。<br>◆ 这一部分您要记住的就是如下内容。(1)透视就是指近大远小，透视永远客观存在。(2)拍摄距离越近，透视效果越明显；拍摄距离越远，透视效果就越不明显，直到可能看不出来。<br>延伸学习 问题与提高<br>◆ 有一句“名言”：天空好看，看地面。<br>◆ 比如拍摄人物特写的时候，一般来说我们不应该选择低角度仰拍。这张照片中，拍摄这位“美女”的特写为什么一定要低角度仰拍呢？造成的结果就是我们可以看到明显的“双下巴”。我有时候也会把这样的角度称为“死亡角度”。很少有人的脸型可以“扛得住”这么拍。<br>◆ 一般来说，我们要采用稍微俯拍的角度去拍摄人物，这会让脸型显得更好看。<br>◆ 画面缺主体如果画面里有主体、有背景的话，主体是用来明确主题的，而背景是用来强化主题的。但是很多人拍摄的照片没有主体，变成一个“大空镜”，这就不好了。<br>◆ 取景范围不对取景范围选择不对也是很影响画面的。取景范围过大，往往会让很多“没用”的元素进入画面。取景范围过小，往往会对主题的表达并不充分。<br>◆ 取景范围选择不对也是很影响画面的。取景范围过大，往往会让很多“没用”的元素进入画面。取景范围过小，往往会对主题的表达并不充分。<br>◆ 画面需要前景通常只有一个原因，有了前景能更加烘托主题、氛围。比如拍摄风景，主题就是美，如果有了前景，一定要更美。如果不是的话，就没必要加前景。<br>◆ 2024/06/21发表想法<br>这点我不大认同，前景的割裂是很多导演拍摄时的手法，用来表示人物间的隔阂。<br>原文：这张照片中，前景将画面切割成了两个部分。但是两个部分没有什么必要关联，也没形成什么对比，反而因为前景的加入对画面造成了严重的干扰。不如不加前景。<br>◆ 控制取景范围营造反差画面中的元素反差其实是多种多样的。就取景来说，我们可以拍摄到两个有反差的元素，画面中这样的反差对比，自然可以引发大家的思考。<br>◆ 对日常景色来说，我们往往是站在地面去看的。观看的高度就是我们身高的高度。站在高处往往可以获得不寻常的视角。<br>◆ 让画面更加有代入感所谓代入感就是指让人能够和画面中的某个元素“感同身受”，或者至少让人有身临其境的感觉。从取景的角度来说，获得代入感，较简单的就是视角一致，或者离得近。[插图]<br>◆ 但是如果我们能将角度降低一些，与猫平视拍摄，这时您会发现照片的代入感明显增强。猫不再只是客观存在的，您会将自己“代入猫的情感”。[插图]<br>◆ 我们使用焦距为35mm的镜头拍摄人文题材时，往往会离得近。这就给我们带来了很强的代入感，好像镜头会讲故事。<br>◆ 首先恰当的前景可以引导我们的视线。有纵深感的前景可以将我们的视线引导到画面的主体，这是突出主体的一个好办法。<br>第1节 “白加黑减”<br>◆ 可以简单将影调理解为一张照片的明暗程度。明亮的照片就是高调，昏暗的照片就是低调，不亮不暗的照片就是中间调。<br>◆ 在纯白和纯黑中间的灰色却并非像我们想象中的反射了50%的光线，根据统计估算，现实生活中所有物品的反射率大概是18%。<br>◆ 为什么相机知道我们拍出来的照片是什么亮度呢？其实这很简单。只要相机知道您准备怎么曝光（参数如何），它“睁开眼睛”好好看看您的取景范围的亮度就行了。相机可以准确知道您拍摄的场景的亮度，因为相机会测光。<br>◆ 测光主要的模式为点测光和评价测光（也称矩阵测光、多重测光等，不用品牌的相机叫法不同）这两种，这也是较常用的两种。此外还有局部测光、中央重点平均测光等。这些其实几乎用不到。所有的测光模式仅在测光区域以及计算权重方面有差异，并无本质上谁更高级、谁更专业的区分。所以如果有人和您说一定要用点测光才专业，那么是非常可笑的。它们的区别仅是测光区域或者计算权重分配不同。<br>◆ 其实只要相机在“醒着”的状态，就是时时刻刻都在测光的。半按快门按钮只是为了激活相机。<br>◆ 从上面的描述我们知道，其实曝光补偿都是在一些特殊场景或者特殊情况下才需要调整的。比如您拍摄的取景范围本身比较白、比较亮，为了体现整体本来的亮度就要把照片拍亮，就要增加曝光补偿。<br>◆ 最终的结果就是曝光不够，环境不够白，欠曝了。[插图]<br>第2节 控制曝光三要素及互易律<br>◆ 　小光圈能拍出星芒效果<br>◆ 小光圈可以检验镜头清洁度<br>◆ (1)光圈是表示镜头中孔径大小的一个比值；(2)光圈越大光圈值越小，光圈越小光圈值越大；(3)光圈越大照片越容易拍明亮，光圈越小照片越容易拍暗；(4)光圈越大虚化效果越强，光圈越小虚化效果越弱。<br>◆ 比1/4秒速度低的，就是很低的快门速度；比1/60秒速度低的，就是慢门；比1/250秒速度高的，就是高速快门；比1/2000秒速度高的，就是很高的高速快门。<br>◆ 快门速度高（高速快门）拍摄出来的感觉，运动速度很高的物体也会被“凝固”住。而慢门——快门速度低（长曝光、低速快门等，叫法很多）拍摄出来的效果则会带来另一番感受。除了对于曝光的影响，拍摄者控制快门速度，往往也是为了得到这样不同的效果。<br>◆ 细腻的照片看起来更好，所以在拍照时能选择较低的感光度（标准值）的时候，一般都建议选择低感光度。<br>◆ 感光度提高造成的画质下降主要表现为4个现象。先出现的是“锐度下降”和“细节损失”，这时的画质还不算糟糕。随后出现的就是“噪点增加”，大家对于高感光度画质差的主要印象就是噪点的大量增加，其实到这个时候，画质依然在可接受的范围。最后出现的就是“色彩偏移”，我们会发现，在画面暗部区域有大量不明色块，这时候画面的锐度已经下降得非常严重，同时噪点的数量也到了难以接受的程度，可以说非特殊情况，我们最好不要使用这么高的感光度。<br>第3节 曝光模式<br>◆ 曝光模式，指的就是M（手动曝光）挡、A（光圈优先）挡、S（快门优先）挡，AUTO（自动曝光）挡以及P（程序曝光）挡。<br>◆ 光圈优先、快门优先以及手动曝光这3种曝光模式是摄影的“充分必要条件”。这3种曝光模式都可以让我们完全控制曝光。<br>◆ A挡适用于绝大多数场景。<br>◆ 还是M挡时拍摄海边礼堂的例子。当使用光圈优先模式时，光圈我们设定为f/8，感光度设定为ISO 100，同时我们是可以设定曝光补偿的——对的，我们可以直接决定这张照片的亮度。比如，设定为–1/3EV，它就不会变了。<br>◆ 光圈优先模式适用于需要控制光圈的时候，比如在拍摄人像、风光等场景中使用。<br>◆ 低于安全快门速度时，那么相机会自动提高感光度，以保证不低于安全快门速度。但是光线条件好的时候，相机肯定会保持低感光度以保证高画质。<br>◆ 用最简单的方式解决问题才是最专业的。<br>第4节 正确的曝光<br>◆ 一张照片最终的明暗效果，可能会得到一些人的肯定，也必然会有人觉得不合适。所以所谓确定的标准是并不存在的。<br>◆ 但是当照片中大面积是白色或者浅色的元素时，我们要将照片拍摄得明亮一些。当照片中大面积是黑色或者深色的元素时，我们要将照片拍摄得灰暗一些，以准确拍摄出这个场景本来的亮度。<br>◆ 拿阔叶植物举例子，如果是面朝光，那么这个面反光就是不亮不暗的绿色；如果是薄薄的侧面对着光线，光线相当于就被叶子的缝隙吸收进去了。如果是针叶植物，光线更是被缝隙吸收了。所以绿色植物整体是偏暗的。<br>◆ (3)在主体已经成为剪影时，背景色彩好看很重要。<br>◆ 画面中的摄影师已经是剪影了，但是我可能还觉得天色“发白”，不够鲜艳，那么继续减少曝光补偿。反正人已经“黑”了，特别黑与特别特别黑其实没什么本质区别。调节到天空色彩好看为止。<br>◆ 一幅强反差的作品，就应该在直方图两边有很多像素，曲线为两边高、中间低。<br>◆ 只要曝光符合您拍摄的主题，就是一个好的直方图。照片的一切要符合拍摄者的意图！<br>◆ 说白了，您拍摄时的确曝光是指一个“段”，稍稍过曝一些，或者稍稍欠曝一些，都不太会影响最终的曝光效果，因为您可以后期调整。所以可以“从容拍摄”<br>◆ 很多纪实摄影师却又有不同的观点，他们认为应宁欠勿过——我喜欢拍摄纪实题材，这也是早期我推荐用这个方法拍摄的原因。<br>◆ 就算从影子里大家也能看出来他在拍摄水母。所以只要您能保证拍摄的主题明确，死白或者死黑又如何？<br>◆ 左图是使用HDR之后的照片。因为有了HDR，所以天空色彩浓重，前景也被提亮，色彩丰富了很多。<br>◆ 这可能也并不是一个玩笑，因为我想告诉您，尽量要避免大光比、强反差的情况，不要将自己置于高难度的拍摄境地。<br>第5节 光线<br>◆ 其实顺光不应过多地运用在人像摄影中。因为人像摄影时正面直射的光线会消除面部的影子，使得面部看起来趋于平面化，所以顺光又叫平光。<br>◆ 看上图中的蓝天，只有在顺光拍摄的时候，才能展现出如此的色彩。很多人说为什么我明明看到的是蓝天，但是拍摄的风景照片中的天总是白白的呢？这就是因为没有顺光拍摄。<br>◆ 侧光一般用在人物摄影的造型上。相比顺光拍摄，侧光拍摄会将人物拍成“大白脸”，侧光能够让人物的面部呈现立体效果。<br>◆ 90°侧光是用来强调明暗对比的特殊光线。被摄主体一面处于强光中，另一面则完全处于阴影中。90°侧光非常适合用来表现被摄主体表面的质感。<br>◆ 逆光是很多摄影师进行创作时会用到的光。使用逆光拍摄的时候，往往会有雾蒙蒙的感觉，并形成暖色调。但是这样子的光线会形成一层浓重的光雾，让照片显得非常不通透。降低影调，可以让这种光雾消散。<br>◆ 但在真实的拍摄过程中，不管是拍摄人像还是拍摄风景，其实摄影师都在尽力地避免逆光拍摄，除非遇到诸如日出、日落或者能够“打透”某些景物的时候，才会采用逆光拍摄。<br>◆ 我们非常熟悉的太阳，是一颗黄矮星，表面温度约为5770K<br>◆ 蓝色是冷色，但是色温高；红色是暖色，但是色温低。<br>◆ 白平衡的初始功能就是将在不同环境色温中的白色物体都还原成真的白色。<br>◆ 这就是白平衡的作用——调节画面最终呈现的色温。<br>◆ 我是一个比较懒的人，所以我一般都选择自动白平衡(Auto White Balance,AWB)。<br>◆ 不同的光线有着不同的强度、不同的方向、不同的色温，所以在应付这些光线的时候就要用不同的方法。都说摄影是光和影的艺术，避开这些光线特性给我们带来的弊端，展现出这些光线美的一面，就是摄影成功的关键。<br>◆ 日出之前和日落之后自然光的色温很高，颜色冷艳迷人，但是光线强度很低，有着一种神秘的气息。<br>◆ 日出、日落时的光线色温很低，光线温暖、柔和，因为光线强度低，所以是拍摄太阳较好的时刻。<br>◆ 在户外拍摄人物的时候，不要在太强的光线下拍摄。所以在正午的大太阳下拍摄人物一般是不合适的。一般可以选择阴天、日出后一小时或者日落前一小时拍摄人物。<br>◆ 摄影中耶稣光现象又称丁达尔现象，就是一束光通过胶体时，在光路的垂直方向可以看到整条光路。<br>◆ 耶稣光其实很常见，能够给人美和神圣的感觉，所以很多摄友都非常喜欢。<br>◆ 我们在拍摄的时候就要分析照亮主体——一桌子食物的主要光线是什么，以及这些光线的强度、方向、色温是什么。<br>◆ 45°侧光常常作为主光使用。<br>◆ 一般在需要进行艺术化处理的时候，才会用90°侧光。拍摄常规人像时一般不会用到这样的光。<br>◆ 伦勃朗布光法<br>◆ 摄影艺术很多时候都是在借鉴绘画艺术。伦勃朗布光法就是非常典型的例子。<br>◆ 伦勃朗布光法有以下几个特点。(1)模特约3/4的面部对着相机。让模特面向相机，缓慢变换角度，直到看不到一侧的耳朵为止。(2)架设主灯，强度要能使模特面部正确曝光，方向为与模特面部方向同一侧45°左右。注意，要在模特面部形成三角形光区（以鼻子阴影、面颊阴影、下眼线为边长，围成的三角形亮区）。(3)架设辅灯，将面部阴影处柔化，并表现出细节。一般会使用4︰1或者3︰1的光比。(4)架设背景灯，打亮背景。如果有可能从模特斜后方打出一束比较集中的光，打在模特轮廓上，形成轮廓光。<br>◆ 使用伦勃朗布光法主要能够表现出模特形象的深邃和坚毅，能够强调面部的线条。所以其更适合用于对男士的摄影，对于女士就不太适合了。<br>延伸学习 问题与提高<br>◆ 过曝不是指照片亮，欠曝也不是指照片暗。过曝是指照片的亮度超过了拍摄的画面应有的亮度范围；欠曝就是指照片的亮度没达到拍摄的画面应有的亮度范围。<br>◆ 照片的曝光可以分为高调、中间调、低调。高调就是照片比较亮，中间调就是照片不亮不暗，低调就是照片比较暗<br>◆ 宽容度是指能正确容纳照片中亮度反差的范围。简单地说，就算曝光“正常了”但是因为画面中的亮度反差超过了相机宽容度的范围，也必然会出现死白、死黑或者两者都出现的情况<br>◆ 室外强光是“杀手”不管是拍摄风光还是拍摄人像，在室外拍摄时我们都该避免“大太阳高高挂”，因为光线太强了。<br>◆ 所以若真的需要在室外拍摄人像的话，要么等光线柔和时拍，比如日出后一小时、日落前一小时，要么就阴天的时候再拍。<br>◆ 只要适当调整一下高光和白色的色阶，往暗调一调，同时将阴影和黑色的色阶往亮调一调，画面就会好看很多。大家拍摄的风光照片多多少少有这样的问题，去试试后期调整您们的风光照片吧<br>◆ 其实我们只要规规矩矩表现色彩，一般也不会差。<br>◆ 如果能够避免上述问题，可以说在曝光这方面您就不再是新手了<br>◆ 当一张照片需要表达年轻、有活力、有希望等正面情绪的时候，其实我们可以稍稍增加一些曝光补偿。这也多用于拍摄孩子。<br>◆ ，照片的影调也可以和拍摄者的心态或者心情有关。<br>◆ 鲜艳的影调和我选择的这样比较暗的影调，对这样的场景来说，没有谁对谁错，也没有谁比谁更加高明，无非是心境不同。对观看者来说，可能会有喜欢更明艳一些的，也会有喜欢更幽暗一些的。<br>◆ 一张照片明暗反差小的时候，整个画面会显得更加柔和、平静。明暗反差大的时候，则往往会表达出一种更加激烈的情绪。<br>◆ 这是一张在法国某游乐园拍摄的照片。画面中烟花亮起，形成非常明显的明暗反差。画面一下子就“澎湃”了起来。<br>◆ ，我们知道高色温一般表现出来的是冷色调，低色温一般表现出来的是暖色调<br>◆ 除此之外，老旧的东西往往会因为氧化而让白色泛黄。所以泛黄的照片也往往会给我们沧桑感。<br>◆ 在色相环中我们可以看到很多不同的颜色绕成一圈。某一种颜色左右15°内的颜色，我们可以将之看作同类色。<br>◆ 如果是色相环上180°相对的两种颜色，就是互补色，互补色的对比是最为强烈的色彩对比。这样的对比和明暗的反差一样，会给人很激烈的感受。蓝配橙，红配绿，大抵如此。<br>◆ 多重曝光多重曝光就是指将一张底片——一张黑画布，2张或者更多张不同的“画”的效果叠加起来<br>◆ 要尽量在第一张照片的暗部区域曝光第二张照片主要的元素。同时不要让第二张照片的亮区遮盖住第一张照片的主要元素。<br>◆ 多重曝光的每次不同曝光，可以表现同一主体的不同状态，也可以表现不同主体的某些共性或者对立性。<br>◆ “相机给了您黑色的画布，摄影让您涂抹光明。”<br>第3章 虚实<br>◆ 而对摄影来说，虚实结合往往是摄影作品非常吸引人的地方。本章会给大家讲讲怎么利用虚实来明确主题、突出主体和简化画面。<br>第1节 对焦与景深<br>◆ 对上焦的地方，绝对是清楚的。那么没对上焦的地方呢？未必模糊。<br>◆ 焦平面是一个面，面上的内容都是清楚的<br>◆ 这段清晰范围就是景深范围<br>◆ 为什么会有景深出现呢。这主要与人眼的分辨能力和照片的实际大小有关。其实只要离开了对焦点，画面就开始模糊，离得越远就越模糊。如果离得很近的话，虽然会模糊，但是因为照片也许没有那么大的尺寸，或者人眼难以分辨，所以我们觉得也是实像。<br>◆ 关于景深要记住以下几点。(1)景深和光圈、焦距、拍摄距离有关。我们在后文会详细介绍。(2)前景深比后景深要浅（短），前面的容易“虚”，后面的不容易虚。(3)随着拍摄距离、焦距、光圈等参数的变化，后景深变化特别快，前景深变化慢。(4)景深范围如果小的话，“实”的区域就小，这被我们称为浅景深。景深范围大的话，实的区域就大，这被我们称为深景深。<br>◆ 1　超过了对焦范围<br>◆ 如果您对着一个纯色区域自动对焦，往往是对不上焦的。因为没有识别度啊，对上焦是一片纯色，没对上焦也是一片纯色，相机无从判断是否对上焦了，自然就对不上焦。<br>◆ 自动对焦AF，可以分为单次自动对焦(AF-S)和连续自动对焦(AF-C)两种对焦模式。<br>◆ AF-C（佳能叫SERVO）就是只要一直半按着快门按钮，相机就会一直不停地自动对焦。拍摄运动的物体的时候，这个模式比较好用。<br>◆ 平时一般拍摄——使用“AF-S+单点对焦”，拍运动物体的时候——使用“AF-C+扩展对焦”。这两套组合较为常用。<br>◆ 同时一定要善于利用相机提供的高级功能，比如眼部追踪对焦，这可以大大提升我们的拍摄成功率；触摸屏可以让我们更加快速地选择对焦点，这都是很好的。<br>第2节 通过景深实现虚化<br>◆ 相信学习摄影的人大都会对那种“主体非常清楚，背景模糊朦胧”的照片有一种特殊的好感。<br>◆ 有4个因素都可以让背景处于景深之外，我总结了4句口诀：背景远，相机近，光圈大，焦距长。<br>◆ 相机离拍摄主体越近，景深就越浅，背景虚化效果就越明显。<br>◆ 相机离拍摄主体近产生的背景虚化效果在微距拍摄的时候更为突出。<br>◆ 本来我想给一个姑娘拍全身像，结果离得近了就变成拍大头像了，甚至是变成拍眼睛特写。我不想离这么近拍摄怎么办<br>◆ 在讲光圈的时候，我们说了小孔成像原理。小孔能成实像，但是孔大了并不是不能成像，只是成的是虚像。这就是用大光圈的时候更容易出现背景虚化效果的原因。<br>◆ 拍摄人像时也不是焦距越长越好。一方面太长的焦距会使我们和模特交流不通畅，另一方面我们在学习透视的时候知道，太长的焦距会让我们离模特非常远，这样拍出来的照片人脸趋于扁平，往往并不好看。<br>◆ 背景远，相机近，光圈大，焦距长，做到背景远是最好的，但是并非所有场景都能如意。相机近往往会受限于我们的取景，而焦距长也会对透视效果产生影响，所以光圈大就是最好的获得背景虚化效果的方法了。这也是大光圈“深入人心”的原因。<br>◆ 现在手机可以通过多摄像头对拍摄场景进行测距，然后模拟虚化的效果。虽然不能完全与相机由光学技术产生的虚化效果比拟，但是也很不错了。<br>◆ 想要实现浅景深就要用“大光圈+长焦+对焦距离近”这三者来搞定。如果我们要使背景不虚化，远近景物都清晰，自然就要用“小光圈+广角+对焦距离远”了。<br>◆ 所以比如拍摄风景，一般来说我建议用小光圈（f/8、f/11就可以了），然后根据您的取景范围选择焦距。取景范围大，选择广角。取景范围小，拍摄远处，该用长焦就用长焦。<br>◆ 首先，我们要知道一个基本概念：超焦距是对焦到某个距离的时候，我们能够获得的理论上最大的景深范围。那么关键的问题就是，这个超焦距到底是对焦到什么距离。<br>◆ 当我们使用某个光圈和焦距的组合，对焦点从最近开始逐渐远去，您会发现景深范围随着对焦距离变远，会逐渐变大。<br>◆ 所以理论上最大的景深范围就是当您对焦在某点时，后景深的边界恰好到了无穷远的地方。找到这个对焦距离，就是实现超焦距摄影的关键。<br>◆ 如此一来，如果我们想后景深边界为无穷远，只需要对焦在无穷远处，那么这时前景深范围就正好在实现超焦距的对焦点上了<br>◆ (1)确定好拍摄场景需要的焦距和光圈，在从我找超焦距直到拍摄完成的过程中都不能变。(2)将相机或者镜头调节至手动对焦，同时将对焦点调节到无穷远。(3)对着有纵深的场景拍摄一张照片，回放照片找到离您最近且清晰的物体。(4)切换成自动对焦，对这个物体对焦。对焦完成之后可以切换成手动对焦，让对焦距离不再改变。<br>◆ 我们拍摄风景时，记住用小光圈，对焦在您认为最重要的元素上，基本上就可以实现远近景都清晰了。<br>第3节 快门控制虚实<br>◆ 先说说高速快门吧。高速快门的一个作用就是“凝固”瞬间。在拍摄高速运动的主体时，往往需要很短的曝光时间才能“凝固”住主体的动作。<br>◆ 利用高速快门“凝固”瞬间，这是用快门速度控制画面“实”的表现。<br>◆ 如果闪光灯一直开着，您就会发现快门速度基本上锁定在了1/200秒（常见的最高闪光同步速度），因为白天室外是很亮的，您怎么拍都会过曝。<br>◆ 高速快门记录的是某一个时间点，而慢速快门记录的则是某一个时间段。<br>◆ 比1/4秒速度低的，就是很低的快门速度。比1/60秒速度低的，就是慢门。比1/250秒速度高的，就是高速快门。比1/2000秒速度高的，就是很高的高速快门。比如用1/4秒拍摄，大概流水就会变成线了。比如用1/60秒拍摄，人物运动速度比较高的动作基本就虚化了，街上奔驰的汽车基本也虚化了。比如用1/250秒拍摄，基本上街拍时所有的人物动作都会被“凝固”。比如用1/2000秒拍摄，水花也会被“凝固”。<br>◆ 除了烘托氛围，使用慢门实现虚实结合还可以让画面显得更加唯美。这往往需要更长的曝光时间，那么三脚架就是必需的。<br>◆ 不管是固定机位拍摄的将移动物体拍成线，还是相机追随主体拍摄的将背景拍得虚成线，慢门都是突出动态主题的好方法。<br>延伸学习 问题与提高<br>◆ 说白了余弦误差是先对焦后构图才会出现的问题。很多人在拍摄的时候养成了先进行中心点对焦再构图的习惯。<br>◆ 这里要说到安全快门速度。说白了，对老手来说，最低的快门速度应该是您使用的焦距的倒数。简单地说：您用200mm焦距的长焦镜头，快门速度至少要1/200秒才能保证拍摄的照片可能不模糊。要是新手，最低的快门速度就可能是焦距的2倍的倒数。也就是如果用200mm的焦距，那么可能至少要1/400秒的快门速度才行。<br>◆ 但是当画面中主体是运动的时候，我们固定相机使用慢门拍摄，主体就虚了<br>◆ 在观看照片的时候，人的眼睛就会去找拍实的背景了，那么主体就不是主体了。<br>◆ 所以拍摄星空而不是星轨时，我们有一个“500原则”。这个原则很简单。用500除以等效焦距，就是您能曝光的最长时间。比如我使用全画幅相机配20mm超广角镜头，等效焦距就是实际焦距——20mm,500÷20=25。那么我最长曝光的时间就是25秒。只要不超过25秒的曝光时间，星星就不会拖影。<br>◆ 所以现在严谨的风光摄影师往往都采用“300原则”。<br>◆ 但是摄影也像文学一样，我们可以将重点隐藏起来，含蓄一些。<br>◆ 其实这是一种含蓄的表达。我将视角放在了枯木上，以它来讲述这个故事。它每天就躺在这里，却时不时有人从它身旁走过。<br>◆ 所以要表达的内容未必一定要是清晰的，但是该突出主体的手法还是要用的。<br>第4章 构图<br>◆ 摄影中的构图理论完全继承自绘画中的构图理论。<br>第1节 构图法<br>◆ 分割画面的两条横线和两条竖线形成了一个“井”字，并且有4个交点。这4条线和4个交点都是极为重要的。<br>◆ 人眼在看某一画面的时候，视觉中心往往不是在画面的正中心，而是偏一些的位置。三分法构图的4个三分线的交点——视觉中心，正是容易让人一眼看到的点。拍摄时避开居中位置，是新手走向成熟的一个标志。<br>◆ 哪里有内容，哪里占比就大。或者就是根据自己照片要表达的主题来决定，到底线条是放在上三分线上，还是下三分线上。<br>◆ 记住一点，永远使您拍摄的主体朝向比较空旷的一面。<br>◆ 纵向的主线条是放在左边还是右边，主体是放在4个点的哪个好呢？我想答案只有一个——看着舒服。<br>◆ 而未来不管您是学习构图，学习摄影，还是学习绘画，或者任何一件事，记住，先学会基础知识，明白规矩，当您需要的时候，您才有资格说“打破”。因为您有明确的需要，您懂得为什么要打破。<br>◆ 其实这样的情况很多见，比如一张照片想表达一些诸如压抑、困顿、无奈等负面情绪的时候就可以使用这样的构图法。这样您的作品不仅是主体本身的表现让人觉得不舒服，构图也能帮助您强化这种不舒服的感觉。<br>◆ 使用重复法较为重要的一点就是一定要是同一元素重复，或者是极为相似的元素重复。一旦画面中有明显的不同的元素出现，不同的元素会被当作主体，大量相同的元素就变成背景了。<br>◆ 当画面中的主要线条汇聚到一点时，会容易被人眼捕捉到。有了这个结论，在适当的条件下，我们可以依靠线条对视线的汇聚作用来突出拍摄主体。<br>◆ 对三角构图法来说，重要的就是如果您想画面看起来稳定的话，一定要想想，画面中重要元素构成的三角形是不能在画面中“摇摇晃晃”的。<br>第2节 摄影构图的一些常识<br>◆ 我曾说，摄影构图和绘画构图是不同的，因为画一幅画您可以画好多年，而拍摄往往就是瞬间的事，构图方法越简单越好。后来向一些绘画领域的人了解，发现其实绘画也不会去用“尺子量”，最重要的还是一种“感觉”。<br>◆ 其实对横构图来说，其会给人一种稳定和宽阔的感觉。那么拍摄大场景风光，包括大场景街拍、人文题材都适合使用横构图。<br>◆ 竖构图的使用，则更多的是要表达画面的纵深，以及高低的感受。<br>◆ 此外因为竖构图表现的画面高度，其还非常适合表达有高度的场景。[插图]<br>◆ 在没有高低落差时，对于有纵深感的画面，采用竖构图同样很合适。纵深、纵深，照片当然要纵（竖）过来。这样聚拢的感觉会让画面显得更加悠远。<br>◆ 所以在拍摄会飞的元素时，我们可以考虑将其放在画面的上半部分。而对于拍摄人，在一般情况下尽量不要让大家“飘”在天上。<br>◆ 方形体现在画面中，常见于拍摄建筑物。可以说绝大多数的建筑物不管是什么形状的，都是底边在地面上的，多数建筑物就是以方形的样子存在的。<br>◆ 至于圆形，圆形在画面中出现的时候，画面会显得聚拢。所以当圆形的主体在画面中出现的时候，画面有一种自然的收缩感。<br>延伸学习 问题与提高<br>◆ 这是很多新手容易犯的错误。水平线一般就是要水平的。很多人说老师为什么不能斜着？因为那都不叫斜，叫“歪”。我们看上图，水平线明显是倾斜的，会给人画面很不稳定的感觉。<br>◆ 所以如果您要倾斜构图，那么请给一个理由。端平拍则不需要任何理由。人物坐着、躺着的情况，以及画面有水的等，要格外注意谨慎倾斜构图。<br>◆ 拍摄人物肖像照的时候，如果是半身像或者全身像，记住，人的脑袋千万别放在中线上，更不能放在中线以下。要不然会显得人非常矮。<br>◆ 简单记一下就是所有关节最好都不要切，手脚不要切。<br>◆ 当我们拍摄人时，尽量不要让人的脑袋上“长树”“长花”“长天线”“长电线杆子”……<br>◆ 以上7个问题是新手在构图时常见的问题。我一直认为对新手来说，多看怎么拍，不如多看看不要怎么拍，这样其拍出的照片会明显好一个档次。加油吧。<br>最终的总结<br>◆ 永远不要忘记，取景、曝光、虚实、构图，就是摄影技术的一切。永远不要忘记，主题才是您的照片‘灵魂’的所在。<br>◆ 一切技术都是为更好地表达内容服务的。所以不要单纯炫技，我们要将更多的精力放在发现好内容上面。炫技可以让您的照片流传一时，但是真正有内容的照片才会传世。而真正的好内容来自我们的内心，来自我们的人生。<br>-- 来自微信读书<br>]]></description><link>culture\阅读\新摄影笔记.html</link><guid isPermaLink="false">Culture/阅读/新摄影笔记.md</guid><pubDate>Mon, 09 Sep 2024 11:58:11 GMT</pubDate></item><item><title><![CDATA[阅读]]></title><description><![CDATA[ 
 <br><br><a data-href="Culture/阅读/小说课" href="\culture\阅读\小说课.html" class="internal-link" target="_self" rel="noopener nofollow">Culture/阅读/小说课</a><br>
<a data-href="Culture/阅读/当我谈跑步时，我谈些什么" href="\culture\阅读\当我谈跑步时，我谈些什么.html" class="internal-link" target="_self" rel="noopener nofollow">Culture/阅读/当我谈跑步时，我谈些什么</a><br>
<a data-href="Culture/阅读/新摄影笔记" href="\culture\阅读\新摄影笔记.html" class="internal-link" target="_self" rel="noopener nofollow">Culture/阅读/新摄影笔记</a><br>
<a data-href="Culture/阅读/择天记" href="\culture\阅读\择天记.html" class="internal-link" target="_self" rel="noopener nofollow">Culture/阅读/择天记</a><br>
<a data-href="Culture/阅读/将夜" href="\culture\阅读\将夜.html" class="internal-link" target="_self" rel="noopener nofollow">Culture/阅读/将夜</a><br>
<a data-href="Culture/阅读/刘擎西方现代思想讲义" href="\culture\阅读\刘擎西方现代思想讲义.html" class="internal-link" target="_self" rel="noopener nofollow">Culture/阅读/刘擎西方现代思想讲义</a><br>
<a data-href="Culture/阅读/机器学习-周志华" href="\culture\阅读\机器学习-周志华.html" class="internal-link" target="_self" rel="noopener nofollow">Culture/阅读/机器学习-周志华</a><br>
<a data-href="Culture/阅读/人类简史" href="\culture\阅读\人类简史.html" class="internal-link" target="_self" rel="noopener nofollow">Culture/阅读/人类简史</a><br>
<a data-href="Culture/阅读/我的二本学生" href="\culture\阅读\我的二本学生.html" class="internal-link" target="_self" rel="noopener nofollow">Culture/阅读/我的二本学生</a><br>
<a data-tooltip-position="top" aria-label="Culture/阅读/中国教育史-孙培青" data-href="Culture/阅读/中国教育史-孙培青" href="\culture\阅读\中国教育史-孙培青.html" class="internal-link" target="_self" rel="noopener nofollow">中国教育史-孙培青</a>]]></description><link>culture\阅读\阅读.html</link><guid isPermaLink="false">Culture/阅读/阅读.md</guid><pubDate>Mon, 02 Dec 2024 14:17:35 GMT</pubDate></item><item><title><![CDATA[择天记]]></title><description><![CDATA[ 
 <br><br>《择天记》<br>猫腻<br>
362个笔记<br>第一章 序 下山<br>◆ 在这里，平静的云层像白色的丝绵向着四面八方蔓延，似乎没有尽头，上方的虚空镜面后是无尽的黑色深渊，里面有无数颗星辰。<br>◆ “你的命……真的很不好。”他看着被麻布裹着的婴儿，怜悯说道。　　……<br>◆ 不讲究修行体悟，不理会命星坐照，不关心神魂淬炼，只是一字记之曰：背。<br>◆ ：“因又在何处呢？”<br>◆ 自十岁生辰之后，那只白鹤便再也没有来过青山，京都那边断了消息，婚书的另一边仿佛从来没有出现过，陈长生偶尔站在溪畔，看着西方，会想起这件事情<br>◆ 陈长生决离开破庙，去繁华的人世间看看，趁自己还能看，他要去看看传说中的天书陵，还要去把那门婚事退掉。<br>第二章 我改主意了<br>◆ 陈长生的神情却忽然间变得严肃起来。　　他说道：“但现在……我改主意了。”　　府里的春风再次变得寒冷起来，气氛再次变得极为压抑，偏厅阴暗角落里，那位嬷嬷脸上的皱纹，深的像是无数道沟壑，忽然间被洪水冲垮。<br>第四章 这是个俗气的名字，但，是我的名字<br>◆ 陈长生歪着头很认真地想了想，稚嫩的脸上渐渐现出笑容，因为确认找到了可以说服自己的理由，说道：“因为……你们没有问过我的名字。”<br>◆ 不是他很擅长让人不愉快，而是他在认真地做着自己认为应该做的事情。无论退婚还是改变主意，他都认为那是正确的，无比地肯定，以至于让人产生一种难以否定的感觉，于是，那些让他不愉快的人，最终都会郁闷到无法愉快起来。<br>◆ 每个人在世间都是独一无二的。<br>◆ 所以大道三千，他求的是顺心意——所谓顺心意，就是心安理得。<br>◆ 人命关天，那位徐小姐一生的幸福，总比自己遭受的这点冷遇和那些白眼要重要的多，他依然这样认为。<br>◆ 有时候，陈长生自己都会忘记自己还是个十四岁的少年，但他终究是个少年，他有自己的骄傲与尊严，被羞辱了总会有情绪。<br>◆ 徐世绩微微眯眼，如猛虎将眠，说道：“那就把他烧成灰扔进洛河里去。”　　再过些天就是雨季，洛河即将涨水，无论灰还是骨，落进河里，都会瞬间消失。<br>第八章 陈唐相遇<br>◆ 其实陈长生想的很简单，在人生地不熟的京都，在满是嘲讽与冷眼的天道院里，对方明明是个天才人物，却主动前来亲近自己，那么自己理所当然应该回赠更多的热情与善意，至少应该主动寒暄，聊些什么。<br>第一十章 我有做错什么吗？<br>◆ 夕阳快要落山，微红的光照耀在神兽与军纪楼冰冷的铁栅栏上，让环境产生了一种神妙诡魅的感觉，陈长生站在光影里，看着还是空空如野的石壁，稚嫩的脸上满是高兴的笑容与对未来的期待。<br>◆ 聪明人会活的不快活，所以做人要难得糊涂。<br>◆ 他看着那位中年妇人，忽然开口说道：“婆婆，我有做错什么吗？”　　中年妇人怔住，一时语塞。<br>第一十一章 何日上青云<br>◆ “既然我没有做错什么，那么我为什么要改变什么？<br>◆ 夕阳西下，陈长生向街对面走去，随着人群走向更远处。　　中年妇人注意到，最开始的时候，他的头有些低，身子有些微佝，显得有些落寞疲惫，然而没有过多长时间，他的身子渐渐挺直，头也渐渐抬起，重新开始平视街上的人群与远处的落日。　　暮晖照耀在少年的身上，仿佛在燃烧。<br>◆ “我从来没有见过这样自律的少年，饮食起居自我控制的非常严厉完美，没有任何不良的嗜好或者娱乐。他很珍惜时间，太珍惜以至于我总觉得有谁在追赶他，又或是有鞭子在不停地抽打他，但他却又不会给身边人焦虑的感觉。看得出来，他很喜欢享受生活，或者说生命……就是有一些轻微的洁癖，第一天时我有数过，他一共洗了七次手，手帕应该也有五条以上。<br>第一十二章 这两个家伙<br>◆ 在唐三十六的印象里，陈长生就是一个天赋可期、气质可亲、精神可嘉的普通少年，此时他忽然发现这个家伙的目光竟然像雪亮的刀锋般锋利，不禁微异，眼睛微眯，对陈长生隐藏着的事情更感兴趣。<br>◆ 陈长生抬头看了他一眼，然后慢慢地翻了个白眼。　　唐三十六正在喝茶，险些把嘴里的茶水喷出来，他怎么也没想到，古板甚至可以说死板的这个家伙也会有如此孩子气的一面。　　陈长生心想，自己郁闷的快要死了，但一定要让你知道？<br>◆ 陈长生忽然有些同情这个家伙，心想这家伙只怕一辈子都在修行，难怪如此年纪便境界如此深厚，为人处事真是糟糕的一塌糊涂，也不知道将来怎么办。<br>◆ 唐三十六看着他忍不住摇了摇头，很是同情这个家伙，心想这家伙只怕一辈子都在读书，难怪如此年纪便能记住那么多典籍教义，为人处事真是糟糕的一塌糊涂，也不知道将来怎么办。<br>第一十三章 让人无话可说的朋友（上）<br>◆ 陈长生认真说道：“不会当场死，但肯定会早死。”<br>◆ 那把剑很小巧，看着比正常的匕首也长不了多少，而且很细，看着非常秀气，剑鞘是普通的皮鞘，剑柄也很朴实，从里到外透着股寻常的气息，没有任何引人注意的地方，也没有灰尘或血迹，总之这柄剑普通到了极点，却让他很想亲近。<br>◆ 陈长生注意到他有些不高兴，有些不安，但依然坚持说道：“你应该先问我，我同意了，你再去拿。”<br>◆ 唐三十六抬头看了他一眼，没理会他。　　陈长生把剑举的更近了些。　　唐三十六不肯接剑，说道：“做事一点都不大气。”　　陈长生无奈，心想到底是谁不大气？是谁在像小孩子一样赌气？<br>◆ 他发现自己今天经常处于无话可说的境地。<br>第一十四章 让人无话可说的朋友（下）<br>◆ 他记的非常清楚，她生于十一月十一日，比自己小三天。　　小一天也是小，更何况是三天。　　这个小女生，真的很让人讨厌啊。<br>第二十二章 读书的方法<br>◆ 这种方法里最重要的环节，是最后那步的笔记。无论是用笔记在纸上，还在记在自己的脑海里，都是对整个阅读过程的再次梳理与确认，也只有完成了这一步，才能说阅读者把书里的内容完全转化成了自己的知识。<br>第二十五章 万千星辰，只取一颗<br>◆ 那是因为他比任何人都清楚，活在这个世界上真正的诱惑是什么。<br>第二十八章 已多年<br>◆ 淡然有时候会让人失去一些锐气，但也会让人变得更加冷静<br>第三十章 一言惊风雨<br>◆ 但她不会，因为她是落落，她很大方，那么，她首先对自己很大方，而且这些东西，本来就是她的。<br>◆ 落落很委屈，所以她不想大方了，她决定以后如果能找到那个人，自己不要送他那么多礼物……　　或者，把礼物减去一半？<br>◆ 落落不止委屈，更开始伤心起来了。　　她可不想死。　　她始终认为，活着是最幸福的一件事情，是最美丽的事情——你看，天边的云很美丽，京都的云很美，有时候像街上姑娘的头发，家乡的云也很美，有时候像少年马贼的脸。<br>◆ 她除了修行、游戏，最喜欢的事情就是睡觉了。　　她知道自己这时候不能睡着，可是，真的很困呀。<br>第三十三章 先生，你就收了我吧<br>◆ 他站起身来，走到馆门将沉重的木门拉开，然后便看见了自己正在担心的那个小姑娘。　　小姑娘看着很小，眼睛很明亮，很大，睫毛很长，嘴唇很红，很好看，睁着大眼睛，眨睫毛的样子很可爱。　　他没有与这么可爱的小姑娘打过交道，一时有些发呆。<br>第三十五章 拜师（下）<br>◆ 其实他想问唐三十六，为什么知道自己进了国教学院却不去找自己，要知道他在京都里就这么一个认识的人，虽然他向来信奉耐得寂寞百事可为，但如果可以不寂寞，也是不错。　　只是以他的性情，实在很难直接问出口。<br>第三十六章 淫贼？废物？<br>◆ 藏书馆里没有灯光，他不在，国教学院自然如以往一般冷清。他走到湖畔，周遭寂静无人，只有星星在清澈的水里沉浮，对岸树林的倒影在夜色里并不清晰，深春的风拂面清爽。　　他站在湖畔的石块上，抬头看着夜空里的星星，看了很长时间，然后望向湖水里的星星，也望了很长时间，然后他闭着眼睛沉默地站立了很长时间，忽然对着湖水大喊了几声仿佛脏话般的字句。　　他给人的感觉一直都是平静沉默，有着超越年龄的早熟，像这样的情泄渲泄极为少见，今夜趁着酒意做了做，才发现居然有些累，干脆坐到湖畔的草坪上，向后倒下，开始发呆。　　藏书馆里一片漆黑，他没有去那里读书，也没有去星光洗髓，他只是躺在草坪上发呆，单纯的发呆，没有思考，这些年来、尤其是十岁那夜之后，他还是第一次这样放纵自己，第一次浪费时间。<br>◆ 习惯是很强大的东西，即便洗髓也无法洗掉——陈长生回到小楼，在水桶旁用湿毛巾认真地擦洗着脸，一面想着这些有的没的事情，余光看到旧墙上那扇紧闭的新门，不知为何竟生出些期盼。<br>◆ 读书是件很枯燥的事情，而看别人读书更是一件很无聊的事情，陈长生安静地读着书，自然不会说话，落落最开始的时候很感兴趣，跟着他凑在一起看，看了会儿发现很多书看不懂，便开始觉得无趣，觉得早起真不是一件好事情，困意就像树底下的那些蚂蚁一样，前仆后继、源源不绝地杀将过来，让她觉得自己的头越来越重……<br>◆ 能够睡的如此熟，如此香甜，自然是因为她很放松。她之所以如此放松，是因为她很信任他。被一个人完全信任，这种感觉非常好，尤其是对于一个人在京都沉默前行的他来说。<br>第三十七章 谢谢<br>◆ 他在名册上添上落落的名字，很凝重，很郑重。　　落落举起，对着阳光，鼓起小脸，用力地吹着，希望快些吹干。　　阳光下，名册被照的非常清楚，只有两个名字，但两个名字就够了<br>◆ 落落笑容微敛，轻提裙摆，缓缓拜倒在乌黑的地板上。　　陈长生沉默片刻，对着西宁镇方向拜倒，然后与她对拜。　　春和景明，湖静如镜，偶有风穿堂而过，绕书架，落鬓间。　　陈长生直起身体，将她扶起。　　落落说道：“谢谢。”　　陈长生不知该说些什么，想了半天，同样说道：“谢谢。”<br>◆ 陈长生沉默片刻，对着西宁镇方向拜倒，然后与她对拜。　　春和景明，湖静如镜，偶有风穿堂而过，绕书架，落鬓间。<br>第三十八章 第一堂课<br>◆ 陈长生想着自己的问题，望向窗外皇宫里凌烟阁的方向，有些感慨，他要做的那些事情，在任何人看来都是痴心妄想，但他必须那样去想，并且为之而奋斗，因为命运没有给他留第二条道路。　　“敢于去想，在梦想实现之前，永远不给自己提前设限，不给自己寻找任何退缩的借口、失败的理由，只有这样，我们才有可能把看似遥远的梦想，变成真正的现实。”　　“这，就是我给你上的第一堂课。”<br>第四十七章 虎虎生风<br>◆ “我可没答应你不杀他，更何况我只是废了他。”<br>第五十章 榕树上<br>◆ 她哪里想到自己很随意的一句话，便伤到了陈长生的自尊心。　　她确实是随意说的，所以伤的真的不轻啊。<br>◆ 他以远超自己年龄的冷静沉默等待着。　　没有任何人知道，他在国教学院里等了整整一夜，直到无数年后，依然没有人知道。只有他自己知道，这一夜是多么的漫长、多么的难熬，他为此付出了多少勇气。<br>◆ 陈长生说道：“意义不大。”　　落落看着他仰慕说道：“先生视虚名如浮云，真是令人佩服。”　　陈长生诚实说道：“主要是怕惹麻烦。”<br>第五十一章 教棍<br>◆ 轩辕破不知道这个人类少年是谁，看他神情便知道误会了什么，有些慌乱，连连摆动蒲扇大小的双手，解释道：“学院没有把我开除，只是……我受了这么重的伤，再也没法修行，不想留在学院里吃白饭，所以出来了。”　　看着陈长生和落落有些不肯相信，他有些着急，说道：“是真的，院长和教官都来劝过我，只是我这个人性子有些笨，不肯听他们的，偷偷跑了出来，你们可不能错怪他们。”<br>◆ 　　轩辕破看都没有看他一眼，一直盯着落落，很是紧张，难抑激动。<br>◆ 那声笑就是鸣，鸣不平，这名妖族少年替国教学院鸣不平，那么国教学院自然要有所回服。<br>第五十二章 铜针<br>◆ 陈长生很是无语，对着窗外东面微作的晨光拜倒。　　他是真没想到，自己才十四岁就要当师祖了。　　师父，你知道吗？　　师兄，好像我们这门真要在国教学院开枝散叶了。<br>第五十三章 有些乱<br>◆ 陈长生没有回头，说道：“菜有些咸，我想去静静。”　　今天的菜有些咸。　　他的声音有些淡。　　这句话有些乱。　　因为他的心乱了。<br>第五十四章 赴宴<br>◆ 自己会变得如此烦闷，甚至有些难过。<br>第五十六章 一道春风入夜来<br>◆ 他问心无愧，所以无惧。<br>第五十七章 人品问题<br>◆ 不用谢我。事实上，你这孩子受了池鱼之灾，我们这些在城门上看风景的无用家伙，应该说声抱歉才是。”　　陈留王看着他微笑说道，说的很随意，语气却很真诚。　　城门失火，才会殃及池鱼。<br>◆ 陈长生想了想，说道：“或者，是因为我人品不错的缘故。”　　说完这句话，他笑了起来。　　在很多人眼中，陈长生有着超越年龄的成熟稳重，因为他向来表现的很平静，很少有大喜大悲的表现，与不怎么亲近的人相处，只是谨守礼数，便是连笑容也不怎么多。　　但他这时候笑的很开心，因为是在徐世绩的身前。　　徐世绩也在笑，似乎是觉得小孩子的回答很有趣，很幼稚，但他笑的很难看。<br>◆ 国教学院是一片无人前来相看的湖，里面生着很多野荷花。　　他只是误入这片废湖的过客，想把小船划到湖对岸，起桨时，却惊起一滩鸥鹭。<br>◆ 你可以叫我莫雨姑娘。”　　“是，莫大姑娘。”<br>第五十九章 桐宫之囚<br>◆ 宁婆婆说道：“老奴倒觉得可笑之人，每多可爱。”<br>◆ 大道三千，他修的是顺心意。顺心意而行，顺心意而活，天地让他不得顺心意，他便要想办法让自己的心意顺起来，只有顺心意，才能拥有真正的平静，而平静，正是冷静的最高境界。<br>◆ 必须做到，所以一定能够做到，在此之前，他必须相信自己能够做到，如此心意方能顺明。<br>◆ 因为只有顺心意，才能逆天命。<br>第六十章 独闯龙潭<br>◆ 短剑是他下山之前，余人师兄送给他的礼物。　　他读遍三千道藏，都未曾发现过比余人师兄还有勇气的人。　　所以他以为师兄的剑，便是勇气的来源。<br>第六十一章 一名少年在黑色巨龙前的独白<br>◆ 陈长生懂得这眼神的意思，那就是一个人类孩子看着树下的蝼蚁。　　那是一种格外纯净的冷漠残暴，不需要原因，也不需要道理。　　孩子可以看树下的蝼蚁看半个时辰，然后用鞋底把它们尽数踩死。<br>◆ 对死亡，他倒是准备了好些年，可现在死亡真的即将到来，他才明白，自己依然没有准备好。　　原来，死亡是一件无法准备的事物。　　地底空间一片死寂，夜明珠洒落的光辉，像雪一般，落在他的身上。<br>◆ “改变命运真的太难，我这些年活的真的太累，但再累我也想活下去，因为西宁镇的猪头肉切成薄片再蘸了红油与岩盐真的很好吃，因为书上真的有很多有趣有意思的知识，因为生命真的很美好。”<br>第六十四章 吱吱<br>◆ 从一千多年前出生开始，直到现在，它从来没有这样开心过，不知道该以怎样的啸声来迎接。　　而且因为某些原因，它必须压抑着啸，压抑着笑。　　“吱吱……吱吱……吱吱……”　　听着很像老鼠在叫，很是滑稽可笑。　　但有无比狂喜在里面。<br>第六十六章 问世间<br>◆ 圣后平静说道：“你又错了，这件事情也不是我能决定的事。”　　太监首领微惊，心想除了您老人家，谁能决定这场婚事的走向？　　“要嫁人的是有容，那么，想不想嫁，要嫁谁，终究要看有容的态度。”　　圣后说道：“那丫头是个有主意的人，别人做再多事情，又有什么意义？徒增笑谈罢了。”<br>第七十章 白帝为姓（上）<br>◆ 你和这些人说利益，他们说情怀，你和他们说情怀，他们和你说道德，你和他们说道德，他们和你说道理，总之，当这些人说不过你的时候，当他们没有道理的时候，他们便会不停转进，直到事情按照他们的想法或者说想象进行。<br>◆ 唐三十六看着他说道，然后转身望向南方使团所在的座席，目光落在关飞白的身上，骂道：“说的就是你们啦！连个小姑娘都知道你们做事无耻，你们自己难道没有感觉？放肆？放你妈的肆啊！”<br>第七十一章 白帝为姓（下）<br>◆ 这个中年男人很啰嗦，很像个大妈。　　中年男人便是百草园里的金长史。<br>◆ 陈长生认真说道：“这不是坏事情，这是值得骄傲的事情。”<br>第七十二章 有一个少年<br>◆ 唐三十六看着他嘲弄说道：“死心吧，你家大师兄秋山君娶不着老婆了……难不成，你现在还敢当众杀了陈长生不成？”<br>◆ 他是个十六岁的少年，真正的少年，看着春风不喜，看着秋风不悲，看着冬雪不叹，看着夏蝉不烦，他看着喜欢的才喜，看着厌憎的便烦，看着不公平的便叹，看到夕阳下的壮烈背影才会悲。<br>◆ 他喜欢独处，喜欢睡觉，就是不喜欢与人打交道，他有些轻微自恋，非常骄傲自信，活的无比自在，人世间的蝇营狗苟和他没有关系，看见不高兴的便要骂，看见喜欢的便要去亲近。　　他就是这样的少年，本性如此，就算他不是青云榜上的天才，只是个在墙角根晒太阳的少年乞丐，看着乘辇经过的漂亮郡主少女，也会吹两声口哨，看着欺男霸女的富家少爷，也会偷偷踹两记黑脚，才不会管会不会被侍卫揍出满头的青包。<br>◆ 唐三十六就是这样的人，喜欢就是真喜欢，不喜欢就是真不喜欢，所以喜欢他的人会非常喜欢他，比如汶川家族里的老爷子，比如天道院的庄副院长，不喜欢他的人是真不喜欢，比如此时南方使团里那些愤怒的年轻人们。<br>第七十五章 意难平<br>◆ 终究意难平。”<br>◆ 国教学院就我们这几只麻雀，输给离山剑宗丢人吗？好吧，确实还是有些丢人，但那无所谓，只要你不出场就行……你不出场，他们便没办法把今天丢的面子找回来。”　　唐三十六看着广场对面夜色里那个神情平静的家伙，冷笑说道：“憋死他们！”　　说完这句话，他手扶剑柄，向对面走去。<br>第八十八章 破院（上）<br>◆ 漆黑的夜空里繁星点点，像河像山像原野，也有些星迹相连仿佛笔画，似乎写着五个字。<br>第八十九章 破院（中）<br>◆ 陈长生依然对着整座京都喊道：“声音喊大些，说不定会有人听到，然后来帮我们啊！”　　唐三十六喊道：“你想的好美啊啊啊啊！”<br>第九十章 破院（下）<br>◆ 鲜衣怒马<br>第九十四章 院门与人心<br>◆ 我没有错，那我凭什么不硬，气势凭什么不强？<br>第九十五章 门房，对话，床上的人<br>◆ 留下倒也不是不可以。”金玉律看着三个少年之间的眼神，呵呵笑了起来，说道：“我这辈子没犯过什么错，因为没有什么太喜欢的事物，不过我真的很喜欢钱。”　　陈长生看着他身上绸衫上那些铜钱的图案，笑了起来，知道对方这便是准备留下了，揖手再谢。　　唐三十六凑到金玉律身边，握着他有些粗糙的手，不停摇着，说道：“您肯定知道我家，我家别的什么都没有，就是有钱，什么都缺，就是不缺钱。”<br>◆ “我如此真实，他不喜欢我，那就是虚伪。”　　“你可以把真实二字换作放浪。”<br>第九十七章 战一座京都（上）<br>◆ 陈长生诚实说道：“如果您可以杀我，前夜在黑龙潭边，我就已经死了，既然我没死，肯定是因为某些原因，您不能杀我，所以我怕死，但……不怕您。”　　还是那句话，越真实越伤人，所以他这句话最伤人。<br>第九十八章 战一座京都（中）<br>◆ 你就会成为历史上最著名的一只癞蛤蟆！那国教学院算什么？养蛤蟆的池塘？<br>第一百三章 满山野花盛开的年代<br>◆ 最重要的是，这三个小家伙仿佛都不知道什么叫害怕，什么叫气馁，他们对世界有自己的看法，而且坚定，心思像琉璃一样剔透，阳光落在他们的身上，会折射出更为艳丽夺目的光彩。<br>第一百二十章 宣告<br>◆ 轩辕破不难受，他很高兴，登上青云榜这件事情让他喜不自胜，却不知该如何表达，一身精力与喜悦无处发泄，扛着唐三十六跑的越来越快，不时还在他的背上拍打两下，很快便跑近了离宫的正门。<br>第一百二十六章 我真的还想再活五百年<br>◆ “算了，死了就死了，留什么话都没有意义。”<br>第一百三十四章 文试开始<br>◆ 那名少年有些瘦，但绝对不瘦弱，单薄的衣裳下，仿佛隐藏着很多力量。　　他眯着眼睛，看着东方初升的朝阳，有些向往，又有些畏惧，不敢接近，所以有些刻意的冷淡，就像陈长生对繁华人间的态度一般。<br>◆ 不刻意平静才是真正的平静，才代表着自信。<br>第一百三十五章 最后交卷的两个人<br>◆ 他的声音淡的像冰，语调平的像荒野，语速很慢，就像是一个字一个字地往外蹦，就像是很久没有开口说话一般。<br>◆ 走到神道前的青树下，苟寒食向他问道：“周虽旧邦，其命唯故，这道题你怎么看？”<br>第一百四十二章 握手<br>◆ 辛教士专程去国教学院泄题，便证明在他或者是主教大人看来，武试里的过江环节，对陈长生来说最为困难，对此陈长生没有说什么，但轩辕破和唐三十六私下已经做好了准备，牺牲自己的准备。　　轩辕破准备抓住陈长生的手，直接把他扔到对岸。　　悄无声息间，唐三十六脚步轻移，站到了陈长生的身后。他和轩辕破清楚，陈长生肯定不会同意这种做法，稍后一定会反抗，他的任务就是在陈长生反抗的时候，直接把他制住，然后把他捆起来。<br>第一百五十四章 崖畔<br>◆ 为天地立心，为生命立命，为往圣继绝学，为万世开太平，所以请你去死。　　铁肩担道义，你死后，家人我来照顾，这个世界也由我来照顾。　　陈长生摇了摇头，如果只有前半段，那很值得尊敬，如果加上后面半句，那便不好。　　他不喜欢这种味道。<br>第一百六十一章 日常<br>◆ 直到今天，人们才知道离山剑宗年轻一代为何如此强大，神国七律的光芒为何如此耀眼。　　同门相战，竟是毫不留力，却不记恨负气，因为在他们看来，这些只是寻常事。　　日日行此寻常事，便是非同寻常，离山如何不强？<br>第一百六十二章 两名少年的连胜<br>◆ 仿佛回到了夏时的故乡，过了鹿鸣坡后有条江，那里种着大豆和高粱，可以不用狩猎，也能填饱肚子，只是高粱烤的再如何焦香，终究不如肉香。<br>第一百六十四章 天煞孤星<br>◆ 大朝试开始前，离宫外人山人海，折袖一人看朝阳，进了昭文殿，他直接离开了文试现场，一人走过那片林海，掠过那道青江，站在山上的亭子里，背对着所有考生，孤单地像是没有妈妈一样，这样的人会需要朋友？　　“你们难道不觉得他很孤？”唐三十六看着陈长生三人问道。　　他这里说的是孤，不是孤单也不是孤独，只是孤伶伶的一个字，于是显得越发孤。<br>第一百七十四章 打出自己的价钱<br>◆ 嘶啦声起，轩辕破开始替他包扎。陈长生替他喂药。落落看着他情绪有些复杂。唐三十六叹道：“何至于打的如此苦？”　　折袖看着他面无表情说道：“加钱。”　　……<br>第一百七十六章 八方候此一战<br>◆ 轩辕破用宽厚的手掌摸遍全身，也没找出什么好玩意儿来，就连代表平安的符都没一个，不由有些沮丧。　　陈长生拍了拍他的上臂，笑着说道：“晚上你做饭。”<br>第一百八十四章 靠着楼墙，断了过往<br>◆ 苟寒食知道原来自己没有猜错。　　他沉默了很长时间，望向楼外的碧空，觉得有些饿，想吃些稀饭。　　过了很长时间后，他摇了摇头，把剑收回鞘中，转身离开了洗尘楼。<br>第二百一章 没有命运这回事<br>◆ “人间本没有路，路只是在我们的脚下，看你怎么走，怎么选择自己的位置。”　　“位置是相对的，我视君为君，我便是臣，我眼中无君，我便不是臣。”　　“所以，没有命运，只有选择。”<br>第二百五章 天书陵<br>◆ 但生命难道不应该是自由而喜悦的吗？怎么能尽数放在这片青山中？<br>第二百六章 守陵人<br>◆ 唐三十六嘲笑说道：“哪里来这么多似是而非的道理？两点之间直线最近，所以最正的正道，本身就是最快捷的途径。”<br>第二百八章 篱笆墙畔两小儿<br>◆ 看着远处将要落山的夕阳，他的手落在短剑的剑柄上，神识轻轻拂过那颗黑色的石头，感受着那股温润的气息，才清醒了些，明白原来观望代表着犹豫，而他之所以犹豫是因为下意识里不想继续修行。<br>◆ 暮色渐浓，青丘仿佛在晚霞里燃烧，他已经绕着天书陵走了一圈多，来到了西南角一片林园里，看到了一间草舍。　　草舍修建的很简陋，梁木上甚至还看得到树皮，显得极为粗糙，檐上铺着的草不知道多少年没有换过，黑黑灰灰很是难看。<br>◆ “活着，是最重要的事情吗？”他看着折袖认真问道。　　一个十五岁的少年，向同龄人询问有关生死、似乎显得很哲学的问题，在京都那些学院里，他绝对会被人嘲笑一番。　　折袖不是普通少年，所以他没有嘲笑陈长生，而是沉默了很长时间，经过一番非常认真的思考之后，才做出了自己的回答。　　“活着，不是最重要的事情。”　　在风雪漫天的北疆，活着是很艰难的事情，一个自幼便被逐出部落的杂血狼崽子，想要活下去更是困难，折袖拼命地活了下来，为了生存做了无数冷血的事情，但他却不认为活着是最重要的事情。　　这个答案有些令人吃惊。　　陈长生认真地想了想，说道：“谢谢。”　　折袖在篱笆墙外说道：“不客气。”　　陈长生问道：“那对你来说，什么才是最重要的事情呢？”　　折袖说道：“清醒的活着，或者清醒的死去。”<br>第二百一十四章 战风雪<br>◆ 生命，就是要痛苦才真实。<br>第二百一十六章 于晨时观碑<br>◆ “以后不管发生什么事情，我都不要对你说谢谢，你也不要对我说不客气。”<br>◆ 他对修行忽然失去了兴趣，他在天书陵里当了一天的游客，都是因为心意乱了。好在他听到了折袖的答案，见到了荀梅向天书陵去。荀梅用三十七年才醒过来，他只用了一夜时间，不得不说，这是很幸运的事情。<br>◆ 微凉的晨风轻拂脸颊，晨光照亮前路，行走在清幽的山林里，听着晨鸟清亮的鸣叫，看着被树枝画花了脸的朝阳，陈长生的心情很是平静喜乐，比起别的人，他要晚了一天时间，但他觉得无所谓。　　是的，这确实是在浪费生命。　　就像他和折袖对话时曾经提过的那样，棋琴书画，欣赏风景，也都是浪费生命。　　但这种浪费生命的方法多么美好。　　有生命可以用来浪费多么美好。　　……<br>第二百二十四章 夜里挑灯看碑（下）<br>◆ 万溪风光不同，终究同入大海。”<br>第二百二十六章 往事知多少（下）<br>◆ 他来到碑庐前，未作停留，伸手拉着陈长生便往天书陵下走去，一路走一路碎碎念道：“瞧你这点出息，连吵架都吵不过个人，真给我们国教学院丢脸。”<br>◆ 不能把有限的生命浪费在无限的破事上。”<br>第二百二十七章 第一个解碑者<br>◆ 唐三十六微傲说道：“让他们嫉妒去。”　　关飞白面无表情说道：“不遭人嫉是庸才。”　　二人对视一眼，忽然觉得不对劲，转过脸去，同声说道：“但我们可不是一路的。<br>第二百三十章 雁鸣（上）<br>◆ 陈长生说道：“哪里不对说不出来，如果按照观碑文变化的思路解下去，应该能够解开天书碑，可我感觉总有些怪，总觉得哪里差了些什么，如果在还没有想透彻的时候依然继续解读下去，我很难说服自己，因为我修的就是顺心意。”<br>第二百三十四章 应作如是观（上）<br>◆ 陈长生的性情虽然平稳，但非常在意顺心意。他想要问个究竟的渴望，或许表现出来的很淡然，实际上同样强烈，如野火一般。<br>第二百三十七章 今夜星光灿烂<br>◆ 如果人类的命运真的隐藏在这片星空里，星辰的位置永恒不变不移，命运自然无法改变，那么人活在世上究竟为什么还要奋斗和努力？<br>◆ 今夜，陈长生认识到肃穆并不代表着僵化，真正的完美并不是永远不变。　　因为星辰是可以移动的，位置是可以改变的，自己的命星与别的星辰之间的距离以及角度自然也在改变。　　如果说那些联系便是命运的痕迹，那么，岂不是说命运可以改变？　　王之策在笔记最后力透纸背写了四个字：没有命运。　　是的，根本没有确定的命运！<br>第二百四十一章 春眠不觉晓<br>◆ 陈长生说道：“那我可不会给你加钱。”　　折袖停下脚步，想了想后说道：“这算赠送。”<br>第二百五十七章 小小苏<br>◆ 他的兴趣在于剑，在于旅途，在于流云与星空。<br>第二百六十二章 两地医（中）<br>◆ 陈长生想了想，说道：“就是有些不忍心。<br>第二百六十三章 两地医（下）<br>◆ 折袖居高临下看着他，说道：“你可以把前句话里的有些人三个字换成她。”　　陈长生做完了事，站起身来，看着他很认真地解释道：“我可不是在和她比什么。”　　折袖很认真地说道：“我不信。”<br>第二百七十三章 一条名为勇气的路<br>◆ “我看不见了，所以从现在开始，由你指路。”　　折袖的声音很平静，没有任何情绪波动。<br>第二百七十四章 狼突<br>◆ 七间不再闭眼，不是因为折袖的保护让他不再害怕，而是他想尽可能地把前路看的更清楚一些，希望他能少摔几次。　　折袖的身上已经满是伤口，鲜血不停地流着。　　他闭着眼睛，低着头，沉默着，继续狂奔着。　　七间紧紧地抱着他，眼圈早就红了。　　她想哭。　　但他说不要哭。　　她听话。　　所以她不哭。　　……<br>第二百八十五章 梧桐<br>◆ 梧箭与孤桐。　　吾的剑，孤的桐<br>第二百九十四章 纵使相逢应不识<br>◆ 她伸手抓住陈长生的腰带，向对岸走去，就像拎着一个包袱。　　因为她个子不高的缘故，陈长生的脸不时浸进水里，在芦苇丛里带出一道水花，惊醒了些游鱼。　　这人天天吃的啥呀，看着不胖，怎么这么沉？　　她这样想着。<br>第三百一章 人生若只如初见（二）<br>◆ 南客曾经不止一次地想起初见他时的那个早晨，每每都会生出淡淡的悔意，心想当时如果自己再果断一些，不去听他说的那些废话，或者真地有可能当时就把他杀死，那么便不再会有后续的那些故事与麻烦。<br>第三百二章 人生若只如初见（三）<br>◆ 看着南客幽绿诡异的眼眸和无风飘舞的黑发，他才觉得自己说错了什么，赶紧伸手比划着解释道：“当然没有我说的那么夸张，你只是眉眼宽一些，眼瞳受到神魂的影响，本能里向中间集中，所以看着有些呆呆的，但你的智力肯定没有任何问题。”<br>◆ 不愧是国教学院的诚实可靠小郎君，这番解释还不如不解释。<br>第三百四章 人生若只如初见（五）<br>◆ 我不知道他为什么要杀你，也不是很理解你们这些同门之间的关系，因为从我开始记事起我就是在独自生活，我不认为世间的事情都需要一个理由，我更看重结果，所以你只需要记住，他要杀你，那么他就是你的敌人，不再是你的师兄。”<br>第三百五章 人生若只如初见（六）<br>◆ 在过去的一天一夜时间里，他们已经很多次重复了这个过程，按道理来说，应该很熟练，但或者是因为确认七间是女孩子的缘故，折袖的动作显得有些生硬，向后伸去的双手有些僵硬，看着就像一只快要被炖熟了的鸭子。<br>第三百六章 人生若只如初见（七）<br>◆ 她的眼如秋水，却不是湖水，而是一抹更淡更清的水色。　　那只青瓷碗静静地搁在檐下，一场清新的春雨洒落大地，顺着檐角淌落，嘀嘀嗒嗒，渐成琴曲，不多时，春雨渐停，阳光重现明媚，那只檐下的碗仿佛先前，但碗中多了些水，没有颜色，却仿佛带着春意，没有味道，却仿佛冲过一番新茶。　　是的，便是瓷碗里的那层水，清澈而浅，但不薄。<br>第三百九章 人生若只如初见（十）<br>◆ 白首如新，倾盖如故，没有说过多少话、连对方名字都不知道的陌生人，可以把自己的身家性命托附。<br>第三百一十章 人生若只如初见（十一）<br>◆ “谢谢。”她醒过神来，扶着他的肩头，靠在了他的背上。　　“不好意思。”他伸手挽住她的膝弯，把她的身体往上挪了挪。<br>◆ 人性是不能考验的，每考验一次，便有可能向出题者相反的方向走一步，同样，信任也不是拿来用的，每用一次都是对信任的一次磋磨。<br>◆ 白草为路，直上星海。<br>◆ 就在这时，他们撞破雨帘，看见了一座庙。<br>第三百一十一章 人生若只如初见（十二）<br>◆ 一路上，因为各种各样的原因，他们很少说话，但为彼此做了很多事情。　　同生共死，不离不弃，这些在世界里最光彩夺目、非常纠连的词汇，就被她和他很简单随意地做到了。<br>◆ 他们都不喜欢那份婚约，都想退婚，但他不想她知道这件事情，她也不想他知道这件事情。<br>◆ “雪山宗，徐生。”　　“秀灵族，陈初见。”<br>◆ 她的声音很轻，舌尖微卷，尾音轻轻地拖着，哪怕是说自己的名字，也显得有些生涩，落入他的耳中，觉得很好听，声音好听，名字也好听，姓陈这很好，叫初见也很好，有句话是怎么说的？人生若只如初见？他看着她有些浮肿但依然清丽的脸，想着前些天在青草堆畔，她捂着自己双颊时的可爱模样，心想，如果人生能够像这个叫初见的女孩一样，倒也确实不错。<br>第三百一十二章 天才夜话以及追赶<br>◆ 而天才往往是孤单的，因为缺少能够在精神世界里平等交流的对象，这句话看上去似乎有些老套，但非常真实<br>第三百一十四章 清风问道<br>◆ 现在做不到，不代表以后也做不到，而且就算一直都做不到，又有什么？努力应该是发自内心的渴求，而不应该来自与别人比较而产生的心理落差，只要真的努力过了，那就足够。<br>◆ 不要再说完美这两个字，完美是用来形容程度的，并不是具体的事实。<br>第三百一十五章 过四季而见陵<br>◆ 跑出被雨云遮盖的夏季，陈长生把徐有容放在一片烂漫的春花里，然后取出在冬天准备好的一大块洁白的净雪以及在前两座庙里拿的器具，开始融雪煮水，同时开始把清晨时分捉的那只秋雁拔毛剖腹，准备做一锅菱角炖雁肉。<br>第三百一十七章 他所寻找的宝藏<br>◆ 在这片草原里，从那片芦苇丛到这座陵墓，已经有数次，她都快要被他真正感动了，却被她以难以想象的精神力量控制住。对于像她来说，能够控制住悲喜，相对容易，能够控制住愤怒，也很容易，但感动是一种很特殊的情绪，很难控制。　　这种情绪从来不会突然地出现，需要很长时间的浸染，但真正出现的那一刻，却必然是突然的，需要某个点。厚积，然后薄发……这句话可能用来说修行，也可以用来形容这种情绪。到了此时此刻，那种情绪终于推破了坚硬的岩壁，在清风里开始招摇生长。　　她真的很感动。　　……<br>第三百一十九章 我可能是你的命运<br>◆ 就因为这句话、这句并不是第一次出现的话，陈长生忽然觉得自己的胸口被一块石头狠狠地砸了下，难过到了极点。<br>第三百二十二章 再临绝境，两个小朋友<br>◆ 他再一次地觉得这个秀灵族的天才少女有些孤单可怜，笑着问道：“……那我算不算？”　　徐有容没想到会听到这句话，看着他微笑说道：“算。”<br>第三百二十三章 临渊对谈，一个动心人<br>◆ 师兄说过，如果努力到最后发现还是无法改变命运，那么只好体味或者享受命运带给你一切。”<br>第三百二十四章 不能要的女人，无耻的男人<br>◆ 陈长生伪光正说道：“小男孩往往都是很让人讨厌的……我也不例外。”<br>◆ “他喜欢拈花惹草。”　　她尽可能平静地客观描述道：“而且都是些不懂事的小姑娘。”　　夜色笼罩的陵墓平台上一片安静。　　不知道过了很长时间，忽然响起一声重击，然后是陈长生愤怒的声音。　　“真是个无耻败类！”<br>第三百六十三章 一剑万里<br>◆ “前你个头的辈，你这个猪头还不赶紧靠过来点！伸手抓住了！”<br>◆ 苏离看着天空里的阴影，神情漠然，自有一派高手风范，只有陈长生能听到他齿缝里钻出来的那道声音：“你这个猪头给我抓紧了，不然半道掉了，我可不会停下来拣你。”　　陈长生很听话地紧紧握着黄纸伞的前端，还加了一只手。<br>第三百七十四章 全职教育（二）<br>◆ 陈长生欲言又止。　　苏离的眉挑的更高了些，说道：“有话就放。”　　陈长生说道：“前辈，这伞……是我的。”<br>第三百七十六章 全职教育（四）<br>◆ 苏离躺在车里，身下垫着厚厚的被褥，身上盖着顺滑柔韧的兽皮，黄纸伞搁在身边，酒食也在身边，竹笛横拿在手，凑在唇边，不时发出清丽的声音，看着惬意到了极点，哪里有半分重伤逃亡的凄惨感觉。<br>第三百七十七章 杀人的神将<br>◆ 薛河没有理会他，看着苏离平静说道：“唯南北合流，我大周统一天下，才能真正战胜魔族，却因为先生的存在，始终难以前行，无论是朝堂还是国教，有很多人都指望先生能改变态度，但我知道先生不会改变态度，所以……您必须死。”　　苏离正色说道：“我……会改的。”<br>第三百八十章 苏离的眼光（下）<br>◆ 苏离坐在毛鹿上，看着陈长生说道：“我真的服了你了。”　　陈长生有些不好意思地笑了笑，说道：“前辈，您太客气了。”　　苏离强忍怒火，说道：“客气你家祖宗十八代，我是说这个吗？”<br>第三百八十一章 周通会知道刘青做过什么<br>◆ 周通做事，什么时候需要证据？<br>第三百八十八章 简单少年<br>◆ “前辈，帐不能这么算，准确来说，性命这种事情是没有办法算帐的。”<br>◆ 苏离微怔。他很清楚，陈长生不是自己的崇拜者，也没有什么意趣相投，更谈不上什么忘年交，所以才会好奇陈长生为什么一直没有离开，直到此时此刻，才知道，原来就是因为这么简单的一个道理，当然，能够坚持这种道理的人，真的很不简单。<br>第三百九十一章 新的剑法<br>◆ 他总以为少年总有少年独有的精气神，所谓朝阳与晨露，新蝶与雏鸟，那种青春的生命的气息是那样的清楚与激昂，陈长生也有这方面的气质，却更加淡然，这个少年也是一缕春风，但是初春的风，很是清淡，于是清新的令人心旷神怡。<br>◆ 一般的少年在醒着的时候，往往会刻意压低音调，故作平静从容，以此搏得长辈老成的赞许以及同辈沉稳的评价羡慕，而在睡眠里则会回到真实年龄段应有的模样，露出天真无邪的那一面，陈长生却并不这样，他的眉眼是少年的眉眼，清稚的仿佛雨前的茶园，但神情却还是像醒着时那般平静，甚至……反而有些哀愁。<br>◆ 陈长生从溪里走了回来，手中的树枝上穿着一只肥嫩的大白鱼，赤着的双足踩碎了溪面上燃烧的太阳，笑了笑，并没有说话。<br>第三百九十四章 浔阳城的春光<br>◆ 一路行来，他看得非常清楚，苏离表面上是个很散漫、甚至有时候会很可爱的前辈高人，但实际上他就像他的名字一样，对这个世界很疏离。苏离不相信人性，不相信人心，不信任自己这个世界，不与这个世界对话，所以他永远不会向这个世界求援。　　他孤单地行走，已经走了数百年。<br>◆ 但陈长生不想这样行走，他总以为自己对世界保有善意，世界便会对你释出善意，当你看青山妩媚的时候，青山也会看你顺眼很多。<br>◆ 苏离觉得手有些冷，压低声音喝道：“你这个小疯子，我……”　　话没有说完，陈长生直接走到窗边，双手向外用力推开窗子。　　深春里的浔阳城，人声鼎沸，春光明媚。　　窗户被推开，阳光与春风灌进了房间，照亮了幽暗的黑夜。　　一道清亮如春光般的喊声，响彻浔阳城的街头。　　“离山小师叔，苏离在此！”　　……<br>第三百九十五章 人间处处是麻烦（上）<br>◆ 浔阳城一片死寂，死寂的背后却是真正的混乱，不知道多少普通人家里的碗碟遭了殃，不知道多少人崴了脚。<br>第三百九十七章 一场盛宴的开端<br>◆ 因为只看了一眼，他便知道自己绝对没有任何可能战胜梁王孙。　　比头发丝更细的一丝可能都没有。<br>◆ 世间有很多事情只能做不能说，更不能让人看见，不然不好交待。<br>第四百二章 我们活着的意思（下）<br>◆ 这意味着，对苏离来说，快意永远是要比恩仇更重要的事情。　　这么活着，真的很有意思。<br>第四百八章 三棵松（上）<br>◆ 没有人会随着年岁增长品德就天然提升，绝大多数时候都是一个年轻的傻逼变成了老傻逼<br>第四百九章 三棵松（下）<br>◆ 我若是砥柱，就该站在大河中央，我若是浮萍，就该顺水而下，我是苏离，我凭什么要站在岸边？<br>第四百一十二章 出剑（上）<br>◆ 除非他这时候收起铁刀，离开雨街，选择避让，才能逃离这些苦处。　　然而生命里有很多苦处，是无法避让的。<br>第四百一十七章 有本事，不代表有用<br>◆ 反正我也不喜欢苏离这个人，他与人世间……太过疏离，留之何用？<br>第四百二十六章 父与子（上）<br>◆ 你们已经老了，可以活得现实一些，但我们还年轻，如果我们活下来，必将还有漫长的岁月等着我们，我不想在以后的岁月里想起今日便后悔、痛苦，所以我不会按照你们的方法行事。<br>第四百三十四章 有朋自南方来<br>◆ 你看看这个世界，只有一个呆子，一个少年和一只见不得光的鬼在你的身前，而我们是整个世界。<br>第四百三十八章 落日不见是清晨<br>◆ 圣女说道：“陈长生和王破是一路人，和你不是。”<br>◆ 圣女说道：“有个年轻人和你很像。”　　“谁？”　　“唐老太爷的孙子，唐棠。”　　苏离厌憎说道：“我最讨厌唐家的人。”　　圣女说道：“人最讨厌的往往就是自己。”<br>◆ 陈长生说道：“但至少是有善的一面，就像前辈杀伐决断，傲视天下，但也有善的一面。”　　苏离挑眉说道：“又不是煎饼子，哪里来这多面，要不要再加个蛋？”<br>◆ 落日仿佛朝阳，夜风微凉仿佛晨风，街上残着的雨珠很像露水。从周园到浔阳城，他经历的这些事情并不如梦，真切地如同身上的伤口一样，但隐隐约约间，他总觉得自己好像忘记了一件很重要的事情。　　他并不知道此时在京都，正有一场风波在等着自己。　　他只想把那件事情想起来。　　然后，他想了起来。　　他对着落日里的苏离的背影喊道：“前辈……那伞是我的。”<br>第四百四十七章 春雨里的太阳<br>◆ 唐三十六从善如流，举起盛着豆浆的碗，以祭苍天，对着渐要被云掩住的太阳，说道：“日。”<br>第四百四十九章 共商何事<br>◆ 生死之外，皆是闲事。　　死生亦大矣。　　人生无大事，唯生死系之。<br>第四百五十章 锦鲤，沉塘，铁刀的光芒<br>◆ 现在他们终于接触到了这些，却忽然间发现自己不想成熟了。　　因为成熟往往意味着腐朽，意味着复杂与疲惫。<br>◆ 你要明白，我们想成为什么样的人，那么我们的世界就会变成什么样。”<br>第四百五十一章 不管秋风还是春风，让我们砸树吧<br>◆ “因为要成为王破太苦太难，而且很容易悲壮。不管我们要怎样活着，最好还是离悲壮这个词远些<br>◆ “天凉了，让王家破产吧。<br>第四百五十四章 把那梅花看好多年<br>◆ 如果没有敌人，或者说如果你的敌人就是时间，那么你如何与之战斗<br>第四百五十五章 钟声响起归家的讯号<br>◆ “成熟真是一件很困难的事情，因为很难把握其间的度，果子熟透了，就很容易腐烂。”<br>第四百六十六章 天道西流去<br>◆ 这里的安静，代表着很多意思，比如在不需要说话的时候，不说话，拙于言而敏于行，却静于心，比如遇大事有静气。<br>第四百六十七章 停车开车，言钱道剑<br>◆ “如果你们觉得我太惨……加钱好了。”<br>第四百七十一章 那些你所不知道的事情<br>◆ 秋山君忽然笑了起来，说道：“想来那个人肯定不是我。”<br>第四百七十七章 今年夏天，就看国教学院<br>◆ “我不管，我想她了。”　　唐三十六站起身来，扶着大榕树粗大的树干，看着远方落日下的离宫大声说道。　　陈长生看了他一眼，很感激。　　他的身份也很敏感，很多话不方便说。唐三十六说想落落了，是因为他知道陈长生想落落了，落落肯定也想这里的大榕树了。<br>第四百九十一章 剑从口出（一）<br>◆ 这时，折袖忽然在床上睁开了眼睛，不知为何。　　唐三十六这时候心情非常不好，看着他喊道：“听着她的名字就知道醒了？不装死了？色狼！”　　折袖想了想，说道：“等我伤好，就来揍你。”<br>第四百九十九章 两株野花满山崖（上）<br>◆ “汶水唐家最了不起的地方是什么？不是财富也不是谋略，而是眼光。”<br>第五百零章 两株野花满山崖（中）<br>◆ 我从来没有见过你这样的人，世界上像你这样的大概比纯白色的独角兽还要少吧，因为你活的……太认真，太端正了，虽然到现在我还不知道你在追求什么，但那种感觉……很有意思。<br>第五百一章 两株野花满山崖（下）<br>◆ 他遇到了唐三十六，才知道原来年少就应该轻狂，而不应该像自己和余人师兄那样，明明还很年轻，却像得道多年的老者一样清心寡俗地活着，才知道原来世界上有些事情就是应该去争取，该放弃就是要放弃，或者说，他从唐三十六的身上学会了如何能够活的更轻松些。<br>◆ 夜空里洒落的星光，笼罩着大榕树，把他的衣衫镀了一层淡淡的星晖，远远望去，就像一个很漂亮的小银人。<br>第五百九章 再入周园<br>◆ “痛苦。”折袖看着他的眼睛，说道：“可以激发生命力，越大的痛苦越能激发出越多的生命力，只要你能够清醒地承受那种痛苦。”<br>第五百一十四章 离宫解铃<br>◆ 只是你要能够做到确认，选择确实是在顺心意而行。”<br>第五百二十二章 风雪故人来<br>◆ 她先前就在想这些事情，这时候再次想起，便无法再压抑住。　　当然不是想他，也不是想去看他。　　她对自己说。<br>第五百二十七章 奈何桥的风景<br>◆ 因为他是在等待，等待便意味着被动，这些在桥上的时光片段，需要思考来填满，然而大战之前，想的太多从来都不是好事。<br>◆ 或者心浮气躁，或者平静宁神，先适应环境，终究是要看人的心性。”<br>第五百三十七章 理还乱<br>◆ 这是奈何桥之战开始之后，二人第一次开口说话。　　也是“陈长生”和“徐有容”的第一次交谈。　　徐有容说我输了。　　陈长生说你再说一遍。　　如果说出这句话的人是唐三十六，那么这句话毫无疑问就是极具杀伤力的嘲讽。徐有容肯定会直接用天凤真血把这座桥烧了。但她知道陈长生的性情为人，知道他猜到了些么，有些紧张，所以并不生气，微笑不语。<br>◆ 她走到桥畔，站到他的身边，向着洛水上游看去，平静说道：“有什么好看的吗？”　　“你……你先别对我说话，我这时候有些乱。”<br>第五百四十一章 倾伞如故否？<br>◆ 一路同生共死，朝夕相伴，坐而论道，起而迎敌，倾盖如故，白首到老。　　倾伞，便如故。<br>第五百四十七章 雪夜入宫<br>◆ 他看着陈长生说道：“居然学会了说笑话，而且还真的很好笑……你真的完了。”<br>◆ 陈长生是一个讷于言而敏于行的人，反正睡不着觉，既然想见她，那便去见她。<br>◆ 圣后娘娘看了眼窗外的雪花，唇角露出一抹微嘲的笑容，说道：“你知道人什么时候胆子最大吗？”　　南北合流近在眼前，各方面的事项陡然增多，莫雨直到深夜，还在陪着娘娘处理事务，已经有些疲惫，忽然听着这句问话，怔了怔后才反应过来，轻声说道：“面对死亡的时辰？”　　“不算错，但还有一种情况……因为爱情。”　　圣后娘娘看着窗外的夜宫，说道：“或者说，色胆包天。”<br>◆ “出了什么事？”　　“没事……只是想你想的睡不着觉。”　　……<br>第五百四十九章 一见<br>◆ 唐三十六浑身雪屑，脸色苍白，黑眼圈极为浓重，看着憔悴到了极点。这两天，为了查探出陈长生的秘密，他殚精竭虑，废寝忘食，真真是下了苦功夫，甚至动用了汶水唐家的两件法器，才最终完美地遮掩住身上的气息，把陈长生抓了一个现行。<br>◆ “哈哈哈哈！”冬林里回荡着他得意的笑声。然后他走到陈长生身前，笑声骤敛，极其恼火地说道：“你这也太过见色忘义了吧？何至于不停地说我坏话，来衬托你的高洁？我刚才在雪堆里听着你提了我好几次名字，就没一句好话！”<br>第五百七十章 生命难以承受的……<br>◆ 人的想法，随着时间的流逝，往往会发生一些他们当初怎么都想不到的变化。<br>第五百七十一章 天地之间诸事更新<br>◆ “有些规矩或者确实过于陈腐，需要改变，但你也要清楚，没有规矩，不成方圆，生活在星空之下，怎能不需要敬畏？都像苏离那样活着，自然快活，但不要忘记，规矩对强者来说是束缚，但对弱者而言，有时候则是保护，我们需要更多的考虑这个世界如何运转，而不是自己的想法。”<br>◆ 从那天之后，他改变了很多，依然平静而专注地活着，但是活的要更加自然随意了很多。　　换句话说，现在的陈长生，活的更加生动，不再像以往那般沉闷甚至木讷。　　这种精神世界发生的变化，也反过来影响了他为了活着做出的那些努力。<br>第五百七十五章 万众之前，其峰自孤<br>◆ 唐三十六取出一件崭新的衣服扔了过去，说道：“这种时候认真一些，因为他们很认真。”<br>第六百一十三章 我且为君战一场（中）<br>◆ 然而，就在手落在果子上的那一瞬间，他的表情便变了。　　他也不明白为什么，就是觉得特别悲伤。　　他忽然很想念师弟。<br>第六百一十五章 数千野火<br>◆ 当初他坚持救她，现在她才能救她，道理就这么简单。<br>第六百二十二章 星空之下，无所敬畏<br>◆ 无论人性还是人心，都是不能考验的，因为当你开始想方法去考验它的时候，说明你已经开始怀疑。”　　教宗最后说道：“而怀疑，是一切不幸的根源。”<br>◆ 因为有所敬畏。”　　像教宗陛下这样无论境界实力还是身份地位都已经在最高处的大人物，还会敬畏什么？　　世人抬头便能看见的星空以及内心最深处的那片光明。<br>◆ 纵使身在高处，依然心存敬畏，这样的人很了不起。　　从始至终，从天到地，从光明至黑暗，无所敬畏，这样的人很可怕。<br>第六百二十六章 何以度余生？<br>◆ 悲剧，或者是把美好地撕碎了给人看，悲伤，则是看着美好却无法靠近，最后被迫转身远离，就此不见。<br>第六百四十五章 母子（上）<br>◆ “把头盔擦一擦就行了。”　　秋风拂动浅渠里的清水，带起盔甲里的尘埃，凉亭下一片安静。　　余人看着那尊铜像，呆了很长时间，吃惊想着，居然是活的啊！　　……<br>第六百五十五章 朕偏偏不<br>◆ 最后她带着些遗憾的意味，感慨说道：“仙人赠我长生果……可惜，你们不是仙人，你们只是人而已。”　　人而已。　　而已。<br>◆ 不是因为警惕与谨慎，而是忠诚于自己的意志。　　她就是她的意志。　　她的意志就是当整个世界都想让她做什么的时候，她就一定不会做。　　……<br>◆ 一个是他的亲生母亲，一个是把他养育成人的师父。　　然而他们对话的时候，连看都没有看他一眼。　　说到冷酷无情，又有谁能比今夜的他体会的更真切，更深刻呢？　　那种淡漠的、悲凉的、又有些令人发笑的感觉，是什么感觉？　　很是刺骨。<br>第六百五十六章 只是当时已惘然<br>◆ 他感谢她在自己生命的最后一刻里说出这句话，从而帮助他想起，生命里终究还是有些美好。　　这样当他离开的时候，或者会因为怀念而有些不舍，但至少不会因为无所怀念而难过。<br>第六百五十七章 在世界中心呼唤<br>◆ 暴雨再如何猛烈，也无法洗去那些星辉。　　暴风再如何肆虐，也无法淹没他痛苦的喊声。　　片刻后，他的精神与意志被这场风暴碾压至粉碎，再也无法承受住，痛苦地喊出声来！　　他的喊声穿透暴风暴雨，传遍了整座天书陵，然后向着更远的地方传去。　　里面有无数痛意，沙哑而撕裂，就像是幼兽最后的呼救，给人一种无比绝望的感觉。　　所有听到他喊声的人，都能感受到他此时的情绪与处境，无论是敌是友，都有为之流泪的冲动。　　……　　……<br>◆ 余人如遭雷击，脸色变得异常苍白。　　因为他听得出来，这是师弟的喊声。　　他更从这道喊声里听出了师弟现在很痛苦、很绝望。<br>◆ 他说不出话来，便是喊声都有些怪异，啊啊啊啊的，像个孩子。　　像个着急的、委屈的孩子。　　然后他抹掉脸上的泥水或者泪水，继续向峰顶爬去。<br>◆ 他望向她的背影，沉默了很长时间，然后说道：“谢谢你。”　　天海圣后没有回头，说道：“不客气。”<br>第六百五十八章 星垂平野阔<br>◆ 　　她神情漠然，冷看雨夜，右手轻抚他的头顶，继续施予着最仁慈的恩赐与最残忍的折磨。<br>第六百五十九章 万里之外，数息之间<br>◆ “朕相信命运这种东西，但朕从来都不曾尊敬过它。”<br>第六百六十三章 原来你什么都不是<br>◆ 天海圣后看着满天繁星，安静了很长时间，然后说了四个字。　　“原来如此。”　　然后她收回视线，望向夜色里的京都，语带嘲讽说了四个字。　　“那又如何？”<br>第六百六十八章 选择即错误，眼光定格局<br>◆ 教宗陛下的声音很平静，但谁都能听出其间的怅然意味。　　“我们都错了，只有梅里砂是正确的。”　　天海圣后微微挑眉，显得有些兴致，想要听到下文。　　教宗想起故人，想着曾经的那些对话，语气很是感慨：“他一直相信，最终你一定会选择救长生，无论长生是谁。”<br>第六百七十四章 可能她一直都知道<br>◆ 我这一生，总是不知如何选择，便像草一般随着风势四处飘荡，数百年前如此，二十年前也是如此。师兄说的对，我这个人啊，真的很是无用，总是直到最后时刻，才能依凭心意做出行为，然而那时候往往已经晚了，所以师兄与娘娘决裂，所以朱洛与观星客死去，仔细算来，这都应该算是我的罪过。<br>第六百八十一章 秋杀<br>◆ 计道人站在废墟之前，脸上的无数道线条已然弯折甚至崩断，看着也像是一座废墟。<br>第六百八十五章 破晓<br>◆ 天海圣后说道：“做我的儿子很丢脸吗？”　　陈长生想了想，说道：“如果能做您的儿子，应该是很骄傲的事情吧？”　　“一个呆，一个傻，真是……”　　天海圣后看了眼陈长生，又看了眼余人。　　最后，她看了眼还在夜穹里散播着无尽光辉的夜空，说道：“但朕终究是有了两个儿子。”<br>◆ 如果仔细去分析，这份带着悲痛的歉意，自然有道理，只不过这时候，说不清楚。　　或者，只是因为这个世界很对不起他们，而他们却无处寻找道理。　　……<br>◆ 师徒二人在神道的中段相遇。　　商行舟没有看他一眼。　　他也没有看商行舟一眼。　　师徒二人擦身而过，形同陌路。<br>◆ 那是天书陵最高的一座石碑。　　那上面没有文字，没有线条，没有图案。　　原来，什么都没有。　　……<br>第六百九十七章 封城<br>◆ 生命是一个极其漫长的过程，在这个过程中，我们会遇到很多的困难，会生出很多的失望，也就是所谓劫数，怎样面对这些劫数，是带着劫后余生的庆幸苟活着，还是经过认真的思考后重新找回自己，这是最重要的分别。<br>◆ “过去的已经过去，那是时间。与此相类，星辰的运动、命运的变化，都只能向前，那么我们也只能向前看，无论曾经发生的那些事情，对你来说造成了怎样的伤害，但至少，现在你的病好了。”<br>◆ 教宗不是一般人，不会如此想，只是想通过点明这一点，让陈长生醒过来：“梅里砂当初应该便是算到了这一点，所以才没有拒绝师兄的提议，他认为，与受到的欺骗、利用、悲伤、痛苦相比，你会收到足够的回报，这是我的猜测。”<br>第六百九十八章 无病<br>◆ “我医术很好，我生活很规律，我从来不吃重油重盐的东西，更不要说腌制品，我健康地生活，认真地修行，我从西宁来京都，说是退婚，其实就是想要治病、救己、想要逆天、改命，我所做的一切的指向，我活着的目的，就是为了活下来。“　　望着湖面上起起浮浮的那几片落叶，陈长生的神情变得有些低沉。　　“现在我的病好了，我可以继续活下去，可以活过二十岁，二百岁，甚至千岁，可是我忽然发现自己只是一个替身、一个工具、一个果子，我的存在，原来没有任何意义，那么继续存在的意义又在哪里？”<br>◆ “师叔，我知道你是想安慰我，可是我现在什么都没有了。”　　他停顿了会儿，继续说道：“我连病都没有了。”　　说这句话的时候，他的声音没有任何颤抖，显得很平静。　　但即便是饱经沧桑，阅遍世情的教宗，都伤感起来。　　他什么都没有了，连病都没有了。　　这句平静的话里，隐藏着多少难过与哀伤？<br>第七百零章 新元<br>◆ 师兄不是喜欢做皇帝的人，他的压力不是来自于那些野心家，而是来自于皇位本身。”<br>第七百二章 死事<br>◆ 大陆一直流传着一句话，如果周通死了，来替他收尸的只有一个人，那个人叫就是薛醒川。　　现在薛醒川死了，死在周通的手里，却还要因为周通的缘故，死无葬身之地。<br>第七百三章 生者<br>◆ 大事之后，表现最疯狂的、经常做出一些最不可思议举动的人，就是那些背叛者，似乎只有通过这种近乎歇斯底里的表现，他们才能证明自己现在的忠诚与以前的忠诚并不相同，才能说服自己不用担心会被新的当权者抛弃，从而获得免于恐惧的自由。<br>第七百五章 真人<br>◆ 饿了就吃，困了就睡，病了就治，死了就埋，这些是天经地义的事情。<br>第七百六章 活路<br>◆ 陈长生说道：“是的，我并不以为有这样一位母亲是羞耻，虽然她不是好人，但是很了不起的人。”<br>第七百九章 闯薛府<br>◆ 陈长生说道：“心意总是会变化的，承认这些变化，才是真正的顺。”　　茅秋雨问道：“因何而变？”　　陈长生说道：“我和薛醒川不熟，所以不去薛府，但我和周通很熟，所以这时候该去了。”<br>第七百一十章 死无地<br>◆ 陈长生说道：“我来京都之后，经常听见人们说，如果你死了，只有薛醒川会替你收尸。<br>第七百一十四章 刀有道<br>◆ 站在树下，看着这幕画面，陈长生默然想着，太阳下山不会再回来，离开的朋友，好像也没有机会回来了。<br>第七百二十章 不再见<br>◆ 是的，这些都是不成熟的，天真的，幼稚的，热血的，冲动的，中二的，可怜的，可笑的。　　可总比这些寂清的、萧瑟的、没有热乎劲儿的世界要来得温暖吧？<br>第七百二十三章 小原则<br>◆ “我太不成熟，年轻冲动，容易耽误大事。”　　陈长生看着殿外阴暗的天空，想着稍后自己就要去做的那件年轻冲动的事情，有些紧张，又有些不安。　　“这就是我选择你的原因啊。”<br>◆ 教宗知道他听懂了自己的意思，很是欣慰，说道：“如果你要离开京都，记得把我的宝贝带走。”<br>第七百三十一章 铁刀的渴望（上）<br>◆ 余人站在风雪里，太监宫女在四周跪了一地。　　年轻的皇帝陛下，第一次违背了老师与大臣们的意愿，出现在天地之间某处。　　那是他替自己选择的位置。　　寒风拂动他的大氅，拂不动他的眉与眼，神情依旧恬淡平静，一派自然。　　风雪再如何愤怒，也是自然之事。　　他静静地看着自己的老师。　　商行舟静静地看着他。　　与陈长生不同，余人是商行舟真正的传人，是商行舟一生理想的寄托。　　商行舟是真的无比疼爱他，愿意为他付出一切，一切都以他的利益出发。　　余人很清楚这些，所以他感动，然后不安，继而恐惧。<br>◆ 越是不安，越是恐惧，他越是听话，越是安静，就像还在西宁镇旧庙一样。　　然而，师父还是要杀师弟。　　那么，他只能站出来，告诉师父这样是不行的。<br>◆ 这块玉佩没有任何气息波动，并不是法器，只是秋山家主前些天进宫晋见新君时送上的礼物。　　这件礼物非常合新君的意。　　当时在殿上，余人接过这块玉佩的时候，没有表现出任何异样，心情却是微漾。　　他没有想到，世间居然有人能够猜到自己的忧愁与不安，并且给出了解决的方法。<br>◆ 或者那是因为他们师兄弟，对这个世界自始至终，都存着一份无法抹灭的善意？<br>第七百三十三章 王破的破（上）<br>◆ 王破说道：“你不敢看这一刀的真相，那么真相便往往会不如你所愿。”<br>第七百六十章 师徒战心意<br>◆ 商行舟坚信自己做的这些事情是正确的，坚信自己是正确的，没有任何愧疚，更没有任何压力。<br>第七百六十一章 最深的阴影<br>◆ 唯立于星空之下，俯仰无愧，回首无憾，方能无所畏，无所惧，道心通明，道法无碍。<br>◆ 如何才能做到不为外物所惑，如何才能拥有不可撼动的意志与自信？　　一字记之曰心。　　只需要你能够说服自己。　　你能说服自己这样做是对的，是符合自己心意的，那么……自然顺心意。<br>◆ 一个连眼睛都还无法睁开的婴儿，一个无知无觉无识的婴儿，一个无善无恶无念的婴儿。　　他找不到任何理由说服自己这样做是正确的。　　这十四年里，他每看到陈长生一次，便会生出一次疑问，道心上多出一道阴影。<br>第七百七十二章 被放逐的教宗<br>◆ 没有人知道，就在一个平常无奇的冬日里，新任教宗陈长生离开了国教学院。　　他出了百花巷，汇入人群，沿着洛水行走，走过奈何桥与离宫前的石柱，出了城门，离开了京都。　　他的怀里揣着一封信，腰间系着一把剑，手里提着一把伞。　　在他的身旁，有个穿着黑衣的小姑娘。　　小姑娘生的清新可人，脸上却没有任何表情，显得格外冷漠。　　她的怀里抱着一盆青叶。　　陈长生走的不快，但小姑娘很娇小，想要跟住他，脚步便必须快起来。　　随着行走，她的黑发在寒风里荡起然后落下，怀里的青叶同样荡起然后落下。　　那不是春风里荡起的双桨，而是她和这个世界应该有的模样。<br>第八百七章 自古以来一魔君<br>◆ “只要活着的，都将死去。”<br>第八百一十二章 不谈而判<br>◆ 我说过，我从来没有救众生的妄信，我只在意能够看到的每一个人。<br>第八百三十五章 请君出山<br>◆ 陈长生说道：“救命之恩，必当回报。”　　罗布说道：“做随你，不必说。”　　陈长生说道：“我一个朋友教过我，有些事情做要做，但说更要说。”<br>◆ 罗布觉得这句话有些意思，说道：“你那个朋友或者是个伪君子，或者是个真小人。”　　陈长生想着那个已经两年不见的朋友，又想着已经半年没有收到他的来信，挂念之情陡然而生，再难抑止。　　他对罗布很认真地解释道：“我那个朋友是个伪小人，真君子。”<br>第八百三十七章 星空与姑娘（上）<br>◆ 对不喝酒的人来说，喝酒的唯一理由就是与他一起喝酒的人是谁。<br>第八百三十八章 星空与姑娘（下）<br>◆ 满天繁星在上。　　姑娘在遥远的南方。　　感谢他此时什么都没有说。<br>第八百四十章 是，陛下<br>◆ 陈酬陈酬，有功难酬，只能搁在案卷里慢慢陈旧。<br>第八百四十一章 春风绿两岸<br>◆ 对这个黑暗且腐朽的世界，苏离是不屑与之为伍，不屑看之，若红尘沾身便一剑斩之，天海圣后的手段则是用更黑暗、更残酷的手段来镇压，来试图把那些陈腐之气尽数驱散，教宗师叔的手段则更加温和且保守。　　在陈长生看来，这些手段都不对。　　他不可能像师叔那样为了所谓大局而不停退让，甘于牺牲自己，他也不像苏离前辈那样与世界如此疏离，这个世界虽然对他也没有什么善意，但他还是喜欢这个世界以及生活在这个世界里的人们，当然他更不可能像天海圣后那样去做，当初在凌烟阁看过王之策笔记后，他便已经放弃了任何让世界随自己起舞的野望。　　他的手段或者说方法或者说要做的事情其实很简单。　　既然不想把这个世界拱手让给那些腐朽的、无趣的人们，那么就应该站出来。　　就像春风绿了江南岸，就像野花开满山坡，就这样光明正大、堂堂正正，昭告天下。　　如果只是他一个人，当然很困难，幸运的是，他还有很多同龄人，同道者。　　如果那个家伙愿意加入进来，那该多好，可惜的是他怎么就不愿意出山呢？　　陈长生望向远处依然灯光明亮的那个房间，不知道罗布这时候在想些什么。<br>第八百四十九章 宿于柳间，不得安眠<br>◆ 柳宿是汉秋城里最好的客栈，邻着城里最美的一片湖泊，围着一片古柳，在春夏里最是清静，但在盛冬时节，湖冰未化，古柳无叶，站在窗边借着星光远望四周风景，难免会觉得有些肃杀凄凉。<br>第八百五十六章 新的同道者<br>◆ 她在闭关。”　　陈长生沉默了片刻，继续说道：“闭死关。”<br>第八百五十八章 大西洲的野望<br>◆ 恩重如山。　　那又如何？　　他依然连刀带鞘打到了二爷的脸上，他依然以刀破鞘斩了铁树。　　恩重如山便还恩，挟恩图报则是另一回事。<br>第八百六十章 道殿内外的夜唱<br>◆ 那位盲琴师弹了很久，罗布也唱了很久，河畔围着的人越来越多，盲琴师身前堆着的铜钱与碎银子也越来越多，借着最后那抹暮色，闪耀着令人心喜的光泽。　　暮色越来越浓，直至变成夜色，汶水两岸的商铺与客栈点起了灯火，星星点点落在水里。<br>第八百六十四章 如山！如海！如旗！<br>◆ 一只盛满酒的皮囊被刺穿了。<br>第八百六十八章 我怀念的<br>◆ 他不觉得滑稽，也没有感觉可怕，只是觉得很难看，而且很痛苦，就像一只等着被喂食、颈子却被铁索系死了的的肥鹅。　　“我更加想念我那位朋友了，如果他这时候在，可能会说……你哑了吗？不然怎么会笑的这么辛苦呢？”　　说这句话的时候，陈长生没有任何嘲讽的意味，而是带着淡淡的想念。<br>第八百七十六章 那一代老人<br>◆ 那一代是哪一代？　　是经历过当年万里焦土、民不聊生、魔族入侵、洛阳被围，生死存亡只在数日之间的那一代人。　　正是因为经历过那么多苦痛与悲壮，承受过现在的人类无法想象的压力，所以那些人意志无比坚毅，如孤峰顶的坚岩，如生在岩石里的青松，无论面对如何凄惨甚至绝望的境遇都不会放弃，依然沉着面对，始终怀抱理想。　　同样是因为他们经历过太多，见过太多残酷而黑暗的历史，所以他们毫无意外地成为了最坚定的现实主义者、最冷酷的的权谋家，阴险的手段与广博的胸怀还有远大的目标在他们日渐衰老的身躯里和谐相处、毫不冲突。<br>第八百七十七章 老宅古井，咸菜清粥<br>◆ 为养生计，早饭熬些小米粥或燕麦是极好的，稻米反而容易伤胃。<br>◆ 名不正则言不顺，言不顺则事难成。”<br>第八百七十八章 杯茶<br>◆ 陈长生请教道：“是何关系？”　　唐老太爷放下茶杯，轻轻敲打了两下桌面，说道：“牌友。”　　陈长生怔了很长时间。<br>第八百八十一章 秋山啊……<br>◆ “我用了二十年的时间来守护我的名望，现在想起来，可能就是为了这个世界相信我一次。”<br>◆ 那个蒲团也很旧。　　不知道是不是因为环境的原因，坐在蒲团上的年轻人脸上也多了几分沧桑感。　　他脸上的胡须长短不一，看着很乱，头发更乱，衣服也有些脏，可以用蓬头垢面来形容。　　他的眼睛以前很明亮，甚至锋锐逼人，但现在已经尽数归于死寂。　　他的嘴唇还是那么薄，然而曾经的刻薄与痛快，已经尽数归于沉默。　　被关进这里后，他整整半年没有说话。　　空旷而幽静的祠堂里，他的身影是那样的孤单。<br>第八百九十二章 二爷有话说<br>◆ 唐老太爷说道：“我与商相识数百载，是真正的同道中人，我知道他的强大，精神上的强大，而当你说出这句话时，意味着你在精神上已经臣服于他，唐家只能与他合作，如果这样下去，你会把唐家给葬送掉。”<br>第八百九十五章 群杀<br>◆ 唐三十六让长房的人退出祠堂，望向刘青说道：“偶像兄，这半年辛苦你了。”<br>◆ 哪怕你再如何聪慧过人，擅长阴谋，如果自己的实力不够，只能利用别人来为自己做事，那么迟早会出问题。<br>第八百九十九章 最了不起的败家子<br>◆ 唐三十六说道：“做为一个人，自恋在某种程度上可以增加魅力，比如我。但做为一个家族太过自恋却不是好事，因为那样容易错误地估计自己的重要性，从而在与对手的谈判中犯下错误<br>◆ “那千古的骂名呢？哪怕你葬在离宫里，人们路过你的坟前，也会往你的墓上吐唾沫。”　　“如果我那时候能从墓里爬出来，自然会吐回去，如果不能，又何必在意。”<br>◆ 如果你把唐家给我，那就是我的，我会好好守着。如果你不把唐家给我，那总有天，我会让它败在我的手里。<br>第九百零章 太阳落山之前以及之后<br>◆ 但唐三十六不是寻常人，不走寻常路，他非常清楚，这样的情意只有用唐家才能够偿还<br>◆ 就算我当家主也是多年后的事情，我更关心的是最近这几年家里的态度<br>第九百一章 看那边黑洞洞<br>◆ 陈长生说道：“我们这样算不算变成当年自己最厌恶的那种人？”<br>◆ 唐三十六说道：“谢谢你。”　　陈长生说道：“不客气。”<br>第九百二章 庵外桃花说别离<br>◆ 看着远处的画面，唐三十六忽然说道：“不要相信老太爷会一直保持中立，那天除苏是被故意放走的。”<br>第九百五章 冬天里狂野的铁枪与茶<br>◆ 无数道视线落在他的身上，随着他的脚步移动，沉默而紧张。　　那人对着县城喝道：“老子的茶，谁他妈敢动！”　　整座奉阳县城都没有声音，没有人敢回答他的话。　　一声断喝，全城俱默。　　此人真是好生嚣张。　　不愧是画甲肖张。　　……<br>第九百六章 铁打的棒棒儿<br>◆ 最先站出来的是奉阳县城里的一名茶商，还有茶行里的十余名伙计。　　“护住肖爷！”<br>第九百七章 有迹可循的爪影<br>◆ 忽然间，他觉得自己这辈子除了那些痛快至极的战斗，还有些别的事情做的不算亏。　　比如当年在风雪里的洛水救了王破，比如当年赞了句这座小县城的冬野茶。<br>◆ “你不了解我们，不然你就不会说这句话，更不用在说话的时候还要看他的眼色。”<br>第九百一十六章 风景旧曾谙<br>◆ 桐江正在北方的原野间流淌，从极高远的地方望过去，极其蜿蜒。　　被斜阳一照，就像是午后绣花乏了的小姐随意扔在桌上的金线。<br>第九百一十九章 南溪斋的乱因<br>◆ 叶小涟举起小手作势要往唐三十六的胸口打去，说道：“开卷钱可是我们这些弟子用的，你可别真的不给啊。”　　唐三十六捂着胸口，作势受伤，难过说道：“小手和小脸都还挺好看，心怎么长得这么偏？我可是为了你才出的头。”<br>第九百二十一章 白鹤搬救兵<br>◆ 有理当然就会声高，因为我理直，所以气壮，没有人说的过我，是因为他们没我有道理。”<br>第九百二十四章 朝廷使团的到来<br>◆ 就算传闻中天赋之高足以惊动星海的陈玄霸，也要在三十岁的时候才有机会越过那道门槛。<br>第九百二十八章 谁来反对<br>◆ 唐三十六嘲笑说道：“觉得很幼稚？那你为何会被我吓到？说明你也知道这件事情是你们理亏。”<br>第九百三十五章 千万人，我在溪边烤鱼<br>◆ 我活着又不是为了让别人记住<br>第九百五十四章 相看两厌<br>◆ 可以尊重，可以理解，但不会接受，不会被你说服，更不会被你改变，不行就是不行，行也不行。<br>第九百五十七章 随心所安情而已<br>◆ 徐有容低头亲了下去。　　嗯，就像糯米糕的味道，还算不坏。　　就在这时，陈长生睁开了眼睛。　　但没有分开。<br>第九百六十章 白帝城里道前事<br>◆ 其实我自己都不清楚，到底我想要什么。”　　“我们以怎样的身份活着，其实就是在扮演怎样的角色，无论是公主、皇后、妻子或者是母亲。”　　“只不过随着扮演的时间越来越长，扮演的角色越来越多，往往会让你忘记你究竟是谁。”<br>第九百六十三章 天要落雨，不准嫁人<br>◆ 还有……唐三十六那张嘴。　　想到这里，轩辕破觉得好生可怕，脸色都变得有些苍白。　　“殿下，我不会让你嫁人的！”<br>第九百六十五章 老少年们的离山行<br>◆ 他们来到这个世界后便知道无法在这里停留太长时间。<br>第九百七十二章 草原枯荣人如昨<br>◆ 折袖面无表情说道：“打不还手，骂不还口，就是往前走。”<br>◆ 折袖看着她认真说道：“我想抱抱你。”　　七间的小脸变得通红，不知道该怎么回应。　　折袖有些笨拙地张开双臂。　　七间有些想哭，说道：“我要你背我。”　　折袖转过身来，在她的身前蹲下。　　七间靠了上去，抱紧他的脖颈，然后就哭了起来。<br>◆ 陈长生退开后便尽可能地保持着安静，以免打扰到他们。　　紧接着他发现这是多虑，因为折袖和七间的眼里明显只有对方，再无旁人。<br>◆ 秋山君挑了挑眉。　　苟寒食摇了摇头。　　关飞白面若寒霜。　　梁半湖皱眉不语。　　白菜差点骂脏话。<br>◆ 陈长生和秋山君摇了摇头，异口同声道：“也不知道那个家伙到底是怎么想的。”　　此言一出，满场俱静。　　众人都知道他们说的那个家伙是苏离，安静却不是因为这句话里的不恭敬。　　苟寒食看着陈长生和秋山君神情微异说道：“你们很默契啊。”<br>第九百七十三章 分别只在一信间<br>◆ 折袖身上的新衣服也很引人注目，可以看出做衣服的人手艺很一般，但针脚很密，说明费了很多心思，下了很多功夫。<br>◆ 七间看了眼静静坐在陈长生身边的南客，说道：“你能不能别这样？”　　陈长生的性情向来温和，这时候终于忍不住有些不悦，说道：“我到底怎样了？我什么都没做过。”　　七间说道：“你明白我说什么。”　　折袖说道：“她的意思是，你不要对别的女孩子太好。”　　唐三十六说道：“你们以为陈长生自己心里不清楚？他清楚的狠，所以才会老羞成怒。”<br>第九百七十六章 有人破云，伴天光而落<br>◆ 活着啊，最重要的事情不是看我们有用没用，而是看我们能不能活的顺心顺意，能不能活的开心。<br>◆ 牧夫人说道：“善战者无赫赫之名，牧人手段如何只需要看羊群生长的如何。那位皇帝陛下亲政以来，朝堂清明，野无遗贤，政事顺畅，民众安居乐业，比他母亲还要更了不起，太宗皇帝当年也不过如此。”<br>第九百九十六章 又一拳<br>◆ 怎样才能把力量变成速度？怎样才能把速度发挥到极致？　　别样红说，不要太刻意。　　随心意而起。　　随心意而落。<br>第一千二十三章 听见你的声音<br>◆ 落落沉默了会儿，说道：“母亲，你终究还是没有把这里当做你的家乡。”牧夫人说道：“为何还要坚持这样认为？”落落说道：“因为你对这座城市没有感情，你会用生活在这座城市里的人们来威胁自己的女儿。”牧夫人的眼里生出一抹深沉的疲惫，说道：“你说的不错，我确实不喜欢这里，因为这里充满了皮毛与汗水的臭味，充满了污言秽语，充满了愚蠢的勇敢与令人厌憎的所谓豪迈，这里就像是一片荒芜的沙漠，野蛮而且原始。<br>第一千三十九章 喵<br>◆ 落落喜欢站在很高的地方，是因为那里才能看到很远的地方。“一个喜欢远方的小姑娘怎么能留在这里做女皇？”陈长生看着她认真说道。<br>第一千四十四章 别样红之死<br>◆ 这屉包子还是滚烫的，如果撕开松软的包子皮，便能闻到牛肉与葱花还有红油的香味。可惜的是晚了些。别样红闭着眼睛，已经没有气息。轩辕破僵住了，怀里的蒸屉冒着热气，向着阴暗的天空飘去，也落在了他的脸上，有些热，有些湿。陈长生沉默地低着头，落在身边的手指微微颤抖，鞘里的剑随之微微震动。轩辕破跪在别样红的身前，把那屉包子搁到前方，然后恭恭敬敬地磕了几个响头，泪水不停地流着。<br>第一千四十七章 生存还是毁灭，井底还是井口？<br>◆ 他忽然觉得有些疲惫，对很多事情都失去了兴趣，就像现在明明知道整个妖族都在警惕不安地等着他的反应，他却不想理会。就像很多人那样，他很喜欢很敬重别样红，但真的不熟，按道理来说不至于受如此大的刺激，可事实上他的精神受到了很大的冲击。好人不见得有好报，甚至活着的时候也谈不上自在，那么为何一定要做好人，我们应该怎样活着，我们为何活着？他望向夜空，想着这个经常被人嘲笑、事实上谁都应该仔细思考的问题。<br>第一千五十一章 直，难<br>◆ “很小的时候，老师曾经用一句话称赞过师兄，同时也是在教育我，那句话是千言万语，不当一默。”陈长生说道：“从那之后我说的话要少了很多，但终究还是不如师兄，总忍不住想说话，想对溪里的鱼说话，想对庙里的书说话，而每到那个时候，我就会觉得好生自责，直到现在我与三十六聊天的时候，还是偶尔会有这种感觉。”牧夫人说道：“皇帝陛下本来就是个哑巴。”“师兄当时也是这么安慰我的。”陈长生沉默了会儿，继续说道：“所以后来我把把那句话改了一个字，以此奉行。”牧夫人神问道：“哪个字？”陈长生说道：“千言万语，不当一直。”<br>◆ 陈长生说道：“不错。我做不到抱残守缺，道心不移，那么想的太多，说的太多，便容易错的太多，既然如此，何不直接一些？只要相信自己做的事情是有道理的，那么便去做好了。”牧夫人说道：“此亦一是非，彼亦一是非。”陈长生说道：“但至少王破与我相信有是非。”<br>第一千八十六章 我见<br>◆ 如果陈长生说的不是要不要和我一起走，而是和我一起走，那么，她或者就随他走了。<br>第一千八十七章 寒风烈，如美酒<br>◆ 唐三十六说道：“能怎么办？什么都不办。一起做大恶人岂不快活？”<br>◆ “是的，世间还是有不少美好的事情。”　　唐三十六说道：“既然如此，谁说我们就一定会成为白帝夫妇那样的人？”　　徐有容淡淡一笑，没有说话。<br>第一千九十一章 她说<br>◆ 徐有容轻声说道：“我就喜欢他无论遇着任何事情，哪怕是生死之间的大恐怖，都绝不郁郁，而且并不是放弃之后的放浪形骸，依然专注与执着，坚定且平静。”<br>第一千九十九章 教宗的归来<br>◆ 教枢处伸向国教学院的那只手，被徐有容平静斩断。<br>第一千一百一章 魔鬼的主意<br>◆ 星海之上的归于神国。　　肮脏之下的归于尘埃。　　“我将承受所有我应承受的罪名。”<br>第一千一百二章 光海的陛下<br>◆ 陈长生说道：“没有人生来就喜欢杀人，喜欢争权夺势，喜欢尔虞我诈。”　　徐有容淡然说道：“我刚出生的时候，也不喜欢打麻将，但那是因为我不会。”<br>第一千一百四章 糖渍的梅子<br>◆ 余人是真的很重视陈长生，就像陈长生对他一样。<br>◆ 很简单，你们师兄弟联手，请你们的师父归老吧。<br>第一千一百六章 寻常的小事<br>◆ 道路以目，德者何存？<br>第一千一百八章 头发乱了<br>◆ 责任以及远方这两句话，是陈长生的心里话，但不只存在于心里。<br>第一千一百二十九章 改世问<br>◆ 徐有容说道：“往星海彼岸驶去的船，上下岂能全遂心意。”　　商行舟说道：“你可曾见过海舟自覆？”　　“只要利益足够，在真正的结局出现之前，最悲观的水手也会奢望一下陆地。”　　徐有容说道：“相反，这只会给他们更多必胜的信念。”　　商行舟说道：“原来是裹挟。”　　徐有容说道：“我看史书，无论英雄还是帝王，若要聚众，便必须如此。”<br>◆ 我是为自己而活，并不是为他人而活，更不是为了他喜欢而活。”<br>第一千一百六十七章 关于陈生生的一切<br>◆ 他人是地狱。　　死亡是明镜。　　可以正衣冠。　　可以明心意。<br>第一千一百六十八章 诸君看吧<br>◆ 陈长生转身望向徐有容，说道：“我赢了。”　　徐有容用赞赏的眼光看着他，说道：“很了不起。”　　陈长生沉默了会儿，又说道：“我没哭。”　　徐有容伸手抹掉他脸上的灰尘，有些心疼说道：“这也很了不起。”<br>第一千一百六十九章 年轻人的时代<br>◆ “这个世界是我们的，也是你们的，但最终会是你们的。”<br>◆ 世间这样的少女太多，在她们想来，王大人必然是活在云上，采露为食。　　如果真的看见了，她们才会知道，那样的谪仙人是不存在的。　　那就是一个会妥协，有些可悲，甚至无趣的老男人。<br>◆ “既然这个世界注定是我们的，那你们为何不退？就一定要年轻人等吗？”　　“等的时间久了，我们也会变成像你们这样无趣的老人。”　　“那这个世界岂不是一直都是你们的世界？”<br>第一千一百七十三章 如果你是除苏<br>◆ 陈长生沉默了会儿，说道：“我也是以工具的身份出生，但我想，我们既然存在，自然有其意义。”　　从某种意义上来说，他与除苏的身世来历非常相似。　　除苏摇了摇头，说道：“那是因为你遇着了一些能够赋予你存在意义的人。”　　陈长生想了想，说道：“你说的不错。”　　除苏说道：“所以你比我幸运，也比我幸福。”　　陈长生说道：“是的，但是这并不能成为理由。”　　什么理由？自然是行恶的理由。<br>◆ 悲惨的人生经历可以是精神上的财富，但不能是债务，随便转到别人头上。<br>第一千二百一十八章 蓦然回首，伊人在灯火阑珊处<br>◆ “其……实……我……从来……没……想过……坐……这把椅子。”　　一个声音在安静的正殿里响了起来。　　那人最开始说的两个字发音非常生涩，就像是刚学会说话的婴儿。<br>第一千二百一十九章 艳阳天<br>◆ 我不会撒谎，所以小时候离开京都的时候，师父让我不要说话，后来我就习惯了不说话。”<br>◆ 不能视物的那只眼睛、缺了半截的耳垂，微微向左偏的肩膀，在他的视野里渐渐消失。<br>第一千二百三十一章 天凉好个秋<br>◆ 天凉好个秋。　　他转身离开。　　再也没有来过京都<br>第一千二百三十二章 圣光大陆之行<br>◆ 活着，应该是主动行为的集合。”<br>◆ 九天之前，太阳落入云墓里，再也没有出现。　　第十天，陈长生来到了孤峰之上。<br>第一千二百三十五章 后记<br>◆ 命里有时终须有，命里无时要强求<br>◆ 为什么要写少年的故事？因为我渐渐老了，失去热血了，很害怕像书里写过很多次的那样，变成渐渐向淤泥里沉去的肥鲤鱼，<br>-- 来自微信读书<br>]]></description><link>culture\阅读\择天记.html</link><guid isPermaLink="false">Culture/阅读/择天记.md</guid><pubDate>Mon, 09 Sep 2024 11:51:58 GMT</pubDate></item><item><title><![CDATA[中国教育史-孙培青]]></title><description><![CDATA[ 
 <br><br>《中国教育史（第四版）》<br>孙培青主编<br>
222个笔记<br>第四章 第一章 原始时期的教育<br>◆ 随着人类的出现与社会的形成，教育便产生了。它以培养人为目的，是人类社会所必需的、基本的社会实践活动之一。<br>◆ ，中国原始社会的发展经过两个阶段：第一阶段，原始人群时期，大约从200万年前至5万年前；第二阶段，氏族公社时期，大约从5万年前至公元前21世纪。<br>第五章 第一节 中国教育的起源<br>◆ 依据科学测定的“巫山人”的年代算起，中国的教育已有200万年的历史。<br>◆ 教育不仅是社会一切实践活动的需要，而且是人类自身生产的需要。<br>◆ 人类社会特有的教育活动，起源于人类适应社会生活的需要和人类自身身心发展的需要，是人类社会存在和发展的必要条件。<br>第七章 第三节 氏族公社末期学校的萌芽<br>◆ 社会经济、政治的变革，推动着教育不断地发生变化。存在于社会生活中的教育逐渐分化出来，出现了学校的萌芽。<br>第八章 第二章 夏、商、西周与春秋时期的教育<br>◆ 这种制度可概括为学在官府、政教合一、官师不分。<br>◆ 孔丘是儒家的创始人，在政治上主张改良，试图利用教育的力量改造社会。他提出一系列的教育主张，形成教育思想体系，为中国古代教育理论奠定了基础，并流传两千多年，成为中华教育传统的主流，也是世界珍贵的教育遗产。<br>◆ 从公元前21世纪到公元前476年，是我国奴隶制社会时期，其发展可分为四个阶段：夏代，前2070年到前1600年，第一个奴隶制国家经历470多年，是奴隶制的初期；商代，前1600年到前1046年，经历了554年左右，是奴隶制发展时期；西周，前1046年到前771年，约276年，是奴隶制全盛时期；春秋，前770年到前476年，近300年，是奴隶制走向崩溃的时期。<br>第九章 第一节 夏、商的教育<br>◆ “序”起初是教“射”的场所，后来发展成为奴隶主贵族一切公共活动如议政、祭祀、养老的场所，也是奴隶主贵族教育子弟的场所。所以，它并非独立的、纯粹的教育机关，教育只是其重要职能之一。<br>◆ 夏朝“为政尚武”，实际是“武人”专政。为适应这种政治需要，教育的目的就是要把本阶级的成员及其后代培养成为能射善战的武士。<br>◆ 总之，在奴隶社会的初期，国家已把教育事务作为行政管理的重要任务之一，司徒负责管理教化。教育机构与政治行政机构结合，有国都的学校，也有地方的学校，开始有了等级层次。教育为政治服务，突出表现在教育目的是要培养奴隶主贵族的武士，教育内容重视军事训练。<br>◆ 贵族为了维护其统治地位，对年轻一代的教育很重视，把子弟送到学校中受教育。有一甲骨卜辞记载：“壬子卜，弗，酒小求学？”[插图]意思是，壬子这一天举行占卜，弗求问上帝，为了王子入学，要设酒祭祖以求赐福，这样办是否可行？这表明贵族把教育下一代当大事看待，入学要占卜，设酒祭祖。<br>◆ 当时大学以乐教为重，乐教的教师也就是乐师。乐师在学中祀其先师为乐祖，大学也就成为乐师的宗庙，故称瞽宗。瞽宗是当时贵族子弟学习礼乐的学校。<br>◆ “孝”成为奴隶主贵族最强调的基本道德准则，遵守孝道才能继承王位，不守孝道在政治上就要受到制裁。<br>◆ 奉先思孝<br>◆ 甲骨文中“教”字大多写成“[插图]”，左半“[插图]”即“孝”字，象征“子曲伏于父”，右边是“[插图]”（音扑），象征手执木棒的样子。<br>◆ 教育的内容和方法从“教”字就可形象表现出来，当时是在棍棒体罚的威胁下，教下一代尽“孝”。孔丘曾说：“夫孝，德之本也，教之所由生也。”[插图]这也概括了商代的教育实际。把“孝”作为思想教育的中心内容，是奴隶主教育的重要特点。<br>◆ 2024/07/01发表想法<br>礼乐教育原来商就有了<br>原文：礼乐教育<br>◆ “戒”字像人手持戈，含有两种意思：一是持戈而警戒，一是持戈而舞蹈。在学校中教“戒”，可能兼有习武和习乐两方面内容。<br>第一十章 第二节 西周的教育<br>◆ 西周是中国奴隶制的全盛时期。其重要特征是在分封制、井田制的基础上实行宗法世袭禄位制。<br>◆ 《诗·小雅·北山》：“溥天之下，莫非王土；率土之滨，莫非王臣。”<br>◆ 2024/03/13发表想法<br>这和冰与火之歌的社会好像<br>原文：周人强调宗法，用血缘宗族关系把奴隶主贵族联系起来，但又区分亲疏等级。<br>◆ 周人强调宗法，用血缘宗族关系把奴隶主贵族联系起来，但又区分亲疏等级。<br>◆ 墨（黥额）、劓（割鼻）、刖（砍脚）、宫（割掉生殖器）、大辟（杀头），共3000条。刑法是专门用于对付奴隶和平民的，所以说：“刑不上大夫。”<br>◆ 相传周礼是由姬旦（史称周公）所制定的，它包括五类：吉、凶、军、宾、嘉。<br>◆ 2024/07/01发表想法<br>这跟欧洲中世纪如出一辙，贵族被礼教束缚，下层被酷刑束缚。<br>原文：“礼不下庶人。<br>◆ “礼不下庶人。<br>◆ 夫礼者，所以定亲疏，决嫌疑，别同异，明是非也。……道德仁义，非礼不成。教训正俗，非礼不备。分争辨讼，非礼不决。君臣上下，父子兄弟，非礼不定。宦学事师，非礼不亲。班朝治军，莅官行法，非礼威严不行。祷祠祭祀，供给鬼神，非礼不诚不庄。……为礼以教人，使人以有礼，知自别于禽兽。[插图]<br>◆ 统治者认为，礼制源于天命，遵守礼制，也就是“敬德”。只有“敬德”，才能保民，才能巩固奴隶主贵族专政。<br>◆ 在文化教育上，其历史特征就是“学在官府”。<br>◆ 奴隶主贵族建立国家机构，设官分职，从事管理。为了管理的需要，制定法纪规章，有文字记录，汇集成专书，由当官者来掌握。这种现象，历史上称之为“学术官守”，并由此而造成“学在官府”。<br>◆ 有官斯有法，故法具于官。有法斯有书，故官守其书。有书斯有学，故师传其学。有学斯有业，故弟子习其业。官守学业皆出于一，而天下以同文为治，故私门无著述文字<br>◆ “学在官府”这种历史现象，有其客观原因。（一）惟官有书，而民无书<br>◆ （二）惟官有器，而民无器西周时期的礼、乐、舞、射都<br>◆ 所以要学习礼、乐、舞、射，只有在官府的人才具有条件。<br>◆ （三）惟官有学，而民无学<br>◆ 二、西周的教育制度奴隶主根据贵族专政的需要确定教育目的，培养具有贵族政治道德思想和军事技能的未来统治者，他们必须受礼、乐、射、御、书、数“六艺”的专门训练。先经过家庭教育，然后才进行学校教育<br>◆ 以乡三物教万民而宾兴之。一曰六德，知、仁、圣、义、忠、和；二曰六行，孝、友、睦、姻、任、恤；三曰六艺，礼、乐、射、御、书、数。<br>◆ （六）官师合一社会存在着阶级对立，劳心与劳力的分离，随着社会发展，内部分工有很大进展，但专业化还不是很细，教师还未成为独立的社会职业，皆由政府职官来兼任。<br>◆ 由上述情况可以看出，国学或者乡学绝大部分学官是国家现任的职官，有小部分是退休的官员担任，总体的情况是“官师合一”。<br>◆ 六艺教育<br>◆ （一）礼乐<br>◆ 礼的内容极广，凡政治、伦理、道德、礼仪皆为其包括，以至社会生活的各方面都不能没有礼。<br>◆ 2024/07/01发表想法<br>所以诗歌在古代这么受重视，原来是乐教的影响。<br>原文：乐教受到高度重视，内容包括诗歌、音乐、舞蹈。<br>◆ 乐教受到高度重视，内容包括诗歌、音乐、舞蹈。<br>◆ 2024/07/01发表想法<br>所以中庸的意思是言出自心，皆有忠实，接事以礼而有常<br>原文：中（言出自心，皆有忠实）、和（不刚不柔，宽猛相济）、祗（见神示则敬）、庸（接事以礼而有常）<br>◆ 中（言出自心，皆有忠实）、和（不刚不柔，宽猛相济）、祗（见神示则敬）、庸（接事以礼而有常）<br>◆ 其中大武是周代国乐，实际是以周武王克殷为题材的大型歌舞剧。其曲调早已失传，而乐词基本上保存在《诗·周颂》里。周人重大典礼都作为传统节目歌舞一番。<br>◆ 乐教是当时的艺术教育。艺术教育过程寓有多种教育因素在其中，它包含了德育、智育、体育、美育的要求，具有实施多种教育的作用。<br>◆ （二）射御<br>◆ （三）书数<br>◆ “书”指的是文字读写，“数”指的是算法<br>◆ 书数是文化基础知识技能，作为“小艺”，安排在小学学习。<br>◆ 西周的教育内容可以总称为六艺教育，它是西周教育的特征和标志。六艺教育包含多方面的教育因素。它既重视思想道德，也重视文化知识；既注意传统文化，也注意实用技能；既重视文事，也重视武备；既要符合礼仪规范，也要求内心情感修养。<br>第一十二章 第四节 孔丘的教育思想<br>◆ 2024/07/01发表想法<br>有些类似文艺复兴<br>原文：“人道”思想、“民本”思想、“尚贤”思想都有发展。时代变化给孔丘的教育思想以深刻的影响。<br>◆ “人道”思想、“民本”思想、“尚贤”思想都有发展。时代变化给孔丘的教育思想以深刻的影响。<br>◆ 他一面为师，一面继续学习，向一切有知识的人学习，还利用机会出去游学。为了教学需要，他注意对历史文献进行整理研究，编成《诗》、《书》、《礼》、《乐》等教材。<br>◆ 他曾参与国政3个月，因与执政者季桓子政见不一，终于弃职出走。学生也随之而去，他的私学也即成为流动学校。<br>◆ 在他68岁那年，他受礼聘返鲁，被尊为国老。他把主要精力用于教育和古代文献的整理上。他以诲人不倦的精神继续招生讲学。据说，他的弟子先后累计达3000多人，有突出才干的70多人。他在晚年完成《诗》、《书》、《礼》、《乐》、《易》、《春秋》的编纂和校订工作，作出了重大的历史贡献。<br>◆ 子适卫，冉有仆。子曰：‘庶矣哉。’冉有曰：‘既庶矣，又何加焉？’曰：‘富之。’曰：‘既富矣，又何加焉？’曰：‘教之。<br>◆ 2024/07/01发表想法<br>现在也是如此，先有足够的人口，然后发展起来经济，人民物质条件好了再去做教育。<br>
我们现在还在富的阶段上，因为没彻底富起来所以人民内卷，教育畸形，是经济基础扭曲了上层的教育。<br>原文：这里论说的是治国的基本大纲，要解决三个重要条件，即：首先是“庶”，要有较多劳动力；其次是“富”，要使人民群众有丰足的物质生活；再次是“教”，要使人民受到政治伦理教育，知道如何安分守己。<br>◆ 这里论说的是治国的基本大纲，要解决三个重要条件，即：首先是“庶”，要有较多劳动力；其次是“富”，要使人民群众有丰足的物质生活；再次是“教”，要使人民受到政治伦理教育，知道如何安分守己。<br>◆ 庶与富是实施教育的先决条件，只有在庶与富的基础上开展教育，才会取得社会成效。孔丘是中国历史上最先论述教育与经济发展关系的教育家，他认为先要抓好经济建设以建立物质基础，随之而来就应当抓教育建设，国家才会走上富强康乐之路。<br>◆ 教育能在社会发展中发挥重要作用，是建立在教育对人的发展有重要作用的认识基础上的。<br>◆ 他在中国历史上首次提出“性相近也，习相远也”[插图]。这一理论具有一定的科学性，指出人的天赋素质相近，打破了奴隶主贵族天赋比平民天赋高贵、优越的思想。提出这一理论，是人类认识史上一个重大的突破，成为人人有可能受教育、人人都应当受教育的理论依据。<br>◆ 2024/07/01发表想法<br>人的本性是相近的，但后天习染和环境导致了人的不同。<br>原文：他在中国历史上首次提出“性相近也，习相远也”[插图]。<br>◆ 人的先天素质没有多大差别，只是由于后天教育和社会环境的影响作用，才造成人的发展有重大的差别。<br>◆ 人一生中的任何发展阶段，教育都是重要的，哪一阶段缺乏教育，哪一阶段就要落后以至发生偏差<br>◆ 2024/07/01发表想法<br>孔老夫子提出的很多思想虽然现在看起来已经是大众习以为常的观点了，但是在奴隶时代后期是翻天覆地的看法。<br>原文：“少成若天性，习贯之为常。”[插图]少儿时期通过教育养成的智能，犹如天生自然一样。他还主张：人应当终生不断受教育，这样才能使知识的掌握和道德的修养不至于停顿、倒退，这个全人生的学习教育过程要到进入坟墓以后才算结束。<br>◆ “少成若天性，习贯之为常。”[插图]少儿时期通过教育养成的智能，犹如天生自然一样。他还主张：人应当终生不断受教育，这样才能使知识的掌握和道德的修养不至于停顿、倒退，这个全人生的学习教育过程要到进入坟墓以后才算结束。<br>◆ 2024/07/01发表想法<br>和现在很多人说的人生最重要的问题是和什么人在一起，与活在在什么环境中。<br>原文：因此，他一方面强调居住环境的选择，主张“里仁为美”；另一方面强调社会交往的选择，主张“就有道而正焉”。这种具有唯物主义因素的教育主张，后来由儒家后学加以继承和发挥。<br>◆ 因此，他一方面强调居住环境的选择，主张“里仁为美”；另一方面强调社会交往的选择，主张“就有道而正焉”。这种具有唯物主义因素的教育主张，后来由儒家后学加以继承和发挥。<br>◆ 2024/07/01发表想法<br>孔子的人性论将人性分为四等，分别是“生而知之者”、“学而知之者”、“困而学之者”和“困而不学者”。<br>一、孔子的四等人性论<br>
<br>
“生而知之者”：生来就具有知识的人，属于上智，是最高等的人性。

<br>
“学而知之者”：通过学习获得知识的人，属于中人，是次一等的人性。

<br>
“困而学之者”：遇到困难后才学习的人，也属于中人，是再次一等的人性。

<br>
“困而不学者”：遇到困难还不学习的人，属于下愚，是最低等的人性。

<br>二、孔子的教育观<br>
<br>
孔子认为，中人是有条件接受教育的，可以对他们谈高深的学问。

<br>
他鼓励弟子和世人说：“我非生而知之者，好古敏以求之者也。

<br>三、孔子的局限性<br>
<br>
孔子把人性分成等级，并断言有不移的上智和下愚，这是不科学的，是他人性论的一个缺憾。

<br>
他的“唯上知与下愚不移”这句话，历来有不同解释，一种是解释为人的品质和行为，另一种是解释为人的知识。

<br>原文：孔丘还提出：“生而知之者，上也；学而知之者，次也；困而学之，又其次也；困而不学，民斯为下矣。”[插图]“唯上知与下愚不移。”<br>◆ 孔丘还提出：“生而知之者，上也；学而知之者，次也；困而学之，又其次也；困而不学，民斯为下矣。”[插图]“唯上知与下愚不移。”<br>◆ “有教无类”的主张<br>◆ “有教无类”本来的意思是：不分贵贱贫富和种族，人人都可以入学受教育。<br>◆ 君子端正自己品行以待四方求教之士，愿意来的不拒绝，愿意走的不制止。<br>◆ 实行开放性的“有教无类”方针，满足了平民入学受教育的愿望，适应了社会发展需要。孔丘私学成为当时规模最大、培养人才最多、社会影响最广的一所学校，从总的社会实践效果来看，是应该肯定的。“有教无类”是顺应历史发展潮流的进步思想，它打破了贵族对学校教育的垄断，把受教育的范围扩大到一般平民，有利于中华民族文化的发展。<br>◆ 他又认为，自夏、商、周以来一些基本制度，如氏族宗法制、贵贱等级制等，是经过历史考验的，不应改变。而那些不是基本的、可以改变的方面，也不能用人民革命的办法，而是要由当政者自上而下采用缓和的办法来改良社会，使社会恢复正常的秩序。<br>◆ 孔丘不是革命者，也不是顽固的保守者，而是一个政治改良主义者。<br>◆ “为政以德，譬如北辰，居其所而众星共之。”<br>◆ 君子的品格可归为两方面，即对己要能“修己”，对人要能“安人<br>◆ 孔丘对君子强调三方面的修养要求，“仁者不忧，知者不惑，勇者不惧”<br>◆ 孔丘提出由平民中培养德才兼备的从政君子，这条培育人才的路线，可简括称之为“学而优则仕”。<br>◆ “学而优则仕”包容多方面的意思：学习是通向做官的途径，培养官员是教育最主要的政治目的，而学习成绩优良是做官的重要条件。如果不学习或虽经学习而成绩不优良，也就没有做官的资格。<br>◆ “不患无位，患所以立。”[插图]不必担心没有官做，要担心的是有没有把做官所需要的知识本领学好<br>◆ 首先，学不优则不能出来做官，其次，国家政治上了轨道才能出来做官，否则宁可退隐。<br>◆ “学而优则仕”口号的提出，确定了培养统治人才这一教育目的，在教育史上有重要的意义。<br>◆ 他主张“行有余力，则以学文”[插图]，首先要求做一个品行符合道德标准的社会成员，其次才是学习以提高文化知识。所以，在他的整个教育中，道德教育居于首要地位。<br>◆ 道德教育并没有专设学科，而是把道德教育要求，贯串到文化知识学科中。<br>◆ 孔丘的教学往往从《诗》入手，认为《诗》在思想政治教育方面有四种作用：一是“可以兴”，由比喻而联想，可以激发人的情感意志；二是“可以观”，由多种生活情境，可以考察社会风俗盛衰；三是“可以群”，利用切磋诗义，可以增进相互情谊；四是“可以怨”，利用讽刺的形式，批判不合理的政治。<br>◆ 《尚书》，古代历史文献汇编。<br>◆ 文武之政，布在方策。其人存，则其政举；其人亡，则其政息。<br>◆ 他要弟子们从学习文献中继承和恢复周道。<br>◆ 《士礼》，传于后世称为《仪礼》。孔丘认为，礼是立国的根本，在社会生活中有重大的作用。<br>◆ 知礼是立足于社会的重要条件，不仅要学会礼的仪式，更重要的是要理解礼的精神实质。<br>◆ 乐的作用表现在两方面：对个人来说，陶冶情操，净化心灵，形成崇高的品格；对社会来说，乐教使人性情宽和朴实，帮助移风易俗改造社会。<br>◆ 《春秋》作为历史教材，是一部提纲挈领的教学大纲。由于记事简略，言辞古朴，后人为了学习的方便进行了阐释和补充，称为《传》。《传》流传至今有三部，即《春秋公羊传》、《春秋谷梁传》、《春秋左氏传》，合称《三传》。《春秋》是我国现存第一部编年史，具有重要的历史价值。<br>◆ 孔丘的教学内容有三个特点：其一，偏重社会人事。他的教材，都是属于社会历史政治伦理方面的文化知识，注重的是现实的人事，而不是崇拜神灵。他虽不是无神论者，但对鬼神持存疑态度，敬鬼神而远之。他不谈“怪、力、乱、神”，不宣传宗教迷信思想，不把宗教内容列为教学科目。这种明智的态度，成为中国古代非宗教性教育传统的开端。其二，偏重文事。他虽要求从政人才文武兼备，但在教学内容的安排上毕竟是偏重文事，有关军事知识技能的教学居于次要地位。孔丘本人善于射御，也对弟子进行教学，常带领弟子习射于射圃；对军旅之学也能精通，并传于冉求、樊迟等弟子，但未普遍传授。其三，轻视科技与生产劳动。他所要培养的是从政人才，不是从事农工的劳动者，因此不强调掌握自然知识和科学技术。他既没有手工业技术可传授，也没有农业技术可传授。他认为，社会分工有君子之事，有小人之事。“君子谋道不谋食”，君子与小人职责不同，君子不必参与小人的物质生产劳动，所以他从根本上反对弟子学习生产劳动技术<br>◆ 他提出“博学于文”[插图]、“好古敏以求之”[插图]，偏重于古代文化、政治知识这些前人积累的间接经验。<br>◆ 他提出“多闻择其善者而从之，多见而识之”[插图]，要多听、多看，还要多问，扩大知识的来源和范围，以获得一些直接的经验<br>◆ 他主张“学而时习之”[插图]，对学习过的知识要时常复习、练习，才能牢固掌握。<br>◆ 他说：“学而不思则罔，思而不学则殆。”[插图]如果只是读书记诵一些知识，而不通过思考加以消化，这只能是抽象的理解，抓不住事物要领，分不清是非。如果光是左思右想，而不通过读书学习以吸收实际知识，那也会心中疑惑，不能解决问题。单纯的学或单纯的思，都存在片面性。<br>◆ 孔丘还强调学习知识要“学以致用”。<br>◆ 从学与行的关系来看，学是手段，行是目的，行比学更重要。<br>◆ 《中庸》把学习过程分为学、问、思、辨、行五个阶段，显然是继承孔丘学、思、行结合的思想并加以发展的。<br>◆ 孔丘认为，不论学习知识或培养道德，都要建立在学生自觉需要的基础上，应充分发挥学生的主动性、积极性。自己对问题能加以思考，获得切实的领会，才是可靠和有效的。为了帮助学生形成遇事思考的习惯，培养善于独立思考的能力，他提倡启发式教学。<br>◆ “不愤不启，不悱不发。举一隅不以三隅反，则不复也。<br>◆ 这种启发教学包含三个基本要点：第一，教师的教学要引导学生探索未知的领域，激发起强烈的求知欲，积极去思考问题，并力求能明确地表达；第二，教师的启发工作以学生的积极思考为前提条件，其重要作用就体现在“开其意”、“达其辞”；第三，使学生的思考能力得到发展，能从具体事例中概括出普遍原则，再以普遍原则类推于同类事物，而扩大认识范围。<br>◆ （三）因材施教孔丘在教育实践的基础上，创造了因材施教的方法，并作为教育原则，贯彻于日常的教育工作之中，取得了成效。他是我国历史上首倡因材施教的教育家。<br>◆ 实行因材施教的前提条件是承认学生间的个体差异，并了解学生的特点。孔丘了解学生，最常用的方法有两种。第一，通过谈话。有目的地找学生谈话，有时个别谈，有时二三人或四五人聚集一起谈，方式较为灵活。他了解学生的志向，就是通过与几位学生自由交谈而得到的。第二，个别观察。注意从学生的言论来了解学生思想特点是重要的，但也要避免单凭言论作判断的片面性，因此要“听其言而观其行”；只凭公开场合的行为表现作判断有片面性，要“退而省其私”；只凭一时的行为作判断有片面性，还应对行为的全过程进行考察，要“视其所以，观其所由，察其所安”[插图]<br>◆ 2024/07/01发表想法<br>孔子对其弟子的评价，柴高愚笨，曾参迟钝，颛孙师偏激，仲由鲁莽。<br>一、柴高<br>
<br>
柴高，字子羔，孔子弟子，比孔子小三十岁。

<br>
柴高为人愚笨，但谨厚有余。

<br>二、曾参<br>
<br>
曾参，字子舆，孔子弟子，比孔子小四十六岁。

<br>
曾参迟钝而少警敏。

<br>三、颛孙师<br>
<br>
颛孙师，字子张，孔子弟子，比孔子小四十八岁。

<br>
颛孙师务为容止，而少至诚恻怛之意，是其辟也。

<br>四、仲由<br>
<br>
仲由，字子路，孔子弟子，比孔子小九岁。

<br>
仲由粗鄙凡陋而少温润文雅之美，是其喭也。

<br>原文：柴也愚，参也鲁，师也辟，由也喭”<br>◆ 柴也愚，参也鲁，师也辟，由也喭”<br>◆ 2024/07/01发表想法<br>所以很多所谓自相矛盾的地方只是面对不同人的不同应对。<br>原文：孔丘说：冉求遇事畏缩不前，所以要鼓励他去做。子路遇事轻率，所以要抑制一下使他审慎些。[插图]这一生动的事例，表明他能区分不同特点，有意识、有目的地进行因材施教。<br>◆ 孔丘说：冉求遇事畏缩不前，所以要鼓励他去做。子路遇事轻率，所以要抑制一下使他审慎些。[插图]这一生动的事例，表明他能区分不同特点，有意识、有目的地进行因材施教。<br>◆ 孔丘认为，教学需要师生双方配合协作，学生端正学习态度，是教学成功的重要条件。<br>◆ 求学的人对于吃住问题不必过多计较，重要的是要勤敏做事，慎于言论，向有道德学问的人学习，这才算得上是好学。好学还不够，进一步还应乐学，他说：“知之者不如好之者，好之者不如乐之者。”[插图]知道学问有用而学的人，不如为了爱好学问而学的人；为爱好学问而学的人，不如以求学为乐的人。以学为乐的人有强烈的求知欲，对学习存在浓厚的兴趣，名利引诱不能动其心，对饥寒威胁能置之度外。<br>◆ 他要求学生“敏而好学，不耻下问”[插图]，即能够虚心向比自己社会地位低的人请教而不认为是羞耻的事。<br>◆ 知道就是知道，不知道就是不知道，不强不知以为知，这才是真正的明智。<br>◆ “毋意、毋必、毋固、毋我。”[插图]看问题不要从个人私意猜测出发，不要主观认定必然是怎么样，不要固执自己的成见，不要自以为自己的意见绝对正确。<br>◆ 道德教育有其过程，首先是道德认识。要能分清善恶与是非，进一步形成道德信念，再进一步转化为道德行为实践<br>◆ 孔丘认为，德育过程最重要的还在于行为实践。他观察当时社会，感到“知德”的人很少，“好德”的人也少，能按道德信念去实践的人更少，整个社会处于一种缺乏道德的状态，因此需要提倡道德教育。<br>◆ 孔丘主张以“礼”为道德规范，以“仁”为最高道德准则。凡符合“礼”的道德行为，都要以“仁”的精神为指导，因此，“礼”与“仁”成为道德教育的主要内容。<br>◆ 道德教育中，提倡礼的教育要贯注仁的精神，是其进步的方面。他说：“人而不仁，如礼何？”[插图]做人而缺乏仁德，怎能去实行礼仪制度呢？礼和仁的关系就是形式和内容的关系，礼为仁的形式，仁为礼的内容。有了仁的精神，礼才能真正充实。<br>◆ 仁最通常的意思就是“爱人”，也就是承认别人的资格，把人当作人来爱。“爱人”并不是不分善恶而普遍地爱一切人，而是以“仁”为基本准则，有所爱也有所憎。<br>◆ 这是说，进行道德教育要抓根本，应从家庭教育着手，先培养孝悌的道德观念。<br>◆ 仁德的实行可分两方面，据曾参的理解：“夫子之道，忠恕而已矣。”[插图]忠与恕，是表现仁的两方面，朱熹注：“尽己之谓忠，推己之谓恕。”“尽己”就是“己欲立而立人，己欲达而达人”，这属于积极一面；“推己”就是“己所不欲，勿施于人”，这属于消极一面。两方面都站在自己的立场，以己之所好恶为基点，推己而及人之所好恶。这种推己及人的办法，就叫“能近取譬”，是实行仁德的便捷途径。<br>◆ “仁远乎哉？我欲仁，斯仁至矣。”[插图]又说：“为仁由己，而由人乎哉？”[插图]他还强调道德修养不是闭门自修，参与社会实践活动更为重要。道德修养不能脱离社会，需要正确处理多方面的关系。他提出的一些道德修养应当遵行的基本要求，是其教育实践的经验总结，且称之为德育原则。<br>◆ （一）立志<br>◆ 孔丘认为，人不应以当前的物质生活为满足，还应有对未来的精神上更高的追求，要有自己的理想。<br>◆ （二）克己<br>◆ 在社会人际关系中，如何对待自己和对待他人是一个重要的道德问题。孔丘主张应着重在要求自己上，约束和克制自己的言行，使之合乎礼、仁的规范。观察一个人遇事如何对人对己，就可以判断他的道德是否高尚。<br>◆ 遇到不如意的事，“不怨天，不尤人”[插图]，“人不知而不愠，不亦君子乎！”[插图]“不患人之不己知，患不知人也。”[插图]“君子病无能焉，不病人之不己知也。<br>◆ 克己是复礼的基本条件。能克制个人非分的欲望，限制对私利的追求，不为利己而损人以至损害社会利益，这才能使自己的言行合乎礼的规范，达到仁这一最高的道德要求。<br>◆ （三）力行<br>◆ 始吾于人也，听其言而信其行；今吾于人也，听其言而观其行。”[插图]实际行动才表明人的道德水平。<br>◆ （四）中庸<br>◆ 人的行为不一定都合乎道德准则，常有做得过分或不及的情况。孔丘认为，最好是做得恰到好处，强调“中庸”。<br>◆ 所谓“择乎中庸”，就是能辨明各种行为过与不及的是非得失，择其中道而行。<br>◆ （五）内省<br>◆ 内省之后，如果问心无愧，心安理得，就增强了道德行为的信心和勇气。但是，能够自觉内省，对自己行为的过失展开内心思想斗争的实在不多。其实内省并没有复杂条件，随时都可进行，他说：“见贤思齐焉，见不贤而内自省也。”[插图]又说：“三人行，必有我师焉，择其善者而从之，其不善者而改之。”[插图]见人有好品德，就应向他看齐，虚心学习他的善行；见到人有不良的品德表现，就要对照检查自己，引以为戒，防止存在类似的缺点错误。<br>◆ （六）改过<br>◆ 人不能杜绝一切小错误，但应力求不要犯大错误。人会犯错误是客观存在，孔丘认为正确的态度是重视改过。<br>◆ 他回答子贡提问时说：“圣则吾不能，我学不厌而教不倦也。”[插图]他也曾在学生面前公开作自我评价说：“若圣与仁，则吾岂敢。抑为（学）之不厌，诲人不倦，则可谓云尔已矣。”[插图]他承认自己只做到“学而不厌”、“诲人不倦”两个方面<br>◆ （一）学而不厌教师要尽自己的社会职责，应重视自身的学习修养，掌握广博的知识，具有高尚的品德，这是教人的前提条件。<br>◆ （二）温故知新只能记诵的人，不足以为人师。孔丘说：“温故而知新，可以为师矣。”[插图]“故”是古，指的是过去的政治历史知识；“新”是今，指的是现在的社会实际问题。教师既要了解掌握过去政治历史知识，又要借鉴有益的历史经验认识当代的社会问题，知道解决问题的办法。<br>◆ （三）诲人不倦教育是高尚的事业，需要对学生、对社会有高度责任心的人来为其服务。教师以教为业，也以教为乐，要树立“诲人不倦”的精神<br>◆ （四）以身作则孔丘认为，教师对学生进行教育的方式，不仅有言教，还有身教。言教在说理，以提高道德认识；身教在示范，实际指导行为方法。<br>◆ （五）爱护学生他爱护关怀学生表现在要学生们努力进德修业<br>◆ （六）教学相长孔丘认为，教学过程中，教师对学生不是单方面的知识传授，而是可以教学相长的。<br>◆ 孔丘是儒家学派的创始人。孔丘之后，儒家学派经历了分化、发展、融合、改造、再改造，起伏变化，已非原本形态。儒家学派与中国封建社会的发展密切相关。历代的封建统治者，根据自己的利益和需要来利用改造儒家思想，使它为维护封建统治服务。<br>◆ 在封建社会处于上升时期，它被利用为巩固封建制度服务，对社会发展起积极作用是主要的；当封建社会到了没落时期，它被利用来维护封建制度，对社会发展则起消极作用。<br>◆ 我们应当以历史唯物主义为指导，正确、全面地评价孔丘的教育思想，批判地继承这一份珍贵的教育遗产，以促进现代文化教育事业的建设。<br>◆ 2024/07/01发表想法<br>不正是中庸之道吗<br>原文：我们应当以历史唯物主义为指导，正确、全面地评价孔丘的教育思想，批判地继承这一份珍贵的教育遗产，以促进现代文化教育事业的建设。<br>第一十九章 第六节 道家的教育思想<br>◆ 道家认为，教育不应是一个在人身上施加人类文明影响的过程，而应是把得之于社会的影响逐渐损弃的过程<br>◆ 强人所不欲的教育将不会有好结果。<br>◆ 《庄子·德充符》中还列举办私学曾与孔丘平分鲁国天下的王骀的事例，倡导一种“立不教，坐不议，虚而往，实而归。固有不言之教，无形而心成”的教育。在《马蹄》篇中，庄周通过伯乐养马的故事说明不顺应自然必将受到惩罚的道理；还以伯乐为象征，批评在教育中类似伯乐那样自以为“我善治马”而实际上大批残害马至死的人和事，指出了教育可能存在着另一面。在《人间世》篇中，他更以大森林中的有用之材往往活不到自然寿命而“中道夭于斧斤”的事例，提出一个颇可深思的问题：为何有用之材最易中途夭折？<br>◆ 道家提出的问题是有价值的。其一，它提醒我们重新审视教育，全面认识教育。<br>◆ 他们也触及了教育活动和教育发展中的本质矛盾，因为任何社会性原则都有可能背离自然法则，任何时代和社会的教育在体现其具体的社会要求、社会内涵时，必须注意个人的价值和发展问题。<br>◆ “大道废，有仁义；智慧出，有大伪；六亲不和，有孝慈；国家昏乱，有贞臣。”[插图]“夫天下多忌讳而民弥贫，民多利器而邦家滋昏，民多智慧而邪事滋起，法令滋章而盗贼多有。”<br>◆ 2024/07/01发表想法<br>其实也有这样的社会，瑞士那种小国寡民就是。<br>原文：“鸡犬之声相闻，民至老死不相往来”<br>◆ “鸡犬之声相闻，民至老死不相往来”<br>◆ “古之善为道者，非以明民，将以愚之。”治国从来就不该是教人聪明，而是使人归于拙朴，因为“民之难治，以其智多。<br>第二十一章 第八节 战国后期的教育论著<br>◆ 《大学》是《礼记》中的一篇，是儒家学者论述大学教育的一篇论文，它着重阐明“大学之道”——大学教育的纲领，被认为是与论述大学教育之法的《学记》互为表里之作。<br>◆ 《大学》在宋代受到理学家的高度重视。朱熹亲加整理，编定为“经”一章和解释经文的“传”十章，并将其与《中庸》一起从《礼记》中抽出，与《论语》、《孟子》合称《四书》，成为宋以后中国古代教育的基本教科书。<br>◆ 这个“为学次第”概括地说就是先读《大学》“以定其规模”，接着读《论语》“以立其根本”，再读《孟子》“以观其发越”，最后读《中庸》“以求古人之微妙处”。<br>◆ （一）“三纲领”《大学》开头就说：“大学之道，在明明德，在亲民，在止于至善。”这是儒家对大学教育目的和为学做人目标的纲领性表达，“明明德”、“亲民”、“止于至善”被称之为“三纲领”。<br>◆ 他们要求凡事都须由己及人，把个人自身的善转化为他人，尤其是民众的善，于是高一步的目标是“亲民”。<br>◆ 大学教育的终极目标是“止于至善”。《大学》对此的解释是：“为人君止于仁，为人臣止于敬，为人子止于孝，为人父止于慈，与国人交止于信。”每个人都应在其不同身份时做到尽善尽美。<br>◆ 《大学》认为人的完善是一个过程，又可细分为八个步骤：格物、致知、诚意、正心、修身、齐家、治国、平天下。这就是“八条目”。八条目前后相续，逐个递进而又逐个包含，体现了阶段与过程的统一。<br>◆ 但是，由于《大学》中缺失对格物、致知的诠释，造成后人对其理解的众说纷纭。<br>◆ 格物就是学习儒家“六德”、“六行”、“六艺”之类。致知则是在格物基础上的提高，是一种“以积蓄学问开始引导出豁然贯通的最后阶段的方法”，“即从寻求事物的理开始，旨在借着综合而得最后的启迪”[插图]<br>◆ “意诚而后心正”。所谓正心，就是不受各种情绪的左右，始终保持认识的中正。诚意与正心的区别在于：诚意主要指人的意念、动机的纯正；正心则要求摆脱情绪对人认识和道德活动的影响。它们的共同特点在于：都是行为发生前的心理活动。作为个人的学习活动，诚意与正心还局限于自我。<br>◆ 修身与正心的不同在于，它是“由内及外，由己及人，由‘明明德’到‘亲民’的转折点”[插图]。作为一种学习，修身不再局限于个人内心的自省与自律，开始走出自我，在与他人的相互关系中再认识、要求和提高自我。<br>◆ 齐家、治国、平天下是个人完善的最高境界。<br>◆ 因为修身的主要内容是正确处理人我关系，而齐家无非是完善起码的人际关系。齐家是一个施教过程，即成为家庭与家族的楷模，为人效法。<br>◆ 只有自己做到了，然后可以去责人做到；只有自己不做，然后才可以责人不做<br>◆ 教人不过是学在人先，善在人先<br>◆ 《中庸》开宗明义的篇首语就可以作此理解：人生来就有善的本性；人应当对此加以保存和发扬；人的善性的真正保存和发扬有待于教育的作用。<br>第二十三章 第一节 秦朝的教育政策及其措施<br>◆ 秦朝的教育政策遵循着一个中心原则，即维护国家的统一和君主集权的封建统治制度，以法治思想指导教育实践。<br>◆ 秦为了达到思想的统一，简单粗暴地采取禁学、烧书的手段，罔顾民众基本的精神自由和文化需求，这不仅是文化专制的反映，也是愚民政策的反映。<br>◆ “焚书”的第二年，爆发了更为残暴的“坑儒”事件。<br>◆ 坑儒”不是一次偶然事件，是秦始皇一贯奉行的文化专制和愚民政策的反映。禁私学、焚书是毁灭文化的载体，堵截文化的传播途径，“坑儒”则是对人——活的文化载体的毁灭。<br>◆ 2024/07/01发表想法<br>到退回去官师合一的时代了<br>原文：实现以法治国的目的，秦采取了以法为教、以吏为师的教育政策。韩非说：“明主之国，无书简之文，以法为教；无先王之语，以吏为师。”[插图]这是秦制定教育政策的思想基础<br>第二十六章 第四节 董仲舒的教育思想<br>◆ “君为臣纲，父为子纲，夫为妻纲。”<br>◆ 仁、义、礼、智、信<br>◆ “三纲”是道德的基本准则，“五常”则是与个体的道德认知、情感、意志、实践等心理、行为能力相关的道德观念。<br>第三十八章 第三节 隋唐科举考试与学校教育<br>◆ 科举制度是由察举制度演化而来的，在吸取察举制度历史经验的基础上，经过一定的调整改进，终于形成科举考试制度，中国考试制度的发展由此进入一个新的历史阶段。<br>◆ 科举制度是一种选官制度，它破除了士族豪门对政权的垄断，适应时代进步的需要，使原来封闭的政权向庶族士人开放，扩大了隋代政权的社会基础。<br>◆ 606年“始建进士科”，是科举考试制度确立的标志，此后科举制度在中国历史上延续了1300年，直到清末1905年才废除，它曾对封建社会的政治、经济、文化产生重大的影响，是不能忽视的。<br>◆ 其类有六：一曰秀才、二曰明经、三曰进士、四曰明法、五曰明书、六曰明算。<br>◆ 由于时代的发展，隋唐科举考试选官的标准也发生根本性的大变化，既不以出身门第为标准，也不以道德品质为标准，而是以文艺才能为标准。<br>第三十九章 第四节 隋唐的中外教育交流<br>◆ 儒教，“入则孝于家，出则忠于国”。道教，“处无为之事，行不言之教”。释教，“诸恶莫作，诸善奉行”<br>第四十八章 第七节 朱熹的教育思想<br>◆ “朱子读书法”六条，即循序渐进、熟读精思、虚心涵泳、切己体察、着紧用力、居敬持志。[插图]这是朱熹教育思想的重要组成部分。<br>◆ 朱熹主张读书要“循序渐进”，包含三个意思：第一，读书应该按一定次序，不要颠倒。“以二书言之，则通一书而后又一书。以一书言之，篇、章、文、句、首尾次第，亦各有序而不可乱也。”第二，应根据自己的实际情况和能力，安排读书计划，并切实遵守它。“量力所至而谨守之。”第三，读书要扎扎实实打好基础，不可囫囵吞枣，急于求成。<br>◆ 朱熹认为，读书既要熟读成诵，又要精于思考。他说有些人读书“所以记不得，说不去，心下若存若亡，皆是不精不熟之患”。<br>◆ 熟读的要求是“使其言皆若出于吾之口”。<br>◆ 所谓“虚心”，是指读书时要虚怀若谷，静心思虑，仔细体会书中的意思，不要先入为主，牵强附会。读书中发现了疑问，“众说纷错”，也应虚心静虑，切勿匆忙决定取舍。<br>◆ 朱熹强调读书不能仅仅停留在书本上，口头上，而必须见之于自己的实际行动，要身体力行。<br>◆ 着紧用力的读书方法，包含两方面的意义：其一，必须抓紧时间，发愤忘食，反对悠悠然；其二，必须抖擞精神，勇猛奋发，反对松松垮垮。<br>◆ 朱熹把读书形象而又深刻地比喻为救火治病，撑上水船和破釜沉舟。他认为读书应该具有犹如救火治病那样的紧迫感，撑上水船那样不进则退的顽强作风和破釜沉舟那样勇往直前的精神。<br>◆ “读书之法，莫贵乎循序而致精，而致精之本，则又在于居敬而持志。此不易之理也。”[插图]所谓“居敬”，就是读书时精神专一，注意力集中。<br>◆ 所谓“持志”，就是要树立远大的志向，高尚的目标，并要以顽强的毅力长期坚持。他说：“立志不定，如何读书？”[插图]只有树立了明确的志向，才能“一味向前”，学业不断长进。<br>第五十三章 第四节 明朝的科举制度<br>◆ 第四节 明朝的科举制度明朝科举制度是中国科举制度史上的鼎盛时期。它在继承宋、元科举制度的基础上，建立了称为“永制”的科举定式，将八股文作为一种固定的考试文体，并将学校教育纳入科举体系，严重地影响和制约着学校教育的发展。<br>◆ 八股文还称时艺、时文、八比文、四书文，它在宋朝经义的基础上演变而成，是一种命题作文，有固定的结构。一般而言，每篇八股文的结构由破题、承题、起讲、入手（又称出题、领题等）、起股、中股、后股、束股八个部分组成。<br>◆ 学校教育的影响，危害尤甚。因此，八股文遭到许多有识之士的猛烈抨击。明清之际，著名思想家顾炎武甚至认为：“八股之害，等于焚书，而败坏人材，有甚于咸阳之郊，所坑者但四百六十余人也。”[插图]<br>第六十二章 第七节 颜元的教育思想<br>◆ 抨击八股取士制度<br>第六十五章 第二节 教会学校的兴办和西方教育观念的引入<br>◆ 英华书院尽管不是设在中国大陆本土，办学目的也只在“为宣传基督教而学习英文与中文”，但它是第一所主要面向华人的新式学校。<br>第六十六章 第三节 洋务教育及中国教育近代转化的启动<br>◆ 洋务运动时期的中国教育仍然以传统的封建教育为主体，但在传统教育主体中萌生了近代新教育的幼芽。正是洋务派举办的新式学堂和留学教育，开辟了传统教育之外的另一番天地。<br>◆ 兴办学堂，其目的在于培养洋务活动所需要的翻译、外交、工程技术、水陆军事等多方面的专门人才，其教学内容以所谓“西文”与“西艺”为主。<br>◆ 1.外国语（“方言”）学堂<br>◆ 2.军事（“武备”）学堂<br>◆ 3.技术实业学堂<br>◆ 京师同文馆最初是作为外语学校设立的，是近代中国被动开放的产物。<br>◆ 中英、中法《天津条约》中都有两国交涉使用文种的规定，即以后在与中国的交涉中，只使用英文和法文，在三年内暂时配附汉文，待中国选派学生学习外文以后，即停附中文。如以后有关交涉文件中发生文词争议，均以英、法文为准。这一歧视性的规定，迫使清政府作出了开办外语学校的决定。<br>◆ 洋务学堂与封建官学、书院、私塾等中国传统学校有显著的差异，因此人们常称其为新式学堂。所谓新，主要表现在培养目标、教学内容、教学方法和教学组织形式等方面。<br>◆ 大多数洋务学堂带有部门办学的性质，是洋务机构的组成部分或附属单位，直接针对本部门和机构的需要培养人才<br>◆ 其次，在“中学为体，西学为用”的总原则下，洋务学堂必然在传授西文西艺的同时，不放弃四书五经的学习。<br>◆ 詹天佑等第一期30名学生经上海预备学校培训后，在监督陈兰彬带领下从上海出发赴美（容闳已先期赴美做准备工作）。<br>第九十二章 第九节 陶行知的教育思想<br>◆ “即知即传”的“小先生制”是指人人都要将自己认识的字和学到的文化随时随地教给别人，而儿童是这一传授过程的主要承担者。<br>◆ “小先生制”是为解决普及教育中师资奇缺、经费匮乏、谋生与教育难以兼顾、女子教育困难等矛盾而提出的，“穷国普及教育最重要的钥匙是小先生”[插图]。<br>]]></description><link>culture\阅读\中国教育史-孙培青.html</link><guid isPermaLink="false">Culture/阅读/中国教育史-孙培青.md</guid><pubDate>Mon, 01 Jul 2024 07:46:04 GMT</pubDate></item><item><title><![CDATA[标签管理]]></title><description><![CDATA[<a class="tag" href="?query=tag:文化" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化</a> <a class="tag" href="?query=tag:文化/小说" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说</a> <a class="tag" href="?query=tag:文化/小说/世界观" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说/世界观</a> <a class="tag" href="?query=tag:文化/小说/人物设定" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说/人物设定</a> <a class="tag" href="?query=tag:文化/小说/剧情大纲" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说/剧情大纲</a> <a class="tag" href="?query=tag:文化/小说/灵感" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说/灵感</a> <a class="tag" href="?query=tag:文化/小说/技巧" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/小说/技巧</a> <a class="tag" href="?query=tag:文化/阅读" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/阅读</a> <a class="tag" href="?query=tag:文化/阅读/摘抄" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/阅读/摘抄</a> <a class="tag" href="?query=tag:文化/阅读/思考" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/阅读/思考</a> <a class="tag" href="?query=tag:文化/影视" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/影视</a> <a class="tag" href="?query=tag:文化/影视/动漫" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/影视/动漫</a> <a class="tag" href="?query=tag:文化/影视/电影" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/影视/电影</a> <a class="tag" href="?query=tag:文化/思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想</a> <a class="tag" href="?query=tag:文化/思想/个人思想" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/思想/个人思想</a> <a class="tag" href="?query=tag:文化/教育学" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/教育学</a> <a class="tag" href="?query=tag:文化/教育学" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#文化/教育学</a> 
 <br><a href=".?query=tag:文化" class="tag" target="_blank" rel="noopener nofollow">#文化</a><br>
<br><a href=".?query=tag:文化\小说" class="tag" target="_blank" rel="noopener nofollow">#文化/小说</a>

<br><a href=".?query=tag:文化\小说\世界观" class="tag" target="_blank" rel="noopener nofollow">#文化/小说/世界观</a>
<br><a href=".?query=tag:文化\小说\人物设定" class="tag" target="_blank" rel="noopener nofollow">#文化/小说/人物设定</a> 
<br><a href=".?query=tag:文化\小说\剧情大纲" class="tag" target="_blank" rel="noopener nofollow">#文化/小说/剧情大纲</a>  
<br><a href=".?query=tag:文化\小说\灵感" class="tag" target="_blank" rel="noopener nofollow">#文化/小说/灵感</a> 
<br><a href=".?query=tag:文化\小说\技巧" class="tag" target="_blank" rel="noopener nofollow">#文化/小说/技巧</a> 


<br><a href=".?query=tag:文化\阅读" class="tag" target="_blank" rel="noopener nofollow">#文化/阅读</a>

<br><a href=".?query=tag:文化\阅读\摘抄" class="tag" target="_blank" rel="noopener nofollow">#文化/阅读/摘抄</a> 
<br><a href=".?query=tag:文化\阅读\思考" class="tag" target="_blank" rel="noopener nofollow">#文化/阅读/思考</a> 


<br><a href=".?query=tag:文化\影视" class="tag" target="_blank" rel="noopener nofollow">#文化/影视</a> 

<br><a href=".?query=tag:文化\影视\动漫" class="tag" target="_blank" rel="noopener nofollow">#文化/影视/动漫</a> 
<br><a href=".?query=tag:文化\影视\电影" class="tag" target="_blank" rel="noopener nofollow">#文化/影视/电影</a> 


<br><a href=".?query=tag:文化\思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想</a>

<br><a href=".?query=tag:文化\思想\个人思想" class="tag" target="_blank" rel="noopener nofollow">#文化/思想/个人思想</a>


<br><a href=".?query=tag:文化\教育学" class="tag" target="_blank" rel="noopener nofollow">#文化/教育学</a> 

<br><a href=".?query=tag:文化\教育学" class="tag" target="_blank" rel="noopener nofollow">#文化/教育学</a>  


]]></description><link>culture\标签管理.html</link><guid isPermaLink="false">Culture/标签管理.md</guid><pubDate>Sun, 17 Mar 2024 07:09:51 GMT</pubDate></item><item><title><![CDATA[大二下寒假计划]]></title><description><![CDATA[ 
 <br><br><br>我希望这个寒假我能具备基础的模型训练能力，论文理解能力及代码复现能力。<br>
<br>通过大创中MMaction模型的使用去熟悉模型训练过程
<br>videoclip和prompt Switch的论文理解和复现
<br>熟悉实验平台，学会使用j云服务器进行模型训练
<br>在github上更新论文代码进度
<br><br>我希望有一个个人博客网站，这个网站用来记录我的思考和一些比较有用的笔记。它是由零碎与整体两部分组成，既有零碎的想法和笔记也有成体系的个人简介。<br>
<br>针对个人思考和笔记在CNBlog上更新
<br>针对网站美化进行学习，使用图床更换背景以及音乐
<br>针对个人的整体介绍，通过github静态网站呈现，具体可以在ob里单独开一个文件夹
<br><br>目前我已经有的爱好是音乐，写作，和阅读。我希望我能爱上跑步。<br>
<br>练习蜂鸟口琴，能完整流畅吹出人生的旋转木马，远空，宫崎骏组曲，雪之花
<br>读完冰与火之歌，并写个阅读报告
<br>在冰与火之歌基础上，去修改我的小说大纲。
<br>买跑鞋，运动手表，骨传导耳机，矫正跑步姿势。从二月份开始跑步。
]]></description><link>plan\大二下\大二下寒假计划.html</link><guid isPermaLink="false">Plan/大二下/大二下寒假计划.md</guid><pubDate>Sun, 07 Apr 2024 05:47:52 GMT</pubDate></item><item><title><![CDATA[大二下考试日程]]></title><description><![CDATA[ 
 <br>
<br>python第三次大作业6-25
<br>教育心理学 周三6-26 18:30-20:30 学正203
<br>俄罗斯历史 周三6-26 13:30-15:00 学海219
<br>算法设计 周四6-27 13:30-15:30 学明401
<br>教育社会学 6-28 教育自传
<br>基础英语4 周六6-29 13:30-15:30 学明401
<br>概率论 周日6-30 10:20-12:20 学正201
<br>中国教育史7-2 18:30-20:30 学正203
<br>教育概论7-4 18:30-20:30 学正203
<br>机器学习 7-4 10:20-12:20 学明107
<br>计算机系统基础作业，最优化作业7-6
<br>复习计算机系统基础1-2章7-7
<br>复习最优化及计算机系统基础第三章7-8
<br>最优化7-9早上看最优化 13:30-15:30 学明107考试
<br>复习计算机系统基础第四章7-10
<br>计算机系统基础 7-11 10:20-12:20 学明107
]]></description><link>plan\大二下\大二下考试日程.html</link><guid isPermaLink="false">Plan/大二下/大二下考试日程.md</guid><pubDate>Fri, 19 Jul 2024 08:40:49 GMT</pubDate></item><item><title><![CDATA[大二下暑假计划]]></title><description><![CDATA[ 
 <br>暑假于2024-7-12日正式开始，今天为2024-7-19。我休息了一周，接下来我要做一些规划。<br>
我首要解决的是我现在的身体和精神问题。健康是首要的事情。<br><br>身体上的问题具体表现为：<br>
<br>无力
<br>肤质差
<br>下颌弹响，可能有下颌紊乱
<br>肠胃容易胀气<br>
精神上问题主要表现为：
<br>失眠
<br>嗜睡
<br><br>这些问题主要是因为我太久没运动了导致的整体身体机能下降，身体懈怠了，导致了无力，肠胃胀气等问题。加之熬夜，睡姿不当，导致了无力，肤质差，下颌紊乱等问题，<br>主要矛盾在于睡眠和运动，要解决睡眠问题并开始运动。睡不着主要是一白天睡得太多，二是想得太多。关于想得太多我后面会讲。<br><br><br>绕着一个地方骑行没意思怎么办，听书。每天保证一个小时的骑行，大概骑行十几公里。回来洗个澡很爽。今天就开始。<br><br>过去的事情不想，越想记忆越深刻，而且往往是不好的记忆越深刻，这会影响我的判断和睡眠。未来的事情不想，最近看的一些失落的一代的论断，一些世界动荡的论断，让我对未来有焦虑。但是这没有意义，最好的做法是提升自己，而这基本与你是否在为未来焦虑无关。<br><br>
<br>给华为配latex环境
<br>数模那本书，把例题做一下
<br>数模培训
<br>PA推进，现在你应该理论基础比之前强了
<br>学习鸿蒙开发
<br><br>
<br>西方现代思想讲义
<br>我们生活在南京
<br>货币的教训
<br>直视骄阳
]]></description><link>plan\大二下\大二下暑假计划.html</link><guid isPermaLink="false">Plan/大二下/大二下暑假计划.md</guid><pubDate>Tue, 10 Sep 2024 07:05:57 GMT</pubDate></item><item><title><![CDATA[进一步确定自己想要的]]></title><description><![CDATA[<a class="tag" href="?query=tag:plan" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#plan</a> 
 <br><a href=".?query=tag:plan" class="tag" target="_blank" rel="noopener nofollow">#plan</a> <br><br>我想要一个宁静惬意的环境，像龙猫那一家人的环境一样，有爱人陪我，我写写书，累了就玩玩音乐，跑跑步，我会有大把的时间去看书，去倾听自然。<br>另一方面，我想要足够的物质条件来支持我找到那个与我能共鸣的人，找到一处此心安处的地方。]]></description><link>plan\大三上\进一步确定自己想要的.html</link><guid isPermaLink="false">Plan/大三上/进一步确定自己想要的.md</guid><pubDate>Sun, 12 Jan 2025 02:05:00 GMT</pubDate></item><item><title><![CDATA[自发课选课]]></title><description><![CDATA[ 
 <br>我还需要修13分自发课<br>
大三下<br>
<br>语音 3分
<br>企业实训 2分
<br>智慧教育 3分
<br>大四上<br>
<br>工程伦理 1分
<br>专业英语 2分
<br>机器人学导论 2分
]]></description><link>plan\大三上\自发课选课.html</link><guid isPermaLink="false">Plan/大三上/自发课选课.md</guid><pubDate>Sun, 12 Jan 2025 02:01:39 GMT</pubDate></item><item><title><![CDATA[复习规划]]></title><description><![CDATA[ 
 <br><br><img alt="{F8C95436-0E2C-4B8C-9493-14F0CCA02209}.png" src="\lib\media\{f8c95436-0e2c-4b8c-9493-14f0cca02209}.png"><br><br>
<br>搜集所考科目各个课程的脑图，大体看一遍
<br>整理院校信息，先将目标大致定好
<br>复习时间及内容规划，主要是基础阶段和强化阶段的时间要规划好
<br>]]></description><link>plan\考研\复习规划.html</link><guid isPermaLink="false">Plan/考研/复习规划.md</guid><pubDate>Thu, 26 Sep 2024 01:31:33 GMT</pubDate><enclosure url="lib\media\{f8c95436-0e2c-4b8c-9493-14f0cca02209}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{f8c95436-0e2c-4b8c-9493-14f0cca02209}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[考研目标院校]]></title><description><![CDATA[ 
 <br>浙江大学本部<br>
东南大学本部<br>
浙江大学海宁校区 15w学费+3w住宿费，单人间<br>
浙江大学软件学院 15w学费+4800住宿，四人间<br>
东南大学蒙纳士 19.5w学费+ 6600住宿，四人间]]></description><link>plan\考研\考研目标院校.html</link><guid isPermaLink="false">Plan/考研/考研目标院校.md</guid><pubDate>Sun, 05 Jan 2025 02:03:28 GMT</pubDate></item><item><title><![CDATA[总览]]></title><description><![CDATA[ 
 <br><br><br>绩点3.2，加上从大二开始没有再卷综测，目前不足以保研，且就业形势不好。确定准备考研或者国外直博。<br>
介于直博难度较大，优先考研，出国作为一个备选方案。<br><br>从今天2024/09/10到考研第一天日期2025/12/23。一共一年三个月零12天。<br>
总共约468天，66周。468天中，有约90天为完整假期时间。其他时间有54周，即108天周末。<br>
也就是确定的完全可学习时间为200天左右，这还不包括期末周复习等其他情况。<br>每周工作日周一周四满课。周二早上空闲，周二周三下午空闲。晚周一到周四晚上有辅修，有意思可以听听，没意思做自己的事。<br><br>数一，英一，政治，408。<br>
考研目标分数360。底线为315。<br>
英语每天三十个单词，224天背完。<br>
数学复习从大三下开始。现在主要解决专业课学习和完整科研经历。<br><br>数学<br>
<img alt="{F57D25AD-9041-48D0-BA67-F543688E18DF} 1.png" src="\lib\media\{f57d25ad-9041-48d0-ba67-f543688e18df}-1.png"><br>
英语刷真题背单词<br>
<img alt="{87720ABA-1FAF-45DE-A4D8-A3C5CB013F66}.png" src="\lib\media\{87720aba-1faf-45de-a4d8-a3c5cb013f66}.png"><br><img alt="{EAA413F3-98B7-4168-BB0F-C3E362139841}.png" src="\lib\media\{eaa413f3-98b7-4168-bb0f-c3e362139841}.png"><img alt="{2D537B54-8D9B-42B9-9F23-11D7FA9ADE97}.png" src="\lib\media\{2d537b54-8d9b-42b9-9f23-11d7fa9ade97}.png"><br><br><img alt="{74580CB9-AC90-4A91-9C25-50CE3807D9DF}.png" src="\lib\media\{74580cb9-ac90-4a91-9c25-50ce3807d9df}.png"><br>整体报考人数下降一些，总录取人数上升。<br><img alt="{81F42B8E-CF8F-452D-B20C-374712E9E197}.png" src="\lib\media\{81f42b8e-cf8f-452d-b20c-374712e9e197}.png"><br>
<img alt="{49CDD59D-58B4-4E45-B811-95CA494FABEE}.png" src="\lib\media\{49cdd59d-58b4-4e45-b811-95ca494fabee}.png"><br>国家线仍在上升，说明整体更卷。<br><br><img alt="{D4DC451B-6AF5-409D-A66A-DA9D5F79C0F2}.png" src="\lib\media\{d4dc451b-6af5-409d-a66a-da9d5f79c0f2}.png"><br><br><img alt="{EF773034-A588-4581-B7B7-F1FE9F5D9007} 1.png" src="\lib\media\{ef773034-a588-4581-b7b7-f1fe9f5d9007}-1.png"><br><br><img alt="{C91B6B12-A62D-4FDA-A1EF-701408E4A97C}.png" src="\lib\media\{c91b6b12-a62d-4fda-a1ef-701408e4a97c}.png"><br><br><img alt="{A87C541D-2353-4D37-A107-424D73533747}.png" src="\lib\media\{a87c541d-2353-4d37-a107-424d73533747}.png"><br><img alt="{C73ECEE4-9369-4A6A-A90F-57F932E4E4A3}.png" src="\lib\media\{c73ecee4-9369-4a6a-a90f-57f932e4e4a3}.png"><br>
<img alt="{8B862210-C4C5-40C0-8F5B-28AFD548384D}.png" src="\lib\media\{8b862210-c4c5-40c0-8f5b-28afd548384d}.png"><br>
<img alt="{3E25C590-7760-4FC3-A425-F74211A07CBD}.png" src="\lib\media\{3e25c590-7760-4fc3-a425-f74211a07cbd}.png"><br>
<img alt="{292638FB-4F0A-4B1C-B4AC-54EE27185302}.png" src="\lib\media\{292638fb-4f0a-4b1c-b4ac-54ee27185302}.png"><br><br><img alt="{D301932F-BB4A-4B62-8E05-50B6072B53E3}.png" src="\lib\media\{d301932f-bb4a-4b62-8e05-50b6072b53e3}.png"><br><br><img alt="{7B9BE174-74AA-49EF-8DD3-C2B55695EAA7}.png" src="\lib\media\{7b9be174-74aa-49ef-8dd3-c2b55695eaa7}.png"><br>
<img alt="{B884CE2C-A52B-4B02-BB32-113187233E87}.png" src="\lib\media\{b884ce2c-a52b-4b02-bb32-113187233e87}.png"><br>
<img alt="{7A3F78EA-0F7B-45D8-9464-5AE3C47D92DC}.png" src="\lib\media\{7a3f78ea-0f7b-45d8-9464-5ae3c47d92dc}.png"><br><br><img alt="{F8C95436-0E2C-4B8C-9493-14F0CCA02209}.png" src="\lib\media\{f8c95436-0e2c-4b8c-9493-14f0cca02209}.png"><br><br><img alt="{6C19D02A-5E96-4ADA-B41F-3B607164A917}.png" src="\lib\media\{6c19d02a-5e96-4ada-b41f-3b607164a917}.png"><br><br><img alt="{B84629F8-58C2-457D-A4A6-B3AA765E0CC9}.png" src="\lib\media\{b84629f8-58c2-457d-a4a6-b3aa765e0cc9}.png"><br><br><img alt="{95D2BCB9-EB10-48BB-93BA-B6DCA283F68D}.png" src="\lib\media\{95d2bcb9-eb10-48bb-93ba-b6dca283f68d}.png">]]></description><link>plan\考研\总览.html</link><guid isPermaLink="false">Plan/考研/总览.md</guid><pubDate>Sun, 12 Jan 2025 02:00:15 GMT</pubDate><enclosure url="lib\media\{f57d25ad-9041-48d0-ba67-f543688e18df}-1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{f57d25ad-9041-48d0-ba67-f543688e18df}-1.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-05-21]]></title><description><![CDATA[ 
 <br><br>
<br>机器学习EM算法
<br>高斯混合模型
<br>概率论作业 *deadline 5-24 
<br>悬赏令 deadline 5-25
<br>python大作业 deadline:5-27
<br>电工杯 deadline:5.24-5.26
<br>概率论第二次阶段考 deadline:5-29
<br>机器学习贝叶斯分类 deadline:5-26
<br>最优化作业
]]></description><link>plan\daily-plan\2024-05-21.html</link><guid isPermaLink="false">Plan/daily plan/2024-05-21.md</guid><pubDate>Sat, 21 Sep 2024 08:03:59 GMT</pubDate></item><item><title><![CDATA[2024-06-01]]></title><description><![CDATA[ 
 <br><br>
<br>教育自传高中部分写完
<br>准备一份参赛代码模板
<br>百度之星6-16
<br>概率论
<br>网络暴力预测模型
<br>计算机系统基础作业
<br>机器学习飞桨
<br>机器学习手写
<br>算法设计解题报告7/30 deadline:6-6
<br>挑战杯 deadline:6-5
<br>计算机系统基础实验
]]></description><link>plan\daily-plan\2024-06-01.html</link><guid isPermaLink="false">Plan/daily plan/2024-06-01.md</guid><pubDate>Sat, 21 Sep 2024 08:03:56 GMT</pubDate></item><item><title><![CDATA[2024-09-21]]></title><description><![CDATA[ 
 <br><br>
<br>数据挖掘实验报告一 9-23
<br>重装虚拟机，解决网络问题
<br>党史作业 9-20
<br>Compact-SER代码跑通自己的数据集 9-25
<br>增加每个类别的ACC再跑一次
<br>数据库原理实验  9-26
<br>数据挖掘实验报告二 9-30
<br>EfficientNetB0调通
<br>LFCC跑一遍
<br>深度学习实验 9-27
<br>计算机组成原理作业
<br>学操作系统第二章
<br>LFCC_MFCC_delta_over-sample
<br>EfficientNetB0模型训练
]]></description><link>plan\daily-plan\2024-09-21.html</link><guid isPermaLink="false">Plan/daily plan/2024-09-21.md</guid><pubDate>Tue, 01 Oct 2024 02:46:26 GMT</pubDate></item><item><title><![CDATA[2024-10-01]]></title><description><![CDATA[ 
 <br>
<br>操作系统实验 10-20
<br>MFCC和LFCC转成12个系数和1个帧强度，增加一阶差分和二阶差分
]]></description><link>plan\daily-plan\2024-10-01.html</link><guid isPermaLink="false">Plan/daily plan/2024-10-01.md</guid><pubDate>Mon, 14 Oct 2024 01:05:03 GMT</pubDate></item><item><title><![CDATA[2024-10-08]]></title><description><![CDATA[ 
 <br>
<br>8:00 中信证券银证转账
<br>挂沪深300ETF易方达买入4.5 2000，科创100ETF华夏买入1.034 10000
<br>数字图像处理作业
<br>看论文，深度学习提取特征
<br>两台主机配置 cuda及pytorch环境
<br>代码跑通，解决librosa库的mfcc返回值问题
<br>解决nx库node问题
<br>党史作业
<br>更改mfcc采样率等参数重新跑一遍看效果
<br>我改回了原本的参数，但是数据预处理结果还是不对
<br>预处理结果不对是因为采样率变了
<br>更改参数后准确率反而下降了，找到代码问题，为什么准确率下降，对比代码
<br>可能是全局归一化的问题
<br>王道的操作系统课看第一章
<br>计算机组成原理课看第一章
]]></description><link>plan\daily-plan\2024-10-08.html</link><guid isPermaLink="false">Plan/daily plan/2024-10-08.md</guid><pubDate>Mon, 14 Oct 2024 01:04:36 GMT</pubDate></item><item><title><![CDATA[2024-10-14]]></title><description><![CDATA[ 
 <br>
<br>解决自选优化器问题
<br>整理修改代码，建立批处理数据，如何保存GNN权重，如何将分类改成概率
<br>帧选择的问题
<br>这个方向走一下，即通过将音频直接切成长段放入预训练模型得到特征再放入GNN<img alt="{A0769007-7792-456D-88E7-DFBE4C6A9856}.png" src="\lib\media\{a0769007-7792-456d-88e7-dfbe4c6a9856}.png">
<br>继续深挖local peak-local peak ，如果还是不好，换成均匀分布采样
]]></description><link>plan\daily-plan\2024-10-14.html</link><guid isPermaLink="false">Plan/daily plan/2024-10-14.md</guid><pubDate>Sun, 12 Jan 2025 02:03:54 GMT</pubDate><enclosure url="lib\media\{a0769007-7792-456d-88e7-dfbe4c6a9856}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{a0769007-7792-456d-88e7-dfbe4c6a9856}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2024-10-18]]></title><description><![CDATA[ 
 <br>
<br>10-19去看李永乐，去外面吃饭拍照玩，过生日
<br>操作系统实验 10-20 实验1-4
<br>操作系统作业 10-21 18:00
<br>数据挖掘实验 10-21 23:59:59
<br>数字图像处理实验 10-23
]]></description><link>plan\daily-plan\2024-10-18.html</link><guid isPermaLink="false">Plan/daily plan/2024-10-18.md</guid><pubDate>Tue, 22 Oct 2024 01:04:23 GMT</pubDate></item><item><title><![CDATA[2024-10-21]]></title><description><![CDATA[ 
 <br>
<br>操作系统进度追一下
<br>深度学习实验第三章
<br>MFCC特征跑CNN的实验
]]></description><link>plan\daily-plan\2024-10-21.html</link><guid isPermaLink="false">Plan/daily plan/2024-10-21.md</guid><pubDate>Sun, 27 Oct 2024 01:50:08 GMT</pubDate></item><item><title><![CDATA[2024-10-27]]></title><description><![CDATA[ 
 <br>
<br>看论文
<br>计算机组成原理进度推进
<br>数据挖掘实验
<br>代码整理
<br>操作系统实验五
<br>明天找到新的GNN
<br>安装台灯
<br>数据挖掘作业
]]></description><link>plan\daily-plan\2024-10-27.html</link><guid isPermaLink="false">Plan/daily plan/2024-10-27.md</guid><pubDate>Mon, 04 Nov 2024 12:50:04 GMT</pubDate></item><item><title><![CDATA[2024-11-01]]></title><description><![CDATA[ 
 <br>
<br>EfficientNet跑出结果
<br>计算机组成原理推进并完成作业四
<br>数据挖掘实验五
<br>操作系统王道课程推进，并完成作业三
<br>深入学习GNN
<br>读GCN博士论文
<br>安排上海行程
]]></description><link>plan\daily-plan\2024-11-01.html</link><guid isPermaLink="false">Plan/daily plan/2024-11-01.md</guid><pubDate>Mon, 04 Nov 2024 14:15:42 GMT</pubDate></item><item><title><![CDATA[2024-11-04]]></title><description><![CDATA[ 
 <br>
<br>11-5 法国高等教育署咨询
<br>11-5 晚上，iGEM讨论
<br>11-6 留学咨询（不去了）
<br>计算机组成原理作业三
<br>深度学习实验复习
]]></description><link>plan\daily-plan\2024-11-04.html</link><guid isPermaLink="false">Plan/daily plan/2024-11-04.md</guid><pubDate>Fri, 08 Nov 2024 05:23:57 GMT</pubDate></item><item><title><![CDATA[2024-11-08]]></title><description><![CDATA[ 
 <br>这个周末要完成的事很多，忙起来！！！<br>
<br>读论文
<br>下午三点科研交流
<br>十二月份前要出初稿，我感觉对于原本的GNN可以去改变，不提CNN，改变图构造方式。
<br>数字图像处理作业实验
<br>计算机组成原理实验一
<br>操作系统实验
<br>数据库实验
<br>matepad air 11.5s 2778
<br>整理桌面
<br>比较教育学作业，找一个感兴趣的教育话题，跟国外做比较
<br>教育哲学期中作业
]]></description><link>plan\daily-plan\2024-11-08.html</link><guid isPermaLink="false">Plan/daily plan/2024-11-08.md</guid><pubDate>Sun, 12 Jan 2025 02:29:45 GMT</pubDate></item><item><title><![CDATA[2024-11-09]]></title><description><![CDATA[ 
 <br>
<br>重新搭建GNN并跑通，使用了Kipf-Welling的方法，效果不好
<br>彻底将论文里的GCN模型搞明白，并应用到自己的代码上
<br>推进操作系统课程
<br>复习操作系统1-5章
<br>学习大模型准备周二开会
<br>看合成生物学综述，准备周二晚上组会（已取消）
<br>开始整理论文数据和主要实验，想一个故事思路，着手写论文
]]></description><link>plan\daily-plan\2024-11-09.html</link><guid isPermaLink="false">Plan/daily plan/2024-11-09.md</guid><pubDate>Sun, 12 Jan 2025 02:31:02 GMT</pubDate></item><item><title><![CDATA[2024-12-01]]></title><description><![CDATA[ 
 <br>12月相当忙，我在11月完成了论文初稿，但是创新点不够，十二月需要做的事情太多，可能来不及继续了。而且ICME难度比较高，且时间与IJCNN太近。选择投IJCNN。<br><br>
<br>写完论文introduction
<br>写完论文method
<br>跑percent of train data
<br>analysis model
<br>整理数据
<br>写完论文experiment
<br>论文整体润色
<br>12-04找老师讨论下一步方向
<br>修改论文缩写问题
<br>少样本数据增强
<br>多通道
<br>修改模型要与原论文有明显区别，多通道
<br>增加抗噪性能实验
<br>消融实验
<br>基于不同样本数展示
<br>1-16 IJCNN
<br><br>
<br>合成生物学第二次会议
<br>12-15大创中期答辩（多模态，最主要的是找到如何将手部关节图的特征进行提取，如何将该特征与视频特征对齐融合）
<br><br>
<br>息壤杯（大模型）下周二开始，订一个地方交流，踩点数理化图书馆，然后开始着手去做
<br>代码跑通
<br>提交一次
<br>修改数据集
<br>RTFSC
<br>增加查询wiki百科进行prompt增强模块
<br>12-10初赛第一阶段(名次：8)
<br>1月2日9:00 - 1月15日18:00 初赛第二阶段
<br><br>
<br>数据库实验（GUI）
<br>深度学习实验（诗词生成）
<br>数据挖掘实验七
<br>操作系统实验
<br>数字图像处理作业
<br>复习英语六级
<br>计组实验
<br>数据库实验5
<br>计算机组成原理王道课看完，并整理笔记
<br>深度学习实验（注意力机制）
<br>数据挖掘大作业12-31
<br>数据库书籍熟悉 1-2
<br>操作系统王道课也看一下
<br><br>
<br>看论文
<br>教育研究方法文献综述
<br>复习德育原理
<br>教育研究方法开题
<br>复习教育哲学
<br><br>现在为12-20周五，这个周末需要复习很多东西，需要做个整理，具体如下：<br>
<br>德育原理的复习
<br>计算机组成原理的复习
<br>教育研究方法的文献综述
<br>教育哲学的复习<br>
现在为12-27周五
<br>数据库书本，代码
<br>数据挖掘大作业整理
<br>操作系统大作业
<br>数字图像处理实验
<br>数据挖掘复习
<br>数字图像处理复习
<br><br>
<br>12-3 工程管理考试
<br>12-10 工程管理大作业
<br>12-11 数字图像处理期中考试
<br>六级模拟
<br>12-14 英语六级
<br>12-23 德育原理考试
<br>12-25 教育研究方法考试
<br>12-25 计算机组成原理考试
<br>12-26 教育哲学考试
<br>1-2 数据库考试
<br>1-7 数据挖掘考试
<br>1-9 数字图像处理考试
<br>1-11 形势与政策考试
<br>1-12 深度学习论文答辩考试
<br>1-14 操作系统考试
]]></description><link>plan\daily-plan\2024-12-01.html</link><guid isPermaLink="false">Plan/daily plan/2024-12-01.md</guid><pubDate>Sun, 12 Jan 2025 02:04:28 GMT</pubDate></item><item><title><![CDATA[2024-12-31]]></title><description><![CDATA[ 
 <br>安排下最近的时间<br>
<br>今天下午重新把数据挖掘大作业做一下
<br>1.1 数据库复习
<br>1.2 数据库考试 8：20-10：20 学明204
<br>间隔四天半（复习四天）
<br>1.7 数据挖掘考试13:30-15:30 学明203
<br>间隔一天（复习）
<br>1.9 数字图像处理 10:20-12:20 学明203
<br>间隔四天半（复习二到三天）
<br>1.14 操作系统原理13:30-15:30 学明202
]]></description><link>plan\daily-plan\2024-12-31.html</link><guid isPermaLink="false">Plan/daily plan/2024-12-31.md</guid><pubDate>Thu, 09 Jan 2025 14:10:13 GMT</pubDate></item><item><title><![CDATA[体制内]]></title><description><![CDATA[<a class="tag" href="?query=tag:plan" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#plan</a> 
 <br><a href=".?query=tag:plan" class="tag" target="_blank" rel="noopener nofollow">#plan</a><br>
1、公务员国考:24年10月15日报名，11月26日考试<br>2、公务员省考:公告未出<br>3、选调生考试:10-12月报名，3月考试<br>4、事业单位:3-5/8-10月报名，5月/9-10月考试，<br>全国联考分上半年、下半年两次<br>5、人才引进:1-5月报名，2-6月考试(硕士研究生及以上)<br>6、选:11月报名(体制内公务员参加)<br>7、军队文职:10月底发布公告并组织报名，12上旬组织全军笔试<br>8、三支一扶:5-8月报名，6-9月考试<br>9、西部计划:3-5月报名，5-6月考试<br>10、特岗教师:5-6月报名，7月考试<br>11、公安考试:11月报名，1月考试<br>12、国家电网:3月/11月报名，4月/12月考试<br>13、国家烟草:2-4月报名<br>14、中石化:9-10月报名，11月考试<br>15、银行:8-9月报名，10-12月考试<br>16、社区工作者:9月报名，9-10月考试<br>【公务员国考】<br>报名：10月15日、考试：11月26日、笔试公布：2月下旬 、面试：预计4月<br>报名网站：国家公务员局<br>笔试内容：《行测》《申论》<br>备注:由中央垂直管理，编制不属于地方，国考的难度较大，竞争比较烈。<br>【公务员省考】<br>报名时间：1月、考试时间：2-3 月、面试时间：4月（具体以公告为准）<br>报名网站：各省人事考试中心、各地政府官网;<br>笔试内容：《行测》《申论》<br>备注：有的省份单独招考，有的参加联考，时间有差异，有多次考试机会。<br>【选调生考试】<br>报名时间：10-12月、考试时间：集中在12月、1月<br>报名网站:各省人事考试网<br>笔试内容:《职测》《综合》<br>备注：1、定向选调生:重点高校优秀应届毕业生，作为领导干部后备人选重点<br>培养，z治前途比一般公务员好。学历很重要，高学历待遇更好，未来的职<br>级也会更高。<br>2、普通选调生:主要面对的是县级和乡镇级别的岗位起点上<br>比定向选调生略低一点。一般会先分配在乡镇上，存在选而不调的情况。<br>【事业编】人才引进<br>报名时间：集中在1-5月份、考试时间：集中在2-6月份<br>报名网站：各省人事考试中心、各地政府官网<br>备注：1、不需要笔试，只要面试就可以获得事业编制<br>2、要求是党员预备党员，学生干部;<br>3、一般情况下，研究生转正副科级待遇，博士转正正科级待遇<br>4、其他待遇:比如给安家费、生活补贴、住房补贴等，各地设置的条件不同。<br>【事业编】事业单位考试<br>报名时间：3月-5月，8月-10月、考试时间:5月、9月-10月<br>报名网站：省人事考试中心、全国事业单位招聘网、各地政府网站<br>备注：分为多省事业单位联考、各省事业单位单独招考，有些是单位自行组<br>织的，有些是县区统一组织的，只要考进去了就会有编制。相对来说省市单<br>位难度较大，基层岗位难度要低一些，更容易上岸。<br>【遴选】11月报名(体制内公务员参加)<br>学历要求（硕士研究生及以上）<br>笔试内容：《行测》《申论》<br>公告网站：各地人民政府官网、组织部官网<br>【军队文职】报名时间：1月13日-1月17日、考试时间：2月19日<br>报名网站:军队人才网<br>备注：军队文职不属于军官级，却享受同级别福利待遇。本科生每月9000元左右硕士研究生每月10000元左右博士研究生每月11000元左右，还有其他福利津贴。<br>【三支一扶】)报名时间：3月-8月、考试时间：4月-9月<br>报名网站：各省人事考试中心。<br>备注：1、报名门槛比较低；2、直接入编：大部分三支一扶服务期满后，可以免试，直接转为当地事业编制；3、服务期满后，在公务员考试中报考优势<br>【西部计划】报名时间：3-5月、考试时间：5-6月<br>报名网站：西部计划国家网站。<br>备注：服务期满2年日考核合格的，可享受国家公务员考试的有关优惠政策<br>除有考专岗外，还有加分政策。<br>【特岗教师】报名时间：5-6月、考试时间：7月<br>报名网站：各省教师教育网。<br>备注:难度相对较小，大学生在基层服务三年后，通过审核，即可获取正式<br>的教师事业编制。转正之后，可以进行调岗，可以往更高层的学校，或者是<br>非义务教育阶段的学校调岗。<br>【公安考试】报名时间：11月、考试时间：1月<br>报名网站：公安司法院校毕业生通过专项招录网站<br>备注：1全称公安机关面向全国公安院校公安专业应届毕业生统一招录人民<br>警察考试。2只要能够通过公安联考，并且顺利毕业就可以入警，成为一<br>名有正式编制的人民警察；3公安院校联考是警校生一生只能参加一次的考试<br>【国家电网】报名时间：3月/11月、考试时间：4月/12月<br>报名网站：国家电网人力资源招聘。<br>备注：各个省份都有分公司，每年举行两次招考，大多岗位都是面对应届毕业生。<br>【国家烟草】报名时间：2-4月<br>报名网站：国家烟草专卖局、中国烟草总公司网站。<br>备注：每个省份的烟草是独立招聘的，考试分为笔试和面试，大部分地区的<br>考试内容和公务员考试相似，也有些省份会考一些烟草专业知识。<br>【银行】报名时间：8-9月、考试时间：10-12月<br>报名网站：各银行公告网站<br>备注：1、不同银行考试时间有所差异，要根据当年银行的通知确定<br>2、银行工作相对稳定、待遇通常不差、工作环境好，当然优势压力较大、事<br>物较多、竞争激烈。]]></description><link>plan\体制内.html</link><guid isPermaLink="false">Plan/体制内.md</guid><pubDate>Tue, 10 Sep 2024 07:06:23 GMT</pubDate></item><item><title><![CDATA[长期Plan]]></title><description><![CDATA[<a class="tag" href="?query=tag:plan" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#plan</a> 
 <br><a href=".?query=tag:plan" class="tag" target="_blank" rel="noopener nofollow">#plan</a><br><br><br>
<br>概率论、机器学习、最优化不低于八十分，知识点全部理解，底子打好
<br>校内数模比赛
<br>电工杯
<br>百度之星
<br>论文框架至少搭好
<br><br>
<br>读书
<br>跑步
<br>口琴
<br>摄影
<br><br>
<br>高教杯数模
<br>准备考研
<br>普通话
<br>息壤杯
<br>论文
<br>教资
<br><br>
<br>大创结项
<br>准备秋招，正好当复习专业课
<br><br>
<br>如果秋招进了我还算满意的单位，考研报南大
<br>如果秋招没进，考研报东南，浙大
<br>主要准备考研，带一下行测
<br><a data-href="体制内" href="\plan\体制内.html" class="internal-link" target="_self" rel="noopener nofollow">体制内</a>国考
<br><br>
<br><a data-href="体制内" href="\plan\体制内.html" class="internal-link" target="_self" rel="noopener nofollow">体制内</a>省考
<br>选调
]]></description><link>plan\长期plan.html</link><guid isPermaLink="false">Plan/长期Plan.md</guid><pubDate>Sun, 12 Jan 2025 02:02:42 GMT</pubDate></item><item><title><![CDATA[正在做的事]]></title><description><![CDATA[<a class="tag" href="?query=tag:plan" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#plan</a> 
 <br><a href=".?query=tag:plan" class="tag" target="_blank" rel="noopener nofollow">#plan</a><br><br>
<br>2024高教杯
<br><a data-tooltip-position="top" aria-label="https://www.notion.so/NNU-1357b571b9e8807f9856fd9c67c5c87c" rel="noopener nofollow" class="external-link" href="https://www.notion.so/NNU-1357b571b9e8807f9856fd9c67c5c87c" target="_blank">NNU-天翼云息壤杯</a>
<br><a data-tooltip-position="top" aria-label="https://www.notion.so/shiziyan/NNU-Software-2025iGEM-c6f3f88ecad44ce589a980b653bfab9e" rel="noopener nofollow" class="external-link" href="https://www.notion.so/shiziyan/NNU-Software-2025iGEM-c6f3f88ecad44ce589a980b653bfab9e" target="_blank">NNU-Software 2025iGEM</a>
<br><br><br>
<br>两台主机配置 cuda及pytorch环境
<br>读论文熟悉基本流程
<br>Compact-SER代码跑通自己的数据集 9-25
<br>增加每个类别的ACC再跑一次
<br> EfficientNetB0调通
<br>LFCC_MFCC_delta_over-sample
<br>EfficientNetB0模型训练
<br>MFCC和LFCC转成12个系数和1个帧强度，增加一阶差分和二阶差分
<br>看论文，深度学习提取特征
<br>代码跑通，解决librosa库的mfcc返回值问题
<br>解决nx库node问题
<br>得到实验室参数，更改mfcc采样率等参数重新跑一遍看效果
<br>我改回了原本的参数，但是数据预处理结果还是不对
<br>预处理结果不对是因为采样率变了
<br>更改参数后准确率反而下降了，找到代码问题，为什么准确率下降，对比代码
<br>可能是全局归一化的问题
<br>解决全局归一化问题，但是参数改变对准确率提升有限
<br>解决自选优化器问题，优化器改变影响不大
<br>继续深挖local peak-local peak ，如果还是不好，换成均匀分布采样。local peak效果不好
<br>帧选择的问题
<br>这个方向走一下，即通过将音频直接切成长段放入预训练模型得到特征再放入GNN。使用hubert成功<img alt="{A0769007-7792-456D-88E7-DFBE4C6A9856}.png" src="\lib\media\{a0769007-7792-456d-88e7-dfbe4c6a9856}.png">
<br>MFCC特征跑CNN的实验
<br>EfficientNet跑出结果
<br><br>
<br>深入学习GNN
<br>读GCN博士论文
<br>十二月份前要出初稿，我感觉对于原本的GNN可以去改变，不提CNN，改变图构造方式。
<br>重新搭建GNN并跑通，使用了Kipf-Welling的方法，效果不好
<br>彻底将论文里的GCN模型搞明白，并应用到自己的代码上
<br>开始整理论文数据和主要实验，想一个故事思路，着手写论文
<br><br>
<br>写完论文introduction
<br>写完论文method
<br>跑percent of train data
<br>analysis model
<br>整理数据
<br>写完论文experiment
<br>论文整体润色
<br>汇报PPT
<br>代码整理、
<br><br>
<br>12-04找老师讨论下一步方向
<br>修改论文缩写问题
<br>消融实验
<br>基于不同样本数展示
<br>少样本数据增强
<br>多通道
<br>修改模型要与原论文有明显区别，多通道
<br>增加抗噪性能实验
<br>1-16 IJCNN
<br><br>目标刊物SMC<br><br>详情见<a data-href="Technology/CollegeProject/计算机系统基础/PA/PA" href="\technology\collegeproject\计算机系统基础\pa\pa.html" class="internal-link" target="_self" rel="noopener nofollow">Technology/CollegeProject/计算机系统基础/PA/PA</a><br>
<br>pa0
<br>pa1

<br>RTFSC
<br>自制简易debug工具


<br>pa2
<br>pa3
<br>pa4
<br><br>
<br>小说课
<br>当我谈跑步时，我谈些什么
<br>兄弟
<br>我的二本学生
<br>冰与火之歌
<br>机器学习
<br>中国教育史
<br>雕刻时光
<br>沙丘
<br>菊与刀
<br>寻羊冒险记
<br>刘擎西方现代思想讲义
<br>毛泽东选集
<br>1984
<br>直视骄阳
]]></description><link>plan\正在做的事.html</link><guid isPermaLink="false">Plan/正在做的事.md</guid><pubDate>Sun, 12 Jan 2025 02:41:45 GMT</pubDate><enclosure url="lib\media\{a0769007-7792-456d-88e7-dfbe4c6a9856}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{a0769007-7792-456d-88e7-dfbe4c6a9856}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[准备数据集方式]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具/MMaction2" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/MMaction2</a> 
 <br><a href=".?query=tag:科技\工具\MMaction2" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/MMaction2</a><br>
快速上手<a data-tooltip-position="top" aria-label="https://mmaction2.readthedocs.io/zh-cn/latest/get_started/quick_run.html#id6" rel="noopener nofollow" class="external-link" href="https://mmaction2.readthedocs.io/zh-cn/latest/get_started/quick_run.html#id6" target="_blank">快速运行 — MMAction2 1.2.0 文档</a><br><br>由于视频数据集格式的多样性不利于数据集的切换，MMAction2 提出了统一的<a data-tooltip-position="top" aria-label="https://mmaction2.readthedocs.io/zh-cn/latest/user_guides/prepare_dataset.html" rel="noopener nofollow" class="external-link" href="https://mmaction2.readthedocs.io/zh-cn/latest/user_guides/prepare_dataset.html" target="_blank">数据格式</a>&nbsp;，并为常用的视频数据集提供了<a data-tooltip-position="top" aria-label="https://mmaction2.readthedocs.io/zh-cn/latest/get_started/quick_run.html#../user_guides/data_prepare/dataset_prepare.md" rel="noopener nofollow" class="external-link" href="https://mmaction2.readthedocs.io/zh-cn/latest/get_started/quick_run.html#../user_guides/data_prepare/dataset_prepare.md" target="_blank">数据集准备指南</a>。通常，要在 MMAction2 中使用这些数据集，你只需要按照步骤进行准备。<br>首先，请下载我们预先准备好的&nbsp;<a data-tooltip-position="top" aria-label="https://download.openmmlab.com/mmaction/kinetics400_tiny.zip" rel="noopener nofollow" class="external-link" href="https://download.openmmlab.com/mmaction/kinetics400_tiny.zip" target="_blank">kinetics400_tiny.zip</a>&nbsp;，并将其解压到 MMAction2 根目录下的&nbsp;data/&nbsp;目录。这将为您提供必要的视频和注释文件。<br>wget https://download.openmmlab.com/mmaction/kinetics400_tiny.zip
mkdir -p data/
unzip kinetics400_tiny.zip -d data/
<br><br>准备好数据集之后，下一步是修改配置文件，以指定训练集和训练参数的位置。<br>在本例中，我们将使用 resnet50 作为主干网络来训练 TSN。由于 MMAction2 已经有了完整的 Kinetics400 数据集的配置文件 (configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py)，我们只需要在其基础上进行一些修改。<br><br>我们首先需要修改数据集的路径。打开&nbsp;configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py&nbsp;，按如下替换关键字:<br>data_root = 'data/kinetics400_tiny/train'
data_root_val = 'data/kinetics400_tiny/val'
ann_file_train = 'data/kinetics400_tiny/kinetics_tiny_train_video.txt'
ann_file_val = 'data/kinetics400_tiny/kinetics_tiny_val_video.txt'
<br><br>此外，由于数据集的大小减少，我们建议将训练批大小减少到4个，训练epoch的数量相应减少到10个。此外，我们建议将验证和权值存储间隔缩短为1轮，并修改学习率衰减策略。修改&nbsp;configs/recognition/tsn/tsn_imagenet-pretrained-r50_8xb32-1x1x3-100e_kinetics400-rgb.py&nbsp;中对应的关键字，如下所示生效。<br># 设置训练批大小为 4
train_dataloader['batch_size'] = 4

# 每轮都保存权重，并且只保留最新的权重
default_hooks = dict(
    checkpoint=dict(type='CheckpointHook', interval=1, max_keep_ckpts=1))
# 将最大 epoch 数设置为 10，并每 1 个 epoch验证模型
train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=10, val_interval=1)
#根据 10 个 epoch调整学习率调度
param_scheduler = [
    dict(
        type='MultiStepLR',
        begin=0,
        end=10,
        by_epoch=True,
        milestones=[4, 8],
        gamma=0.1)
]# 设置训练批大小为 4
train_dataloader['batch_size'] = 4

# 每轮都保存权重，并且只保留最新的权重
default_hooks = dict(
    checkpoint=dict(type='CheckpointHook', interval=1, max_keep_ckpts=1))
# 将最大 epoch 数设置为 10，并每 1 个 epoch验证模型
train_cfg = dict(type='EpochBasedTrainLoop', max_epochs=10, val_interval=1)
#根据 10 个 epoch调整学习率调度
param_scheduler = [
    dict(
        type='MultiStepLR',
        begin=0,
        end=10,
        by_epoch=True,
        milestones=[4, 8],
        gamma=0.1)
]
]]></description><link>project\大创\mmaction2\mmaction2基本操作.html</link><guid isPermaLink="false">Project/大创/MMaction2/MMaction2基本操作.md</guid><pubDate>Sun, 24 Dec 2023 01:58:26 GMT</pubDate></item><item><title><![CDATA[大创初审稿子]]></title><description><![CDATA[ 
 <br><br>各位老师，各位同学大家好。我们的项目是面向多模态数据的中学化学实验智能评价系统。<br><br>《教育部关于加强和改进中小学实验教学的意见》明确指出：要开齐开足开好国家课 程标准规定实验，切实扭转忽视实验教学的倾向，不断将科技前沿知识和最新技术成果融 入实验教学。在当下这个生成式AI快速发展的时代，对于中小学教育，填鸭式的课内知识教育会越来越式微，动手能力、实验探索素质在接下来的时代会被更多的强调。那么一套在学生初学实验阶段时的智能评价系统便显得尤为重要了，它会在学生早期帮助学生建立良好的动手能力和实验素养。为国家培养真正的科技人才打下良好基础。<br><br><br>现有的相关研究中，通过提取视频的全局特征进行行为分析。这会导致特征性不足。<br>
（1）多视角：为了防止实验过程中的遮挡等因素，通常采用多路摄像头从不同角度记录学生的操作过程。如图 1所示，每套实验设备包含正视、俯视和侧视三个角度的摄像头，实验视频理解需要探索如何利用多视角多实验全面评价。<br>
（2）关注实验步骤序列：通常实验步骤在逻辑上有着一定的先后顺序，实验视频理解不仅需要理解现在在做什么，还要考虑步骤顺序的合理性。<br>
（3）背景相似动作差异小：实验都是在同一背景下完成，动作之间的差异非常小。如将集气瓶放入水里收集氧气和最后清理台面清洗集气瓶动作几乎完全一致。<br>
（4）不同环节需求差异大：视频理解通常采用一种模型解决问题，而实验视频理解需要根据场景选择不同的模型。在实验教学阶段，需要对学生的操作及时地反馈和交互，强调对步骤理解和结果分析的实时性，采用轻量化模型；在实验考试阶段，需要精确判断步骤的区间和实验结果，强调实验判分的准确性，采用大模型；在老师批阅视频阶段，可能需要分析某个子动作是否正确，这时就考虑要定制化的根据文本检索视频，采用多模态模型。<br>并且，过往的相关研究只着重于视频特征的提取，而忽略了实验人员手部特征的信息，以及文本标注信息。过往的文本标注信息只被作为类别划分标签，而没有利用其中的语义信息。这导致其准确率有限。<br><br>而我们将会从视频特征，手势特征，文本特征三个方面获取更多信息，以达到提高准确率的效果。<br>
对于具体的技术细节，这是我们的研究路线规划图。<br>
分别使用这三种模型。<br><br>MediaPipe 是一款由 Google Research 开发并开源的多媒体机器学习模型应用框架。在谷歌，一系列重要产品，如 、Google Lens、ARCore、Google Home 以及 ，都已深度整合了 MediaPipe。<br>VideoMae，首个提出了基于ViT的掩码和重建的视频自监督预训练框架VideoMAE。即使在较小规模的视频数据集上进行自监督预训练，VideoMAE仍能取得非常优异的表现。 <br>Bert：谷歌AI团队新发布的BERT模型，在机器阅读理解顶级水平测试SQuAD1.1中表现出惊人的成绩：全部两个衡量指标上全面超越人类，并且还在11种不同NLP测试中创出最佳成绩，包括将GLUE基准推至80.4％（绝对改进7.6％），MultiNLI准确度达到86.7% （绝对改进率5.6％）等。可以预见的是，BERT将为NLP带来里程碑式的改变，也是NLP领域近期最重要的进展。<br><br>
<br>目前我们已经初步建成可用的实验评价系统。已经申请软著。
<br>对于多模态的探索，我们已经对于手势和视频特征进行了提取。
<br>deepsort目标跟踪
<br><br>第一阶段（2023 年 12 月-2024 年 1 月）<br>
多模态特征提取<br>
（1）视频特征提取：利用 GateHUB 完成在线动作检测任务，得到到行为的类别以及在视频 中发生的开始帧和结束帧。<br>
（2）文本特征提取：运用预训练的 BERT 模型提取视频文本特征。<br>
（3）手关节特征提取：利用 Mediapipe 库对数据库中的视频分帧进行手势骨架提取和关键 点标注，得到手指关节的 3D 特征。 <br>第二阶段（2024 年 2 月-2024 年 6 月）<br>
跨模态表征融合： 基于双线性池化的融合办法，融合视觉特征向量和文本特征向量来获得一个联合表征 空间，对权值张量进行分解，不断训练和测试相关的模型。 <br>第三阶段（2024 年 7 月-2024 年 10 月）<br>
（1）优化行为识别模型：为了能够更加准确细致的识别实验操作，在原本利用 colar 进行 在线动作检测单一模态的基础上，将文本、视频、手部关节特征融合之后建立行为检测模 型，重新标注和训练数据，并逐步改善该模型。<br>
（2）优化目标检测模型：在已有的特征模型基础上，基于细粒度的动态路由机制来增强单 个目标的特征表达能力，之后逐渐改善模型，直至达到相应的标准。<br>
第四阶段（2024 年 11 月-2025 年 4 月）<br>
（1）对原有实验教学评价系统进行改进，通过行为识别检测实验步骤，通过目标检测判断 操作是否正确，从而增强考试评分的可解释性，完成项目软件的多模态检索功能的开发。<br>
（2） 将项目成果进行封装，总结项目所做的工作，总结项目的收获，撰写结项 书并提交。]]></description><link>project\大创\大创初审稿子.html</link><guid isPermaLink="false">Project/大创/大创初审稿子.md</guid><pubDate>Tue, 16 Apr 2024 11:39:15 GMT</pubDate></item><item><title><![CDATA[研究背景]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/大创" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大创</a> 
 <br><a href=".?query=tag:项目\个人项目\大创" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大创</a><br><br>一个是文本信息没有完全发掘。二是视频细粒度。<br><br>是个系统，可以使用多模态数据，可以准确评价实验操作过程。速度上，性能上，数据上的目标。<br><br>
<br>三个模态获取
<br>融合
<br>行为实时识别，评价
<br>系统分析与实现
<br><br>讲多模态<br>
南京师范大学<br><a data-href="南京师范大学大学生创新创业训练计划项目申报表 .pdf" href="\附件\南京师范大学大学生创新创业训练计划项目申报表-.pdf" class="internal-link" target="_self" rel="noopener nofollow">南京师范大学大学生创新创业训练计划项目申报表 .pdf</a>]]></description><link>project\大创\大创申报书.html</link><guid isPermaLink="false">Project/大创/大创申报书.md</guid><pubDate>Thu, 21 Mar 2024 03:00:02 GMT</pubDate></item><item><title><![CDATA[大创中期答辩]]></title><description><![CDATA[ 
 <br><br>
<br>成果（要证明我们已经做了很多事了）
<br>
<br>手势识别（图片）
<br>deepsort（准确度提高）
<br>VideoMae 视频特征提取
<br>文本特征失败，因为做的是实时监测，测试视频中没有文本特征。
<br>正在申请手势软著
<br>参与了xx专利（待定）
<br>
<br>未来（我们接下来要做的事情）
<br>
<br>手势视频多模态融合
<br>
<br>目前
<br>
<br>我们正在做调研（手势特征提取方法、手势特征与视频特征的对齐融合）
<br><br>关于利用图卷积网络（GCN）进行手势识别的研究，近年来已有一些论文探索了如何将手势数据转化为图结构，并通过图卷积进行有效的分类。以下是一些相关的研究方向和论文：<br><br>
<br>论文: "Graph Convolutional Networks for Hand Gesture Recognition"
<br>概述: 本文提出了利用图卷积网络（GCN）来进行手势识别的方法。手势图由手指关节的位置和连接关系构成，图卷积网络用于从这些结构化的图中学习特征，进而进行手势识别。
<br>方法: 手势数据通常由多个关节或关键点的空间坐标表示，利用这些关节之间的空间关系构建图结构。图卷积网络对这些图结构进行处理，挖掘图中的空间信息和局部模式，从而提升手势识别的准确性。
<br>引用: <a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2007.06932" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2007.06932" target="_blank">Paper link</a>
<br><br>
<br>论文: "Hand Gesture Recognition with Graph Convolutional Networks"
<br>概述: 本文提出了一种基于GCN的手势识别方法，重点是通过利用手部骨骼图来构建手势图，GCN则用于学习关节之间的空间关系和运动模式。
<br>方法: 作者通过构建手部骨骼图，其中每个节点代表手部的一个关节，边则表示关节之间的连接。GCN模型用于捕捉关节之间的依赖关系，并进行多类手势的分类。
<br>引用: <a data-tooltip-position="top" aria-label="https://ieeexplore.ieee.org/document/9097119" rel="noopener nofollow" class="external-link" href="https://ieeexplore.ieee.org/document/9097119" target="_blank">Paper link</a>
<br><br>
<br>论文: "Learning Hand Pose Estimation and Gesture Recognition with Graph Convolutional Networks"
<br>概述: 本研究结合了手势识别和手势姿态估计，提出了一种基于图卷积网络的联合学习方法，通过图卷积网络来同时进行手势分类和姿态估计。
<br>方法: 构建一个动态图模型，其中图中的每个节点代表手的一个关节，每条边则表示关节之间的依赖关系。通过GCN提取图中空间关系来进行更精确的手势识别。
<br>引用: <a data-tooltip-position="top" aria-label="https://arxiv.org/abs/2007.12131" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/2007.12131" target="_blank">Paper link</a>
<br><br>
<br>论文: "3D Hand Gesture Recognition Using Graph Convolutional Networks"
<br>概述: 本文提出了一种3D手势识别方法，利用3D空间中的关节坐标通过GCN进行分类，重点解决了传统方法无法有效处理3D空间信息的问题。
<br>方法: 通过使用3D深度摄像头捕捉手部关节数据，并构建3D图模型，使用GCN来学习手势的空间模式，并进行分类。
<br>引用: <a data-tooltip-position="top" aria-label="https://ieeexplore.ieee.org/document/9282690" rel="noopener nofollow" class="external-link" href="https://ieeexplore.ieee.org/document/9282690" target="_blank">Paper link</a>
<br><br>
<br>论文: "Dynamic Graph CNN for Gesture Recognition"
<br>概述: 这篇论文提出了一种动态图卷积网络（DGCNN）的方法，该方法结合了动态图和卷积神经网络来处理动态手势序列。
<br>方法: 该方法动态构建手势的图结构，图中的节点代表手部关节，边表示关节之间的关系。动态图卷积网络能捕捉到手势序列的时空信息，从而提升识别精度。
<br>引用: <a data-tooltip-position="top" aria-label="https://arxiv.org/abs/1812.01847" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1812.01847" target="_blank">Paper link</a>
<br><br>
<br>论文: "Graph Neural Networks for Hand Gesture Recognition in Video"
<br>概述: 本文探索了如何利用图神经网络（GNN）进行视频中的手势识别，通过在视频帧中提取手势的图结构，利用GNN进行时序信息的学习。
<br>方法: 视频中的手势每一帧被表示为一个图结构，通过时序图卷积网络（T-GCN）来捕捉时序和空间上的信息，进行手势的动态识别。
<br>引用: <a data-tooltip-position="top" aria-label="https://arxiv.org/abs/1905.01948" rel="noopener nofollow" class="external-link" href="https://arxiv.org/abs/1905.01948" target="_blank">Paper link</a>
<br><br>这些论文展示了如何将手势数据转化为图结构，并利用图卷积网络（GCN）来进行手势识别。GCN能够有效地捕捉手势数据中的空间和时序关系，从而提升识别精度。可以根据我们的数据类型（如2D关节坐标、3D关节坐标或视频序列）选择合适的方法。<br><br>本项目旨在通过多模态特征提取与融合、行为识别、目标检测等技术，构建一个高效的实验评价系统，特别是在化学实验过程中的动作监测和评估。项目的实施内容涵盖了视频特征提取、手部关节特征提取、多模态特征融合、行为识别与目标检测等多个方面，每个环节都涉及到最新的人工智能技术，特别是深度学习和计算机视觉领域的先进方法。<br><br>本项目的核心研究内容主要包括以下几个部分：<br>
<br>多模态特征提取：通过提取视频、手势等多种类型的数据特征，为后续的行为识别和目标检测提供有力支持。
<br>多模态特征融合：将来自不同模态的数据特征进行融合，提升识别准确性和鲁棒性。
<br>行为识别：基于提取的特征，对实验过程中学生的行为进行实时识别与评估。
<br>目标检测：实时检测实验过程中的关键物体或设备，确保实验的顺利进行。
<br>评价系统建立：基于行为识别与目标检测结果，构建一个系统性的实验评价模型，自动评估学生实验操作的质量和准确性。
<br><br>本项目的实施过程中，我们为每个阶段设定了明确的时间目标，并进行了灵活调整。最终时间安排如下：<br>
<br>
初期准备阶段（1-2个月）：

<br>在该阶段，我们主要进行了文献调研，了解相关领域的最新进展，选择合适的模型和算法。
<br>进行模型的初步选择与环境搭建。


<br>
中期开发阶段（3-5个月）：

<br>开始多模态特征提取和行为识别模块的开发，重点完成视频特征提取与手部关节特征提取的实验。
<br>完成MediaPipe Hands模型的集成，实现对手部关节的实时检测。
<br>进行多模态数据的融合实验，评估不同特征融合方法的效果。


<br>
后期优化阶段（6-8个月）：

<br>对模型进行进一步优化，提升识别精度和实时性。
<br>开始目标检测模块的开发，确保能够准确检测实验过程中的关键物体。
<br>建立实验评价系统，基于多模态特征进行学生实验过程的全面评估。
<br>完成系统的整体集成和测试工作，确保系统的稳定性与准确性。


<br>
最终测试与报告阶段（9-10个月）：

<br>完成整个系统的最终调试与测试。
<br>撰写项目总结报告与论文，准备进行学术汇报与项目展示。


<br><br>在项目实施过程中，我们与指导老师陈燚教授保持了定期的沟通与反馈。具体交流内容包括：<br>
<br>模型选择与优化：在选择合适的模型时，我们就多模态特征提取方法、行为识别模型等方面与指导老师进行了深入讨论。老师针对视频特征提取和手部关节检测的技术路线提出了宝贵的意见，帮助我们做出更为合理的决策。
<br>实验设计与数据分析：每次实验后，我们都会向老师汇报结果，及时获得反馈。通过与老师的讨论，我们能够调整实验策略，更加有效地推进项目。
<br>问题解决与技术支持：在遇到技术难题时，指导老师为我们提供了很多有价值的建议，尤其是在多模态特征融合和目标检测的实现过程中。老师的指导帮助我们迅速定位问题并提出优化方案。
<br>通过与指导老师的持续交流，我们能够及时纠正项目中的偏差，并根据反馈不断优化项目方案，确保项目按计划顺利推进。<br><br>在项目实施过程中，我们遇到了一些技术难题和挑战，主要包括：<br>
<br>
模型的实时性问题：

<br>在进行视频特征提取时，尽管VIdeoMae模型能够提供较高的准确性，但其实时性仍然存在一定的瓶颈。在处理长时间的视频流时，模型的响应时间可能会影响到系统的实时反馈能力。为了提高实时性，我们尝试了不同的优化方法，如使用更高效的特征提取模块、降低图像分辨率等，但这些方法仍然存在一定的效果局限。


<br>
手部关键点检测的准确性问题：

<br>MediaPipe Hands模型在大多数场景下表现优秀，但在某些特殊情况下（如手部遮挡、低光照环境或者手套颜色与背景颜色相似），模型的准确性可能受到影响。我们尝试通过数据增强和更精细的模型调整来应对这些问题，但仍然面临一定的挑战。


<br>
多模态数据的融合问题：

<br>多模态特征融合是提高模型精度的关键，但由于不同模态之间的数据类型和结构差异较大，如何有效融合这些数据一直是一个难题。我们尝试了多种融合方法（如加权融合、拼接融合等），但依然需要进一步优化融合策略，以达到最佳效果。


<br>
目标检测的准确性问题：

<br>尽管目标检测模型在静态场景下能够取得较好的效果，但在实验过程中，尤其是在设备快速移动或背景复杂的情况下，模型的识别准确性有所下降。我们正计划通过改进训练数据的质量和多样性来提升目标检测的稳定性。


<br>
系统的稳定性问题：

<br>在系统集成过程中，多个模块的兼容性和稳定性问题逐渐显现。例如，视频流处理与手部特征提取之间的协调性，以及行为识别与目标检测模块的联动等问题都需要在后期不断调试和优化。


<br>尽管面临这些问题，我们通过调整实验方案和模型优化策略，逐步克服了部分技术难关。未来，我们计划继续优化各个环节的技术，确保系统在实际应用中的稳定性和高效性。<br><br>总体而言，本项目在多模态特征提取、行为识别、目标检测和实验评价系统的构建等方面取得了一定的进展。虽然在实现过程中遇到了一些技术瓶颈和挑战，但通过与指导老师的积极沟通与合作，我们不断调整和优化了方案，推动了项目的顺利进行。未来，我们将继续优化模型的准确性和实时性，进一步提高系统的稳定性，力争在最终测试中取得更好的结果。]]></description><link>project\大创\大创中期答辩.html</link><guid isPermaLink="false">Project/大创/大创中期答辩.md</guid><pubDate>Thu, 19 Dec 2024 01:39:17 GMT</pubDate></item><item><title><![CDATA[大创主要任务]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/大创" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大创</a> 
 <br><a href=".?query=tag:项目\个人项目\大创" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大创</a><br>
主线任务：完成对制取二氧化碳化学实验的智能评分系统。<br>
主要要求：可解释性<br>
子任务：视频特征提取-&gt;行为识别-&gt;评分<br>我们的任务：在原有demo上对于行为识别和视频特征提取进行改进。<br>
<br>视频特征提取目前改进方法是使用效果更好的提取算法。
<br>行为识别希望使用多模态方法，主要有以下三个模态：

<br>基于<a data-href="MMaction2基本操作" href="\project\大创\mmaction2\mmaction2基本操作.html" class="internal-link" target="_self" rel="noopener nofollow">MMaction2基本操作</a>的提取的手部特征信息
<br>视频特征信息
<br>文本特征信息


]]></description><link>project\大创\大创主要任务.html</link><guid isPermaLink="false">Project/大创/大创主要任务.md</guid><pubDate>Thu, 21 Dec 2023 10:03:37 GMT</pubDate></item><item><title><![CDATA[个人介绍]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/大创" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大创</a> 
 <br><a href=".?query=tag:项目\个人项目\大创" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大创</a><br>
李世博<br>
组织能力：大一担任学生会志愿者协会干事，认真负责，一丝不苟，有钻研精神。<br>
学科能力：目前已具备C、C++编程能力。目前的专业基础课及专业主干课不低于90，大一综测成绩前十，两次获得优秀学生奖学金三等奖。荣获蓝桥杯及校级院级编程比赛多个奖项。<br>
科研经历：目前正在写多模态检索相关论文，阅读论文多篇，目前正在复现关键论文。]]></description><link>project\大创\个人介绍.html</link><guid isPermaLink="false">Project/大创/个人介绍.md</guid><pubDate>Sun, 17 Dec 2023 07:02:48 GMT</pubDate></item><item><title><![CDATA[Text Elements]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/大创" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大创</a> 
 <br>⚠  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠<br><br>搜集实验数据 <br>数据标注 <br>数据集获取 <br>视频特征提取 <br>标注文本特征提取 <br>特征提取 <br>行为识别 <br> 评分系统 <br>手关节特征提取 <br>目标检测 <br>细粒度检测 <br>表征融合 <br>实验示范数据库建立 <br>考试评分 <br>错误纠正 <br>多模态检索 <br>推送正确示范 <br>实验操作评分 <br><a href=".?query=tag:项目\个人项目\大创" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大创</a> <br>特征提取 <br>视频数据 <br>文本数据 <br>手关节数据 <br>多模态表征融合 <br>行为识别 <br>目标检测 <br>评价系统 <br>实验操作实时评分 <br>]]></description><link>project\大创\路线.html</link><guid isPermaLink="false">Project/大创/路线.md</guid><pubDate>Wed, 10 Apr 2024 01:25:48 GMT</pubDate></item><item><title><![CDATA[Text Elements]]></title><description><![CDATA[ 
 <br>⚠  Switch to EXCALIDRAW VIEW in the MORE OPTIONS menu of this document. ⚠<br><br>实验视频<br>
数据集 <br>文本特征 <br>手关节特征 <br>视频特征 <br>Bert <br>MediaPipe <br>VideoMae <br>Concat <br>Model Attention <br>MLP <br>MLP <br>MLP <br>Concat <br>MLP <br>二级类目 <br>三级类目 <br>Mask <br>HMC <br>]]></description><link>project\大创\研究内容.html</link><guid isPermaLink="false">Project/大创/研究内容.md</guid><pubDate>Wed, 10 Apr 2024 01:27:54 GMT</pubDate></item><item><title><![CDATA[原则1:模态是异质的]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/大二论文/论文" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大二论文/论文</a> 
 <br><a href=".?query=tag:项目\个人项目\大二论文\论文" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大二论文/论文</a><br><br>异质性原则反映了这样一种观察，即以不同模式呈现的信息通常会表现出不同的质量、结构和表征。两种不同的语言捕捉到相同的意思但根据语族不同而有所不同，这两种语言略有异质，语言和视觉甚至更加异质。每个多模态问题都可能涉及多个维度的异质性。<br><br>每种模态通常由一组元素组成，这些元素是最基本的数据单元，不能(或者更确切地说，用户选择不)分解为进一步的单元[26,147]。例如，输入的文本通过一组字符来记录，视频通过一组帧来记录，图形通过一组节点和边来记录。每种情态中呈现的基本元素是什么，我们又该如何表示它们呢?形式上，这个维度衡量的是在模态元素的样本空间或表示空间中的异质性。<br><br>分布是指模态中元素的频率和相似度。元素通常遵循一个独特的分布，语言语料库中的单词遵循齐夫定律就是一个经典的例子。分布异质性则是指不同模态元素在频率分布的可能性上的差异，比如记录信号中的不同频率和元素的密度。<br><br>自然数据以单个元素组成整体模态[38]的方式表现出结构。例如，图像表现出跨越单个对象元素的空间结构，语言是由单个单词分层组成的，信号表现出跨越时间的时间结构。结构异质性是指这种底层结构的差异。<br><br>度量每个模态中存在的总信息含量。随后，信息异质性测量了不同模态之间信息内容的差异，这可以通过信息理论度量来正式测量[227]。<br><br>噪声可以在自然发生的数据和数据记录过程中的几个级别上引入。自然数据噪声包括闭塞、人为生成数据的不完美(例如，不完美的键盘输入或不清晰的语音)，或由于传感器故障导致的数据模糊[151]。噪声异质性衡量的是不同模态中噪声分布的差异，以及信噪比的差异。<br><br>每种模态对特定任务和上下文表现出不同的相关性——某些模态可能比其他模态对某些任务更有用[78]。任务相关性描述了如何使用模态进行推理，而上下文相关性描述了模态如何与其他模态进行语境化。<br><br>虽然模态是异质的，但由于共享的互补信息，它们通常是连接的。共享信息的存在往往与仅存在于单一模态中的独特信息形成对比[290]。模态连接描述了信息可以跨模态共享的程度和维度。在推理多模态数据中的连接时，同时考虑自底向上(统计)和自顶向下(语义)方法是有帮助的(见图3)。从统计数据驱动的角度来看，连接是从多模态数据中的分布模式中识别出来的，而语义方法根据我们关于模态如何共享和包含唯一信息的领域知识来定义连接。<br>(1)当一个变量的值与另一个变量的值相关时，就存在统计关联。例如，两个元素可能会共同出现，从而导致两者同时出现的频率更高。从统计学上讲，这可能导致相关性——元素线性相关的程度，或其他非线性关联。从数据驱动的角度来看，发现哪些元素彼此关联对于在多模态表示和对齐期间建模跨模态的联合分布非常重要[257]。<br>(2)统计依赖比关联更深入，需要理解两个元素之间统计依赖的确切类型。例如，是否存在从一个元素到另一个元素的因果依赖关系，或者是否存在导致两个元素同时存在的潜在混杂因素?其他形式的依赖关系可能是空间的或时间的:一个元素出现在另一个元素之上，或者在另一个元素之后。通常，虽然统计关联可以纯粹从数据中估计，但理解统计依赖的本质需要对元素及其潜在关系有一定的了解[188,267]。<br>(3)语义对应可以被看作是确定一个模态中的哪些元素与另一个模态中的元素具有相同语义的问题[192]。识别对应关系是与语言基础[46]、翻译和检索[203]以及跨模态对齐[248]相关的许多问题的基础。<br>(4)语义关系:语义关系概括了语义对应:与共享相同确切含义的模态元素不同，语义关系包括描述两个模态元素之间关系的确切性质的属性，例如语义、逻辑关系、因果关系或功能关系。识别这些语义相关的连接对于高阶推理非常重要。<br><br>模态相互作用研究模态元素在集成在一起进行任务推理时如何相互作用以产生新信息。我们注意到模态连接和交互之间的一个重要区别:连接存在于多模态数据本身中，而交互只有在模态被整合和处理在一起以产生新的响应时才会出现。在图4中，我们提供了可以存在的交互的一些维度的高级说明。<br>(1)相互作用信息调查相互作用中涉及的连接信息的类型。当交互涉及两种模式共有的共享信息时，交互是冗余的，而非冗余的交互则不完全依赖于共享信息，而是依赖于不同比例的共享信息、唯一信息，甚至可能是协同信息[290]。<br>(2)交互机制是集成模态元素进行任务推理时所涉及的功能算子。例如，交互可以表示为统计上的加性、非加性和非线性形式[117]，也可以从语义的角度来看，两个元素通过逻辑、因果或时间操作进行交互[268]。<br>(3)交互响应研究的是在多种模态存在下，推断的响应是如何变化的。例如，通过细分冗余交互作用，我们可以说，如果多模态响应与任一模态的响应相同，则两个模态会产生等效响应，如果多模态响应显示出更高的置信度，则会产生增强响应。另一方面，当存在不同的多模态响应和单模态响应时，调制或涌现等非冗余相互作用就会发生[197]。<br><br>这个挑战可以被看作是学习元素之间的“局部”表示，或者是使用整体特征的表示。本节涵盖<br>(1)表征融合:整合来自2个或更多模态的信息，有效减少单独表征的数量;<br>(2)表征协调:交换跨模态信息，目标是保持相同数量的表征，改善多模态语境化;<br>(3)表征裂变:创建新的解耦表示集，通常比输入集的数量更大，反映有关内部结构的知识，如数据聚类或因数分解<br><br>表征融合旨在学习一种联合表征，对不同模态的单个元素之间的跨模态交互进行建模，有效减少分离的数量。<br>我们将这些方法分为与抽象模态的融合和与原始模态的融合(图6)。在与抽象模态的融合中，首先应用合适的单模态编码器来捕获每个元素(或整个模态)的整体表示，然后使用几个用于表示融合的构建块来学习联合表示。因此，融合发生在抽象表示层面。另一方面，与原始模态的融合需要在非常早期的阶段进行表征融合，预处理最少，甚至可能涉及原始模态本身。<br><br>我们开始处理抽象表征与加法和乘法相互作用的表征融合。这些运算符可以被看作是可微的构建块，结合了来自两个数据流的信息，可以灵活地插入到几乎任何单模态机器学习过程中。给定单模态数据或特征x1 和 x2，加性融合可以看作是学习一个新的联合表示zmm =𝑤0+𝑤1x1+𝑤2x2+𝜖，其中𝑤1和𝑤2是以w0为偏置项和𝜖为误差项的x1和x2加性融合学习到的权重。如果直接将联合表示zmm作为预测结果y尖帽，则可加性融合类似于具有单模态预测符𝑓1 and 𝑓2后期或集合融合的𝑦 = 𝑓1 (x1) + 𝑓2 (x2)。否则，加性表示z也可以经历随后的单模态或多模态处理[23]。Zmm 乘法相互作用扩展了加性相互作用，包括交叉项𝑤3(x1 ×x2)。这些模型在统计学中被广泛使用，可以解释为x1对 x2 和y之间的线性关系的调节效应。总的来说，纯加性相互作用zmm =𝑤0+𝑤1x1 +w2x2可以看作是输入模态x1 and x2之间的一阶多项式，结合加性和乘性zmm =𝑤0+𝑤1x1 +𝑤2x2 + 𝑤3(x1 ×x2)捕获二阶多项式。<br>为了进一步超越一阶和二阶相互作用，张量被专门设计为明确地捕捉跨模态的高阶相互作用。张量定义为zmm = x1 ⊗x2，其中⊗表示外积。因为它们的维度随着模态的数量呈指数级增长，因此已经提出了几种基于低秩分解的有效近似，<br>MI定义了一个双线性积zmm = x1Wx2 + xU⊤1 + Vx+2 b，其中W、U、z和b是可训练的参数。<br><br>需要在非常早期的阶段进行表示融合，甚至可能涉及原始模态本身。这些方法通常与早期融合[23]相似，[23]在应用预测模型(即zmm = [x1, x2])之前执行输入数据的连接。原始模态级别的融合更具挑战性，因为原始模态可能表现出更多维度的异质性。尽管如此，Barnum等人[77]证明了融合在早期阶段的稳健性优势，而Gadzicki等人[77]也发现，复杂的早期融合可以优于抽象融合。为了解释复杂早期融合过程中更大的异质性，许多方法依赖于适用于两种模式的通用编码器，如卷积层[24,77]和变压器[150,153]。然而，这些复杂的非加性融合模型真的学习了模态元素之间的非加性相互作用吗?根据Hessel和Lee[94]的研究，未必如此。我们在量化挑战(§8)中涵盖了这些基本分析问题和更多问题。<br><br>表征协调旨在学习多模态情境化表征，这些表征通过它们之间的相互联系进行协调(图7)。与表征融合相比，协调保持了相同数量的表征，但提高了多模态情境化。我们从强协调开始我们的讨论，强协调强制模态元素之间的强等效，然后再转向部分协调，后者捕获更一般的连接，如相关性、顺序、层次结构或相似性之外的关系。<br>1.强协调旨在将语义上对应的模态在协调空间中紧密地结合在一起，从而在模态元素之间实现强对等。例如，这些模型会鼓励单词“狗”和狗的图像的表示接近(即语义上的积极对)，而单词“狗”和汽车图像之间的距离远离(即语义上的消极对)[75]。协调距离通常是余弦距离[174,287]或最大边际损失[102]。最近的工作通过扩大图像和文本对的对比学习来探索大规模的表示协调[206]，并且还发现对比学习可以证明捕获跨两个视图的冗余信息[256,258]但不能捕获非冗余信息。除了对比学习之外，还有几种方法通过将相应的数据从一种模态映射到另一种模态来学习协调空间[69]。例如，Socher等人[236]将图像嵌入映射到单词嵌入空间中，用于零镜头图像分类。类似的想法被用于学习文本、视频和音频之间的协调表示[202]，以及预训练的语言模型和图像特征之间的协调表示[249]。<br>2.部分协调:部分协调不是通过强协调严格捕获等价，而是捕获更一般的模态连接，如相关性、顺序、层次或关系。为了实现这些目标，部分协调模型在语义相似性之外对表示空间施加了不同类型的约束，并且可能仅在表示的某些维度上。<br>典型相关分析(Canonical correlation analysis, CCA)计算一个线性投影，最大化两个随机变量之间的相关性，同时强制新表示中的每个维度彼此正交[254]。CCA模型已广泛用于跨模态检索[211]、视听信号分析[221]和情感识别[186]。为了提高CCA的表达性，已经提出了几种非线性扩展，包括内核CCA[134]，深度CCA[16]和CCA自动编码器[283]。<br>有序和层次空间:表示协调的另一个例子来自图像和语言的顺序嵌入[276]，其目的是捕获语言和图像嵌入的部分顺序，以在协调空间中强制执行层次结构。Young等人[306]也提出了一个使用外延图的类似模型，其中使用外延图来诱导这种偏序层次结构。<br>关系协调:为了学习一个超越对应关系的协调空间，Zhang等人[319]使用文本和图像的结构化表示来创建多模态概念分类法。Delaherche和Chetouani[61]学习捕获层次关系的协调表示，而Alviar等人[12]使用部分相关度量应用语音和音乐的多尺度协调。最后，Xu等人[298]使用柯西损失(Cauchy loss)学习协调表征，以增强对异常值的鲁棒性。<br><br>表征裂变旨在创建一个新的解耦的表示集(通常比输入表示集的数量更大)，反映有关内部多模态结构的知识，如数据聚类、独立的变异因素或特定于模态的信息。与联合表示和协调表示相比，表示裂变实现了细致的解释和细粒度的可控性。根据解耦因素的粒度，方法可以分为模态级和细粒度裂变(图8)。<br>模态级裂变的目的是将每种模态中的主要模态特定信息和两种模态中冗余的多模态信息分解为特定模态信息。<br>细粒度裂变:除了仅分解为单个模态表征之外，细粒度裂变试图进一步将多模态数据分解为模态覆盖的单个子空间[277]。基于语义相似性对数据进行分组的聚类方法[165]已与多模态网络集成，用于端到端表示裂变和预测。例如，Hu等人[102]将𝑘-means 表示中的聚类与无监督视听学习相结合。Chen等人[48]将𝑘-means 聚类与视频上的自监督对比学习相结合。子空间聚类[1]、近似图拉普拉斯算子[125]、共轭混合模型[124]和字典学习[126]也与多模态模型相结合。在表示裂变的类似目标的激励下，矩阵分解技术也在多模态预测[10]和图像检索[41]中得到了一些应用。<br><br>第二个挑战是识别多个模态元素之间的跨模态连接和相互作用。例如，在分析人类主体的语音和手势时，我们如何将特定手势与口语单词或话语结合起来?模态之间的对齐是具有挑战性的，因为它可能依赖于长期依赖关系，涉及模棱两可的分割(例如，单词或话语)，并且可能是一对一的，多对多的，或者根本不存在。本节涵盖了最近在多模态对齐方面的工作，涉及(1)离散对齐:识别跨模态的离散元素之间的连接，(2)连续对齐:在具有模糊分割的连续模态信号之间建模对齐，以及(3)情境化表示:通过捕获元素之间的跨模态交互来学习更好的多模态表示(图9)。<br><br>第一个子挑战旨在识别多个模态的离散元素之间的连接。我们描述了最近的工作(1)局部对齐，以发现给定模态元素匹配对之间的连接，以及(2)全局对齐，其中必须全局执行对齐以学习连接和匹配(图10)。<br><br>连接元素之间的局部对齐特别适用于多模态任务，这些任务需要明确分割成离散元素，如文本中的单词或图像或视频中的对象边界框(例如，视觉共参考分辨率[131]、视觉参考表达识别[58,59]和跨模态检索[75,203]等任务)。当我们以连接的模态对的形式拥有监督数据时，对比学习是一种流行的方法，其目标是匹配用不同模态表达的相同概念的表示[23]。表示协调(§3.2)的想法也适用于局部对齐。一些例子包括将书籍与其对应的电影/剧本对齐[323]，将引用表达式与视觉对象匹配[169]，以及寻找图像区域与其描述之间的相似性[105]。局部对齐的方法也使得共享语义概念的学习不仅仅基于语言，还基于其他模式，如视觉[107]、声音[60,236]和多媒体[323]，这些模式对下游任务很有用。<br><br>当真实模态对不可用时，必须在两种模态的所有元素之间进行全局对齐。基于最优传输(OT)的方法[278]属于更广泛的匹配算法集是一种潜在的解决方案，因为它们通过将对齐作为散度最小化问题来共同优化协调函数和模态元素之间的最优耦合。这些方法对于对齐多模态表示空间非常有用[142,205]。为了缓解计算问题，最近的一些进展将它们与神经网络[54]集成，用熵正则化近似最优传输[288]，并为高效学习制定凸松弛[85]。<br><br>到目前为止，我们做的一个重要假设是，模态元素已经被分割和离散化了。虽然某些模态显示了清晰的分割(例如，句子中的单词/短语或图像中的对象区域)，但在许多情况下，分割并不容易提供，例如连续信号(例如，金融或医疗时间序列)，时空数据(例如，卫星或天气图像)或没有明确语义边界的数据(例如，MRI图像)。在这些设置中，最近提出了基于翘曲和分割的方法.<br><br>文搜图、图搜图已经研究二十多年了，这种研究基本细致到具体的数据集，即只能在本数据集分类中检索，而不属于该数据集分类的数据无法使用，局限性较大。所以研究方向之一为<a data-href="zero-shot" href="\project\知识储备\zero-shot.html" class="internal-link" target="_self" rel="noopener nofollow">zero-shot</a>。比较多研究，且仍有空间的是文搜视频的研究。<br><br><a data-href="CCA" href="\project\知识储备\cca.html" class="internal-link" target="_self" rel="noopener nofollow">CCA</a>]]></description><link>project\大二论文\论文\多模态机器学习综述.html</link><guid isPermaLink="false">Project/大二论文/论文/多模态机器学习综述.md</guid><pubDate>Sun, 17 Dec 2023 07:05:04 GMT</pubDate></item><item><title><![CDATA[多模态融合]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/大二论文/论文" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大二论文/论文</a> 
 <br><a href=".?query=tag:项目\个人项目\大二论文\论文" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大二论文/论文</a><br>
<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/133990245" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/133990245" target="_blank">面向深度学习的多模态融合技术研究综述 - 知乎 (zhihu.com)</a>]]></description><link>project\大二论文\论文\多模态融合.html</link><guid isPermaLink="false">Project/大二论文/论文/多模态融合.md</guid><pubDate>Thu, 21 Dec 2023 09:33:19 GMT</pubDate></item><item><title><![CDATA[Progressive Spatio-Temporal Prototype Matching for Text-Video Retrieval]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/大二论文/论文" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大二论文/论文</a> 
 <br><a href=".?query=tag:项目\个人项目\大二论文\论文" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大二论文/论文</a><br>
<img alt="v2-9c9b7433f8d781dab4708defd5cf79c8_r.jpg" src="\lib\media\v2-9c9b7433f8d781dab4708defd5cf79c8_r.jpg"><br>
<a data-tooltip-position="top" aria-label="https://blog.csdn.net/MiHu001/article/details/134265337" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/MiHu001/article/details/134265337" target="_blank">【论文阅读】Progressive Spatio-Temporal Prototype Matching for Text-Video Retrieval-CSDN博客</a><br>
文本-视频检索是近年来比较新兴的领域，随着多模态和大模型的发展，这一领域也迸发出了前所未有的潜力。目前的主流方法是学习一个joint embedding space，将视频和文本编码成特征向量，在空间中含义相近的向量的位置也是相近的，从而通过计算向量间相似度实现检索。本文梳理了近期的一些工作，主要分为以下三个方向：<br>
细粒度匹配：单一的特征向量难以编码丰富的细节信息，需要进行更细粒度的视频文本匹配。<br>
多模态特征：视频有着丰富的多模态信息，使用多种多模态特征可增强检索性能。<br>
大规模预训练：近年来大规模预训练广泛应用，经过预训练的模型检索能力得到显著提升。<br>
作者团队在这一问题上，主要着重于第一个方向的研究。<br><img alt="Pasted image 20231205113244.png" src="\lib\media\pasted-image-20231205113244.png"><br>典型的解决方案是直接对齐整个视频与句子的特征，这会忽视视频内容与文本的内在关系。因此，匹配过程应当同时考虑细粒度的空间内容和各种时间语义事件。这就是细粒度的匹配。]]></description><link>project\大二论文\论文\progressive-spatio-temporal-prototype-matching-for-text-video-retrieval.html</link><guid isPermaLink="false">Project/大二论文/论文/Progressive Spatio-Temporal Prototype Matching for Text-Video Retrieval.md</guid><pubDate>Sun, 17 Dec 2023 07:05:10 GMT</pubDate><enclosure url="lib\media\v2-9c9b7433f8d781dab4708defd5cf79c8_r.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\v2-9c9b7433f8d781dab4708defd5cf79c8_r.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Prompt Switch Efficient CLIP Adaptation for Text-Video Retrieval]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/大二论文/论文" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大二论文/论文</a> 
 <br><a href=".?query=tag:项目\个人项目\大二论文\论文" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大二论文/论文</a>]]></description><link>project\大二论文\论文\prompt-switch-efficient-clip-adaptation-for-text-video-retrieval.html</link><guid isPermaLink="false">Project/大二论文/论文/Prompt Switch Efficient CLIP Adaptation for Text-Video Retrieval.md</guid><pubDate>Sun, 17 Dec 2023 07:05:13 GMT</pubDate></item><item><title><![CDATA[Abstract]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/大二论文/论文" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大二论文/论文</a> 
 <br><a href=".?query=tag:项目\个人项目\大二论文\论文" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大二论文/论文</a><br>
VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding<br>
关于<a data-href="CLIP" href="\project\知识储备\clip.html" class="internal-link" target="_self" rel="noopener nofollow">CLIP</a><br>
论文地址：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2109.14084.pdf" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//arxiv.org/pdf/2109.14084.pdf" target="_blank">https://arxiv.org/pdf/2109.14084.pdf</a><br>代码地址：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//github.com/pytorch/fairseq/tree/main/examples/MMPT" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//github.com/pytorch/fairseq/tree/main/examples/MMPT" target="_blank">https://github.com/pytorch/fair</a><br><br>在本文中，作者提出了VideoCLIP，这是一种不需要下游任务的任何标签，用于预训练零样本视频和文本理解模型的对比学习方法。VideoCLIP通过对比时间重叠的正视频文本对&nbsp;和最近邻检索的负样本对&nbsp;，训练视频和文本的Transformer。在本文中，作者对一系列下游任务（包括序列级文本视频检索、VideoQA、token级动作定位和动作分割）进行了实验，实验结果表明本文提出的VideoCLIP可以达到SOTA的性能，在某些情况下甚至优于监督方法。<br><br>练+微调”的训练范式对NLP和CV领域进行了革新。尽管以这种方式训练的模型可以获得不错的性能，但它们 仍然需要特定于任务的标注数据，并需要基于每个下游任务进行微调。<br>
基于这样的问题，最近也有一些工作致力于研究无需微调的零样本迁移到下游任务的预训练，比如NLP领域中GPT，CV领域中的CLIP。<br>
在本文中，作者主要研究零样本迁移到视频文本理解任务的预训练。本文的方法使用成对的视频文本 clip，基于对比学习的目标函数，对Transformer结构进行预训练。本文的VideoCLIP基于一个公开的预训练数据集HowTo100M来使模型能够获得视频理解的能力。实验表明，所得到的预训练模型可以直接应用于或通过微调应用于一系列视频文本任务。<br>
作者发现，简单直接的目标函数会导致较差的结果，并认为学习视频和文本之间的细粒度关联对于零样本迁移到下游任务至关重要，因为下游任务可能需要不同粒度的视频文本交互。以前的工作是在随机batch中对短时间的、对齐的视频和文本片段进行采样，但没有学习视频帧和单词token之间的细粒度关联。<br>
<img alt="Pasted image 20231128211925.png" src="\lib\media\pasted-image-20231128211925.png"><br>
在本文中，作者提出了VideoCLIP，使用了两种关键技术（如上图所示）来计算训练目标，通过对比学习来预训练统一的视频文本表示。<br>
首先，作者的目标是改善视频和文本与不同序列长度的关联。尽管大多数视频和文本没有语义对齐，但当前的视频文本模型是通过精确的时间对齐进行训练的。因此，多个或更长的文本clip能与视频clip很好地对齐，但是许多视频clip并可能没有任何相应的文本。<br>
为了解决这些问题，作者使用临时重叠的视频和文本clip对进行预训练（如上图所示），从而大大提高视频文本对齐的质量和数量&nbsp;。其次，作者收集更难的负样本对，从对比损失函数中学习细粒度视频文本相似度。现有的工作通过从同一视频中采样多个视频片段来对比视频内的片段，但作者发现从其他视频中挖掘片段可以提供更具挑战性的负样本对。因此，作者提出了一种检索增强预训练方法来检索每个训练batch中相似的视频&nbsp;。<br><br><br>在零样本迁移的多模态视频文本预训练范式中，关键的挑战是学习视频和文本之间的细粒度关联，以满足下游任务的不同需求。在本节中，作者首先介绍视频和文本模型的主干网络和<a data-href="对比损失函数" href="\project\知识储备\对比损失函数.html" class="internal-link" target="_self" rel="noopener nofollow">对比损失函数</a>；然后，提出重叠的视频和文本clip，以提高正样本对的关联性；最后，介绍了检索增强的预训练，以改进负样本对的挖掘。<br><br>Video and Text Transformers<br>
<img alt="Pasted image 20231204101318.png" src="\lib\media\pasted-image-20231204101318.png"><br>
注意：使用S3D卷积对视频clip进行信息提取，生成tokens<br>使用均值池化而不是CLS标记来鼓励文本transformer和视频transformer学习标记级别的表征，可能对动作定位和动作分段有益。在实验中，作者发现共享两个transformer的参数只比不共享的效果差了一点。<br>值得注意的是，使用冻结的S3D权重参数能够建模长期的视觉文本一致性（大约32s），而典型的video CNNs只能捕获大约3s的时间窗口。<br><br><img alt="Pasted image 20231204101401.png" src="\lib\media\pasted-image-20231204101401.png"><br>
<a data-href="对比损失函数" href="\project\知识储备\对比损失函数.html" class="internal-link" target="_self" rel="noopener nofollow">对比损失函数</a><br><br>首先，现有的很多预训练方法关注时序上精确对齐的视频文本对，它们的起止时间完全一致。大多数视频和文本并没有语义对齐，但现在的模型以精确的时序对齐来进行训练。比如一个人在说话，内容是“我去给你展示如何做炒饭”，这个片段和这个内容描述在语义上并不对齐，而随后一个米饭在锅中的片段可能与这个内容描述具有较高的相关性。因为人类很少同时说话和进行对应的动作。所以采取时间对齐可能导致多个或者较长的文本与一个视频具有更好的一致性，但是许多视频可能没有对应的字幕描述。因为在短片段中，时间上对齐的视频文本对在语义上也接近的可能性很小。该论文按照以下方法建立重叠的正样本对：<br>1）采样一个文本段（先采样一个视频可能没有邻近的相应文本）<br>2）在文本段的时间边界内取样一个时间戳作为视频片段的中心；<br>3）从这个中心时间戳开始，裁剪出一个具有随机持续时间的视频片段（最长32s）<br>该方法提高了视频和文本的相关性，并鼓励细粒度的关联。<br><br>通过使用对比预训练目标中更困难的负样例，可以学习建立更细粒度的视频文本相似性模型。因此作者在训练batch中使用难负例样本 ，它们在语义上与正例的样本对相关，这些难负例是通过检索采样得到的。<br>本文的方法旨在通过视频聚类来构建一个batch的训练样本，因此作者将其建模成了在视频潜在空间中进行检索的任务。整个训练过程可以看成是一个二阶段的方法，在每个迭代过程中交替执行检索和训练任务，如下图所示：<br>
<img alt="Pasted image 20231204101424.png" src="\lib\media\pasted-image-20231204101424.png"><br>
Retrieval Augmented Training 使用更困难的负样本对来建模视频和文本之间的细粒度关联。使用基于检索的采样，获取与正样本对语义上类似的负样本对，来构建训练批次。负样本并不只来自于同一视频中，还从其他不同的视频中挖掘。训练过程可以归结为一个两阶段的方法：检索和训练，如上图所示。检索的方法如下：<br>1）上面line2通过平均一个视频的所有视频和文本的向量表示，来计算一个视频的全局特征。通过消融试验证明了这样获得的视频特征比只取视频的开始片段来推断视频的表示效果更好。<br>2）上面line3为所有在训练中用到的视频构建了一个密度索引。<br>3）上面line4首先找到个随机的视频（对应训练集中的批次数量），其中每个视频会生成一个视频簇。我们从K个最邻近的视频中采样K个视频，而不是直接取样K个最邻近的视频。这是因为我们想要一个簇中的视频互相接近，而不是全部靠近。这样从一个视频中采样的所有视频/文本片段可以作为从另一个视频中采样的片段的负例。<br><br>使用InfoNCE来学习视频文本的一致性，对比损失函数如下图所示，其中T是一个temperature超参数。<br>
<img alt="Pasted image 20231204101604.png" src="\lib\media\pasted-image-20231204101604.png">]]></description><link>project\大二论文\论文\videoclip.html</link><guid isPermaLink="false">Project/大二论文/论文/VideoCLIP.md</guid><pubDate>Sun, 17 Dec 2023 07:05:16 GMT</pubDate><enclosure url="lib\media\pasted-image-20231128211925.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20231128211925.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[搜视频的心路历程]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目</a> 
 <br><a href=".?query=tag:项目\个人项目" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目</a> <br><br>当我产生一个问题，这个问题并不是文字描述可以解决的，这时我会选择去搜视频。<br>
视频最优势在于它同时兼具图像的静态信息和文字的动态信息。且一般是有人加工过，有突出的重点。<br>由于当代视频软件的本质是刷，通过大量的刷视频来找到自己所喜爱的，而不是搜，用户有目的地搜特定的视频与短视频想要留住用户的愿望相悖，用户用这个动作的时候比较少。<br>
那么什么样的问题我会去搜视频呢？<br>
第一，技术手工类的，具体操作，如折纸，做饭，视频更直观。<br>
第二，旅游景色类，如我想体验一下某个地方的美景，视频更沉浸。<br>
第四，产品测评类，视频更真实。<br>
第五，知识了解类，视频更通俗易懂。<br>
当然，这五种情况只是代表其中一部分场景，大部分的这类搜索场景可以通过标签和关键词搜索解决。<br>
但是我们对于视频的搜索不仅仅局限于这些具体的问题。我们很多时候想要去搜索过去看过的视频中的某个场景。由于刷视频并非学习，记忆较浅，但是后期用户可能想要分享和回看，那么这个时候他的印象一般是一个场景，或者印象深刻的一句话的大概内容。前者我们需要用文搜视频，后者我们可以通过字幕检索。即我们尚需解决的问题是对于一段简单的文字场景描述，我们如何找到对应的视频片段。<br><br>
<br>提取视频特征向量，建立语义空间。这里我们使用<a data-href="zero-shot" href="\project\知识储备\zero-shot.html" class="internal-link" target="_self" rel="noopener nofollow">zero-shot</a>,学习视频分类，在给定的文本提示下，能找到对应类别的视频。
<br>对找到的类别视频进行分析，对比视频片段与文本的相似度。
<br><br>Prompt Switch: Efficient CLIP Adaptation for Text-Video Retrieval<br>
VideoCLIP: Contrastive Pre-training for Zero-shot Video-Text Understanding<br>
对于这两篇论文吃透，并了解代码。<br>
在此基础上改进videoCLIP中的一些时间戳选择，截取时间长度等问题。再加上prompt learning实现在某些数据集上的专项检索，并且能够泛化检索普通视频。]]></description><link>project\大二论文\text-to-video初步想法.html</link><guid isPermaLink="false">Project/大二论文/text-to-video初步想法.md</guid><pubDate>Tue, 12 Dec 2023 01:48:14 GMT</pubDate></item><item><title><![CDATA[对比损失函数]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> 
 <br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a> <br><br>假设我们现在有2张人脸图片，我们要进行一个简单的对比任务，就是判断这两张人脸图片是不是对应同一个人，那么我们一般会如何解决？一种简单直接的思路就是提取图片的特征向量，然后去对比两个向量的相似度。但这种简单的做法存在一个明显的问题，那就是CNN提取的特征“类间”区分性真的有那么好吗？昨天我们了解到用SoftMax损失函数训练出的分类模型在Mnist测试集上就表现出“类间”区分边界不大的问题了，使得遭受对抗样本攻击的时候很容易就分类失败。况且人脸识别需要考虑到样本的类别以及数量都是非常多的，这无疑使得直接用特征向量来对比更加困难。<br><br>针对上面这个问题，孪生网络被提出，大致结构如下所示：<br><img src="https://pic1.zhimg.com/80/v2-11d8832ac50a466d06ba1a7e2b03bd64_1440w.webp" referrerpolicy="no-referrer"><br>然后孪生网络一般就使用这里要介绍的Contrastive Loss作为损失函数，这种损失函数可以有效的处理这种网络中的成对数据的关系。<br>Contrastive Loss的公式如下：<br><img src="https://pic2.zhimg.com/80/v2-46090ace3073bd875d28d4ff9a541605_1440w.webp" referrerpolicy="no-referrer"><br>其中是网络权重，是成对标签，如果，这对样本属于同一个类，则=0，属于不同类则=1。是与在潜变量空间的欧几里德距离。当=0，调整参数最小化与之间的距离。当=1，当与之间距离大于，则不做优化（省时省力）当与  之间的距离小于, 则增大两者距离到m。下面的公式（4）是将上面的展开写了一下，如下所示：<br><img src="https://pic3.zhimg.com/80/v2-bfa48776c69d7e2cbfcf9bc118e5e86e_1440w.webp" referrerpolicy="no-referrer"><br>
而下面的Figure1展示的就是损失函数和样本特征的欧氏距离之间的关系，其中红色虚线表示相似样本的损失值，而蓝色实线表示的是不相似样本的损失值。<br><img src="https://pic3.zhimg.com/80/v2-f6a190a980225fa965c650b307a05cf6_1440w.webp" referrerpolicy="no-referrer"><br>在LeCun的论文中他用弹簧在收缩到一定程度的时候因为受到斥力的原因会恢复到原始长度来形象解释了这个损失函数，如下图：<br><img src="https://pic3.zhimg.com/80/v2-80d7f800c39ab317a39fb2fde7c2ac4a_1440w.webp" referrerpolicy="no-referrer"><br>代码实现：<br># Custom Contrastive Loss
class ContrastiveLoss(torch.nn.Module):
    """
    Contrastive loss function.
    Based on: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf
    """

    def __init__(self, margin=2.0):
        super(ContrastiveLoss, self).__init__()
        self.margin = margin

    def forward(self, output1, output2, label):
        euclidean_distance = F.pairwise_distance(output1, output2)
        loss_contrastive = torch.mean((1-label) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法
                                      (label) * torch.pow(torch.clamp(self.margin - euclidean_distance, min=0.0), 2))     
 

        return loss_contrastive
]]></description><link>project\知识储备\对比损失函数.html</link><guid isPermaLink="false">Project/知识储备/对比损失函数.md</guid><pubDate>Wed, 06 Dec 2023 02:10:37 GMT</pubDate><enclosure url="https://pic1.zhimg.com/80/v2-11d8832ac50a466d06ba1a7e2b03bd64_1440w.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://pic1.zhimg.com/80/v2-11d8832ac50a466d06ba1a7e2b03bd64_1440w.webp&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[岭回归]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> 
 <br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a><br>
岭回归(ridge regression)是一种 restrain回归分析方法。它通过添加自变量矩阵的2范数作为惩罚项来处理多重共线性问题。<br>具体来说:<br>
<br>岭回归试图找到一组回归系数θ,使得平方损失函数与θ的2范数平方和的和取得最小值:
<br>minimize <br>这里的第二项θ的2范数平方和就是惩罚项。<br>
<br>
惩罚项可以防止回归系数θ取很大值,从而避免过拟合问题。α控制着惩罚项的权重。

<br>
当α=0时,它等同于传统的最小均方差回归。α增加时,回归系数θ的大小会减少。

<br>
岭回归相比LASSO回归,它的回归系数不会被完全约略,因此保留了所有特征,但回归系数会被“压缩”。

<br>
岭回归可以很好地处理多重共线性,还可以防止过拟合。它通常用于高维回归问题。

<br>所以总结来说,岭回归通过添加2范数惩罚项来稳定回归问题,从而使回归结果不会太过于依赖某个特定特征。]]></description><link>project\知识储备\岭回归.html</link><guid isPermaLink="false">Project/知识储备/岭回归.md</guid><pubDate>Sat, 02 Dec 2023 16:31:04 GMT</pubDate></item><item><title><![CDATA[余弦相似性]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> 
 <br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a> <br><br>对于两个向量可以用其夹角余弦表示其近似的程度（公式如下）：<br><img alt="Pasted image 20231203002824.png" src="\lib\media\pasted-image-20231203002824.png"><br>两个向量夹角余弦值就是两个向量的余弦相似度。<br>该公式直接来源于内积的定义。<br>分子为两个向量内积，分母为两个向量模（长度）的积。通过公式，可以直观的认为其一定程度上消除了向量长度的影响，余弦相似度体现的是方向的差异。（欧氏距离体现的是距离差异）<br>
<br>当夹角为0，两个向量同向，相当于相似度最高，余弦值为1<br>

<br>当夹角90°，两个向量垂直，余弦为0。<br>

<br>当夹角180°，两个向量反向，余弦为-1
<br><br>余弦相似度被大量用于对比：如人脸对比、声音对比，来快速判断两个图片或者两段声音的相似度，进而判断是不是来自同一个人。<br>当一个图像或者声音样本具有n维的特征，我们就可以把他认为是n维向量，两个样本使用余弦相似度比对时，就是对两个n维向量的夹角余弦值，其大小进行衡量。<br>特别的，当我们拥有一个训练完成的分类神经网络，理论上这个神经网络在最后一层全连接层的输入，就是神经网络提取的特征（因为最后一层全连接层借由这些数据完成了分类任务）。<br>
<br>
余弦相似度而非算法，求出余弦相似度后，到底阈值如何界定（值大于多少认为是样本来自同一类），往往需要依次用不同的阈值数值对全部数据集进行测试，挑选效果最好的数值作为阈值<br>


<br>
尽管余弦相似度用法类似欧氏距离（欧氏距离也可以用于比对：把n维特征认为是n维空间的一个点，当两个样本对应的点，距离足够近认为认为来自同一类），但余弦相似度并不符合距离定义。<br>


<br>
余弦相似度范围[-1,1]包含负值，不便于使用，改进方法有：

<br>
将余弦相似度用于正空间，对于各个维度均为正的向量，可以保证余弦相似度非负（该空间的夹角被限定在0-90，或者根据公式，内积恒为正）。

<br>
用1减余弦相似度，此时结果范围为[0,2]，且值越小表示越接近（类似欧氏距离）。

<br><br>例如鸢尾花数据集的四种特征，我们可以把每个样本认为是四维空间的一个点，每个样本的四个特征分别是这四个维度的坐标。<br>下图为散点图，四个特征中仅使用petal length，petal width两个特征作图（分别横纵坐标，二维的便于观察）<br><img src="https://pic2.zhimg.com/80/v2-0a206ba34a2212b6ed665ac10a4bc241_1440w.webp" referrerpolicy="no-referrer"><br>在此基础上，我们从原点起，向每个样本点引一个有向线段，这就把每个样本转换成一个四维空间的向量，余弦相似度就是两个向量间的夹角余弦值。本例中特征为长度，余弦相似度不会有负值。<br>为避免箭头太多混乱，挑选1个setosa样本（蓝箭头）与2个virginia样本（绿箭头），查看同类样本、不同类样本之间的夹角（夹角越小，余弦值越大）。<br><img src="https://pic1.zhimg.com/80/v2-47025502bb163e541b92afefa147fcec_1440w.webp" referrerpolicy="no-referrer"><br>在本例中可以发现，同类的绿色向量间，夹角更小，相似度高；不同类的蓝绿向量之间，夹角大，相似度低。<br>实际上，通过观察散点图，可以发现鸢尾花数据集并不特别适合使用余弦相似度，理论上应当同类型花的各样本向量夹角小，不同类夹角大；但很多不同类的样本向量夹角也很小，不利于根据余弦相似度大小区分是否同类。<br>这是因为余弦相似度关注的是方向，一定程度上忽略了距离的影响，但花朵的长度参数petal length，petal width会极大的影响花的分类，不应进行忽略。<br><br>余弦相似度计算代码（定义后可以直接调用，a,b为n维的array类数据特征）<br>def simcos(a,b): #
    dot = sum(a*b)
    mod_a = sum(a**2)**0.5
    mod_b = sum(b**2)**0.5
    return dot/(mod_a*mod_b)
#用法示例
a = np.array([0,1]) #向量维度可任意，示例使用2维的数据
b = np.array([1,0])
print(a.shape,b.shape) #(2,) (2,)
print(simcos(a,b)) #0.0 #两者相似度为0
<br>鸢尾花数据集作图代码（需要事先安装scikit-learn库，通过pip install scikit-learn安装）<br>from sklearn.datasets import load_iris
import numpy as np
import matplotlib.pyplot as plt

iris = load_iris()#导入数据集
print(iris.data.shape) #(150,4) 150条数据4种特征
print(iris.feature_names) #['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'] 4种特征含义
print(iris.target.shape) #(150,) 150条数据的类别
print(iris.target_names)#['setosa' 'versicolor' 'virginica'] 3种类别名称

n_class = len(set(iris.target))#计算总类别数3
for i in range(n_class):#对每一类
    plt.plot(*iris.data[:,2:][iris.target==i].T,#该类样本呢的后两个特征作图
             '.',label = iris.target_names[i]) #将该类名称作为图例
plt.legend()
plt.show()
<br>挑选部分样本计算余弦相似度<br>from sklearn.datasets import load_iris
import numpy as np
import matplotlib.pyplot as plt

def simcos(a,b): #a,b为n维的array类数据特征
    dot = sum(a*b)
    mod_a = sum(a**2)**0.5
    mod_b = sum(b**2)**0.5
    return dot/(mod_a*mod_b)

iris = load_iris()#导入数据集

s0 = iris.data[25]
v0 = iris.data[120]
v1 = iris.data[140]

print(s0.shape, v0.shape, v1.shape) #(4,) (4,) (4,)均是4维向量
print(simcos(s0,v0)) #0.9073500898640795 #不同类之间余弦相似度偏低
print(simcos(v0,v1)) #0.9998554672050123 #同类之间余弦相似度高
<br><br>一个简单的对比算法，对余弦相似度用阈值判断：对任意两个样本，计算余弦相似度，如果超过该阈值认为是同一类，否则认为是不同类。<br>下面是通过遍历确定阈值的方法：<br>from sklearn.datasets import load_iris
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm

def simcos(a,b): #a,b为n维的array类数据特征
    dot = sum(a*b)
    mod_a = sum(a**2)**0.5
    mod_b = sum(b**2)**0.5
    return dot/(mod_a*mod_b)

iris = load_iris()#导入数据集

n_sample = len(iris.data)

thres_list = []
acc_list = []
for thres in tqdm(np.arange(0,1,0.002)): #遍历阈值的取值
    n_sum = 0 #每个阈值下的判断总数
    n_correct = 0 #每个阈值下的正确判断数
    for i in range(n_sample):
        for j in range(n_sample):
            if iris.target[i] == iris.target[j]:#两个样本是同类
                if simcos(iris.data[i],iris.data[j]) &gt;= thres:#如果余弦相似度大于给定阈值
                    n_correct += 1#认为判断正确
            else:#两个样本不同类
                if simcos(iris.data[i],iris.data[j]) &lt; thres:#余弦相似度小于给定阈值
                    n_correct += 1#认为判断正确
            n_sum += 1

    thres_list.append(thres)#记录该阈值
    acc_list.append(n_correct/n_sum)#记录该阈值判断准确率

best_thres = thres_list[acc_list.index(max(acc_list))] #最佳阈值是最大准确率对应的阈值
print(best_thres) #最佳阈值
print(max(acc_list)) #最高准确率
plt.plot(thres_list, acc_list)
plt.plot(best_thres,max(acc_list),'o')
plt.show()
<br>运行结果（横轴为阈值，纵轴为选取该阈值进行判断的准确率）<br><img src="https://pic1.zhimg.com/80/v2-d8351ebaad0df5a4cb0cc22d725fa4dc_1440w.webp" referrerpolicy="no-referrer"><br>#0.996 阈值设置为0.996 超过（含）认为是同类，效果最佳
#0.8807111111111111 此时根据已有数据，对比判断准确率88.07%
]]></description><link>project\知识储备\余弦相似性.html</link><guid isPermaLink="false">Project/知识储备/余弦相似性.md</guid><pubDate>Sat, 02 Dec 2023 16:28:57 GMT</pubDate><enclosure url="lib\media\pasted-image-20231203002824.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20231203002824.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[CCA]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> 
 <br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a><br>
典型关联分析(Canonical Correlation Analysis，以下简称CCA)是最常用的挖掘数据关联关系的算法之一。比如我们拿到两组数据，第一组是人身高和体重的数据，第二组是对应的跑步能力和跳远能力的数据。那么我们能不能说这两组数据是相关的呢？CCA可以帮助我们分析这个问题。将数据形式不同的矩阵映射成向量，从而可以比较他们之间的相关系数。多用在信息的检索.<br>主要特征:<br>
<br>CCA目标是找到两个数据集中线性组合的最大相关性。这两个线性组合成为一对共趋相关向量。<br>

<br>它用于分析两个数据集中变量之间的相关关系,找出它们线性组合后相关性最大的组合模式。<br>

<br>CCA输出的是一对一匹配的表达式,以最大限度提高两个表达形式之间的协同变化程度。<br>

<br>应用实例:<br>
<br>文本与图像之间相关性分析。<br>

<br>fMRI图像数据与行为得分之间的关系分析。<br>

<br>遗传学数据与病理学数据之间的关系挖掘。<br>

<br>优点:<br>
<br>无监督学习方法,不需要标签信息。<br>

<br>能提取数据集间隐含的复杂非线性关系。<br>

<br>对相关子空间进行降维,减少数据噪声影响。<br>

<br>所以总之,CCA是一种重要的多元统计技术,用于挖掘多源非监督数据集间的内在结构相关性。它在多模态学习等领域有重要应用。****]]></description><link>project\知识储备\cca.html</link><guid isPermaLink="false">Project/知识储备/CCA.md</guid><pubDate>Fri, 01 Dec 2023 11:30:03 GMT</pubDate></item><item><title><![CDATA[<strong>CLIP是如何工作的</strong>]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> 
 <br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a><br>
<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/493489688" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/493489688" target="_blank">神器CLIP：连接文本和图像，打造可迁移的视觉模型 - 知乎 (zhihu.com)</a><br>
clip模型代码<br>
<a data-tooltip-position="top" aria-label="https://github.com/OpenAI/CLIP" rel="noopener nofollow" class="external-link" href="https://github.com/OpenAI/CLIP" target="_blank">openai/CLIP: CLIP (Contrastive Language-Image Pretraining), Predict the most relevant text snippet given an image --- openai/CLIP： CLIP （Contrastive Language-Image Pretraining），预测给定图像的最相关的文本片段 (github.com)</a><br><br>CLIP的英文全称是Contrastive Language-Image Pre-training，即一种基于对比文本-图像对的预训练方法或者模型。CLIP是一种基于对比学习的多模态模型，与CV中的一些对比学习方法如moco和simclr不同的是，CLIP的训练数据是文本-图像对：一张图像和它对应的文本描述，这里希望通过对比学习，模型能够学习到文本-图像对的匹配关系。如下图所示，CLIP包括两个模型：Text Encoder和Image Encoder，其中Text Encoder用来提取文本的特征，可以采用NLP中常用的text transformer模型；而Image Encoder用来提取图像的特征，可以采用常用CNN模型或者vision transformer。<br><img src="https://pic2.zhimg.com/80/v2-b86361b47d4db80258439b8ad33bdf8d_1440w.webp" referrerpolicy="no-referrer"><br>这里对提取的文本特征和图像特征进行对比学习。对于一个包含n个文本-图像对的训练batch，将n个文本特征和n个图像特征两两组合，CLIP模型会预测出n^2个可能的文本-图像对的相似度，这里的相似度直接计算文本特征和图像特征的<a data-href="余弦相似性" href="\project\知识储备\余弦相似性.html" class="internal-link" target="_self" rel="noopener nofollow">余弦相似性</a>（cosine similarity），即上图所示的矩阵。这里共有n个正样本，即真正属于一对的文本和图像（矩阵中的对角线元素），而剩余的n^2−n个文本-图像对为负样本，那么CLIP的训练目标就是最大n个正样本的相似度，同时最小化n^2−n个负样本的相似度，对应的伪代码实现如下所示：<br>
问题：为什么要最小化负样本相似度呢？<br># image_encoder - ResNet or Vision Transformer
# text_encoder - CBOW or Text Transformer
# I[n, h, w, c] - minibatch of aligned images
# T[n, l] - minibatch of aligned texts
# W_i[d_i, d_e] - learned proj of image to embed
# W_t[d_t, d_e] - learned proj of text to embed
# t - learned temperature parameter

# 分别提取图像特征和文本特征
I_f = image_encoder(I) #[n, d_i]
T_f = text_encoder(T) #[n, d_t]

# 对两个特征进行线性投射，得到相同维度的特征，并进行l2归一化
I_e = l2_normalize(np.dot(I_f, W_i), axis=1)
T_e = l2_normalize(np.dot(T_f, W_t), axis=1)

# 计算缩放的余弦相似度：[n, n]
logits = np.dot(I_e, T_e.T) * np.exp(t)

# 对称的对比学习损失：等价于N个类别的cross_entropy_loss
labels = np.arange(n) # 对角线元素的labels
loss_i = cross_entropy_loss(logits, labels, axis=0)
loss_t = cross_entropy_loss(logits, labels, axis=1)
loss = (loss_i + loss_t)/2
<br>为了训练CLIP，OpenAI从互联网收集了共4个亿的文本-图像对，论文称之为WebImageText，如果按照文本的单词量，它和训练GPT-2的WebText规模类似，如果从数量上对比的话，它还比谷歌的JFT-300M数据集多一个亿，所以说这是一个很大规模的数据集。CLIP虽然是多模态模型，但它主要是用来训练可迁移的视觉模型。论文中Text Encoder固定选择一个包含63M参数的text transformer模型，而Image Encoder采用了两种的不同的架构，一是常用的CNN架构ResNet，二是基于transformer的ViT，其中ResNet包含5个不同大小的模型：ResNet50，ResNet101，RN50x4，RN50x16和RNx64（后面三个模型是按照EfficientNet缩放规则对ResNet分别增大4x，16x和64x得到），而ViT选择3个不同大小的模型：ViT-B/32，ViT-B/16和ViT-L/14。所有的模型都训练32个epochs，采用AdamW优化器，而且训练过程采用了一个较大的batch size：32768。由于数据量较大，最大的ResNet模型RN50x64需要在592个V100卡上训练18天，而最大ViT模型ViT-L/14需要在256张V100卡上训练12天，可见要训练CLIP需要耗费多大的资源。对于ViT-L/14，还在336的分辨率下额外finetune了一个epoch来增强性能，论文发现这个模型效果最好，记为ViT-L/14@336，论文中进行对比实验的CLIP模型也采用这个。<br><br>上面我们介绍了CLIP的原理，可以看到训练后的CLIP其实是两个模型，除了视觉模型外还有一个文本模型，那么如何对预训练好的视觉模型进行迁移呢？与CV中常用的先预训练然后微调不同，CLIP可以直接实现zero-shot的图像分类，即不需要任何训练数据，就能在某个具体下游任务上实现分类，这也是CLIP亮点和强大之处。用CLIP实现zero-shot分类很简单，只需要简单的两步：<br>
<br>根据任务的分类标签构建每个类别的描述文本：A photo of {label}，然后将这些文本送入Text Encoder得到对应的文本特征，如果类别数目为n，那么将得到n个文本特征；
<br>将要预测的图像送入Image Encoder得到图像特征，然后与n个文本特征计算缩放的余弦相似度（和训练过程一致），然后选择相似度最大的文本对应的类别作为图像分类预测结果，进一步地，可以将这些相似度看成logits，送入softmax后可以到每个类别的预测概率。
<br><img src="https://pic4.zhimg.com/80/v2-acd4b008007ca7de78bdab1c9042bbcb_1440w.webp" referrerpolicy="no-referrer"><br>可以看到，我们是利用CLIP的多模态特性为具体的任务构建了动态的分类器，其中Text Encoder提取的文本特征可以看成分类器的weights，而Image Encoder提取的图像特征是分类器的输入。这里我们给出了一个基于CLIP的一个实例（参考官方<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//github.com/openai/CLIP/blob/main/notebooks/Interacting_with_CLIP.ipynb" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//github.com/openai/CLIP/blob/main/notebooks/Interacting_with_CLIP.ipynb" target="_blank">notebook</a>），这里任务共有6个类别："dog", "cat", "bird", "person", "mushroom", "cup"，首先我们创建文本描述，然后提取文本特征：<br># 首先生成每个类别的文本描述
labels = ["dog", "cat", "bird", "person", "mushroom", "cup"]
text_descriptions = [f"A photo of a {label}" for label in labels]
text_tokens = clip.tokenize(text_descriptions).cuda()

# 提取文本特征
with torch.no_grad():
    text_features = model.encode_text(text_tokens).float()
    text_features /= text_features.norm(dim=-1, keepdim=True)
<br>然后我们读取要预测的图像，输入Image Encoder提取图像特征，并计算与文本特征的余弦相似度：<br># 读取图像
original_images = []
images = []
texts = []

for label in labels:
    image_file = os.path.join("images", label+".jpg")
    name = os.path.basename(image_file).split('.')[0]

    image = Image.open(image_file).convert("RGB")
    original_images.append(image)
    images.append(preprocess(image))
    texts.append(name)

image_input = torch.tensor(np.stack(images)).cuda()

# 提取图像特征  
with torch.no_grad():
    image_features = model.encode_image(image_input).float()
    image_features /= image_features.norm(dim=-1, keepdim=True)

# 计算余弦相似度（未缩放）
similarity = text_features.cpu().numpy() @ image_features.cpu().numpy().T
<br>相似度如下所示，可以看到对于要预测的6个图像，按照最大相似度，其均能匹配到正确的文本标签：<br><img src="https://pic4.zhimg.com/80/v2-b16c535d2c33028e33c59d041d4aa8cf_1440w.webp" referrerpolicy="no-referrer"><br>进一步地，我们也可以对得到的余弦相似度计算softmax，得到每个预测类别的概率值，注意这里要对相似度进行缩放：<br>logit_scale = np.exp(model.logit_scale.data.item())
text_probs = (logit_scale * image_features @ text_features.T).softmax(dim=-1)
top_probs, top_labels = text_probs.cpu().topk(5, dim=-1)
<br>得到的预测概率如下所示，可以看到6个图像，CLIP模型均能够以绝对的置信度给出正确的分类结果：<br><img src="https://pic2.zhimg.com/80/v2-00749f75a141a99c98207fab0c91c2ad_1440w.webp" referrerpolicy="no-referrer"><br>使用CLIP进行zero-shot分类，另外一个比较重要的地方是文本描述的生成，上面的例子我们采用A photo of {label}，但其实也有其它选择，比如我们直接用类别标签，这其实属于最近NLP领域比较火的一个研究：prompt learning或者prompt engineering，具体可以见这篇综述论文：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2107.13586" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2107.13586" target="_blank">Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing</a>，简单来说，prompt learning的核心是通过构建合适prompt（提示）来使预训练模型能够直接应用到下游任务，这和之前的预训练+微调属于不同的范式。论文也说了，如果我们直接采用类别标签作为文本描述，那么很多文本就是一个单词，缺少具体的上下文，而且也和CLIP的训练数据不太一致，效果上会不如采用A photo of {label}（ImageNet数据集上可以提升1.3%）。论文也实验了采用80个不同的prompt来进行集成，发现在ImageNet数据集上能带来3.5%的提升，具体见CLIP公开的<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//github.com/openai/CLIP/blob/main/notebooks/Prompt_Engineering_for_ImageNet.ipynb" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//github.com/openai/CLIP/blob/main/notebooks/Prompt_Engineering_for_ImageNet.ipynb" target="_blank">notebook</a>。下图对比了基于ResNet的CLIP模型直接采用类别名与进行prompt engineering和ensembling的效果对比：<br><img src="https://pic2.zhimg.com/80/v2-cbebe6dfb596bf0c93a4c22c441f17cd_1440w.webp" referrerpolicy="no-referrer"><br>上面我们介绍了如何用CLIP实现zero-shot分类，下面将简单介绍CLIP与其它方法的效果对比，这个也是论文中篇幅最多的内容。首先是CLIP和17年的一篇工作<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1612.09161" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/1612.09161" target="_blank">Learning Visual N-Grams from Web Data</a>的在3个分类数据集上zero-shot效果对比，如下表所示，可以看到CLIP模型在效果上远远超过之前的模型，其中在ImageNet数据集可以达到76.2，这和全监督的ResNet50效果相当，不用任何训练数据就能达到这个效果是相当惊艳的。<br><img src="https://pic1.zhimg.com/80/v2-d3c1c6676c28f75d26029c0cde43ed60_1440w.webp" referrerpolicy="no-referrer"><br>更进一步地，论文还对比了zero-shot CLIP和ResNet50 linear probing（ImageNet数据上预训练，在加上线性分类层进行finetune）在27个数据集上表现，如下图所示，其中在16个数据集上CLIP可以超过ResNet50。但是在一些特别的，复杂的或者抽象的数据集上CLIP表现较差，比如卫星图像分类，淋巴结转移检测，在合成场景中计数等，CLIP的效果不如全监督的ResNet50，这说明CLIP并不是万能的，还是有改进的空间。如果认真看下图的话，CLIP表现较差的竟然还有MNIST数据集，分类准确度只有88%，这是不可思议的，因为这个任务太简单了，通过对CLIP训练数据进行分析，作者发现4亿的训练数据中基本上没有和MNIST比较相似的数据，所以这对CLIP来说就属于域外数据了，表现较差就比较容易理解了。这也表明：CLIP依然无法解决域外泛化这个深度学习难题。<br><img src="https://pic1.zhimg.com/80/v2-dc8ba977117fdec5fd2f79961d7110d4_1440w.webp" referrerpolicy="no-referrer"><br>除了zero-shot对比，论文还对比few-shot性能，即只用少量的样本来微调模型，这里对比了3个模型：在ImageNet21K上训练的BiT-M ResNet-152x2，基于SimCLRv2训练的ResNet50，以及有监督训练的ResNet50。可以看到CLIP的zero-shot和最好的模型（BiT-M）在16-shot下的性能相当，而CLIP在16-shot下效果有进一步的提升。另外一个比较有意思的结果是：虽然CLIP在few-shot实验中随着样本量增加性能有提升，但是1-shot和2-shot性能比zero-shot还差，这个作者认为主要是CLIP的训练和常规的有监督训练存在一定的差异造成的。<br><img src="https://pic3.zhimg.com/80/v2-4d122ef5767f0453121698d4bad08036_1440w.webp" referrerpolicy="no-referrer"><br>除此之外，论文还进行了表征学习（representation Learning）实验，即自监督学习中常用的linear probe：用训练好的模型先提取特征，然后用一个线性分类器来有监督训练。下图为不同模型在27个数据集上的average linear probe score对比，可以看到CLIP模型在性能上超过其它模型，而且计算更高效：<br><img src="https://pic1.zhimg.com/80/v2-42d05e933b46aebf16ba11e2cfce6154_1440w.webp" referrerpolicy="no-referrer"><br>另外，论文还发现CLIP在自然分布漂移上表现更鲁棒，比如CLIP和基于ImageNet上有监督训练的ResNet101在ImageNet验证集都能达到76.2%，但是在ImageNetV2数据集上，CLIP要超过ResNet101。在另外的4个分布漂移的数据集上，ResNet101性能下降得比较厉害，但是CLIP能依然保持较大的准确度，比如在ImageNet-A数据集上，ResNet101性能只有2.7%，而CLIP能达到77.1%。<br><img src="https://pic2.zhimg.com/80/v2-7798ab2d513a0ab79117adcf74d8ec05_1440w.webp" referrerpolicy="no-referrer"><br>CLIP能实现这么好的zero-shot性能，大家很可能质疑CLIP的训练数据集可能包含一些测试数据集中的样例，即所谓的数据泄漏。关于这点，论文也采用一个重复检测器对评测的数据集重合做了检查，发现重合率的中位数为2.2%，而平均值在3.2%，去重前后大部分数据集的性能没有太大的变化，如下所示：<br><img src="https://pic1.zhimg.com/80/v2-dcbbf5bc5e3f0e3ff60155547fd134b8_1440w.webp" referrerpolicy="no-referrer"><br>论文的最后也对CLIP的局限性做了讨论，这里简单总结其中比较重要的几点：<br>
<br>CLIP的zero-shot性能虽然和有监督的ResNet50相当，但是还不如<a data-href="SOTA" href="\project\知识储备\sota.html" class="internal-link" target="_self" rel="noopener nofollow">SOTA</a>，作者估计要达到SOTA的效果，CLIP还需要增加1000x的计算量，这是难以想象的；
<br>CLIP的zero-shot在某些数据集上表现较差，如细粒度分类，抽象任务等；
<br>CLIP在自然分布漂移上表现鲁棒，但是依然存在域外泛化问题，即如果测试数据集的分布和训练集相差较大，CLIP会表现较差；
<br>CLIP并没有解决深度学习的数据效率低下难题，训练CLIP需要大量的数据；
]]></description><link>project\知识储备\clip.html</link><guid isPermaLink="false">Project/知识储备/CLIP.md</guid><pubDate>Sat, 02 Dec 2023 16:25:36 GMT</pubDate><enclosure url="https://pic2.zhimg.com/80/v2-b86361b47d4db80258439b8ad33bdf8d_1440w.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://pic2.zhimg.com/80/v2-b86361b47d4db80258439b8ad33bdf8d_1440w.webp&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[CoCa]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> 
 <br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a><br>
CoCa是一个多模态预训练模型,它可以处理来自不同模态的数据,如图像和文本。<br>CoCa特点:<br>
<br>
使用CNN从图像中提取视觉特征,使用Transformer从文本中提取语言特征。

<br>
在两个编码器之后使用对比学习来对图像和文本进行匹配。

<br>
在预训练过程中,最大限度地区分匹配图像-文本对和不匹配对,实现跨模态表示的学习。

<br>
预训练任务包括检测匹配关系、图像Captioning、文本摘要等。

<br>
预训练过后可以直接用于下游任务,如图像识别、生成、检索等。

<br>模型结构:<br>
<br>
图像编码器:使用ResNet作为CNN backbone提取图像特征。

<br>
文本编码器:使用Transformer编码器处理输入文本。 

<br>
对比学习器:使用Cosine距离来判断图像-文本对是否匹配。

<br>
目标:最小化匹配对距离,最大化不匹配对距离。

<br>优点:<br>
<br>
可直接处理多模态数据,无需单独预训练部分。

<br>
实现了跨模态表达空间的建立与学习。

<br>
在实质上不同任务上都取得优异效果。

<br>总之,CoCa是一种优秀的多模态基础模型,可直接用于多种图像和语言相关下游任务。<br><a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/518265211" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/518265211" target="_blank">CoCa：多模态图像-文本基础模型 - 知乎 (zhihu.com)</a>]]></description><link>project\知识储备\coca.html</link><guid isPermaLink="false">Project/知识储备/CoCa.md</guid><pubDate>Fri, 01 Dec 2023 11:29:56 GMT</pubDate></item><item><title><![CDATA[SOTA]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> 
 <br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a><br>
即目前任务中最好的模型]]></description><link>project\知识储备\sota.html</link><guid isPermaLink="false">Project/知识储备/SOTA.md</guid><pubDate>Tue, 12 Dec 2023 13:59:51 GMT</pubDate></item><item><title><![CDATA[tokens]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> 
 <br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a><br>
对于模型而言，token 是一种数字化的表示形式。每个 token 都与一个唯一的数字 ID 相关联，模型通过这些 ID 来区分不同的 token。在训练过程中，模型学习了将文本映射到这些数字 ID 的方法，以便能够对新的文本进行编码和解码。]]></description><link>project\知识储备\tokens.html</link><guid isPermaLink="false">Project/知识储备/tokens.md</guid><pubDate>Mon, 04 Dec 2023 02:16:37 GMT</pubDate></item><item><title><![CDATA[zero-shot]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> 
 <br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a><br>
零样本学习或零shot学习(Zero-Shot Learning)是一种机器学习任务,其目的是识别训练集中没有出现过的类别。<br>具体来说:<br>
<br>训练样本只包含有限类别,但测试样本可能包含未见过的新类别。<br>

<br>零样本学习的模型需要利用已有类别信息,才能推理新类别的概念并进行分类。<br>

<br>主要思路是:<br>
<br>为每一个类别学习一个独立的语义特征向量。
<br>训练一个映射函数,能将样本映射到语义特征空间中。
<br>测试时,直接根据新类别的语义向量进行分类,而无需实际训练样本。
<br>优点是能够识别学习过程完全没有看到的新类别。这对实际应用很重要,因为新类别总是不断出现。<br>实现零样本学习的主要方法有:<br>
<br>基于属性的方法(Attribute-based)<br>

<br>基于关系的方法(Relational)<br>

<br>密度比例进行匹配(Density Ratio Matching)<br>

<br>它打破了传统分类算法依赖大量标注数据的限制,在语义学习上取得了重要进展。<br>通俗解释如下:<br><br>每次在实验室做工作汇报的时候，总会把ZSL的基本概念讲一遍，但是每次的效果都不是很好，工作都讲完了，提的第一个问题依然是：ZSL到底是什么？这让我一度认为我的表达能力有问题。。。。。。不过回忆起我第一次接触这个题目的时候，也花了挺长的时间才搞清楚到底在做一件什么事情，那篇入门的文章[1]看了很久才基本看懂。因此，我尽量用最简单的，不带任何公式的方式来讲一下这到底是个什么问题。<br>假设小暗（纯粹因为不想用小明）和爸爸，到了动物园，看到了马，然后爸爸告诉他，这就是马；之后，又看到了老虎，告诉他：“看，这种身上有条纹的动物就是老虎。”；最后，又带他去看了熊猫，对他说：“你看这熊猫是黑白色的。”然后，爸爸给小暗安排了一个任务，让他在动物园里找一种他从没见过的动物，叫斑马，并告诉了小暗有关于斑马的信息：“斑马有着马的轮廓，身上有像老虎一样的条纹，而且它像熊猫一样是黑白色的。”最后，小暗根据爸爸的提示，在动物园里找到了斑马（意料之中的结局。。。）。<br>上述例子中包含了一个人类的推理过程，就是利用过去的知识（马，老虎，熊猫和斑马的描述），在脑海中推理出新对象的具体形态，从而能对新对象进行辨认。（如图1所示）ZSL就是希望能够模仿人类的这个推理过程，使得计算机具有识别新事物的能力。<br><img src="https://pic3.zhimg.com/v2-d8efa9870a3ce5ee028277ec57033036_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"><br>图1 ZSL概念图[17]<br>如今深度学习非常火热，使得纯监督学习在很多任务上都达到了让人惊叹的结果，但其限制是：往往需要足够多的样本才能训练出足够好的模型，并且利用猫狗训练出来的分类器，就只能对猫狗进行分类，其他的物种它都无法识别。 这样的模型显然并不符合我们对人工智能的终极想象，我们希望机器能够像上文中的小暗一样，具有通过推理，识别新类别的能力。<br>ZSL就是希望我们的模型能够对其从没见过的类别进行分类，让机器具有推理能力，实现真正的智能。其中零次（Zero-shot）是指对于要分类的类别对象，一次也不学习。这样的能力听上去很具有吸引力，那么到底是怎么实现的呢？<br>假设我们的模型已经能够识别马，老虎和熊猫了，现在需要该模型也识别斑马，那么我们需要像爸爸一样告诉模型，怎样的对象才是斑马，但是并不能直接让模型看见斑马。 所以模型需要知道的信息是马的样本、老虎的样本、熊猫的样本和样本的标签，以及关于前三种动物和斑马的描述。将其转换为常规的机器学习，这里我们只讨论一般的图片分类问题：<br>（1）训练集数据X{tr}&nbsp;及其标签&nbsp;Y{tr}&nbsp;，包含了模型需要学习的类别（马、老虎和熊猫），这里和传统的监督学习中的定义一致；<br>（2）测试集数据X{te}及其标签Y{te}&nbsp;，包含了模型需要辨识的类别（斑马），这里和传统的监督学习中也定义一直；<br>（3）训练集类别的描述&nbsp;<img alt="A_{tr}" src="https://www.zhihu.com/equation?tex=A_%7Btr%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，以及测试集类别的描述&nbsp;<img alt="A_{te}" src="https://www.zhihu.com/equation?tex=A_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;；我们将每一个类别&nbsp;<img alt="y_{i}\in Y" src="https://www.zhihu.com/equation?tex=y_%7Bi%7D%5Cin+Y&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，都表示成一个语义向量&nbsp;<img alt="a_{i}\in A" src="https://www.zhihu.com/equation?tex=a_%7Bi%7D%5Cin+A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;的形式，而这个语义向量的每一个维度都表示一种高级的属性，比如“黑白色”、“有尾巴”、“有羽毛”等等，当这个类别包含这种属性时，那在其维度上被设置为非零值。对于一个数据集来说，语义向量的维度是固定的，它包含了能够较充分描述数据集中类别的属性。<br>在ZSL中，我们希望利用&nbsp;X{tr}&nbsp;和Y{tr}&nbsp;来训练模型，而模型能够具有识别X{te}的能力，因此模型需要知道所有类别的描述&nbsp;![A{tr}](<a rel="noopener nofollow" class="external-link" href="https://www.zhihu.com/equation?tex=A_%7Btr%7D&amp;consumer=ZHI_MENG" target="_blank">https://www.zhihu.com/equation?tex=A_%7Btr%7D&amp;consumer=ZHI_MENG</a>)&nbsp;和&nbsp;<img alt="A_{te}" src="https://www.zhihu.com/equation?tex=A_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;。ZSL这样的设置其实就是上文中小暗识别斑马的过程中，爸爸为他提供的条件。<br><img src="https://pic2.zhimg.com/v2-33a9764b792911eedce07dd4974e46f5_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"><br>图2 ZSL设置图[16]<br>如图2，可以较为直观地了解ZSL的设置。<br>讲到这，很多同学可能会问：<br>（1）类别的描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;到底是怎么获取的？<br>答：有人工专家定义的，也有通过海量的附加数据集自动学习出来的，但前者的效果目前要好很多。<br>（2）这样做让人觉得有点失望呀！我希望模型能够在没有斑马样本的情况下，识别斑马，而现在，虽然我不需要为模型提供斑马的样本，但是却要为每一个类别添加一种描述，更离谱的是我还需要斑马（测试集）的描述，这个过程并没有想象中智能诶！<br>答：的确，在我们的想象中，我们期待的智能是：只给机器马、老虎和熊猫，然后它就可以识别斑马了，这样多爽，多神奇。但我们回过头去，再想想小暗的思考过程，如果爸爸不告诉小暗关于斑马的任何信息，那么当小暗看见斑马的时候，并不会知道它是什么，只是小暗能够描述它：“这是一匹有着黑白颜色条纹的马。”这里，有同学可能又会说：至少我们可以不用告诉小暗类别的描述呀，但是ZSL就不行。其实，我们是需要告诉小暗类别描述的，或者说小暗在之前就学习到了类别描述，比如怎样的图案是“条纹”，怎样的颜色称为“黑白色”，这样的属性定义。对于一个模型来说，它就像刚出生的婴儿，我们需要教会它这些属性的定义。<br>（3）就算是这样，需要实现定义这个描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;还是很蛋疼的一件事情。<br>答：（1）中就有提到，描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;可以自动学习，我们将小暗已经掌握的知识描述为一个知识库，这个知识库里就有对各种属性的定义；而能够模仿人类知识库的最好东西就是“百度百科”，“维基百科”等等各种百科，我们可以利用百科中的各种定义，生成类别的定义，这方面侧重于NLP，因此不进一步讨论。<br>在此，我们小小总结一下ZSL问题的定义。利用训练集数据训练模型，使得模型能够对测试集的对象进行分类，但是训练集类别和测试集类别之间没有交集；期间需要借助类别的描述，来建立训练集和测试集之间的联系，从而使得模型有效。<br><br>在上文中提到，要实现ZSL功能似乎需要解决两个部分的问题：第一个问题是获取合适的类别描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;；第二个问题是建立一个合适的分类模型。<br>目前大部分工作都集中在第二个问题上，而第一个问题的研究进展比较缓慢。个人认为的原因是， 目前<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;的获取主要集中于一些NLP的方法，而且难度较大；而第二个问题能够用的方法较多，比较容易出成果。<br>因此，接下来的算法部分，也只介绍研究分类模型的方法。<br><br>先介绍数据集，是因为希望在算法介绍部分，直接给出实例，让大家能够直接上手，这里顺便插个沐神&nbsp;<a data-tooltip-position="top" aria-label="https://www.zhihu.com/people/13fd0fce2affd948bfd821a8f7ed10f3" rel="noopener nofollow" class="external-link" href="https://www.zhihu.com/people/13fd0fce2affd948bfd821a8f7ed10f3" target="_blank">@李沐</a>&nbsp;的感悟。<br>
虽然在我认识的人里，好些人能够读一篇论文或者听一个报告后就能问出很好的问题，然后就基本弄懂了。但我在这个上笨很多。读过的论文就像喝过的水，第二天就不记得了。一定是需要静下心来，从头到尾实现一篇，跑上几个数据，调些参数，才能心安地觉得懂了。例如在港科大的两年读了很多论文，但现在反过来看，仍然记得可能就是那两个老老实实动手实现过写过论文的模型了。即使后来在机器学习这个方向又走了五年，学习任何新东西仍然是要靠动手。——李沐（MXNet开发者）
<br>（1）Animal with Attributes（AwA）官网：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//cvml.ist.ac.at/AwA/" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//cvml.ist.ac.at/AwA/" target="_blank">Animals with Attributes</a><br>提出ZSL定义的作者，给出的数据集，都是动物的图片，包括50个类别的图片，其中40个类别作为训练集，10个类别作为测试集，每个类别的语义为85维，总共有30475张图片。但是目前由于版权问题，已经无法获取这个数据集的图片了，作者便提出了AwA2，与前者类似，总共37322张图片。<br>（2）Caltech-UCSD-Birds-200-2011（CUB）官网：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=http%3A//www.vision.caltech.edu/visipedia/CUB-200-2011.html" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=http%3A//www.vision.caltech.edu/visipedia/CUB-200-2011.html" target="_blank">Caltech-UCSD Birds-200-2011</a><br>全部都是鸟类的图片，总共200类，150类为训练集，50类为测试集，类别的语义为312维，有11788张图片。<br>（3）Sun database（SUN）官网：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=http%3A//groups.csail.mit.edu/vision/SUN/" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=http%3A//groups.csail.mit.edu/vision/SUN/" target="_blank">SUN Database</a><br>总共有717个类别，每个类别20张图片，类别语义为102维。传统的分法是训练集707类，测试集10类。<br>（4）Attribute Pascal and Yahoo dataset（aPY）官网：<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=http%3A//vision.cs.uiuc.edu/attributes/" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=http%3A//vision.cs.uiuc.edu/attributes/" target="_blank">Describing Objects by their Attributes</a><br>共有32个类，其中20个类作为训练集，12个类作为测试集，类别语义为64维，共有15339张图片。<br>（5）ILSVRC2012/ILSVRC2010（ImNet-2）<br>利用ImageNet做成的数据集，由ILSVRC2012的1000个类作为训练集，ILSVRC2010的360个类作为测试集，有254000张图片。它由 4.6M 的Wikipedia数据集训练而得到，共1000维。<br>上述数据集中（1）-（4）都是较小型（small-scale）的数据集，（5）是大型（large-scale）数据集。虽然（1）-（4）已经提供了人工定义的类别语义，但是有些作者也会从维基语料库中自动提取出类别的语义表示，来检测自己的模型。<br>这里给大家提供一些已经用GoogleNet提取好的数据集图片特征，大家可以比较方便地使用。<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/29807635" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/29807635" target="_blank">Zero-Shot Learing问题数据集分享（GoogleNet 提取）</a><br><br>在此，只具体介绍最简单的方法，让大家可以快速上手。我们面对的是一个图片分类问题，即对测试集的样本X{te}进行分类，而我们分类时需要借助类别的描述&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，由于每一个类别&nbsp;![y{i}\in Y](<a rel="noopener nofollow" class="external-link" href="https://www.zhihu.com/equation?tex=y_%7Bi%7D%5Cin+Y&amp;consumer=ZHI_MENG" target="_blank">https://www.zhihu.com/equation?tex=y_%7Bi%7D%5Cin+Y&amp;consumer=ZHI_MENG</a>)&nbsp;，都对应一个语义向量&nbsp;<img alt="a_{i}\in A" src="https://www.zhihu.com/equation?tex=a_%7Bi%7D%5Cin+A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，因此我们现在可以忘掉&nbsp;<img alt="Y" src="https://www.zhihu.com/equation?tex=Y&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，直接使用&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;。我们把&nbsp;<img alt="X" src="https://www.zhihu.com/equation?tex=X&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;（利用深度网络提取的图片特征，比如GoogleNet提取为1024维）称为特征空间（visual feature space），把类别的语义表示&nbsp;<img alt="A" src="https://www.zhihu.com/equation?tex=A&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，称为语义空间。我们要做的，其实就是建立特征空间与语义空间之间的映射。<br>对于分类，我们能想到的最简单的形式就是<a data-href="岭回归" href="\project\知识储备\岭回归.html" class="internal-link" target="_self" rel="noopener nofollow">岭回归</a>（ridge regression），俗称均方误差加范数约束，具体形式为：<br><img alt="min||X_{tr}W - A_{tr}||^{2}+\eta\Omega(W)" src="https://www.zhihu.com/equation?tex=min%7C%7CX_%7Btr%7DW+-+A_%7Btr%7D%7C%7C%5E%7B2%7D%2B%5Ceta%5COmega%28W%29&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;(1)<br>其中，&nbsp;<img alt="\Omega()" src="https://www.zhihu.com/equation?tex=%5COmega%28%29&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;通常为2范数约束，&nbsp;<img alt="\eta" src="https://www.zhihu.com/equation?tex=%5Ceta&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;为超参，对&nbsp;<img alt="W" src="https://www.zhihu.com/equation?tex=W&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;求导，并让导为0，即可求出&nbsp;<img alt="W" src="https://www.zhihu.com/equation?tex=W&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;的值。测试时，利用&nbsp;<img alt="W" src="https://www.zhihu.com/equation?tex=W&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;将&nbsp;<img alt="x_{i}\in X_{te}" src="https://www.zhihu.com/equation?tex=x_%7Bi%7D%5Cin+X_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;投影到语义空间中，并在该空间中寻找到离它最近的&nbsp;<img alt="a_{i}\in A_{te}" src="https://www.zhihu.com/equation?tex=a_%7Bi%7D%5Cin+A_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;，则样本的类别为&nbsp;<img alt="a_{i}" src="https://www.zhihu.com/equation?tex=a_%7Bi%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;所对应的标签&nbsp;<img alt="y_{i}\in Y_{tr}" src="https://www.zhihu.com/equation?tex=y_%7Bi%7D%5Cin+Y_%7Btr%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;。<br>简单写一个matlab实现。<br>regression_lambda = 1.0;
W = ridge_regression(param.train_set, param.train_class_attributes, regression_lambda , 1024);
S_test = param.test_set * W;
[zsl_accuracy]= zsl_el(S_test, param.S_te, param); 
fprintf('AwA ZSL accuracy on test set: %.1f%%\n', zsl_accuracy*100);
<br>我们使用AwA数据集，图片事先利用GoogleNet提取了特征（1024维），在测试集上可以得到59.1%的准确率。<br>这样一个岭回归之所以有效，是因为训练集类别语义&nbsp;<img alt="A_{tr}" src="https://www.zhihu.com/equation?tex=A_%7Btr%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;与测试集类别语义&nbsp;<img alt="A_{te}" src="https://www.zhihu.com/equation?tex=A_%7Bte%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;之间存在的密切联系。其实任何ZSL方法有效的基础，都是因为这两者之间具体的联系。<br>仅仅利用如此naive的方式，得到的结果显然不能满足我们的要求，那么建立更好的模型，则需要进一步了解ZSL问题中，存在着哪些和传统监督分类的差异。<br><br>在此，介绍一些目前ZSL中主要存在的问题，以便让大家了解目前ZS领域有哪些研究点。<br>领域漂移问题（domain shift problem）<br>该问题的正式定义首先由[2]提出。简单来说，就是同一种属性，在不同的类别中，视觉特征的表现可能很大。如图3所示，斑马和猪都有尾巴，因此在它的类别语义表示中，“有尾巴”这一项都是非0值，但是两者尾巴的视觉特征却相差很远。如果斑马是训练集，而猪是测试集，那么利用斑马训练出来的模型，则很难正确地对猪进行分类。<br><img src="https://pic3.zhimg.com/v2-733de891fa7f478740b35228dad776c2_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"><br>图3 domain shift示意图，图中的prototype表示类别在语义空间中的位置[2]<br>枢纽点问题（Hubness problem）<br>这其实是高维空间中固有的问题：在高维空间中，某些点会成为大多数点的最近邻点。这听上去有些反直观，细节方面可以参考[3]。由于ZSL在计算最终的正确率时，使用的是K-NN，所以会受到hubness problem的影响，并且[4]中，证明了基于岭回归的方法会加重hubness problem问题。<br>语义间隔（semantic gap）<br>样本的特征往往是视觉特征，比如用深度网络提取到的特征，而语义表示却是非视觉的，这直接反应到数据上其实就是：样本在特征空间中所构成的流型与语义空间中类别构成的流型是不一致的。（如图4所示）<br><img src="https://pic3.zhimg.com/v2-869ec7e6e0f91229f8f66997ce59123a_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"><br>图4 流型不一致示意图[8]<br>这使得直接学习两者之间的映射变得困难。<br>还有其他的，比如semantic loss[5]问题，样本通过映射坍塌到一点[6]等，由于还不常研究，在此就不再讨论。<br>在此，我们给出解决上述三个问题的基本方法，从而更加深度地了解这三个问题。<br>（1）领域漂移<br>由于样本的特征维度往往比语义的维度大，所以建立从&nbsp;<img alt="X" src="https://www.zhihu.com/equation?tex=X&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;到&nbsp;<img alt="S" src="https://www.zhihu.com/equation?tex=S&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;的映射往往会丢失信息，为了保留更多的信息，保持更多的丰富性，最流行的做法是将映射到语义空间中的样本，再重建回去，这样学习到的映射就能够得到保留更多的信息。因此，在原来简单岭回归[1]的基础上，可以将目标函数改为：[7]<br><img alt="min||X_{tr} - W^{T}A_{tr}||^{2}+\lambda ||WX_{tr} - A_{tr}||^{2}" src="https://www.zhihu.com/equation?tex=min%7C%7CX_%7Btr%7D+-+W%5E%7BT%7DA_%7Btr%7D%7C%7C%5E%7B2%7D%2B%5Clambda+%7C%7CWX_%7Btr%7D+-+A_%7Btr%7D%7C%7C%5E%7B2%7D&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;(2)<br>从目标函数可以看出，这其实完成的是一个简易的自编码器过程，我们简称这个算法为SAE，利用matlab可以轻松对其实现。<br>lambda1 = 800000;
W = SAE(param.train_set', param.train_class_attributes', lambda1);
S_test = param.test_set * NormalizeFea(W');
[zsl_accuracy]= zsl_el(S_test, param.S_te, param); 
fprintf('AwA ZSL accuracy on test set: %.1f%%\n', zsl_accuracy*100);
<br>依然是在AwA上进行测试，可以得到83.2%的准确率，比简单的岭回归(1)提高了24.1%。自编码器的这个结构目前在ZSL方法中非常流行，稍后我们还会提到。<br>（2）枢纽点问题<br>目前对于枢纽点问题的解决主要有两种方法：<br>a. 如果模型建立的方式为岭回归，那么可以建立从语义空间到特征空间的映射，从而不加深hubness problem对结果的影响[4]，也就是说将目标函数（1）改为：<br><img alt="min||X_{tr} - A_{tr}W||^{2}+\eta\Omega(W)" src="https://www.zhihu.com/equation?tex=min%7C%7CX_%7Btr%7D+-+A_%7Btr%7DW%7C%7C%5E%7B2%7D%2B%5Ceta%5COmega%28W%29&amp;consumer=ZHI_MENG" referrerpolicy="no-referrer">&nbsp;(3)<br>在AwA数据集上，这种简单的改变能够得到76.5%的正确率，比原本提高了17.4%。<br>b.可以使用生成模型，比如自编码器、GAN等，生成测试集的样本，这样就变成了一个传统的监督分类问题，不存在K-NN的操作，所以不存在hubness problem的影响。<br>（3）语义间隔问题<br>语义间隔问题的本质是二者的流形结构不一致，因此，解决此问题的着手点就在于将两者的流形调整到一致，再学习两者之间的映射[8]。最简单的方法自然是将类别的语义表示调整到样本的流型上，即用类别语义表示的K近邻样本点，重新表示类别语义即可。<br><br>这里将提到一些ZSL涉及到的其他概念。<br>（1）直推式学习（Transductive setting）<br>这里的直推式学习其实是指在训练模型的时候，我们可以拿到测试集的数据，只是不能拿到测试集的样本的标签，因此我们可以利用测试集数据，得到一些测试集类别的先验知识。这种设置在迁移学习中很常见。<br><img src="https://pic4.zhimg.com/v2-7a2f3465bcf020ccb2f0375d86fd4943_b.webp?consumer=ZHI_MENG" referrerpolicy="no-referrer"><br>图5 非直推式（inductive）和直推式学习的区别[16]<br>（2）泛化的ZSL（generalized ZSL）<br>上文中提到的ZSL，在测试时使用K-NN进行正确率的评估时，只在测试类别中找最近邻的类别，但是在现实的问题中，拿到的样本也可能属于训练集类别，因此在测试时，同时加入训练集类别。[9]现在的很多方法都开始测试模型在这种设置下的能力。<br><br>我一直不想写ZSL的发展史，因为据我的经验，写了一大段发展史之后，往往大家的兴致不高，而且看完之后一般都不会有什么特别的感觉，基本也记不得什么东西。所以倒不如给大家推荐一些论文，从最早的到目前最新的，使得大家在短时间内能对ZSL的发展有一个大概的概念。<br>（1）Learning To Detect Unseen Object Classes by Between-Class Attribute Transfer[1]<br>ZSL问题的开创性文章，当然是必读的喽，而且可以顺便看看别人是如何阐述一个新问题（挖坑）的。<br>（2）An embarrassingly simple approach to zero-shot learning[10]<br>有着很强的理论基础，算法简单、有效，虽然已经过去很多年了，但还是目前新工作需要进行对比的方法之一。<br>（3）Transductive Multi-View Zero-Shot Learning[2]<br>第一次定义了domain shift问题。<br>（4）Zero-shot recognition using dual visualsemantic mapping paths[11]<br>解决semantic gap问题的简单做法。<br>（5）Predicting visual exemplars of unseen classes for zero-shot learning[12]<br>从本质的角度出发，将ZSL问题，看作聚类问题，用最简单的方法直接建立映射。<br>（6）Semantic Autoencoder for Zero-Shot Learning[7]<br>引入自编码器结构的第一篇文章，直接导致现在出现的新方法大都具有这种结构。<br>（7）Zero-Shot Learning - A Comprehensive Evaluation of the Good, the Bad and the Ugly[14]<br>综述性的文章，总结了17年底以前的方法，提出了新的评价标准，对当时领域发展比较混乱的地方做出了一些更标准的评估。<br>（8）Zero-Shot Learning via Class-Conditioned Deep Generative Models[6]<br>将[7]改造为深度模型，并加上一些其他的约束。<br>（9）Preserving Semantic Relations for Zero-Shot Learning[13]<br>在自编码器结构的基础上，显示地加入语义类别之间的关系约束。<br>（10）Recent Advances in Zero-shot Recognition[15]<br>综述性的文章，读起来很顺畅，可以看看别人是怎么写综述，中顶刊的。<br>以上几篇文章，是我认为较有代表性，比较值得读的工作。]]></description><link>project\知识储备\zero-shot.html</link><guid isPermaLink="false">Project/知识储备/zero-shot.md</guid><pubDate>Fri, 01 Dec 2023 11:29:45 GMT</pubDate><enclosure url="https://pic3.zhimg.com/v2-d8efa9870a3ce5ee028277ec57033036_b.webp?consumer=ZHI_MENG" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://pic3.zhimg.com/v2-d8efa9870a3ce5ee028277ec57033036_b.webp?consumer=ZHI_MENG&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[想法]]></title><description><![CDATA[ 
 <br>我们现在想法太宽泛，卷积神经网络的什么基本先别想，都不具体。我们需要把问题具体化，我们就做两件事，简化问题，然后把问题数学建模。下面是我的一个简化思路。<br><br>假设我们现在就是尽量解决城市堵车问题。<br>
假设我们现在有城市所有路线图。<br>
我们假定某些建筑作为车流的出入点，比如整座城市的停车场位置我们清楚，停车场和居民区作为车流的主要出入点。流量可以给，也可以不给。<br>
我们假定一条路被分为三个部分，左转右转和直行。<br>
我们假定如果出了车祸，将会堵塞两条车道。<br>
假定一个平均车速和平均车距。<br>
假定对于一条路，即从一个红绿灯到另一个红绿灯这一段路，这段路的流出量小于流入量即认为这条路将会堵车，差值越大堵得越快。这边可以计算一个堵车时间用于车流的路径规划。<br>
假定当一条路从头到尾全部停满，则认为彻底堵了，并将进入该路段的车道流出量降为0<br>
假定我们有交通信号灯的停止时间控制权，我们有汽车的路径规划权。<br>
假定汽车出发时按最短路径驶向目的地。<br><br>我们去分析城市堵车的原因，堵车有两种情况。<br>一种是因为意外比如车祸造成了道路堵塞。这种往往属于意外很快发生难以反应，很快这条路就堵了。我们可以以车祸点看为节点，将一条路分成两条，由于分割后的后面一条路只有一个车道作为出口，流出量明显降低造成堵塞。<br>一种是因为车流量太大造成的堵塞，由于车辆起步速度差不多，车流出量基本由红绿灯的绿灯时间决定。流入量由上一个红绿灯决定。所以这种情况往往是可控的也是我们优化的目标。我们要去控制每一条路都保证是收支平衡的。<br>如何控制收支平衡，我们去控制每个红绿灯节点的时间，达到调节流量的目的，但这个时间是有个阈值的，比如不能超过两分钟。我们控制车流的路径，提前避开将要堵车的路段。<br>整个效果的衡量标准可以按通勤平均时间来。<br>天气因素等等无非是影响一下车流车速间距等事故发生率等参数]]></description><link>project\challenge-cup-交通系统优化\想法.html</link><guid isPermaLink="false">Project/Challenge Cup -交通系统优化/想法.md</guid><pubDate>Wed, 05 Jun 2024 14:00:17 GMT</pubDate></item><item><title><![CDATA[思路]]></title><description><![CDATA[ 
 <br><br><br><br>
<br>目标：优化交通系统，提高交通流畅度，减少拥堵。
<br>关键指标：车辆行驶时间、交通流量、车辆等待时间、交通事故率等。
<br><br>
<br>交通流量数据：摄像头、传感器、GPS 设备等提供的实时交通数据。
<br>路网结构数据：包括道路、交叉口、信号灯等信息。
<br>历史交通数据：过去的交通流量、事故、天气情况等。
<br><br><br>
<br>处理缺失数据和异常值。
<br>数据格式转换和规范化。
<br><br>
<br>将不同来源的数据进行融合，例如将实时交通数据和历史数据结合，构建全面的交通信息数据库。
<br><br><br>
<br>节点：城市道路网络中的交叉口、重要路段或其他关键点。
<br><br>
<br>边：表示节点之间的道路，边的权重可以根据交通流量、道路长度、行驶时间等进行定义。
<br><br>
<br>时空属性：每条边的权重会随着时间和空间的变化而变化，反映实时交通状况。
<br><br><br>
<br>提取时空特征，例如交通流量的变化趋势、交通事件的时空分布等。
<br><br>
<br>图神经网络 (GNN)：适用于处理图结构数据，能有效捕捉交通网络中的时空关系。
<br>时序模型：如LSTM、GRU，用于捕捉交通流量的时间序列特征。
<br><br><br>
<br>将数据划分为训练集、验证集和测试集。
<br><br>
<br>使用训练集训练模型，调整参数优化性能。
<br><br>
<br>在验证集上评估模型性能，避免过拟合。
<br>在测试集上进行最终评估，确保模型的泛化能力。
<br><br><br>
<br>实时交通信号控制：根据实时交通流量动态调整信号灯配时。
<br>路径规划建议：为车辆提供实时最佳行驶路径。
<br><br>
<br>基础设施改进：根据长期交通数据分析，提出道路扩建、公共交通改进等建议。
<br>政策制定：如限行措施、高峰期收费等。
<br><br><br>
<br>构建数据采集、处理、存储和分析的完整系统架构。
<br><br>
<br>将模型和优化策略部署到实际交通管理系统中，实现自动化控制和实时监测。
<br><br>
<br>进行系统测试，收集反馈，不断优化模型和策略。
<br><br><br>
<br>收集部署后的数据，评估系统优化效果，是否达到预期目标。
<br><br>
<br>根据评估结果和反馈，不断改进模型和优化策略，提升系统性能。
<br>通过以上步骤，可以系统化地利用动态时空图优化智慧城市交通系统，实现交通管理的智能化和高效化。<br><br>以下是一些关于利用动态时空图优化智慧城市交通系统的相关文献。这些文献涵盖了图神经网络、时空数据分析、交通系统优化等方面的研究，可以为你的研究提供参考。<br><br>
<br>
Wu, Z., Pan, S., Chen, F., Long, G., Zhang, C., &amp; Yu, P. S. (2020). A Comprehensive Survey on Graph Neural Networks. IEEE Transactions on Neural Networks and Learning Systems.

<br>这篇文章全面综述了图神经网络的发展和应用，包括在时空数据分析中的应用。
<br><a data-tooltip-position="top" aria-label="https://doi.org/10.1109/TNNLS.2020.2978386" rel="noopener nofollow" class="external-link" href="https://doi.org/10.1109/TNNLS.2020.2978386" target="_blank">DOI: 10.1109/TNNLS.2020.2978386</a>


<br>
Li, Y., Yu, R., Shahabi, C., &amp; Liu, Y. (2018). Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting. In Proceedings of the International Conference on Learning Representations (ICLR).

<br>介绍了扩散卷积递归神经网络（DCRNN），一种结合了图卷积和递归神经网络的模型，用于交通流量预测。
<br><a data-tooltip-position="top" aria-label="https://openreview.net/forum?id=SJiHXGWAZ" rel="noopener nofollow" class="external-link" href="https://openreview.net/forum?id=SJiHXGWAZ" target="_blank">Paper Link</a>


<br><br>
<br>
Yao, H., Tang, X., Wei, H., Zheng, G., Li, Z., &amp; Gong, Y. (2019). Revisiting Spatial-Temporal Similarity: A Deep Learning Framework for Traffic Prediction. In Proceedings of the AAAI Conference on Artificial Intelligence.

<br>提出了一个深度学习框架，结合了时空相似性，用于交通预测。
<br><a data-tooltip-position="top" aria-label="https://aaai.org/ojs/index.php/AAAI/article/view/4451" rel="noopener nofollow" class="external-link" href="https://aaai.org/ojs/index.php/AAAI/article/view/4451" target="_blank">Paper Link</a>


<br>
Jin, X., Xu, C., &amp; Gao, J. (2020). Urban traffic prediction from spatio-temporal data using deep meta learning. In Proceedings of the 26th ACM SIGKDD International Conference on Knowledge Discovery &amp; Data Mining (KDD).

<br>介绍了利用深度元学习进行城市交通预测的方法，结合了时空数据。
<br><a data-tooltip-position="top" aria-label="https://doi.org/10.1145/3394486.3403311" rel="noopener nofollow" class="external-link" href="https://doi.org/10.1145/3394486.3403311" target="_blank">DOI: 10.1145/3394486.3403311</a>


<br><br>
<br>
Zheng, Y., Liu, F., &amp; Hsieh, H. P. (2013). U-Air: When urban air quality inference meets big data. In Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD).

<br>探讨了大数据在城市空气质量推断中的应用，相关方法也适用于交通流量预测。
<br><a data-tooltip-position="top" aria-label="https://doi.org/10.1145/2487575.2488188" rel="noopener nofollow" class="external-link" href="https://doi.org/10.1145/2487575.2488188" target="_blank">DOI: 10.1145/2487575.2488188</a>


<br>
Wang, D., Zhang, F., Zhang, L., &amp; Wang, Z. (2016). A Survey on Human Mobility and its Applications. ACM Computing Surveys (CSUR).

<br>综述了人类移动性研究及其在智慧城市交通系统中的应用。
<br><a data-tooltip-position="top" aria-label="https://doi.org/10.1145/2893471" rel="noopener nofollow" class="external-link" href="https://doi.org/10.1145/2893471" target="_blank">DOI: 10.1145/2893471</a>


<br><br>
<br>
Chen, C., Jiang, L., &amp; Yin, L. (2019). A Deep Learning Model for Urban Traffic Flow Prediction with Traffic-Big Data. In Proceedings of the 28th International Joint Conference on Artificial Intelligence (IJCAI).

<br>提出了一个基于深度学习的城市交通流预测模型，利用大数据进行训练。
<br><a data-tooltip-position="top" aria-label="https://doi.org/10.24963/ijcai.2019/744" rel="noopener nofollow" class="external-link" href="https://doi.org/10.24963/ijcai.2019/744" target="_blank">DOI: 10.24963/ijcai.2019/744</a>


<br>
Lv, Y., Duan, Y., Kang, W., Li, Z., &amp; Wang, F. Y. (2015). Traffic Flow Prediction with Big Data: A Deep Learning Approach. IEEE Transactions on Intelligent Transportation Systems.

<br>使用深度学习方法进行交通流预测，基于大规模交通数据。
<br><a data-tooltip-position="top" aria-label="https://doi.org/10.1109/TITS.2014.2345663" rel="noopener nofollow" class="external-link" href="https://doi.org/10.1109/TITS.2014.2345663" target="_blank">DOI: 10.1109/TITS.2014.2345663</a>


]]></description><link>project\challenge-cup-交通系统优化\thinking.html</link><guid isPermaLink="false">Project/Challenge Cup -交通系统优化/Thinking.md</guid><pubDate>Thu, 30 May 2024 10:34:32 GMT</pubDate></item><item><title><![CDATA[国外案例]]></title><description><![CDATA[ 
 <br>好的，我将为你汇总近十年内的真实国外网络暴力案例，确保案例数大于三十，并形成表格。表格包含时间、舆情事件、舆情事件类型和表现形式。以下是一些知名的案例：<br><br>此表格包含了每个事件的时间、类型和表现形式，满足了你所需要的要求。]]></description><link>project\challenge-cup-网络暴力治理\国外案例.html</link><guid isPermaLink="false">Project/Challenge Cup-网络暴力治理/国外案例.md</guid><pubDate>Thu, 23 May 2024 08:53:56 GMT</pubDate></item><item><title><![CDATA[技术]]></title><description><![CDATA[ 
 <br><br>
<br>侮辱词知识增强（Toxic Knowledge Enhancement，TKE）：此技术通过整合词汇特征来丰富原始句子表示。具体方法包括创建侮辱词嵌入，通过判断一个词是否是侮辱词的子词来表示不同类别的侮辱词。
<br><br>
<br>
双向长短期记忆网络（BiLSTM）：该模型使用来自腾讯AI Lab的静态词向量来整合上下文信息。最终的句子嵌入通过将前向和后向的最后隐藏状态连接起来获得

<br>
BERT（双向编码器表示）：该模型使用编码器的池化输出作为输入，进行分类。论文中使用了中文BERT模型。

<br>
RoBERTa（鲁棒优化的BERT方法）：与BERT类似，使用编码器的池化输出进行分类，使用的是中文RoBERTa模型。

<br>
百度文本审核：这是一个在线API，主要基于关键词词典来识别侮辱性内容。该API用于二元有毒识别子任务，但其性能较深度学习模型低。

<br>实验结果显示，深度学习模型，特别是基于Transformer的模型如BERT和RoBERTa，优于传统方法如百度文本审核。]]></description><link>project\challenge-cup-网络暴力治理\技术.html</link><guid isPermaLink="false">Project/Challenge Cup-网络暴力治理/技术.md</guid><pubDate>Wed, 05 Jun 2024 10:39:12 GMT</pubDate></item><item><title><![CDATA[题目及思路]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目/个人项目/挑战杯" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/挑战杯</a> 
 <br><a href=".?query=tag:项目\个人项目\挑战杯" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/挑战杯</a> <br><br>主题：数字时代网络暴力信息的风险治理路径<br>伴随着网络信息技术的创新、个人信息保护的重要性等社会经济技术基础和要素发生变化，近年来网络暴力致人自杀、伤亡等恶性事件愈发频繁，网络暴力信息治理也愈发迫切。<br>
网络暴力是一种群体情绪激化行为，往往与网络谣言、网络诈骗、个人信息泄露、“开盒挂人”等违法违规行为密切相关。同时，由于网络水军等网络黑灰产的推波助澜，网络暴力已经严重影响整个网络信息内容生态体系的安全性和稳定性。<br>
虽然我国已相继出台《关于依法惩治网络暴力违法犯罪的指导意见》《关于切实加强网络暴力治理的通知》等法律法规和政策文件，但是由于违法成本低、维权成本高、施暴者身份难以确定、法律威慑力不足等因素，网络暴力信息的治理实效有所欠缺。因此，网络暴力信息的治理不能仅依靠立法，需要更加多元化的治理方式实现体系性的风险预防和控制。<br>
请以下列要点为主要内容，针对数字时代网络暴力信息的风险治理问题，创新研究方法、研究思路、研究模式，开展规范、系统、可落地、可操作的具体方案研究：<br>
<br>研究网络暴力信息的呈现方式、认定标准、具体类型等；
<br>研究网络暴力信息的形成原因、产生机理、演变过程、影响因素、重点关键环节等；
<br>研究特殊主体在网络暴力信息传播中的识别预判、角色定位、作用影响等；
<br>研究网络平台在网络暴力信息治理中的责任内容、功能作用、义务边界、创新工具等；
<br><br>主题是数字时代网络暴力信息的风险治理路径，那么重点在于网络暴力信息和风险治理路径。即对网络暴力信息的判断，与一个可行的具体的解决策略或者法案。<br>那么如何判断一个话题是否有网络暴力因素或者有会发展成网络暴力的潜力？主要在于公众参与度、话题负面性。论文里还有个媒体参与度我觉得没有意义，媒体参与度跟公众参与度基本正相关。然后论文里用的是贝叶斯网，得出的效果其实并不好，因为朴素贝叶斯是要求各因素后验概率是相互独立的，这里明显多因素是互相有关联的。<br>公众关注度主要包括普通网民及自媒体平台大 V（意见领袖）的微博评论数、转发数、发博数等条件来决定，大 V 的意见往往能带来很大的影响，对普通网民产生巨大舆论引导力量。<br>话题负面性是由话题的敏感性和话题言语暴力性来决定，话题敏感性是指话题中出现敏感性高的因素，成为负面话题的可能性较大，话题言语充满暴力性就是负面性话题。这里涉及到文本的语义分析，数据量不够的话不好做的，数据量够我们也没算力。估计只能做关键词判断，比如有暴力或侮辱字眼的就判为暴力信息。这些字眼需要尽可能全。<br>以上信息可以训练出一个模型，用来判断一个话题是否是网络暴力。当然效果不一定好，论文里的效果很差。我觉得我们数据量不会太大的情况下多用几个基础模型bagging一下应该效果比论文里好点。<br>可行方案，网络暴力事件和所有犯罪事件一样，最好的方案还是预防，网络暴力事件一般需要一定的发展时间，最好在发展初期将其封禁。那么可以监测每一个话题的网络暴力概率，这个概率随着评论里的暴力、阴阳的暴力元素越多、转发数越多而增加，到一定阈值进行话题封禁并检索相关内容进行封禁。至于对网络用户个体的约束等等法规那跟我专业无关。]]></description><link>project\challenge-cup-网络暴力治理\题目及思路.html</link><guid isPermaLink="false">Project/Challenge Cup-网络暴力治理/题目及思路.md</guid><pubDate>Tue, 14 May 2024 10:52:00 GMT</pubDate></item><item><title><![CDATA[网络暴力语言细粒度分类模型]]></title><description><![CDATA[ 
 <br> 网络暴力语言预测模型.docx<br><br>本部分旨在建立一个网络暴力语言预测模型，以识别网络暴力语言并进行细粒度分类。本部分数据集采用TOXICN数据集，该数据集是由Junyu Lu, Bo Xu(2023) 提出的中文互联网的网络暴力语言细粒度分类数据集。预测模型在预训练大语言模型(PLM)如Bert基础上，通过TKE、侮辱词典等辅助手段加强语言模型对于网络暴力语言的识别能力。<br><br><br>我们使用了TOXICN数据集，该数据集抓取的数据范围限定在几个敏感话题下，包括性别、种族、地域黑和LGBTQ，这些话题在互联网上很容易引起争论。其中列出了每个话题的一些关键词，并利用这些关键词提取出了总计15442条 没有回复的评论。删除了文本过于简短而没有实际语义的样本，比如只由词形变化和助词组成的短语。删除了包括重复的样本和不相关的广告等数据。最后，保留了12011条评论。<br>以下是数据集的部分样本示例。<br><br>其中platform指数据来源平台，topic指该评论出自什么主题的帖子，content即为文本内容，toxic即为评判是否网络暴力的二分类标注，toxic_type表示其为对言论的分类一般攻击性语言和仇恨性言论。expression表示表达方式，target表示攻击的目标群体，length表示文本内容长度，num_attacked表示攻击目标个数。<br>
对于一般攻击性语言和仇恨性言论的区别，根据Waseem and Hovy(2016)和Fortuna and Nunes(2018)，以下是几个识别仇恨言论的标准:1)攻击特定群体，或2)煽动他人仇恨少数群体，或3)基 刻板印象和扭曲事实对少数群体制造偏见、排斥或厌恶，或4)使用讽刺或幽默来嘲笑群体，尽管发布者可能并非恶意。相比之下， 一般的攻击性语言并没有对具有特定社会属性的目标进行侮辱(David-son et al.2017)。<br><br>标注者的主观偏见会对数据集的质量产生负 面影响(Waseem和Hovy, 2016)。因此，在标 注的设计和构建过程中，mit-igate这些偏差 是很重要的。为此，我们采取以下措施:我们 首先保证标注者在背景信息方面的多样性， 包括性别、年龄、种族、地区和研究。所有参与者均为语言学专业，并经过系统训练。 标注者的人口统计数据如表所示。然后， 我们对爬取的帖子中包含的有毒内容进行渐 进式分析，初步确定各种粒度的标注规则。 经过几次迭代的小规模标注测试和对边缘情况的讨论，最终确定了标准。<br><img alt="Pasted image 20240616181800.png" src="\lib\media\pasted-image-20240616181800.png"><br><br>主要使用了Facilitating Fine-grained Detection of Chinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks中的模型与方法。<br><br>
<br>分层分类法（MONITOR TOXIC FRAME）：

<br>目的: 区分仇恨言论和一般冒犯性语言，并分析有害表达方式。
<br>层级：

<br>有害识别： 二元分类，用于确定评论是否包含有害语言。
<br>有害类型区分： 区分一般冒犯性语言和仇恨言论。
<br>目标群体和表达类型检测： 识别目标群体（性别歧视、种族歧视、地域偏见和反LGBTQ）以及表达类型（显性、隐性或报告）。




<br>侮辱词典：

<br>目的： 包含隐性脏话，这对于检测微妙的有害语言至关重要。
<br>内容： 包含显性脏话和隐性有害术语，如讽刺性隐喻。


<br>有害知识增强（TKE）：

<br>描述： 一个基准，结合词汇特征来增强文本表示，改善有害语言的检测。
<br>评估： 使用多个基准结合TKE，证明其在检测有害语言方面的有效性。


<br><img alt="Pasted image 20240616182233.png" src="\lib\media\pasted-image-20240616182233.png"><br><br>我们使用多个基准模型作为编码器进行实验，包括BiLSTM和预训练语言模型（PLM），如BERT和RoBERTa。<br>
这里我们介绍实验的基线。以下几个现有的基准模型被用作编码器。我们使用一个全连接层作为几个子任务的分类器。<br>
BiLSTM。该方法采用腾讯AI Lab Embedding6的静态词向量，具有200维特征， 并使BiLSTM整合上下文信息。<br>
BERT。两个最常用的基于中文的transform文本模型, bert- basedchinese7 和 robertabasedchinese8，被用作基准模型。在实验中，编码器的池化输出被用作连接分类器的输入。<br><br>根据攻击对象的不同，将标注过程中构建的 辱骂词典分为五类。该词典包括性别歧视、 种族主义、地域偏见、反lbgtq以及一般脏话， 指的是那些可以用来冒犯任何群体的脏话。 最终的词典收录了1032个词条，不仅包括露骨的粗俗词汇，也包括含蓄的侮辱性词汇。 此外，由于互联网每年都会产生大量新的辱骂词，为了规避过滤机制，网民改变原有的辱骂词，创造出字形和发音相似的新变体(陈2012;Zhang, 2010)，分别被称为 变形和谐音。此外，在一些脏话中，汉字有时会被其他语言取代形成混合词或缩写。探索它们的起源至关重要。因此我们进一步从提出的侮辱词中分析网络脏话的派生规则。具体来说，我们从表面特征和实际含义两个方面对它们进行了简要总结。更多相关的术语说明和亵渎的例子如下。<br>实际意义。互联网用户经常引入隐含的术语来攻击或诋毁目标群体，包括隐喻和反讽的使用(陈，2012)。除此之外，一些外来词还含有特定的偏见，被用于隐性的有毒评论中(Shi, 2010)。与基于表面特征的变体相比， 这些具有深层语义的术语必须借助背景知识进行检测。<br>
以下是一些变形方式的总结：<br>变形。由于汉字是象形文字，通过与单个 汉字的分离和结合，赋予汉字包含特定情感的 意义(陈，2012)。一个例子是“默”(意为“沉 默”)，其字形由“黑”(意为“黑”)和“犬” (意为“狗”)组成，含蓄地表达了对黑人群体<br>
的厌恶。<br>旧词新意。褒义词有时是讽刺地使用来达到侮辱的效果，这往往体现在带有新含义的旧词 上(Fortuna and Nunes, 2018)。就像“仙女” (意为“仙女”)，原本温柔善良的形象被暗含<br>
为粗鲁无礼的“泼妇”。<br>缩写。例如“txl”，每个字母分别是 “同”、“性”和“恋”的发音首字母，意思是“gay”。<br>语种混合。为了强调语气，在中文网络平 台的文本中广泛混合了非中文语言，比如英文和表情符号(Li etal.， 2020)。比如脏话“ni哥”(意为“ni哥”)， 和“nagger”的读音相同。<br>舶来词。一些语音外来词弥漫着某种有 毒的文化内涵(Shi, 2010)。因此，需要背景信<br>
息来澄清这些术语的实际语义。一个例子是 “凯勒奇”，指的是反犹的卡勒吉计划，被用<br>
作一个煽动性的术语。<br><br>TKE方法旨在通过结合词汇特征来增强文本表示，改善有害语言的检测能力。具体步骤如下：<br>
<br>词汇嵌入： 对于给定的句子 ，每个词元  被嵌入为一个d维向量 。
<br>有害嵌入设计： 利用n-gram方法确定  是否为侮辱词的子词，并根据攻击的群体类别进行标注。随机初始化群体类别表示 ，其中  表示非有害词， 表示侮辱词典的类别数。在此工作中，。
<br>有害嵌入定义： 对于 ，其有害嵌入  的定义如下：

<br>，如果  是非有害词。
<br>，如果  属于第  类。


<br>增强表示： 将有害嵌入  和词汇嵌入  进行逐元素加法得到增强表示  是一个控制有害知识摄取的权重系数。最终的句子嵌入表示为 。
<br><img alt="Pasted image 20240616182256.png" src="\lib\media\pasted-image-20240616182256.png"><br><br><br>我们采用了广泛使用的加权精度(P)、召回率(R) 和F1-score (F1)指标来评估模型的性能。利用 加权交叉熵来解决类别不平衡问题，优化器是 AdamW。在训练阶段应用了早期停止机制。所有样本被分成训练集和测试集，比例 为8:2。我们对超参进行微调，并在测试集上保 留表现最好的模型和超参数，通过改变随机种子来减少误差，重复5次相同的实验。<br><br><br><br><br><br>
<br>实验结果： 结果表明，深度学习方法相比于在线API如百度文本审核，具有更好的性能。这可能是因为在线API的过滤机制较为简单。
<br>不同子任务的性能： 实验结果显示，TKE在不同粒度的有害语言检测任务中提高了模型的性能，尤其在隐性有害表达的检测中效果显著。
<br>错误分析： 通过对所有模型误分类样本的人工检查，识别出两种主要的错误类型：

<br>类型I错误（假阴性）： 模型将有害句子分类为非有害，通常是由于缺乏语义层面的背景信息。
<br>类型II错误（假阳性）： 模型将非有害句子分类为有害，通常是由于标记中的脏话或少数群体代词引起的误判。


<br><br>Facilitating Fine-grained Detection of Chinese Toxic Language: Hierarchical Taxonomy, Resources, and Benchmarks<br>Nlpdove at semeval-2020 task 12: Improving offensive language detection with cross-lingual transfer]]></description><link>project\challenge-cup-网络暴力治理\网络暴力语言细粒度分类模型.html</link><guid isPermaLink="false">Project/Challenge Cup-网络暴力治理/网络暴力语言细粒度分类模型.md</guid><pubDate>Sun, 16 Jun 2024 10:23:25 GMT</pubDate><enclosure url="lib\media\pasted-image-20240616181800.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240616181800.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Toxic-CN中文网络暴力语言细粒度分类]]></title><description><![CDATA[ 
 <br><a rel="noopener nofollow" class="external-link" href="https://github.com/DUT-lujunyu/ToxiCN/tree/main" target="_blank">https://github.com/DUT-lujunyu/ToxiCN/tree/main</a><br><br>侮辱词典<br>
See <a rel="noopener nofollow" class="external-link" href="https://github.com/DUT-lujunyu/ToxiCN/tree/main/ToxiCN_ex/ToxiCN/lexicon" target="_blank">https://github.com/DUT-lujunyu/ToxiCN/tree/main/ToxiCN_ex/ToxiCN/lexicon</a><br>这篇题为“促进中文有害语言的细粒度检测：分层分类法、资源与基准”的论文，主要致力于解决中文有害语言检测中的挑战。以下是其主要方法和思路的总结：<br><br>
<br>
分层分类法（MONITOR TOXIC FRAME）：

<br>目的：区分仇恨言论和一般冒犯性语言，并分析有害表达方式。
<br>层级：

<br>**有害识别：二元分类，用于确定评论是否包含有害语言。
<br>**有害类型区分：区分一般冒犯性语言和仇恨言论。
<br>**目标群体和表达类型检测：识别目标群体（性别歧视、种族歧视、地域偏见和反LGBTQ）以及表达类型（显性、隐性或报告）。




<br>
TOXICN 数据集：

<br>**描述：一个细粒度的数据集，包含直接和间接的有害样本。
<br>**内容：从知乎和贴吧收集的12011条评论，分类为性别歧视、种族歧视、地域偏见和反LGBTQ。
<br>**标注：采用分层和细粒度的标注方法，区分一般冒犯性语言和仇恨言论，以及不同类型的有害表达。


<br>
侮辱词典：

<br>**目的：包含隐性脏话，这对于检测微妙的有害语言至关重要。
<br>**内容：包含显性脏话和隐性有害术语，如讽刺性隐喻。


<br>
有害知识增强（TKE）：

<br>**描述：一个基准，结合词汇特征来增强文本表示，改善有害语言的检测。
<br>**评估：使用多个基准结合TKE，证明其在检测有害语言方面的有效性。


<br><br>
<br>**TKE的有效性：通过各种基准验证。
<br>**定量和定性分析：对研究结果进行系统分析，并提供改进有害语言检测的建议。
<br><br>
<br>**分层分类法：MONITOR TOXIC FRAME提供了一种结构化的方法，用于分析不同粒度水平的有害语言。
<br>**细粒度数据集：TOXICN数据集包含全面的标注，涵盖直接和间接的有害语言。
<br>**侮辱词典和TKE基准：这些工具结合词汇特征，提高了显性和隐性有害语言的检测准确性。
<br>这种综合方法通过引入细粒度标注和利用词汇知识，解决了以往中文有害语言检测研究中的局限性，从而提高了检测的准确性。<br><br>检测不同表达形式的有害内容：利用最优训练模型检测测试集中的样本，并分析非有害、显性、隐性和报告类样本的准确性。结果表明，隐性有害表达的检测准确性显著低于显性有害表达，表明隐性词汇知识增强了模型检测间接表达样本的能力​​。<br><br>类型I错误（假阴性）：模型将标注为有害的句子分类为非有害，通常是由于缺乏语义层面的背景信息。<br>
类型II错误（假阳性）：模型将标注为非有害的句子分类为有害，通常是由于标记中的脏话或少数群体代词引起的。这些错误表明模型在引入更多外部知识时仍面临挑战，需要进一步研究以减少虚假关联​​。]]></description><link>project\challenge-cup-网络暴力治理\toxic-cn中文网络暴力语言细粒度分类.html</link><guid isPermaLink="false">Project/Challenge Cup-网络暴力治理/Toxic-CN中文网络暴力语言细粒度分类.md</guid><pubDate>Sun, 02 Jun 2024 03:32:19 GMT</pubDate></item><item><title><![CDATA[标签管理]]></title><description><![CDATA[<a class="tag" href="?query=tag:项目" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目</a> <a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> <a class="tag" href="?query=tag:项目/个人项目" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目</a> <a class="tag" href="?query=tag:项目/个人项目/大二论文" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大二论文</a> <a class="tag" href="?query=tag:项目/个人项目/大二论文/论文" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大二论文/论文</a> <a class="tag" href="?query=tag:项目/个人项目/大创" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大创</a> <a class="tag" href="?query=tag:项目/个人项目/挑战杯" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/挑战杯</a> 
 <br><a href=".?query=tag:项目" class="tag" target="_blank" rel="noopener nofollow">#项目</a>  <br>
<br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a>
<br><a href=".?query=tag:项目\个人项目" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目</a> 

<br><a href=".?query=tag:项目\个人项目\大二论文" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大二论文</a>

<br><a href=".?query=tag:项目\个人项目\大二论文\论文" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大二论文/论文</a>


<br><a href=".?query=tag:项目\个人项目\大创" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大创</a> 
<br><a href=".?query=tag:项目\个人项目\挑战杯" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/挑战杯</a>


]]></description><link>project\标签管理.html</link><guid isPermaLink="false">Project/标签管理.md</guid><pubDate>Tue, 14 May 2024 10:01:00 GMT</pubDate></item><item><title><![CDATA[李世博 - CV(中文版本)]]></title><description><![CDATA[ 
 <br><br>
<br>年龄：21
<br>住址：江苏苏州
<br>联系方式：

<br>邮箱： <a data-tooltip-position="top" aria-label="mailto:aisaberli0423@gmail.com" rel="noopener nofollow" class="external-link" href="mailto:aisaberli0423@gmail.com" target="_blank">aisaberli0423@gmail.com</a>
<br>QQ：   2835817201


<br>学校：南京师范大学计算机与电子信息学院/人工智能学院
<br>主修专业：人工智能
<br>辅修专业：教育学
<br><br><br><br><br><br>]]></description><link>resume\李世博-cv(中文版本).html</link><guid isPermaLink="false">Resume/李世博 - CV(中文版本).md</guid><pubDate>Sun, 12 Jan 2025 02:16:06 GMT</pubDate></item><item><title><![CDATA[生涯发展报告]]></title><description><![CDATA[ 
 <br><br>
<br>
职业目标设定：结合所学人工智能专业，本人通过多渠道了解了人工智能领域的行业发展趋势和就业市场需求。随着人工智能在教育、环境保护、医疗健康等领域的深度应用，特别是在语音识别、智能化评价系统等细分领域的快速发展，我确定了将人工智能技术应用于跨学科项目的职业目标。通过结合个人的兴趣特长与能力优势，我意识到自己在算法研究与技术应用的结合方面具有较强的潜力，因此设定了致力于成为一名在人工智能与多领域交叉应用中具有创新能力的科研工作者的职业目标。

<br>
目标与现实差距分析与成长计划：在对比个人现状与职业目标后，我发现自己在理论深度和项目实践方面还有差距。为此，我制定了包括加强算法研究能力、提升编程技能、丰富项目经验和培养跨学科合作能力的成长计划。具体而言，我计划通过参与更多科研项目和实践，积累实际应用经验，提升解决复杂问题的能力，同时借助学校资源和外部平台拓展人脉和视野。

<br>
与国家需求及经济社会发展结合：我的职业目标不仅符合个人兴趣和学术能力，还与国家对人工智能人才的需求以及社会各行各业对智能化技术的需求相契合。人工智能在中国的产业化应用正加速推进，国家对技术创新和人才培养的重视为我的职业目标提供了广阔的空间和发展机遇。

<br><br>
<br>
学习与实践行动：围绕我的职业目标，我充分利用学校的资源，积极参加各类学术竞赛与科研项目。通过加入陈燚副教授课题组，我参与了中学生化学实验智能评价系统的研究，这让我在人工智能和教育结合的应用领域积累了宝贵的经验。加入谢捷副教授课题组进行鸟类声音识别模型研究，也让我在语音识别与深度学习领域深入学习和实践。同时，我还通过参与如iGEM合成生物学项目等跨学科项目，提升了自己的跨学科整合能力。

<br>
阶段性标志性成果：通过上述实践，我在多个竞赛中取得了优秀成绩，如获得“码蹄杯”银奖和“中国电气工程学会杯”三等奖等。这些成绩不仅是对我学习成果的肯定，也为我未来的职业目标达成奠定了基础。此外，我的科研项目也已取得初步进展，论文《Lightweight GCN for bird sound classification on Edge devices》的写作正朝着完成的目标迈进。

<br><br>
<br>
自我评估与调整：在不断推进职业目标的过程中，我进行了多次自我评估，及时总结学习和实践中的收获与不足。例如，我发现自己在跨学科项目的整合能力方面还有提升空间，因此，近期我计划加大在生物信息学和环境科学领域的学习与实践，进一步拓宽自己的知识面。同时，我也意识到在算法设计与工程实现之间的结合能力不足，为此，我将加强工程项目的实战经验，提升算法优化与实际应用的能力。

<br>
动态调整目标与路径：随着对行业的进一步了解，我决定将职业目标调整为不仅专注于算法研究，还包括推动人工智能技术在更多社会实践中的应用，尤其是教育、生态保护等领域。针对这一调整，我将继续在理论研究的基础上加强项目落地与技术实施的经验，进一步推动理论与实践的结合。

<br><br>2023年：<br>
<br>
南京师范大学优秀学生奖学金（2022-2023学年）<br>
获得南京师范大学2022-2023学年优秀学生奖学金，以表彰其在学术和社会活动中的杰出表现。

<br>
南京师范大学计算机科学暑期学校网络安全竞赛技能三等奖<br>
在网络安全竞赛中获得三等奖，展示了扎实的编程与安全技能。

<br>
蓝桥杯全国软件与信息技术专业人才大赛，江苏省三等奖<br>
在蓝桥杯大赛中获得江苏省三等奖，体现了在软件开发和信息技术应用方面的综合能力。

<br>
南京师范大学第八届互联网创新创业科技节计算机编程大赛二等奖<br>
在互联网创新创业科技节的计算机编程大赛中，凭借优异的编程能力获得二等奖。

<br>2024年：<br>
<br>
“中国电气工程学会杯”全国大学生电气数学建模竞赛三等奖<br>
获得三等奖，展现了在数学建模和电气工程问题解决方面的能力。

<br>
"码蹄杯"全国大学生程序设计大赛银奖<br>
在“码蹄杯”程序设计大赛中获得银奖，证明了卓越的算法设计与编程能力。

<br>
高教杯全国数学建模大赛省一等奖<br>
在全国数学建模大赛中获得省一等奖，突出表现了数学建模与实际问题解决的能力。

<br>
天翼云息壤杯大模型应用赛道<br>
参与天翼云息壤杯大模型应用赛道，展示了在大规模模型应用领域的潜力与创新。

<br><br>通过对职业目标的科学分析、学习实践的持续推进与动态调整，我已逐步接近自己的职业目标。在未来，我将继续通过学习、实践与反思，不断提升自己的综合素质和专业能力，推动职业目标的实现，并为社会发展做出贡献。]]></description><link>resume\生涯发展报告.html</link><guid isPermaLink="false">Resume/生涯发展报告.md</guid><pubDate>Mon, 18 Nov 2024 04:11:33 GMT</pubDate></item><item><title><![CDATA[Waferen - CV(English Version)]]></title><description><![CDATA[ 
 <br><br>
<br>Male 21 Suzhou,Jiangsu
<br>Email:<a data-tooltip-position="top" aria-label="mailto:aisabrli0423@gmail.com" rel="noopener nofollow" class="external-link" href="mailto:aisabrli0423@gmail.com" target="_blank">aisabrli0423@gmail.com</a>
<br>Nanjing Normal University,School of Computer and Electronic Information/School of Artificial Intelligence
<br><br><br><br><br><br>]]></description><link>resume\waferen-cv(english-version).html</link><guid isPermaLink="false">Resume/Waferen - CV(English Version).md</guid><pubDate>Sun, 12 Jan 2025 02:18:41 GMT</pubDate></item><item><title><![CDATA[参数量]]></title><description><![CDATA[ 
 <br>GCN的总参数量：40596<br>
EfficientNetB0总参数量: 4,033,168]]></description><link>technology\科研\实验\参数量.html</link><guid isPermaLink="false">Technology/科研/实验/参数量.md</guid><pubDate>Mon, 21 Oct 2024 03:52:35 GMT</pubDate></item><item><title><![CDATA[初始实验数据]]></title><description><![CDATA[ 
 <br>这个的代码跑通了。我用了你给我的那个鸟类声音数据集。整体效果还行。我做了一些变化，他其实并不是每个音频文件对应一张图，而是把音频文件分割成固定的120帧，可能也算种数据增强，每一帧与下一帧连接组成一个线性图。每个节点就是一帧，节点特征就是这一帧对应的MFCC特征。因为我们鸟类的那个数据集是固定的2秒一个文件，没有分割的余地了，就直接将一个音频文件198帧作为一张线性图。<br>
然后我跑的时候为节约时间没用交叉验证，是直接划分数据集8:2，epoch设置的100，感觉acc还有上升的趋势,应该没到极限。下面这个是100轮的loss,和训练集测试集上的acc和最后10轮的训练。我不清楚这个准确率算高算低。<br>
<img alt="a12074b88d58a1ccfbc6a88a3d345ba2.png" src="\lib\media\a12074b88d58a1ccfbc6a88a3d345ba2.png"><br>
<img alt="4903cd2d8ba2b41511d15e8bed79dbe8.png" src="\lib\media\4903cd2d8ba2b41511d15e8bed79dbe8.png">]]></description><link>technology\科研\实验\初始实验数据.html</link><guid isPermaLink="false">Technology/科研/实验/初始实验数据.md</guid><pubDate>Sat, 21 Sep 2024 13:03:28 GMT</pubDate><enclosure url="lib\media\a12074b88d58a1ccfbc6a88a3d345ba2.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\a12074b88d58a1ccfbc6a88a3d345ba2.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[纯GCN预测]]></title><description><![CDATA[ 
 <br><br>EPOCH: 160, acc_train: 0.9907, acc_test: 0.9076<br>
训练集每个类别的准确率:<br>
类别 0: 0.9918<br>
类别 1: 0.9984<br>
类别 2: 0.9804<br>
类别 3: 0.9917<br>
类别 4: 0.9130<br>
类别 5: 1.0000<br>
类别 6: 0.9859<br>
类别 7: 0.9940<br>
类别 8: 0.9985<br>
类别 9: 0.9765<br>
类别 10: 0.9932<br>
类别 11: 0.9569<br>
类别 12: 0.9853<br>
类别 13: 0.9973<br>
类别 14: 0.9984<br>
类别 15: 0.9969<br>
类别 16: 0.9982<br>
类别 17: 0.9984<br>
类别 18: 0.9924<br>
类别 19: 0.9791<br>
测试集每个类别的准确率:<br>
类别 0: 0.8947<br>
类别 1: 0.9625<br>
类别 2: 0.8896<br>
类别 3: 0.9421<br>
类别 4: 0.5000<br>
类别 5: 0.9865<br>
类别 6: 0.9125<br>
类别 7: 0.9581<br>
类别 8: 0.8882<br>
类别 9: 0.8889<br>
类别 10: 0.8844<br>
类别 11: 0.6897<br>
类别 12: 0.8529<br>
类别 13: 0.9022<br>
类别 14: 0.9367<br>
类别 15: 0.9509<br>
类别 16: 0.8803<br>
类别 17: 0.9241<br>
类别 18: 0.9091<br>
类别 19: 0.8787<br><br>Test Loss: 1.1846, Accuracy: 74.26%<br>
Class 0 Accuracy: 61.84%<br>
Class 1 Accuracy: 86.88%<br>
Class 2 Accuracy: 83.77%<br>
Class 3 Accuracy: 70.25%<br>
Class 4 Accuracy: 16.67%<br>
Class 5 Accuracy: 77.70%<br>
Class 6 Accuracy: 75.00%<br>
Class 7 Accuracy: 82.04%<br>
Class 8 Accuracy: 82.94%<br>
Class 9 Accuracy: 73.68%<br>
Class 10 Accuracy: 61.22%<br>
Class 11 Accuracy: 32.76%<br>
Class 12 Accuracy: 69.85%<br>
Class 13 Accuracy: 65.22%<br>
Class 14 Accuracy: 83.54%<br>
Class 15 Accuracy: 73.01%<br>
Class 16 Accuracy: 65.49%<br>
Class 17 Accuracy: 69.62%<br>
Class 18 Accuracy: 78.18%<br>
Class 19 Accuracy: 81.59%<br>
Class 0 Accuracy: 61.84%<br>
Class 1 Accuracy: 86.88%<br>
Class 2 Accuracy: 83.77%<br>
Class 3 Accuracy: 70.25%<br>
Class 4 Accuracy: 16.67%<br>
Class 5 Accuracy: 77.70%<br>
Class 6 Accuracy: 75.00%<br>
Class 7 Accuracy: 82.04%<br>
Class 8 Accuracy: 82.94%<br>
Class 9 Accuracy: 73.68%<br>
Class 10 Accuracy: 61.22%<br>
Class 11 Accuracy: 32.76%<br>
Class 12 Accuracy: 69.85%<br>
Class 13 Accuracy: 65.22%<br>
Class 14 Accuracy: 83.54%<br>
Class 15 Accuracy: 73.01%<br>
Class 16 Accuracy: 65.49%<br>
Class 17 Accuracy: 69.62%<br>
Class 18 Accuracy: 78.18%<br>
Class 19 Accuracy: 81.59%<br><br>Test Loss: 1.5174, Accuracy: 56.61%<br>
Class 0 Accuracy: 47.37%<br>
Class 1 Accuracy: 69.38%<br>
Class 2 Accuracy: 81.17%<br>
Class 3 Accuracy: 17.36%<br>
Class 4 Accuracy: 0.00%<br>
Class 5 Accuracy: 78.38%<br>
Class 6 Accuracy: 72.50%<br>
Class 7 Accuracy: 64.07%<br>
Class 8 Accuracy: 77.65%<br>
Class 9 Accuracy: 34.50%<br>
Class 10 Accuracy: 32.65%<br>
Class 11 Accuracy: 5.17%<br>
Class 12 Accuracy: 39.71%<br>
Class 13 Accuracy: 46.74%<br>
Class 14 Accuracy: 77.22%<br>
Class 15 Accuracy: 46.63%<br>
Class 16 Accuracy: 31.69%<br>
Class 17 Accuracy: 62.03%<br>
Class 18 Accuracy: 69.70%<br>
Class 19 Accuracy: 66.95%<br>
Class 0 Accuracy: 47.37%<br>
Class 1 Accuracy: 69.38%<br>
Class 2 Accuracy: 81.17%<br>
Class 3 Accuracy: 17.36%<br>
Class 4 Accuracy: 0.00%<br>
Class 5 Accuracy: 78.38%<br>
Class 6 Accuracy: 72.50%<br>
Class 7 Accuracy: 64.07%<br>
Class 8 Accuracy: 77.65%<br>
Class 9 Accuracy: 34.50%<br>
Class 10 Accuracy: 32.65%<br>
Class 11 Accuracy: 5.17%<br>
Class 12 Accuracy: 39.71%<br>
Class 13 Accuracy: 46.74%<br>
Class 14 Accuracy: 77.22%<br>
Class 15 Accuracy: 46.63%<br>
Class 16 Accuracy: 31.69%<br>
Class 17 Accuracy: 62.03%<br>
Class 18 Accuracy: 69.70%<br>
Class 19 Accuracy: 66.95%<br><br>Test Loss: 1.5368, Accuracy: 56.47%<br>
Class 0 Accuracy: 39.47%<br>
Class 1 Accuracy: 57.50%<br>
Class 2 Accuracy: 79.87%<br>
Class 3 Accuracy: 26.45%<br>
Class 4 Accuracy: 0.00%<br>
Class 5 Accuracy: 84.46%<br>
Class 6 Accuracy: 71.25%<br>
Class 7 Accuracy: 68.86%<br>
Class 8 Accuracy: 77.65%<br>
Class 9 Accuracy: 40.94%<br>
Class 10 Accuracy: 35.37%<br>
Class 11 Accuracy: 6.90%<br>
Class 12 Accuracy: 51.47%<br>
Class 13 Accuracy: 33.70%<br>
Class 14 Accuracy: 77.85%<br>
Class 15 Accuracy: 47.85%<br>
Class 16 Accuracy: 30.28%<br>
Class 17 Accuracy: 62.66%<br>
Class 18 Accuracy: 66.06%<br>
Class 19 Accuracy: 61.51%<br>
Class 0 Accuracy: 39.47%<br>
Class 1 Accuracy: 57.50%<br>
Class 2 Accuracy: 79.87%<br>
Class 3 Accuracy: 26.45%<br>
Class 4 Accuracy: 0.00%<br>
Class 5 Accuracy: 84.46%<br>
Class 6 Accuracy: 71.25%<br>
Class 7 Accuracy: 68.86%<br>
Class 8 Accuracy: 77.65%<br>
Class 9 Accuracy: 40.94%<br>
Class 10 Accuracy: 35.37%<br>
Class 11 Accuracy: 6.90%<br>
Class 12 Accuracy: 51.47%<br>
Class 13 Accuracy: 33.70%<br>
Class 14 Accuracy: 77.85%<br>
Class 15 Accuracy: 47.85%<br>
Class 16 Accuracy: 30.28%<br>
Class 17 Accuracy: 62.66%<br>
Class 18 Accuracy: 66.06%<br>
Class 19 Accuracy: 61.51%]]></description><link>technology\科研\实验\纯gcn预测.html</link><guid isPermaLink="false">Technology/科研/实验/纯GCN预测.md</guid><pubDate>Fri, 15 Nov 2024 04:53:34 GMT</pubDate></item><item><title><![CDATA[第二阶段]]></title><description><![CDATA[ 
 <br>第二阶段主要解决最好的lfcc，mfcc组合是多少，获得一组最好的组合<br>
<br>先通过mfcc找到最好的倒频谱系数总数，从8到16去找，14
<br>固定特征总数，找到最好的lfcc，mfcc特征数组合
<br>将CNN与GCN做融合，观察是否提升
<br>第二阶段的主要任务是解决local peak问题。如何将local peak 特征用在GCN上，以及如何提取loacl peak。<br>local peak 怎么做呢？由于我们的频谱图是有STFT提取，短时傅里叶变换相当于将很短的一段时间内的波形分解成不同频率，那么这些频率中幅度也即能量最大的即是最有效的特征。那么我们通过local peak 方式去将这种有效特征提取出来。那么提取几个peak是一个参数，local peak中local的范围是一个参数。local范围难以确定。我们可以从另一个角度规避对于local范围的界定。我们借鉴分水岭算法，把它从二维的图像分割算法，变成一维的找local peak 的算法。具体算法思想是这样的，先去找这一帧中的能量最小值点，作为谷底部，从底部开始画一条水平线，这条水平线不断上升，然后我们只控制peak数这一个参数，当这条水平线上的local peak只剩下我们想要的peak数后，我们就将这几个peak的频率值作为这一帧的特征。嗯——好像就是找最大的几个局部峰值。<br>或者我们先将local peak全找出来，然后找距离最远的几个峰值。<br>这样我们就可以动手做了。<br>分两种，一种是找最大的几个峰值，一种是找距离最远几个峰值。<br>抽帧<br>
<img alt="a015a900161c2d89a7c6bd97445c7a11.png" src="\lib\media\a015a900161c2d89a7c6bd97445c7a11.png"><br>
<img alt="397ec445d857734022087b36ab8164ea.png" src="\lib\media\397ec445d857734022087b36ab8164ea.png"><br>
我现在把抽帧做了下，去掉百分之二十的静音帧<br>平滑处理后的帧频率<br>
<img alt="f0771a3bd89aabcd64e5547fe3a8db92.png" src="\lib\media\f0771a3bd89aabcd64e5547fe3a8db92.png">]]></description><link>technology\科研\实验\第二阶段.html</link><guid isPermaLink="false">Technology/科研/实验/第二阶段.md</guid><pubDate>Mon, 14 Oct 2024 02:49:09 GMT</pubDate><enclosure url="lib\media\a015a900161c2d89a7c6bd97445c7a11.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\a015a900161c2d89a7c6bd97445c7a11.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[第一阶段]]></title><description><![CDATA[ 
 <br>第一阶段主要任务是把GCN代码跑通，了解完整的特征提取流程。然后，训练CNN预训练模型。得到最终的两个模块，即GCN模块，和CNN模块。<br>
<br>GCN模块
<br>特征提取
<br>CNN模块
]]></description><link>technology\科研\实验\第一阶段.html</link><guid isPermaLink="false">Technology/科研/实验/第一阶段.md</guid><pubDate>Sun, 29 Sep 2024 02:05:27 GMT</pubDate></item><item><title><![CDATA[第一阶段数据情况]]></title><description><![CDATA[ 
 <br>目前GCN与CNN都跑通了。<br><br>不对数据集进行任何处理，得到的结果如下。<br>
<img alt="{3FB02C08-1037-4652-8C07-964C96EC5FA0}.png" src="\lib\media\{3fb02c08-1037-4652-8c07-964c96ec5fa0}.png"><br><img alt="{394E98D4-ABEF-4F9B-A7A2-8698C4789A27}.png" src="\lib\media\{394e98d4-abef-4f9b-a7a2-8698c4789a27}.png"><br><br>EfficientNet B0 的混淆矩阵<br>
<img alt="{0EA1BDBA-7696-4C61-85B8-E1A7607B737A}.png" src="\lib\media\{0ea1bdba-7696-4c61-85b8-e1a7607b737a}.png">]]></description><link>technology\科研\实验\第一阶段数据情况.html</link><guid isPermaLink="false">Technology/科研/实验/第一阶段数据情况.md</guid><pubDate>Sat, 28 Sep 2024 10:35:36 GMT</pubDate><enclosure url="lib\media\{3fb02c08-1037-4652-8c07-964c96ec5fa0}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{3fb02c08-1037-4652-8c07-964c96ec5fa0}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数据整理]]></title><description><![CDATA[ 
 <br><br><br>test_mfcc_accuracies = [0.846664, 0.856095, 0.865875, 0.875655,0.888928,0.874604,0.892071,0.878100,0.889976]
<br>Best number of cepstral coefficients: 14 with accuracy: 0.8920712539294446<br>Final train acc: 0.970475,  Final test acc: 0.892071
18117.3s	4928	训练集每个类别的准确率:
18117.3s	4929	类别 0: 0.9883
18117.3s	4930	类别 1: 0.9905
18117.3s	4931	类别 2: 0.9651
18117.3s	4932	类别 3: 0.9831
18117.3s	4933	类别 4: 0.9693
18117.3s	4934	类别 5: 0.9909
18117.3s	4935	类别 6: 0.9877
18117.3s	4936	类别 7: 0.8696
18117.3s	4937	类别 8: 0.9423
18117.3s	4938	类别 9: 0.9853
18117.3s	4939	类别 10: 0.9087
18117.3s	4940	类别 11: 0.9746
18117.3s	4941	类别 12: 0.9719
18117.3s	4942	类别 13: 0.9869
18117.3s	4943	类别 14: 0.9728
18117.3s	4944	类别 15: 0.9731
18117.3s	4945	类别 16: 0.9508
18117.3s	4946	类别 17: 0.8578
18117.3s	4947	类别 18: 0.9781
18117.3s	4948	类别 19: 0.9877
18117.3s	4949	测试集每个类别的准确率:
18117.3s	4950	类别 0: 0.9123
18117.3s	4951	类别 1: 0.9299
18117.3s	4952	类别 2: 0.8456
18117.3s	4953	类别 3: 0.9459
18117.3s	4954	类别 4: 0.8299
18117.3s	4955	类别 5: 0.9152
18117.3s	4956	类别 6: 0.9632
18117.3s	4957	类别 7: 0.5000
18117.3s	4958	类别 8: 0.8158
18117.3s	4959	类别 9: 0.9647
18117.3s	4960	类别 10: 0.7917
18117.3s	4961	类别 11: 0.9341
18117.3s	4962	类别 12: 0.9375
18117.3s	4963	类别 13: 0.8889
18117.3s	4964	类别 14: 0.8478
18117.3s	4965	类别 15: 0.9051
18117.3s	4966	类别 16: 0.8745
18117.3s	4967	类别 17: 0.5690
18117.3s	4968	类别 18: 0.8994
18117.3s	4969	类别 19: 0.9366
<br><br>test_lfcc_accuracies = [0.810688,0.813133,0.824659,0.836186,0.841774,0.847,0.853999,0.863430,0.829200]
<br>Final train acc: 0.967068,  Final test acc: 0.863430
19719.8s	5238	训练集每个类别的准确率:
19719.8s	5239	类别 0: 0.9648
19719.8s	5240	类别 1: 0.9936
19719.8s	5241	类别 2: 0.9577
19719.8s	5242	类别 3: 0.9932
19719.8s	5243	类别 4: 0.9710
19719.8s	5244	类别 5: 0.9924
19719.8s	5245	类别 6: 0.9892
19719.8s	5246	类别 7: 0.8261
19719.8s	5247	类别 8: 0.9143
19719.8s	5248	类别 9: 0.9721
19719.8s	5249	类别 10: 0.9481
19719.8s	5250	类别 11: 0.9731
19719.8s	5251	类别 12: 0.9625
19719.8s	5252	类别 13: 0.9723
19719.8s	5253	类别 14: 0.9538
19719.8s	5254	类别 15: 0.9699
19719.8s	5255	类别 16: 0.9331
19719.8s	5256	类别 17: 0.9181
19719.8s	5257	类别 18: 0.9922
19719.8s	5258	类别 19: 0.9824
19719.8s	5259	测试集每个类别的准确率:
19719.8s	5260	类别 0: 0.8129
19719.8s	5261	类别 1: 0.9554
19719.8s	5262	类别 2: 0.8529
19719.8s	5263	类别 3: 0.9662
19719.8s	5264	类别 4: 0.8163
19719.8s	5265	类别 5: 0.8909
19719.8s	5266	类别 6: 0.9080
19719.8s	5267	类别 7: 0.5000
19719.8s	5268	类别 8: 0.7500
19719.8s	5269	类别 9: 0.9294
19719.8s	5270	类别 10: 0.8417
19719.8s	5271	类别 11: 0.8862
19719.8s	5272	类别 12: 0.9062
19719.8s	5273	类别 13: 0.8301
19719.8s	5274	类别 14: 0.8152
19719.8s	5275	类别 15: 0.8481
19719.8s	5276	类别 16: 0.8745
19719.8s	5277	类别 17: 0.6207
19719.8s	5278	类别 18: 0.8679
19719.8s	5279	类别 19: 0.8521
<br><br>Final train acc: 0.970475,  Final test acc: 0.897311
3038.0s	626	训练集每个类别的准确率:
3038.0s	627	类别 0: 0.9692
3038.0s	628	类别 1: 0.9984
3038.0s	629	类别 2: 0.9540
3038.0s	630	类别 3: 0.9966
3038.0s	631	类别 4: 0.9710
3038.0s	632	类别 5: 0.9818
3038.0s	633	类别 6: 0.9754
3038.0s	634	类别 7: 0.9130
3038.0s	635	类别 8: 0.9341
3038.0s	636	类别 9: 0.9897
3038.0s	637	类别 10: 0.9481
3038.0s	638	类别 11: 0.9895
3038.0s	639	类别 12: 0.9859
3038.0s	640	类别 13: 0.9821
3038.0s	641	类别 14: 0.9674
3038.0s	642	类别 15: 0.9636
3038.0s	643	类别 16: 0.9320
3038.0s	644	类别 17: 0.9009
3038.0s	645	类别 18: 0.9765
3038.0s	646	类别 19: 0.9912
3038.0s	647	测试集每个类别的准确率:
3038.0s	648	类别 0: 0.8772
3038.0s	649	类别 1: 0.9618
3038.0s	650	类别 2: 0.8456
3038.0s	651	类别 3: 0.9595
3038.0s	652	类别 4: 0.8367
3038.0s	653	类别 5: 0.8848
3038.0s	654	类别 6: 0.9448
3038.0s	655	类别 7: 0.6667
3038.0s	656	类别 8: 0.8289
3038.0s	657	类别 9: 0.9588
3038.0s	658	类别 10: 0.8417
3038.0s	659	类别 11: 0.9760
3038.0s	660	类别 12: 0.9375
3038.0s	661	类别 13: 0.9216
3038.0s	662	类别 14: 0.8804
3038.0s	663	类别 15: 0.8797
3038.0s	664	类别 16: 0.8870
3038.0s	665	类别 17: 0.5690
3038.0s	666	类别 18: 0.8994
3038.0s	667	类别 19: 0.9296
<br><br>num_peaks=13, test accuracy: 0.6430317848410758
num_peaks=14, test accuracy: 0.6597974152986378
num_peaks=21, test accuracy: 0.661893119105833
num_peaks=29, test accuracy: 0.5354523227383863
]]></description><link>technology\科研\实验\数据整理.html</link><guid isPermaLink="false">Technology/科研/实验/数据整理.md</guid><pubDate>Tue, 08 Oct 2024 15:29:38 GMT</pubDate></item><item><title><![CDATA[思路整理及数据]]></title><description><![CDATA[ 
 <br><img alt="{092C924C-246B-46B8-BC6F-F3B7C69E19D2}.png" src="\lib\media\{092c924c-246b-46b8-bc6f-f3b7c69e19d2}.png"><br><br>Test Accuracy: 0.9634<br>
Class 0009 Accuracy: 0.9474<br>
Class 0017 Accuracy: 0.9875<br>
Class 0034 Accuracy: 0.9610<br>
Class 0036 Accuracy: 0.9587<br>
Class 0074 Accuracy: 1.0000<br>
Class 0077 Accuracy: 0.9932<br>
Class 0114 Accuracy: 0.9812<br>
Class 0121 Accuracy: 0.9760<br>
Class 0180 Accuracy: 0.9588<br>
Class 0202 Accuracy: 0.9649<br>
Class 0235 Accuracy: 0.9456<br>
Class 0257 Accuracy: 0.8793<br>
Class 0265 Accuracy: 0.9191<br>
Class 0281 Accuracy: 0.9783<br>
Class 0298 Accuracy: 0.9873<br>
Class 0300 Accuracy: 0.9816<br>
Class 0364 Accuracy: 0.9718<br>
Class 0368 Accuracy: 0.9430<br>
Class 0370 Accuracy: 0.9697<br>
Class 1331 Accuracy: 0.9498<br>Batch size: 16<br>
Similarity matrix shape: torch.Size([16, 16])<br>
KNN indices shape: torch.Size([16, 5])<br>
Source nodes shape: torch.Size([80])<br>
Target nodes shape: torch.Size([80])<br>
Final edge_index shape: torch.Size([2, 160])<br><br>EPOCH: 70, acc_train: 0.1946, acc_test: 0.1807<br>
38811.1s	632	训练集每个类别的准确率:<br>
38811.1s	633	类别 0: 0.1433<br>
38811.1s	634	类别 1: 0.1797<br>
38811.1s	635	类别 2: 0.0016<br>
38811.1s	636	类别 3: 0.0229<br>
38811.1s	637	类别 4: 0.0000<br>
38811.1s	638	类别 5: 0.3949<br>
38811.1s	639	类别 6: 0.0754<br>
38811.1s	640	类别 7: 0.1347<br>
38811.1s	641	类别 8: 0.6221<br>
38811.1s	642	类别 9: 0.0279<br>
38811.1s	643	类别 10: 0.0085<br>
38811.1s	644	类别 11: 0.0000<br>
38811.1s	645	类别 12: 0.4283<br>
38811.1s	646	类别 13: 0.0000<br>
38811.1s	647	类别 14: 0.0398<br>
38811.1s	648	类别 15: 0.1198<br>
38811.1s	649	类别 16: 0.0651<br>
38811.1s	650	类别 17: 0.1946<br>
38811.1s	651	类别 18: 0.1636<br>
38811.1s	652	类别 19: 0.6182<br>
38811.1s	653	测试集每个类别的准确率:<br>
38811.1s	654	类别 0: 0.1316<br>
38811.1s	655	类别 1: 0.1625<br>
38811.1s	656	类别 2: 0.0065<br>
38811.1s	657	类别 3: 0.0248<br>
38811.1s	658	类别 4: 0.0000<br>
38811.1s	659	类别 5: 0.3716<br>
38811.1s	660	类别 6: 0.0625<br>
38811.1s	661	类别 7: 0.1317<br>
38811.1s	662	类别 8: 0.5765<br>
38811.1s	663	类别 9: 0.0117<br>
38811.1s	664	类别 10: 0.0068<br>
38811.1s	665	类别 11: 0.0000<br>
38811.1s	666	类别 12: 0.3235<br>
38811.1s	667	类别 13: 0.0000<br>
38811.1s	668	类别 14: 0.0316<br>
38811.1s	669	类别 15: 0.1288<br>
38811.1s	670	类别 16: 0.0493<br>
38811.1s	671	类别 17: 0.2089<br>
38811.1s	672	类别 18: 0.1333<br>
38811.1s	673	类别 19: 0.6192\<br><br>EPOCH: 10, acc_train: 0.9824, acc_test: 0.9323<br>
训练集每个类别的准确率:<br>
类别 0: 0.9588<br>
类别 1: 0.9859<br>
类别 2: 0.9951<br>
类别 3: 0.9834<br>
类别 4: 0.9130<br>
类别 5: 0.9949<br>
类别 6: 0.9969<br>
类别 7: 0.9940<br>
类别 8: 0.9912<br>
类别 9: 0.9780<br>
类别 10: 0.9863<br>
类别 11: 0.9310<br>
类别 12: 0.9724<br>
类别 13: 0.9783<br>
类别 14: 0.9952<br>
类别 15: 0.9816<br>
类别 16: 0.9806<br>
类别 17: 0.9778<br>
类别 18: 0.9909<br>
类别 19: 0.9676<br>
测试集每个类别的准确率:<br>
类别 0: 0.9276<br>
类别 1: 0.9625<br>
类别 2: 0.9351<br>
类别 3: 0.9256<br>
类别 4: 0.6667<br>
类别 5: 0.9865<br>
类别 6: 0.9625<br>
类别 7: 0.9521<br>
类别 8: 0.9235<br>
类别 9: 0.9123<br>
类别 10: 0.9184<br>
类别 11: 0.8276<br>
类别 12: 0.9044<br>
类别 13: 0.9457<br>
类别 14: 0.9620<br>
类别 15: 0.9571<br>
类别 16: 0.8873<br>
类别 17: 0.9304<br>
类别 18: 0.9636<br>
类别 19: 0.8912<br><br>Test Accuracy: 0.9567<br>
Class 0009 Accuracy: 0.9605<br>
Class 0017 Accuracy: 0.9750<br>
Class 0034 Accuracy: 0.9805<br>
Class 0036 Accuracy: 0.9421<br>
Class 0074 Accuracy: 0.9167<br>
Class 0077 Accuracy: 0.9899<br>
Class 0114 Accuracy: 0.9625<br>
Class 0121 Accuracy: 0.9910<br>
Class 0180 Accuracy: 0.9559<br>
Class 0202 Accuracy: 0.9678<br>
Class 0235 Accuracy: 0.9320<br>
Class 0257 Accuracy: 0.8448<br>
Class 0265 Accuracy: 0.9118<br>
Class 0281 Accuracy: 0.9620<br>
Class 0298 Accuracy: 0.9810<br>
Class 0300 Accuracy: 0.9693<br>
Class 0364 Accuracy: 0.9507<br>
Class 0368 Accuracy: 0.9082<br>
Class 0370 Accuracy: 0.9879<br>
Class 1331 Accuracy: 0.9351<br>Confusion Matrix:<br>
[[292   0   0   0   0   0   3   0   3   2   0   1   0   2   0   1   0   0
    0   0]
 [  1 312   0   0   0   0   0   0   0   3   0   0   0   1   0   0   0   1
    0   2]
 [  1   0 302   2   0   0   0   0   1   1   0   0   0   0   0   0   0   0
    1   0]
 [  3   0   1 228   0   2   0   0   0   2   1   1   1   1   0   0   0   0
    1   1]
 [  1   0   0   0  11   0   0   0   0   0   0   0   0   0   0   0   0   0
    0   0]
 [  0   0   0   1   0 293   0   0   0   0   0   0   0   0   0   0   2   0
    0   0]
 [  3   0   1   0   1   0 308   0   0   2   0   1   0   0   0   1   0   0
    0   3]
 [  0   0   1   0   0   0   0 331   0   0   0   1   0   0   0   0   0   0
    0   1]
 [  7   0   6   0   0   1   0   0 325   0   1   0   0   0   0   0   0   0
    0   0]
 [  2   2   0   2   0   0   0   1   0 331   0   1   0   0   0   0   0   0
    0   3]
 [  1   0   0   0   0   0   0   1   0   1 274  12   0   0   1   1   1   2
    0   0]
 [  2   1   0   1   0   0   1   0   0   0   5  98   1   0   1   0   1   2
    0   3]
 [  1   0   1   1   0   0   1   0   1   1   4   1 248   3   1   0   2   1
    1   5]
 [  1   1   1   1   0   0   0   0   0   1   1   0   0 177   1   0   0   0
    0   0]
 [  0   0   1   0   0   1   1   0   0   0   0   0   0   0 310   0   0   0
    3   0]
 [  1   0   0   0   0   0   2   0   0   0   1   0   0   0   1 316   0   1
    2   2]
 [  0   0   1   0   0   0   2   0   0   0   0   0   0   0   1   0 270   1
    6   3]
 [  2   2   1   2   0   1   3   0   0   2   1   2   1   0   0   1   1 287
   10   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   0   0   0   1   1
  326   1]
 [  0   2   2   2   0   0   4   2   0   2   2   1   2   0   1   1   5   1
    4 447]]
]]></description><link>technology\科研\实验\思路整理及数据.html</link><guid isPermaLink="false">Technology/科研/实验/思路整理及数据.md</guid><pubDate>Fri, 01 Nov 2024 04:26:39 GMT</pubDate><enclosure url="lib\media\{092c924c-246b-46b8-bc6f-f3b7c69e19d2}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{092c924c-246b-46b8-bc6f-f3b7c69e19d2}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[EfficientNetB0数据]]></title><description><![CDATA[ 
 <br><br>Test Accuracy: 0.9521<br>
Class 0009 Accuracy: 0.9079<br>
Class 0017 Accuracy: 0.9688<br>
Class 0034 Accuracy: 0.9608<br>
Class 0036 Accuracy: 0.8917<br>
Class 0074 Accuracy: 0.8333<br>
Class 0077 Accuracy: 0.9865<br>
Class 0114 Accuracy: 0.9623<br>
Class 0121 Accuracy: 0.9701<br>
Class 0180 Accuracy: 0.9824<br>
Class 0202 Accuracy: 0.9649<br>
Class 0235 Accuracy: 0.9592<br>
Class 0257 Accuracy: 0.7759<br>
Class 0265 Accuracy: 0.9338<br>
Class 0281 Accuracy: 0.9457<br>
Class 0298 Accuracy: 0.9809<br>
Class 0300 Accuracy: 0.9632<br>
Class 0364 Accuracy: 0.9366<br>
Class 0368 Accuracy: 0.9430<br>
Class 0370 Accuracy: 0.9636<br>
Class 1331 Accuracy: 0.9582<br>
Confusion Matrix:<br>[[138   1   0   3   0   0   3   3   0   2   1   0   0   0   1   0   0   0
    0   0]
 [  1 155   1   0   0   0   1   1   0   0   0   0   0   1   0   0   0   0
    0   0]
 [  0   0 147   0   0   0   0   0   1   2   1   0   0   0   1   0   1   0
    0   0]
 [  0   0   2 107   0   0   0   1   0   1   1   0   0   0   1   0   1   1
    2   3]
 [  0   0   0   0   5   0   0   0   0   0   0   0   0   0   0   1   0   0
    0   0]
 [  0   0   1   0   0 146   0   0   0   0   1   0   0   0   0   0   0   0
    0   0]
 [  1   0   0   0   0   0 153   0   0   1   0   0   0   0   0   1   0   0
    0   3]
 [  2   0   0   0   0   0   0 162   2   0   0   0   0   0   0   0   0   1
    0   0]
 [  2   0   0   0   0   0   0   0 167   0   0   0   0   0   0   0   1   0
    0   0]
 [  2   1   1   1   0   0   0   0   1 165   0   0   0   0   0   0   0   0
    0   0]
 [  0   0   0   0   0   0   1   0   0   0 141   2   0   0   0   1   0   0
    0   2]
 [  0   0   1   3   0   0   1   0   0   0   4  45   1   0   0   0   0   0
    0   3]
 [  2   0   0   0   0   0   1   0   0   0   0   1 127   2   0   0   1   0
    1   1]
 [  0   2   1   0   0   0   0   0   0   0   1   0   0  87   0   0   0   0
    0   1]
 [  0   0   0   1   0   0   0   0   0   0   0   0   0   0 154   0   1   0
    1   0]
 [  0   1   1   0   0   0   0   0   0   0   0   0   0   0   0 157   0   2
    0   2]
 [  0   0   1   0   0   0   1   0   0   0   1   0   1   0   0   0 133   1
    0   4]
 [  1   0   0   1   0   0   0   0   0   1   0   1   1   1   0   0   0 149
    3   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   1   0   0   0   2   2
  159   1]
 [  0   1   2   0   0   0   3   0   1   0   1   0   1   0   0   0   0   1
    0 229]]
<br><br>Test Accuracy: 0.9037
Class 0009 Accuracy: 0.9013
Class 0017 Accuracy: 0.9812
Class 0034 Accuracy: 0.9286
Class 0036 Accuracy: 0.9091
Class 0074 Accuracy: 0.5000
Class 0077 Accuracy: 0.9730
Class 0114 Accuracy: 0.9375
Class 0121 Accuracy: 0.9401
Class 0180 Accuracy: 0.9353
Class 0202 Accuracy: 0.8889
Class 0235 Accuracy: 0.8776
Class 0257 Accuracy: 0.7069
Class 0265 Accuracy: 0.8456
Class 0281 Accuracy: 0.8804
Class 0298 Accuracy: 0.9177
Class 0300 Accuracy: 0.9571
Class 0364 Accuracy: 0.8662
Class 0368 Accuracy: 0.8481
Class 0370 Accuracy: 0.8788
Class 1331 Accuracy: 0.8787
Confusion Matrix:
[[137   0   1   0   0   0   4   2   0   3   1   1   0   2   0   0   0   1
    0   0]
 [  0 157   1   0   0   0   0   2   0   0   0   0   0   0   0   0   0   0
    0   0]
 [  0   0 143   4   0   0   1   0   2   0   0   0   0   0   0   0   0   3
    0   1]
 [  2   0   1 110   0   0   0   1   2   1   1   0   1   1   0   0   0   1
    0   0]
 [  0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   2   0   0
    0   1]
 [  0   0   0   0   0 144   0   0   2   0   0   0   2   0   0   0   0   0
    0   0]
 [  1   0   2   2   0   0 150   1   0   2   0   0   0   0   0   0   1   0
    0   1]
 [  3   1   1   0   0   0   0 157   1   1   0   0   1   0   0   1   0   0
    0   1]
 [  7   0   2   0   0   0   0   1 159   0   0   0   0   1   0   0   0   0
    0   0]
 [  3   1   3   3   0   0   2   0   2 152   0   0   1   0   1   0   1   1
    0   1]
 [  2   0   0   1   0   0   1   0   1   1 129   3   1   0   5   0   1   2
    0   0]
 [  1   0   0   0   0   0   0   0   0   2   6  41   1   0   3   0   1   2
    0   1]
 [  1   0   0   2   0   0   0   0   1   0   4   0 115   0   3   2   2   2
    2   2]
 [  1   2   0   1   0   0   0   0   0   1   1   0   0  81   1   1   0   3
    0   0]
 [  4   0   0   0   0   0   0   0   1   0   0   1   2   1 145   0   1   0
    3   0]
 [  0   0   0   0   0   0   1   0   0   0   0   0   0   2   0 156   1   1
    0   2]
 [  1   0   1   1   0   0   1   0   1   0   1   0   3   0   1   0 123   4
    2   3]
 [  1   1   0   9   0   2   1   0   2   0   0   0   2   0   0   0   3 134
    2   1]
 [  1   0   0   2   0   0   1   0   0   0   2   0   1   0   2   0   5   4
  145   2]
 [  4   2   2   3   1   0   4   1   0   1   3   0   0   0   0   3   4   0
    1 210]]
<br><br>Test Accuracy: 0.9606<br>
Class 0009 Accuracy: 0.9605<br>
Class 0017 Accuracy: 0.9688<br>
Class 0034 Accuracy: 0.9870<br>
Class 0036 Accuracy: 0.9669<br>
Class 0074 Accuracy: 0.9167<br>
Class 0077 Accuracy: 0.9932<br>
Class 0114 Accuracy: 0.9719<br>
Class 0121 Accuracy: 0.9880<br>
Class 0180 Accuracy: 0.9382<br>
Class 0202 Accuracy: 0.9795<br>
Class 0235 Accuracy: 0.9286<br>
Class 0257 Accuracy: 0.8793<br>
Class 0265 Accuracy: 0.9191<br>
Class 0281 Accuracy: 0.9402<br>
Class 0298 Accuracy: 0.9873<br>
Class 0300 Accuracy: 0.9785<br>
Class 0364 Accuracy: 0.9507<br>
Class 0368 Accuracy: 0.9335<br>
Class 0370 Accuracy: 0.9939<br>
Class 1331 Accuracy: 0.9331<br>
Confusion Matrix:<br>[[292   0   0   0   0   0   4   2   0   3   0   0   0   0   1   0   0   2
    0   0]
 [  0 310   0   0   0   0   0   0   0   2   0   1   0   0   0   0   0   0
    1   6]
 [  0   0 304   0   0   0   1   0   0   1   0   0   0   0   0   0   0   2
    0   0]
 [  1   0   2 234   0   0   0   0   0   0   0   1   0   2   0   0   0   2
    0   0]
 [  0   0   0   0  11   0   1   0   0   0   0   0   0   0   0   0   0   0
    0   0]
 [  0   0   0   0   0 294   0   0   0   0   0   1   0   0   0   0   0   1
    0   0]
 [  1   0   3   0   0   0 311   0   0   1   0   0   0   0   0   0   0   1
    0   3]
 [  0   0   1   0   0   0   0 330   0   0   1   1   0   0   0   0   0   0
    0   1]
 [  5   0   5   0   0   0   1   0 319   6   2   0   0   0   2   0   0   0
    0   0]
 [  1   2   0   1   0   0   1   0   0 335   0   0   0   0   0   0   1   0
    0   1]
 [  0   0   0   0   0   0   0   1   0   0 273  14   1   0   0   0   0   5
    0   0]
 [  0   0   0   0   0   0   1   1   0   0   3 102   1   0   1   0   0   3
    1   3]
 [  1   0   0   2   0   0   0   0   2   1   3   2 250   1   1   0   2   2
    2   3]
 [  0   0   1   3   0   0   0   0   0   3   0   1   0 173   2   0   0   1
    0   0]
 [  0   0   1   0   0   0   0   0   0   0   0   1   1   0 312   0   0   0
    1   0]
 [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   3 319   0   1
    1   2]
 [  0   0   1   0   0   0   0   0   0   0   0   0   0   0   1   0 270   3
    6   3]
 [  1   1   0   1   0   2   0   0   0   1   0   1   1   0   0   2   1 295
    7   3]
 [  0   0   0   0   0   0   0   0   0   0   1   0   0   0   0   0   0   1
  328   0]
 [  0   1   3   0   0   0   4   2   2   5   0   2   1   0   1   2   3   4
    2 446]]
]]></description><link>technology\科研\实验\efficientnetb0数据.html</link><guid isPermaLink="false">Technology/科研/实验/EfficientNetB0数据.md</guid><pubDate>Fri, 01 Nov 2024 11:50:24 GMT</pubDate></item><item><title><![CDATA[GCN]]></title><description><![CDATA[ 
 <br><br><br>总参数量：40596<br>
Final train acc: 0.975096,  Final test acc: 0.902686<br>
训练集每个类别的准确率:<br>
类别 0: 0.9341<br>
类别 1: 0.9891<br>
类别 2: 0.9690<br>
类别 3: 0.9647<br>
类别 4: 0.7826<br>
类别 5: 0.9949<br>
类别 6: 0.9922<br>
类别 7: 0.9865<br>
类别 8: 0.9956<br>
类别 9: 0.9692<br>
类别 10: 0.9676<br>
类别 11: 0.9440<br>
类别 12: 0.9430<br>
类别 13: 0.9973<br>
类别 14: 0.9952<br>
类别 15: 0.9923<br>
类别 16: 0.9560<br>
类别 17: 0.9794<br>
类别 18: 0.9727<br>
类别 19: 0.9707<br>
测试集每个类别的准确率:<br>
类别 0: 0.8224<br>
类别 1: 0.9625<br>
类别 2: 0.9091<br>
类别 3: 0.9174<br>
类别 4: 0.5000<br>
类别 5: 0.9932<br>
类别 6: 0.9125<br>
类别 7: 0.9461<br>
类别 8: 0.9059<br>
类别 9: 0.9064<br>
类别 10: 0.8435<br>
类别 11: 0.8103<br>
类别 12: 0.8162<br>
类别 13: 0.9348<br>
类别 14: 0.9304<br>
类别 15: 0.9571<br>
类别 16: 0.8099<br>
类别 17: 0.9051<br>
类别 18: 0.9091<br>
类别 19: 0.9038<br><br>Final train acc: 0.973785,  Final test acc: 0.888734<br>
训练集每个类别的准确率:<br>
类别 0: 0.9753<br>
类别 1: 0.9812<br>
类别 2: 0.9804<br>
类别 3: 0.9543<br>
类别 4: 0.7826<br>
类别 5: 0.9915<br>
类别 6: 0.9686<br>
类别 7: 0.9835<br>
类别 8: 0.9838<br>
类别 9: 0.9692<br>
类别 10: 0.9625<br>
类别 11: 0.8707<br>
类别 12: 0.9632<br>
类别 13: 0.9674<br>
类别 14: 0.9936<br>
类别 15: 0.9908<br>
类别 16: 0.9894<br>
类别 17: 0.9731<br>
类别 18: 0.9955<br>
类别 19: 0.9519<br>
测试集每个类别的准确率:<br>
类别 0: 0.8618<br>
类别 1: 0.9500<br>
类别 2: 0.8961<br>
类别 3: 0.8430<br>
类别 4: 0.5000<br>
类别 5: 0.9797<br>
类别 6: 0.9125<br>
类别 7: 0.8982<br>
类别 8: 0.8941<br>
类别 9: 0.8713<br>
类别 10: 0.7891<br>
类别 11: 0.6034<br>
类别 12: 0.8603<br>
类别 13: 0.8587<br>
类别 14: 0.9557<br>
类别 15: 0.9448<br>
类别 16: 0.8873<br>
类别 17: 0.8924<br>
类别 18: 0.9273<br>
类别 19: 0.8703<br>
Number of CEPs: 14, Test Accuracy: 0.8887<br><br>Number of CEPs: 12 begin<br>
Final train acc: 0.938134,  Final test acc: 0.859435<br>
训练集每个类别的准确率:<br>
类别 0: 0.9357<br>
类别 1: 0.9656<br>
类别 2: 0.9641<br>
类别 3: 0.8607<br>
类别 4: 0.6087<br>
类别 5: 0.9814<br>
类别 6: 0.9309<br>
类别 7: 0.9671<br>
类别 8: 0.9779<br>
类别 9: 0.9427<br>
类别 10: 0.9198<br>
类别 11: 0.7672<br>
类别 12: 0.9301<br>
类别 13: 0.9321<br>
类别 14: 0.9554<br>
类别 15: 0.9770<br>
类别 16: 0.9419<br>
类别 17: 0.9304<br>
类别 18: 0.9061<br>
类别 19: 0.9247<br>
测试集每个类别的准确率:<br>
类别 0: 0.8421<br>
类别 1: 0.9250<br>
类别 2: 0.8961<br>
类别 3: 0.7934<br>
类别 4: 0.3333<br>
类别 5: 0.9865<br>
类别 6: 0.8375<br>
类别 7: 0.9281<br>
类别 8: 0.8706<br>
类别 9: 0.8538<br>
类别 10: 0.7619<br>
类别 11: 0.6379<br>
类别 12: 0.8382<br>
类别 13: 0.9130<br>
类别 14: 0.8418<br>
类别 15: 0.9509<br>
类别 16: 0.8803<br>
类别 17: 0.8291<br>
类别 18: 0.7576<br>
类别 19: 0.8661<br>
Number of CEPs: 12, Test Accuracy: 0.8594<br>
Number of CEPs: 12 end<br>
Number of CEPs: 13 begin<br>
Final train acc: 0.970552,  Final test acc: 0.877572<br>
训练集每个类别的准确率:<br>
类别 0: 0.9605<br>
类别 1: 0.9906<br>
类别 2: 0.9837<br>
类别 3: 0.9626<br>
类别 4: 0.8261<br>
类别 5: 0.9915<br>
类别 6: 0.9859<br>
类别 7: 0.9835<br>
类别 8: 0.9971<br>
类别 9: 0.9809<br>
类别 10: 0.9642<br>
类别 11: 0.8793<br>
类别 12: 0.9467<br>
类别 13: 0.9755<br>
类别 14: 0.9745<br>
类别 15: 0.9846<br>
类别 16: 0.9472<br>
类别 17: 0.9668<br>
类别 18: 0.9758<br>
类别 19: 0.9425<br>
测试集每个类别的准确率:<br>
类别 0: 0.8487<br>
类别 1: 0.9375<br>
类别 2: 0.9156<br>
类别 3: 0.8926<br>
类别 4: 0.5000<br>
类别 5: 0.9797<br>
类别 6: 0.8938<br>
类别 7: 0.9042<br>
类别 8: 0.9000<br>
类别 9: 0.9006<br>
类别 10: 0.8367<br>
类别 11: 0.6724<br>
类别 12: 0.7794<br>
类别 13: 0.9130<br>
类别 14: 0.8797<br>
类别 15: 0.9264<br>
类别 16: 0.8239<br>
类别 17: 0.8671<br>
类别 18: 0.8303<br>
类别 19: 0.8619<br>
Number of CEPs: 13, Test Accuracy: 0.8776<br>
Number of CEPs: 13 end<br>
Number of CEPs: 14 begin<br>
Final train acc: 0.946959,  Final test acc: 0.875131<br>
训练集每个类别的准确率:<br>
类别 0: 0.9654<br>
类别 1: 0.9719<br>
类别 2: 0.9510<br>
类别 3: 0.9459<br>
类别 4: 0.8696<br>
类别 5: 0.9814<br>
类别 6: 0.9262<br>
类别 7: 0.9656<br>
类别 8: 0.9618<br>
类别 9: 0.9589<br>
类别 10: 0.9027<br>
类别 11: 0.8103<br>
类别 12: 0.8952<br>
类别 13: 0.9620<br>
类别 14: 0.9889<br>
类别 15: 0.9831<br>
类别 16: 0.9437<br>
类别 17: 0.9415<br>
类别 18: 0.9212<br>
类别 19: 0.9341<br>
测试集每个类别的准确率:<br>
类别 0: 0.9145<br>
类别 1: 0.9500<br>
类别 2: 0.9091<br>
类别 3: 0.8926<br>
类别 4: 0.5000<br>
类别 5: 0.9865<br>
类别 6: 0.8438<br>
类别 7: 0.8982<br>
类别 8: 0.8588<br>
类别 9: 0.8772<br>
类别 10: 0.7415<br>
类别 11: 0.6207<br>
类别 12: 0.8235<br>
类别 13: 0.9130<br>
类别 14: 0.9051<br>
类别 15: 0.9264<br>
类别 16: 0.8732<br>
类别 17: 0.8608<br>
类别 18: 0.8303<br>
类别 19: 0.8703<br>
Number of CEPs: 14, Test Accuracy: 0.8751<br>
Number of CEPs: 14 end<br><br>Number of CEPs: 13 begin<br>
Final train acc: 0.960329,  Final test acc: 0.880363<br>
训练集每个类别的准确率:<br>
类别 0: 0.9572<br>
类别 1: 0.9891<br>
类别 2: 0.9477<br>
类别 3: 0.9418<br>
类别 4: 0.7826<br>
类别 5: 0.9949<br>
类别 6: 0.9388<br>
类别 7: 0.9746<br>
类别 8: 0.9824<br>
类别 9: 0.9442<br>
类别 10: 0.9625<br>
类别 11: 0.7931<br>
类别 12: 0.9522<br>
类别 13: 0.9429<br>
类别 14: 0.9889<br>
类别 15: 0.9770<br>
类别 16: 0.9701<br>
类别 17: 0.9620<br>
类别 18: 0.9591<br>
类别 19: 0.9582<br>
测试集每个类别的准确率:<br>
类别 0: 0.8618<br>
类别 1: 0.9750<br>
类别 2: 0.8896<br>
类别 3: 0.8843<br>
类别 4: 0.5000<br>
类别 5: 0.9932<br>
类别 6: 0.8750<br>
类别 7: 0.8802<br>
类别 8: 0.9118<br>
类别 9: 0.8596<br>
类别 10: 0.8367<br>
类别 11: 0.6207<br>
类别 12: 0.8088<br>
类别 13: 0.8696<br>
类别 14: 0.9051<br>
类别 15: 0.9387<br>
类别 16: 0.8803<br>
类别 17: 0.8671<br>
类别 18: 0.8242<br>
类别 19: 0.8828<br>
Number of CEPs: 13, Test Accuracy: 0.8804<br>
Number of CEPs: 13 end<br>
Number of CEPs: 14 begin<br>
Final train acc: 0.977106,  Final test acc: 0.887339<br>
训练集每个类别的准确率:<br>
类别 0: 0.9736<br>
类别 1: 0.9828<br>
类别 2: 0.9902<br>
类别 3: 0.9584<br>
类别 4: 0.8261<br>
类别 5: 0.9966<br>
类别 6: 0.9639<br>
类别 7: 0.9880<br>
类别 8: 0.9926<br>
类别 9: 0.9868<br>
类别 10: 0.9693<br>
类别 11: 0.9181<br>
类别 12: 0.9577<br>
类别 13: 0.9647<br>
类别 14: 0.9952<br>
类别 15: 0.9939<br>
类别 16: 0.9665<br>
类别 17: 0.9778<br>
类别 18: 0.9773<br>
类别 19: 0.9686<br>
测试集每个类别的准确率:<br>
类别 0: 0.8355<br>
类别 1: 0.9437<br>
类别 2: 0.9351<br>
类别 3: 0.8678<br>
类别 4: 0.5000<br>
类别 5: 0.9865<br>
类别 6: 0.8938<br>
类别 7: 0.9162<br>
类别 8: 0.8588<br>
类别 9: 0.8830<br>
类别 10: 0.8503<br>
类别 11: 0.6034<br>
类别 12: 0.8603<br>
类别 13: 0.8696<br>
类别 14: 0.9367<br>
类别 15: 0.9325<br>
类别 16: 0.8944<br>
类别 17: 0.9114<br>
类别 18: 0.8485<br>
类别 19: 0.8661<br>
Number of CEPs: 14, Test Accuracy: 0.8873<br>
Number of CEPs: 14 end<br>epoch time: 10.644408<br><br>Final train acc: 0.962251,  Final test acc: 0.870945<br>
训练集每个类别的准确率:<br>
类别 0: 0.9357<br>
类别 1: 0.9828<br>
类别 2: 0.9706<br>
类别 3: 0.9584<br>
类别 4: 0.8261<br>
类别 5: 0.9983<br>
类别 6: 0.9137<br>
类别 7: 0.9835<br>
类别 8: 0.9765<br>
类别 9: 0.9515<br>
类别 10: 0.9369<br>
类别 11: 0.9569<br>
类别 12: 0.9228<br>
类别 13: 0.9674<br>
类别 14: 0.9809<br>
类别 15: 0.9923<br>
类别 16: 0.9665<br>
类别 17: 0.9810<br>
类别 18: 0.9470<br>
类别 19: 0.9582<br>
测试集每个类别的准确率:<br>
类别 0: 0.8158<br>
类别 1: 0.9625<br>
类别 2: 0.9286<br>
类别 3: 0.8760<br>
类别 4: 0.6667<br>
类别 5: 0.9932<br>
类别 6: 0.7812<br>
类别 7: 0.8862<br>
类别 8: 0.8588<br>
类别 9: 0.8713<br>
类别 10: 0.7347<br>
类别 11: 0.7069<br>
类别 12: 0.7721<br>
类别 13: 0.8696<br>
类别 14: 0.9177<br>
类别 15: 0.9571<br>
类别 16: 0.8662<br>
类别 17: 0.8987<br>
类别 18: 0.8303<br>
类别 19: 0.8954<br>
Number of CEPs: 14, Test Accuracy: 0.8709<br><br>Final train acc: 0.978067,  Final test acc: 0.892919<br>
训练集每个类别的准确率:<br>
类别 0: 0.9703<br>
类别 1: 0.9922<br>
类别 2: 0.9918<br>
类别 3: 0.9688<br>
类别 4: 0.7826<br>
类别 5: 0.9949<br>
类别 6: 0.9906<br>
类别 7: 0.9760<br>
类别 8: 0.9897<br>
类别 9: 0.9809<br>
类别 10: 0.9710<br>
类别 11: 0.9397<br>
类别 12: 0.9559<br>
类别 13: 0.9783<br>
类别 14: 0.9936<br>
类别 15: 0.9770<br>
类别 16: 0.9771<br>
类别 17: 0.9794<br>
类别 18: 0.9894<br>
类别 19: 0.9550<br>
测试集每个类别的准确率:<br>
类别 0: 0.8750<br>
类别 1: 0.9625<br>
类别 2: 0.9416<br>
类别 3: 0.8678<br>
类别 4: 0.5000<br>
类别 5: 0.9865<br>
类别 6: 0.9250<br>
类别 7: 0.9102<br>
类别 8: 0.8882<br>
类别 9: 0.8889<br>
类别 10: 0.8367<br>
类别 11: 0.6897<br>
类别 12: 0.8309<br>
类别 13: 0.8804<br>
类别 14: 0.8797<br>
类别 15: 0.8957<br>
类别 16: 0.8873<br>
类别 17: 0.8924<br>
类别 18: 0.9212<br>
类别 19: 0.8787<br>
Number of CEPs: 14, Test Accuracy: 0.8929<br><br>Final train acc: 0.940668,  Final test acc: 0.870248<br>
训练集每个类别的准确率:<br>
类别 0: 0.9506<br>
类别 1: 0.9609<br>
类别 2: 0.9297<br>
类别 3: 0.8857<br>
类别 4: 0.4348<br>
类别 5: 0.9831<br>
类别 6: 0.9717<br>
类别 7: 0.9716<br>
类别 8: 0.9765<br>
类别 9: 0.9354<br>
类别 10: 0.9334<br>
类别 11: 0.7931<br>
类别 12: 0.9099<br>
类别 13: 0.9022<br>
类别 14: 0.9745<br>
类别 15: 0.9708<br>
类别 16: 0.9014<br>
类别 17: 0.9446<br>
类别 18: 0.9485<br>
类别 19: 0.9226<br>
测试集每个类别的准确率:<br>
类别 0: 0.8816<br>
类别 1: 0.9313<br>
类别 2: 0.9091<br>
类别 3: 0.7934<br>
类别 4: 0.3333<br>
类别 5: 0.9662<br>
类别 6: 0.9313<br>
类别 7: 0.9042<br>
类别 8: 0.8941<br>
类别 9: 0.8889<br>
类别 10: 0.7891<br>
类别 11: 0.6724<br>
类别 12: 0.8162<br>
类别 13: 0.8370<br>
类别 14: 0.8924<br>
类别 15: 0.9202<br>
类别 16: 0.8099<br>
类别 17: 0.8734<br>
类别 18: 0.8485<br>
类别 19: 0.8368<br>
Number of CEPs: 14, Test Accuracy: 0.8702<br><br>Final train acc: 0.979640,  Final test acc: 0.889083<br>
训练集每个类别的准确率:<br>
类别 0: 0.9901<br>
类别 1: 0.9797<br>
类别 2: 0.9869<br>
类别 3: 0.9813<br>
类别 4: 0.8696<br>
类别 5: 0.9898<br>
类别 6: 0.9749<br>
类别 7: 0.9895<br>
类别 8: 0.9941<br>
类别 9: 0.9824<br>
类别 10: 0.9812<br>
类别 11: 0.9009<br>
类别 12: 0.9430<br>
类别 13: 0.9946<br>
类别 14: 0.9936<br>
类别 15: 0.9954<br>
类别 16: 0.9930<br>
类别 17: 0.9810<br>
类别 18: 0.9833<br>
类别 19: 0.9498<br>
测试集每个类别的准确率:<br>
类别 0: 0.9145<br>
类别 1: 0.9250<br>
类别 2: 0.9545<br>
类别 3: 0.8843<br>
类别 4: 0.5000<br>
类别 5: 0.9865<br>
类别 6: 0.8812<br>
类别 7: 0.9461<br>
类别 8: 0.9176<br>
类别 9: 0.8480<br>
类别 10: 0.8503<br>
类别 11: 0.5690<br>
类别 12: 0.8015<br>
类别 13: 0.9239<br>
类别 14: 0.8734<br>
类别 15: 0.9448<br>
类别 16: 0.9225<br>
类别 17: 0.9177<br>
类别 18: 0.8121<br>
类别 19: 0.8577<br><br>window_time_ms = 20 hop_time_ms = 10  sr=16000<br>
Final train acc: 0.958406,  Final test acc: 0.887339<br>
训练集每个类别的准确率:<br>
类别 0: 0.9259<br>
类别 1: 0.9734<br>
类别 2: 0.9559<br>
类别 3: 0.9376<br>
类别 4: 0.8261<br>
类别 5: 0.9932<br>
类别 6: 0.9341<br>
类别 7: 0.9805<br>
类别 8: 0.9956<br>
类别 9: 0.9604<br>
类别 10: 0.9744<br>
类别 11: 0.8578<br>
类别 12: 0.9246<br>
类别 13: 0.9701<br>
类别 14: 0.9793<br>
类别 15: 0.9831<br>
类别 16: 0.9665<br>
类别 17: 0.9668<br>
类别 18: 0.9455<br>
类别 19: 0.9331<br>
测试集每个类别的准确率:<br>
类别 0: 0.8355<br>
类别 1: 0.9500<br>
类别 2: 0.9091<br>
类别 3: 0.8760<br>
类别 4: 0.5000<br>
类别 5: 0.9865<br>
类别 6: 0.8625<br>
类别 7: 0.9341<br>
类别 8: 0.9353<br>
类别 9: 0.8830<br>
类别 10: 0.8367<br>
类别 11: 0.7069<br>
类别 12: 0.8309<br>
类别 13: 0.8804<br>
类别 14: 0.9241<br>
类别 15: 0.9325<br>
类别 16: 0.8803<br>
类别 17: 0.8671<br>
类别 18: 0.8485<br>
类别 19: 0.8703<br>
Number of CEPs: 14, Test Accuracy: 0.8873<br><br>Final train acc: 0.947798,  Final test acc: 0.860830<br>
训练集每个类别的准确率:<br>
类别 0: 0.9055<br>
类别 1: 0.9563<br>
类别 2: 0.9673<br>
类别 3: 0.9363<br>
类别 4: 0.8824<br>
类别 5: 0.9796<br>
类别 6: 0.9582<br>
类别 7: 0.9581<br>
类别 8: 0.9804<br>
类别 9: 0.9569<br>
类别 10: 0.8907<br>
类别 11: 0.8161<br>
类别 12: 0.9363<br>
类别 13: 0.9130<br>
类别 14: 0.9873<br>
类别 15: 0.9795<br>
类别 16: 0.9601<br>
类别 17: 0.9599<br>
类别 18: 0.9455<br>
类别 19: 0.9261<br>
测试集每个类别的准确率:<br>
类别 0: 0.8092<br>
类别 1: 0.8812<br>
类别 2: 0.9026<br>
类别 3: 0.8264<br>
类别 4: 0.5000<br>
类别 5: 0.9527<br>
类别 6: 0.8812<br>
类别 7: 0.8982<br>
类别 8: 0.9059<br>
类别 9: 0.8655<br>
类别 10: 0.7211<br>
类别 11: 0.5517<br>
类别 12: 0.8456<br>
类别 13: 0.7935<br>
类别 14: 0.9367<br>
类别 15: 0.9080<br>
类别 16: 0.8944<br>
类别 17: 0.8734<br>
类别 18: 0.8606<br>
类别 19: 0.8326<br>
Number of CEPs: 14, Test Accuracy: 0.8608<br><br>Final train acc: 0.966325,  Final test acc: 0.877708<br>
训练集每个类别的准确率:<br>
类别 0: 0.9538<br>
类别 1: 0.9792<br>
类别 2: 0.9673<br>
类别 3: 0.9557<br>
类别 4: 0.8824<br>
类别 5: 0.9796<br>
类别 6: 0.9833<br>
类别 7: 0.9860<br>
类别 8: 0.9725<br>
类别 9: 0.9569<br>
类别 10: 0.9567<br>
类别 11: 0.9080<br>
类别 12: 0.9583<br>
类别 13: 0.9638<br>
类别 14: 0.9809<br>
类别 15: 0.9980<br>
类别 16: 0.9577<br>
类别 17: 0.9726<br>
类别 18: 0.9495<br>
类别 19: 0.9484<br>
测试集每个类别的准确率:<br>
类别 0: 0.8224<br>
类别 1: 0.9313<br>
类别 2: 0.8954<br>
类别 3: 0.8083<br>
类别 4: 0.6667<br>
类别 5: 0.9459<br>
类别 6: 0.9308<br>
类别 7: 0.9341<br>
类别 8: 0.9353<br>
类别 9: 0.8412<br>
类别 10: 0.7551<br>
类别 11: 0.7759<br>
类别 12: 0.8162<br>
类别 13: 0.8696<br>
类别 14: 0.9045<br>
类别 15: 0.9632<br>
类别 16: 0.8662<br>
类别 17: 0.8734<br>
类别 18: 0.8848<br>
类别 19: 0.8410<br>
Number of CEPs: 14, Test Accuracy: 0.8777<br><br>Final Test Accuracy: 73.04%<br>
Class 0 Accuracy: 69.74%<br>
Class 1 Accuracy: 84.38%<br>
Class 2 Accuracy: 82.47%<br>
Class 3 Accuracy: 64.46%<br>
Class 4 Accuracy: 0.00%<br>
Class 5 Accuracy: 86.49%<br>
Class 6 Accuracy: 73.12%<br>
Class 7 Accuracy: 83.83%<br>
Class 8 Accuracy: 86.47%<br>
Class 9 Accuracy: 65.50%<br>
Class 10 Accuracy: 59.18%<br>
Class 11 Accuracy: 25.86%<br>
Class 12 Accuracy: 61.03%<br>
Class 13 Accuracy: 58.70%<br>
Class 14 Accuracy: 82.91%<br>
Class 15 Accuracy: 73.62%<br>
Class 16 Accuracy: 66.20%<br>
Class 17 Accuracy: 72.15%<br>
Class 18 Accuracy: 72.73%<br>
Class 19 Accuracy: 77.82%<br><br><br>总参数量: 4,033,168<br>
Test Accuracy: 0.9355<br>
Class 0009 Accuracy: 0.9145<br>
Class 0017 Accuracy: 0.9625<br>
Class 0034 Accuracy: 0.9675<br>
Class 0036 Accuracy: 0.9339<br>
Class 0074 Accuracy: 0.6667<br>
Class 0077 Accuracy: 0.9797<br>
Class 0114 Accuracy: 0.9563<br>
Class 0121 Accuracy: 0.9461<br>
Class 0180 Accuracy: 0.9118<br>
Class 0202 Accuracy: 0.9474<br>
Class 0235 Accuracy: 0.9116<br>
Class 0257 Accuracy: 0.9138<br>
Class 0265 Accuracy: 0.8676<br>
Class 0281 Accuracy: 0.9348<br>
Class 0298 Accuracy: 0.9620<br>
Class 0300 Accuracy: 0.9816<br>
Class 0364 Accuracy: 0.9507<br>
Class 0368 Accuracy: 0.8924<br>
Class 0370 Accuracy: 0.9515<br>
Class 1331 Accuracy: 0.8954<br>
Confusion Matrix:<br>
[[139   0   1   1   0   0   2   3   1   1   1   0   0   1   1   0   0   1<br>
0   0]<br>
[  2 154   0   0   0   0   0   1   0   2   0   0   0   0   1   0   0   0<br>
0   0]<br>
[  0   1 149   0   0   0   0   0   0   1   0   1   0   1   0   0   0   0<br>
1   0]<br>
[  4   0   0 113   0   1   0   0   0   2   0   0   0   1   0   0   0   0<br>
0   0]<br>
[  1   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0<br>
0   1]<br>
[  0   0   1   0   0 145   0   0   0   0   0   0   0   0   0   0   2   0<br>
0   0]<br>
[  2   0   1   0   0   0 153   0   2   0   0   1   0   0   0   0   0   0<br>
0   1]<br>
[  1   3   1   0   0   0   1 158   0   0   0   1   0   1   0   0   0   0<br>
0   1]<br>
[  6   0   2   0   0   0   1   0 155   2   1   0   0   0   0   1   1   1<br>
0   0]<br>
[  2   0   0   1   0   0   1   0   0 162   0   0   1   0   0   0   1   0<br>
0   3]<br>
[  0   0   0   0   0   0   0   1   0   0 134   4   2   0   0   2   2   2<br>
0   0]<br>
[  0   0   0   1   0   0   0   0   0   0   1  53   1   0   0   0   1   0<br>
0   1]<br>
[  1   0   0   0   0   0   0   0   1   1   0   2 118   2   1   2   3   0<br>
3   2]<br>
[  0   2   0   0   0   0   0   0   0   2   0   0   0  86   1   0   0   1<br>
0   0]<br>
[  0   0   0   0   0   0   0   0   0   0   0   0   0   1 152   0   0   0<br>
4   1]<br>
[  0   0   0   0   0   0   0   0   0   0   0   0   0   1   1 160   1   0<br>
0   0]<br>
[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   1   1 135   1<br>
4   0]<br>
[  1   1   0   1   0   0   0   0   0   2   0   0   0   1   0   1   1 141<br>
7   2]<br>
[  0   0   0   0   0   0   1   0   0   1   0   0   0   0   0   1   2   2<br>
157   1]<br>
[  1   1   4   0   0   0   2   1   1   5   1   1   1   1   0   1   2   3<br>
0 214]<br><a data-tooltip-position="top" aria-label="file:///h%3A/BaiduSyncdisk/python/GCN%20for%20Audio/figs/dominant_frequencies_boxplot.pdf" rel="noopener nofollow" class="external-link" href="file:\\h%3A\BaiduSyncdisk\python\GCN for Audio\figs\dominant_frequencies_boxplot.pdf" target="_blank">H:\BaiduSyncdisk\python\GCN for Audio\figs\dominant_frequencies_boxplot.pdf</a><br><br>Test Accuracy: 0.9184<br>
Class 0009 Accuracy: 0.8947<br>
Class 0017 Accuracy: 0.9688<br>
Class 0034 Accuracy: 0.9610<br>
Class 0036 Accuracy: 0.9091<br>
Class 0074 Accuracy: 0.5000<br>
Class 0077 Accuracy: 0.9797<br>
Class 0114 Accuracy: 0.9375<br>
Class 0121 Accuracy: 0.9521<br>
Class 0180 Accuracy: 0.9176<br>
Class 0202 Accuracy: 0.9298<br>
Class 0235 Accuracy: 0.8844<br>
Class 0257 Accuracy: 0.8448<br>
Class 0265 Accuracy: 0.8971<br>
Class 0281 Accuracy: 0.9239<br>
Class 0298 Accuracy: 0.9684<br>
Class 0300 Accuracy: 0.9632<br>
Class 0364 Accuracy: 0.8803<br>
Class 0368 Accuracy: 0.8671<br>
Class 0370 Accuracy: 0.9030<br>
Class 1331 Accuracy: 0.8577<br>
Confusion Matrix:<br>
[[136   1   0   1   0   0   3   3   1   3   0   1   0   1   1   0   0   1<br>
0   0]<br>
[  1 155   0   0   0   0   0   1   1   0   1   1   0   0   0   0   0   0<br>
0   0]<br>
[  0   0 148   0   0   0   0   1   2   1   1   0   0   0   0   0   0   0<br>
1   0]<br>
[  1   0   0 110   0   1   0   0   2   2   0   1   1   1   0   0   1   0<br>
1   0]<br>
[  0   0   0   0   3   0   0   0   0   0   0   0   0   0   0   1   0   0<br>
0   2]<br>
[  0   0   1   0   0 145   0   0   0   0   0   0   0   0   0   0   1   0<br>
0   1]<br>
[  3   0   1   0   0   0 150   0   0   1   0   2   0   1   0   0   0   1<br>
1   0]<br>
[  0   2   1   0   0   0   0 159   0   2   0   0   0   2   0   1   0   0<br>
0   0]<br>
[  6   2   2   0   0   0   0   0 156   3   0   0   0   0   0   0   0   0<br>
0   1]<br>
[  2   0   2   2   0   0   0   0   2 159   0   0   1   1   0   0   0   0<br>
0   2]<br>
[  1   0   0   1   0   0   0   0   0   0 130   7   0   1   0   2   0   2<br>
2   1]<br>
[  0   1   0   0   0   0   0   0   0   0   4  49   1   0   2   0   1   0<br>
0   0]<br>
[  1   0   0   0   0   0   0   0   2   0   0   2 122   0   2   1   2   0<br>
1   3]<br>
[  0   1   0   0   0   0   0   0   0   2   0   0   0  85   3   0   0   1<br>
0   0]<br>
[  0   0   0   0   0   0   0   0   0   0   0   1   2   1 153   0   0   0<br>
1   0]<br>
[  0   1   0   0   0   0   1   0   0   0   0   0   0   2   0 157   1   0<br>
1   0]<br>
[  0   0   1   0   0   0   1   0   0   1   0   0   0   0   0   0 125   1<br>
9   4]<br>
[  1   0   0   2   0   3   0   1   0   0   0   1   0   1   1   1   2 137<br>
6   2]<br>
[  1   0   0   0   0   0   0   0   0   1   1   0   3   0   0   1   6   1<br>
149   2]<br>
[  1   1   3   1   0   2   4   1   2   3   3   0   2   0   0   0   6   0<br>
5 205]]<br><br><br>总参数量: 4,033,168<br>
Test Accuracy: 0.9500<br>
Class 0009 Accuracy: 0.9258<br>
Class 0017 Accuracy: 0.9831<br>
Class 0034 Accuracy: 0.9607<br>
Class 0036 Accuracy: 0.9444<br>
Class 0074 Accuracy: 0.6667<br>
Class 0077 Accuracy: 0.9863<br>
Class 0114 Accuracy: 0.9622<br>
Class 0121 Accuracy: 0.9879<br>
Class 0180 Accuracy: 0.9484<br>
Class 0202 Accuracy: 0.9252<br>
Class 0235 Accuracy: 0.9591<br>
Class 0257 Accuracy: 0.9036<br>
Class 0265 Accuracy: 0.9208<br>
Class 0281 Accuracy: 0.9496<br>
Class 0298 Accuracy: 0.9534<br>
Class 0300 Accuracy: 0.9752<br>
Class 0364 Accuracy: 0.9346<br>
Class 0368 Accuracy: 0.9280<br>
Class 0370 Accuracy: 0.9508<br>
Class 1331 Accuracy: 0.9348<br>
Confusion Matrix:<br>
[[212   1   0   1   0   0   2   2   2   2   1   1   0   1   2   1   0   1<br>
0   0]<br>
[  1 233   0   0   0   0   2   1   0   0   0   0   0   0   0   0   0   0<br>
0   0]<br>
[  0   1 220   3   0   0   0   0   2   2   0   0   0   0   0   0   0   0<br>
1   0]<br>
[  1   0   0 170   0   0   1   0   1   0   0   1   0   1   1   1   0   2<br>
0   1]<br>
[  0   0   0   0   6   0   0   0   0   0   0   0   0   0   0   0   0   0<br>
0   3]<br>
[  0   0   1   0   0 216   0   0   0   0   0   0   0   0   0   0   1   0<br>
1   0]<br>
[  5   0   1   0   0   1 229   1   0   1   0   0   0   0   0   0   0   0<br>
0   0]<br>
[  0   1   0   0   0   0   0 245   0   1   1   0   0   0   0   0   0   0<br>
0   0]<br>
[  8   1   0   1   0   0   0   0 239   2   1   0   0   0   0   0   0   0<br>
0   0]<br>
[  6   0   2   2   0   0   0   3   3 235   0   0   0   0   0   1   1   0<br>
0   1]<br>
[  1   0   0   0   0   0   0   0   0   0 211   5   2   0   0   0   0   1<br>
0   0]<br>
[  0   0   0   1   0   0   0   0   0   0   1  75   2   0   1   0   1   1<br>
0   1]<br>
[  1   0   0   0   0   0   0   0   0   1   3   0 186   0   1   2   2   0<br>
1   5]<br>
[  0   1   0   0   0   0   0   0   0   2   2   1   0 132   0   0   0   1<br>
0   0]<br>
[  1   0   0   3   0   0   0   0   0   0   0   1   0   3 225   1   0   1<br>
1   0]<br>
[  0   0   0   0   0   0   1   0   0   1   0   0   0   1   0 236   1   0<br>
0   2]<br>
[  0   0   1   0   0   0   1   0   0   1   0   1   0   0   1   0 200   4<br>
4   1]<br>
[  1   0   0   1   0   0   0   0   0   1   0   1   0   0   0   1   3 219<br>
6   3]<br>
[  0   0   0   0   0   0   1   0   0   1   0   0   3   0   0   0   6   0<br>
232   1]<br>
[  0   0   2   1   0   1   1   1   2   1   1   0   1   0   0   1   6   1<br>
4 330]]<br>
<img alt="{4DAF5396-9453-4F75-9EA8-90BC971BA1F6}.png" src="\lib\media\{4daf5396-9453-4f75-9ea8-90bc971ba1f6}.png"><br>
为对比公平我们没有使用预训练好的权重，因为我们想对比网络之间的差异。<br>
由于边缘设备的录音能力有限，我们设置采样率为16000。<br><br>Test Accuracy: 0.9208<br>
Class 0009 Accuracy: 0.8421<br>
Class 0017 Accuracy: 0.9313<br>
Class 0034 Accuracy: 0.9221<br>
Class 0036 Accuracy: 0.9256<br>
Class 0074 Accuracy: 0.6667<br>
Class 0077 Accuracy: 0.9730<br>
Class 0114 Accuracy: 0.9250<br>
Class 0121 Accuracy: 0.9880<br>
Class 0180 Accuracy: 0.9353<br>
Class 0202 Accuracy: 0.8772<br>
Class 0235 Accuracy: 0.8844<br>
Class 0257 Accuracy: 0.7931<br>
Class 0265 Accuracy: 0.8676<br>
Class 0281 Accuracy: 0.9348<br>
Class 0298 Accuracy: 0.9620<br>
Class 0300 Accuracy: 0.9693<br>
Class 0364 Accuracy: 0.9366<br>
Class 0368 Accuracy: 0.9114<br>
Class 0370 Accuracy: 0.9515<br>
Class 1331 Accuracy: 0.8996<br>
Confusion Matrix:<br>
[[128   1   0   2   0   0   1   5   0   2   0   1   1   3   2   1   0   1<br>
1   3]<br>
[  3 149   1   1   0   0   0   2   0   2   1   0   0   0   0   0   0   0<br>
0   1]<br>
[  0   1 142   3   0   0   1   1   1   2   0   0   0   1   0   0   1   0<br>
0   1]<br>
[  0   0   0 112   0   1   0   0   1   3   0   1   0   1   1   0   0   1<br>
0   0]<br>
[  0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0<br>
0   2]<br>
[  0   0   3   0   0 144   0   0   0   0   0   0   0   0   0   0   1   0<br>
0   0]<br>
[  6   0   0   1   0   1 148   0   0   1   0   0   0   1   0   0   0   0<br>
0   2]<br>
[  1   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   1<br>
0   0]<br>
[  6   0   1   1   0   0   0   1 159   1   0   0   0   0   0   0   0   0<br>
1   0]<br>
[  5   0   0   1   0   0   2   2   2 150   0   0   0   1   0   0   3   1<br>
0   4]<br>
[  0   0   0   0   0   0   0   1   0   0 130   6   0   2   3   2   0   0<br>
1   2]<br>
[  0   0   0   1   0   0   0   0   0   0   6  46   1   1   1   0   0   0<br>
0   2]<br>
[  1   0   2   0   0   0   1   0   0   1   3   0 118   0   1   1   2   1<br>
1   4]<br>
[  1   0   1   0   0   1   0   0   0   0   0   0   1  86   2   0   0   0<br>
0   0]<br>
[  1   0   0   0   0   0   0   0   0   0   0   0   0   1 152   0   2   0<br>
2   0]<br>
[  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 158   0   0<br>
0   3]<br>
[  0   1   0   1   0   0   0   0   0   1   2   0   0   0   0   0 133   0<br>
1   3]<br>
[  2   0   0   1   0   0   0   0   0   0   0   0   2   0   0   1   1 144<br>
4   3]<br>
[  0   0   0   2   0   0   1   0   1   0   0   0   0   0   0   0   2   2<br>
157   0]<br>
[  1   1   1   1   0   1   0   1   2   2   2   3   0   0   0   0   7   1<br>
1 215]]<br><br>Test Accuracy: 0.9208<br>
Class 0009 Accuracy: 0.8421<br>
Class 0017 Accuracy: 0.9313<br>
Class 0034 Accuracy: 0.9221<br>
Class 0036 Accuracy: 0.9256<br>
Class 0074 Accuracy: 0.6667<br>
Class 0077 Accuracy: 0.9730<br>
Class 0114 Accuracy: 0.9250<br>
Class 0121 Accuracy: 0.9880<br>
Class 0180 Accuracy: 0.9353<br>
Class 0202 Accuracy: 0.8772<br>
Class 0235 Accuracy: 0.8844<br>
Class 0257 Accuracy: 0.7931<br>
Class 0265 Accuracy: 0.8676<br>
Class 0281 Accuracy: 0.9348<br>
Class 0298 Accuracy: 0.9620<br>
Class 0300 Accuracy: 0.9693<br>
Class 0364 Accuracy: 0.9366<br>
Class 0368 Accuracy: 0.9114<br>
Class 0370 Accuracy: 0.9515<br>
Class 1331 Accuracy: 0.8996<br>
Confusion Matrix:<br>
[[128   1   0   2   0   0   1   5   0   2   0   1   1   3   2   1   0   1<br>
1   3]<br>
[  3 149   1   1   0   0   0   2   0   2   1   0   0   0   0   0   0   0<br>
0   1]<br>
[  0   1 142   3   0   0   1   1   1   2   0   0   0   1   0   0   1   0<br>
0   1]<br>
[  0   0   0 112   0   1   0   0   1   3   0   1   0   1   1   0   0   1<br>
0   0]<br>
[  0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0<br>
0   2]<br>
[  0   0   3   0   0 144   0   0   0   0   0   0   0   0   0   0   1   0<br>
0   0]<br>
[  6   0   0   1   0   1 148   0   0   1   0   0   0   1   0   0   0   0<br>
0   2]<br>
[  1   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   1<br>
0   0]<br>
[  6   0   1   1   0   0   0   1 159   1   0   0   0   0   0   0   0   0<br>
1   0]<br>
[  5   0   0   1   0   0   2   2   2 150   0   0   0   1   0   0   3   1<br>
0   4]<br>
[  0   0   0   0   0   0   0   1   0   0 130   6   0   2   3   2   0   0<br>
1   2]<br>
[  0   0   0   1   0   0   0   0   0   0   6  46   1   1   1   0   0   0<br>
0   2]<br>
[  1   0   2   0   0   0   1   0   0   1   3   0 118   0   1   1   2   1<br>
1   4]<br>
[  1   0   1   0   0   1   0   0   0   0   0   0   1  86   2   0   0   0<br>
0   0]<br>
[  1   0   0   0   0   0   0   0   0   0   0   0   0   1 152   0   2   0<br>
2   0]<br>
[  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 158   0   0<br>
0   3]<br>
[  0   1   0   1   0   0   0   0   0   1   2   0   0   0   0   0 133   0<br>
1   3]<br>
[  2   0   0   1   0   0   0   0   0   0   0   0   2   0   0   1   1 144<br>
4   3]<br>
[  0   0   0   2   0   0   1   0   1   0   0   0   0   0   0   0   2   2<br>
157   0]<br>
[  1   1   1   1   0   1   0   1   2   2   2   3   0   0   0   0   7   1<br>
1 215]]<br><br>Test Accuracy: 0.9208<br>
Class 0009 Accuracy: 0.8421<br>
Class 0017 Accuracy: 0.9313<br>
Class 0034 Accuracy: 0.9221<br>
Class 0036 Accuracy: 0.9256<br>
Class 0074 Accuracy: 0.6667<br>
Class 0077 Accuracy: 0.9730<br>
Class 0114 Accuracy: 0.9250<br>
Class 0121 Accuracy: 0.9880<br>
Class 0180 Accuracy: 0.9353<br>
Class 0202 Accuracy: 0.8772<br>
Class 0235 Accuracy: 0.8844<br>
Class 0257 Accuracy: 0.7931<br>
Class 0265 Accuracy: 0.8676<br>
Class 0281 Accuracy: 0.9348<br>
Class 0298 Accuracy: 0.9620<br>
Class 0300 Accuracy: 0.9693<br>
Class 0364 Accuracy: 0.9366<br>
Class 0368 Accuracy: 0.9114<br>
Class 0370 Accuracy: 0.9515<br>
Class 1331 Accuracy: 0.8996<br>
Confusion Matrix:<br>
[[128   1   0   2   0   0   1   5   0   2   0   1   1   3   2   1   0   1<br>
1   3]<br>
[  3 149   1   1   0   0   0   2   0   2   1   0   0   0   0   0   0   0<br>
0   1]<br>
[  0   1 142   3   0   0   1   1   1   2   0   0   0   1   0   0   1   0<br>
0   1]<br>
[  0   0   0 112   0   1   0   0   1   3   0   1   0   1   1   0   0   1<br>
0   0]<br>
[  0   0   0   0   4   0   0   0   0   0   0   0   0   0   0   0   0   0<br>
0   2]<br>
[  0   0   3   0   0 144   0   0   0   0   0   0   0   0   0   0   1   0<br>
0   0]<br>
[  6   0   0   1   0   1 148   0   0   1   0   0   0   1   0   0   0   0<br>
0   2]<br>
[  1   0   0   0   0   0   0 165   0   0   0   0   0   0   0   0   0   1<br>
0   0]<br>
[  6   0   1   1   0   0   0   1 159   1   0   0   0   0   0   0   0   0<br>
1   0]<br>
[  5   0   0   1   0   0   2   2   2 150   0   0   0   1   0   0   3   1<br>
0   4]<br>
[  0   0   0   0   0   0   0   1   0   0 130   6   0   2   3   2   0   0<br>
1   2]<br>
[  0   0   0   1   0   0   0   0   0   0   6  46   1   1   1   0   0   0<br>
0   2]<br>
[  1   0   2   0   0   0   1   0   0   1   3   0 118   0   1   1   2   1<br>
1   4]<br>
[  1   0   1   0   0   1   0   0   0   0   0   0   1  86   2   0   0   0<br>
0   0]<br>
[  1   0   0   0   0   0   0   0   0   0   0   0   0   1 152   0   2   0<br>
2   0]<br>
[  0   0   0   0   0   0   0   0   0   1   0   0   1   0   0 158   0   0<br>
0   3]<br>
[  0   1   0   1   0   0   0   0   0   1   2   0   0   0   0   0 133   0<br>
1   3]<br>
[  2   0   0   1   0   0   0   0   0   0   0   0   2   0   0   1   1 144<br>
4   3]<br>
[  0   0   0   2   0   0   1   0   1   0   0   0   0   0   0   0   2   2<br>
157   0]<br>
[  1   1   1   1   0   1   0   1   2   2   2   3   0   0   0   0   7   1<br>
1 215]]]]></description><link>technology\科研\实验\final.html</link><guid isPermaLink="false">Technology/科研/实验/FINAL.md</guid><pubDate>Fri, 29 Nov 2024 03:06:10 GMT</pubDate><enclosure url="lib\media\{4daf5396-9453-4f75-9ea8-90bc971ba1f6}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{4daf5396-9453-4f75-9ea8-90bc971ba1f6}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Hubert数据]]></title><description><![CDATA[ 
 <br><br>Final train acc: 0.845683,  Final test acc: 0.728985<br>
训练集每个类别的准确率:<br>
类别 0: 0.8880<br>
类别 1: 0.8859<br>
类别 2: 0.8546<br>
类别 3: 0.7588<br>
类别 4: 0.4348<br>
类别 5: 0.9695<br>
类别 6: 0.6923<br>
类别 7: 0.9057<br>
类别 8: 0.9912<br>
类别 9: 0.8825<br>
类别 10: 0.8618<br>
类别 11: 0.6078<br>
类别 12: 0.7941<br>
类别 13: 0.5842<br>
类别 14: 0.9156<br>
类别 15: 0.9263<br>
类别 16: 0.8451<br>
类别 17: 0.7896<br>
类别 18: 0.7909<br>
类别 19: 0.8462<br>
测试集每个类别的准确率:<br>
类别 0: 0.7434<br>
类别 1: 0.8375<br>
类别 2: 0.7922<br>
类别 3: 0.6116<br>
类别 4: 0.1667<br>
类别 5: 0.9662<br>
类别 6: 0.5750<br>
类别 7: 0.8024<br>
类别 8: 0.8882<br>
类别 9: 0.7251<br>
类别 10: 0.6667<br>
类别 11: 0.3276<br>
类别 12: 0.5956<br>
类别 13: 0.3913<br>
类别 14: 0.8481<br>
类别 15: 0.8712<br>
类别 16: 0.6690<br>
类别 17: 0.7025<br>
类别 18: 0.6727<br>
类别 19: 0.7322<br><br>各鸟类准确率:<br>
鸟类ID  准确率  样本数<br>
0009    88.16%  304<br>
0017    84.38%  320<br>
0034    93.18%  308<br>
0036    93.80%  242<br>
0074    75.00%  12<br>
0077    96.28%  296<br>
0114    84.38%  320<br>
0121    85.63%  334<br>
0180    88.53%  340<br>
0202    84.80%  342<br>
0235    74.15%  294<br>
0257    80.17%  116<br>
0265    87.87%  272<br>
0281    92.39%  184<br>
0298    86.08%  316<br>
0300    89.88%  326<br>
0364    81.69%  284<br>
0368    83.54%  316<br>
0370    96.36%  330<br>
1331    80.33%  478<br>总体准确率: 86.78%<br><br>各鸟类准确率:<br>
鸟类ID	准确率	样本数<br>0009	94.08%	152<br>
0017	94.38%	160<br>
0034	96.10%	154<br>
0036	94.21%	121<br>
0074	66.67%	6<br>
0077	98.65%	148<br>
0114	96.88%	160<br>
0121	91.62%	167<br>
0180	95.29%	170<br>
0202	95.91%	171<br>
0235	87.76%	147<br>
0257	86.21%	58<br>
0265	88.97%	136<br>
0281	94.57%	92<br>
0298	94.94%	158<br>
0300	97.55%	163<br>
0364	94.37%	142<br>
0368	90.51%	158<br>
0370	95.76%	165<br>
1331	91.63%	239<br>总体准确率: 93.83%]]></description><link>technology\科研\实验\hubert数据.html</link><guid isPermaLink="false">Technology/科研/实验/Hubert数据.md</guid><pubDate>Wed, 30 Oct 2024 05:12:20 GMT</pubDate></item><item><title><![CDATA[LFCC数据]]></title><description><![CDATA[ 
 <br>Number of CEPs: 16 begin<br>
Final train acc: 0.928434,  Final test acc: 0.820370<br>
训练集每个类别的准确率:<br>
类别 0: 0.8122<br>
类别 1: 0.9391<br>
类别 2: 0.9559<br>
类别 3: 0.8857<br>
类别 4: 0.7826<br>
类别 5: 0.9797<br>
类别 6: 0.9058<br>
类别 7: 0.9296<br>
类别 8: 0.9721<br>
类别 9: 0.9471<br>
类别 10: 0.9215<br>
类别 11: 0.7931<br>
类别 12: 0.8897<br>
类别 13: 0.9049<br>
类别 14: 0.9602<br>
类别 15: 0.9462<br>
类别 16: 0.9718<br>
类别 17: 0.9589<br>
类别 18: 0.9409<br>
类别 19: 0.9215<br>
测试集每个类别的准确率:<br>
类别 0: 0.6316<br>
类别 1: 0.8500<br>
类别 2: 0.9026<br>
类别 3: 0.7521<br>
类别 4: 0.3333<br>
类别 5: 0.9392<br>
类别 6: 0.7562<br>
类别 7: 0.8563<br>
类别 8: 0.8529<br>
类别 9: 0.8480<br>
类别 10: 0.8095<br>
类别 11: 0.5000<br>
类别 12: 0.7500<br>
类别 13: 0.7391<br>
类别 14: 0.8734<br>
类别 15: 0.9080<br>
类别 16: 0.8451<br>
类别 17: 0.8734<br>
类别 18: 0.8424<br>
类别 19: 0.8117<br>
Number of CEPs: 16, Test Accuracy: 0.8204<br>
Number of CEPs: 16 end<br>
Number of CEPs: 17 begin<br>
Final train acc: 0.932192,  Final test acc: 0.818975<br>
训练集每个类别的准确率:<br>
类别 0: 0.8171<br>
类别 1: 0.9297<br>
类别 2: 0.9559<br>
类别 3: 0.8586<br>
类别 4: 0.6957<br>
类别 5: 0.9814<br>
类别 6: 0.9388<br>
类别 7: 0.9596<br>
类别 8: 0.9750<br>
类别 9: 0.9413<br>
类别 10: 0.9266<br>
类别 11: 0.8276<br>
类别 12: 0.9393<br>
类别 13: 0.9266<br>
类别 14: 0.9825<br>
类别 15: 0.9355<br>
类别 16: 0.9507<br>
类别 17: 0.9573<br>
类别 18: 0.9333<br>
类别 19: 0.9069<br>
测试集每个类别的准确率:<br>
类别 0: 0.6316<br>
类别 1: 0.8250<br>
类别 2: 0.9026<br>
类别 3: 0.6612<br>
类别 4: 0.3333<br>
类别 5: 0.9595<br>
类别 6: 0.8187<br>
类别 7: 0.8922<br>
类别 8: 0.8941<br>
类别 9: 0.8304<br>
类别 10: 0.8095<br>
类别 11: 0.5862<br>
类别 12: 0.8088<br>
类别 13: 0.7065<br>
类别 14: 0.8671<br>
类别 15: 0.8405<br>
类别 16: 0.7958<br>
类别 17: 0.8797<br>
类别 18: 0.8485<br>
类别 19: 0.7908<br>
Number of CEPs: 17, Test Accuracy: 0.8190<br>
Number of CEPs: 17 end<br>
Number of CEPs: 18 begin<br>
Final train acc: 0.868927,  Final test acc: 0.780956<br>
训练集每个类别的准确率:<br>
类别 0: 0.6755<br>
类别 1: 0.8438<br>
类别 2: 0.9020<br>
类别 3: 0.7630<br>
类别 4: 0.7391<br>
类别 5: 0.9712<br>
类别 6: 0.9168<br>
类别 7: 0.9207<br>
类别 8: 0.9618<br>
类别 9: 0.8825<br>
类别 10: 0.8584<br>
类别 11: 0.6552<br>
类别 12: 0.7886<br>
类别 13: 0.9076<br>
类别 14: 0.9124<br>
类别 15: 0.8740<br>
类别 16: 0.8856<br>
类别 17: 0.8924<br>
类别 18: 0.8545<br>
类别 19: 0.8787<br>
测试集每个类别的准确率:<br>
类别 0: 0.5658<br>
类别 1: 0.7562<br>
类别 2: 0.8442<br>
类别 3: 0.6860<br>
类别 4: 0.3333<br>
类别 5: 0.9392<br>
类别 6: 0.8000<br>
类别 7: 0.8743<br>
类别 8: 0.9000<br>
类别 9: 0.7719<br>
类别 10: 0.8231<br>
类别 11: 0.6034<br>
类别 12: 0.6838<br>
类别 13: 0.7283<br>
类别 14: 0.7975<br>
类别 15: 0.7975<br>
类别 16: 0.7465<br>
类别 17: 0.8481<br>
类别 18: 0.7758<br>
类别 19: 0.7490<br>
Number of CEPs: 18, Test Accuracy: 0.7810<br>
Number of CEPs: 18 end<br>
Number of CEPs: 19 begin<br>
Final train acc: 0.938920,  Final test acc: 0.837461<br>
训练集每个类别的准确率:<br>
类别 0: 0.8748<br>
类别 1: 0.9297<br>
类别 2: 0.9493<br>
类别 3: 0.9252<br>
类别 4: 0.6522<br>
类别 5: 0.9881<br>
类别 6: 0.9058<br>
类别 7: 0.9551<br>
类别 8: 0.9647<br>
类别 9: 0.9236<br>
类别 10: 0.9044<br>
类别 11: 0.8319<br>
类别 12: 0.9007<br>
类别 13: 0.9538<br>
类别 14: 0.9841<br>
类别 15: 0.9724<br>
类别 16: 0.9701<br>
类别 17: 0.9652<br>
类别 18: 0.9773<br>
类别 19: 0.9142<br>
测试集每个类别的准确率:<br>
类别 0: 0.6974<br>
类别 1: 0.8313<br>
类别 2: 0.9156<br>
类别 3: 0.8099<br>
类别 4: 0.3333<br>
类别 5: 0.9459<br>
类别 6: 0.7812<br>
类别 7: 0.9042<br>
类别 8: 0.8765<br>
类别 9: 0.7661<br>
类别 10: 0.7891<br>
类别 11: 0.6897<br>
类别 12: 0.8088<br>
类别 13: 0.7717<br>
类别 14: 0.8861<br>
类别 15: 0.8650<br>
类别 16: 0.8944<br>
类别 17: 0.8608<br>
类别 18: 0.9152<br>
类别 19: 0.8075<br>
Number of CEPs: 19, Test Accuracy: 0.8375<br>
Number of CEPs: 19 end<br>
Number of CEPs: 20 begin<br>
Final train acc: 0.943813,  Final test acc: 0.844088<br>
训练集每个类别的准确率:<br>
类别 0: 0.8517<br>
类别 1: 0.9891<br>
类别 2: 0.9592<br>
类别 3: 0.8919<br>
类别 4: 0.7826<br>
类别 5: 0.9814<br>
类别 6: 0.8823<br>
类别 7: 0.9611<br>
类别 8: 0.9868<br>
类别 9: 0.9369<br>
类别 10: 0.9437<br>
类别 11: 0.8276<br>
类别 12: 0.9614<br>
类别 13: 0.9484<br>
类别 14: 0.9873<br>
类别 15: 0.9601<br>
类别 16: 0.9525<br>
类别 17: 0.9446<br>
类别 18: 0.9727<br>
类别 19: 0.9236<br>
测试集每个类别的准确率:<br>
类别 0: 0.7105<br>
类别 1: 0.8938<br>
类别 2: 0.9091<br>
类别 3: 0.7934<br>
类别 4: 0.5000<br>
类别 5: 0.9392<br>
类别 6: 0.7500<br>
类别 7: 0.9281<br>
类别 8: 0.9118<br>
类别 9: 0.8421<br>
类别 10: 0.8299<br>
类别 11: 0.5690<br>
类别 12: 0.8603<br>
类别 13: 0.6957<br>
类别 14: 0.9367<br>
类别 15: 0.9080<br>
类别 16: 0.7465<br>
类别 17: 0.8418<br>
类别 18: 0.8909<br>
类别 19: 0.8326<br>
Number of CEPs: 20, Test Accuracy: 0.8441<br>
Number of CEPs: 20 end<br>
Number of CEPs: 21 begin<br>
Final train acc: 0.943813,  Final test acc: 0.844088<br>
训练集每个类别的准确率:<br>
类别 0: 0.8517<br>
类别 1: 0.9891<br>
类别 2: 0.9592<br>
类别 3: 0.8919<br>
类别 4: 0.7826<br>
类别 5: 0.9814<br>
类别 6: 0.8823<br>
类别 7: 0.9611<br>
类别 8: 0.9868<br>
类别 9: 0.9369<br>
类别 10: 0.9437<br>
类别 11: 0.8276<br>
类别 12: 0.9614<br>
类别 13: 0.9484<br>
类别 14: 0.9873<br>
类别 15: 0.9601<br>
类别 16: 0.9525<br>
类别 17: 0.9446<br>
类别 18: 0.9727<br>
类别 19: 0.9236<br>
测试集每个类别的准确率:<br>
类别 0: 0.7105<br>
类别 1: 0.8938<br>
类别 2: 0.9091<br>
类别 3: 0.7934<br>
类别 4: 0.5000<br>
类别 5: 0.9392<br>
类别 6: 0.7500<br>
类别 7: 0.9281<br>
类别 8: 0.9118<br>
类别 9: 0.8421<br>
类别 10: 0.8299<br>
类别 11: 0.5690<br>
类别 12: 0.8603<br>
类别 13: 0.6957<br>
类别 14: 0.9367<br>
类别 15: 0.9080<br>
类别 16: 0.7465<br>
类别 17: 0.8418<br>
类别 18: 0.8909<br>
类别 19: 0.8326<br>
Number of CEPs: 21, Test Accuracy: 0.8441<br>
Number of CEPs: 21 end]]></description><link>technology\科研\实验\lfcc数据.html</link><guid isPermaLink="false">Technology/科研/实验/LFCC数据.md</guid><pubDate>Thu, 31 Oct 2024 16:15:35 GMT</pubDate></item><item><title><![CDATA[local peaks数据]]></title><description><![CDATA[ 
 <br>Number of CEPs: 21 begin<br>
Final train acc: 0.832401,  Final test acc: 0.670038<br>
训练集每个类别的准确率:<br>
类别 0: 0.7578<br>
类别 1: 0.9172<br>
类别 2: 0.8922<br>
类别 3: 0.6466<br>
类别 4: 0.5652<br>
类别 5: 0.9034<br>
类别 6: 0.8870<br>
类别 7: 0.8877<br>
类别 8: 0.9250<br>
类别 9: 0.8693<br>
类别 10: 0.7235<br>
类别 11: 0.4612<br>
类别 12: 0.7537<br>
类别 13: 0.7120<br>
类别 14: 0.9013<br>
类别 15: 0.9293<br>
类别 16: 0.8292<br>
类别 17: 0.8006<br>
类别 18: 0.7788<br>
类别 19: 0.8703<br>
测试集每个类别的准确率:<br>
类别 0: 0.5592<br>
类别 1: 0.7375<br>
类别 2: 0.8182<br>
类别 3: 0.5207<br>
类别 4: 0.0000<br>
类别 5: 0.7838<br>
类别 6: 0.6500<br>
类别 7: 0.7725<br>
类别 8: 0.8059<br>
类别 9: 0.7076<br>
类别 10: 0.4490<br>
类别 11: 0.2241<br>
类别 12: 0.6544<br>
类别 13: 0.4130<br>
类别 14: 0.7405<br>
类别 15: 0.7423<br>
类别 16: 0.6338<br>
类别 17: 0.6266<br>
类别 18: 0.6182<br>
类别 19: 0.7824<br>
Number of CEPs: 21, Test Accuracy: 0.6700<br>
Number of CEPs: 21 end<br>
Number of CEPs: 22 begin<br>
Final train acc: 0.765292,  Final test acc: 0.647018<br>
训练集每个类别的准确率:<br>
类别 0: 0.6178<br>
类别 1: 0.8703<br>
类别 2: 0.7827<br>
类别 3: 0.5551<br>
类别 4: 0.0870<br>
类别 5: 0.8678<br>
类别 6: 0.8179<br>
类别 7: 0.8503<br>
类别 8: 0.8971<br>
类别 9: 0.8341<br>
类别 10: 0.5939<br>
类别 11: 0.3793<br>
类别 12: 0.6489<br>
类别 13: 0.6033<br>
类别 14: 0.7659<br>
类别 15: 0.9140<br>
类别 16: 0.7430<br>
类别 17: 0.8924<br>
类别 18: 0.6439<br>
类别 19: 0.8379<br>
测试集每个类别的准确率:<br>
类别 0: 0.4803<br>
类别 1: 0.6937<br>
类别 2: 0.6883<br>
类别 3: 0.4463<br>
类别 4: 0.0000<br>
类别 5: 0.8041<br>
类别 6: 0.6500<br>
类别 7: 0.7844<br>
类别 8: 0.7882<br>
类别 9: 0.6842<br>
类别 10: 0.4762<br>
类别 11: 0.2586<br>
类别 12: 0.6250<br>
类别 13: 0.3913<br>
类别 14: 0.6266<br>
类别 15: 0.7423<br>
类别 16: 0.6197<br>
类别 17: 0.7658<br>
类别 18: 0.5394<br>
类别 19: 0.7615<br>
Number of CEPs: 22, Test Accuracy: 0.6470<br>
Number of CEPs: 22 end<br>
Number of CEPs: 23 begin]]></description><link>technology\科研\实验\local-peaks数据.html</link><guid isPermaLink="false">Technology/科研/实验/local peaks数据.md</guid><pubDate>Thu, 17 Oct 2024 14:30:04 GMT</pubDate></item><item><title><![CDATA[MFCC数据]]></title><description><![CDATA[ 
 <br><br>Final train acc: 0.911657,  Final test acc: 0.795605<br>
训练集每个类别的准确率:<br>
类别 0: 0.8913<br>
类别 1: 0.8781<br>
类别 2: 0.9477<br>
类别 3: 0.7817<br>
类别 4: 0.5652<br>
类别 5: 0.9847<br>
类别 6: 0.9105<br>
类别 7: 0.9536<br>
类别 8: 0.9574<br>
类别 9: 0.9295<br>
类别 10: 0.8788<br>
类别 11: 0.8319<br>
类别 12: 0.8824<br>
类别 13: 0.8641<br>
类别 14: 0.9729<br>
类别 15: 0.9555<br>
类别 16: 0.8908<br>
类别 17: 0.8750<br>
类别 18: 0.9227<br>
类别 19: 0.9121<br>
测试集每个类别的准确率:<br>
类别 0: 0.7303<br>
类别 1: 0.8187<br>
类别 2: 0.8766<br>
类别 3: 0.6033<br>
类别 4: 0.3333<br>
类别 5: 0.9662<br>
类别 6: 0.6937<br>
类别 7: 0.8802<br>
类别 8: 0.7882<br>
类别 9: 0.8012<br>
类别 10: 0.6735<br>
类别 11: 0.6379<br>
类别 12: 0.8015<br>
类别 13: 0.7065<br>
类别 14: 0.8924<br>
类别 15: 0.8896<br>
类别 16: 0.7746<br>
类别 17: 0.7595<br>
类别 18: 0.8424<br>
类别 19: 0.8033<br><br>Final train acc: 0.936648,  Final test acc: 0.825602<br>
训练集每个类别的准确率:<br>
类别 0: 0.8896<br>
类别 1: 0.9297<br>
类别 2: 0.9575<br>
类别 3: 0.8690<br>
类别 4: 0.7391<br>
类别 5: 0.9898<br>
类别 6: 0.9356<br>
类别 7: 0.9491<br>
类别 8: 0.9706<br>
类别 9: 0.9427<br>
类别 10: 0.9334<br>
类别 11: 0.8966<br>
类别 12: 0.8824<br>
类别 13: 0.9076<br>
类别 14: 0.9506<br>
类别 15: 0.9539<br>
类别 16: 0.9560<br>
类别 17: 0.9304<br>
类别 18: 0.9576<br>
类别 19: 0.9383<br>
测试集每个类别的准确率:<br>
类别 0: 0.7171<br>
类别 1: 0.8313<br>
类别 2: 0.9156<br>
类别 3: 0.6942<br>
类别 4: 0.3333<br>
类别 5: 0.9662<br>
类别 6: 0.7937<br>
类别 7: 0.8623<br>
类别 8: 0.8412<br>
类别 9: 0.8187<br>
类别 10: 0.7823<br>
类别 11: 0.6034<br>
类别 12: 0.7721<br>
类别 13: 0.7391<br>
类别 14: 0.8671<br>
类别 15: 0.9018<br>
类别 16: 0.8169<br>
类别 17: 0.8418<br>
类别 18: 0.8848<br>
类别 19: 0.8326<br><br>Final train acc: 0.931405,  Final test acc: 0.826997<br>
训练集每个类别的准确率:<br>
类别 0: 0.9094<br>
类别 1: 0.9187<br>
类别 2: 0.9657<br>
类别 3: 0.8732<br>
类别 4: 0.6522<br>
类别 5: 0.9915<br>
类别 6: 0.9435<br>
类别 7: 0.9461<br>
类别 8: 0.9691<br>
类别 9: 0.9339<br>
类别 10: 0.8840<br>
类别 11: 0.8750<br>
类别 12: 0.8750<br>
类别 13: 0.8696<br>
类别 14: 0.9666<br>
类别 15: 0.9662<br>
类别 16: 0.9032<br>
类别 17: 0.9241<br>
类别 18: 0.9439<br>
类别 19: 0.9487<br>
测试集每个类别的准确率:<br>
类别 0: 0.7566<br>
类别 1: 0.8500<br>
类别 2: 0.9156<br>
类别 3: 0.7686<br>
类别 4: 0.5000<br>
类别 5: 0.9730<br>
类别 6: 0.8125<br>
类别 7: 0.8623<br>
类别 8: 0.8529<br>
类别 9: 0.8304<br>
类别 10: 0.6735<br>
类别 11: 0.5862<br>
类别 12: 0.7647<br>
类别 13: 0.7826<br>
类别 14: 0.9051<br>
类别 15: 0.9202<br>
类别 16: 0.7817<br>
类别 17: 0.8038<br>
类别 18: 0.8606<br>
类别 19: 0.8201<br><br>Final train acc: 0.922143,  Final test acc: 0.848622<br>
训练集每个类别的准确率:<br>
类别 0: 0.8748<br>
类别 1: 0.9391<br>
类别 2: 0.9493<br>
类别 3: 0.8836<br>
类别 4: 0.7826<br>
类别 5: 0.9729<br>
类别 6: 0.9482<br>
类别 7: 0.9641<br>
类别 8: 0.9779<br>
类别 9: 0.8752<br>
类别 10: 0.9386<br>
类别 11: 0.6767<br>
类别 12: 0.8879<br>
类别 13: 0.9185<br>
类别 14: 0.9586<br>
类别 15: 0.9724<br>
类别 16: 0.9313<br>
类别 17: 0.9051<br>
类别 18: 0.9061<br>
类别 19: 0.8912<br>
测试集每个类别的准确率:<br>
类别 0: 0.7763<br>
类别 1: 0.9062<br>
类别 2: 0.9221<br>
类别 3: 0.7851<br>
类别 4: 0.5000<br>
类别 5: 0.9595<br>
类别 6: 0.8562<br>
类别 7: 0.9042<br>
类别 8: 0.9000<br>
类别 9: 0.8012<br>
类别 10: 0.7891<br>
类别 11: 0.5862<br>
类别 12: 0.8162<br>
类别 13: 0.8043<br>
类别 14: 0.8671<br>
类别 15: 0.9387<br>
类别 16: 0.8732<br>
类别 17: 0.8418<br>
类别 18: 0.8424<br>
类别 19: 0.7908<br><br>Final train acc: 0.931842,  Final test acc: 0.845832<br>
训练集每个类别的准确率:<br>
类别 0: 0.9160<br>
类别 1: 0.9531<br>
类别 2: 0.9575<br>
类别 3: 0.8586<br>
类别 4: 0.6087<br>
类别 5: 0.9814<br>
类别 6: 0.9262<br>
类别 7: 0.9611<br>
类别 8: 0.9574<br>
类别 9: 0.8722<br>
类别 10: 0.9078<br>
类别 11: 0.8664<br>
类别 12: 0.9044<br>
类别 13: 0.9185<br>
类别 14: 0.9904<br>
类别 15: 0.9524<br>
类别 16: 0.9349<br>
类别 17: 0.9225<br>
类别 18: 0.9288<br>
类别 19: 0.9383<br>
测试集每个类别的准确率:<br>
类别 0: 0.8092<br>
类别 1: 0.9000<br>
类别 2: 0.9156<br>
类别 3: 0.8017<br>
类别 4: 0.1667<br>
类别 5: 0.9662<br>
类别 6: 0.8375<br>
类别 7: 0.9042<br>
类别 8: 0.8353<br>
类别 9: 0.7368<br>
类别 10: 0.7279<br>
类别 11: 0.6897<br>
类别 12: 0.8529<br>
类别 13: 0.7717<br>
类别 14: 0.8924<br>
类别 15: 0.9080<br>
类别 16: 0.8732<br>
类别 17: 0.8038<br>
类别 18: 0.8485<br>
类别 19: 0.8745<br><br>Final train acc: 0.965834,  Final test acc: 0.883153<br>
训练集每个类别的准确率:<br>
类别 0: 0.9621<br>
类别 1: 0.9719<br>
类别 2: 0.9739<br>
类别 3: 0.9501<br>
类别 4: 0.7826<br>
类别 5: 0.9864<br>
类别 6: 0.9796<br>
类别 7: 0.9701<br>
类别 8: 0.9882<br>
类别 9: 0.9559<br>
类别 10: 0.9761<br>
类别 11: 0.8793<br>
类别 12: 0.9522<br>
类别 13: 0.9755<br>
类别 14: 0.9889<br>
类别 15: 0.9770<br>
类别 16: 0.9683<br>
类别 17: 0.9636<br>
类别 18: 0.9667<br>
类别 19: 0.9331<br>
测试集每个类别的准确率:<br>
类别 0: 0.8487<br>
类别 1: 0.9313<br>
类别 2: 0.9026<br>
类别 3: 0.9091<br>
类别 4: 0.6667<br>
类别 5: 0.9797<br>
类别 6: 0.8875<br>
类别 7: 0.8922<br>
类别 8: 0.9059<br>
类别 9: 0.8304<br>
类别 10: 0.8707<br>
类别 11: 0.6552<br>
类别 12: 0.8750<br>
类别 13: 0.9457<br>
类别 14: 0.9114<br>
类别 15: 0.9325<br>
类别 16: 0.8732<br>
类别 17: 0.8671<br>
类别 18: 0.8545<br>
类别 19: 0.8326<br><br>Final train acc: 0.965834,  Final test acc: 0.883153<br>
训练集每个类别的准确率:<br>
类别 0: 0.9621<br>
类别 1: 0.9719<br>
类别 2: 0.9739<br>
类别 3: 0.9501<br>
类别 4: 0.7826<br>
类别 5: 0.9864<br>
类别 6: 0.9796<br>
类别 7: 0.9701<br>
类别 8: 0.9882<br>
类别 9: 0.9559<br>
类别 10: 0.9761<br>
类别 11: 0.8793<br>
类别 12: 0.9522<br>
类别 13: 0.9755<br>
类别 14: 0.9889<br>
类别 15: 0.9770<br>
类别 16: 0.9683<br>
类别 17: 0.9636<br>
类别 18: 0.9667<br>
类别 19: 0.9331<br>
测试集每个类别的准确率:<br>
类别 0: 0.8487<br>
类别 1: 0.9313<br>
类别 2: 0.9026<br>
类别 3: 0.9091<br>
类别 4: 0.6667<br>
类别 5: 0.9797<br>
类别 6: 0.8875<br>
类别 7: 0.8922<br>
类别 8: 0.9059<br>
类别 9: 0.8304<br>
类别 10: 0.8707<br>
类别 11: 0.6552<br>
类别 12: 0.8750<br>
类别 13: 0.9457<br>
类别 14: 0.9114<br>
类别 15: 0.9325<br>
类别 16: 0.8732<br>
类别 17: 0.8671<br>
类别 18: 0.8545<br>
类别 19: 0.8326<br><br>Final train acc: 0.949056,  Final test acc: 0.876526<br>
训练集每个类别的准确率:<br>
类别 0: 0.9456<br>
类别 1: 0.9734<br>
类别 2: 0.9722<br>
类别 3: 0.9335<br>
类别 4: 0.8261<br>
类别 5: 0.9864<br>
类别 6: 0.9702<br>
类别 7: 0.9656<br>
类别 8: 0.9618<br>
类别 9: 0.9442<br>
类别 10: 0.8891<br>
类别 11: 0.9095<br>
类别 12: 0.9118<br>
类别 13: 0.9620<br>
类别 14: 0.9682<br>
类别 15: 0.9401<br>
类别 16: 0.9718<br>
类别 17: 0.9335<br>
类别 18: 0.9500<br>
类别 19: 0.9289<br>
测试集每个类别的准确率:<br>
类别 0: 0.8618<br>
类别 1: 0.9500<br>
类别 2: 0.9545<br>
类别 3: 0.8926<br>
类别 4: 0.6667<br>
类别 5: 0.9730<br>
类别 6: 0.8812<br>
类别 7: 0.8982<br>
类别 8: 0.8706<br>
类别 9: 0.8772<br>
类别 10: 0.7687<br>
类别 11: 0.7586<br>
类别 12: 0.7941<br>
类别 13: 0.8587<br>
类别 14: 0.8861<br>
类别 15: 0.9080<br>
类别 16: 0.8944<br>
类别 17: 0.8481<br>
类别 18: 0.8667<br>
类别 19: 0.8452<br><br>Final train acc: 0.890947,  Final test acc: 0.839902<br>
训练集每个类别的准确率:<br>
类别 0: 0.8764<br>
类别 1: 0.9297<br>
类别 2: 0.8791<br>
类别 3: 0.8295<br>
类别 4: 0.6087<br>
类别 5: 0.9780<br>
类别 6: 0.8885<br>
类别 7: 0.9326<br>
类别 8: 0.9574<br>
类别 9: 0.8546<br>
类别 10: 0.9044<br>
类别 11: 0.5819<br>
类别 12: 0.8401<br>
类别 13: 0.8288<br>
类别 14: 0.9411<br>
类别 15: 0.9324<br>
类别 16: 0.8556<br>
类别 17: 0.8386<br>
类别 18: 0.9394<br>
类别 19: 0.8975<br>
测试集每个类别的准确率:<br>
类别 0: 0.7895<br>
类别 1: 0.9313<br>
类别 2: 0.8896<br>
类别 3: 0.7851<br>
类别 4: 0.5000<br>
类别 5: 0.9595<br>
类别 6: 0.8562<br>
类别 7: 0.8443<br>
类别 8: 0.8647<br>
类别 9: 0.8304<br>
类别 10: 0.8095<br>
类别 11: 0.4655<br>
类别 12: 0.7647<br>
类别 13: 0.7826<br>
类别 14: 0.8987<br>
类别 15: 0.8957<br>
类别 16: 0.7535<br>
类别 17: 0.7785<br>
类别 18: 0.8848<br>
类别 19: 0.8745<br><br>Final train acc: 0.956222,  Final test acc: 0.885943<br>
训练集每个类别的准确率:<br>
类别 0: 0.9077<br>
类别 1: 0.9812<br>
类别 2: 0.9624<br>
类别 3: 0.9335<br>
类别 4: 0.8696<br>
类别 5: 0.9915<br>
类别 6: 0.9670<br>
类别 7: 0.9686<br>
类别 8: 0.9794<br>
类别 9: 0.9545<br>
类别 10: 0.9232<br>
类别 11: 0.8750<br>
类别 12: 0.9577<br>
类别 13: 0.9620<br>
类别 14: 0.9777<br>
类别 15: 0.9754<br>
类别 16: 0.9736<br>
类别 17: 0.9509<br>
类别 18: 0.9303<br>
类别 19: 0.9477<br>
测试集每个类别的准确率:<br>
类别 0: 0.7961<br>
类别 1: 0.9750<br>
类别 2: 0.8961<br>
类别 3: 0.8430<br>
类别 4: 0.6667<br>
类别 5: 0.9932<br>
类别 6: 0.9187<br>
类别 7: 0.9222<br>
类别 8: 0.9118<br>
类别 9: 0.8713<br>
类别 10: 0.7959<br>
类别 11: 0.7414<br>
类别 12: 0.8750<br>
类别 13: 0.8478<br>
类别 14: 0.9304<br>
类别 15: 0.9325<br>
类别 16: 0.8662<br>
类别 17: 0.8671<br>
类别 18: 0.8364<br>
类别 19: 0.8912<br><br>Final train acc: 0.949755,  Final test acc: 0.878270<br>
训练集每个类别的准确率:<br>
类别 0: 0.9209<br>
类别 1: 0.9641<br>
类别 2: 0.9657<br>
类别 3: 0.9480<br>
类别 4: 0.7826<br>
类别 5: 0.9881<br>
类别 6: 0.9576<br>
类别 7: 0.9716<br>
类别 8: 0.9676<br>
类别 9: 0.9604<br>
类别 10: 0.9096<br>
类别 11: 0.8578<br>
类别 12: 0.9044<br>
类别 13: 0.9212<br>
类别 14: 0.9936<br>
类别 15: 0.9539<br>
类别 16: 0.9595<br>
类别 17: 0.9209<br>
类别 18: 0.9697<br>
类别 19: 0.9404<br>
测试集每个类别的准确率:<br>
类别 0: 0.8421<br>
类别 1: 0.9313<br>
类别 2: 0.9481<br>
类别 3: 0.8430<br>
类别 4: 0.5000<br>
类别 5: 0.9865<br>
类别 6: 0.8938<br>
类别 7: 0.9222<br>
类别 8: 0.8941<br>
类别 9: 0.8655<br>
类别 10: 0.8027<br>
类别 11: 0.7414<br>
类别 12: 0.8015<br>
类别 13: 0.8152<br>
类别 14: 0.9430<br>
类别 15: 0.8957<br>
类别 16: 0.8521<br>
类别 17: 0.8228<br>
类别 18: 0.9091<br>
类别 19: 0.8619<br><br>Final train acc: 0.957445,  Final test acc: 0.884200<br>
训练集每个类别的准确率:<br>
类别 0: 0.9176<br>
类别 1: 0.9766<br>
类别 2: 0.9559<br>
类别 3: 0.9459<br>
类别 4: 0.7826<br>
类别 5: 0.9847<br>
类别 6: 0.9686<br>
类别 7: 0.9671<br>
类别 8: 0.9926<br>
类别 9: 0.9589<br>
类别 10: 0.9642<br>
类别 11: 0.8534<br>
类别 12: 0.9596<br>
类别 13: 0.9321<br>
类别 14: 0.9809<br>
类别 15: 0.9816<br>
类别 16: 0.9718<br>
类别 17: 0.9320<br>
类别 18: 0.9682<br>
类别 19: 0.9226<br>
测试集每个类别的准确率:<br>
类别 0: 0.8355<br>
类别 1: 0.9563<br>
类别 2: 0.9156<br>
类别 3: 0.8926<br>
类别 4: 0.5000<br>
类别 5: 0.9797<br>
类别 6: 0.8938<br>
类别 7: 0.9222<br>
类别 8: 0.9059<br>
类别 9: 0.8830<br>
类别 10: 0.8367<br>
类别 11: 0.6034<br>
类别 12: 0.8382<br>
类别 13: 0.8587<br>
类别 14: 0.9241<br>
类别 15: 0.9448<br>
类别 16: 0.8803<br>
类别 17: 0.8291<br>
类别 18: 0.8788<br>
类别 19: 0.8536<br><br>Final train acc: 0.984359,  Final test acc: 0.897803<br>
训练集每个类别的准确率:<br>
类别 0: 0.9654<br>
类别 1: 0.9969<br>
类别 2: 0.9967<br>
类别 3: 0.9854<br>
类别 4: 0.7826<br>
类别 5: 0.9966<br>
类别 6: 0.9890<br>
类别 7: 0.9865<br>
类别 8: 0.9985<br>
类别 9: 0.9912<br>
类别 10: 0.9778<br>
类别 11: 0.9095<br>
类别 12: 0.9761<br>
类别 13: 0.9810<br>
类别 14: 0.9920<br>
类别 15: 0.9954<br>
类别 16: 0.9894<br>
类别 17: 0.9810<br>
类别 18: 0.9848<br>
类别 19: 0.9718<br>
测试集每个类别的准确率:<br>
类别 0: 0.8553<br>
类别 1: 0.9750<br>
类别 2: 0.9416<br>
类别 3: 0.9091<br>
类别 4: 0.3333<br>
类别 5: 0.9797<br>
类别 6: 0.9313<br>
类别 7: 0.8982<br>
类别 8: 0.8882<br>
类别 9: 0.9123<br>
类别 10: 0.8299<br>
类别 11: 0.7069<br>
类别 12: 0.8382<br>
类别 13: 0.8696<br>
类别 14: 0.8987<br>
类别 15: 0.9387<br>
类别 16: 0.9014<br>
类别 17: 0.8608<br>
类别 18: 0.9515<br>
类别 19: 0.8661<br><br>Final train acc: 0.952552,  Final test acc: 0.873736<br>
训练集每个类别的准确率:<br>
类别 0: 0.9012<br>
类别 1: 0.9875<br>
类别 2: 0.9771<br>
类别 3: 0.9459<br>
类别 4: 0.6522<br>
类别 5: 0.9780<br>
类别 6: 0.9655<br>
类别 7: 0.9581<br>
类别 8: 0.9809<br>
类别 9: 0.9545<br>
类别 10: 0.9369<br>
类别 11: 0.7888<br>
类别 12: 0.9357<br>
类别 13: 0.9484<br>
类别 14: 0.9713<br>
类别 15: 0.9800<br>
类别 16: 0.9736<br>
类别 17: 0.9066<br>
类别 18: 0.9636<br>
类别 19: 0.9467<br>
测试集每个类别的准确率:<br>
类别 0: 0.7763<br>
类别 1: 0.9437<br>
类别 2: 0.9351<br>
类别 3: 0.9008<br>
类别 4: 0.3333<br>
类别 5: 0.9459<br>
类别 6: 0.9062<br>
类别 7: 0.8862<br>
类别 8: 0.9118<br>
类别 9: 0.8421<br>
类别 10: 0.7959<br>
类别 11: 0.6379<br>
类别 12: 0.8382<br>
类别 13: 0.8913<br>
类别 14: 0.8797<br>
类别 15: 0.9509<br>
类别 16: 0.8451<br>
类别 17: 0.7848<br>
类别 18: 0.8909<br>
类别 19: 0.8954<br><br>Final train acc: 0.952814,  Final test acc: 0.877921<br>
训练集每个类别的准确率:<br>
类别 0: 0.9555<br>
类别 1: 0.9781<br>
类别 2: 0.9363<br>
类别 3: 0.9252<br>
类别 4: 0.7391<br>
类别 5: 0.9847<br>
类别 6: 0.9403<br>
类别 7: 0.9805<br>
类别 8: 0.9853<br>
类别 9: 0.9604<br>
类别 10: 0.9334<br>
类别 11: 0.8922<br>
类别 12: 0.9173<br>
类别 13: 0.9429<br>
类别 14: 0.9841<br>
类别 15: 0.9862<br>
类别 16: 0.9560<br>
类别 17: 0.9478<br>
类别 18: 0.9667<br>
类别 19: 0.9038<br>
测试集每个类别的准确率:<br>
类别 0: 0.8618<br>
类别 1: 0.9437<br>
类别 2: 0.9286<br>
类别 3: 0.8512<br>
类别 4: 0.5000<br>
类别 5: 0.9662<br>
类别 6: 0.8562<br>
类别 7: 0.9341<br>
类别 8: 0.9000<br>
类别 9: 0.8596<br>
类别 10: 0.7347<br>
类别 11: 0.7241<br>
类别 12: 0.8235<br>
类别 13: 0.8370<br>
类别 14: 0.9114<br>
类别 15: 0.9387<br>
类别 16: 0.8521<br>
类别 17: 0.8418<br>
类别 18: 0.9212<br>
类别 19: 0.8703<br><br>Final train acc: 0.963911,  Final test acc: 0.892222<br>
训练集每个类别的准确率:<br>
类别 0: 0.9539<br>
类别 1: 0.9719<br>
类别 2: 0.9788<br>
类别 3: 0.9023<br>
类别 4: 0.6957<br>
类别 5: 0.9831<br>
类别 6: 0.9859<br>
类别 7: 0.9880<br>
类别 8: 0.9809<br>
类别 9: 0.9750<br>
类别 10: 0.9454<br>
类别 11: 0.9310<br>
类别 12: 0.9301<br>
类别 13: 0.9647<br>
类别 14: 0.9650<br>
类别 15: 0.9800<br>
类别 16: 0.9683<br>
类别 17: 0.9763<br>
类别 18: 0.9697<br>
类别 19: 0.9414<br>
测试集每个类别的准确率:<br>
类别 0: 0.8750<br>
类别 1: 0.9563<br>
类别 2: 0.9416<br>
类别 3: 0.8595<br>
类别 4: 0.5000<br>
类别 5: 0.9797<br>
类别 6: 0.9187<br>
类别 7: 0.9641<br>
类别 8: 0.8765<br>
类别 9: 0.8772<br>
类别 10: 0.7891<br>
类别 11: 0.7586<br>
类别 12: 0.8088<br>
类别 13: 0.8913<br>
类别 14: 0.8797<br>
类别 15: 0.9387<br>
类别 16: 0.8803<br>
类别 17: 0.9114<br>
类别 18: 0.8788<br>
类别 19: 0.8787<br><br>Final train acc: 0.953338,  Final test acc: 0.884897<br>
训练集每个类别的准确率:<br>
类别 0: 0.8929<br>
类别 1: 0.9797<br>
类别 2: 0.9412<br>
类别 3: 0.9127<br>
类别 4: 0.8261<br>
类别 5: 0.9915<br>
类别 6: 0.9623<br>
类别 7: 0.9746<br>
类别 8: 0.9779<br>
类别 9: 0.9325<br>
类别 10: 0.9164<br>
类别 11: 0.9095<br>
类别 12: 0.9596<br>
类别 13: 0.9565<br>
类别 14: 0.9920<br>
类别 15: 0.9831<br>
类别 16: 0.9754<br>
类别 17: 0.9225<br>
类别 18: 0.9530<br>
类别 19: 0.9487<br>
测试集每个类别的准确率:<br>
类别 0: 0.7961<br>
类别 1: 0.9875<br>
类别 2: 0.9221<br>
类别 3: 0.9008<br>
类别 4: 0.5000<br>
类别 5: 0.9932<br>
类别 6: 0.9000<br>
类别 7: 0.9042<br>
类别 8: 0.9059<br>
类别 9: 0.8363<br>
类别 10: 0.8231<br>
类别 11: 0.7069<br>
类别 12: 0.8529<br>
类别 13: 0.9239<br>
类别 14: 0.9051<br>
类别 15: 0.9325<br>
类别 16: 0.8803<br>
类别 17: 0.8608<br>
类别 18: 0.8424<br>
类别 19: 0.8661<br><br>Final train acc: 0.981562,  Final test acc: 0.893617<br>
训练集每个类别的准确率:<br>
类别 0: 0.9868<br>
类别 1: 0.9922<br>
类别 2: 0.9788<br>
类别 3: 0.9875<br>
类别 4: 0.8696<br>
类别 5: 0.9932<br>
类别 6: 0.9953<br>
类别 7: 0.9790<br>
类别 8: 0.9853<br>
类别 9: 0.9589<br>
类别 10: 0.9573<br>
类别 11: 0.9483<br>
类别 12: 0.9688<br>
类别 13: 0.9918<br>
类别 14: 0.9952<br>
类别 15: 0.9954<br>
类别 16: 0.9789<br>
类别 17: 0.9905<br>
类别 18: 0.9803<br>
类别 19: 0.9759<br>
测试集每个类别的准确率:<br>
类别 0: 0.8750<br>
类别 1: 0.9500<br>
类别 2: 0.9351<br>
类别 3: 0.9008<br>
类别 4: 0.5000<br>
类别 5: 1.0000<br>
类别 6: 0.9000<br>
类别 7: 0.9042<br>
类别 8: 0.8647<br>
类别 9: 0.8480<br>
类别 10: 0.7755<br>
类别 11: 0.7586<br>
类别 12: 0.8750<br>
类别 13: 0.8804<br>
类别 14: 0.9304<br>
类别 15: 0.9325<br>
类别 16: 0.8732<br>
类别 17: 0.9114<br>
类别 18: 0.8848<br>
类别 19: 0.8996<br><br>Final train acc: 0.973174,  Final test acc: 0.891175<br>
训练集每个类别的准确率:<br>
类别 0: 0.9539<br>
类别 1: 0.9922<br>
类别 2: 0.9886<br>
类别 3: 0.9813<br>
类别 4: 0.9130<br>
类别 5: 0.9898<br>
类别 6: 0.9199<br>
类别 7: 0.9820<br>
类别 8: 0.9926<br>
类别 9: 0.9706<br>
类别 10: 0.9812<br>
类别 11: 0.9052<br>
类别 12: 0.9559<br>
类别 13: 0.9918<br>
类别 14: 1.0000<br>
类别 15: 0.9800<br>
类别 16: 0.9771<br>
类别 17: 0.9668<br>
类别 18: 0.9818<br>
类别 19: 0.9550<br>
测试集每个类别的准确率:<br>
类别 0: 0.8224<br>
类别 1: 0.9563<br>
类别 2: 0.9545<br>
类别 3: 0.8843<br>
类别 4: 0.5000<br>
类别 5: 0.9730<br>
类别 6: 0.8938<br>
类别 7: 0.9222<br>
类别 8: 0.9235<br>
类别 9: 0.8480<br>
类别 10: 0.8639<br>
类别 11: 0.6552<br>
类别 12: 0.8235<br>
类别 13: 0.8913<br>
类别 14: 0.9114<br>
类别 15: 0.9325<br>
类别 16: 0.9085<br>
类别 17: 0.8797<br>
类别 18: 0.9152<br>
类别 19: 0.8494<br><br>Final train acc: 0.968979,  Final test acc: 0.892222<br>
训练集每个类别的准确率:<br>
类别 0: 0.9407<br>
类别 1: 0.9969<br>
类别 2: 0.9902<br>
类别 3: 0.9667<br>
类别 4: 0.8261<br>
类别 5: 0.9898<br>
类别 6: 0.9702<br>
类别 7: 0.9910<br>
类别 8: 0.9882<br>
类别 9: 0.9442<br>
类别 10: 0.9573<br>
类别 11: 0.9440<br>
类别 12: 0.9485<br>
类别 13: 0.9701<br>
类别 14: 0.9825<br>
类别 15: 0.9908<br>
类别 16: 0.9718<br>
类别 17: 0.9557<br>
类别 18: 0.9833<br>
类别 19: 0.9320<br>
测试集每个类别的准确率:<br>
类别 0: 0.8553<br>
类别 1: 0.9938<br>
类别 2: 0.9286<br>
类别 3: 0.8843<br>
类别 4: 0.5000<br>
类别 5: 0.9865<br>
类别 6: 0.8875<br>
类别 7: 0.9341<br>
类别 8: 0.9118<br>
类别 9: 0.8713<br>
类别 10: 0.7959<br>
类别 11: 0.7586<br>
类别 12: 0.8382<br>
类别 13: 0.8587<br>
类别 14: 0.8924<br>
类别 15: 0.9693<br>
类别 16: 0.8803<br>
类别 17: 0.8797<br>
类别 18: 0.9152<br>
类别 19: 0.8368<br><br>Final train acc: 0.946173,  Final test acc: 0.879665<br>
训练集每个类别的准确率:<br>
类别 0: 0.9325<br>
类别 1: 0.9609<br>
类别 2: 0.9673<br>
类别 3: 0.9314<br>
类别 4: 0.7826<br>
类别 5: 0.9847<br>
类别 6: 0.9592<br>
类别 7: 0.9686<br>
类别 8: 0.9603<br>
类别 9: 0.9398<br>
类别 10: 0.9130<br>
类别 11: 0.8276<br>
类别 12: 0.9228<br>
类别 13: 0.9239<br>
类别 14: 0.9761<br>
类别 15: 0.9770<br>
类别 16: 0.8996<br>
类别 17: 0.9415<br>
类别 18: 0.9591<br>
类别 19: 0.9414<br>
测试集每个类别的准确率:<br>
类别 0: 0.8158<br>
类别 1: 0.9500<br>
类别 2: 0.9091<br>
类别 3: 0.9174<br>
类别 4: 0.3333<br>
类别 5: 0.9932<br>
类别 6: 0.8812<br>
类别 7: 0.9102<br>
类别 8: 0.8882<br>
类别 9: 0.8538<br>
类别 10: 0.7891<br>
类别 11: 0.7069<br>
类别 12: 0.8162<br>
类别 13: 0.8370<br>
类别 14: 0.9241<br>
类别 15: 0.9509<br>
类别 16: 0.8169<br>
类别 17: 0.8797<br>
类别 18: 0.9030<br>
类别 19: 0.8619<br><br>Final train acc: 0.960241,  Final test acc: 0.888734<br>
训练集每个类别的准确率:<br>
类别 0: 0.9522<br>
类别 1: 0.9688<br>
类别 2: 0.9869<br>
类别 3: 0.9376<br>
类别 4: 0.7826<br>
类别 5: 0.9831<br>
类别 6: 0.9702<br>
类别 7: 0.9686<br>
类别 8: 0.9912<br>
类别 9: 0.9310<br>
类别 10: 0.9625<br>
类别 11: 0.8578<br>
类别 12: 0.9651<br>
类别 13: 0.9810<br>
类别 14: 0.9952<br>
类别 15: 0.9754<br>
类别 16: 0.9243<br>
类别 17: 0.9494<br>
类别 18: 0.9515<br>
类别 19: 0.9446<br>
测试集每个类别的准确率:<br>
类别 0: 0.8684<br>
类别 1: 0.9313<br>
类别 2: 0.9351<br>
类别 3: 0.8760<br>
类别 4: 0.3333<br>
类别 5: 0.9797<br>
类别 6: 0.9062<br>
类别 7: 0.9042<br>
类别 8: 0.9235<br>
类别 9: 0.8421<br>
类别 10: 0.8776<br>
类别 11: 0.7414<br>
类别 12: 0.8897<br>
类别 13: 0.8370<br>
类别 14: 0.9367<br>
类别 15: 0.9141<br>
类别 16: 0.8310<br>
类别 17: 0.8797<br>
类别 18: 0.8242<br>
类别 19: 0.8912]]></description><link>technology\科研\实验\mfcc数据.html</link><guid isPermaLink="false">Technology/科研/实验/MFCC数据.md</guid><pubDate>Thu, 17 Oct 2024 08:01:32 GMT</pubDate></item><item><title><![CDATA[图的拉普拉斯矩阵]]></title><description><![CDATA[ 
 <br>图的拉普拉斯矩阵是图论中的一个重要概念，通常用于分析图的性质，特别是在图神经网络和谱图理论中。它可以通过图的邻接矩阵和度矩阵定义。具体来说，对于一个无向图：<br>
<br>
邻接矩阵：一个的矩阵，其中是图中节点的数量，矩阵的元素表示节点和节点之间是否有边相连。如果有边，；如果没有边，。

<br>
度矩阵：一个对角矩阵，表示节点的度（即与节点相连的边的数量）。

<br>
拉普拉斯矩阵：由度矩阵和邻接矩阵构造，定义为：<br>
其中，如果节点和节点之间有边相连，且；是节点的度。

<br>拉普拉斯矩阵有几个重要的性质：<br>
<br>它是半正定的，即所有特征值非负。
<br>其最小特征值为0，特征值为0的特征向量对应的特征是常数向量（表示图的连通性）。
<br>拉普拉斯矩阵可以用于计算图的聚类、分割以及其他图论算法。
<br>在图神经网络中，拉普拉斯矩阵常用于定义图卷积操作，通过谱域的特征来更新节点的表示。<br><br>拉普拉斯矩阵的定义源于其在图结构分析中的独特性质，主要体现在以下几个方面：<br>
<br>
捕捉节点的连通性：拉普拉斯矩阵由度矩阵和邻接矩阵构成，其中表示每个节点的度，而表示图的边连接情况。通过这种定义，拉普拉斯矩阵能够捕捉每个节点与邻居的连接强度。对于任意两个相邻节点和，表示它们的负相关；而对于节点自身，的值为节点的度，这表示节点与其邻域的连接总强度。

<br>
度量图的平滑性：拉普拉斯矩阵的定义直接用于衡量图的“平滑性”。它可以帮助计算图上的信号在邻近节点之间的变化程度。例如，对于一个节点特征向量，其平滑性可以通过二次型来度量。值越小，说明相邻节点的特征越接近，图结构越平滑。

<br>
光谱性质：拉普拉斯矩阵的特征值和特征向量揭示了图的重要结构信息。其最小特征值为，对应的特征向量是常数向量。这意味着如果图是连通的，拉普拉斯矩阵只有一个特征值为，其他特征值都大于。这种性质使拉普拉斯矩阵在图的聚类和连通性分析中十分有用，例如在谱聚类中，拉普拉斯矩阵的特征向量被用来定义图的子结构。

<br>
能量最小化：在许多应用中，图拉普拉斯可以用于能量最小化问题。特别是在信号处理和图神经网络中，拉普拉斯矩阵可以作为正则化项来抑制信号在图上相邻节点之间的过大变化，从而实现平滑信号或特征的效果。

<br>综上，拉普拉斯矩阵的定义使其能够有效地捕捉图的连接特性、度量节点之间的关系、分析图的平滑度以及揭示图的光谱特性，适用于许多基于图的机器学习和图论问题。]]></description><link>technology\科研\学习\图的拉普拉斯矩阵.html</link><guid isPermaLink="false">Technology/科研/学习/图的拉普拉斯矩阵.md</guid><pubDate>Sat, 02 Nov 2024 09:00:56 GMT</pubDate></item><item><title><![CDATA[GCN]]></title><description><![CDATA[ 
 <br><br><br><a rel="noopener nofollow" class="external-link" href="https://medium.com/ai-in-plain-english/graph-convolutional-networks-gcn-baf337d5cb6b" target="_blank">https://medium.com/ai-in-plain-english/graph-convolutional-networks-gcn-baf337d5cb6b</a><br>
<img alt="Pasted image 20240914214802.png" src="\lib\media\pasted-image-20240914214802.png"><br>其中A为邻接矩阵，D为度矩阵，X为特征矩阵。<br><img alt="Pasted image 20240914214832.png" src="\lib\media\pasted-image-20240914214832.png"><br>我们将A×X，得到新的特征矩阵，可以看到，A节点的特征变成了E节点的特征，这是因为E是A节点唯一的一阶邻居节点。同理第二行为DE之和。<br>可以看出，这样失去了节点本身的信息，我们如果要保留节点本身信息也很简单，即给A加一个单位矩阵。<br>
<img alt="Pasted image 20240914215339.png" src="\lib\media\pasted-image-20240914215339.png"><br><img alt="Pasted image 20240914215346.png" src="\lib\media\pasted-image-20240914215346.png"><br>
其本质上是给图中每个节点加了一个自环。这里我们认为自环只加一个度。<br><img alt="Pasted image 20240914215734.png" src="\lib\media\pasted-image-20240914215734.png"><br>
这里我们得到了新的度矩阵，然后对其求逆。<br><img alt="Pasted image 20240914215805.png" src="\lib\media\pasted-image-20240914215805.png"><br>左乘为行变换，右乘为列变换，这里的即是根据度信息，将原本的邻接矩阵进行了行变换，让度数越多的节点信息传递越少，即完成了缩放或者说归一化向量。<br><img alt="Pasted image 20240914220359.png" src="\lib\media\pasted-image-20240914220359.png"><br>由于邻接矩阵为一个对称矩阵，所以我们在进行行变换的同时也进行列变化，即右乘<br>这样得到的特征聚合，度数越多的邻居节点所传递的信息越少。<br><img alt="Pasted image 20240914220714.png" src="\lib\media\pasted-image-20240914220714.png"><br><br><img alt="Pasted image 20240914220835.png" src="\lib\media\pasted-image-20240914220835.png"><br><br><img alt="Pasted image 20240914221215.png" src="\lib\media\pasted-image-20240914221215.png"><br>import torch
from torch.nn import Linear, Parameter
from torch_geometric.nn import MessagePassing
from torch_geometric.utils import add_self_loops, degree

class GCNConv(MessagePassing):
    def __init__(self, in_channels, out_channels):
        super().__init__(aggr='add')  # "Add" aggregation (Step 5).
        self.lin = Linear(in_channels, out_channels, bias=False)
        self.bias = Parameter(torch.empty(out_channels))

        self.reset_parameters()

    def reset_parameters(self):
        self.lin.reset_parameters()
        self.bias.data.zero_()

    def forward(self, x, edge_index):
        # x has shape [N, in_channels]
        # edge_index has shape [2, E]

        # Step 1: Add self-loops to the adjacency matrix.增加自环
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))

        # Step 2: Linearly transform node feature matrix.线性变换
        x = self.lin(x)

        # Step 3: Compute normalization.计算归一化系数
        row, col = edge_index
        deg = degree(col, x.size(0), dtype=x.dtype)
        deg_inv_sqrt = deg.pow(-0.5)
        deg_inv_sqrt[deg_inv_sqrt == float('inf')] = 0
        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]

        # Step 4-5: Start propagating messages.自动调用message
        out = self.propagate(edge_index, x=x, norm=norm)

        # Step 6: Apply a final bias vector.加一个偏执
        out += self.bias

        return out

    def message(self, x_j, norm):
        # x_j has shape [E, out_channels]

        # Step 4: Normalize node features.
        return norm.view(-1, 1) * x_j
]]></description><link>technology\科研\学习\gcn.html</link><guid isPermaLink="false">Technology/科研/学习/GCN.md</guid><pubDate>Sat, 14 Sep 2024 14:16:58 GMT</pubDate><enclosure url="lib\media\pasted-image-20240914214802.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240914214802.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[GNN]]></title><description><![CDATA[ 
 <br><br><br>
<br>GNN<br>
<a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1pt4y1o7ER?spm_id_from=333.788.videopod.sections&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">https://www.bilibili.com/video/BV1pt4y1o7ER?spm_id_from=333.788.videopod.sections&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea</a>
<br>spectral theory of graph<br>
<a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1pr421L7xH/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">https://www.bilibili.com/video/BV1pr421L7xH/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea</a>
<br><br>
<br>《深入浅出图神经网络》
<br><br><br>PyG (PyTorch Geometric) is a library built upon  PyTorch to easily write and train Graph Neural Networks (GNNs) for a wide range of applications related to structured data.<br>
<a rel="noopener nofollow" class="external-link" href="https://pytorch-geometric.readthedocs.io/en/latest/" target="_blank">https://pytorch-geometric.readthedocs.io/en/latest/</a><br><br>以下面这张图为例。<br>
<img alt="Pasted image 20240914213015.png" src="\lib\media\pasted-image-20240914213015.png"><br>import torch
from torch_geometric.nn import MessagePassing

x = torch.tensor([[1, 2],
                  [2, 3],
                  [8, 3],
                  [2, 4]])
edge_index = torch.tensor([[0, 0, 1, 2, 2, 3],
                           [0, 1, 2, 1, 3, 2]])

class MessagePassingLayer(MessagePassing):
    def __init__(self):
        super(MessagePassingLayer, self).__init__(aggr='add')
    def forward(self, x, edge_index):
        "propagate()内部调用message()函数，并将x_j传入给message()"
        return self.propagate(x=x, edge_index=edge_index)
    def message(self, x_i, x_j):
        "x_j has shape(E, in_channels)[和索引顺序有关系]"
        print(x_i) # 中心节点特征：x_i has shape(E, in_channels)[和索引顺序有关系]
        print(x_j) # 邻居节点特征
        return x_j

MessagePassingLayer = MessagePassingLayer()
output = MessagePassingLayer(x, edge_index)
print(output)
<br>tensor([[1, 2],
        [2, 3],
        [8, 3],
        [2, 3],
        [2, 4],
        [8, 3]])
tensor([[1, 2],
        [1, 2],
        [2, 3],
        [8, 3],
        [8, 3],
        [2, 4]])
tensor([[1, 2],
        [9, 5],
        [4, 7],
        [8, 3]])
<br>edge_index = torch.tensor([[0, 0, 1, 2, 2, 3],
                           [0, 1, 2, 1, 3, 2]])
<br>edge_index在pyG中是一个邻接表，有两行，第一行为起点，第二行为终点。<br>def __init__(self):
        super(MessagePassingLayer, self).__init__(aggr='add')
<br>aggr='add'表示聚合方法为相加<br>def message(self, x_i, x_j):
        "x_j has shape(E, in_channels)[和索引顺序有关系]"
        print(x_i) # 中心节点特征：x_i has shape(E, in_channels)[和索引顺序有关系]
        print(x_j) # 邻居节点特征
        return x_j
<br>为当前需要更新的中心节点<br>
为中心节点的一阶邻居节点<br>
这里的中心节点为被指向的节点，指向该节点的节点为其邻居节点<br>当return改为+，其output会有变化<br>    def message(self, x_i, x_j):
        "x_j has shape(E, in_channels)[和索引顺序有关系]"
        print(x_i) # 中心节点特征：x_i has shape(E, in_channels)[和索引顺序有关系]
        print(x_j) # 邻居节点特征
        return (x_j + x_i)
<br>tensor([[ 2,  4],
        [13, 11],
        [20, 13],
        [10,  7]])
<br><br><br><img alt="Pasted image 20240914210835.png" src="\lib\media\pasted-image-20240914210835.png"><br>卷积算子分为基于频谱方法（代表<a data-href="GCN" href="\technology\科研\学习\gcn.html" class="internal-link" target="_self" rel="noopener nofollow">GCN</a>）与基于空间方法（代表GraphSAGE)。<br><br>Spectral GNN（谱图神经网络）和Spatial GNN（空间图神经网络）是图神经网络的两种主要类型，它们在处理图数据时采用不同的方法：<br>
<br>
Spectral GNN:

<br>基于图的谱理论，利用<a data-href="图的拉普拉斯矩阵" href="\technology\科研\学习\图的拉普拉斯矩阵.html" class="internal-link" target="_self" rel="noopener nofollow">图的拉普拉斯矩阵</a>进行信号处理。
<br>通过特征在频域中的表示来学习节点的表示，通常使用傅里叶变换。
<br>训练时需要计算图的特征值和特征向量，这可能导致计算开销较大。
<br>适合于图结构相对固定的情况，因为其方法依赖于全局的谱特性。


<br>
Spatial GNN:

<br>直接在图的空间结构上进行操作，聚合邻居节点的特征来更新每个节点的表示。
<br>不需要计算图的谱特征，而是通过局部邻域信息来学习。
<br>更加灵活，适合动态变化的图结构，计算效率较高。
<br>常见的例子包括Graph Convolutional Networks (GCNs) 和 Graph Attention Networks (GATs)。


<br>总结来说，Spectral GNN偏重于全局特征和频域分析，而Spatial GNN则更加关注局部邻域的特征聚合。选择哪种方法通常取决于具体任务的需求和图的性质。<br><br>示例1：分子属性预测<br>
<br>问题：给定一组分子结构，预测分子的特定属性（例如毒性或溶解度）。
<br>解决方案：使用Spectral GNN，首先将分子表示为图，其中节点代表原子，边代表原子之间的键。通过分子的拉普拉斯矩阵和频域卷积（如ChebNet）来提取图的全局特征。
<br>过程：利用ChebNet通过近似的频域滤波器来执行图卷积，以捕捉图的全局结构。模型在频域上学习原子之间的复杂关系，输出分子属性的预测值。
<br>示例2：脑网络分析<br>
<br>问题：给定一组大脑功能连接网络（即fMRI数据），预测是否存在某种神经疾病。
<br>解决方案：使用Spectral CNN。首先构建大脑的连接网络图，每个节点代表一个大脑区域，边表示区域之间的连接强度。使用图的拉普拉斯矩阵特征来在频域上执行卷积操作。
<br>过程：通过频域卷积捕捉大脑区域之间的全局连接特征，并检测是否存在特定模式（例如患病与否）。这种方法适合用于脑网络的全局特征分析。
<br><br>示例1：社交推荐系统<br>
<br>问题：在社交网络中，基于用户的历史行为和朋友关系，推荐可能感兴趣的内容。
<br>解决方案：使用GCN模型。构建社交网络图，每个节点代表一个用户，边代表用户之间的好友关系。利用邻居信息，通过聚合邻居节点的特征来更新每个节点的表示。
<br>过程：GCN在每一层中聚合每个用户的朋友的特征，从而获得节点的局部信息。通过多个卷积层，模型可以逐步捕捉较远邻居的影响，最终生成推荐列表。
<br>示例2：交通流量预测<br>
<br>问题：基于道路网络的传感器数据，预测某路段的未来交通流量。
<br>解决方案：使用GAT模型。将道路网络构建成图结构，节点表示道路传感器，边表示道路之间的连接关系。GAT模型通过注意力机制给相邻节点赋予不同的权重来聚合信息。
<br>过程：每个传感器节点聚合邻居节点的信息，并通过注意力机制对不同路段的影响进行加权。模型能够根据路段的重要性和当前交通状况做出预测。
<br>这两个具体应用场景展示了Spectral GNN和Spatial GNN的区别：Spectral GNN更关注全局图结构特征，适合结构固定的图，而Spatial GNN通过局部聚合方式，更适合动态图或节点间关系不对称的图。<br><br><a rel="noopener nofollow" class="external-link" href="https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html?highlight=create%20message" target="_blank">https://pytorch-geometric.readthedocs.io/en/latest/notes/create_gnn.html?highlight=create%20message</a><br>
<img alt="Pasted image 20240914211414.png" src="\lib\media\pasted-image-20240914211414.png"><br>
<img alt="Pasted image 20240914211345.png" src="\lib\media\pasted-image-20240914211345.png"><br>为当前需要更新的中心节点<br>
为中心节点的一阶邻居节点<br>
为当前中心节点与邻居节点的边<br>
表示对上面三者信息的一个聚合<br>
即为本身与其他的聚合信息更新所得<br><br><br>在图卷积网络（GCN）中，可以对图的节点进行分类，也可以对整个图结构进行分类。每种任务有不同的应用场景和模型设计，下面详细介绍这两种任务以及相关的GCN模型。<br><br>任务描述：<br>
图节点分类的目标是对图中的每个节点进行分类。每个节点可能属于多个类别，常见的应用场景包括社交网络中的用户分类、蛋白质相互作用网络中的蛋白质功能预测等。<br>模型结构：<br>
对于图节点分类任务，常用的模型结构包括多个GCN层，最后通过激活函数（如softmax）将节点特征转换为类别概率。<br>示例模型：<br>import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv

class NodeClassificationGCN(torch.nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(NodeClassificationGCN, self).__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, output_dim)

    def forward(self, x, edge_index):
        # 第一层
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, training=self.training)

        # 第二层
        x = self.conv2(x, edge_index)

        return F.log_softmax(x, dim=1)
<br>训练和评估：<br>import torch.optim as optim

# 初始化模型和优化器
model = NodeClassificationGCN(input_dim=3, hidden_dim=4, output_dim=2)
optimizer = optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.NLLLoss()

def train(data):
    model.train()
    optimizer.zero_grad()
    out = model(data.x, data.edge_index)
    loss = criterion(out[data.train_mask], data.y[data.train_mask])
    loss.backward()
    optimizer.step()
    return loss.item()

def test(data):
    model.eval()
    out = model(data.x, data.edge_index)
    pred = out.argmax(dim=1)
    correct = pred[data.test_mask].eq(data.y[data.test_mask]).sum().item()
    return correct / data.test_mask.sum().item()

# 训练模型
for epoch in range(200):
    loss = train(data)
    acc = test(data)
    print(f'Epoch: {epoch:03d}, Loss: {loss:.4f}, Test Acc: {acc:.4f}')
<br><br>任务描述：<br>
图结构分类的目标是对整个图进行分类。每个图可能属于多个类别，常见的应用场景包括分子分类、社交网络中的社区检测等。<br>模型结构：<br>
对于图结构分类任务，常用的模型结构包括多个GCN层，最后通过池化操作将每个图的节点特征聚合为一个图级别的特征向量，再通过一个全连接层进行分类。<br>示例模型：<br>import torch
import torch.nn.functional as F
from torch_geometric.nn import GCNConv
from torch_scatter import scatter_mean

class GraphClassificationGCN(torch.nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        super(GraphClassificationGCN, self).__init__()
        self.conv1 = GCNConv(input_dim, hidden_dim)
        self.conv2 = GCNConv(hidden_dim, output_dim)

    def forward(self, x, edge_index, batch):
        # 第一层
        x = self.conv1(x, edge_index)
        x = F.relu(x)
        x = F.dropout(x, training=self.training)

        # 第二层
        x = self.conv2(x, edge_index)

        # 对每个图进行池化，获取图级别的特征
        x = scatter_mean(x, batch, dim=0)

        return F.log_softmax(x, dim=1)
<br>训练和评估：<br>import torch.optim as optim

# 初始化模型和优化器
model = GraphClassificationGCN(input_dim=3, hidden_dim=4, output_dim=2)
optimizer = optim.Adam(model.parameters(), lr=0.01)
criterion = torch.nn.NLLLoss()

def train():
    model.train()
    for data in loader:
        out = model(data.x, data.edge_index, data.batch)
        loss = criterion(out, data.y)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

def test(loader):
    model.eval()
    correct = 0
    for data in loader:
        out = model(data.x, data.edge_index, data.batch)
        pred = out.argmax(dim=1)
        correct += pred.eq(data.y).sum().item()
    return correct / len(loader.dataset)

# 训练模型
for epoch in range(200):
    train()
    train_acc = test(loader)
    print(f'Epoch: {epoch:03d}, Train Acc: {train_acc:.4f}')
<br><br>GCNConv层是图卷积网络中的基本组件，用于对图中的节点特征进行卷积操作。其核心公式为：<br><br>其中：<br>
<br> 是输入特征矩阵，形状为 ，其中  是节点数， 是输入特征维度。
<br> 是归一化的邻接矩阵， 是添加了自环的邻接矩阵， 是对应的度矩阵。
<br> 是权重矩阵，形状为 ，其中  是输出特征维度。
<br> 是激活函数，例如 ReLU。
<br>内部实现：<br>class GCNConv(torch.nn.Module):
    def __init__(self, in_channels, out_channels):
        super(GCNConv, self).__init__()
        self.lin = torch.nn.Linear(in_channels, out_channels)

    def forward(self, x, edge_index):
        # 添加自环
        edge_index, _ = add_self_loops(edge_index, num_nodes=x.size(0))

        # 计算度矩阵的平方根逆
        row, col = edge_index
        deg = degree(col, x.size(0), dtype=x.dtype)
        deg_inv_sqrt = deg.pow(-0.5)
        norm = deg_inv_sqrt[row] * deg_inv_sqrt[col]

        # 应用权重矩阵 W
        x = self.lin(x)

        # 消息传递
        return self.propagate(edge_index, x=x, norm=norm)

    def message(self, x_j, norm):
        # 归一化消息
        return norm.view(-1, 1) * x_j

    def update(self, aggr_out):
        # 返回聚合后的消息
        return aggr_out
<br>详细步骤：<br>
<br>
添加自环：

<br>通过 add_self_loops 函数在邻接矩阵中添加自环，确保每个节点都能接收到自身的特征信息。


<br>
计算度矩阵的平方根逆：

<br>计算每个节点的度（即连接的边数），并计算度矩阵的平方根逆。
<br>归一化系数  用于在消息传递过程中对消息进行归一化。


<br>
应用权重矩阵 ：

<br>通过 self.lin(x) 应用线性变换，将输入特征矩阵  转换为新的特征矩阵 。


<br>
消息传递：

<br>在 message 方法中，将归一化后的消息  发送到相邻节点。
<br>在 update 方法中，聚合所有接收到的消息，得到每个节点的新特征。


<br>让我们通过一个示例来描述每一层的输入和输出，具体讲解图卷积网络（GCN）的节点分类任务。这个示例将帮助我们理解数据是如何在每一层中流动的。<br><br>我们有一个简单的图，包含4个节点和4条边。每个节点有一个长度为3的特征向量，并且我们将使用2个GCN层进行节点分类。<br><br>
<br>
节点：4个节点，编号为

<br>
边：图中有以下边：。

<br>
节点特征：每个节点有一个长度为3的特征向量。
假设节点的特征矩阵如下所示：

这里，每一行表示每个节点的特征向量。

<br>
邻接矩阵（添加自环）：

邻接矩阵表示图的连接性。对角线上的元素被设为1，以包括自环（即每个节点与自己相连）。

<br><br><br>第一个GCN层对输入特征矩阵执行图卷积操作。<br><br>
<br>
节点特征矩阵：这是所有节点的特征矩阵，形状为（4个节点，每个节点有3个特征）。


<br>
邻接矩阵：这是表示图结构的邻接矩阵。


<br><br>第一个GCN层执行以下操作：<br><br>其中：<br>
<br>是归一化的邻接矩阵（包括自环）。
<br>是第一个GCN层的权重矩阵，形状为（输入大小为3，输出大小为4）。
<br>是激活函数，通常使用ReLU。
<br>邻接矩阵归一化：<br>
在乘以特征矩阵之前，邻接矩阵需要进行归一化，以确保节点的邻居数目较多的节点不会在信息聚合中占主导地位。<br><br>
<br>形状：该层的输出形状为（4个节点，每个节点有4个输出特征）。
<br>在应用图卷积和激活函数（如ReLU）后，得到变换后的特征矩阵，该矩阵包含每个节点的新特征表示。
<br><br>第二个GCN层对第一个层的输出进行图卷积操作。<br><br>
<br>第一个GCN层的输出特征矩阵：该矩阵的形状为（4个节点，每个节点有4个特征）。
<br>邻接矩阵：邻接矩阵保持不变。
<br><br>第二个GCN层执行以下操作：<br><br>其中：<br>
<br>是第二个GCN层的权重矩阵，形状为（输入大小为4，输出大小为2）。
<br>是激活函数，通常使用ReLU。
<br><br>
<br>形状：该层的输出形状为（4个节点，每个节点有2个输出特征，表示每个类别的概率）。
<br>在应用第二个图卷积和激活函数后，得到最终输出矩阵，每个节点的输出向量现在是一个2维向量（表示类别的概率）。
<br><br>对于节点分类，通常在输出层应用softmax激活函数，以获得每个节点的预测类别概率。<br><br>
<br>形状：，每行表示每个节点的类别概率分布。
<br>解释：每个节点的输出是一个2维向量，表示该节点属于每个类别的概率。
<br><br><br><br><br>
<br>输入特征：每个节点开始时有一个特征向量（例如3维）。
<br>GCN层：每个GCN层执行图卷积操作，聚合邻居节点的信息，并变换节点特征。
<br>输出：通过GCN层处理后，节点特征被转换为类别的预测概率。
<br>通过这种逐步的流动，GCN能够通过考虑邻居节点和自身特征，学习到节点的有意义表示，从而可以用于节点分类等任务。<br>让我们通过一个示例来说明图结构分类任务中的输入和输出。与节点分类任务不同，图结构分类任务的目标是对整个图进行分类，而不是对每个节点进行分类。我们将使用图卷积网络（GCN）来完成这个任务，并重点描述每一层的输入和输出。<br><br>假设我们有3个图，每个图有不同数量的节点和边。我们将对这些图进行分类，目标是预测每个图属于哪个类别（例如，化学分子的分类任务）。<br><br>
<br>图1：包含3个节点和3条边，节点特征维度为3。
<br>图2：包含4个节点和4条边，节点特征维度为3。
<br>图3：包含5个节点和5条边，节点特征维度为3。
<br>每个图的目标是通过GCN来生成一个图级别的特征表示，并最终输出该图的类别。<br><br>
<br>对每个图进行图卷积操作。
<br>使用池化操作（如全局平均池化，和池，Max池化）将每个图的节点特征聚合为图级别的特征。
<br>使用一个全连接层进行分类，输出该图的类别。
<br><br><br>第一个GCN层对每个图的节点特征进行卷积操作，生成新的节点特征。<br><br>
<br>
节点特征矩阵（每个图的输入矩阵）：假设每个图的节点特征维度为3。
例如，图1的节点特征矩阵为：


<br>
邻接矩阵（每个图的邻接矩阵）：假设图1的邻接矩阵为：


<br><br>第一个GCN层执行以下操作：<br><br>其中：<br>
<br>是归一化的邻接矩阵（包括自环）。
<br>是第一个GCN层的权重矩阵，形状为（输入特征维度为3，输出特征维度为4）。
<br>是激活函数（例如ReLU）。
<br><br>
<br>形状：该层的输出特征矩阵的形状为（3个节点，每个节点4个特征）。
<br><br>第二个GCN层对第一个GCN层的输出进行图卷积操作。<br><br>
<br>
第一个GCN层的输出特征矩阵：该矩阵的形状为。

<br>
邻接矩阵：邻接矩阵仍然保持不变。

<br><br>第二个GCN层执行以下操作：<br><br>其中：<br>
<br>是第二个GCN层的权重矩阵，形状为（输入特征维度为4，输出特征维度为2）。
<br>是激活函数（通常使用ReLU）。
<br><br>
<br>形状：该层的输出特征矩阵的形状为（3个节点，每个节点2个特征，表示类别的概率）。
<br>输出矩阵中的每个节点都包含一个2维的特征表示。
<br><br>在图结构分类任务中，我们通常需要对每个图的节点特征进行池化操作，得到一个图级别的特征表示。常用的池化方法有全局平均池化或全局最大池化。这里我们使用全局平均池化来聚合图中所有节点的特征。<br><br>全局平均池化会对每个图的所有节点特征取平均值，得到一个图级别的特征向量。对于图1，池化操作如下：<br><br>其中是图中节点的数量，是第个节点的特征。<br>对于图1，假设其输出矩阵为：<br><br>全局平均池化后，我们得到：<br><br><br>
<br>形状：每个图经过池化后都得到一个维的图级别特征向量。每个图的输出为维向量，表示图的特征。
<br><br>将图级别的特征传入全连接层进行分类。<br><br>
<br>图级别特征向量（来自池化层）：假设池化后的特征为维向量。
<br><br>通过一个全连接层对图级别特征进行分类，输出图的类别。假设有2个类别，我们使用softmax函数输出每个图属于各个类别的概率。<br><br>其中是全连接层的权重矩阵，是分类概率。<br><br>
<br>形状：每个图的输出是一个2维的概率向量，表示该图属于每个类别的概率。
<br><br><br><br>这样，每一层的输入和输出形状与示例中的节点数保持一致。<br><br>
<br>节点特征：每个图开始时的节点特征通常是多维的（例如3维）。
<br>GCN层：每个GCN层对图进行卷积操作，更新节点特征。
<br>池化操作：通过池化将每个图的节点特征聚合为一个图级别的特征表示。
<br>分类：通过全连接层和softmax对图进行分类，输出类别概率。
<br>通过这种方式，GCN能够学习到图的全局特征，从而用于图结构分类任务。]]></description><link>technology\科研\学习\gnn学习.html</link><guid isPermaLink="false">Technology/科研/学习/GNN学习.md</guid><pubDate>Tue, 12 Nov 2024 03:33:33 GMT</pubDate><enclosure url="lib\media\pasted-image-20240914213015.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240914213015.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[代码]]></title><description><![CDATA[ 
 <br>代码链接：<a rel="noopener nofollow" class="external-link" href="https://github.com/AmirSh15/Compact_SER" target="_blank">https://github.com/AmirSh15/Compact_SER</a>]]></description><link>technology\科研\rtfsc-gcn\代码.html</link><guid isPermaLink="false">Technology/科研/RTFSC-GCN/代码.md</guid><pubDate>Thu, 19 Sep 2024 07:29:27 GMT</pubDate></item><item><title><![CDATA[代码结构]]></title><description><![CDATA[ 
 ]]></description><link>technology\科研\rtfsc-gcn\代码结构.html</link><guid isPermaLink="false">Technology/科研/RTFSC-GCN/代码结构.canvas</guid><pubDate>Wed, 25 Sep 2024 10:07:57 GMT</pubDate></item><item><title><![CDATA[修改后的图卷积神经网络]]></title><description><![CDATA[ 
 <br><br>### MLP with linear output
class MLP(nn.Module):
    def __init__(self, num_layers, input_dim, hidden_dim, output_dim):
        '''
            num_layers: 神经网络层数（不包括输入层）。如果 num_layers=1，则简化为线性模型。
            input_dim: 输入特征的维度。
            hidden_dim: 所有隐藏层的单元维度。
            output_dim: 预测的类别数。
        '''

        super(MLP, self).__init__()

        # 默认为线性模型
        self.linear_or_not = True 
        self.num_layers = num_layers

        # 检查层数是否为正数
        if num_layers &lt; 1:
            raise ValueError("神经网络的层数应该为正数！")
        elif num_layers == 1:
            # 线性模型
            self.linear = nn.Linear(input_dim, output_dim, bias=True)
        else:
            # 多层模型
            self.linear_or_not = False
            self.linears = torch.nn.ModuleList()  # 用于存储每一层的线性变换
            self.batch_norms = torch.nn.ModuleList()  # 用于存储每一层的批量归一化
            
            # 第一层从输入维度到隐藏维度
            self.linears.append(nn.Linear(input_dim, hidden_dim))
            
            # 中间层
            for layer in range(num_layers - 2):
                self.linears.append(nn.Linear(hidden_dim, hidden_dim))
            
            # 最后一层从隐藏维度到输出维度
            self.linears.append(nn.Linear(hidden_dim, output_dim))
            
            # 添加批量归一化层
            for layer in range(num_layers - 1):
                self.batch_norms.append(nn.BatchNorm1d(hidden_dim))

    def forward(self, x):
        if self.linear_or_not:
            # 如果是线性模型
            return self.linear(x)
        else:
            # 如果是多层感知机
            h = x
            for layer in range(self.num_layers - 1):
                h = F.relu(self.batch_norms[layer](self.linears[layer](h)))  # 通过线性层、批量归一化层和激活函数
            return self.linears[self.num_layers - 1](h)  # 最终的输出层，没有激活函数
print('complete')
# 归一化有向图
def normalize_digraph(A):
    Dl = np.sum(A, 0)
    num_node = A.shape[0]
    Dn = np.zeros((num_node, num_node))
    for i in range(num_node):
        if Dl[i] &gt; 0:
            Dn[i, i] = Dl[i]**(-1)
    AD = np.dot(A, Dn)
    return AD

# 将密集张量转换为稀疏格式
def to_sparse(x):
    x_typename = torch.typename(x).split('.')[-1]
    sparse_tensortype = getattr(torch.sparse, x_typename)

    indices = torch.nonzero(x)
    if len(indices.shape) == 0:  # 如果所有元素都是零
        return sparse_tensortype(*x.shape)
    indices = indices.t()
    values = x[tuple(indices[i] for i in range(indices.shape[0]))]
    return sparse_tensortype(indices, values, x.size())

# 计算图的度矩阵
def Comp_degree(A):
    device = A.device
    out_degree = torch.sum(A, dim=0).to(device)
    in_degree = torch.sum(A, dim=1).to(device)
    diag = torch.eye(A.size()[0], device=device)
    degree_matrix = diag*in_degree + diag*out_degree - torch.diagflat(torch.diagonal(A))
    return degree_matrix

# 图卷积层定义
class GraphConv_Ortega(nn.Module):
    def __init__(self, in_dim, out_dim, num_layers=2, hidden_dim=128):
        super(GraphConv_Ortega, self).__init__()
        self.in_dim = in_dim
        self.out_dim = out_dim
        self.MLP = MLP(num_layers, in_dim, hidden_dim, out_dim)

        for i in range(num_layers):
            init.xavier_uniform_(self.MLP.linears[i].weight)
            init.constant_(self.MLP.linears[i].bias, 0)

    def forward(self, features, A):
        b, n, d = features.shape
        assert (d == self.in_dim)
        if(len(A.shape) == 2):
            A_norm = A
            deg_mat = Comp_degree(A_norm)
            frac_degree = torch.FloatTensor(fractional_matrix_power(deg_mat.detach().cpu(), -0.5)).cuda()
            Laplacian = deg_mat - A_norm
            Laplacian_norm = frac_degree.matmul(Laplacian.matmul(frac_degree))
            landa, U = torch.linalg.eig(Laplacian_norm)

            # 只保留实数部分
            U_real = U.real

            repeated_U_t = U_real.t().repeat(b, 1, 1)
            repeated_U = U_real.repeat(b, 1, 1)
        else:
            repeated_U_t = []
            repeated_U = []
            for i in range(A.shape[0]):
                A_norm = A[i]
                deg_mat = Comp_degree(A_norm)
                frac_degree = torch.FloatTensor(fractional_matrix_power(deg_mat.detach().cpu(), -0.5)).cuda()
                Laplacian = deg_mat - A_norm
                Laplacian_norm = frac_degree.matmul(Laplacian.matmul(frac_degree))
                landa, U = torch.linalg.eig(Laplacian_norm)

                # 只保留实数部分
                U_real = U.real

                repeated_U_t.append(U_real.t().view(1, U_real.shape[0], U_real.shape[1]))
                repeated_U.append(U_real.view(1, U_real.shape[0], U_real.shape[1]))
            repeated_U_t = torch.cat(repeated_U_t)
            repeated_U = torch.cat(repeated_U)

        agg_feats = torch.bmm(repeated_U_t, features)
        out = self.MLP(agg_feats.view(-1, d)).view(b, -1, self.out_dim)
        out = torch.bmm(repeated_U, out)
        return out

# 定义图卷积神经网络模型
class Graph_CNN_ortega(nn.Module):
    def __init__(self, num_layers, input_dim, hidden_dim, output_dim, final_dropout,
                 graph_pooling_type, device, adj):
        super(Graph_CNN_ortega, self).__init__()

        self.final_dropout = final_dropout
        self.device = device
        self.num_layers = num_layers
        self.graph_pooling_type = graph_pooling_type
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim

        self.Adj = adj

        self.GCNs = torch.nn.ModuleList()
        self.GCNs.append(GraphConv_Ortega(self.input_dim, self.hidden_dim))
        for i in range(self.num_layers-1):
            self.GCNs.append(GraphConv_Ortega(self.hidden_dim, self.hidden_dim))

        self.classifier = nn.Sequential(
                            nn.Linear(self.hidden_dim, 128),
                            nn.Dropout(p=self.final_dropout),
                            nn.PReLU(128),
                            nn.Linear(128, output_dim))

    def forward(self, data: Data):
        """
        :param data: torch_geometric.data.Data object
        """
        # 获取 Data 对象中的节点特征和邻接矩阵
        x = data.x  # 节点特征: (num_nodes, num_features)
        edge_index = data.edge_index  # 边连接信息: (2, num_edges)

        # 获取邻接矩阵
        edge_index = edge_index.to(self.device)
        adj = torch.zeros(x.size(0), x.size(0), device=self.device)

        adj[edge_index[0], edge_index[1]] = 1
        adj[edge_index[1], edge_index[0]] = 1  # 对称邻接矩阵

        # 归一化邻接矩阵
        adj = normalize_digraph(adj)

        # 图卷积操作
        h = x
        for layer in self.GCNs:
            h = F.relu(layer(h, adj))

        # 池化操作
        if self.graph_pooling_type == 'mean':
            pooled = torch.mean(h, dim=1)
        elif self.graph_pooling_type == 'max':
            pooled = torch.max(h, dim=1)[0]
        elif self.graph_pooling_type == 'sum':
            pooled = torch.sum(h, dim=1)

        # 分类
        score = self.classifier(pooled)

        return score

<br><br>class Base_GCNModel(torch.nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=2, dropout=0.5):
        super(Base_GCNModel, self).__init__()

        self.num_layers = num_layers
        self.hidden_dim = hidden_dim
        self.dropout = dropout

        # 定义GCN层
        self.convs = torch.nn.ModuleList()  # 用来存储多个 GCNConv 层
        self.convs.append(GCNConv(input_dim, hidden_dim))  # 第一层
        for _ in range(num_layers - 1):
            self.convs.append(GCNConv(hidden_dim, hidden_dim))  # 后续层
        
        # 全连接层进行分类
        self.fc1 = torch.nn.Linear(hidden_dim, hidden_dim)
        self.fc2 = torch.nn.Linear(hidden_dim, output_dim)

    def forward(self, data):
        x, edge_index = data.x, data.edge_index

        # 多层 GCN + 激活函数 + Dropout
        for i in range(self.num_layers):
            x = F.relu(self.convs[i](x, edge_index))  # 每层 GCN
            x = F.dropout(x, p=self.dropout, training=self.training)  # Dropout
        
        # 池化操作，汇聚所有节点特征
        x = global_mean_pool(x, data.batch)  # 使用全局平均池化

        # 全连接层进行分类
        x = F.relu(self.fc1(x))  # 激活函数
        x = F.dropout(x, p=self.dropout, training=self.training)  # Dropout
        x = self.fc2(x)  # 输出层

        return F.log_softmax(x, dim=-1)  # 使用log softmax进行分类


<br>这个卷积层与传统图卷积（GCN）有几个显著的区别：<br><br>
<br>传统GCN：通常使用简单的图卷积操作，其中节点特征通过邻接矩阵进行加权传播。标准的GCN卷积操作形式为：  

其中， 是归一化的邻接矩阵， 是度矩阵， 是邻接矩阵， 是节点特征， 是权重矩阵， 是激活函数（如ReLU）。
<br>这个卷积层：在传统GCN的基础上进行了扩展和修改，使用了拉普拉斯矩阵和度矩阵的分数阶矩阵幂（fractional power）。具体来说，它计算了图的拉普拉斯矩阵（），并对度矩阵进行分数阶矩阵幂操作：

这样做的目的是为了通过度矩阵的分数幂来进一步调节节点特征的传播方式，使得信息传播的机制更加灵活，可能更好地捕捉到图中节点之间的关系。
<br><br>
<br>传统GCN：节点特征通过邻接矩阵直接传播，常见的聚合方式包括加和或平均。
<br>这个卷积层：在每层图卷积操作中，特征通过拉普拉斯矩阵的特征向量（）进行加权聚合。它首先计算拉普拉斯矩阵的特征值和特征向量，然后使用这些特征向量将节点特征进行加权聚合。通过特征向量的操作，可以理解为将图的结构信息引入特征聚合的过程中，增强了卷积操作对图结构的感知能力。
<br><br>
<br>传统GCN：通常使用单一的线性变换和非线性激活函数来变换节点特征。
<br>这个卷积层：在图卷积之后，使用了一个MLP（多层感知器）来进一步处理特征。这个MLP通过多个全连接层来映射节点的聚合特征到更高维度，并最终输出节点的表示。MLP的引入增加了模型的非线性变换能力，可以提取更多复杂的特征。
<br><br>
<br>传统GCN：通常假设邻接矩阵是固定的，且通过简单的标准化（例如归一化）来处理图结构。
<br>这个卷积层：除了标准的邻接矩阵处理，还根据拉普拉斯矩阵的特征向量和分数阶度矩阵的计算，对邻接矩阵进行了更加复杂的处理。这样处理后，邻接矩阵不仅仅用于图的结构描述，还可以通过它的特征向量和度矩阵的变换来控制节点特征的传播模式。
<br><br>
<br>传统GCN侧重于通过邻接矩阵的标准化来完成信息传播。
<br>这个卷积层通过引入拉普拉斯矩阵的特征向量和度矩阵的分数阶矩阵幂操作，增强了对图结构的感知能力。并且，它结合了MLP进一步处理特征信息，提高了模型的表达能力。
<br>因此，这个卷积层相比传统GCN更加复杂且灵活，通过对图的结构信息进行更加精细的处理，可能能够提升模型在一些图数据上的表现。]]></description><link>technology\科研\rtfsc-gcn\修改后的图卷积神经网络.html</link><guid isPermaLink="false">Technology/科研/RTFSC-GCN/修改后的图卷积神经网络.md</guid><pubDate>Wed, 13 Nov 2024 09:22:10 GMT</pubDate></item><item><title><![CDATA[OpenSmile配置文件解读]]></title><description><![CDATA[ 
 <br>这个 openSMILE 配置文件定义了从音频信号中提取各种特征的过程。下面是对配置文件各个部分的详细解释：<br><br>///////////////////////////////////////////////////////////////////////////
// openSMILE configuration template file generated by SMILExtract binary //
// you must manually adapt this file and change at least the             //
// 'reader/writer.dmLevel =' lines.                                      //
///////////////////////////////////////////////////////////////////////////
<br>
<br>这是一个由 SMILExtract 生成的 openSMILE 配置文件模板。
<br>用户需要手动调整文件，特别是 reader/writer.dmLevel 行。
<br><br>;===== component manager configuration (= list of enabled components!) =====

[componentInstances:cComponentManager]
instance[dataMemory].type = cDataMemory
instance[waveSource].type = cWaveSource
instance[framer].type = cFramer
instance[mzcr].type=cMZcr
instance[csvSink].type = cCsvSink
instance[pe].type=cVectorPreemphasis
instance[win].type=cWindower
instance[fft].type=cTransformFFT
instance[fftmag].type=cFFTmagphase
instance[melspec].type=cMelspec
instance[mfcc].type=cMfcc
instance[acf].type=cAcf
instance[cepstrum].type=cAcf
instance[pitchACF].type=cPitchACF
instance[sma].type=cContourSmoother
instance[delta].type=cDeltaRegression
instance[energy].type = cEnergy
<br>
<br>定义了启用的组件及其类型。
<br>cDataMemory：默认数据内存组件。
<br>cWaveSource：读取音频文件。
<br>cFramer：将音频信号分割成帧。
<br>cMZcr：计算过零率（Zero Crossing Rate）。
<br>cCsvSink：将结果输出到 CSV 文件。
<br>cVectorPreemphasis：对音频信号进行预加重处理。
<br>cWindower：应用窗口函数。
<br>cTransformFFT：进行快速傅里叶变换（FFT）。
<br>cFFTmagphase：计算 FFT 的幅度和相位。
<br>cMelspec：计算梅尔频谱。
<br>cMfcc：计算 MFCC 特征。
<br>cAcf：计算自相关函数（用于基音检测）。
<br>cPitchACF：基于自相关函数的基音检测。
<br>cContourSmoother：平滑轮廓特征。
<br>cDeltaRegression：计算特征的一阶差分。
<br>cEnergy：计算音频信号的能量。
<br><br>; run single threaded (nThreads=1)
; NOTE: a single thread is more efficient for processing small files, since multi-threaded processing involves more 
;       overhead during startup, which will make the system slower in the end
nThreads=1
; do not show any internal dataMemory level settings 
; (if you want to see them set the value to 1, 2, 3, or 4, depending on the amount of detail you wish)
printLevelStats=0
<br>
<br>设置为单线程运行 (nThreads=1)，对于小文件更高效。
<br>printLevelStats=0：不显示内部数据内存级别的设置。
<br><br><br>[waveSource:cWaveSource]
writer.dmLevel = wave
basePeriod = -1
filename = \cm[inputfile(I):file name of the input wave file]
properTimestamps = 0
monoMixdown = 1
start = 0
end = -1
endrel = 0
noHeader = 0
outFieldName = pcm
<br>
<br>读取音频文件。
<br>writer.dmLevel = wave：写入的数据级别为 wave。
<br>basePeriod = -1：基础周期设置为 -1，表示使用整个文件。
<br>filename：输入音频文件名。
<br>properTimestamps = 0：不使用精确时间戳。
<br>monoMixdown = 1：将立体声混合为单声道。
<br>start 和 end：开始和结束时间点，默认处理整个文件。
<br>outFieldName = pcm：输出字段名为 pcm。
<br><br>[framer:cFramer]
reader.dmLevel = wave
writer.dmLevel = waveframes
copyInputName = 1
EOIlevel = 0
allowLastFrameIncomplete = 0
frameMode = fixed
frameSize = 0.025000
frameStep = 0.010000
frameCenterSpecial = left
noPostEOIprocessing = 1
<br>
<br>将音频信号分割成帧。
<br>reader.dmLevel = wave：从 wave 数据级别读取。
<br>writer.dmLevel = waveframes：写入的数据级别为 waveframes。
<br>frameSize = 0.025000：每帧大小为 25 毫秒。
<br>frameStep = 0.010000：帧移为 10 毫秒。
<br><br>[energy:cEnergy]
reader.dmLevel = waveframes
writer.dmLevel = energy
nameAppend = energy
copyInputName = 1
EOIlevel = 0
processArrayFields = 0
includeSingleElementFields = 0
preserveFieldNames = 1
htkcompatible = 0
rms = 0
energy2 = 0
log = 1
escaleLog = 1
escaleRms = 1
escaleSquare = 1
ebiasLog = 0
ebiasRms = 0
ebiasSquare = 0
<br>
<br>计算音频信号的能量。
<br>reader.dmLevel = waveframes：从 waveframes 数据级别读取。
<br>writer.dmLevel = energy：写入的数据级别为 energy。
<br>log = 1：对能量取对数。
<br>escaleLog = 1：对数能量的缩放。
<br><br>[pe:cVectorPreemphasis]
reader.dmLevel=waveframes
writer.dmLevel=framespe
k = 0.97
de = 0
<br>
<br>对音频信号进行预加重处理。
<br>reader.dmLevel=waveframes：从 waveframes 数据级别读取。
<br>writer.dmLevel=framespe：写入的数据级别为 framespe。
<br>k = 0.97：预加重系数。
<br><br>[win:cWindower]
reader.dmLevel=framespe
writer.dmLevel=winframes
copyInputName = 1
processArrayFields = 1
winFunc = ham
gain = 1.0
offset = 0
<br>
<br>应用窗口函数。
<br>reader.dmLevel=framespe：从 framespe 数据级别读取。
<br>writer.dmLevel=winframes：写入的数据级别为 winframes。
<br>winFunc = ham：使用汉明窗。
<br><br>[fft:cTransformFFT]
reader.dmLevel=winframes
writer.dmLevel=fft
copyInputName = 1
processArrayFields = 1
inverse = 0
zeroPadSymmetric = 0
<br>
<br>进行快速傅里叶变换。
<br>reader.dmLevel=winframes：从 winframes 数据级别读取。
<br>writer.dmLevel=fft：写入的数据级别为 fft。
<br><br>[fftmag:cFFTmagphase]
reader.dmLevel=fft
writer.dmLevel=fftmag
copyInputName = 1
processArrayFields = 1
inverse = 0
magnitude = 1
phase = 0
<br>
<br>计算 FFT 的幅度。
<br>reader.dmLevel=fft：从 fft 数据级别读取。
<br>writer.dmLevel=fftmag：写入的数据级别为 fftmag。
<br>magnitude = 1：计算幅度。
<br>phase = 0：不计算相位。
<br><br>[melspec:cMelspec]
reader.dmLevel=fftmag
writer.dmLevel=melspec
copyInputName = 1
processArrayFields = 1
htkcompatible = 1
nBands = 26
usePower = 1
lofreq = 0
hifreq = 8000
specScale = mel
inverse = 0
<br>
<br>计算梅尔频谱。
<br>reader.dmLevel=fftmag：从 fftmag 数据级别读取。
<br>writer.dmLevel=melspec：写入的数据级别为 melspec。
<br>nBands = 26：梅尔滤波器的数量。
<br>lofreq = 0 和 hifreq = 8000：频率范围。
<br>specScale = mel：使用梅尔刻度。
<br><br>[mfcc:cMfcc]
reader.dmLevel=melspec
writer.dmLevel=ft0
copyInputName = 1
processArrayFields = 1
firstMfcc = 0
lastMfcc  = 12
cepLifter = 22.0
htkcompatible = 1
<br>
<br>计算 MFCC 特征。
<br>reader.dmLevel=melspec：从 melspec 数据级别读取。
<br>writer.dmLevel=ft0：写入的数据级别为 ft0。
<br>firstMfcc = 0 和 lastMfcc = 12：计算 13 个 MFCC 系数。
<br>cepLifter = 22.0：倒谱提升系数。
<br><br>[mzcr:cMZcr]
reader.dmLevel=waveframes
writer.dmLevel=mzcr
copyInputName = 1
processArrayFields = 1
zcr = 1
amax = 0
mcr = 0
maxmin = 0
dc = 0
<br>
<br>计算过零率。
<br>reader.dmLevel=waveframes：从 waveframes 数据级别读取。
<br>writer.dmLevel=mzcr：写入的数据级别为 mzcr。
<br>zcr = 1：计算过零率。
<br><br>[acf:cAcf]
reader.dmLevel=fftmag
writer.dmLevel=acf
nameAppend = acf
copyInputName = 1
processArrayFields = 1
usePower = 1
cepstrum = 0

[cepstrum:cAcf]
reader.dmLevel=fftmag
writer.dmLevel=cepstrum
nameAppend = acf
copyInputName = 1
processArrayFields = 1
usePower = 1
cepstrum = 1
<br>
<br>计算自相关函数和倒谱。
<br>reader.dmLevel=fftmag：从 fftmag 数据级别读取。
<br>writer.dmLevel=acf 和 writer.dmLevel=cepstrum：分别写入 acf 和 cepstrum 数据级别。
<br>cepstrum = 0 和 cepstrum = 1：是否计算倒谱。
<br><br>[pitchACF:cPitchACF]
reader.dmLevel=acf;cepstrum
writer.dmLevel=pitch
copyInputName = 1
processArrayFields=0
maxPitch = 500
voiceProb = 1
voiceQual = 0
HNR = 0
F0 = 1
F0raw = 0
F0env = 0
voicingCutoff = 0.550000
<br>
<br>基于自相关函数的基音检测。
<br>reader.dmLevel=acf;cepstrum：从 acf 和 cepstrum 数据级别读取。
<br>writer.dmLevel=pitch：写入的数据级别为 pitch。
<br>maxPitch = 500：最大基音频率。
<br>F0 = 1：计算基音频率。
<br><br>[sma:cContourSmoother]
reader.dmLevel=ft0;mzcr;pitch;energy
writer.dmLevel=lld
nameAppend = sma
copyInputName = 1
noPostEOIprocessing = 0
smaWin = 3
<br>
<br>平滑轮廓特征。
<br>reader.dmLevel=ft0;mzcr;pitch;energy：从多个数据级别读取。
<br>writer.dmLevel=lld：写入的数据级别为 lld。
<br>smaWin = 3：平滑窗口大小为 3。
<br><br>[delta:cDeltaRegression]
reader.dmLevel=lld
writer.dmLevel=lld_de
nameAppend = de
copyInputName = 1
noPostEOIprocessing = 0
deltawin=2
blocksize=1
<br>
<br>计算特征的一阶差分。
<br>reader.dmLevel=lld：从 lld 数据级别读取。
<br>writer.dmLevel=lld_de：写入的数据级别为 lld_de。
<br>deltawin=2：差分窗口大小为 2。
<br><br>[csvSink:cCsvSink]
reader.dmLevel = ft0;mzcr;pitch;lld_de
errorOnNoOutput = 0
filename = \cm[outputfile(O):file name of the output CSV file]
delimChar = ;
append = 0
timestamp = 1
frameTime = 1
number = 1
frameIndex = 1
printHeader = 1
flush = 0
<br>
<br>将结果输出到 CSV 文件。
<br>reader.dmLevel = ft0;mzcr;pitch;lld_de：从多个数据级别读取。
<br>filename：输出 CSV 文件名。
<br>delimChar = ;：CSV 分隔符为分号。
<br>timestamp = 1 和 frameTime = 1：包含时间戳和帧时间。
<br>printHeader = 1：输出文件包含表头。
<br><br>// ################### END OF openSMILE CONFIG FILE ######################
<br>
<br>标记配置文件的结束。
<br>通过这个配置文件，openSMILE 可以从音频文件中提取多种特征，并将结果输出到 CSV 文件中。每个组件都有其特定的功能，如读取音频、分帧、预加重、窗口化、FFT、梅尔频谱、MFCC、过零率、自相关函数、基音检测、平滑等。]]></description><link>technology\科研\rtfsc-gcn\opensmile配置文件解读.html</link><guid isPermaLink="false">Technology/科研/RTFSC-GCN/OpenSmile配置文件解读.md</guid><pubDate>Thu, 26 Sep 2024 07:26:39 GMT</pubDate></item><item><title><![CDATA[代码结构]]></title><description><![CDATA[ 
 <br><a data-href="data.py" href="\technology\科研\rtfsc-multilabel\data.py.html" class="internal-link" target="_self" rel="noopener nofollow">data.py</a>创建训练集、测试集类<br><a data-href="helpers.py" href="\technology\科研\rtfsc-multilabel\helpers.py.html" class="internal-link" target="_self" rel="noopener nofollow">helpers.py</a>创建主要训练测试逻辑]]></description><link>technology\科研\rtfsc-multilabel\代码结构.html</link><guid isPermaLink="false">Technology/科研/RTFSC-Multilabel/代码结构.canvas</guid><pubDate>Mon, 16 Sep 2024 08:55:18 GMT</pubDate></item><item><title><![CDATA[多标签转化为Graph]]></title><description><![CDATA[ 
 <br>def create_graph(embedding_file, verbose):
    gts = np.load('data\\file_gts.npy')
    print(f'load initial node embedding from {embedding_file}... ', end='')
    if embedding_file[-3:] == 'npy':
        x0 = np.load(embedding_file)
        x0 = torch.from_numpy(x0).float()
    elif embedding_file[-3:] == 'pth':
        x0 = torch.load(embedding_file)
    else:
        raise ValueError('Initial embedding not defined')
    print('done')

    print('building graph... ', end='')
    C = gts.T @ gts  # compute labels co-occurence binary matrix
    C = C / np.diag(C)  # compute labels co-occurrence probability matrix
    np.fill_diagonal(C, 0)  # remove self-loops

    adj = SparseTensor.from_dense(torch.from_numpy(C).float())
    row, col, edge_attr = adj.t().coo()
    edge_index = torch.stack([row, col], dim=0)

    G = Data(x=x0, edge_index=edge_index, edge_attr=edge_attr, batch=torch.ones(200))
    print('done\n')

    if verbose:
        print('Graph statistics:')
        print(G)
        print(f'Number of nodes: {G.num_nodes}')
        print(f'Number of edges: {G.num_edges}')
        print(f'Average node degree: {G.num_edges / G.num_nodes:.2f}')
        print(f'Has isolated nodes: {G.has_isolated_nodes()}')
        print(f'Has self-loops: {G.has_self_loops()}')
        print(f'Is undirected: {G.is_undirected()}\n')

    return G
<br>好的，让我们通过一个具体的例子来解释这一系列操作是如何工作的。<br><br>假设我们有一个数据集，其中包含多个音频片段，每个音频片段可以拥有多个标签。例如，音频片段可以是环境声音，标签可以是“鸟叫声”、“汽车声”、“风声”等。<br><br>假设 gts 是一个 NumPy 数组，其中每一行表示一个音频片段，每一列表示一个标签的存在情况。例如：<br>gts = np.array([
    [1, 0, 1, 0],  # 音频片段 1 有标签 0 和 2
    [0, 1, 0, 1],  # 音频片段 2 有标签 1 和 3
    [1, 1, 0, 0],  # 音频片段 3 有标签 0 和 1
    [0, 0, 1, 1]   # 音频片段 4 有标签 2 和 3
])
<br><br>C = gts.T @ gts
<br>计算标签共现矩阵 C，即 gts 的转置与自身相乘。这一步得到的是标签之间共现的次数矩阵。<br>print(C)
<br>输出结果为：<br>[[2 1 1 0]
 [1 2 0 1]
 [1 0 2 1]
 [0 1 1 2]]
<br>这意味着：<br>
<br>标签 0 和 0 共现 2 次（音频片段 1 和 3）。
<br>标签 0 和 1 共现 1 次（音频片段 3）。
<br>标签 0 和 2 共现 1 次（音频片段 1）。
<br>标签 0 和 3 共现 0 次。
<br>标签 1 和 1 共现 2 次（音频片段 2 和 3）。
<br>标签 1 和 2 共现 0 次。
<br>标签 1 和 3 共现 1 次（音频片段 2）。
<br>... （以此类推）
<br><br>C = C / np.diag(C)
<br>将标签共现矩阵 C 归一化，除以其对角线元素（即每个标签的出现次数），得到标签共现概率矩阵。<br>print(C)
<br>输出结果为：<br>[[1.         0.5        0.5        0.        ]
 [0.5        1.         0.         0.5       ]
 [0.5        0.         1.         0.5       ]
 [0.         0.5        0.5        1.        ]]
<br>这意味着：<br>
<br>标签 0 和 0 的共现概率为 1（即标签 0 出现的情况下，标签 0 也出现的概率）。
<br>标签 0 和 1 的共现概率为 0.5。
<br>标签 0 和 2 的共现概率为 0.5。
<br>标签 0 和 3 的共现概率为 0。
<br>... （以此类推）
<br><br>np.fill_diagonal(C, 0)
<br>将标签共现概率矩阵 C 的对角线元素设置为 0，去除自环。<br>print(C)
<br>输出结果为：<br>[[0.         0.5        0.5        0.        ]
 [0.5        0.         0.         0.5       ]
 [0.5        0.         0.         0.5       ]
 [0.         0.5        0.5        0.        ]]
<br>这意味着：<br>
<br>标签 0 和 0 的共现概率现在为 0（去除自环）。
<br>标签 1 和 1 的共现概率现在为 0。
<br>标签 2 和 2 的共现概率现在为 0。
<br>标签 3 和 3 的共现概率现在为 0。
<br>... （以此类推）
<br><br>adj = SparseTensor.from_dense(torch.from_numpy(C).float())
row, col, edge_attr = adj.t().coo()
edge_index = torch.stack([row, col], dim=0)
<br>将归一化的标签共现概率矩阵转换为稀疏张量，并从中提取行索引、列索引和边属性。然后将行索引和列索引组合成 edge_index。<br>print(edge_index)
<br>输出结果为：<br>tensor([[0, 1, 0, 1, 1, 2, 2, 0, 2, 3, 3, 1],
        [1, 0, 2, 2, 3, 0, 3, 1, 1, 0, 2, 3]])
<br>这意味着：<br>
<br>第一行表示源节点索引。
<br>第二行表示目标节点索引。
<br>每一列表示一个边的连接（从 row 到 col）。
<br><br>G = Data(x=x0, edge_index=edge_index, edge_attr=edge_attr, batch=torch.ones(200))
<br>创建一个 PyTorch Geometric 的 Data 对象 G，包含以下信息：<br>
<br>x：节点特征。
<br>edge_index：边的索引。
<br>edge_attr：边的属性。
<br>batch：一个全为 1 的张量，用于指示所有节点属于同一个图。
<br><br>通过这个例子，我们可以看到如何从标签共现矩阵构建一个图结构。这个图结构可以用于图神经网络（GNN）中的进一步处理，如训练和预测。标签共现矩阵反映了不同标签之间的共现关系，并通过归一化和去除自环得到标签共现概率矩阵，进而构建稀疏图结构。]]></description><link>technology\科研\rtfsc-multilabel\多标签转化为graph.html</link><guid isPermaLink="false">Technology/科研/RTFSC-Multilabel/多标签转化为Graph.md</guid><pubDate>Mon, 16 Sep 2024 07:01:26 GMT</pubDate></item><item><title><![CDATA[基于knn的图转化]]></title><description><![CDATA[ 
 <br>import numpy as np
import torch
from torch_geometric.data import Data
from sklearn.neighbors import kneighbors_graph

def create_knn_graph(embedding_file, k, verbose=False):
    # Load ground truth labels
    gts = np.load('data\\file_gts.npy')
    
    # Load the initial node embeddings
    print(f'load initial node embedding from {embedding_file}... ', end='')
    if embedding_file[-3:] == 'npy':
        x0 = np.load(embedding_file)
        x0 = torch.from_numpy(x0).float()
    elif embedding_file[-3:] == 'pth':
        x0 = torch.load(embedding_file)
    else:
        raise ValueError('Initial embedding not defined')
    print('done')

    print('building graph using KNN... ', end='')
    
    # Compute the KNN graph using scikit-learn's function
    A = kneighbors_graph(x0.numpy(), n_neighbors=k, mode='connectivity', include_self=False)
    A = A + A.T  # Make the graph symmetric
    
    # Convert the adjacency matrix to COO format and extract indices and values
    row, col = A.nonzero()
    edge_index = torch.tensor([row, col], dtype=torch.long)
    
    # Since we're only interested in connectivity, edge_attr can be None or set to a constant value
    edge_attr = None
    
    # Create the PyTorch Geometric data object
    G = Data(x=x0, edge_index=edge_index, edge_attr=edge_attr, batch=torch.ones(x0.size(0), dtype=torch.long))
    
    print('done\n')
    
    if verbose:
        print('Graph statistics:')
        print(G)
        print(f'Number of nodes: {G.num_nodes}')
        print(f'Number of edges: {G.num_edges}')
        print(f'Average node degree: {G.num_edges / G.num_nodes:.2f}')
        print(f'Has isolated nodes: {G.has_isolated_nodes()}')
        print(f'Has self-loops: {G.has_self_loops()}')
        print(f'Is undirected: {G.is_undirected()}\n')
    
    return G

# Example usage:
# G = create_knn_graph('path_to_embedding_file', k=5, verbose=True)
]]></description><link>technology\科研\rtfsc-multilabel\基于knn的图转化.html</link><guid isPermaLink="false">Technology/科研/RTFSC-Multilabel/基于knn的图转化.md</guid><pubDate>Mon, 16 Sep 2024 07:35:20 GMT</pubDate></item><item><title><![CDATA[data.py]]></title><description><![CDATA[ 
 <br><br> 参数配置
parameters = {
    'meta_root': '/path/to/meta/root',  # 元数据根目录
    'labels_map': 'labels_map.json',  # 标签映射文件
    'train_manifest': 'train_manifest.csv',  # 训练集元数据文件
    'val_manifest': 'val_manifest.csv',  # 验证集元数据文件
    'merge_train_val': True,  # 是否合并训练集和验证集
    'sample_rate': 16000,  # 采样率
    'n_fft': 1024,  # FFT 窗口大小
    'win_len': 1024,  # 窗口长度
    'hop_len': 512,  # Hop 长度
    'n_mels': 128,  # Mel bins 数量
    'mixup': True,  # 是否启用 Mixup
    'spec_augm': True  # 是否启用频谱图掩码
}

# 创建训练数据集实例
train_ds = FSD50K_train_dataset(parameters)

# 创建 DataLoader
train_dl = DataLoader(train_ds,
                      num_workers=4,
                      shuffle=True,
                      batch_size=32,
                      pin_memory=True,
                      drop_last=True)

<br><br>import os
import torch
import json
import pandas as pd
from torch.utils.data import Dataset
from torch.distributions.beta import Beta
from audio_parser import MELspParser
import soundfile as sf
import numpy as np

class FSD50K_train_dataset(Dataset):
    """
    训练集数据集类，用于处理FSD50K数据集中的chunk级别的音频文件。
    """

    def __init__(self, par):
        super(FSD50K_train_dataset, self).__init__()

        # 加载标签映射
        self.labels_map_path = os.path.join(par['meta_root'], par['labels_map'])
        with open(self.labels_map_path, 'r') as fd:
            self.labels_map = json.load(fd)

        # 如果配置合并训练集和验证集，则读取并合并
        if par['merge_train_val']:
            df_train = pd.read_csv(os.path.join(par['meta_root'], par['train_manifest']))
            df_val = pd.read_csv(os.path.join(par['meta_root'], par['val_manifest']))
            df = pd.merge(df_train, df_val, how='outer')
        else:
            df = pd.read_csv(os.path.join(par['meta_root'], par['train_manifest']))

        # 提取文件名和标签
        self.files = df['files'].values
        self.labels = df['labels'].values
        assert len(self.files) == len(self.labels), "文件数量与标签数量必须相同"
        self.len = len(self.files)

        # 设置音频处理参数
        self.sr = par['sample_rate']
        self.n_fft = par['n_fft']
        self.win_len = par['win_len']
        self.hop_len = par['hop_len']
        self.n_mels = par['n_mels']

        # 设置数据增强标志位
        self.mixup = par['mixup']  # 是否执行Mixup
        self.spec_augm = par['spec_augm']  # 是否执行频谱图时频掩码
        self.beta = Beta(torch.tensor([0.2]), torch.tensor([0.2]))  # 用于Mixup参数的Beta分布

        # 初始化Mel-spectrogram解析器
        self.spec_parser = MELspParser(sr=self.sr,
                                       n_fft=self.n_fft,
                                       win_length=self.win_len,
                                       hop_length=self.hop_len,
                                       n_mels=self.n_mels)

    def __getitem__(self, index):
        # 如果启用Mixup并且索引超出原数据集长度，则执行Mixup
        if self.mixup and index &gt; self.len - 1:
            chunk_melsp, label_tensor = self.__mixup__(index - self.len)
        # 如果启用频谱图掩码并且索引超出原数据集长度，则执行频谱图掩码
        elif self.spec_augm and index &gt; self.len - 1:
            chunk_melsp, label_tensor = self.__spec_augment__(index - self.len)
        else:
            # 读取音频文件并转换为Mel-spectrogram
            f = self.files[index]
            folder_name = os.path.basename(os.path.dirname(f))
            lbl = folder_name  # 文件夹名作为标签
            label_tensor = self.__parse_labels__(lbl)
            chunk_audio = sf.read(f)[0].astype('float32')
            chunk_melsp = torch.from_numpy(self.spec_parser(chunk_audio))

        return chunk_melsp, label_tensor

    def __parse_labels__(self, lbl: str) -&gt; torch.Tensor:
        # 从字符串标签转换为单个标签索引
        label_index = self.labels_map[lbl]
        return torch.tensor(label_index, dtype=torch.long)

    def __mixup__(self, index):
        # 选择一个新的索引
        new_index = torch.randint(0, self.len - 1, (1,))

        # 提取第一个音频片段
        f_1 = self.files[index]
        lbls_1 = os.path.basename(os.path.dirname(f_1))
        label_tensor_1 = self.__parse_labels__(lbls_1)
        chunk_audio_1 = sf.read(f_1)[0].astype('float32')
        chunk_melsp_1 = torch.from_numpy(self.spec_parser(chunk_audio_1))

        # 提取第二个音频片段
        f_2 = self.files[new_index]
        lbls_2 = os.path.basename(os.path.dirname(f_2))
        label_tensor_2 = self.__parse_labels__(lbls_2)
        chunk_audio_2 = sf.read(f_2)[0].astype('float32')
        chunk_melsp_2 = torch.from_numpy(self.spec_parser(chunk_audio_2))

        # 根据Mixup比例混合频谱图和标签
        lam = self.beta.sample()
        chunk_mixup = torch.mul(chunk_melsp_1, lam) + torch.mul(chunk_melsp_2, (1 - lam))
        label_mixup = torch.mul(label_tensor_1, lam) + torch.mul(label_tensor_2, (1 - lam))

        return chunk_mixup, label_mixup

    def __spec_augment__(self, index):
        # 频谱图掩码参数
        num_mask = 2
        freq_masking_max_percentage = 0.15
        time_masking_max_percentage = 0.3

        # 提取音频片段并转换为Mel-spectrogram
        f = self.files[index]
        folder_name = os.path.basename(os.path.dirname(f))
        lbl = folder_name  # 文件夹名作为标签
        label_tensor = self.__parse_labels__(lbl)
        chunk_audio = sf.read(f)[0].astype('float32')
        chunk_melsp = torch.from_numpy(self.spec_parser(chunk_audio))

        # 对频谱图进行随机掩码
        for i in range(num_mask):
            all_frames_num, all_freqs_num = chunk_melsp.shape
            freq_percentage = np.random.uniform(0.0, freq_masking_max_percentage)
            num_freqs_to_mask = int(freq_percentage * all_freqs_num)
            f0 = np.random.uniform(low=0.0, high=all_freqs_num - num_freqs_to_mask)
            f0 = int(f0)
            chunk_melsp[:, f0:f0 + num_freqs_to_mask] = 0

            time_percentage = np.random.uniform(0.0, time_masking_max_percentage)
            num_frames_to_mask = int(time_percentage * all_frames_num)
            t0 = np.random.uniform(low=0.0, high=all_frames_num - num_frames_to_mask)
            t0 = int(t0)
            chunk_melsp[t0:t0 + num_frames_to_mask, :] = 0

        return chunk_melsp, label_tensor

    def __len__(self):
        # 如果启用了Mixup或频谱图掩码，则数据集长度翻倍
        if self.mixup or self.spec_augm:
            return 2 * self.len
        else:
            return self.len

class FSD50K_test_dataset(Dataset):
    """
    测试集数据集类，用于处理FSD50K数据集中的clip级别的音频文件。
    """

    def __init__(self, par):
        super(FSD50K_test_dataset, self).__init__()

        # 加载标签映射
        self.labels_map_path = os.path.join(par['meta_root'], par['labels_map'])
        with open(self.labels_map_path, 'r') as fd:
            self.labels_map = json.load(fd)

        # 读取测试集元数据
        df = pd.read_csv(os.path.join(par['meta_root'], par['test_manifest']))
        self.files = df['files'].values
        self.labels = df['labels'].values
        self.exts = df['ext'].values
        self.unique_exts = np.unique(self.exts)
        assert len(self.files) == len(self.labels) == len(self.exts), "文件、标签和扩展名数量必须相同"
        self.len = len(self.unique_exts)  # 按clip级别工作！
        print(f'测试集长度：{self.len} 个文件')

        # 设置音频处理参数
        self.sr = par['sample_rate']
        self.n_fft = par['n_fft']
        self.win_len = par['win_len']
        self.hop_len = par['hop_len']
        self.n_mels = par['n_mels']

        # 初始化Mel-spectrogram解析器
        self.spec_parser = MELspParser(sr=self.sr,
                                       n_fft=self.n_fft,
                                       win_length=self.win_len,
                                       hop_length=self.hop_len,
                                       n_mels=self.n_mels)

    def __getitem__(self, index):
        # 获取目标扩展名对应的索引
        tgt_ext = self.unique_exts[index]
        idxs = np.where(self.exts == tgt_ext)[0]
        tensors = []
        label_tensors = []

        # 处理每个chunk级别的音频
        for idx in idxs:
            f = self.files[idx]
            lbls = self.labels[idx]
            label_tensor = self.__parse_labels__(lbls)
            chunk_audio, _ = sf.read(f)  # 读取音频文件
            chunk_audio = chunk_audio.astype('float32')
            chunk_melsp = torch.from_numpy(self.spec_parser(chunk_audio))
            tensors.append(chunk_melsp.unsqueeze(0).unsqueeze(0))
            label_tensors.append(label_tensor.unsqueeze(0))

        # 合并所有chunk级别的音频
        tensors = torch.cat(tensors)
        return tensors, label_tensors[0]

    def __parse_labels__(self, lbl: str) -&gt; torch.Tensor:
        # 从字符串标签转换为单个标签索引
        label_index = self.labels_map[lbl]
        return torch.tensor(label_index, dtype=torch.long)

    def __len__(self):
        return self.len
]]></description><link>technology\科研\rtfsc-multilabel\data.py.html</link><guid isPermaLink="false">Technology/科研/RTFSC-Multilabel/data.py.md</guid><pubDate>Mon, 16 Sep 2024 08:48:32 GMT</pubDate></item><item><title><![CDATA[helpers.py]]></title><description><![CDATA[ 
 <br><br>import time
import os
import numpy as np
import torch
import torch.nn as nn
from data.data import FSD50K_train_dataset, FSD50K_test_dataset
from torch.utils.data import DataLoader
from tqdm import tqdm
import pandas as pd
from eval_metrics import calculate_stats, calculate_overall_lwlrap

def train_(device, model, optimizer, criterion, train_dataloader, graph):
    """训练流程"""
    model.train()  # 设置模型为训练模式
    total_train_loss = 0
    if graph is not None:
        graph = graph.to(device)
    for x_data, y_data in tqdm(train_dataloader):  # 迭代训练数据集
        x_data = x_data.to(device)
        y_data = y_data.to(device)
        x_data = x_data.unsqueeze(1)  # 添加通道维度
        optimizer.zero_grad()  # 清零梯度
        train_outputs = model(x_data, graph)  # 前向传播
        train_loss = criterion(train_outputs, y_data)  # 计算损失
        train_loss.backward()  # 反向传播
        optimizer.step()  # 更新权重
        total_train_loss += train_loss.item()  # 累加损失
    total_train_loss /= len(train_dataloader)  # 计算平均损失

    return total_train_loss

def get_train_data(par):
    """获取训练数据加载器"""
    train_ds = FSD50K_train_dataset(par)  # 创建训练数据集实例
    train_dl = DataLoader(train_ds,
                          num_workers=par['num_workers'],
                          shuffle=True,
                          batch_size=par['batch_size'],
                          pin_memory=True,
                          drop_last=True)
    return train_dl

def get_test_data(par):
    """获取测试数据集实例"""
    test_ds = FSD50K_test_dataset(par)  # 创建测试数据集实例
    test_dl = DataLoader(test_ds,
                         num_workers=par['num_workers'],
                         shuffle=False,
                         batch_size=par['batch_size'],
                         pin_memory=True)
    return test_dl

def start_train(model, train_dataloader, graph, par):
    """开始训练"""
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 选择设备

    train_loss_list = []  # 存储训练损失列表
    ckptfile = os.path.join(par['logs_path'], 'model.pth')  # 模型保存路径
    e_tot = par['epochs']  # 总共训练轮数
    best_loss = 1e10  # 最佳损失初始值

    if par['pre_train_path'] != '':  # 如果指定了预训练模型路径
        model.load_state_dict(torch.load(par['pre_train_path']))  # 加载预训练模型
        print('Pretrained model loaded')  # 输出提示信息

    model = model.to(device)  # 将模型移动到指定设备上

    # 选择是否使用加权的BCE损失函数
    if par['class_weights'] is not None:
        print('Use weighted BCEWithLogitsLoss')
        cw = torch.from_numpy(np.load(par['class_weights'])).to(device)
        criterion = nn.BCEWithLogitsLoss(pos_weight=cw)
    else:
        print('Use unweighted BCEWithLogitsLoss')
        criterion = nn.BCEWithLogitsLoss()

    optimizer = torch.optim.Adam(model.parameters(), lr=par['learning_rate'], weight_decay=5e-4)  # 创建优化器

    print(f'Start training with {device}...')  # 输出训练开始信息

    for e in range(e_tot):  # 进行多轮训练
        t1 = time.time()  # 开始计时

        epoch_train_loss = train_(device, model, optimizer, criterion, train_dataloader, graph)  # 训练一轮
        if par['verbose']:  # 如果设置了打印详细信息
            print('Epoch [{}/{}] - Train Loss:{:.4f} - Elapsed time: {:.4f} s'.format(e + 1, e_tot, epoch_train_loss, time.time() - t1))  # 输出训练信息

        # 更新学习率
        # lr_scheduler.step()

        # 记录训练损失和准确率
        train_loss_list.append(epoch_train_loss)

        # 如果损失减少则保存模型
        if epoch_train_loss &lt; best_loss:
            torch.save(model.state_dict(), ckptfile)
            print(f'model checkpoint saved, previous loss: {best_loss}, current loss: {epoch_train_loss}')
            best_loss = epoch_train_loss

        # 保存性能值到csv文件
        perf_dict = {'TRAIN_LOSS': train_loss_list}
        df = pd.DataFrame(perf_dict)
        df.to_csv(os.path.join(par['logs_path'], 'loss.csv'))

    print('-' * 20)
    print('done')

def start_test(model, test_dataloader, graph, par):
    """
    进行测试
    """
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')  # 选择设备
    # 加载预训练模型
    model.load_state_dict(torch.load(os.path.join(par['logs_path'], 'model.pth')))
    model = model.to(device).eval()
    print('Pretrained model loaded')  # 输出加载成功信息
    if graph is not None:
        graph = graph.to(device)
    print(f'Start test with {device}...')  # 输出测试开始信息

    test_predictions = []  # 测试预测结果列表
    test_gts = []  # 测试地面真值列表

    # 迭代测试数据集
    for x_data, y_data in tqdm(test_dataloader):
        with torch.no_grad():  # 不计算梯度
            x_data = x_data.to(device)
            y_pred = model(x_data, graph)  # 前向传播
            y_pred = y_pred.mean(0).unsqueeze(0)  # 平均预测结果
        test_predictions.append(y_pred.detach().cpu().numpy()[0])  # 保存预测结果
        test_gts.append(y_data.detach().cpu().numpy()[0])  # 保存真实标签

    test_predictions = np.asarray(test_predictions).astype('float32')  # 转换为NumPy数组
    test_gts = np.asarray(test_gts).astype('int32')  # 转换为NumPy数组

    # 计算评价指标
    APs, AUCs, d_prime = calculate_stats(test_gts, test_predictions)
    lwl_rap = calculate_overall_lwlrap(test_gts, test_predictions)
    np.save(os.path.join(par['logs_path'], 'APs.npy'), APs)
    np.save(os.path.join(par['logs_path'], 'AUCs.npy'), AUCs)
    m_APs = np.mean(APs)
    m_AUCs = np.mean(AUCs)
    print(f'mAP: {m_APs:.6f}')
    print(f'mAUC: {m_AUCs:.6f}')
    print(f'dprime: {d_prime:.6f}')
    print(f'lwl_rap: {lwl_rap:.6f}')

    # 保存指标值到csv文件
    test_dict = {'mAP': m_APs,
                 'mAUC': m_AUCs,
                 'dPrime': d_prime,
                 'lwl_rap': lwl_rap
                 }
    df = pd.DataFrame(data=list(test_dict.values()), index=list(test_dict.keys()), columns=None)
    df.to_csv(os.path.join(par['logs_path'], 'test_result.csv'))
]]></description><link>technology\科研\rtfsc-multilabel\helpers.py.html</link><guid isPermaLink="false">Technology/科研/RTFSC-Multilabel/helpers.py.md</guid><pubDate>Mon, 16 Sep 2024 08:54:23 GMT</pubDate></item><item><title><![CDATA[论文]]></title><description><![CDATA[ 
 <br><br><br>第一次写论文要先将思路理清楚，我的主题是Lightweight Spectral GCN for bird sound classification on Edge devices，本质上是个building on任务，也就是使用其他任务中优秀的方式来解决特定场景的问题。<br>主要结构：<br>
大问题---&gt;小问题<br>
大目标---&gt;小目标<br>比如引入是大问题，边缘设备上的AI部署面临的问题，算力及存储限制，导向具体鸟类音频识别任务的特殊性，边缘设备对于鸟类音频识别的重要性。即解决这个小问题。<br>
如何解决，前人解决这个问题时使用的方法，但不适配边缘设备，目标是找一个新的方法，在准确率不损失或者损失较小的情况下，实现参数量计算量，推理速度等方面的提升。<br><br>Graph-based Representation of Audio signals for Sound Event Classification<br> Concurrent with the progress of AI, the deployment of machine learning<br>
solutions on mobile (edge) devices for consumer applications is gaining more<br>
and more attention [12–14]. Thus, ML systems with stable performance and<br>
great accuracy in real-world situations are required for all of these applications.<br>
However, the limited storage and computation resources provided by these<br>
platforms are an obstacle that is being addressed by many researchers working<br>
to reduce their complexity [15–17]. In this thesis, our proposed graph-based<br>
model is a compact, efficient and scalable way to represent data results in a<br>
lightweight graph-based network with a much fewer number of parameters<br>
enabling them to perform swiftly on edge devices without losing performance.<br>
随着人工智能的进步，在移动(边缘)设备上部署面向消费者应用的机器学习解决方案正越来越受到关注[12-14]。因此，这些应用需要在实际环境中具有稳定性能和高精度的ML系统。然而，这些平台提供的有限的存储和计算资源是许多研究人员正在努力解决的问题[15-17]。在这篇论文中，我们提出的图基模型是一种紧凑、高效且可扩展的方式，可以在轻量级图基网络中以更少的参数表示数据结果，从而使它们能够在边缘设备上快速运行而不会损失性能。<br>Feature extraction for Acoustic Bird Species Classification (ABSC) tasks has traditionally been based on parametric representations that were specifically developed for speech signals, such as Mel Frequency Cepstral Coefficients (MFCC). However, the discrimination capabilities of these features for ABSC could be enhanced by accounting for the vocal production mechanisms of birds, and, in particular, the spectro-temporal structure of bird sounds. In this paper, a new front-end for ABSC is proposed that incorporates this specific information through the non-negative decomposition of bird sound spectrograms. It consists of the following two different stages: short-time feature extraction and temporal feature integration. In the first stage, which aims at providing a better spectral representation of bird sounds on a frame-by-frame basis, two methods are evaluated. In the first method, cepstral-like features (NMF_CC) are extracted by using a filter bank that is automatically learned by means of the application of Non-Negative Matrix Factorization (NMF) on bird audio spectrograms. In the second method, the features are directly derived from the activation coefficients of the spectrogram decomposition as performed through NMF (H_CC). The second stage summarizes the most relevant information contained in the short-time features by computing several statistical measures over long segments. The experiments show that the use of NMF_CC and H_CC in conjunction with temporal integration significantly improves the performance of a Support Vector Machine (SVM)-based ABSC system with respect to conventional MFCC.<br>
声学鸟类分类 （ABSC） 任务的特征提取传统上基于专为语音信号开发的参数表示，例如 Mel 频率倒谱系数 （MFCC）。然而，通过考虑鸟类的声音产生机制，特别是鸟类声音的频谱时间结构，可以增强 ABSC 的这些特征的区分能力。在本文中，提出了一种新的 ABSC 前端，它通过鸟类声音频谱图的非负分解来整合这些特定信息。它由以下两个不同的阶段组成：短时特征提取和时间特征集成。在第一阶段，旨在逐帧提供更好的鸟叫声频谱表示，评估了两种方法。在第一种方法中，通过使用滤波器组提取倒谱样特征 （NMF_CC） ，该滤波器组是通过在鸟类音频频谱图上应用非负矩阵分解 （NMF） 自动学习的。在第二种方法中，特征直接来自通过 NMF （H_CC） 执行的频谱图分解的激活系数。第二阶段通过计算长段上的几个统计度量来总结短时特征中包含的最相关信息。实验表明，与传统 MFCC 相比，NMF_CC 和 H_CC 与时间积分结合使用可显著提高基于支持向量机 （SVM） 的 ABSC 系统的性能<br>
<a rel="noopener nofollow" class="external-link" href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0179403" target="_blank">https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0179403</a><br>Birds are widely regarded as an excellent indicator of biodiversity for their important ecosystem services (Acevedo et al., 2009). However, the decrease in bird population has been noticed worldwide. To optimize the protection policy and increase the bird population, it is becoming ever more important to monitor birds (Bao and Cui, 2005). Traditional methods for surveying birds that require ecologists to conduct a bird census are both time-consuming and costly (Bardeli et al., 2010; Brandes, 2008).<br>
鸟类因其重要的生态系统服务而被广泛认为是生物多样性的极好指标（Acevedo et al.， 2009）。然而，全世界都注意到鸟类数量的减少。为了优化保护政策并增加鸟类数量，监测鸟类变得越来越重要（Bao 和 Cui，2005 年）。需要生态学家进行鸟类普查的传统鸟类调查方法既耗时又昂贵（Bardeli 等人，2010 年;Brandes，2008 年）。<br>
Acoustics have been widely used to monitor animals' presence and activity, because most animals, such as insects, anurans, birds, and certain mammals are often heard rather than seen (Briggs et al., 2012; Brown, 1991). To fully utilize acoustic cues of animal calls, collecting animal sounds is in high demand. Recent advances in acoustic sensor techniques provide a novel way to record animal vocalizations over larger temporal and spatial scales (Costa et al., 2012; Farina and Gage, 2017). Since several gigabytes of compressed data can be generated by an acoustic sensor per day, enabling automating animal species identification in acoustic datasets has become increasingly important (Brandes, 2008).<br>
声学已被广泛用于监测动物的存在和活动，因为大多数动物，如昆虫、无尾动物、鸟类和某些哺乳动物，通常是听到而不是看到的（Briggs 等人，2012 年;Brown， 1991）。为了充分利用动物叫声的声学线索，收集动物的声音需求量很大。声学传感器技术的最新进展提供了一种在更大的时间和空间尺度上记录动物发声的新方法（Costa等人，2012 年;Farina 和 Gage，2017 年）。由于声学传感器每天可以生成数 GB 的压缩数据，因此在声学数据集中实现动物物种识别的自动化变得越来越重要（Brandes，2008 年）。<br>
<a rel="noopener nofollow" class="external-link" href="https://www.sciencedirect.com/science/article/pii/S1574954118302991" target="_blank">https://www.sciencedirect.com/science/article/pii/S1574954118302991</a><br> In this thesis, our proposed graph-based<br>
model is a compact, efficient and scalable way to represent data results in a<br>
lightweight graph-based network with a much fewer number of parameters<br>
enabling them to perform swiftly on edge devices without losing performance<br>
引用：在本文中，我们提出的基于图的模型是一种紧凑、高效和可扩展的方式，用于在轻量级的基于图的网络中表示数据结果，其参数数量少得多，使它们能够在边缘设备上快速执行而不会损失性能<br>Research on audio or speech processing has traditionally considered the task of<br>
designing hand-engineered acoustic features as a separate distinct problem from<br>
the task of designing efficient machine learning (ML) models to make prediction<br>
and classification decisions.<br>
传统上，音频或语音处理的研究将设计手工设计的声学特征的任务与设计高效的机器学习（ML）模型以进行预测和分类决策的任务视为一个独立的问题。<br><br><br>Concurrent with the progress of AI, the deployment of machine learning solutions on mobile (edge) devices for consumer applications is gaining more and more attention [12–14].提出一个problem， Acoustic Bird Species Classification (ABSC)。现在的研究现状，如研究者A提出基于Mel频谱图加CNN的方式,研究者B提出一种基于预训练模型的方式。但野外场景导致了户外鸟类音频分类更多使用移动设备mobile (edge) devices。一方面，CNN或者pre-trained model的参数量过大,需要的计算资源过多，测试和推理时间过长。另一方面，CNN忽略了对于音频时序信息的提取 While many works have been ignored, audio is a temporal data type whose temporality must be taken into account both during preprocessing and while creating the architecture for processing. 引用Graph Neural Network for Audio Representation Learning。而图神经网络在近些年在文本和图像上的应用增加，而缺少在音频上的应用，而图神经网络可以方便地表示实体间的关系。<br>With the rapid advancement of AI, the deployment of machine learning solutions on mobile (edge) devices for consumer applications is gaining increasing attention \cite{howard2019searching}. However, in practical scenarios, particularly in the field of Acoustic Bird Species Classification (ABSC), existing technologies still face significant challenges. <br>Traditional bird audio classification tasks primarily involve two aspects: one is the design of more effective acoustic features, and the other is the development of efficient deep learning models for prediction and classification. For acoustic feature extraction, hand-engineered features such as Mel spectrograms and MFCCs have been commonly used. However, with the advancement of deep learning, more sophisticated representation learning methods, such as self-supervised learning, have emerged for feature extraction. Additionally, pre-trained models like HuBERT and Wav2Vec 2.0 have been leveraged for feature extraction in speech and audio processing tasks \cite{niu2023speech}.<br>Regarding deep learning models, CNN-based approaches have been widely used in audio classification \cite{xie2019investigation}, along with Recurrent Neural Networks (RNNs), particularly Long Short-Term Memory (LSTM) networks, which are employed for sequential data such as avian vocalizations \cite{LSTM-based Vocalization Analysis for Identification and Classification of Avian Acoustics}.<br>While these methods have shown promising results in controlled environments, they still face bottlenecks in outdoor settings, especially when deployed on mobile devices. Firstly, CNNs and pre-trained models typically require large parameter sets, which demand substantial computational resources, leading to slow inference speeds that cannot meet the real-time processing needs of mobile devices \cite{aironi2021graph}. Secondly, most of the existing methods overlook the temporal nature of audio data. Since audio is inherently temporal, the sequential relationships within the data are crucial for classification tasks. This brings about the need for more effective approaches to capture the temporal dependencies within audio signals. <br>Recently, Graph Neural Networks (GNNs) have gained significant traction in text and image processing tasks, yet their application in audio remains relatively underexplored \cite{castro2024graph}. GNNs offer distinct advantages by representing relationships between entities in a flexible graph structure, making them well-suited for modeling the temporal dynamics of audio data. And leveraging theories from graph signal processing, \cite{shirian2022graph} proposed a GCN-based graph classification approach that can efficiently perform accurate graph convolution. Therefore, exploring the use of lightweight GNNs in acoustic bird species classification may provide a more efficient and accurate solution for this task.<br>在GNN做分类任务当中，主要包括 node classification, graph classification<br><br>With the rapid advancement of AI, the deployment of machine learning solutions on mobile (edge) devices for consumer applications is gaining increasing attention \cite{howard2019searching}. However, in practical scenarios, particularly in the field of Acoustic Bird Species Classification (ABSC), existing technologies still face significant challenges. <br>Traditional bird audio classification tasks primarily involve two aspects: one is the design of more effective acoustic features, and the other is the development of efficient deep learning models for prediction and classification. For acoustic feature extraction, hand-engineered features such as Mel spectrograms and MFCCs have been commonly used. However, with the advancement of deep learning, more sophisticated representation learning methods, such as self-supervised learning, have emerged for feature extraction. Additionally, transfer learning based on pre-trained models has been applied to speech and audio processing tasks, such as feature extraction using HuBERT and Wav2Vec 2.0 \cite{niu2023speech}.Regarding deep learning models, CNN-based approaches have been widely used in audio classification \cite{xie2019investigation}, with the primary application being the use of CNNs to process spectrograms derived from audio files.Advanced CNN architectures, such as ResNet and EfficientNet, have further enhanced the performance of such models in classifying bird species from their vocalizations.<br>While these methods have shown promising results in controlled environments, they still face bottlenecks in outdoor settings, especially when deployed on mobile devices. Firstly, CNNs and pre-trained models typically require large parameter sets, which demand substantial computational resources, leading to slow inference speeds that cannot meet the real-time processing needs of mobile devices \cite{aironi2021graph}. Secondly, most of the existing methods overlook the temporal and structural nature of audio data. Audio signals, like textual data, are inherently temporal and often exhibit non-Euclidean properties due to their variability in length and structure. Traditional deep learning models for capturing temporal information, such as RNNs and LSTMs, face challenges due to their computational complexity and long training times, making them less suitable for resource-constrained environments. Moreover, while CNNs excel in processing Euclidean data by leveraging translation invariance, they struggle with non-Euclidean data like audio, as defining convolutional kernels becomes challenging due to the unfixed number and arrangement order of neighboring nodes \cite{liu2023survey}. This highlights the need for more advanced methods capable of efficiently capturing the temporal and structural dependencies of audio data.<br>Recently, Graph Neural Networks (GNNs) have gained significant traction in text and image processing tasks, yet their application in audio remains relatively underexplored \cite{castro2024graph}. GNNs offer distinct advantages by representing relationships between entities in a flexible graph structure, making them well-suited for modeling the temporal dynamics of audio data. <br>Graph classification models can be broadly categorized into two types: spectral-based and spatial-based approaches. Spectral-based methods, such as Spectral GCN, leverage graph signal processing techniques and operate in the spectral domain. They perform convolution operations using the graph Laplacian eigenbasis, making them highly effective for graph data representation \cite{bruna2013spectral}. In contrast,spatial-based methods, such as GraphSAGE \cite{hamilton2017inductive} and GAT \cite{velivckovic2017graph}, perform convolutions directly on graph structures by aggregating information from neighboring nodes. These methods excel at handling dynamic graphs but often require higher computational costs.<br>While spatial-based models are flexible and effective, they tend to demand substantial computational resources, making them less suitable for resource-constrained environments like edge devices. Spectral-based methods, such as Spectral GCN, provide a computationally efficient alternative by transforming graph data into the spectral domain and leveraging matrix operations for feature extraction \cite{kipf2016semi}.<br>Leveraging theories from graph signal processing, \cite{shirian2022graph} proposed a Spectral GCN-based graph classification approach that can efficiently perform accurate graph convolution, demonstrating the feasibility of applying GNNs to audio classification tasks. Building on this foundation, we propose a lightweight bird audio classification model based on MFCC and Spectral GCN, which outperforms the traditional Mel spectrogram + CNN baseline on the Birdsdata dataset—a natural sound detection dataset jointly released by the Beijing Academy of Artificial Intelligence and Bird100. Our model achieves superior performance under low parameter and computational resource constraints, making it an efficient and practical solution for real-world applications.<br><br>With the rapid advancements in AI, deploying machine learning solutions on mobile (edge) devices for consumer applications has garnered significant attention \cite{howard2019searching}. However, existing technologies, particularly in Acoustic Bird Species Classification (ABSC), face notable challenges in practical scenarios.  <br>Traditional bird audio classification involves two key aspects: (1) the design of effective acoustic features, and (2) the development of efficient deep learning models for prediction and classification. Conventional approaches often rely on handcrafted features such as Mel spectrograms and MFCCs, which, while effective, may not fully capture the complexity of audio signals. Recently, the rise of deep learning has introduced more advanced feature extraction techniques, such as self-supervised learning and transfer learning based on pre-trained models like HuBERT and Wav2Vec 2.0, which have proven successful in speech and audio processing tasks \cite{niu2023speech}.  <br>For deep learning models, CNN-based approaches remain a popular choice for processing spectrograms derived from audio data \cite{xie2019investigation}. Modern CNN architectures, including ResNet and EfficientNet, have further improved performance in controlled settings. Despite these advancements, deploying such models in outdoor and resource-constrained environments remains challenging.  <br>Key limitations of existing methods include:  <br>
<br>Computational demands: CNNs and pre-trained models typically have large parameter sets, requiring substantial computational resources that impede real-time inference on mobile devices \cite{aironi2021graph}.  
<br>Overlooking temporal relationships in audio data: Audio signals are inherently temporal, meaning that sequential relationships within the data play a critical role in classification tasks. Existing methods, such as CNNs, struggle to model these dependencies effectively, limiting their ability to fully exploit the temporal dynamics of audio signals \cite{liu2023survey}.  
<br>Graph Neural Networks (GNNs) have recently gained prominence in text and image processing, offering a compelling alternative for audio classification tasks by representing audio as a graph structure. GNNs are particularly adept at modeling temporal and structural relationships in data \cite{castro2024graph}.  <br>Among GNN methods, graph classification models can be divided into two categories:  <br>
<br>Spectral-based approaches: These leverage graph signal processing in the spectral domain, using graph Laplacian eigenbasis for convolution operations \cite{bruna2013spectral}.  
<br>Spatial-based approaches: Methods like GraphSAGE \cite{hamilton2017inductive} and GAT \cite{velivckovic2017graph} perform direct convolution on graph structures by aggregating information from neighboring nodes.  
<br>While spatial-based approaches are versatile, they often require higher computational costs, making them less suitable for edge devices. In contrast, Spectral GCN offers computational efficiency and scalability by transforming graph data into the spectral domain, making it ideal for resource-constrained environments \cite{kipf2016semi}.  <br>Building on recent advances, such as the Spectral GCN-based graph classification method for audio proposed by \cite{shirian2022graph}, this study introduces a lightweight bird audio classification model. By leveraging MFCC features and Spectral GCN, our model surpasses the traditional Mel spectrogram + CNN baseline on the Birdsdata dataset—a natural sound detection dataset jointly released by the Beijing Academy of Artificial Intelligence and Bird100. The proposed model achieves superior performance under constrained computational resources, offering a practical and efficient solution for real-world bird audio classification applications.  <br><br><br>因为我们没有自己的模型，纯粹是搬过来的，我们应该尝试去做些修改。如果修改不了也没办法。那我们使用他的方法，纯粹讲一遍。<br><br>在这个模块我们将详细解释我们的方法，我们将每一个音频文件构造成一个图结构，然后通过Spectral GCN进行Embedding的学习，最后通过一个MLP做分类器，实现鸟类音频的分类。具体模型请参考图片。<br><br>首先我们先根据训练数据的频率分布范围(插入图片fig)确定fmin和fmax，鸟类音频的主要分布范围是0~8000hz,这与我们的测试相符合。然后我们使用20ms的window_size与10ms的步长进行分帧，对于总长度为两秒的音频，我们将得到248帧，我们从中抽出能量最强的200帧。然后提取每一帧的MFCC(该特征较Mel频谱图信息量更少)。<br><br><br>Spectral GCN 的核心基于谱图理论，图卷积在频域中的定义为：<br><br>其中：<br>
<br> 是输入特征矩阵， 是节点数， 是输入特征维度。
<br> 是图拉普拉斯矩阵  的特征向量矩阵。
<br> 是特征值构成的对角矩阵。
<br> 是可学习的滤波器，用于特征变换。
<br> 是非线性激活函数（如 ReLU）。
<br><br>上述公式中，特征值分解的计算复杂度为 ，对于大规模图数据（节点数  较大）不可行。因此，直接使用 Spectral GCN 面临实际应用的障碍。<br><br><br>Kipf 和 Welling 在 2017 年的论文中对 Spectral GCN 进行了重要简化，核心改进如下：<br><br>将频域滤波器  表示为切比雪夫多项式的展开：<br><br>并限制多项式的阶数为 ，即仅考虑一阶邻居的特征聚合。这将频域操作本地化为节点的一阶邻域。<br><br>通过归一化邻接矩阵  替代特征分解：<br><br>其中：<br>
<br> 是添加自环的邻接矩阵。
<br> 是对应的度矩阵。
<br>这一归一化操作显著简化了计算。<br><br>最终，Kipf 和 Welling 的 GCN 的核心公式为：<br><br>其中：<br>
<br> 是节点特征矩阵，包含  个节点，每个节点有  个输入特征。
<br> 是归一化的邻接矩阵。
<br> 是添加了自环的邻接矩阵。
<br> 是原始邻接矩阵。
<br> 是  维的单位矩阵，表示自环的引入。
<br> 是  的度矩阵，其对角元素为 。
<br> 是可学习的权重矩阵，用于将 -维输入特征映射到 -维输出特征。
<br> 是非线性激活函数，例如 ReLU（Rectified Linear Unit）。
<br><br><br><br><br><br>
<br>高效计算：避免显式特征值分解，复杂度降低到图的边数级别。
<br>易于实现：可用深度学习框架（如 PyTorch 或 TensorFlow）直接实现。
<br>实用性强：在实际任务中表现良好，成为许多图神经网络的基础模型。
<br>因此，Kipf 和 Welling 的 GCN 可以被视为 Spectral GCN 的一种高效变体，并在大规模图数据处理中得到了广泛应用。<br>但是该方法由于限制了每一层的消息传递只能由一阶邻居产生，从而导致如果需要节点获得全局信息需要较多层。<br>而原始的Spectral GCN虽然进行特征分解会产生大量计算量，但是如果图结构固定，则不需要进行重复计算，从而规避了过多的计算量又能使得节点在进行消息传递时获取全局信息。<br>因此我们使用{引用 COMPACTGRAPHARCHITECTUREFORSPEECHEMOTIONRECOGNITION}的思路，对音频信号构造环形图。将连续的每一帧首尾相连构造一个环形图，每一个节点的特征即为提取的MFCC。<br><br>\subsubsection{Efficient Computation of Eigenvalues and Eigenvectors}<br>
In this study, the graph under consideration is a cycle graph, which introduces a specific structure to the graph Laplacian. For a cycle graph with  nodes, the Laplacian matrix  has the following form:<br>
\begin{equation}<br>
\mathbf{L} =<br>
\begin{bmatrix}<br>
2 &amp; -1 &amp;  0 &amp; \cdots &amp;  0 &amp; -1 \<br>
-1 &amp;  2 &amp; -1 &amp; \cdots &amp;  0 &amp;  0 \<br>
0 &amp; -1 &amp;  2 &amp; \cdots &amp;  0 &amp;  0 \<br>
\vdots &amp; \vdots &amp; \vdots &amp; \ddots &amp; \vdots &amp; \vdots \<br>
0 &amp;  0 &amp;  0 &amp; \cdots &amp;  2 &amp; -1 \<br>
-1 &amp;  0 &amp;  0 &amp; \cdots &amp; -1 &amp;  2<br>
\end{bmatrix}<br>
\end{equation}<br>This structure is derived from the adjacency matrix of a cycle graph, where each node is connected to two neighbors, with wrap-around connections between the first and last nodes. The resulting Laplacian matrix is highly regular, with a tridiagonal structure and periodic boundary conditions.<br>The regularity of the Laplacian matrix  for a cycle graph allows for significant computational optimizations. Specifically, the eigenvalues and eigenvectors can be computed analytically, avoiding the need for high-cost numerical decomposition methods. The eigenvalues of  for a cycle graph are given by:<br>
\begin{equation}<br>
\lambda_k = 2 \left( 1 - \cos\left( \frac{2\pi k}{n} \right) \right), \quad k = 0, 1, \dots, n-1,<br>
\end{equation}<br>and the corresponding eigenvectors are:<br>
\begin{equation}<br>
\mathbf{u}_k = \frac{1}{\sqrt{n}} \begin{bmatrix}<br>
1 \<br>
e^{-i \frac{2\pi k}{n}} \<br>
e^{-i \frac{4\pi k}{n}} \<br>
\vdots \<br>
e^{-i \frac{2\pi (n-1)k}{n}}<br>
\end{bmatrix}, \quad k = 0, 1, \dots, n-1,<br>
\end{equation}<br>where  represents the complex exponential terms.<br><br>图结构主要由节点信息与边信息组成，将上述方法写成论文语言，我提供插图(fig)<br><br>目前的问题：我的模型和原本的模型太像了<br><br>Audio parameterization with robust frame selection for improved bird identification<br>
<img alt="{FF0B4463-BEE7-4AB9-8F3C-5779623E47ED}.png" src="\lib\media\{ff0b4463-bee7-4ab9-8f3c-5779623e47ed}.png"><br>
<img alt="{8FD3E261-3ACD-4DB8-88D5-5C1CE1C130DE}.png" src="\lib\media\{8fd3e261-3acd-4db8-88d5-5c1ce1c130de}.png"><br>
<img alt="{662A61F4-E876-42B0-BD27-19709555F593}.png" src="\lib\media\{662a61f4-e876-42b0-bd27-19709555f593}.png">]]></description><link>technology\科研\论文.html</link><guid isPermaLink="false">Technology/科研/论文.md</guid><pubDate>Wed, 18 Dec 2024 07:06:44 GMT</pubDate><enclosure url="lib\media\{ff0b4463-bee7-4ab9-8f3c-5779623e47ed}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{ff0b4463-bee7-4ab9-8f3c-5779623e47ed}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[目标]]></title><description><![CDATA[ 
 <br>
<br>最好的结果是证明local peaks结合GNN可以 辅助CNN。
<br>其次的话，就是cepstral coefficients结合GNN，可以 辅助 spectrogram结合CNN，提升分类性能。
]]></description><link>technology\科研\目标.html</link><guid isPermaLink="false">Technology/科研/目标.md</guid><pubDate>Sun, 06 Oct 2024 11:17:00 GMT</pubDate></item><item><title><![CDATA[总流程]]></title><description><![CDATA[ 
 DL<br>音频文件<br>频谱图<br>CNN<br>SSL<br>Transformer<br>特征序列<br>Graph<br>GCN做分类<br>librosa库STFT转化]]></description><link>technology\科研\总流程.html</link><guid isPermaLink="false">Technology/科研/总流程.canvas</guid><pubDate>Mon, 16 Sep 2024 05:15:20 GMT</pubDate></item><item><title><![CDATA[关于数模的一些建议]]></title><description><![CDATA[ 
 <br><br>这是最关键的一个部分，这个部分不完成是没法继续推进的。就我前两次的经验来看，高教杯就是没有建立自己的模型，只是在套用，所以白费功夫，而且做得很痛苦。我们要清楚一个完整的新问题是难以通过一个机器学习的模型来解决的，世界上没有两片相同的树叶也没有两个完全一致的问题。我们需要建立独属于这个问题的模型。<br>那建立自己的模型主要是一个怎么样的过程呢？下面是我的个人理解不一定对。<br>我们建模需要先将问题简化，这一步一些题目会帮你简化，提出具体的问题。并且将问题抽象化，抽象成一个目标函数，然后找可行域，然后求解。比如让你找一种方案使得成本最低之类的，这种题我们需要建立目标函数，我们要最大化成本就把成本用变量表示出来，然后找限制条件。这我想你们上过朱群生的数学建模看他的例子就能知道。当然不是所有的问题都是凸优化找最值，还有回归问题比如给一堆数据进行拟合，分类问题如下面的广告点击率问题，聚类问题如故障预测类问题，还有比如时间序列或者动态规划的问题。<br><br>但是仅仅只是表示出来并不是建模的全部，还要想如何能求解。比如凸优化问题用梯度下降、牛顿法、拟牛顿法等等去迭代出最优解，或者直接用拉格朗日乘子法解出，或者求对偶问题求解。不同的问题有不同的求法。我想这些你们数科院应该比我熟悉。<br>对于拉格朗日乘子法的理解可以先看这两个视频。<br>
<a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV15T411f7DY/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">https://www.bilibili.com/video/BV15T411f7DY/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea</a><br><a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1HP4y1Y79e/?spm_id_from=333.1007.top_right_bar_window_history.content.click" target="_blank">https://www.bilibili.com/video/BV1HP4y1Y79e/?spm_id_from=333.1007.top_right_bar_window_history.content.click</a><br>例题：<br>
<img alt="Pasted image 20240708213706.png" src="\lib\media\pasted-image-20240708213706.png"><br>
<img alt="Pasted image 20240708213727.png" src="\lib\media\pasted-image-20240708213727.png"><br>
<img alt="Pasted image 20240708213751.png" src="\lib\media\pasted-image-20240708213751.png"><br>
<img alt="Pasted image 20240708213824.png" src="\lib\media\pasted-image-20240708213824.png"><br>
<img alt="Pasted image 20240708213856.png" src="\lib\media\pasted-image-20240708213856.png"><br><br>回归和分类和聚类问题。我觉得所有的问题都可以用这三类问题概括。这是我们的一个实验，只是很简单的用logistic模型做了一个分类问题，通过其他的特征去预测是否会点击。这就是一个典型的分类问题。<br>这样一个问题有这几个比较重要的步骤：<br>
<br>数据集处理划分，比如一些数据有缺失，一些异常值。还有比如说分类问题的类别不平衡比如故障那个问题，故障的类别很少，而正常的很多，那么就需要对少的进行超采样，或者调节模型权重。
<br>确定超参，有些超参数比如牛顿法的初始值，kmeans聚类里的k值和初始聚类中心点，这些无法通过计算得出最优的参数，我们通过交叉验证法等操作去确定最优的超参数。
<br>模型训练，训练模型，这个过程你可以看成在调整一个函数的参数，对于回归问题就是在更好地让它拟合数据，分类问题，就是让分界面更好地分割类别。
<br>模型预测，我们使用accuracy，precision，recall，或者roc曲线，auc值等方式多方面地去评价一个模型预测的结果是好是坏。
<br>广告点击率(CTR)预测是广告行业的典型应用，是评估广告效果的一个非常重要的指标。通过历史数据训练预测模型，对于每天的增量数据进行预测，找出广告的CTR符合标准的样本进行投放。<br><br>数据集来自于kaggle，数据包含了10天的Avazu的广告点击数据，训练集10000个，测试集1000个。每一条广告包含：广告id、时间、广告位置等属性。<br><img src="https://ai-studio-static-online.cdn.bcebos.com/1682d3186a5d4fedab10c4ad3a7f3656e3db56852e5c4fdbb4fb26005c0ba811" referrerpolicy="no-referrer"><br><br>
<br>读入训练数据和测试数据，划分data和label
<br>将string类型的特征转化为int型：1）进行 one-hot 编码处理，会得到高维稀疏的特征，增大内存开销；2）使用python内置的hash函数将那些类型为object的特征变量映射为一定范围内的整数(原来的string被映射成了integer)，可以大大降低内存的消耗。
<br>import gzip
import pandas as pd
import random
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model
from sklearn.preprocessing import StandardScaler

types_train = {
    'id': np.dtype(int),
    'click': np.dtype(int),         #是否点击,1表示被点击,0表示没被点击
    'hour': np.dtype(int),          #广告被展现的日期+时间
    'C1': np.dtype(int),            #匿名分类变量
    'banner_pos': np.dtype(int),    #广告位置
    'site_id': np.dtype(str),       #站点Id
    'site_domain': np.dtype(str),   #站点域名
    'site_category': np.dtype(str), #站点分类
    'app_id': np.dtype(str),        # appId
    'app_domain': np.dtype(str),    # app域名
    'app_category': np.dtype(str),  # app分类
    'device_id': np.dtype(str),     #设备Id
    'device_ip': np.dtype(str),     #设备Ip
    'device_model': np.dtype(str),  #设备型号
    'device_type': np.dtype(int),   #设备型号
    'device_conn_type': np.dtype(int),
    'C14': np.dtype(int),   #匿名分类变量
    'C15': np.dtype(int),   #匿名分类变量
    'C16': np.dtype(int),   #匿名分类变量
    'C17': np.dtype(int),   #匿名分类变量
    'C18': np.dtype(int),   #匿名分类变量
    'C19': np.dtype(int),   #匿名分类变量
    'C20': np.dtype(int),   #匿名分类变量
    'C21':np.dtype(int)     #匿名分类变量
}

# 添加列名
header_row = ['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain', 'site_category', \
              'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip', 'device_model',\
              'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19',\
              'C20', 'C21']

# 读入训练数据和测试数据
train = pd.read_csv('train_data.csv', names=header_row, dtype=types_train)
test = pd.read_csv('test_data.csv', names=header_row, dtype=types_train)
# 去除第0行（表示列的编号，不是样本）
train = train.drop(labels=train.index.values[0])
test = test.drop(labels=test.index.values[0])
print(test.shape)

# 划分data和label
train_data = train.drop(columns=['click']) #去除click 这一列
print(train_data.shape)
train_label = train['click']#提取click 这一列

test_data = test.drop(columns=['click']) #去除click 这一列
print(test_data.shape)
test_label =test['click'] #提取click 这一列


# 数据预处理
# 使用pd.get_dummies对非数值型特征进行 one-hot 编码处理，得到高维稀疏的特征
#因为函数会将string类型的列视为分类数据（categorical data），并对其进行one-hot编码。对于每一个唯一的分类（unique category）在数据中，它将会创建一个新的列。
#但如果该非数值列的类很多，就会被分成很多类，会加很多列，但这些列只有被分入该类的数据会标记为1，其余皆是0，所以会形成高维稀疏矩阵，这不利于计算。
train_data1 = pd.get_dummies(train_data)
print(train_data1.shape)

# 编写convert_obj_to_int()函数将string类型的特征转换为int型
def convert_obj_to_int(self):
    object_list_columns = self.columns
    object_list_dtypes = self.dtypes
    new_col_suffix = '_int'
    for index in range(0, len(object_list_columns)):
        if object_list_dtypes[index] == object:
            # 使用hash和map将string特征变量映射为一定范围内的整数
            self[object_list_columns[index] + new_col_suffix] = self[object_list_columns[index]].map(hash)
            self.drop([object_list_columns[index]], inplace=True, axis=1)
    return self

# 调用convert_obj_to_int()函数，将string类型转换为int型
scaler = StandardScaler()    
train_data = convert_obj_to_int(train_data) 
train_data = scaler.fit_transform(train_data)
print(train_data.shape)
test_data = convert_obj_to_int(test_data) 
test_data = scaler.transform(test_data)
print(test_data.shape)
<br>(1000, 24)
(10000, 23)
(1000, 23)
(10000, 10531)
(10000, 23)
(1000, 23)
<br><br>以广告在网页中的位置(banner_pos)为例，查看banner_pos和最终类标(click)之间的关系。<br>
<br>查看banner_pos在数据集中的取值分布；
<br>查看不同banner_pos对点击率click的贡献。
<br># 查看banner_pos在数据集中的取值分布
print(train.banner_pos.value_counts()/len(train))

# 查看不同banner_pos对点击率click的贡献
banner_pos_val = train.banner_pos.unique()
banner_pos_val.sort()
ctr_avg_list = []
for i in banner_pos_val:
    selected_data = train.loc[train.banner_pos == i]
    ctr_avg = selected_data.click.mean()
    ctr_avg_list.append(ctr_avg)
    print(" banner 位置: {},  点击率: {}".format(i, ctr_avg))
<br>0    0.8041
1    0.1951
2    0.0007
4    0.0001
Name: banner_pos, dtype: float64
 banner 位置: 0,  点击率: 0.16975500559631887
 banner 位置: 1,  点击率: 0.19067145053818554
 banner 位置: 2,  点击率: 0.14285714285714285
 banner 位置: 4,  点击率: 0.0
<br><br>
<br>调用sklearn的逻辑回归函数LogisticRegression()，进行模型训练
<br>对测试集test_data进行预测，计算预测结果的各项指标acc, pre, recall, auc
<br>绘制ROC曲线（使用预测的概率值而不是预测的类标）
<br>选做：自定义逻辑回归函数MyLogisticRegression()，进行模型训练与预测，与上述结果比较。
<br>from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.metrics import auc
# 调用sklearn的逻辑回归函数LogisticRegression()
#clf = LogisticRegression(penalty='l2', C=1, solver='lbfgs',max_iter=1000)
clf = LogisticRegression(solver="liblinear")
# 模型训练
clf.fit(train_data,train_label)
print("Finish Training!")
# 模型预测
pred = clf.predict(test_data)
#预测的概率值
pred_proba = clf.predict_proba(test_data)[:, 1]
# 计算模型的acc, pre, recall, auc，并输出
# 请在下方作答
# 计算 Accuracy
accuracy = accuracy_score(test_label.values, pred)
print('Accuracy: %.3f' % accuracy)

# 计算 Precision
precision = precision_score(test_label.values, pred)
print('Precision: %.3f' % precision)

# 计算 Recall
recall = recall_score(test_label.values, pred)
print('Recall: %.3f' % recall)

# 计算 AUC
Auc = roc_auc_score(test_label.values, pred_proba)
print('AUC: %.3f' % Auc)

# 绘制roc曲线
# 请在下方作答


# 通过roc_curve()函数，得到fpr（假阳性率）、tpr（真阳性率）和阈值
fpr, tpr, thresholds = roc_curve(test_label, pred_proba )

# 计算面积即AUC值
roc_auc = auc(fpr, tpr)

plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--') # 中间的对角线
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic example')
plt.legend(loc="lower right")
plt.show()



<br>Finish Training!
Accuracy: 0.825
Precision: 0.710
Recall: 0.117
AUC: 0.675
<br><img alt="广告点击率预测_5_1.png" src="\lib\media\广告点击率预测_5_1.png"><br><br>class MyLogisticRegression:
    def __init__(self, learning_rate=0.01, n_iterations=1000):
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.weights, self.bias = None, None

    def _sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def fit(self, X, y):
        n_samples, n_features = X.shape

        # 1. 参数初始化
        self.weights = np.zeros(n_features)
        self.bias = 0

        # 2. 梯度下降
        for _ in range(self.n_iterations):
            linear_model = np.dot(X, self.weights) + self.bias
            y_predicted = self._sigmoid(linear_model)

            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))
            db = (1 / n_samples) * np.sum(y_predicted - y)

            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db

    def predict(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        y_predicted = self._sigmoid(linear_model)
        y_predicted_cls = [1 if i &gt; 0.5 else 0 for i in y_predicted]
        return y_predicted_cls

    def predict_proba(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        y_predicted = self._sigmoid(linear_model)
        return y_predicted

model=MyLogisticRegression();
model.fit(train_data, train_label)
print("Finish Training!")
# 模型预测
pred0 = model.predict(test_data)
predict_proba0 = model.predict_proba(test_data)
# 计算 Accuracy
accuracy = accuracy_score(test_label.values, pred0)
print('Accuracy: %.3f' % accuracy)

# 计算 Precision
precision = precision_score(test_label.values, pred0)
print('Precision: %.3f' % precision)

# 计算 Recall
recall = recall_score(test_label.values, pred0)
print('Recall: %.3f' % recall)

# 计算 AUC
Auc = roc_auc_score(test_label.values, pred_proba)
print('AUC: %.3f' % Auc)

# 绘制roc曲线
# 请在下方作答
# 通过roc_curve()函数，得到fpr（假阳性率）、tpr（真阳性率）和阈值
fpr, tpr, thresholds = roc_curve(test_label, predict_proba0 )

# 计算面积即AUC值
roc_auc = auc(fpr, tpr)

plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--') # 中间的对角线
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic example')
plt.legend(loc="lower right")
plt.show()

<br>Finish Training!
Accuracy: 0.824
Precision: 0.667
Recall: 0.128
AUC: 0.675
<br><img alt="广告点击率预测_7_1.png" src="\lib\media\广告点击率预测_7_1.png"><br>这部分用你们那本教材学习主要的一些算法就可以了。这部分我涉猎的不多，但是最难的一部分。我觉得这部分没什么办法，只有多做题，教材上例题看一看，过去几年国赛的题目做一做，不需要全部做完，只要建模即可。<br><br>代码我选择用python，然后在notebook编写。不选matlab是因为matlab能做的python基本都能做，但是python可以用notebook，看起来清晰一点，也方便共享，会清晰很多。一些三维的图可以用matlab画，python的三维图很丑。<br>
<br>配好python环境，建议用anaconda配，方便你们以后做科研。(网上有教程，编辑器建议用vscode)
<br>我们会使用notebook编程，即在.ipynb文件中编程，朱群生应该用的是网页版，直接在vscode上下载notebook插件即可。
<br>看得懂python代码，并会做一些数据预处理比如excel导入成dataframe和画图的工作，不会写可以向GPT提问，能清晰地表达出自己的需求，让GPT写也可，自己看得懂就行。
<br><br>论文是最简单的也是最重要的，不如直接从头学latex，不会就查或者问GPT。<br>
latex编辑不需要耗时间排版，可以找特定的模板。公式表格之类都有特定的输入方式，熟练了可以节省很多排版浪费的时间。<br>
具体的下载和配置方式：<br>
<a rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/qq_44089921/article/details/107719981" target="_blank">https://blog.csdn.net/qq_44089921/article/details/107719981</a><br>论文最关键的是能否清晰地表述模型的来龙去脉，每一步遇到的问题，又是如何解决这些问题的。可以参考历年优秀的国奖论文，看他们的语言表述，依葫芦画瓢。<br><br>数学建模过程中，建模最难，调代码最费时间，论文最关键。<br>
<br>读题至少要一个小时的时间，一般是晚上出题，当天要把题目确定下来。
<br>读题先不要查论文，先自己想，选有思路的。在读题阶段要大致知道前两道题的方向。因为基本没有完全适配的题目的论文，而且读论文需要时间，很难有时间去理解然后化用。论文引用是锦上添花的事。
<br>一般在题目第一问往往不会直接需要建模，而是画图找变量关系之类的问题。但会需要大量画图和数据处理，如果是这种情况可以用matlab做第一题。
<br>在解决第一题的时候第二题的建模就要开始了。建完模需要建模的同学把想法清晰地告诉其他人，最好把思路写下来，方便之后出论文。然后一个人去写代码一个人去写论文，建模的同学继续往后推。
<br>如果遇到困难，可以去帮着调代码，也可以去帮着写论文，因为自己的想法自己最清楚，尤其是建模的文字部分其实谁建模谁写，问题重述之类的，GPT写即可。诸如画一些流程图之类的可以让专门负责论文的同学来做。
<br><br>这部分用你们那本教材学习主要的一些算法就可以了。这部分我涉猎的不多，但是最难的一部分。我觉得这部分没什么办法，只有多做题，教材上例题看一看，过去几年国赛的题目做一做，不需要全部做完，只要建模即可。<br><br>代码我选择用python，然后在notebook编写。不选matlab是因为matlab能做的python基本都能做，但是python可以用notebook，看起来清晰一点，也方便共享，会清晰很多。一些三维的图可以用matlab画，python的三维图很丑。<br>
<br>配好python环境，建议用anaconda配，方便你们以后做科研。(网上有教程，编辑器建议用vscode)
<br>使用notebook编程，即在.ipynb文件中编程，朱群生应该用的是网页版，直接在vscode上下载notebook插件即可。
<br>看得懂python代码，并会做一些数据预处理比如excel导入成dataframe和画图的工作，不会写可以向GPT提问，能清晰地表达出自己的需求，让GPT写也可，自己看得懂就行。
<br><br>论文是最简单的也是最重要的，latex应该你们之后要科研也要用的，不如直接从头学latex，不会就查或者问GPT。<br>
<br>latex编辑不需要耗时间排版，可以找特定的模板。公式表格之类都有特定的输入方式，熟练了可以节省很多排版浪费的时间。
<br>具体的下载和配置方式：即下载texlive然后在vscode里下个插件就可以了。
<br><a rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/qq_44089921/article/details/107719981" target="_blank">https://blog.csdn.net/qq_44089921/article/details/107719981</a>
<br>熟悉一些快捷键以及公式的书写，这里建议用AxMath。画图AxGlyph。
<br>论文最关键的是能否清晰地表述模型的来龙去脉，每一步遇到的问题，又是如何解决这些问题的。可以参考历年优秀的国奖论文，看他们的语言表述，依葫芦画瓢。
<br><br>数学建模过程中，建模最难，调代码最费时间，论文最关键。这三者不是完全割裂的。<br>
<br>读题至少要一个小时的时间，一般是晚上出题，当天要把题目确定下来。
<br>读题先不要查论文，先自己想，选有思路的。在读题阶段要大致知道前两道题的方向。因为基本没有完全适配的题目的论文，而且读论文需要时间，很难有时间去理解然后化用。论文引用是锦上添花的事。
<br>一般在题目第一问往往不会直接需要建模，而是画图找变量关系之类的问题。但会需要大量画图和数据处理，如果是这种情况可以用matlab做第一题。
<br>在解决第一题的时候第二题的建模就要开始了。建完模需要建模的同学把想法清晰地告诉其他人，最好把思路写下来，方便之后出论文。然后一个人去写代码一个人去写论文，建模的同学继续往后推。
<br>如果遇到困难，可以去帮着调代码，也可以去帮着写论文，因为自己的想法自己最清楚，尤其是建模的文字部分其实谁建模谁写，问题重述之类的，GPT写即可。诸如画一些流程图之类的可以让专门负责论文的同学来做。
]]></description><link>technology\数学建模\关于数模的一些建议.html</link><guid isPermaLink="false">Technology/数学建模/关于数模的一些建议.md</guid><pubDate>Mon, 09 Sep 2024 08:11:47 GMT</pubDate><enclosure url="lib\media\pasted-image-20240708213706.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240708213706.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[国赛2019A]]></title><description><![CDATA[ 
 <br><a rel="noopener nofollow" class="external-link" href="https://github.com/waferen/2019A" target="_blank">https://github.com/waferen/2019A</a>]]></description><link>technology\数学建模\国赛2019a.html</link><guid isPermaLink="false">Technology/数学建模/国赛2019A.md</guid><pubDate>Mon, 09 Sep 2024 08:12:55 GMT</pubDate></item><item><title><![CDATA[国赛2023D]]></title><description><![CDATA[ 
 <br><a rel="noopener nofollow" class="external-link" href="https://github.com/waferen/2023D" target="_blank">https://github.com/waferen/2023D</a>]]></description><link>technology\数学建模\国赛2023d.html</link><guid isPermaLink="false">Technology/数学建模/国赛2023D.md</guid><pubDate>Mon, 09 Sep 2024 08:13:54 GMT</pubDate></item><item><title><![CDATA[国赛2024B]]></title><description><![CDATA[ 
 <br><a rel="noopener nofollow" class="external-link" href="https://github.com/waferen/2024B" target="_blank">https://github.com/waferen/2024B</a>]]></description><link>technology\数学建模\国赛2024b.html</link><guid isPermaLink="false">Technology/数学建模/国赛2024B.md</guid><pubDate>Mon, 09 Sep 2024 08:14:38 GMT</pubDate></item><item><title><![CDATA[数模基础]]></title><description><![CDATA[ 
 <br>
<br>chatGPT的使用，如何正确提问
<br>SPSSPRO使用
<br>Visio使用
<br>latex配置及使用
<br>找latex模板
<br>AXmath的下载和使用
<br>数学建模算法与应用练习
<br>使用wsl编辑c/c++，使用Windows编辑python和latex
<br>常见模型<img alt="mmexport1721024759918.png" src="\lib\media\mmexport1721024759918.png">
]]></description><link>technology\数学建模\数模基础.html</link><guid isPermaLink="false">Technology/数学建模/数模基础.md</guid><pubDate>Mon, 09 Sep 2024 08:05:20 GMT</pubDate><enclosure url="lib\media\mmexport1721024759918.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\mmexport1721024759918.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数学建模]]></title><description><![CDATA[ 
 <br><br><a data-href="电工杯" href="\technology\数学建模\电工杯.html" class="internal-link" target="_self" rel="noopener nofollow">电工杯</a><br>
<a data-href="国赛2024B" href="\technology\数学建模\国赛2024b.html" class="internal-link" target="_self" rel="noopener nofollow">国赛2024B</a><br>
<a data-href="国赛2023D" href="\technology\数学建模\国赛2023d.html" class="internal-link" target="_self" rel="noopener nofollow">国赛2023D</a><br>
<a data-href="国赛2019A" href="\technology\数学建模\国赛2019a.html" class="internal-link" target="_self" rel="noopener nofollow">国赛2019A</a><br>
<a data-href="校赛" href="\technology\数学建模\校赛.html" class="internal-link" target="_self" rel="noopener nofollow">校赛</a>]]></description><link>technology\数学建模\数学建模.html</link><guid isPermaLink="false">Technology/数学建模/数学建模.md</guid><pubDate>Mon, 09 Sep 2024 12:05:05 GMT</pubDate></item><item><title><![CDATA[题目：燃气调压器故障预测与诊断]]></title><description><![CDATA[ 
 <br><br>小区燃气调压器是确保供气安全和稳定的重要设备。然而，常见故障如过滤器堵塞、阀座损坏和隔膜损坏可能会影响其正常运行。当燃气调压器出现故障时，通常会表现为以下三种常见故障：过滤器堵塞、阀座损坏和隔膜损坏。这些故障可能会导致燃气调压器无法正常工作，进而影响到燃气供应系统的安全性和稳定性。<br>
过滤器堵塞的主要原因是燃气中含有的杂质和污染物，在长时间使用后，这些杂质和污染物会积聚在过滤器中，导致通道堵塞。其表现形式为燃气通过的流量减小，从而使得输出压力无法正常调节，可能出现输出压力波动、不稳定甚至无法维持设定值的情况。<br>
阀座损坏通常是由于长期使用或不当操作导致的阀门密封面磨损或变形，使得阀门无法完全关闭或密封不严。阀座损坏会导致燃气泄漏或无法完全关闭，从而造成输出压力偏高或无法稳定调节的情况，甚至可能引发安全隐患。<br>
隔膜损坏通常是由于材料老化、疲劳、物理损伤或操作不当等因素引起的，使得隔膜的密封性能降低或失效。隔膜损坏会导致燃气调压器的密封性能下降，可能会引起燃气泄漏、输出压力波动大或无法维持稳定的情况，严重时可能会导致系统压力失控和安全隐患。<br>
为了提前预防故障并进行及时维修，我们希望通过实时的燃气压力监测数据来预测可能出现的故障。我们提供了实时的燃气压力监测数据，包括输入压力（in_pressure）、输出压力（out_pressure）以及环境温度（temperature）。数据以每分钟为单位记录。基于提供的实时监测数据，请完成以下任务。<br>一、对输入压力、输出压力和环境温度的数据进行可视化分析，探索它们之间的关系以及可能的异常情况。<br>
二、故障预测模型建立。基于监测数据，建立预测模型，以预测燃气调压器可能出现的故障情况（过滤器堵塞、阀座损坏、隔膜损坏），并评估模型的准确性和鲁棒性。<br>
三、故障诊断与维修策略：提出针对不同故障类型的预防和诊断策略，以及可能的维修措施。<br>要求：提交报告，包括数据可视化、模型建立和评估结果，并附带详细的解释和推理过程。<br>
报告格式不限，但应清晰展示分析过程和结论。 评分将考虑报告的逻辑性、模型预测准确性、提出的策略可行性等因素。<br>备注：<br>
参赛者可以根据需要进行数据预处理和特征工程，但需在报告中说明具体步骤和理由。<br>
参赛者可选择合适的机器学习算法或统计模型，但需说明模型的选择原因和假设。<br>
请在报告中提供对不同故障类型的预防和诊断策略的详细解释和理由。<br><br><br>主要做了时间序列图、差分图、相关性热力图、散点图、压力差时间序列图<br><br>由相关性热力图可知：输入压力与输出压力正相关，与环境温度呈一定负相关<br><br>这三种故障（过滤器堵塞、阀座损坏和隔膜损坏）在出口压力和进口压力上的表现有明显的区别。以下是对每种故障的分析与假设：<br><br><br>
<br>燃气流量减小：由于杂质和污染物积聚在过滤器中，导致燃气流量减少。
<br>出口压力无法正常调节：过滤器堵塞会使出口压力波动、不稳定，甚至无法维持设定值。
<br><br>
<br>降低：由于燃气流量减少，出口压力通常会降低。
<br>波动和不稳定：堵塞可能导致压力调节不稳定，出口压力波动较大。
<br><br>
<br>基本不变：进口压力通常不会受到过滤器堵塞的直接影响。
<br>轻微升高（极端情况下）：如果过滤器非常严重地堵塞，进口压力可能会略微升高，但这种情况较少见。
<br><br><br>
<br>密封不严或无法完全关闭：阀门密封面磨损或变形，使得阀门无法完全关闭或密封不严。
<br>燃气泄漏：导致燃气泄漏或无法完全关闭。
<br><br>
<br>偏高：如果阀座损坏导致燃气泄漏，出口压力可能会偏高，因为燃气没有完全被调节到预期水平。
<br>不稳定：阀座损坏会使出口压力不稳定，调节困难，波动较大。
<br><br>
<br>基本不变：进口压力通常不受阀座损坏的直接影响。
<br><br><br>
<br>密封性能降低或失效：由于材料老化、疲劳或物理损伤，隔膜的密封性能下降。
<br>调压失效：隔膜损坏会导致燃气调压器的调压功能失效。
<br><br>
<br>波动大、不稳定：隔膜损坏会导致出口压力波动较大，无法稳定调节。
<br>无法维持设定值：严重时，出口压力无法维持在设定值，可能偏高或偏低。
<br><br>
<br>基本不变：进口压力通常不受隔膜损坏的直接影响。
<br><br><br><br>
<br>过滤器堵塞：监测出口压力的下降和波动情况，结合流量监测（燃气流量减小）。
<br>阀座损坏：检查出口压力偏高或不稳定的情况，并进行泄漏检测。
<br>隔膜损坏：观察出口压力的剧烈波动和无法维持设定值的情况，检查调压功能是否失效。
<br><br>
<br>
由于我们没有故障标签，所以我们需要做一个聚类来检测哪些属于故障

<br>
由于只按一户人家一个样本的话样本量太少，容易欠拟合。

<br>
如果按每一分钟作为一个样本缺乏时间尺度的信息，比如波动无法体现，且一天中不同的使用情况也会产生不同的输入压力与输出压力，所以短时间的信息缺乏时间语义。

<br>
于是，我决定使用一户人家一天的数据作为一个样本数据，其中设置的统计量特征主要有以下几个：进出口压力的最大值、最小值、方差、偏度系数、峰度系数。

<br>
由于特征过多，需要pca降维之后才能进行聚类

<br>
<img alt="Pasted image 20240518115022.png" src="\lib\media\pasted-image-20240518115022.png">

<br>
我根据这些特征进行k-means聚类，分为两类，将故障天数标出，然后去检查这些天数，对他们进行标记，标记为三种故障。

<br>
<img alt="Pasted image 20240518115431.png" src="\lib\media\pasted-image-20240518115431.png">

<br>
只有一个被分成故障聚类效果还是不行

<br>
由于第一与第三种异常题目给出的特点基本一致，如何将两者区分开来，我们做出假设，由于第三种为泄露，我们认为如果进口与出口压力差值较大，那么就认为是第一种。标签手动标记

<br>
然后在有标签后，用随机森林对以上数据建立模型，并测试。与单决策树进行比较。
1.是的<br>
2.代码里有，算的是八小时一个区间，其中用到的特征统计量如下:

<br>def calc_stats(group):
	stats = {}
	for col in ['Pressure_Difference', 'Out_Pressure (kPa)']:
		stats[f'{col}_max'] = group[col].max()
		stats[f'{col}_min'] = group[col].min()
		stats[f'{col}_var'] = group[col].var()
		stats[f'{col}_skew'] = skew(group[col])
		stats[f'{col}_kurtosis'] = kurtosis(group[col])
	return pd.Series(stats)
<br>就是最大值最小值方差两个系数。<br>用于聚类的特征如下:<br>features = all_results[['Pressure_Difference_max', 'Pressure_Difference_min', 'Pressure_Difference_var', 'Pressure_Difference_skew', 'Pressure_Difference_kurtosis']]
<br>Pressure_Difference指输出-输入。<br>随机森林模型的代码在RandomForest.py中<br>3.准确性和鲁棒性就是这张图<br>
<img alt="5e8d244766c01618b46bea8c6119be25.png" src="\lib\media\5e8d244766c01618b46bea8c6119be25.png"><br>precision是查准率，recall是查全率，f1是两个的调和平均<br>
Single Tree:指单一决策树的正确率<br>
Random Forest:是随机森林的正确率<br>我现在不知道标签，我如何得到标签，那么我先要去对数据进行聚类，因为聚类并不可靠，我只把它分成两类一类正常Normal一类fault，这个在output.xlsx中。那么如何去聚类，我需要一些可以将数据分开的特征，这些特征我该如何选择，我觉得输入和输出的相对值更重要一些，它同时反应了输入和输出。那么每一分钟可以得到一个差值，八个小时的差值求方差、最大最小等，就得到了八小时为一个区间，特征值为我上面说的那些特征的这样一个矩阵，对于这个矩阵进行聚类。聚类结束后，对故障的我去打标签，打完标签去做训练、预测。]]></description><link>technology\数学建模\校赛.html</link><guid isPermaLink="false">Technology/数学建模/校赛.md</guid><pubDate>Sat, 18 May 2024 09:23:25 GMT</pubDate><enclosure url="lib\media\pasted-image-20240518115022.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240518115022.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[关于C++文件流操作]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/cplus" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/cplus</a> 
 <br><a href=".?query=tag:科技\cplus" class="tag" target="_blank" rel="noopener nofollow">#科技/cplus</a><br><br>#include&lt;fstream&gt;  
#include&lt;iostream&gt;

using namespace std;

int main(){
	
	string filepath;//filepath为接下来用户输入的文件地址
	cout&lt;&lt;"请输入您的文件地址:"&lt;&lt;endl;
	getline(cin, filepath);
	
	ifstream file(filepath);//打开文件，这里使用ifstream构造函数，构造文件流输入操作file，且将它链接到filepath这个文件地址上，即打开filepath
	
	if (file.fail()) {
		cerr &lt;&lt; "未能打开文件" &lt;&lt; std::endl;
		return 1;
	}
	
	string line;//用来存储文件中读入的行信息
	
	while(getline(file,line)){
		
	};//具体对每一行进行操作
	
	file.close();//关闭文件
	
	return 0;
	
}
<br><br>std::ofstream和std::ifstream都是C++标准库中的文件流类，但它们有不同的用途。<br>std::ofstream是用于写入文件的类，全名是 output file stream，它提供了一种向文件写入数据的方式。你可以使用std::ofstream的成员函数（比如&lt;&lt;运算符）来将数据写入文件。  <br>std::ifstream则是用于读取文件的类，全名是 input file stream，它提供了一种从文件读取数据的方式。你可以使用std::ifstream的成员函数（比如&gt;&gt;运算符）来读取文件中的数据。<br>
同样地，std::fstream类可以同时对文件进行读写操作。<br>这个设计是为了遵循C++的尽可能显式的原则，通过不同的类型来区分对文件的读或写操作。这样做也有助于防止因误操作而对文件进行意外的修改。]]></description><link>technology\collegeproject\编程语言\c++\关于c++文件流操作.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/C++/关于C++文件流操作.md</guid><pubDate>Tue, 27 Feb 2024 03:58:19 GMT</pubDate></item><item><title><![CDATA[关于map]]></title><description><![CDATA[ 
 <br><br>在C++中，map 和 multimap 都是关联容器，用于存储键值对（key-value pairs），并且键值对根据键自动排序。它们的区别主要在于是否允许键重复。<br><br>map 是一种键值对的关联容器，使用红黑树（Red-Black Tree）等平衡二叉树结构实现。键值对根据键自动排序，默认情况下使用 std::less 比较函数进行排序，即升序排列。具体特性如下：<br>
<br>键唯一：map 中的每个键是唯一的，不能有重复的键。
<br>自动排序：插入时会自动根据键的大小进行排序。
<br>例如：<br>#include &lt;iostream&gt;
#include &lt;map&gt;

int main() {
    std::map&lt;int, std::string&gt; myMap;
    myMap[3] = "three";
    myMap[1] = "one";
    myMap[2] = "two";

    for (const auto &amp;pair : myMap) {
        std::cout &lt;&lt; pair.first &lt;&lt; ": " &lt;&lt; pair.second &lt;&lt; std::endl;
    }

    return 0;
}
<br>输出：<br>1: one
2: two
3: three
<br><br>multimap 与 map 相似，但允许多个键相同的元素存在，即同一个键可以有多个值。其具体特性如下：<br>
<br>键不唯一：multimap 允许键重复，同一个键可以有多个值。
<br>自动排序：和 map 一样，multimap 也会自动根据键的大小进行排序。
<br>例如：<br>#include &lt;iostream&gt;
#include &lt;map&gt;

int main() {
    std::multimap&lt;int, std::string&gt; myMultiMap;
    myMultiMap.insert({3, "three"});
    myMultiMap.insert({1, "one"});
    myMultiMap.insert({2, "two"});
    myMultiMap.insert({2, "another two"});

    for (const auto &amp;pair : myMultiMap) {
        std::cout &lt;&lt; pair.first &lt;&lt; ": " &lt;&lt; pair.second &lt;&lt; std::endl;
    }

    return 0;
}
<br>输出：<br>1: one
2: two
2: another two
3: three
<br><br>
<br>键是否唯一：map 键唯一，multimap 键可以重复。
<br>自动排序：map 和 multimap 都会自动根据键进行排序。
<br>这两个容器在选择时，主要依据你是否需要允许键重复来决定。如果需要存储多个相同键的元素，选择 multimap；如果不需要重复键且只需要唯一键，选择 map。]]></description><link>technology\collegeproject\编程语言\c++\关于map.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/C++/关于map.md</guid><pubDate>Tue, 25 Jun 2024 08:54:24 GMT</pubDate></item><item><title><![CDATA[关于string]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/cplus" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/cplus</a> 
 <br><a href=".?query=tag:科技\cplus" class="tag" target="_blank" rel="noopener nofollow">#科技/cplus</a><br><br>#include &lt;iostream&gt;
#include &lt;string&gt;

int main() {
    std::string str = "Hello World!";
    
    char last_char = str.back();
    
    std::cout &lt;&lt; "The last character of the string is: " &lt;&lt; last_char &lt;&lt; std::endl;
    
    return 0;
}
<br>当你运行这段代码时，将会输出：<br>The last character of the string is: !
<br>需要注意的是，如果字符串是空的，那么调用back()函数将会产生未定义的行为。因此，在调用back()函数前，最好先检查字符串是否为空。<br><br>在C++中，我们可以用以下的方法将一个string变量赋值为空：<br>std::string str;
<br>当我们在没有提供初始值的情况下声明一个string变量时，C++默认会初始化这个字符串为空。<br>你也可以用一个空的双引号（""）字符串来给string变量赋值为空，例如：<br>std::string str = "";
<br>或者你也可以使用string类的clear()方法来清空一个已经存在的string变量，例如：<br>std::string str = "Hello, World!";
str.clear();  // str现在为空
<br>以上三种方式都可以将string变量赋值为空。<br><br>是的，C++的std::string类重载了比较运算符，所以你可以直接使用==、!=、&lt;、&lt;=、&gt;和&gt;=这些运算符来比较两个字符串的大小。<br>比较是基于字符的ASCII码值进行的，从两个字符串的第一个字符开始比较，如果某一位置上的字符不同，那么具有较小ASCII码值的字符对应的字符串就被视为较小的字符串。如“apple”小于"banana"，因为'a'的ASCII码小于'b'。如果在某一位置字符相同，则比较下一位置，以此类推。如果字符串的所有字符都相同，但是长度不同，那么长度较短的那个字符串被视为较小的字符串。<br>
以下是一些示例：<br>#include &lt;iostream&gt;
#include &lt;string&gt;

int main() {
    std::string str1 = "apple";
    std::string str2 = "banana";

    if (str1 &lt; str2)
        std::cout &lt;&lt; str1 &lt;&lt; " is less than " &lt;&lt; str2 &lt;&lt; std::endl;
    else if (str1 &gt; str2)
        std::cout &lt;&lt; str1 &lt;&lt; " is greater than " &lt;&lt; str2 &lt;&lt; std::endl;
    else
        std::cout &lt;&lt; str1 &lt;&lt; " is equal to " &lt;&lt; str2 &lt;&lt; std::endl;

    return 0;
}
<br>当你运行这段代码时，输出应该是：<br>apple is less than banana
]]></description><link>technology\collegeproject\编程语言\c++\关于string.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/C++/关于string.md</guid><pubDate>Mon, 26 Feb 2024 03:51:44 GMT</pubDate></item><item><title><![CDATA[关于vector]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/cplus" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/cplus</a> 
 <br><a href=".?query=tag:科技\cplus" class="tag" target="_blank" rel="noopener nofollow">#科技/cplus</a><br><br>在 C++ 中，可以使用&nbsp;std::vector&nbsp;的成员函数&nbsp;insert()&nbsp;来在向量的中间插入一个或多个元素。以下是一个使用&nbsp;insert()&nbsp;函数在向量中间插入元素的示例：<br>#include &lt;iostream&gt;
#include &lt;vector&gt;

int main() {
    // 创建一个包含1, 2, 3的向量
    std::vector&lt;int&gt; v = {1, 2, 3};
    
    // 获取到中间元素的迭代器
    std::vector&lt;int&gt;::iterator mid = v.begin() + v.size() / 2;
    
    // 在中间位置插入元素4
    v.insert(mid, 4);

    // 打印修改后的向量
    for (int i : v) {
        std::cout &lt;&lt; i &lt;&lt; ' ';
    }

    return 0;
}
<br>当你运行这段代码时，输出应该是：<br>1 4 2 3
<br>在上面的代码中，我们首先创建了一个整数向量&nbsp;v，然后找到了向量中间元素的位置（通过计算向量大小的一半并添加到&nbsp;begin()&nbsp;得到的迭代器）。之后，我们使用了&nbsp;insert()&nbsp;函数在该位置插入新的元素&nbsp;4。最后，我们遍历了整个向量并打印出其元素，可以看到新元素已经被成功插入到了向量的中间。<br>
需要注意的是，insert()&nbsp;函数可以改变向量的大小，而且插入操作可能会导致向量中其他元素的复制或移动，因此这个操作的复杂性可能是线性的，即与向量的大小成正比。剩余元素将会向后移动。<br>在 C++ 中，可以使用 std::vector 的成员函数 insert() 来在向量的中间插入一个或多个元素。以下是一个使用 insert() 函数在向量中间插入元素的示例：<br>#include &lt;iostream&gt;
#include &lt;vector&gt; 
int main() { 
// 创建一个包含1, 2, 3的向量 
	std::vector&lt;int&gt; v = {1, 2, 3}; 
	// 获取到中间元素的迭代器 
	std::vector&lt;int&gt;::iterator mid = v.begin() + v.size() / 2; // 在中间位置插入元素4 v.insert(mid, 4); // 打印修改后的向量 for (int i : v) { std::cout &lt;&lt; i &lt;&lt; ' '; } return 0; } 
<br>当你运行这段代码时，输出应该是： 1 4 2 3<br>
在上面的代码中，我们首先创建了一个整数向量 v，然后找到了向量中间元素的位置（通过计算向量大小的一半并添加到 begin() 得到的迭代器）。之后，我们使用了 insert() 函数在该位置插入新的元素 4。最后，我们遍历了整个向量并打印出其元素，可以看到新元素已经被成功插入到了向量的中间。 需要注意的是，insert() 函数可以改变向量的大小，而且插入操作可能会导致向量中其他元素的复制或移动，因此这个操作的复杂性可能是线性的，即与向量的大小成正比。剩余元素将会向后移动。<br>
std::vector&nbsp;的&nbsp;insert&nbsp;方法用于在向量的特定位置插入一个或多个元素。以下是其具体的用法：<br>
<br>
单个元素插入：insert(iterator position, const T&amp; val)
position&nbsp;是一个迭代器，指向您希望新元素插入的向量中的位置。val&nbsp;是您希望插入的元素的值。

<br>
重复元素插入：insert(iterator position, size_type n, const T&amp; val)
此重载版本允许您在指定位置插入&nbsp;n&nbsp;个相同的元素，每个元素的值为&nbsp;val。

<br>
范围插入：insert(iterator position, InputIterator first, InputIterator last)
得益于范围插入，您可以在向量的指定位置插入另一个容器（例如另一个向量、数组或列表）的元素。这里的&nbsp;first&nbsp;和&nbsp;last&nbsp;是指向您要插入的元素范围的迭代器。

<br><br>return vector&lt;string&gt;();

或者：（C++11）

return {};
]]></description><link>technology\collegeproject\编程语言\c++\关于vector.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/C++/关于vector.md</guid><pubDate>Tue, 27 Feb 2024 02:49:14 GMT</pubDate></item><item><title><![CDATA[一些C语言函数]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/cplus" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/cplus</a> <a class="tag" href="?query=tag:include" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#include</a> <a class="tag" href="?query=tag:include" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#include</a> 
 <br><a href=".?query=tag:科技\cplus" class="tag" target="_blank" rel="noopener nofollow">#科技/cplus</a><br><br>1.定义<br>
分解字符串为一组字符串。s为要分解的字符，delim为分隔符字符（如果传入字符串，则传入的字符串中每个字符均为分割符）。首次调用时，s指向要分解的字符串，之后再次调用要把s设成NULL。在头文件#include&lt;string.h&gt;中。<br>
2.原型<br>
char *strtok(char s[], const char *delim);<br>3.说明<br>
（1）当strtok()在参数s的字符串中发现参数delim中包含的分割字符时,则会将该字符改为\0 字符。在第一次调用时，strtok()必需给予参数s字符串，往后的调用则将参数s设置成NULL。每次调用成功则返回指向被分割出片段的指针。<br>
（2）返回值<br>从s开头开始的一个个被分割的串。当s中的字符查找到末尾时，返回NULL。如果查找不到delim中的字符时，返回当前strtok的字符串的指针。所有delim中包含的字符都会被滤掉，并将被滤掉的地方设为一处分割的节点。<br>（3）需要注意的是，使用该函数进行字符串分割时，会破坏被分解字符串的完整，调用前和调用后的s已经不一样了。第一次分割之后，原字符串str是分割完成之后的第一个字符串，剩余的字符串存储在一个静态变量中，因此多线程同时访问该静态变量时，则会出现错误。<br>4.使用<br>
strtok函数会破坏被分解字符串的完整，调用前和调用后的s已经不一样了。如果要保持原字符串的完整，可以使用strchr和sscanf的组合等。<br><a href=".?query=tag:include" class="tag" target="_blank" rel="noopener nofollow">#include</a>&lt;string.h&gt;<br>
<a href=".?query=tag:include" class="tag" target="_blank" rel="noopener nofollow">#include</a>&lt;stdio.h&gt;<br>
int main(void)<br>
{<br>
char input[16]="abc,d";<br>
charp;<br>
/strtok places a NULL terminator<br>
infront of the token,if found/<br>
p=strtok(input,",");<br>
if(p)<br>
printf("%s\n",p);<br>
/Asecond call to strtok using a NULL<br>
as the first parameter returns a pointer<br>
to the character following the token*/<br>
p=strtok(NULL,",");<br>
if(p)<br>
printf("%s\n",p);<br>
return 0;<br>}<br>
————————————————<br><br>atoi()函数<br>atoi():int atoi(const char *str );<br>功能：把字符串转换成整型数。<br>str：要进行转换的字符串<br>返回值：每个函数返回 int 值，此值由将输入字符作为数字解析而生成。 如果该输入无法转换为该类型的值，则atoi的返回值为 0。<br>说明：当第一个字符不能识别为数字时，函数将停止读入输入字符串。<br><br>strcmp()函数有两个参数，即要比较的两个字符串。strcmp()函数对两个字符串进行大小写敏感的(case-sensitiVe)和字典式的(lexicographic)比较，并返回下列值之一：<br><br>返  回  值         意  义
<br><br>&lt;0               第一个字符串小于第二个字符串
 0               两个字符串相等    ·
&gt;0               第一个字符串大于第二个字符串
<br><br><br>readline()是C语言库中的一个函数，主要用于从标准输入读取一行数据。这个函数可以读取用户在命令行中输入的字符串。它的基本语法为：<br>char *readline(const char *prompt);
<br>
<br>prompt：readline() 的参数是一个字符串。当调用函数的时候，它会在屏幕上输出这个字符串，以提示用户输入。
<br>readline()函数会读取一行输入（直到检测到'\n'为止），然后返回一个指向输入字符串的指针。重要的一点要注意是，readline()会为返回的字符串动态分配内存，因此在使用完返回的字符串后，需要使用free()函数来释放这块内存以防止内存泄漏。<br>下面是一个简单的readline()函数使用示例：<br>#include &lt;stdio.h&gt;
#include &lt;readline/readline.h&gt;
#include &lt;stdlib.h&gt;

int main() {
    char *input = readline("Please enter a line of text: ");
    printf("You entered: %s\n", input);
    free(input);
    return 0;
}
<br>在这个例子中，我们使用readline()函数提示用户输入一行文字，然后接收用户输入并打印出来，最后释放字符串占用的内存。<br>readline()函数除了基本的读取一行输入之外，还提供了一些强大的功能，包括命令行历史和编辑功能。<br>
<br>命令行历史：默认情况下，readline会保留用户输入的历史记录，并允许用户使用向上和向下的箭头键来访问之前输入的文本。这在一些长命令或者多次重复的命令中非常有用，用户无需重复输入，直接通过箭头键就可以找到历史命令。
<br>编辑功能：readline支援Emacs风格的文字编辑快捷方式，例如使用Ctrl+A移动光标到行首；Ctrl+E移动光标至行尾。还可通过Ctrl+K来剪切从光标位置到行尾的所有字符，使用Ctrl+Y可以粘贴之前剪切的文本。<br>
这两项功能都大大提高了用户在交互式程序中的使用体验。
<br>具体用法，你可以参考GNU readline库的<a data-tooltip-position="top" aria-label="https://tiswww.case.edu/php/chet/readline/rluserman.html" rel="noopener nofollow" class="external-link" href="https://tiswww.case.edu/php/chet/readline/rluserman.html" target="_blank">官方文档</a>，里面包含了readline函数的详细特性和操作方法.<br><br><br>C 库函数&nbsp;long int strtol(const char *str, char endptr, int base)&nbsp;把参数&nbsp;str&nbsp;所指向的字符串根据给定的&nbsp;base**&nbsp;转换为一个长整数（类型为 long int 型），base 必须介于 2 和 36（包含）之间，或者是特殊值 0。<br><br>下面是 strtol() 函数的声明。<br>long int strtol(const char *str, char **endptr, int base)<br><br>
<br>str&nbsp;-- 要转换为长整数的字符串。
<br>endptr&nbsp;-- 对类型为 char* 的对象的引用，其值由函数设置为&nbsp;str&nbsp;中数值后的下一个字符。
<br>base&nbsp;-- 基数，必须介于 2 和 36（包含）之间，或者是特殊值 0。如果 base 为 0，则会根据字符串的前缀来判断进制：如果字符串以 '0x' 或 '0X' 开头，则将其视为十六进制；如果字符串以 '0' 开头，则将其视为八进制；否则将其视为十进制。
<br><br>函数返回被转换的长整型整数值。如果输入字符串不符合数字格式，strtol() 将返回 0。如果转换结果超出了 long 整数的表示范围，那么将产生溢出，并设置 errno 为 ERANGE。你可以使用 &lt;errno.h&gt; 头文件中的 errno 变量来检查是否有溢出发生。<br><br>下面的实例演示了 strtol() 函数的用法。<br>以下实例我们将字符串 "12345" 转换为长整型整数。strtol() 函数会将这个字符串转换为对应的整数值 12345。因为我们指定了 base 为 10，所以它会按照十进制进行转换。<br><br>#include &lt;stdio.h&gt;  
#include &lt;stdlib.h&gt;  
  
int main() {  
    char str[] = "12345";  
    char *endptr;  
    long int num;  
  
    num = strtol(str, &amp;endptr, 10);  
  
    if (*endptr != '\0') {  
        printf("转换失败：输入字符串不是一个有效的整数。\n");  
    } else {  
        printf("转换结果：%ld\n", num);  
    }  
  
    return 0;  
}  
<br>让我们编译并运行上面的程序，这将产生以下结果：<br>转换结果：12345<br>如果输入字符串不能被完全转换为整数，strtol() 函数将返回转换成功的部分，而 endptr 将指向未转换部分的第一个字符。在这个例子中，endptr 是指向字符串末尾的空字符 '\0'，表示整个输入字符串都被成功转换为整数。<br>如果输入字符串包含非数字字符，例如 "12ab"，那么 endptr 将指向 "ab" 的起始位置，指示转换失败。<br><br>#include &lt;stdio.h&gt;  
#include &lt;stdlib.h&gt;  
  
int main() {  
    char str[] = "12ab";  
    char *endptr;  
    long int num;  
  
    num = strtol(str, &amp;endptr, 10);  
  
    if (*endptr != '\0') {  
        printf("转换失败：输入字符串不是一个有效的整数。未转换部分：%s\n", endptr);  
    } else {  
        printf("转换结果：%ld\n", num);  
    }  
  
    return 0;  
}  
<br>以上实例我们将字符串 "12ab" 转换为长整型整数。strtol() 函数会尝试将这个字符串转换为对应的整数值 12，但因为字符串中包含非数字字符 "ab"，转换无法完成。<br>输出将是：<br>转换失败：输入字符串不是一个有效的整数。未转换部分：ab]]></description><link>technology\collegeproject\编程语言\c++\一些c语言函数.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/C++/一些C语言函数.md</guid><pubDate>Tue, 25 Jun 2024 08:53:47 GMT</pubDate></item><item><title><![CDATA[C++]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/cplusplus" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/cplusplus</a> 
 <br><a href=".?query=tag:科技\cplusplus" class="tag" target="_blank" rel="noopener nofollow">#科技/cplusplus</a> <br><a data-href="Technology/CollegeProject/编程语言/C++/关于vector" href="\technology\collegeproject\编程语言\c++\关于vector.html" class="internal-link" target="_self" rel="noopener nofollow">Technology/CollegeProject/编程语言/C++/关于vector</a><br>
<a data-href="Technology/CollegeProject/编程语言/C++/关于string" href="\technology\collegeproject\编程语言\c++\关于string.html" class="internal-link" target="_self" rel="noopener nofollow">Technology/CollegeProject/编程语言/C++/关于string</a><br>
<a data-href="Technology/CollegeProject/编程语言/C++/关于C++文件流操作" href="\technology\collegeproject\编程语言\c++\关于c++文件流操作.html" class="internal-link" target="_self" rel="noopener nofollow">Technology/CollegeProject/编程语言/C++/关于C++文件流操作</a><br>
<a data-href="Technology/CollegeProject/编程语言/C++/C++关于vector做返回值的引用细节" href="\technology\collegeproject\编程语言\c++\c++关于vector做返回值的引用细节.html" class="internal-link" target="_self" rel="noopener nofollow">Technology/CollegeProject/编程语言/C++/C++关于vector做返回值的引用细节</a>]]></description><link>technology\collegeproject\编程语言\c++\c++.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/C++/C++.md</guid><pubDate>Fri, 06 Dec 2024 06:11:29 GMT</pubDate></item><item><title><![CDATA[C++ 运算符优先级总表]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/cplus" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/cplus</a> 
 <br><a href=".?query=tag:科技\cplus" class="tag" target="_blank" rel="noopener nofollow">#科技/cplus</a><br>
<a rel="noopener nofollow" class="external-link" href="https://oi-wiki.org/lang/op/#c-%E8%BF%90%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E7%BA%A7%E6%80%BB%E8%A1%A8" target="_blank">https://oi-wiki.org/lang/op/#c-%E8%BF%90%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E7%BA%A7%E6%80%BB%E8%A1%A8</a>]]></description><link>technology\collegeproject\编程语言\c++\c++-运算符优先级总表.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/C++/C++ 运算符优先级总表.md</guid><pubDate>Sun, 14 Apr 2024 02:56:20 GMT</pubDate></item><item><title><![CDATA[C++关于vector做返回值的引用细节]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/cplus" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/cplus</a> 
 <br><a href=".?query=tag:科技\cplus" class="tag" target="_blank" rel="noopener nofollow">#科技/cplus</a><br><br>在C++中，当函数返回一个vector时，可以选择在返回类型中使用引用（&amp;）或者不使用引用的方式。这两种方式有一些区别，主要涉及到拷贝构造和性能。<br>
<br>
使用引用 (&amp;)：
std::vector&lt;int&gt;&amp; functionWithRefReturn() {
    std::vector&lt;int&gt; myVector = {1, 2, 3, 4, 5};
    return myVector;
}


<br>优点： 避免了拷贝构造，返回的是原始向量的引用，没有额外的开销。
<br>缺点： 可能导致悬空引用（dangling reference）问题，因为函数结束后局部变量 myVector 将被销毁，但引用仍然指向已经被销毁的对象。所以这种写法是错误的。


<br>
不使用引用：
std::vector&lt;int&gt; functionWithoutRefReturn() {
    std::vector&lt;int&gt; myVector = {1, 2, 3, 4, 5};
    return myVector;
}


<br>优点： 返回的是原始向量的副本，避免了悬空引用的问题。
<br>缺点： 有一定的性能开销，因为需要进行向量的拷贝构造。


<br>在某些情况下，还可以使用移动语义（move semantics）来提高性能。C++11引入了右值引用和移动构造函数，可以通过std::move将临时对象的所有权转移给返回的对象，减少了拷贝的开销。示例如下：<br>std::vector&lt;int&gt; functionWithMoveReturn() {
    std::vector&lt;int&gt; myVector = {1, 2, 3, 4, 5};
    return std::move(myVector);
}
<br>在使用移动语义时，需要注意避免悬空引用的问题，确保不再使用已经移动的对象。<br><br>以下是两种常见的方法：<br>
<br>静态成员变量或全局变量：您可以将要返回的std::vector&lt;int&gt;对象声明为静态成员变量或全局变量。这样，它的生命周期将会延长到整个程序的运行期间，因此可以安全地返回对它的引用。但是，使用全局变量或静态成员变量需要谨慎使用，因为它们可能会引入全局状态和潜在的并发访问问题。
<br>std::vector&lt;int&gt; myVector = {1, 2, 3, 4, 5};

std::vector&lt;int&gt;&amp; functionWithRefReturn() {
    return myVector;
}
<br>
<br>使用动态内存分配：您可以在堆上动态分配std::vector&lt;int&gt;对象，并返回对它的引用。这样，对象的生命周期将由您自己来管理，可以在需要时手动释放内存。但是，需要确保在不再需要引用时释放内存，以避免内存泄漏。
<br>std::vector&lt;int&gt;&amp; functionWithRefReturn() {
    std::vector&lt;int&gt;* myVector = new std::vector&lt;int&gt;({1, 2, 3, 4, 5});
    return *myVector;
}

// 在使用完引用后手动释放内存
std::vector&lt;int&gt;&amp; returnedVector = functionWithRefReturn();
// 使用returnedVector...
delete &amp;returnedVector;
<br>请注意，在使用动态内存分配时，需要特别注意避免悬空引用和内存泄漏。确保在不再需要引用时手动释放内存是非常重要的。<br>无论您选择哪种方法，都需要权衡使用引用而不是拷贝构造函数所带来的潜在问题和风险。确保您理解代码的生命周期和内存管理，以避免出现错误和不必要的复杂性。]]></description><link>technology\collegeproject\编程语言\c++\c++关于vector做返回值的引用细节.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/C++/C++关于vector做返回值的引用细节.md</guid><pubDate>Mon, 26 Feb 2024 03:51:36 GMT</pubDate></item><item><title><![CDATA[Python应用]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能</a> <a class="tag" href="?query=tag:项目/知识储备" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/知识储备</a> <a class="tag" href="?query=tag:科技/工具" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具</a> 
 <br><a href=".?query=tag:科技\人工智能" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能</a> <br><br>
<br>与c语言的不同，不需main函数，每个文件可以独立运行
<br>具有大量第三方库
<br>解释性语言是一步一执行，不像c/c++需要编译成可执行文件再执行
<br>再python中debug用pdb，c/c++用gdb，使用断点和命令查看变量值，不要用print
<br><a href=".?query=tag:项目\知识储备" class="tag" target="_blank" rel="noopener nofollow">#项目/知识储备</a><br>
<a href=".?query=tag:科技\工具" class="tag" target="_blank" rel="noopener nofollow">#科技/工具</a> <br><br>查看anaconda配置信息：<br>
conda info<br>
查看虚拟环境列表：<br>
conda env list<br>
anaconda换源：<br>
conda config --add channels <a rel="noopener nofollow" class="external-link" href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/" target="_blank">http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</a><br>
conda config --add channels <a rel="noopener nofollow" class="external-link" href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/" target="_blank">http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</a><br>
conda config --set show_channel_urls yes<br>
更改anaconda虚拟环境默认安装位置：<br>
conda config --add envs_dirs D:\software\anaconda\envs<br>
新建虚拟环境：<br>
conda create -n yourname python=3.7<br>
启用虚拟环境<br>
conda activate yourname<br>
删除虚拟环境<br>
conda remove -n yourname --all<br>
指定源安装<br>
pip install opencv-python -i <a rel="noopener nofollow" class="external-link" href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank">https://pypi.tuna.tsinghua.edu.cn/simple</a><br>
注意：如果pypi换成mirrors就有问题<br><br><a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1ao4y1E7Vm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1ao4y1E7Vm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">【python环境安装】超详细的Anaconda(python)环境配置及pycharm专业版安装教程，适合完全零基础学习！！_哔哩哔哩_bilibili</a><br><br><a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1bQ4y1n7sn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1bQ4y1n7sn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">Python环境配置小白教学，Anaconda+VScode安装与配置_哔哩哔哩_bilibili</a><br>注意事项：域名一定是http<br>
注意：git clone 用git clone <a rel="noopener nofollow" class="external-link" href="https://gitclone.com/github.com/" target="_blank">https://gitclone.com/github.com/</a>...<br><br>本章节我们主要结合前面所学的知识点来介绍Python数据结构。<br><br><br>Python中列表是可变的，这是它区别于字符串和元组的最重要的特点，一句话概括即：列表可以修改，而字符串和元组不能。<br>以下是 Python 中列表的方法：<br><br>下面示例演示了列表的大部分方法：<br><br>&gt;&gt;&gt; a = [66.25, 333, 333, 1, 1234.5]  
&gt;&gt;&gt; print(a.count(333), a.count(66.25), a.count('x'))  
2 1 0  
&gt;&gt;&gt; a.insert(2, -1)  
&gt;&gt;&gt; a.append(333)  
&gt;&gt;&gt; a  
[66.25, 333, -1, 333, 1, 1234.5, 333]  
&gt;&gt;&gt; a.index(333)  
1  
&gt;&gt;&gt; a.remove(333)  
&gt;&gt;&gt; a  
[66.25, -1, 333, 1, 1234.5, 333]  
&gt;&gt;&gt; a.reverse()  
&gt;&gt;&gt; a  
[333, 1234.5, 1, 333, -1, 66.25]  
&gt;&gt;&gt; a.sort()  
&gt;&gt;&gt; a  
[-1, 1, 66.25, 333, 333, 1234.5]  

注意：类似 insert, remove 
<br>或 sort 等修改列表的方法没有返回值。<br><br><br>列表方法使得列表可以很方便的作为一个堆栈来使用，堆栈作为特定的数据结构，最先进入的元素最后一个被释放（后进先出）。用 append() 方法可以把一个元素添加到堆栈顶。用不指定索引的 pop() 方法可以把一个元素从堆栈顶释放出来。例如：<br><br>&gt;&gt;&gt; stack = [3, 4, 5]  
&gt;&gt;&gt; stack.append(6)  
&gt;&gt;&gt; stack.append(7)  
&gt;&gt;&gt; stack  
[3, 4, 5, 6, 7]  
&gt;&gt;&gt; stack.pop()  
7  
&gt;&gt;&gt; stack  
[3, 4, 5, 6]  
&gt;&gt;&gt; stack.pop()  
6  
&gt;&gt;&gt; stack.pop()  
5  
&gt;&gt;&gt; stack  
[3, 4]  

<br><br><br>也可以把列表当做队列用，只是在队列里第一加入的元素，第一个取出来；但是拿列表用作这样的目的效率不高。在列表的最后添加或者弹出元素速度快，然而在列表里插入或者从头部弹出速度却不快（因为所有其他的元素都得一个一个地移动）。<br><br>&gt;&gt;&gt; from collections import deque  
&gt;&gt;&gt; queue = deque(["Eric", "John", "Michael"])  
&gt;&gt;&gt; queue.append("Terry")           # Terry arrives  
&gt;&gt;&gt; queue.append("Graham")          # Graham arrives  
&gt;&gt;&gt; queue.popleft()                 # The first to arrive now leaves  
'Eric'  
&gt;&gt;&gt; queue.popleft()                 # The second to arrive now leaves  
'John'  
&gt;&gt;&gt; queue                           # Remaining queue in order of arrival  
deque(['Michael', 'Terry', 'Graham'])  

<br><br><br>列表推导式提供了从序列创建列表的简单途径。通常应用程序将一些操作应用于某个序列的每个元素，用其获得的结果作为生成新列表的元素，或者根据确定的判定条件创建子序列。<br>每个列表推导式都在 for 之后跟一个表达式，然后有零到多个 for 或 if 子句。返回结果是一个根据表达从其后的 for 和 if 上下文环境中生成出来的列表。如果希望表达式推导出一个元组，就必须使用括号。<br>这里我们将列表中每个数值乘三，获得一个新的列表：<br>&gt;&gt;&gt; vec = [2, 4, 6]  
&gt;&gt;&gt; [3*x for x in vec]  
[6, 12, 18]  
<br>现在我们玩一点小花样：<br>&gt;&gt;&gt; [[x, x**2] for x in vec]  
[[2, 4], [4, 16], [6, 36]]  
<br>这里我们对序列里每一个元素逐个调用某方法：<br><br>&gt;&gt;&gt; freshfruit = ['  banana', '  loganberry ', 'passion fruit  ']  
&gt;&gt;&gt; [weapon.strip() for weapon in freshfruit]  
['banana', 'loganberry', 'passion fruit']  
<br>我们可以用 if 子句作为过滤器：<br>&gt;&gt;&gt; [3*x for x in vec if x &gt; 3]  
[12, 18]  
&gt;&gt;&gt; [3*x for x in vec if x &lt; 2]  
[]  
<br>以下是一些关于循环和其它技巧的演示：<br>&gt;&gt;&gt; vec1 = [2, 4, 6]  
&gt;&gt;&gt; vec2 = [4, 3, -9]  
&gt;&gt;&gt; [x*y for x in vec1 for y in vec2]  
[8, 6, -18, 16, 12, -36, 24, 18, -54]  
&gt;&gt;&gt; [x+y for x in vec1 for y in vec2]  
[6, 5, -7, 8, 7, -5, 10, 9, -3]  
&gt;&gt;&gt; [vec1[i]*vec2[i] for i in range(len(vec1))]  
[8, 12, -54]  
<br>列表推导式可以使用复杂表达式或嵌套函数：<br>&gt;&gt;&gt; [str(round(355/113, i)) for i in range(1, 6)]  
['3.1', '3.14', '3.142', '3.1416', '3.14159']  
<br><br><br>Python的列表还可以嵌套。<br>以下实例展示了3X4的矩阵列表：<br>&gt;&gt;&gt; matrix = [  
...     [1, 2, 3, 4],  
...     [5, 6, 7, 8],  
...     [9, 10, 11, 12],  
... ]  
<br>以下实例将3X4的矩阵列表转换为4X3列表：<br>&gt;&gt;&gt; [[row[i] for row in matrix] for i in range(4)]  
[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]  
<br>以上实例也可以使用以下方法来实现：<br>&gt;&gt;&gt; transposed = []  
&gt;&gt;&gt; for i in range(4):  
...     transposed.append([row[i] for row in matrix])  
...  
&gt;&gt;&gt; transposed  
[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]  
<br>另外一种实现方法：<br>&gt;&gt;&gt; transposed = []  
&gt;&gt;&gt; for i in range(4):  
...     # the following 3 lines implement the nested listcomp  
...     transposed_row = []  
...     for row in matrix:  
...         transposed_row.append(row[i])  
...     transposed.append(transposed_row)  
...  
&gt;&gt;&gt; transposed  
[[1, 5, 9], [2, 6, 10], [3, 7, 11], [4, 8, 12]]  
<br><br><br>使用 del 语句可以从一个列表中根据索引来删除一个元素，而不是值来删除元素。这与使用 pop() 返回一个值不同。可以用 del 语句从列表中删除一个切割，或清空整个列表（我们以前介绍的方法是给该切割赋一个空列表）。例如：<br>&gt;&gt;&gt; a = [-1, 1, 66.25, 333, 333, 1234.5]  
&gt;&gt;&gt; del a[0]  
&gt;&gt;&gt; a  
[1, 66.25, 333, 333, 1234.5]  
&gt;&gt;&gt; del a[2:4]  
&gt;&gt;&gt; a  
[1, 66.25, 1234.5]  
&gt;&gt;&gt; del a[:]  
&gt;&gt;&gt; a  
[]  
<br>也可以用 del 删除实体变量：<br>&gt;&gt;&gt; del a
<br><br><br>元组由若干逗号分隔的值组成，例如：<br>&gt;&gt;&gt; t = 12345, 54321, 'hello!'  
&gt;&gt;&gt; t[0]  
12345  
&gt;&gt;&gt; t  
(12345, 54321, 'hello!')  
&gt;&gt;&gt; # Tuples may be nested:  
... u = t, (1, 2, 3, 4, 5)  
&gt;&gt;&gt; u  
((12345, 54321, 'hello!'), (1, 2, 3, 4, 5))  

<br>如你所见，元组在输出时总是有括号的，以便于正确表达嵌套结构。在输入时可能有或没有括号， 不过括号通常是必须的（如果元组是更大的表达式的一部分）。<br><br><br>集合是一个无序不重复元素的集。基本功能包括关系测试和消除重复元素。<br>可以用大括号({})创建集合。注意：如果要创建一个空集合，你必须用 set() 而不是 {} ；后者创建一个空的字典，下一节我们会介绍这个数据结构。<br>以下是一个简单的演示：<br>&gt;&gt;&gt; basket = {'apple', 'orange', 'apple', 'pear', 'orange', 'banana'}  
&gt;&gt;&gt; print(basket)                      # 删除重复的  
{'orange', 'banana', 'pear', 'apple'}  
&gt;&gt;&gt; 'orange' in basket                 # 检测成员  
True  
&gt;&gt;&gt; 'crabgrass' in basket  
False  
<br>&gt;&gt;&gt; # 以下演示了两个集合的操作  
...  
&gt;&gt;&gt; a = set('abracadabra')  
&gt;&gt;&gt; b = set('alacazam')  
&gt;&gt;&gt; a                                  # a 中唯一的字母  
{'a', 'r', 'b', 'c', 'd'}  
&gt;&gt;&gt; a - b                              # 在 a 中的字母，但不在 b 中  
{'r', 'd', 'b'}  
&gt;&gt;&gt; a | b                              # 在 a 或 b 中的字母  
{'a', 'c', 'r', 'd', 'b', 'm', 'z', 'l'}  
&gt;&gt;&gt; a &amp; b                              # 在 a 和 b 中都有的字母  
{'a', 'c'}  
&gt;&gt;&gt; a ^ b                              # 在 a 或 b 中的字母，但不同时在 a 和 b 中  
{'r', 'd', 'b', 'm', 'z', 'l'}  
<br>集合也支持推导式：<br>&gt;&gt;&gt; a = {x for x in 'abracadabra' if x not in 'abc'}  
&gt;&gt;&gt; a  
{'r', 'd'}  
<br><br><br>另一个非常有用的 Python 内建数据类型是字典。<br>序列是以连续的整数为索引，与此不同的是，字典以关键字为索引，关键字可以是任意不可变类型，通常用字符串或数值。<br>理解字典的最佳方式是把它看做无序的键=&gt;值对集合。在同一个字典之内，关键字必须是互不相同。<br>一对大括号创建一个空的字典：{}。<br>这是一个字典运用的简单例子：<br>&gt;&gt;&gt; tel = {'jack': 4098, 'sape': 4139}  
&gt;&gt;&gt; tel['guido'] = 4127  
&gt;&gt;&gt; tel  
{'sape': 4139, 'guido': 4127, 'jack': 4098}  
&gt;&gt;&gt; tel['jack']  
4098  
&gt;&gt;&gt; del tel['sape']  
&gt;&gt;&gt; tel['irv'] = 4127  
&gt;&gt;&gt; tel  
{'guido': 4127, 'irv': 4127, 'jack': 4098}  
&gt;&gt;&gt; list(tel.keys())  
['irv', 'guido', 'jack']  
&gt;&gt;&gt; sorted(tel.keys())  
['guido', 'irv', 'jack']  
&gt;&gt;&gt; 'guido' in tel  
True  
&gt;&gt;&gt; 'jack' not in tel  
False  
<br>构造函数 dict() 直接从键值对元组列表中构建字典。如果有固定的模式，列表推导式指定特定的键值对：<br>&gt;&gt;&gt; dict([('sape', 4139), ('guido', 4127), ('jack', 4098)])  
{'sape': 4139, 'jack': 4098, 'guido': 4127}  

<br>此外，字典推导可以用来创建任意键和值的表达式词典：<br>&gt;&gt;&gt; {x: x**2 for x in (2, 4, 6)}  
{2: 4, 4: 16, 6: 36}  
<br>如果关键字只是简单的字符串，使用关键字参数指定键值对有时候更方便：<br>&gt;&gt;&gt; dict(sape=4139, guido=4127, jack=4098)  
{'sape': 4139, 'jack': 4098, 'guido': 4127}  

<br><br><br>在字典中遍历时，关键字和对应的值可以使用 items() 方法同时解读出来：<br>&gt;&gt;&gt; knights = {'gallahad': 'the pure', 'robin': 'the brave'}  
&gt;&gt;&gt; for k, v in knights.items():  
...     print(k, v)  
...  
gallahad the pure  
robin the brave  
<br>在序列中遍历时，索引位置和对应值可以使用 enumerate() 函数同时得到：<br>&gt;&gt;&gt; for i, v in enumerate(['tic', 'tac', 'toe']):  
...     print(i, v)  
...  
0 tic  
1 tac  
2 toe  
<br>同时遍历两个或更多的序列，可以使用 zip() 组合：<br>&gt;&gt;&gt; questions = ['name', 'quest', 'favorite color']  
&gt;&gt;&gt; answers = ['lancelot', 'the holy grail', 'blue']  
&gt;&gt;&gt; for q, a in zip(questions, answers):  
...     print('What is your {0}?  It is {1}.'.format(q, a))  
...  
What is your name?  It is lancelot.  
What is your quest?  It is the holy grail.  
What is your favorite color?  It is blue.  
<br>要反向遍历一个序列，首先指定这个序列，然后调用 reversed() 函数：<br>&gt;&gt;&gt; for i in reversed(range(1, 10, 2)):  
...     print(i)  
...  
9  
7  
5  
3  
1  
<br>要按顺序遍历一个序列，使用 sorted() 函数返回一个已排序的序列，并不修改原值：<br>&gt;&gt;&gt; basket = ['apple', 'orange', 'apple', 'pear', 'orange', 'banana']  
&gt;&gt;&gt; for f in sorted(set(basket)):  
...     print(f)  
...  
apple  
banana  
orange  
pear
]]></description><link>technology\collegeproject\编程语言\python\python应用.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/Python/Python应用.md</guid><pubDate>Thu, 28 Mar 2024 10:20:02 GMT</pubDate></item><item><title><![CDATA[python语法问题]]></title><description><![CDATA[ 
 <br><br>格式：变量 = {key1 : value1, key2: value2…}<br>
空字典定义：<br>
{}<br>
dict（）<br>
字典中键不能重复，是唯一的，但是值可以重复<br>
字典中的键要见名知意，体现字典可以见名知意的特性]]></description><link>technology\collegeproject\编程语言\python\python语法问题.html</link><guid isPermaLink="false">Technology/CollegeProject/编程语言/Python/python语法问题.md</guid><pubDate>Thu, 02 May 2024 08:04:24 GMT</pubDate></item><item><title><![CDATA[习题三-同步、通信和死锁]]></title><description><![CDATA[ 
 <br><img alt="{55A18A6E-894A-422B-AC08-B3977B3CF3FE}.png" src="\lib\media\{55a18a6e-894a-422b-ac08-b3977b3cf3fe}.png"><br><img alt="Pasted image 20241104222148.png" src="\lib\media\pasted-image-20241104222148.png"><br><img alt="{20EFBA93-D14F-4562-A10F-844363545C6A}.png" src="\lib\media\{20efba93-d14f-4562-a10f-844363545c6a}.png"><br>
<img alt="Pasted image 20241104222204.png" src="\lib\media\pasted-image-20241104222204.png"><br>
<img alt="Pasted image 20241104222222.png" src="\lib\media\pasted-image-20241104222222.png"><br><img alt="{F284A7DF-7998-4B97-8C20-31F2D51F08BA}.png" src="\lib\media\{f284a7df-7998-4b97-8c20-31f2d51f08ba}.png"><br>
<img alt="扫描件_process daught e-i()_001_edit_118642670279361.jpg" src="\lib\media\扫描件_process-daught-e-i()_001_edit_118642670279361.jpg">]]></description><link>technology\collegeproject\操作系统\课程作业\习题三-同步、通信和死锁.html</link><guid isPermaLink="false">Technology/CollegeProject/操作系统/课程作业/习题三-同步、通信和死锁.md</guid><pubDate>Mon, 04 Nov 2024 14:22:35 GMT</pubDate><enclosure url="lib\media\{55a18a6e-894a-422b-ac08-b3977b3cf3fe}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{55a18a6e-894a-422b-ac08-b3977b3cf3fe}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[大作业（存储管理）]]></title><description><![CDATA[ 
 <br><br><br>
<br>开辟一块内存空间，作为模拟内存 (malloc)

<br>空间大小为  字节


<br>假设系统的页面大小为 256 字节

<br>每个页表项占 4 个字节
<br>系统的物理页面数为 
<br>每个页表正好占一个页面


<br>用位图刻画内存页面的分配状态

<br>可以用一个辅助的变量来对空闲内存页面计数


<br>每个进程的虚拟地址空间也是  字节
<br>每个进程分配 9 个页面（连页表一共 10 个页面）
<br>创建 12 个作业，并模拟作业的运行

<br>创建 12 个文件，模拟磁盘上的代码和数据
<br>可以在文件的第  字节处写入 &lt;作业号，页面号&gt;，以识别相应的页面


<br><br>
<br>
如果系统中的空闲页面数 &lt; 10

<br>因为页表也要占用一个页面，所以至少要有 10 个空闲页面才行。
<br>如果空闲页面数不足 10，则作业需要等待空闲页面数。


<br>
否则，为作业分配 9 个空闲页框和一个存放页表的页框，记录下页表的基地址

<br>需要修改位图和空闲页框计数器的值。
<br>注意互斥访问。


<br>
模拟进程的访问行为

<br>每个进程随机生成 200 次逻辑地址，每次地址访问后休眠（0-100ms）中的一个随机值。
<br>逻辑地址的生成规则：进程对第  号页面的访问概率正比于 。

<br>如果对应的逻辑地址已经在内存，则直接访问。
<br>如果对应的逻辑地址不在内存，则读文件，将文件对应的页面数据载入内存中相应的块，并修改页表项。


<br>在此过程中，可能会发生页面替换，页面替换采用 FIFO 和 LRU 两种替换算法。
<br>输出进程的本次访问记录（进程号，虚拟地址，虚拟地址页面的内容，物理地址，物理地址中的内容）。
<br>统计每个进程的缺页中断次数


<br>
进程运行结束

<br>输出进程的缺页中断率
<br>唤醒可能等待内存资源的作业


<br><br><br><br>
<br>理解操作系统中的内存管理机制。
<br>实现两种页面替换算法：FIFO（先进先出）和 LRU（最近最少使用）。
<br>观察不同页面替换算法下的缺页中断情况。
<br><br>
<br>
FIFO（先进先出）：

<br>选择最早进入内存的页面进行替换。
<br>实现简单，但可能导致频繁的缺页中断，尤其是在工作集变化较快的情况下。


<br>
LRU（最近最少使用）：

<br>选择最长时间未被使用的页面进行替换。
<br>更接近理想页面替换策略，但在实现上相对复杂一些。


<br><br><br># 定义常量
MEMORY_SIZE = 2 ** 14  # 2^14 字节
PAGE_SIZE = 256        # 256 字节
NUM_PAGES = MEMORY_SIZE // PAGE_SIZE
PHYSICAL_FRAMES = 2 ** 6  # 2^6 物理页面数
PROCESS_PAGE_COUNT = 9    # 每个进程分配9个页面
TOTAL_PROCESSES = 12      # 总共12个进程
<br><br>class PageTableEntry:
    def __init__(self):
        self.valid = False       # 页面是否有效
        self.frame_number = -1   # 物理帧号

class Process:
    def __init__(self):
        self.page_table = [PageTableEntry() for _ in range(NUM_PAGES)]  # 初始化页表条目
        self.base_frame = -1  # 基页表索引
<br><br>def initialize_memory():
    """初始化内存空间，用随机数填充"""
    random.seed(time.time())
    return bytearray(random.getrandbits(8) for _ in range(MEMORY_SIZE))
<br><br>def initialize_free_frames():
    """初始化空闲帧列表"""
    free_frames = list(range(PHYSICAL_FRAMES))  # 创建一个包含所有物理帧编号的列表
    free_frame_count = PHYSICAL_FRAMES         # 空闲帧数量初始为总物理帧数
    return free_frames, free_frame_count
<br><br>def allocate_page(free_frames, free_frame_count):
    """分配一个物理帧"""
    if free_frame_count == 0:
        return -1, free_frames, free_frame_count  # 如果没有空闲帧，返回-1
    frame = free_frames.pop()                     # 弹出一个空闲帧
    free_frame_count -= 1                         # 减少空闲帧计数
    return frame, free_frames, free_frame_count

def deallocate_page(frame, free_frames, free_frame_count):
    """释放一个物理帧"""
    free_frames.append(frame)                      # 将帧号加入空闲帧列表
    free_frame_count += 1                          # 增加空闲帧计数
    return free_frames, free_frame_count
<br><br>def load_page(memory, process, logical_page, physical_frame, disk_data):
    """从磁盘加载页面到内存"""
    start_index = logical_page * PAGE_SIZE          # 计算磁盘数据的起始索引
    end_index = start_index + PAGE_SIZE             # 计算磁盘数据的结束索引
    memory[physical_frame * PAGE_SIZE:(physical_frame + 1) * PAGE_SIZE] = disk_data[start_index:end_index]  # 加载页面数据到内存
    process.page_table[logical_page].valid = True     # 标记页表条目为有效
    process.page_table[logical_page].frame_number = physical_frame  # 设置页表条目的物理帧号
<br><br><br>def fifo_replace(fifo_queue, processes, lru_access_time):
    """使用FIFO算法替换一个页面"""
    physical_frame = fifo_queue.pop(0)  # 弹出最早进入队列的帧号
    victim_process = None
    victim_logical_page = -1
    for p in processes:
        for pg in range(PROCESS_PAGE_COUNT):
            if p.page_table[pg].frame_number == physical_frame:
                victim_process = p
                victim_logical_page = pg
                break
        if victim_process is not None:
            break
    if victim_process is not None:
        victim_process.page_table[victim_logical_page].valid = False  # 标记受害者页面为无效
    return physical_frame
<br><br>def lru_replace(lru_access_time, processes):
    """使用LRU算法替换一个页面"""
    min_access_time = float('inf')
    victim_process = None
    victim_logical_page = -1
    victim_physical_frame = -1
    for p in processes:
        for pg in range(PROCESS_PAGE_COUNT):
            if p.page_table[pg].valid and lru_access_time[p.page_table[pg].frame_number] &lt; min_access_time:
                min_access_time = lru_access_time[p.page_table[pg].frame_number]
                victim_process = p
                victim_logical_page = pg
                victim_physical_frame = p.page_table[pg].frame_number
    if victim_process is not None:
        victim_process.page_table[victim_logical_page].valid = False  # 标记受害者页面为无效
    return victim_physical_frame
<br><br>def simulate_process(process, process_id, memory, free_frames, free_frame_count, disk_data, fifo_queue, lru_access_time, replacement_algorithm):
    """模拟进程的行为"""
    page_faults = 0
    cumulative_prob = [0] * (PROCESS_PAGE_COUNT + 1)
    for i in range(PROCESS_PAGE_COUNT):
        cumulative_prob[i + 1] = cumulative_prob[i] + 1 / (i + 1) ** 0.5  # 预先计算累积概率数组

    for _ in range(50):  # 每个进程访问50次，增加访问次数以提高缺页中断的可能性
        r = random.random() * cumulative_prob[-1]  # 生成一个随机数乘以最大累积概率
        logical_page = next(i for i, prob in enumerate(cumulative_prob) if prob &gt; r) - 1  # 根据累积概率选择逻辑页面

        physical_frame = -1
        if process.page_table[logical_page].valid:
            physical_frame = process.page_table[logical_page].frame_number  # 如果页面在内存中，获取其物理帧号
        else:
            page_faults += 1  # 缺页中断次数增加
            print(f"Process {process_id}: 缺页中断，逻辑页面 {logical_page}")

            if free_frame_count == 0:
                # 使用选定的页面置换算法替换一个页面
                if replacement_algorithm == 'FIFO':
                    physical_frame = fifo_replace(fifo_queue, processes, lru_access_time)
                elif replacement_algorithm == 'LRU':
                    physical_frame = lru_replace(lru_access_time, processes)
                fifo_queue.remove(physical_frame)  # 移除被替换的帧号
            else:
                physical_frame, free_frames, free_frame_count = allocate_page(free_frames, free_frame_count)  # 分配一个新的物理帧

            load_page(memory, process, logical_page, physical_frame, disk_data)  # 加载页面到内存
            fifo_queue.append(physical_frame)  # 将新分配的帧号加入FIFO队列
            lru_access_time[physical_frame] = len(lru_access_time) + 1  # 更新最近访问时间

        offset = random.randint(0, PAGE_SIZE - 1)  # 随机生成偏移量
        virtual_address = logical_page * PAGE_SIZE + offset  # 计算虚拟地址
        physical_address = physical_frame * PAGE_SIZE + offset  # 计算物理地址
        value = memory[physical_address]  # 获取物理地址中的值

        print(f"Process {process_id}: 虚拟地址 {virtual_address} -&gt; 物理地址 {physical_address}, 值 {value}")  # 输出访问记录

        time.sleep(random.uniform(0, 0.1))  # 休眠0-100毫秒

    page_fault_rate = page_faults / 50  # 计算缺页中断率
    print(f"进程 {process_id} 结束，缺页中断率 {page_fault_rate:.2%}")  # 输出缺页中断率
<br><br>if __name__ == "__main__":
    memory = initialize_memory()  # 初始化内存
    free_frames, free_frame_count = initialize_free_frames()  # 初始化空闲帧

    # 创建磁盘数据
    disk_data = bytearray()
    for i in range(TOTAL_PROCESSES * PROCESS_PAGE_COUNT):
        disk_data.extend(f"&lt;{i // PROCESS_PAGE_COUNT},{i % PROCESS_PAGE_COUNT}&gt;".encode('utf-8'))  # 写入作业号和页面号
        disk_data.extend(b'\x00' * (PAGE_SIZE - len(disk_data) % PAGE_SIZE))  # 补充剩余字节

    processes = [Process() for _ in range(TOTAL_PROCESSES)]  # 创建所有进程

    fifo_queue = []  # 初始化FIFO队列
    lru_access_time = [0] * PHYSICAL_FRAMES  # 初始化LRU访问时间数组

    # 用户选择页面替换算法
    replacement_algorithm = input("请选择页面替换算法 (FIFO/LRU): ").strip().upper()

    if replacement_algorithm not in ['FIFO', 'LRU']:
        print("无效的选择，默认使用FIFO算法")
        replacement_algorithm = 'FIFO'

    for i in range(TOTAL_PROCESSES):
        processes[i].base_frame, free_frames, free_frame_count = allocate_page(free_frames, free_frame_count)  # 分配基页表帧
        # 初始时不分配具体页面帧，而是等到进程访问时才分配
        simulate_process(processes[i], i, memory, free_frames, free_frame_count, disk_data, fifo_queue, lru_access_time, replacement_algorithm)  # 模拟进程行为
        for j in range(PROCESS_PAGE_COUNT):
            if processes[i].page_table[j].valid:
                free_frames, free_frame_count = deallocate_page(processes[i].page_table[j].frame_number, free_frames, free_frame_count)  # 释放页面帧
        free_frames, free_frame_count = deallocate_page(processes[i].base_frame, free_frames, free_frame_count)  # 释放基页表帧
<br><br>通过运行上述代码并选择不同的页面替换算法，我们可以观察到以下结果：<br>
<br>
FIFO 替换算法：

<br>初始阶段会频繁发生缺页中断，因为所有页面最初都不在内存中。
<br>当物理内存满时，FIFO 会替换最早进入内存的页面，可能导致较高的缺页中断率。


<br>
LRU 替换算法：

<br>同样在初始阶段会发生缺页中断。
<br>相比 FIFO，LRU 更倾向于保留最近使用的页面，因此在某些情况下可能会减少缺页中断次数。


<br><br>通过本次实验，我们成功实现了两种页面替换算法，并观察到了它们在不同场景下的表现差异。这有助于我们更好地理解操作系统中的内存管理和页面替换机制。<br>]]></description><link>technology\collegeproject\操作系统\实验\大作业（存储管理）.html</link><guid isPermaLink="false">Technology/CollegeProject/操作系统/实验/大作业（存储管理）.md</guid><pubDate>Sun, 22 Dec 2024 07:50:30 GMT</pubDate></item><item><title><![CDATA[实验1：Linux基本环境]]></title><description><![CDATA[ 
 <br><br>
<br>VMware
<br>Ubuntu 22.04 
<br><br>Linux操作系统遵循一种被称为文件系统层次结构标准（Filesystem Hierarchy Standard, FHS）的目录结构。这种结构定义了文件和目录应该如何组织，以确保不同Linux发行版之间具有一定程度的一致性。以下是Linux中常见的顶级目录及其用途：<br>
<br>/：根目录，是整个文件系统的起点。
<br>/bin：存放系统启动和运行所必需的二进制可执行文件。
<br>/boot：包含启动Linux时使用的核心文件，包括内核和启动加载程序配置。
<br>/dev：设备文件目录，每个设备在该目录下都有一个对应的文件节点。
<br>/etc：系统配置文件的存放位置，比如网络设置、服务配置等。
<br>/home：用户的个人数据存储区，每个用户在此有一个自己的子目录。
<br>/lib 或 /lib64：库文件目录，存放着系统启动或运行/bin及/sbin下的命令所需的共享库。
<br>/media：可移动媒体挂载点，如USB驱动器、CD-ROM等临时挂载点。
<br>/mnt：手动挂载点，通常用于临时安装文件系统。
<br>/opt：提供给第三方软件包使用的安装目录。
<br>/proc：虚拟文件系统，提供有关进程和其他系统信息的实时数据。
<br>/root：超级用户（root）的家目录。
<br>/run：存放应用程序状态信息的临时文件系统。
<br>/sbin：存放系统管理员使用的系统二进制文件。
<br>/srv：存放服务相关的数据。
<br>/sys：与/proc类似，是一个虚拟文件系统，提供了访问内核和系统硬件参数的接口。
<br>/tmp：供所有用户和程序暂时存放文件的地方，重启后通常会被清空。
<br>/usr：用户程序和文件的二级层次结构，它包含了大部分的应用程序和文件。

<br>/usr/bin：存放非关键性的用户命令。
<br>/usr/lib 或 /usr/lib64：存放用户命令相关的库文件。
<br>/usr/local：本地安装软件的位置，不会被系统升级覆盖。
<br>/usr/sbin：存放非关键性的系统管理命令。
<br>/usr/share：架构无关的数据文件存放处。


<br>/var：存放变量数据，如日志文件、缓存文件等。
<br>这个结构有助于保持系统的有序性和一致性，并且使得管理和维护更加容易。不同的Linux发行版可能会有一些小的变化或添加额外的目录来满足特定的需求。<br><br>在Linux中，shell是用户与操作系统内核之间的接口。它接收用户的命令，并将这些命令传递给内核执行。Bash（Bourne Again Shell）是最常用的shell之一。下面是一些基本的Linux shell命令：<br>
<br>
文件和目录操作

<br>ls：列出目录内容。

<br>例如：ls -l 显示详细信息；ls -a 显示隐藏文件。


<br>cd：改变当前工作目录。

<br>例如：cd /path/to/directory


<br>pwd：显示当前工作目录的路径。
<br>mkdir：创建一个新目录。

<br>例如：mkdir new_directory


<br>rm：删除文件或目录。

<br>例如：rm file.txt 删除文件；rm -r directory 递归删除目录及其内容。


<br>cp：复制文件或目录。

<br>例如：cp file.txt /path/to/destination 复制文件；cp -R dir1 /path/to/destination 递归复制目录。


<br>mv：移动文件或重命名文件/目录。

<br>例如：mv file.txt /path/to/destination 移动文件；mv oldname.txt newname.txt 重命名文件。




<br>
查看文件内容

<br>cat：显示文件内容。

<br>例如：cat file.txt


<br>less：分页显示文件内容。

<br>例如：less file.txt 可以使用方向键翻阅，按q退出。


<br>head：显示文件开头部分，默认为前10行。

<br>例如：head -n 20 file.txt 显示前20行。


<br>tail：显示文件结尾部分，默认为后10行。

<br>例如：tail -f logfile.txt 实时显示日志文件的更新。




<br>
搜索文件

<br>find：查找符合特定条件的文件。

<br>例如：find /path/to/search -name "filename"


<br>grep：在文件中搜索文本模式。

<br>例如：grep "search_term" file.txt




<br>
系统信息

<br>uname：显示系统信息。

<br>例如：uname -a 显示所有信息。


<br>df：显示磁盘空间使用情况。

<br>例如：df -h 以人类可读格式显示。


<br>top 或 htop：实时显示系统运行状态。
<br>ps：报告进程的状态。

<br>例如：ps aux 列出所有用户的所有进程。




<br>
网络相关

<br>ping：测试主机之间网络连接。

<br>例如：ping www.example.com


<br>ifconfig 或 ip：配置网络接口。
<br>netstat：显示网络连接、路由表等。

<br>例如：netstat -tuln 显示TCP和UDP监听端口。




<br>
权限管理

<br>chmod：更改文件或目录权限。

<br>例如：chmod 755 file.txt 设置权限。


<br>chown：更改文件或目录的所有者。

<br>例如：chown user:group file.txt 更改所有权。


<br>sudo：以另一个用户身份执行命令，通常用来获取超级用户权限。

<br>例如：sudo apt-get update




<br><br>Vim（Vi IMproved）是一个高度可配置的文本编辑器，适用于命令行界面。它基于早期的vi编辑器，并添加了许多改进和新功能。下面是Vim的一些基本指令：<br><br>
<br>打开或创建一个文件：vim filename
<br><br>Vim主要分为几种模式：<br>
<br>普通模式（Normal Mode）：当你启动Vim时，默认进入的是普通模式。这个模式下可以进行移动、删除、复制等操作。
<br>插入模式（Insert Mode）：在这个模式下你可以输入文字。从普通模式按下i键即可进入插入模式。
<br>可视模式（Visual Mode）：用于选择文本区域，类似于其他编辑器中的高亮选择。在普通模式下按v进入字符可视模式，按V进入行可视模式，按Ctrl+v进入块可视模式。
<br>命令行模式（Command-line Mode）：执行如保存文件、退出编辑器等命令。在任何模式下按:或/键都可以进入命令行模式。
<br><br>
<br>
移动

<br>h：左移
<br>j：下移
<br>k：上移
<br>l：右移
<br>0：移动到当前行首
<br>^：移动到当前行第一个非空白字符
<br>$：移动到当前行尾
<br>gg：跳转到文件开头
<br>G：跳转到文件结尾
<br>{数字}G：跳转到指定行，例如10G跳转到第10行


<br>
插入

<br>i：在当前位置之前插入
<br>I：在当前行首开始插入
<br>a：在当前位置之后插入
<br>A：在当前行尾开始插入
<br>o：在当前行下面新开一行并进入插入模式
<br>O：在当前行上面新开一行并进入插入模式


<br>
删除

<br>x：删除光标所在位置的一个字符
<br>d{移动命令}：删除由移动命令指定的文本范围

<br>例如：dw 删除一个单词；dd 删除整行


<br>D：删除从光标到行尾的所有内容


<br>
复制与粘贴

<br>y{移动命令}：复制由移动命令指定的文本

<br>例如：yw 复制一个单词；yy 复制整行


<br>p：在光标后粘贴
<br>P：在光标前粘贴


<br>
撤销与重做

<br>u：撤销上一步操作
<br>Ctrl+r：重做被撤销的操作


<br>
搜索

<br>/pattern：向下搜索模式
<br>?pattern：向上搜索模式
<br>n：重复上次搜索（向前）
<br>N：反向重复上次搜索（向后）


<br>
保存与退出

<br>:w：保存文件但不退出
<br>:q：退出编辑器，如果文件有未保存更改，则不允许退出
<br>:q!：强制退出，放弃所有未保存更改
<br>:wq 或 ZZ：保存并退出
<br>:x：保存并退出，如果文件没有修改则不会写入时间戳


]]></description><link>technology\collegeproject\操作系统\实验\实验1：linux基本环境.html</link><guid isPermaLink="false">Technology/CollegeProject/操作系统/实验/实验1：Linux基本环境.md</guid><pubDate>Fri, 27 Sep 2024 02:50:31 GMT</pubDate></item><item><title><![CDATA[实验2：用户管理与文件权限]]></title><description><![CDATA[ 
 <br><br>在 Linux 系统中，包括通过 WSL（Windows Subsystem for Linux）运行的 Linux 发行版，你可以使用 ls 命令来查看文件和目录的权限。这里有几个常用的命令选项和方法来检查文件或目录的权限：<br><br>ls -l 命令以长格式列出文件和目录信息，其中包括权限、所有者、组、大小、修改日期以及名称等信息。<br>ls -l [directory]
<br>例如，如果你想查看当前目录下所有文件和子目录的详细信息，可以运行：<br>ls -l
<br>输出示例：<br>-rw-r--r-- 1 user group 4096 Jan 29 14:33 file.txt
drwxr-xr-x 2 user group 4096 Jan 29 14:33 folder
<br>在上述例子中，第一列 -rw-r--r-- 和 drwxr-xr-x 就是文件/目录的权限信息。这些信息分为四部分：<br>
<br>第一个字符表示文件类型：- 表示普通文件，d 表示目录。
<br>接下来的三个字符 (rw-) 表示文件所有者的权限。
<br>再接下来的三个字符 (r--) 表示文件所属组的权限。
<br>最后的三个字符 (r--) 表示其他用户的权限。
<br>权限字符的含义如下：<br>
<br>r (读) - 允许读取文件内容或列出目录内容。
<br>w (写) - 允许修改文件内容或修改目录中的内容。
<br>x (执行) - 允许执行文件或进入目录。
<br><img alt="{B107CA30-B8B1-49D7-8834-FC4C00AE24BC}.png" src="\lib\media\{b107ca30-b8b1-49d7-8834-fc4c00ae24bc}.png"><br><br>umask 是 Unix 和类 Unix 系统（包括 Linux）中的一个命令和环境设置，用于确定新创建文件和目录的默认权限。umask 设置了一组权限位，这些权限位会被从文件或目录的默认最大权限中移除，从而得到实际的初始权限。<br><br>
<br>对于普通文件，默认的最大权限是 666（即 -rw-rw-rw-），表示所有者、所属组和其他用户都有读写权限。
<br>对于目录，默认的最大权限是 777（即 drwxrwxrwx），表示所有者、所属组和其他用户都有读、写和执行权限。
<br><br>umask 的值是一个三位数的八进制数，每个数字代表不同用户的权限屏蔽：<br>
<br>第一个数字：所有者的权限屏蔽
<br>第二个数字：所属组的权限屏蔽
<br>第三个数字：其他用户的权限屏蔽
<br>在每个数字中：<br>
<br>0 表示不屏蔽任何权限。
<br>1 表示屏蔽执行权限。
<br>2 表示屏蔽写权限。
<br>4 表示屏蔽读权限。
<br>7 表示屏蔽读、写和执行权限。
<br><br>实际权限 = 默认最大权限 - umask<br>例如，如果 umask 设置为 022，那么：<br>
<br>对于文件，实际权限将是 666 - 022 = 644（即 -rw-r--r--）。
<br>对于目录，实际权限将是 777 - 022 = 755（即 drwxr-xr-x）。
<br><br>你可以在终端中输入以下命令来查看当前的 umask 设置：<br>umask
<br>输出通常会显示为一个八进制数值，比如 0022 或 0002。<br><br>你可以通过在终端中运行 umask 命令并指定一个新的值来临时改变 umask。例如，要将 umask 设置为 027，可以这样做：<br>umask 027
<br>这会使得新创建的文件具有 640 权限（-rw-r-----），而新创建的目录具有 750 权限（drwxr-x---）。<br>如果想永久更改 umask 设置，可以在 shell 的配置文件（如 .bashrc 或 .profile）中添加 umask 命令，这样每次登录时都会自动应用这个设置。<br><img alt="{D7C0A6F2-698E-46D8-9C2A-A8EFD77F03DC}.png" src="\lib\media\{d7c0a6f2-698e-46d8-9c2a-a8efd77f03dc}.png"><br><br><img alt="{9F38A0E7-20F0-455B-A541-AA9AF3CB6AD9}.png" src="\lib\media\{9f38a0e7-20f0-455b-a541-aa9af3cb6ad9}.png"><br>
<img alt="{E9A4D00D-25B3-4C0B-BB1A-41C198316B26}.png" src="\lib\media\{e9a4d00d-25b3-4c0b-bb1a-41c198316b26}.png"><br>首先，为系统添加四个用户，分别为他们设置密码，并在/home下创建一个共享目录work：<br>sudo useradd -d /home/alice -m alice
sudo useradd -d /home/bob -m bob
sudo useradd -d /home/john -m john
sudo useradd -d /home/mike -m mike

passwd alice
passwd bob
passwd john
passwd mike

mkdir /home/work
<br>接着，创建一个用户组workgroup，将alice, bob, john加入到用户组workgroup，并将目录work的所有权改为alice和workgroup：<br>sudo groupadd workgroup
sudo usermod -aG workgroup alice
sudo usermod -aG workgroup bob
sudo usermod -aG workgroup john

chown alice.workgroup /home/work
<br>现在，修改work目录的权限，使得属组内的用户对该目录具有完全访问权限，而属组外的用户对该目录没有访问权限：<br>chmod ug+rwX,o-rwx /home/work
<br>尝试以bob的身份在work目录下创建文件bob.txt：<br>su - bob
cd /home/work
touch bob.txt
<br>尝试以john的身份查看或修改bob.txt：<br>su - john
cd /home/work
cat bob.txt
<br>尝试以mike的身份查看或修改bob.txt：<br>su - mike
cd /home/work
cat bob.txt
<br>以mike的身份在其工作目录下创建mike.txt文件，并尝试将其移动到/home/work目录下：<br>su - mike
mkdir mike
chown mike.mike mike
touch mike.txt
mv mike.txt /home/work/
<br>总结一下，这些命令演示了如何在Linux中管理用户和组权限，以及如何限制和授予对特定目录的访问权限。<br><br>
<br>
添加四个用户，分别为他们设置密码，并在/home下创建一个共享目录work，创建一个用户组workgroup，将alice, bob, john加入到用户组workgroup，并将目录work的所有权改为alice和workgroup。修改work目录的权限，使得属组内的用户对该目录具有完全访问权限，而属组外的用户对该目录没有访问权限<br>
<img alt="{BAE6BCC0-441C-49F9-899E-270E4584770E}.png" src="\lib\media\{bae6bcc0-441c-49f9-899e-270e4584770e}.png">

<br>
尝试以bob的身份在work目录下创建文件bob.txt <img alt="{608D2A0F-22ED-4DA2-A190-BC6AB8EC321C}.png" src="\lib\media\{608d2a0f-22ed-4da2-a190-bc6ab8ec321c}.png">

<br>
尝试以john的身份查看或修改bob.txt：<img alt="{F2B7F6F4-E2D8-426B-8934-FCB9CA7250BB}.png" src="\lib\media\{f2b7f6f4-e2d8-426b-8934-fcb9ca7250bb}.png">

<br>
修改组权限后再次修改bob.txt<img alt="{80CFE216-2E07-40B8-B41E-097B2D6ADCC0}.png" src="\lib\media\{80cfe216-2e07-40b8-b41e-097b2d6adcc0}.png">

<br>
初始尝试更改mike.txt目录失败 <img alt="{46FC50F2-8566-4CB2-A79D-9C2239CABED6}.png" src="\lib\media\{46fc50f2-8566-4cb2-a79d-9c2239cabed6}.png">

<br>
发现没有将mike添加到workgroup中<img alt="{295BF28A-E412-4A3E-88EC-49121AD6AA44}.png" src="\lib\media\{295bf28a-e412-4a3e-88ec-49121ad6aa44}.png">

]]></description><link>technology\collegeproject\操作系统\实验\实验2：用户管理与文件权限.html</link><guid isPermaLink="false">Technology/CollegeProject/操作系统/实验/实验2：用户管理与文件权限.md</guid><pubDate>Fri, 18 Oct 2024 04:03:55 GMT</pubDate><enclosure url="lib\media\{b107ca30-b8b1-49d7-8834-fc4c00ae24bc}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{b107ca30-b8b1-49d7-8834-fc4c00ae24bc}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验3：进程管理及调试]]></title><description><![CDATA[ 
 <br><br>在 Linux 系统中，进程管理是一个非常重要的任务，它涉及到创建、监控、控制和终止进程。以下是一些常用的命令和工具，用于管理和操作 Linux 中的进程：<br><br>
<br>
ps：显示当前终端的进程。
ps

你可以使用不同的选项来获取更详细的信息：
ps -ef  # 显示所有用户的所有进程
ps -aux  # 显示所有进程的详细信息


<br>
top：实时显示系统中各个进程的状态。
top

top 命令会持续更新并显示系统的资源使用情况和进程状态。

<br>
htop：一个交互式的进程查看器，提供了比 top 更友好的界面。
htop

如果你没有安装 htop，可以使用包管理器进行安装：
sudo apt-get install htop  # Debian/Ubuntu
sudo yum install htop      # CentOS/RHEL


<br>
pgrep：根据名称或其他属性查找进程 ID (PID)。
pgrep process_name


<br>
pkill：根据名称或其他属性发送信号给进程。
pkill process_name


<br><br>
<br>
后台运行：在命令后面加上 &amp; 可以将进程放到后台运行。
command &amp;


<br>
nohup：使进程在关闭终端后仍然继续运行。
nohup command &amp;

输出会被重定向到 nohup.out 文件，除非你指定了其他输出文件。

<br>
screen 或 tmux：多窗口管理器，可以在断开连接后继续运行会话。
screen
tmux


<br><br>
<br>
kill：向进程发送信号，最常用的是 SIGTERM（默认）和 SIGKILL。
kill &lt;PID&gt;
kill -9 &lt;PID&gt;  # 发送 SIGKILL 信号


<br>
killall：根据名称杀死所有匹配的进程。
killall process_name


<br>
nice 和 renice：调整进程的优先级。
nice -n &lt;priority&gt; command  # 启动时设置优先级
renice &lt;priority&gt; -p &lt;PID&gt;  # 调整现有进程的优先级


<br><br>
<br>
free：显示系统内存使用情况。
free -m  # 以 MB 为单位显示


<br>
df：显示磁盘空间使用情况。
df -h  # 以人类可读的方式显示


<br>
iostat：显示 CPU 使用率和磁盘 I/O 统计信息。
iostat -x 1  # 每秒更新一次


<br>
vmstat：报告虚拟内存统计信息。
vmstat 1  # 每秒更新一次


<br><br>
<br>
pstree：以树状图显示进程及其子进程。
pstree


<br>
strace：跟踪系统调用和信号。
strace -p &lt;PID&gt;


<br>
lsof：列出打开的文件和网络连接。
lsof -p &lt;PID&gt;


<br>
netstat 或 ss：显示网络连接、路由表、接口统计等信息。
netstat -tuln  # 显示所有监听端口
ss -tuln  # 替代 netstat 的现代工具


<br><br><img alt="{D36ECE61-8155-426E-AB12-C0236BFFE809}.png" src="\lib\media\{d36ece61-8155-426e-ab12-c0236bffe809}.png"><br>
为了演示如何编写一个简单的 shell 程序并按照你的要求执行一系列操作，我将为你提供一个简单的 shell 脚本 badproc.sh，它会在后台无限循环创建和删除文件。注意，这个脚本只是为了演示目的，实际应用中应避免这样的行为。<br><br>在文本编辑器中创建一个名为 badproc.sh 的文件，并输入以下内容：<br>#!/bin/bash

while true; do
    mkdir testdir
    sleep 1
    rmdir testdir
done
<br><br>使用 chmod 命令为 badproc.sh 添加可执行权限：<br>chmod +x badproc.sh
<br><br>在后台执行 badproc.sh：<br>./badproc.sh &amp;
<br><br>使用 ps 查找 badproc.sh 的进程号：<br>ps aux | grep badproc.sh
<br><br>找到进程号后，使用 kill 命令杀死该进程：<br>kill &lt;PID&gt;
<br>替换 &lt;PID&gt; 为实际的进程号。<br><br>
<br>
创建 badproc.sh：
echo '#!/bin/bash' &gt; badproc.sh
echo 'while true; do mkdir testdir; sleep 1; rmdir testdir; done' &gt;&gt; badproc.sh


<br>
增加可执行权限：
chmod +x badproc.sh


<br>
在后台执行 badproc.sh：
./badproc.sh &amp;


<br>
查看进程号：
ps aux | grep badproc.sh


<br>
杀死进程：
kill &lt;PID&gt;


<br>
删除目录和文件（如果有需要的话）：
rm -r /path/to/files/directory


<br><br><img alt="{47555368-53CA-4DF0-9A89-E88518AE4CA1}.png" src="\lib\media\{47555368-53ca-4df0-9a89-e88518ae4ca1}.png"><br><br>
<br>创建badproc.sh<img alt="{75F3EF47-2D10-439B-BE09-F95E4C59836A}.png" src="\lib\media\{75f3ef47-2d10-439b-be09-f95e4c59836a}.png">
<br>杀死badproc进程<img alt="{C5FF8668-040D-44C7-8D58-3F2C14DEF42A}.png" src="\lib\media\{c5ff8668-040d-44c7-8d58-3f2c14def42a}.png">
<br>fork程序及调试<img alt="{305D684D-1E13-41E3-A826-3A0D7C57CEF3}.png" src="\lib\media\{305d684d-1e13-41e3-a826-3a0d7c57cef3}.png">
]]></description><link>technology\collegeproject\操作系统\实验\实验3：进程管理及调试.html</link><guid isPermaLink="false">Technology/CollegeProject/操作系统/实验/实验3：进程管理及调试.md</guid><pubDate>Fri, 18 Oct 2024 08:07:34 GMT</pubDate><enclosure url="lib\media\{d36ece61-8155-426e-ab12-c0236bffe809}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{d36ece61-8155-426e-ab12-c0236bffe809}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验4：Linux编程环境]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/操作系统" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统</a> 
 <br><a href=".?query=tag:科技\操作系统" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统</a><br><br>熟悉Linux编程环境<br><br>
<br>
使用gedit hello.c命令在主文件夹下创建一个hello.c文件

<br>
在hello.c文件中编写程序后将其保存

<br>
预处理阶段：使用gcc -E hello.c -o hello.i gedit hello.i得到预处理之后hello.i文件文本）

<br>
编译阶段：使用gcc -S hello.i -o hello.s gedit hello.s得到汇编代码（文本）

<br>
汇编阶段：使用gcc -c hello.s -o hello.o gedit hello.o得到可重定向目标程序（二进制）

<br>
链接阶段：使用gcc hello.o -o hello gedit hello得到可执行目标程序（二进制）

<br>
运行阶段：使用./hello得到运行结果

<br><br><br>输入以下代码，生成文件hello.c<br>vim hello.c
<br>#include &lt;stdio.h&gt;

#define DISPLAY "hello c!"

int main(void)

{

    printf("%s\n", DISPLAY);

    return 0;

}

<br><br>gcc -E hello.c -o hello.i
<br>E参数 通知gcc对目标文件进行预编译，这里是对文件hello.c文件<br>o参数 是对命令输出结果进行导入操作，这里是把&nbsp;gcc -E hello.c 操作结果输出到文件hello.i（命名要自定义）中进行保存。<br><br>对代码进行语法、语义分析和错误判断，生成汇编代码文件<br> gcc -S hello.i -o hello.s
<br>S参数 通知gcc对目标文件进行编译，这个命令执行完后目录下多了一个hello.s文件，内容如图<br><br>gcc -c hello.s -o hello.o
<br>c参数 通知gcc对目标文件执行指令转换操作，此步骤后得到文件hello.o<br><br>gcc hello.o -o hello
<br>这样就得到了一个可以直接在系统下执行的文件 hello。<br><br>./hello
<br><br>hello c!
<br><br>1. 编写c源程序<br><img alt="Pasted image 20240324140529.png" src="\lib\media\pasted-image-20240324140529.png"><br>2. 预编译(Preprocessing)<br><img alt="Pasted image 20240324140725.png" src="\lib\media\pasted-image-20240324140725.png"><br>3. 编译(Compilation)<br><img alt="Pasted image 20240324140906.png" src="\lib\media\pasted-image-20240324140906.png"><br>
4. 汇编(Assembly) 链接(Linking/Build) 程序运行<br>
<img alt="Pasted image 20240324141238.png" src="\lib\media\pasted-image-20240324141238.png"><br><br>我学习了如何使用cd切换目录，如何使用ls查看当前目录下的文件，如何使用mkdir创建新的目录，如何使用touch创建新的文件等基本命令。<br>接下来我按照这个实验的要求，编写了一个名为hello.c的C程序。<br>写完后，我使用gcc命令将其编译为一个可执行文件。然后我运行./hello命令，成功看到了“Hello, World！”的输出。<br><br>我在这个过程中深化了对Linux的理解，体验到了其强大、灵活的一面。我明白了命令行是如何简化复杂任务的，并且也理解了为何许多开发人员都优先选择使用它。<br>同时，我也体验到了编译并运行一个C程序的过程，我很清楚地看到了程序从代码到可执行文件的转变过程，也理解了作为编程人员，我们是如何通过编程语言表达问题的解决方案，然后通过编译器将其转化为机器能够理解的格式。<br>总的来说，通过这个实验，我加深了对操作系统与编程语言的了解，激发了我对探求更深层次计算机知识的兴趣。我期待接下来的学习和实验过程。]]></description><link>technology\collegeproject\操作系统\实验\实验4：linux编程环境.html</link><guid isPermaLink="false">Technology/CollegeProject/操作系统/实验/实验4：Linux编程环境.md</guid><pubDate>Fri, 18 Oct 2024 08:17:55 GMT</pubDate><enclosure url="lib\media\pasted-image-20240324140529.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240324140529.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验7：进程与线程并发]]></title><description><![CDATA[ 
 <br><br>
<br>有两个文件，现要求统计所有文件中的单词个数.为了加快统计速度，可以使用多线程机制，为每个要统计的文件创建一个线程，用于检测该文件中的单词个数
<br>区分单词的原则:凡是一个非字母或数字的字符跟在字母或数字的后面，那么这个字母或数字就是单词的结尾
<br><br>两个变量不共享变量，各自独自统计各自文件的单词个数。当线程结束后，将统计的单词个数返回给主线程，(注意，作为返回值的变量不能是定义在线程函数中的局部变量）<br>
主程序等两个线程都结束后，将两个返回值相加，得到单词总数<br><br>#include &lt;stdio.h&gt;
#include &lt;pthread.h&gt;
#include &lt;ctype.h&gt;
#include &lt;pthread.h&gt;
#include &lt;stdlib.h&gt;
// 线程函数声明，用于统计单词数量
void *count_words(void*);

// 用于向线程传递文件名，并存放返回值的结构体
struct buf {
    char *filename; // 文件名
    int wc_count;   // 单词计数
} args[2];

// 统计单词数量的线程函数
void *count_words(void *arg) {
    struct buf *ptr = (struct buf*)arg; // 将传入的参数转换为结构体指针
    char *filename = ptr-&gt;filename;      // 获取文件名
    FILE *fp;                             // 文件指针
    int c, prevc = '\0';                 // 当前字符和前一个字符

    // 打开文件进行读取
    if ((fp = fopen(filename, "r")) != NULL) {
        // 逐个字符读取文件
        while ((c = getc(fp)) != EOF) {
            // 如果当前字符不是字母数字且前一个字符是字母数字，则单词计数加一
            if (!isalnum(c) &amp;&amp; isalnum(prevc))
                ptr-&gt;wc_count++;
            prevc = c; // 更新前一个字符
        }
        fclose(fp); // 关闭文件
    } else {
        perror(filename); // 打印错误信息
    }

    // 通过pthread_exit()退出，可以向等待该线程结束的pthread_join提供返回值
    pthread_exit((void*)&amp;ptr-&gt;wc_count);
}

int main(int ac, char *av[]) {
    // 检查命令行参数数量是否正确
    if (ac != 3) {
        printf("Usage: %s file1 file2\n", av[0]); // 提示用户正确的用法
        exit(1); // 退出程序
    }

    // 初始化第一个文件的参数
    args[0].filename = av[1];
    args[0].wc_count = 0; // 初始单词计数为0

    // 初始化第二个文件的参数
    args[1].filename = av[2];
    args[1].wc_count = 0; // 初始单词计数为0

    pthread_t tids[2]; // 创建两个线程ID数组
    void *status;      // 存放线程返回值的变量

    // 分别以args[0], args[1]为参数，创建两个线程t1, t2
    for (int i = 0; i &lt; 2; ++i) {
        if (pthread_create(&amp;tids[i], NULL, count_words, &amp;args[i])) {
            perror("pthread_create");
            exit(EXIT_FAILURE);
        }
    }

    // 让主线程等待线程t1和t2完成后再执行
    for (int i = 0; i &lt; 2; ++i) {
        if (pthread_join(tids[i], &amp;status)) {
            perror("pthread_join");
            exit(EXIT_FAILURE);
        }
        // 分别获取两个线程的返回值
        args[i].wc_count = *(int *)status;
    }

    // 输出统计单词总数
    printf("Total words in both files: %d\n", args[0].wc_count + args[1].wc_count);

    return 0;
}
<br><br><img alt="{5E478A94-FF29-45BD-9546-7262D39C4D9F} 1.png" src="\lib\media\{5e478a94-ff29-45bd-9546-7262d39c4d9f}-1.png">]]></description><link>technology\collegeproject\操作系统\实验\实验7：进程与线程并发.html</link><guid isPermaLink="false">Technology/CollegeProject/操作系统/实验/实验7：进程与线程并发.md</guid><pubDate>Wed, 13 Nov 2024 07:13:22 GMT</pubDate><enclosure url="lib\media\{5e478a94-ff29-45bd-9546-7262d39c4d9f}-1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{5e478a94-ff29-45bd-9546-7262d39c4d9f}-1.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[第1章 计算机系统概述]]></title><description><![CDATA[ 
 <br><br><br><img alt="{268DE3FF-0E5F-467E-A574-69A6CE92F70F}.png" src="\lib\media\{268de3ff-0e5f-467e-a574-69a6ce92f70f}.png"><br><br><br><img alt="{A260DAF0-F8F3-48DA-8F29-9EC9F43D5DA2}.png" src="\lib\media\{a260daf0-f8f3-48da-8f29-9ec9f43d5da2}.png"><br><br>操作系统是指控制和管理整个计算机系统的硬件和软件资源，并合理组织调度计算机的工作和资源的分配；以提供给用户和其他软件方便的接口和环境；它是计算机系统中最基本的系统软件。<br><img alt="{D950882C-1AE4-4619-9800-16B97317E44D}.png" src="\lib\media\{d950882c-1ae4-4619-9800-16b97317e44d}.png"><br><br>
<br>操作系统是系统资源的管理者<img alt="{17BF60BC-711A-4D35-94C1-C6EC1436CED7}.png" src="\lib\media\{17bf60bc-711a-4d35-94c1-c6ec1436ced7}.png">
<br>向上层提供方便易用的服务接口(如GUI图形化用户接口)<img alt="{E9FD52FC-D0AE-45B0-BA61-3E2ACA127342}.png" src="\lib\media\{e9fd52fc-d0ae-45b0-ba61-3e2aca127342}.png">
<br>是最接近硬件的一层软件<img alt="{9563F66F-84BF-4E80-A09B-E9C977DEBC6F}.png" src="\lib\media\{9563f66f-84bf-4e80-a09b-e9c977debc6f}.png">
<br><br><img alt="{CAFD948A-A1D6-478E-A5EB-26CDA014DF3A}.png" src="\lib\media\{cafd948a-a1d6-478e-a5eb-26cda014df3a}.png"><br><br>并发：宏观上看是在一时间段同时进行了多个任务，微观上最多只进行一个任务。<br>
并行：同一时刻运行多个任务<br>
<img alt="{C49CFB1E-8FBC-4E4A-84D9-3E52A96E1892}.png" src="\lib\media\{c49cfb1e-8fbc-4e4a-84d9-3e52a96e1892}.png"><br><br> <img alt="{5676C038-3895-42B7-B70A-76E91E927C85}.png" src="\lib\media\{5676c038-3895-42b7-b70a-76e91e927c85}.png"><br><br> <img alt="{2F580A04-580A-4121-A602-DB0C766DEA00}.png" src="\lib\media\{2f580a04-580a-4121-a602-db0c766dea00}.png"><br><br><img alt="{49F0A3E9-1930-49E5-80B8-D2D68824D067}.png" src="\lib\media\{49f0a3e9-1930-49e5-80b8-d2d68824d067}.png"><br>
<img alt="{C5DFBA1F-7175-45AA-87B6-5773B3250949}.png" src="\lib\media\{c5dfba1f-7175-45aa-87b6-5773b3250949}.png"><br><br><img alt="{049FE5A9-F52A-497C-9A31-F67257E3FFAA}.png" src="\lib\media\{049fe5a9-f52a-497c-9a31-f67257e3ffaa}.png"><br><br><img alt="{842B86CB-CBF2-4564-964E-411723C1050E}.png" src="\lib\media\{842b86cb-cbf2-4564-964e-411723c1050e}.png"><br><br><img alt="{64F5ECF8-42E4-4BAA-B4B4-FEA838435A35}.png" src="\lib\media\{64f5ecf8-42e4-4baa-b4b4-fea838435a35}.png"><br><br><img alt="{5D9151A0-9D83-45BD-AF3C-BEF23B6ECEAB}.png" src="\lib\media\{5d9151a0-9d83-45bd-af3c-bef23b6eceab}.png"><br><br><img alt="{83D3C1DC-435F-49E5-9931-8E3E856DADC9}.png" src="\lib\media\{83d3c1dc-435f-49e5-9931-8e3e856dadc9}.png"><br><br><img alt="{3E83781D-2DB3-4028-A5CE-67148FA67451}.png" src="\lib\media\{3e83781d-2db3-4028-a5ce-67148fa67451}.png"><br><br><img alt="{82FA53DE-6BCE-47EB-AB56-9976B3FA2EA6}.png" src="\lib\media\{82fa53de-6bce-47eb-ab56-9976b3fa2ea6}.png"><br><br><img alt="{61F3C92E-587B-466A-856B-3ECFDE63C728}.png" src="\lib\media\{61f3c92e-587b-466a-856b-3ecfde63c728}.png"><br><br><img alt="{E9B014AB-6094-46F8-A26B-CA44DE0157AB}.png" src="\lib\media\{e9b014ab-6094-46f8-a26b-ca44de0157ab}.png"><br><br><img alt="{B6897BC5-B14E-45E3-BFF9-D95CDDEC7F46}.png" src="\lib\media\{b6897bc5-b14e-45e3-bff9-d95cddec7f46}.png"><br><br><img alt="{1FB838A8-82EE-4552-9220-97F1A3E32FB6}.png" src="\lib\media\{1fb838a8-82ee-4552-9220-97f1a3e32fb6}.png"><br><br><img alt="{F9A61810-D19D-407E-AB17-1504ECC7D4D3}.png" src="\lib\media\{f9a61810-d19d-407e-ab17-1504ecc7d4d3}.png"><br><br><img alt="{EAEEE8C1-FC32-44BC-A9D3-D7F3EA95149B}.png" src="\lib\media\{eaeee8c1-fc32-44bc-a9d3-d7f3ea95149b}.png"><br>
<img alt="{6CC4788F-4204-435C-9443-8183936C0474}.png" src="\lib\media\{6cc4788f-4204-435c-9443-8183936c0474}.png"><br>
<img alt="{171D34ED-15C4-45D0-ACFD-073349B7D8AB}.png" src="\lib\media\{171d34ed-15c4-45d0-acfd-073349b7d8ab}.png"><br><br><img alt="{373FA8EC-595C-4FBA-9257-6E030F6871C7}.png" src="\lib\media\{373fa8ec-595c-4fba-9257-6e030f6871c7}.png"><br><br>中断是让操作系统内核夺回CPU使用权的唯一途径<br>
<img alt="{B70C9A8C-BF7F-42F4-B132-D924ACECD8A3}.png" src="\lib\media\{b70c9a8c-bf7f-42f4-b132-d924acecd8a3}.png"><br><br><img alt="{45A7D152-CCA3-4942-9A35-A9B9E59BEA19}.png" src="\lib\media\{45a7d152-cca3-4942-9a35-a9b9e59bea19}.png"><br><br><img alt="{75A51442-83A5-430E-978D-0878F2897366}.png" src="\lib\media\{75a51442-83a5-430e-978d-0878f2897366}.png"><br><img alt="{8B271809-209F-4BEF-B0F0-FFD2F428D3A2}.png" src="\lib\media\{8b271809-209f-4bef-b0f0-ffd2f428d3a2}.png"><br><br><img alt="{6FC70DD1-C7D6-4A44-A9C5-8520D2C2A68D}.png" src="\lib\media\{6fc70dd1-c7d6-4a44-a9c5-8520d2c2a68d}.png"><br><br><img alt="{26D91BE1-2756-44ED-8352-AE5082472CCF}.png" src="\lib\media\{26d91be1-2756-44ed-8352-ae5082472ccf}.png"><br><br><img alt="{DCA0AD9C-E7F3-4617-8CA9-ADA7C6589925}.png" src="\lib\media\{dca0ad9c-e7f3-4617-8ca9-ada7c6589925}.png"><br><br><img alt="{EEF196DE-7110-4C76-9F5C-0766FF8E6BAD}.png" src="\lib\media\{eef196de-7110-4c76-9f5c-0766ff8e6bad}.png"><br><br><img alt="{487EC28A-D856-4C05-8C86-3E3742516299}.png" src="\lib\media\{487ec28a-d856-4c05-8c86-3e3742516299}.png"><br><br><img alt="{370F7657-D75F-4DBF-A982-88185963138E}.png" src="\lib\media\{370f7657-d75f-4dbf-a982-88185963138e}.png"><br>
凡是跟共享资源有关的操作，都必须通过系统调用的方式向操作系统内核提出服务请求，让操作系统内核代为完成，这样可以保证系统的稳定性和安全性。<br><br><img alt="{69A20664-AC73-4A20-96D3-484185362AE3}.png" src="\lib\media\{69a20664-ac73-4a20-96d3-484185362ae3}.png"><br>
<img alt="{B1E5858E-6B86-4F2C-9B6B-847C22DCBD96}.png" src="\lib\media\{b1e5858e-6b86-4f2c-9b6b-847c22dcbd96}.png"><br><br><img alt="{054BAEB2-6B77-47FF-B0A4-06B54032A50F}.png" src="\lib\media\{054baeb2-6b77-47ff-b0a4-06b54032a50f}.png"><br>
<img alt="{6D4A087D-5A1A-4CD9-86FB-3224C87E42B0}.png" src="\lib\media\{6d4a087d-5a1a-4cd9-86fb-3224c87e42b0}.png"><br><br><img alt="{F1074A1A-776B-42B3-A156-71F500D10C33}.png" src="\lib\media\{f1074a1a-776b-42b3-a156-71f500d10c33}.png"><br>
<img alt="{9E3BEA29-C212-44A0-A050-764A7DA8E87C}.png" src="\lib\media\{9e3bea29-c212-44a0-a050-764a7da8e87c}.png"><br><br><img alt="{A7D96B2C-C1CA-426E-9BFF-610F6A280AAF}.png" src="\lib\media\{a7d96b2c-c1ca-426e-9bff-610f6a280aaf}.png"><br><br><img alt="{12AA72F7-FD89-4249-A6FD-9AA672AC11CC}.png" src="\lib\media\{12aa72f7-fd89-4249-a6fd-9aa672ac11cc}.png"><br><br><img alt="{8DFA81BA-DE2D-4E70-9AF1-D68E0081DCCB}.png" src="\lib\media\{8dfa81ba-de2d-4e70-9af1-d68e0081dccb}.png"><br><br><img alt="{1BC7E885-DB30-4124-BB65-F540728E49C7}.png" src="\lib\media\{1bc7e885-db30-4124-bb65-f540728e49c7}.png"><br><br><br><img alt="{EE4549AE-D875-4E31-BAE4-0C5A6305C59A}.png" src="\lib\media\{ee4549ae-d875-4e31-bae4-0c5a6305c59a}.png"><br><img alt="{2E9AE64A-3B83-4029-B0F1-35DFB25C0301}.png" src="\lib\media\{2e9ae64a-3b83-4029-b0f1-35dfb25c0301}.png"><br><br><br><img alt="{693CF39F-1F86-4C2A-810D-E4071C994F30}.png" src="\lib\media\{693cf39f-1f86-4c2a-810d-e4071c994f30}.png"><br>
<img alt="{F0BABE6B-3656-4E0A-8A4F-453CB5BF34AE}.png" src="\lib\media\{f0babe6b-3656-4e0a-8a4f-453cb5bf34ae}.png"><br><br><img alt="{B8922719-5619-4035-A45D-B6AFE6487007}.png" src="\lib\media\{b8922719-5619-4035-a45d-b6afe6487007}.png"><br><br><br><img alt="{D088A95C-DA9B-4E65-9BE5-EB2C8EE8F315}.png" src="\lib\media\{d088a95c-da9b-4e65-9be5-eb2c8ee8f315}.png"><br>
<img alt="{99258210-170B-46EE-B1D8-3E04B6A515F6}.png" src="\lib\media\{99258210-170b-46ee-b1d8-3e04b6a515f6}.png"><br>
<img alt="{430E9AA1-9C63-46A7-BA6A-1E9311589A9B}.png" src="\lib\media\{430e9aa1-9c63-46a7-ba6a-1e9311589a9b}.png"><br>
<img alt="{D347965E-DDA8-4F14-9D91-170B20DCDE89}.png" src="\lib\media\{d347965e-dda8-4f14-9d91-170b20dcde89}.png"><br>进程是进程实体的运行过程，是系统进行资源分配和调度的一个独立单位。<br><br><img alt="{72B371D1-19A7-4B74-BB7D-C55D548343E5}.png" src="\lib\media\{72b371d1-19a7-4b74-bb7d-c55d548343e5}.png"><br><br><img alt="{54137A94-EF6C-4671-8239-D3FF78F4A31A}.png" src="\lib\media\{54137a94-ef6c-4671-8239-d3ff78f4a31a}.png"><br><br><img alt="{0F5506D2-AE3A-4573-883A-B96F65E1C3AA}.png" src="\lib\media\{0f5506d2-ae3a-4573-883a-b96f65e1c3aa}.png"><br>
<img alt="{47461B9C-A79E-4FF5-82ED-F408ECF8D694}.png" src="\lib\media\{47461b9c-a79e-4ff5-82ed-f408ecf8d694}.png"><br>
<img alt="{20632A75-3ECF-44E8-BBB3-E755C7E26479}.png" src="\lib\media\{20632a75-3ecf-44e8-bbb3-e755c7e26479}.png"><br>
<img alt="{96290832-3EEE-4016-A545-BFA3546E792A}.png" src="\lib\media\{96290832-3eee-4016-a545-bfa3546e792a}.png"><img alt="{0BE86CC7-AE9A-420A-9FB5-22E0F76A339E}.png" src="\lib\media\{0be86cc7-ae9a-420a-9fb5-22e0f76a339e}.png"><img alt="{B3333E01-667C-49AB-9871-C3A9A3EDFB21}.png" src="\lib\media\{b3333e01-667c-49ab-9871-c3a9a3edfb21}.png"><br>
<img alt="{D7F8B49C-B5DA-4B54-A14F-460F3D45E99B}.png" src="\lib\media\{d7f8b49c-b5da-4b54-a14f-460f3d45e99b}.png"><br>
<img alt="{AFFF581F-DD2F-431D-A472-495D8BE9A557}.png" src="\lib\media\{afff581f-dd2f-431d-a472-495d8be9a557}.png"><br><br><img alt="{035DB312-E0B1-4F15-815C-947C76375ED3}.png" src="\lib\media\{035db312-e0b1-4f15-815c-947c76375ed3}.png"><br><br>类似链表<br>
<img alt="{B7F2B27F-7E81-4A7C-88B1-C03EA5CF26C1}.png" src="\lib\media\{b7f2b27f-7e81-4a7c-88b1-c03ea5cf26c1}.png"><br><br>类似数组<br>
<img alt="{D601E093-11B0-4482-8B3D-83808376502D}.png" src="\lib\media\{d601e093-11b0-4482-8b3d-83808376502d}.png"><br><br><img alt="{2B745C73-67B0-4F34-B3C8-7AC7A7C0CA8A}.png" src="\lib\media\{2b745c73-67b0-4f34-b3c8-7ac7a7c0ca8a}.png"><br><br><img alt="{DCAFB1E6-1723-4544-B1A6-78E6B8557168}.png" src="\lib\media\{dcafb1e6-1723-4544-b1a6-78e6b8557168}.png"><br><br>正常情况下CPU每执行完一条指令都要检查有无外部中断指令需要执行<br>
<img alt="{9A0891C8-5C04-4C4D-B6E8-4D3546223C42}.png" src="\lib\media\{9a0891c8-5c04-4c4d-b6e8-4d3546223c42}.png"><br><br><img alt="{01E7E9C8-1243-4521-B38B-999D0E33CAA2}.png" src="\lib\media\{01e7e9c8-1243-4521-b38b-999d0e33caa2}.png"><br>
<img alt="{42027CFA-8A59-430B-9CF0-7CA422EF8C6E}.png" src="\lib\media\{42027cfa-8a59-430b-9cf0-7ca422ef8c6e}.png"><br>
<img alt="{B183FCE4-8D3D-4213-B926-34174F3C83C2}.png" src="\lib\media\{b183fce4-8d3d-4213-b926-34174f3c83c2}.png"><br>
<img alt="{3EB4F342-7209-4D6E-B902-C050BC104B82}.png" src="\lib\media\{3eb4f342-7209-4d6e-b902-c050bc104b82}.png"><br><br>就是进程运行时寄存器里的数据<br>
<img alt="{D14B4E79-4BAD-4DDC-8511-893D09B67366}.png" src="\lib\media\{d14b4e79-4bad-4ddc-8511-893d09b67366}.png"><br><br><br><img alt="{EBE09AA1-AFD5-489F-A16E-1DD47F462192}.png" src="\lib\media\{ebe09aa1-afd5-489f-a16e-1dd47f462192}.png"><br><br><img alt="{507DFBF8-10A5-4435-B8B5-57B7D94AD84C}.png" src="\lib\media\{507dfbf8-10a5-4435-b8b5-57b7d94ad84c}.png"><br><br><img alt="{84C7631F-9D5C-44E6-8183-40D08C263997}.png" src="\lib\media\{84c7631f-9d5c-44e6-8183-40d08c263997}.png"><br>
<img alt="{12D0B52E-A90D-42D5-BDCF-78DE55CDEEC0}.png" src="\lib\media\{12d0b52e-a90d-42d5-bdcf-78de55cdeec0}.png"><br><br><img alt="{D2627D4A-9D2C-4986-A96F-B9019ABE4C80}.png" src="\lib\media\{d2627d4a-9d2c-4986-a96f-b9019abe4c80}.png"><br><br><img alt="{9F7741DA-4D25-4A86-AB1A-2DAFE7A8D587}.png" src="\lib\media\{9f7741da-4d25-4a86-ab1a-2dafe7a8d587}.png"><br><br><img alt="{CF5AA00C-344C-43EC-84AF-607734DC3793}.png" src="\lib\media\{cf5aa00c-344c-43ec-84af-607734dc3793}.png"><br><br><br><img alt="{18BDD78A-4D94-4C1F-92CC-4672099D16FC}.png" src="\lib\media\{18bdd78a-4d94-4c1f-92cc-4672099d16fc}.png"><br>
<img alt="{6008DF8B-C2B3-4EBF-84D7-75BB0199AB56}.png" src="\lib\media\{6008df8b-c2b3-4ebf-84d7-75bb0199ab56}.png"><br>
<img alt="{292E0D03-B74D-4CF6-B900-C54D93298A09}.png" src="\lib\media\{292e0d03-b74d-4cf6-b900-c54d93298a09}.png"><br><br><img alt="{73248138-A154-491A-8D3C-A679DB7E1381}.png" src="\lib\media\{73248138-a154-491a-8d3c-a679db7e1381}.png"><br><br><img alt="{59BFA5EA-42AA-4E99-B32D-CFF38788E1BE}.png" src="\lib\media\{59bfa5ea-42aa-4e99-b32d-cff38788e1be}.png"><img alt="{551DA399-B865-419E-98CC-4E4DAA96A4D4}.png" src="\lib\media\{551da399-b865-419e-98cc-4e4daa96a4d4}.png"><br>
<img alt="{5624049F-3C4B-4C3D-A8D7-635EBA4E4556}.png" src="\lib\media\{5624049f-3c4b-4c3d-a8d7-635eba4e4556}.png"><br><br><img alt="{179777BB-CB97-47F1-8898-3B3062F7CEE4}.png" src="\lib\media\{179777bb-cb97-47f1-8898-3b3062f7cee4}.png"><br>
<img alt="{9A208C8C-5E54-4006-80C6-ACFDC086F060}.png" src="\lib\media\{9a208c8c-5e54-4006-80c6-acfdc086f060}.png"><br><br><img alt="{29025664-4F5B-404D-9F57-4538BFA42560}.png" src="\lib\media\{29025664-4f5b-404d-9f57-4538bfa42560}.png"><br><br><img alt="{88652D23-3A5E-4D83-984B-1C30DE602F6B}.png" src="\lib\media\{88652d23-3a5e-4d83-984b-1c30de602f6b}.png"><br><br><img alt="{7645052E-298F-4770-A730-F2D17E217FF4}.png" src="\lib\media\{7645052e-298f-4770-a730-f2d17e217ff4}.png"><br>
<img alt="{12729115-0C35-4A71-8E42-F008E3F0C506}.png" src="\lib\media\{12729115-0c35-4a71-8e42-f008e3f0c506}.png"><br>
<img alt="{5BB31A45-1641-479F-B256-94B6F1D62CAB}.png" src="\lib\media\{5bb31a45-1641-479f-b256-94b6f1d62cab}.png"><br>
<img alt="{C48913DA-F782-4E6B-B222-41CB4B7CFE9B}.png" src="\lib\media\{c48913da-f782-4e6b-b222-41cb4b7cfe9b}.png"><br>
<img alt="{C69042FA-BED7-4B9F-B5E4-C7FD91936A12}.png" src="\lib\media\{c69042fa-bed7-4b9f-b5e4-c7fd91936a12}.png"><br><br><img alt="{0F5A3085-D464-4846-9069-3681A2F8D0F1}.png" src="\lib\media\{0f5a3085-d464-4846-9069-3681a2f8d0f1}.png"><br><br><img alt="{A64B48AD-3B3C-4955-8031-1F938EB32FDF}.png" src="\lib\media\{a64b48ad-3b3c-4955-8031-1f938eb32fdf}.png"><br>
<img alt="{EFD36C64-906F-46B3-9437-2F425CE2276F}.png" src="\lib\media\{efd36c64-906f-46b3-9437-2f425ce2276f}.png"><br><br><img alt="{9558A421-2E82-4E82-A964-9D6B26CD03DC}.png" src="\lib\media\{9558a421-2e82-4e82-a964-9d6b26cd03dc}.png"><br><br><img alt="{E89FDA89-8254-4ABA-B3A5-463F52D26D7B}.png" src="\lib\media\{e89fda89-8254-4aba-b3a5-463f52d26d7b}.png"><br><br><img alt="{82E9149F-92E8-4B98-AA46-4F05EBE5AB1C}.png" src="\lib\media\{82e9149f-92e8-4b98-aa46-4f05ebe5ab1c}.png"><br>
<img alt="{9B040CDF-C1DF-4625-B32F-4A0AE52D78C0}.png" src="\lib\media\{9b040cdf-c1df-4625-b32f-4a0ae52d78c0}.png"><br><br><img alt="{00C066F7-538C-4B48-84DE-AF017D7A54F7}.png" src="\lib\media\{00c066f7-538c-4b48-84de-af017d7a54f7}.png"><br><img alt="{20FE5F58-06F4-498F-B952-0B9D4FA27AFC}.png" src="\lib\media\{20fe5f58-06f4-498f-b952-0b9d4fa27afc}.png"><br>
<img alt="{5AE40594-A924-4AC8-95AD-3DAFD21AEC49}.png" src="\lib\media\{5ae40594-a924-4ac8-95ad-3dafd21aec49}.png"><br>
<img alt="{A5ECDFFC-B5F6-48FB-8761-B13C5C6875E9}.png" src="\lib\media\{a5ecdffc-b5f6-48fb-8761-b13c5c6875e9}.png"><br>
<img alt="{49FD3087-CB34-46BC-9391-A772DB73BD1C}.png" src="\lib\media\{49fd3087-cb34-46bc-9391-a772db73bd1c}.png"><br>
<img alt="{1C2A42A6-F24B-4337-8423-EF35C9F5B8EE}.png" src="\lib\media\{1c2a42a6-f24b-4337-8423-ef35c9f5b8ee}.png"><br>
<img alt="{100876A2-C09A-4B4D-965E-45C0593A726F}.png" src="\lib\media\{100876a2-c09a-4b4d-965e-45c0593a726f}.png"><br><br><img alt="{53055F4A-C1C5-4E5B-83FD-D3257BB1B0E5}.png" src="\lib\media\{53055f4a-c1c5-4e5b-83fd-d3257bb1b0e5}.png"><br><br><img alt="{90EE8574-B0C8-44BB-AC53-670CD1726804}.png" src="\lib\media\{90ee8574-b0c8-44bb-ac53-670cd1726804}.png"><br>
<img alt="{A3F1B590-3911-4C83-B1D7-399D8AA54B02}.png" src="\lib\media\{a3f1b590-3911-4c83-b1d7-399d8aa54b02}.png"><br><br><img alt="{8CF786A3-BA72-405D-8698-D78DBB9F6B4D}.png" src="\lib\media\{8cf786a3-ba72-405d-8698-d78dbb9f6b4d}.png"><br><br><img alt="{B5835956-7609-4C7C-819A-394209C6C23B}.png" src="\lib\media\{b5835956-7609-4c7c-819a-394209c6c23b}.png"><br><br><img alt="{7E99C536-BAFE-4D7E-AF1D-FA5EC813EDDE}.png" src="\lib\media\{7e99c536-bafe-4d7e-af1d-fa5ec813edde}.png"><br>
<img alt="{3212F4DF-EDB8-4328-A6F6-9697B70C98FC}.png" src="\lib\media\{3212f4df-edb8-4328-a6f6-9697b70c98fc}.png"><br><br><img alt="{FB2E2E1C-7470-45A2-8B26-6F91F4BAFC84}.png" src="\lib\media\{fb2e2e1c-7470-45a2-8b26-6f91f4bafc84}.png"><br><br><img alt="{F2912831-0629-44FE-A68C-40E07E647F5E}.png" src="\lib\media\{f2912831-0629-44fe-a68c-40e07e647f5e}.png"><br>
<img alt="{826BC4BE-61B8-4787-B7A2-AB439A3E7F7C}.png" src="\lib\media\{826bc4be-61b8-4787-b7a2-ab439a3e7f7c}.png"><br><br><img alt="{19370414-0E52-4ECB-A1A9-E7682FED7699}.png" src="\lib\media\{19370414-0e52-4ecb-a1a9-e7682fed7699}.png"><br><br><img alt="{950AF708-2B9B-453F-AFE3-CE934DF211AD}.png" src="\lib\media\{950af708-2b9b-453f-afe3-ce934df211ad}.png"><br>
<img alt="{05B9C48E-9A2D-4E62-844B-86CD86381922}.png" src="\lib\media\{05b9c48e-9a2d-4e62-844b-86cd86381922}.png"><br>
<img alt="{B880B191-A2EA-4B3A-9769-EC808D2B5A77}.png" src="\lib\media\{b880b191-a2ea-4b3a-9769-ec808d2b5a77}.png"><br>
<img alt="{ADACE4B8-4DD0-4F54-B328-C5C2CD2E21A3}.png" src="\lib\media\{adace4b8-4dd0-4f54-b328-c5c2cd2e21a3}.png"><br>
<img alt="{16D029A3-48FF-4872-BAE2-5ACE4D8D0F99}.png" src="\lib\media\{16d029a3-48ff-4872-bae2-5ace4d8d0f99}.png"><br>
<img alt="{E880BD09-E5C7-400F-BC2B-826CD571838D}.png" src="\lib\media\{e880bd09-e5c7-400f-bc2b-826cd571838d}.png"><br>
一般来说，设计时间片时要让切换进程的开销占比不超过1%。<br><br><img alt="{10440108-E52C-4A04-B52E-995B4EFA613A}.png" src="\lib\media\{10440108-e52c-4a04-b52e-995b4efa613a}.png"><br><br><img alt="{13FE3A1A-39E3-44F8-BC62-E601D0486128}.png" src="\lib\media\{13fe3a1a-39e3-44f8-bc62-e601d0486128}.png"><br><br><img alt="{68B4CD3E-19DC-4FED-A9DC-396866986D5D}.png" src="\lib\media\{68b4cd3e-19dc-4fed-a9dc-396866986d5d}.png"><br><br><img alt="{6F65E462-1BBC-4A7E-A60C-99D449F28925}.png" src="\lib\media\{6f65e462-1bbc-4a7e-a60c-99d449f28925}.png"><br>
<img alt="{E31A9CAD-E34C-44DB-8CC0-2AA6AEE370A0}.png" src="\lib\media\{e31a9cad-e34c-44db-8cc0-2aa6aee370a0}.png"><br><br><img alt="{4E0A3530-4FF4-4044-8543-95C49C4B1E47}.png" src="\lib\media\{4e0a3530-4ff4-4044-8543-95c49c4b1e47}.png"><br><img alt="{77F3CB73-DF90-44AB-9284-B749A14C9D57}.png" src="\lib\media\{77f3cb73-df90-44ab-9284-b749a14c9d57}.png"><br><br><img alt="{187CD1D4-D6DF-471B-9B49-C0654488D20C}.png" src="\lib\media\{187cd1d4-d6df-471b-9b49-c0654488d20c}.png"><br><br><img alt="{E6591577-10D7-4CA1-A4FB-71CD3D3E093C}.png" src="\lib\media\{e6591577-10d7-4ca1-a4fb-71cd3d3e093c}.png"><br><br><img alt="{7B0DFCB0-0C39-4DB4-8338-383722653318}.png" src="\lib\media\{7b0dfcb0-0c39-4db4-8338-383722653318}.png"><br>
<img alt="{7C42B03F-DD6E-45A4-ADF2-9ADF7C2FC4AE}.png" src="\lib\media\{7c42b03f-dd6e-45a4-adf2-9adf7c2fc4ae}.png"><br>
<img alt="{07E5504F-C462-4E63-B652-FE91FB9E2B13}.png" src="\lib\media\{07e5504f-c462-4e63-b652-fe91fb9e2b13}.png"><br><br><img alt="{0D768D7F-AD2D-4CE5-9ED7-B5523616761A}.png" src="\lib\media\{0d768d7f-ad2d-4ce5-9ed7-b5523616761a}.png"><br><br><img alt="{5564CD90-A649-4DF7-9300-31E31CBA145B}.png" src="\lib\media\{5564cd90-a649-4df7-9300-31e31cba145b}.png"><br>
<img alt="{FC935170-5D60-4F43-95FC-6F8EB15E5E66}.png" src="\lib\media\{fc935170-5d60-4f43-95fc-6f8eb15e5e66}.png"><br><br><img alt="{4228FE63-697C-427E-A58E-629177BA7D25}.png" src="\lib\media\{4228fe63-697c-427e-a58e-629177ba7d25}.png"><br>
<img alt="{317C8D5D-98EA-4286-B28E-32F1CB3B9A22}.png" src="\lib\media\{317c8d5d-98ea-4286-b28e-32f1cb3b9a22}.png"><br><br><img alt="{8DF61FED-C1D9-49AD-B216-4AB313D42DAA}.png" src="\lib\media\{8df61fed-c1d9-49ad-b216-4ab313d42daa}.png"><br>
<img alt="{6B8CDEE0-F1B8-4B35-87A6-482F502E908E}.png" src="\lib\media\{6b8cdee0-f1b8-4b35-87a6-482f502e908e}.png"><br><br><img alt="{F85D18A7-5AD3-454F-834D-09C29DCDD082}.png" src="\lib\media\{f85d18a7-5ad3-454f-834d-09c29dcdd082}.png"><br>
<img alt="{EF63343A-F1B9-4E2C-A8AA-0A11D44F7EA3}.png" src="\lib\media\{ef63343a-f1b9-4e2c-a8aa-0a11d44f7ea3}.png"><br><br><img alt="{524FD0D6-7484-4BAF-8410-69681B63996A}.png" src="\lib\media\{524fd0d6-7484-4baf-8410-69681b63996a}.png"><br><br><img alt="{F44B7391-0C3B-4C91-9B62-F13D4837BF3F}.png" src="\lib\media\{f44b7391-0c3b-4c91-9b62-f13d4837bf3f}.png"><br><br><img alt="{13ABE55A-2B06-47E4-91AD-D8DCCA680E46} 2.png" src="\lib\media\{13abe55a-2b06-47e4-91ad-d8dcca680e46}-2.png"><br><br><img alt="{88369F2E-089A-4905-9F4D-7580332788AB}.png" src="\lib\media\{88369f2e-089a-4905-9f4d-7580332788ab}.png"><br><br><img alt="{FC4E3272-844A-4191-99ED-9A3B90DFC7F2}.png" src="\lib\media\{fc4e3272-844a-4191-99ed-9a3b90dfc7f2}.png"><br>
<img alt="{012FE184-1FBA-41F7-B55C-62E380C78DF2}.png" src="\lib\media\{012fe184-1fba-41f7-b55c-62e380c78df2}.png"><br><br><img alt="{995480AD-7141-43B4-A25B-552F82D13AC5}.png" src="\lib\media\{995480ad-7141-43b4-a25b-552f82d13ac5}.png"><br><br><img alt="{A47E0F7C-0F43-4655-A193-892A8C05A5E3}.png" src="\lib\media\{a47e0f7c-0f43-4655-a193-892a8c05a5e3}.png"><br><br><img alt="{B86C9E82-F817-458D-8B1E-BFDEFBF91FB3}.png" src="\lib\media\{b86c9e82-f817-458d-8b1e-bfdefbf91fb3}.png"><br><br><img alt="{FD79C512-8B47-4C98-8E1E-A55638B4C8AC}.png" src="\lib\media\{fd79c512-8b47-4c98-8e1e-a55638b4c8ac}.png"><br><br><img alt="{D884E0DB-93E4-4732-9F4B-4ECF51673399}.png" src="\lib\media\{d884e0db-93e4-4732-9f4b-4ecf51673399}.png"><br>
<img alt="{477570E5-42C6-48FA-838D-228BA8EC4283}.png" src="\lib\media\{477570e5-42c6-48fa-838d-228ba8ec4283}.png"><br><br><img alt="{26860191-D6C1-4F0B-BE1B-FAB9F6BC1844}.png" src="\lib\media\{26860191-d6c1-4f0b-be1b-fab9f6bc1844}.png"><br><br><img alt="{E2343BF4-DB5E-475F-B1E4-B1380E5468BE}.png" src="\lib\media\{e2343bf4-db5e-475f-b1e4-b1380e5468be}.png"><br><br><img alt="{1CAF59C7-0B91-4C97-BD97-2BE43111C298}.png" src="\lib\media\{1caf59c7-0b91-4c97-bd97-2be43111c298}.png"><br>
<img alt="{45971548-3844-4B6E-9374-2F13814C089A}.png" src="\lib\media\{45971548-3844-4b6e-9374-2f13814c089a}.png"><br><br><img alt="{14D57A3C-0825-4DA4-8DF0-AD9B23E3F08C} 1.png" src="\lib\media\{14d57a3c-0825-4da4-8df0-ad9b23e3f08c}-1.png"><br><img alt="{ACABB993-3CA8-4CB5-B33D-0BEE0CDD739B}.png" src="\lib\media\{acabb993-3ca8-4cb5-b33d-0bee0cdd739b}.png"><br><br><img alt="{A8E08E6E-4705-4CC7-86B6-65B1A74406E0}.png" src="\lib\media\{a8e08e6e-4705-4cc7-86b6-65b1a74406e0}.png"><br><br><img alt="{6DF69BD0-5557-42CD-A40B-1873F14597A0}.png" src="\lib\media\{6df69bd0-5557-42cd-a40b-1873f14597a0}.png"><br><br><img alt="{4FAAF6BC-4235-4B1B-BD35-55EE022B0CBE}.png" src="\lib\media\{4faaf6bc-4235-4b1b-bd35-55ee022b0cbe}.png"><br><br><img alt="{A669B0D3-4421-4A44-A156-71DFFEDB2631}.png" src="\lib\media\{a669b0d3-4421-4a44-a156-71dffedb2631}.png"><br><br><img alt="{E8F7F29D-2D26-4459-BBD1-51E6CC301D53}.png" src="\lib\media\{e8f7f29d-2d26-4459-bbd1-51e6cc301d53}.png"><br>
<img alt="{055590B0-A005-41CB-A0E3-E1403B21AFF3}.png" src="\lib\media\{055590b0-a005-41cb-a0e3-e1403b21aff3}.png"><br>
<img alt="{6180A335-D0D6-439C-B5C0-FF714F10722B}.png" src="\lib\media\{6180a335-d0d6-439c-b5c0-ff714f10722b}.png">]]></description><link>technology\collegeproject\操作系统\王道操作系统笔记.html</link><guid isPermaLink="false">Technology/CollegeProject/操作系统/王道操作系统笔记.md</guid><pubDate>Tue, 05 Nov 2024 14:58:09 GMT</pubDate><enclosure url="lib\media\{268de3ff-0e5f-467e-a574-69a6ce92f70f}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{268de3ff-0e5f-467e-a574-69a6ce92f70f}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[项目计划书]]></title><description><![CDATA[ 
 <br><br><br><br>随着科技的进步和医疗需求的多样化，人工智能在医疗行业的应用已经开始展现出巨大的潜力。我们的小组选择了开发一个“智能医疗诊断系统”，该系统利用人工智能技术，特别是深度学习和机器学习算法，辅助医生进行更精准的病症预测和诊断。该系统将支持多种疾病的自动识别，包括但不限于常见的心脏病、糖尿病、肺癌等，通过患者的基本信息、病史数据、实验室检查结果等多个数据源，为医生提供智能化的决策支持。<br><br><br>本项目的目标是开发一个基于人工智能的智能医疗诊断系统，具体目标包括：<br>
<br>精准诊断：通过智能算法实现对不同疾病的高效识别和诊断，提升诊断准确率。
<br>提升效率：减少人工诊断的时间，提高医生的工作效率，使其能处理更多病例。
<br>数据分析：通过对患者数据的深度分析，为医疗机构提供诊疗报告和趋势预测。
<br>用户友好：确保系统具有良好的用户体验，使得医护人员能够轻松操作和使用。
<br><br><br>
<br>
功能需求：

<br>疾病识别模块：通过历史数据、病症数据等进行疾病诊断。
<br>健康数据分析模块：分析患者的健康数据，包括体温、血压、心电图等信息。
<br>报告生成模块：根据系统诊断结果自动生成病情报告。
<br>用户界面：为医生和患者提供便捷的交互界面。


<br>
非功能需求：

<br>高效性：系统的响应时间不超过2秒。
<br>稳定性：系统保证99%的正常运行时间。
<br>安全性：患者数据必须加密存储，并遵守相关隐私保护法律法规。


<br>
技术需求：

<br>AI算法：主要使用深度学习和机器学习模型，进行数据分析和疾病识别。
<br>数据库：采用MySQL或MongoDB存储病历数据。
<br>前端开发：使用Vue.js等前端框架开发用户界面。
<br>后端开发：使用Python、Flask等后端技术提供API支持。


<br><br><br>
<br>项目边界：本项目将覆盖智能医疗诊断的算法开发、数据采集与处理、前后端开发等内容，聚焦于疾病诊断领域，暂不涉及药物推荐或健康管理等其他领域。
<br>不包括内容：本项目不会涉及到医疗设备的开发与硬件支持，系统会集成现有的硬件接口进行数据采集。
<br><br><br>项目计划周期为6个月，分为以下阶段：<br>
<br>需求调研与分析（第1个月）：

<br>完成项目需求调研，分析人工智能在医疗诊断中的应用案例。
<br>收集与整理医疗领域的数据。


<br>系统设计（第2个月）：

<br>完成系统架构设计与技术选型。
<br>确定AI算法模型与数据分析方法。


<br>开发阶段（第3-4个月）：

<br>开发前端与后端功能，进行AI算法模型训练。
<br>开发与测试初步版本的智能医疗诊断系统。


<br>测试与优化（第5个月）：

<br>进行系统功能、性能、兼容性等多方面测试。
<br>根据反馈进行系统优化，提升准确率和稳定性。


<br>部署与上线（第6个月）：

<br>完成产品上线和部署，提供系统使用培训。
<br>撰写项目报告和总结，提交最终成果。


<br><br><br>
<br>
人力成本：

<br>项目团队包含3-5人，团队成员的薪酬按市场平均水平计算。
<br>人力成本总计约为30万元（每人月薪5000元）。


<br>
技术成本：

<br>AI算法开发、数据存储、服务器等技术成本预计为20万元。


<br>
其他成本：

<br>包括办公场地、设备采购等，预算为10万元。


<br>项目总成本：60万元<br><br><br>
<br>
团队成员：

<br>项目经理：负责整体项目的规划与管理，确保项目按时完成。
<br>技术负责人：负责AI算法开发与技术架构设计。
<br>前端开发：负责系统前端的设计与开发。
<br>后端开发：负责后端API的设计与实现。
<br>测试工程师：负责系统的功能和性能测试。


<br>
设备资源：

<br>需要购买一定数量的高性能服务器，以支持AI模型的训练和数据存储。


<br><br><br>
<br>
项目可行性分析：

<br>技术可行性：基于现有的深度学习框架（如TensorFlow、PyTorch）和医疗数据集（如MIMIC-III数据库），技术实现难度较低，系统开发可行。
<br>经济可行性：初期投资较大，但通过AI技术降低医生的工作负担，提高医疗诊断的效率，项目具有较高的长期投资回报。
<br>市场可行性：随着人工智能在医疗领域的应用越来越广泛，市场需求逐渐增大，项目的市场前景良好。


<br>
绩效分析：

<br>通过项目的成功交付，我们能够为医疗行业提供更高效的诊断工具，减少医疗资源浪费，同时提升患者的治疗质量。
<br>成功实施后，系统可推广至更多医疗机构，进一步扩大市场份额。


<br><br><br>
<br>甘特图：用于项目进度的管理和监控，确保各阶段按时完成。
<br>JIRA：用于团队任务的分配和跟踪，确保任务分工明确。
<br>Slack：用于团队成员间的即时沟通和协作。
<br>Trello：用于管理项目的不同阶段和任务，帮助团队进行有效的任务追踪。
<br><br><br>
<br>李世博：项目经理，负责整体规划、协调与进度管理。
<br>张三：技术负责人，负责AI算法的研究和实现。
<br>李四：前端开发，负责UI设计与前端代码实现。
<br>王五：后端开发，负责API设计与数据库开发。
<br>赵六：测试工程师，负责系统测试和优化。
<br>]]></description><link>technology\collegeproject\工程管理\项目计划书.html</link><guid isPermaLink="false">Technology/CollegeProject/工程管理/项目计划书.md</guid><pubDate>Fri, 06 Dec 2024 06:21:20 GMT</pubDate></item><item><title><![CDATA[半监督学习]]></title><description><![CDATA[ 
 <br><br>半监督学习是一种机器学习方法，结合了少量标注数据（有标签的数据）和大量未标注数据（无标签的数据）来训练模型。其基本思想是利用未标注数据的潜在信息来辅助少量标注数据，提高模型的泛化能力和准确性。<br>基本思想：<br>
<br>
利用未标注数据的分布信息： 半监督学习方法利用未标注数据的分布信息来构建更准确的模型。例如，通过聚类、流形学习等方法，可以发现数据的结构和关系，从而辅助模型学习。

<br>
伪标签生成： 在某些方法中，模型首先用少量标注数据进行初步训练，然后用训练好的模型对未标注数据进行预测，生成伪标签。这些伪标签可以作为额外的训练数据，进一步训练模型。

<br>
一致性正则化： 假设数据和标签之间存在某种一致性。通过对未标注数据加噪声或变换，并要求模型对变换前后的数据输出一致，可以增强模型的稳健性和泛化能力。

<br>相比于监督学习和无监督学习的优势：<br>
<br>
提高模型性能： 半监督学习能利用大量未标注数据，改进模型的性能，尤其是在标注数据稀缺或获取标注数据成本高的情况下。

<br>
降低标注成本： 获取大量标注数据通常需要大量的人力和时间，而半监督学习通过结合未标注数据，减少了对标注数据的依赖，降低了数据标注的成本。

<br>
处理数据不平衡： 在某些应用场景中，标注数据可能存在类别不平衡的问题。半监督学习可以通过利用未标注数据，缓解类别不平衡对模型训练的影响。

<br>应用场景：<br>
<br>
自然语言处理（NLP）： 例如文本分类、命名实体识别等任务中，标注数据通常稀缺且获取困难，半监督学习可以利用大量的未标注文本数据提升模型性能。

<br>
计算机视觉： 例如图像分类、物体检测等任务中，标注图像数据的获取成本很高，通过半监督学习，可以利用大量的未标注图像提高模型的准确性。

<br>
医学影像分析： 医学影像数据的标注需要专业医生的参与，成本高且时间长。半监督学习可以利用未标注的医学影像数据，辅助模型训练，提高诊断的准确率。

<br>
推荐系统： 在推荐系统中，用户的行为数据（如点击、浏览记录）大多是未标注的，通过半监督学习，可以结合少量的用户反馈数据，提高推荐的精确度。

<br>总结来说，半监督学习通过结合有标签和无标签的数据，能够在标注数据有限的情况下，显著提升模型的性能和泛化能力，广泛应用于需要大量数据但标注成本高的领域。<br><br><img alt="Pasted image 20240623210153.png" src="\lib\media\pasted-image-20240623210153.png"><br>
<img alt="Pasted image 20240623210130.png" src="\lib\media\pasted-image-20240623210130.png"><br>
<img alt="Pasted image 20240623210755.png" src="\lib\media\pasted-image-20240623210755.png"><br>
<img alt="Pasted image 20240623211242.png" src="\lib\media\pasted-image-20240623211242.png">]]></description><link>technology\collegeproject\机器学习\概念\半监督学习.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/半监督学习.md</guid><pubDate>Sun, 23 Jun 2024 13:12:44 GMT</pubDate><enclosure url="lib\media\pasted-image-20240623210153.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240623210153.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[贝叶斯决策论]]></title><description><![CDATA[ 
 <br><img alt="文档扫描_20240520193252870.jpg" src="\lib\media\文档扫描_20240520193252870.jpg">]]></description><link>technology\collegeproject\机器学习\概念\贝叶斯决策论.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/贝叶斯决策论.md</guid><pubDate>Mon, 20 May 2024 11:35:51 GMT</pubDate><enclosure url="lib\media\文档扫描_20240520193252870.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\文档扫描_20240520193252870.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[度量学习]]></title><description><![CDATA[ 
 <br><br>度量学习（Metric Learning）的目标是学习一个距离度量，使得在这种度量下，相似的样本距离更近，不相似的样本距离更远。度量学习在各种任务中都很重要，包括图像检索、分类、聚类和推荐系统等。<br>LMNN（Large Margin Nearest Neighbor， 大边界最近邻）算法是一种监督式度量学习算法，旨在优化最近邻分类器的性能。LMNN通过学习一个线性变换，使得经过该变换后的特征空间中，相同类别的样本距离更近，不同类别的样本距离更远，从而提高k近邻分类器的准确性。<br>在LMNN算法中，三元组损失（triplet loss）是一个关键的概念。三元组损失用于衡量在变换后的特征空间中样本点之间的距离关系，并指导模型进行优化。<br>一个三元组通常表示为 ，其中：<br>
<br> 是一个给定的样本（锚点，anchor）。
<br> 是与  同类别的一个样本（正样本，positive）。
<br> 是与  不同类别的一个样本（负样本，negative）。
<br>三元组损失的计算公式如下：<br><br>其中：<br>
<br> 表示样本  和样本  之间的距离，可以是欧氏距离或其他距离度量。
<br> 是锚点样本的特征向量。
<br> 是正样本的特征向量。
<br> 是负样本的特征向量。
<br>1 是一个超参数，称为边际（margin），用于确保正样本距离比负样本距离至少小1个单位。
<br>三元组损失的核心思想是：<br>
<br>如果 ，即正样本距离加上边际小于等于负样本距离，则损失为0。
<br>如果 ，即正样本距离加上边际大于负样本距离，则损失值为 。
<br>通过最小化三元组损失，LMNN算法能够调整特征空间，使得正样本对更接近而负样本对更远，从而优化最近邻分类器的性能。<br><br>LMNN（Large Margin Nearest Neighbor，大边界最近邻）算法通过学习一个线性变换，使得在新的特征空间中，相同类别的样本尽可能接近，不同类别的样本尽可能远离，从而提高最近邻分类器的性能。具体过程如下：<br><br>LMNN的目标是学习一个线性变换矩阵 ，初始情况下，可以将 初始化为单位矩阵 ，这意味着最开始的度量是普通的欧氏距离。<br><br>LMNN的目标函数由两部分组成：<br>
<br>拉近同类样本的距离（Pulling Similar Examples Together）：<br>
确保每个样本与其同类最近邻样本之间的距离尽可能小。
<br>拉远不同类样本的距离（Pushing Dissimilar Examples Apart）：<br>
确保每个样本与不同类样本之间的距离尽可能大。
<br>目标函数可以表示为：<br><br>其中：<br>
<br>是一个二值变量，当 是 的同类最近邻时取值为1，否则为0。
<br>是一个二值变量，当 和 属于同一类别时取值为1，否则为0。
<br>是一个超参数，权衡两部分损失。
<br><br>计算目标函数对 的梯度，用于梯度下降优化：<br>
<br>同类样本的梯度：
<br><br>
<br>不同类样本的梯度：
<br><br>在误差项有效时（即 函数不为0），梯度为：<br><br><br>使用梯度下降算法更新 矩阵：<br><br>其中，是学习率。<br><br>重复步骤3和4，直到目标函数收敛或达到预设的迭代次数。<br><br>训练结束后，得到最终的变换矩阵 $ L$。在分类任务中，使用新的距离度量：<br><br>新的距离度量用于最近邻分类器中。<br><br>LMNN通过迭代优化目标函数，学习一个线性变换，使得同类样本距离更近、不同类样本距离更远，从而提高最近邻分类器的性能。这一过程包括初始化、定义目标函数、计算梯度、梯度下降优化和重复迭代，最终得到一个用于距离度量的变换矩阵。]]></description><link>technology\collegeproject\机器学习\概念\度量学习.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/度量学习.md</guid><pubDate>Mon, 10 Jun 2024 13:42:27 GMT</pubDate></item><item><title><![CDATA[对数几率回归，极大似然法]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br><br><img alt="扫描件_19220423_001.jpg" src="\lib\media\扫描件_19220423_001.jpg">]]></description><link>technology\collegeproject\机器学习\概念\对数几率回归，极大似然法.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/对数几率回归，极大似然法.md</guid><pubDate>Sun, 21 Apr 2024 02:16:18 GMT</pubDate><enclosure url="lib\media\扫描件_19220423_001.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\扫描件_19220423_001.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[多分类任务与感知机]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<img alt="扫描件_多分类任务_003 1.jpg" src="\lib\media\扫描件_多分类任务_003-1.jpg"><img alt="扫描件_多分类任务_002 1.jpg" src="\lib\media\扫描件_多分类任务_002-1.jpg">]]></description><link>technology\collegeproject\机器学习\概念\多分类任务与感知机.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/多分类任务与感知机.md</guid><pubDate>Mon, 08 Apr 2024 11:53:31 GMT</pubDate><enclosure url="lib\media\扫描件_多分类任务_003-1.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\扫描件_多分类任务_003-1.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[多元线性回归与岭回归]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<img alt="Pasted image 20240408195145.png" src="\lib\media\pasted-image-20240408195145.png">]]></description><link>technology\collegeproject\机器学习\概念\多元线性回归与岭回归.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/多元线性回归与岭回归.md</guid><pubDate>Mon, 08 Apr 2024 11:53:34 GMT</pubDate><enclosure url="lib\media\pasted-image-20240408195145.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240408195145.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[交叉熵、KL散度]]></title><description><![CDATA[ 
 <br><img alt="文档扫描_20240522213821899.jpg" src="\lib\media\文档扫描_20240522213821899.jpg">]]></description><link>technology\collegeproject\机器学习\概念\交叉熵、kl散度.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/交叉熵、KL散度.md</guid><pubDate>Thu, 23 May 2024 02:31:34 GMT</pubDate><enclosure url="lib\media\文档扫描_20240522213821899.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\文档扫描_20240522213821899.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[卡方检验]]></title><description><![CDATA[ 
 <br><br>卡方检验（Chi-Square Test）和卡方分布（Chi-Square Distribution）确实有紧密的关系。卡方检验是一种基于卡方分布的统计检验方法。以下是它们之间关系的具体说明：<br>
<br>
卡方分布：

<br>卡方分布是一种连续概率分布，用于描述一组独立随机变量平方和的分布。其形状取决于自由度（degrees of freedom, df）。
<br>如果有  个独立的标准正态随机变量 ，则这些变量的平方和  服从自由度为  的卡方分布。


<br>
卡方检验：

<br>卡方检验是一种非参数检验，用于检验观测数据与期望数据之间的差异是否显著。
<br>常见的卡方检验包括独立性检验和拟合优度检验。
<br>在进行卡方检验时，首先计算卡方统计量，该统计量近似服从卡方分布。


<br>
卡方统计量：

<br>在卡方检验中，计算的卡方统计量  通常如下：

 其中  是观测频数， 是期望频数。
<br>该卡方统计量在  （零假设）成立时，近似服从自由度为  的卡方分布。


<br>
自由度：

<br>自由度  是卡方分布和卡方检验中的一个关键参数。它通常与样本的规模和分类变量的数量有关。
<br>在独立性检验中，自由度为 ，其中  是行数， 是列数。
<br>在拟合优度检验中，自由度为 ，其中  是类别数。


<br>总的来说，卡方分布为卡方检验提供了理论基础，而卡方检验则利用卡方分布来评估数据是否符合预期模式或两个变量是否独立。<br><br>卡方检验的流程可以分为以下几个步骤，以卡方独立性检验和卡方拟合优度检验为例分别进行说明。<br><br>卡方独立性检验用于确定两个分类变量之间是否存在显著的关联。其步骤如下：<br>
<br>
构建假设：

<br>零假设（H0）：变量之间独立。
<br>备择假设（H1）：变量之间不独立。


<br>
构建列联表：

<br>收集数据并构建一个列联表（contingency table），记录每个类别组合的观测频数。


<br>
计算期望频数：

<br>期望频数的计算公式为：

 其中， 是期望频数， 是第  行的总计数， 是第  列的总计数， 是总计数。


<br>
计算卡方统计量：

<br>使用以下公式计算卡方统计量：

 其中， 是观测频数， 是期望频数。


<br>
确定自由度：

<br>自由度的计算公式为：

 其中， 是行数， 是列数。


<br>
查表确定临界值：

<br>根据计算得出的自由度和显著性水平（通常为0.05），查找卡方分布表，找到临界值。


<br>
比较并得出结论：

<br>比较计算出的卡方统计量与临界值。
<br>如果卡方统计量大于临界值，拒绝零假设，认为变量之间存在显著关联。
<br>如果卡方统计量小于或等于临界值，不拒绝零假设，认为变量之间独立。


<br><br>卡方拟合优度检验用于确定观测频数与期望频数是否有显著差异。其步骤如下：<br>
<br>
构建假设：

<br>零假设（H0）：观测频数与期望频数没有显著差异。
<br>备择假设（H1）：观测频数与期望频数有显著差异。


<br>
计算期望频数：

<br>根据理论或模型计算每个类别的期望频数。


<br>
计算卡方统计量：

<br>使用以下公式计算卡方统计量：

 其中， 是观测频数， 是期望频数。


<br>
确定自由度：

<br>自由度的计算公式为：

 其中， 是类别数。


<br>
查表确定临界值：

<br>根据计算得出的自由度和显著性水平（通常为0.05），查找卡方分布表，找到临界值。


<br>
比较并得出结论：

<br>比较计算出的卡方统计量与临界值。
<br>如果卡方统计量大于临界值，拒绝零假设，认为观测频数与期望频数有显著差异。
<br>如果卡方统计量小于或等于临界值，不拒绝零假设，认为观测频数与期望频数没有显著差异。


<br>通过以上步骤，卡方检验可以有效地评估分类变量之间的关联性或观测数据与期望数据的拟合程度。]]></description><link>technology\collegeproject\机器学习\概念\卡方检验.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/卡方检验.md</guid><pubDate>Thu, 13 Jun 2024 02:29:05 GMT</pubDate></item><item><title><![CDATA[类别不平衡]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
类别不平衡（Class Imbalance）是指在分类问题中，不同类别的数据样本数量差异显著的情况。具体来说，就是某些类别的数据样本数量远多于其他类别。在这种情况下，模型可能会倾向于预测多数类别，而忽略或错误预测少数类别，从而导致模型性能下降。<br>例如，在一个二分类问题中，如果类别A有950个样本，而类别B只有50个样本，那么这个数据集就是不平衡的。模型在训练时可能会更多地学习到如何识别类别A，而忽略了类别B，导致在实际应用中对类别B的预测效果不佳。<br>类别不平衡常见于以下领域：<br>
<br>欺诈检测：合法交易远多于欺诈交易。
<br>医学诊断：健康样本远多于患病样本。
<br>故障检测：正常运行的数据远多于故障数据。
<br>解决类别不平衡的方法有很多，常见的方法包括：<br>
<br>重采样：通过过采样少数类（如SMOTE）或欠采样多数类来平衡数据集。
<br>数据增强：生成新的少数类样本。
<br>代价敏感学习：为少数类样本赋予更大的权重，使模型更重视少数类。
<br>使用合适的评估指标：如F1分数、ROC-AUC等，而不是单纯的准确率。
<br>通过这些方法，可以改善模型在不平衡数据集上的表现。<br><img alt="扫描件_李世博._002.jpg" src="\lib\media\扫描件_李世博._002.jpg">]]></description><link>technology\collegeproject\机器学习\概念\类别不平衡.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/类别不平衡.md</guid><pubDate>Wed, 03 Jul 2024 05:38:28 GMT</pubDate><enclosure url="lib\media\扫描件_李世博._002.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\扫描件_李世博._002.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[朴素贝叶斯]]></title><description><![CDATA[ 
 <br><br><img alt="文档扫描_20240520205016056.jpg" src="\lib\media\文档扫描_20240520205016056.jpg"><br><br>已知训练数据集如下表所示，使用贝叶斯算法预测样本  属于哪一类？<br><br>这样一个问题，用贝叶斯决策论怎么做？<br><br><br>先验概率是指在没有任何特征信息时，某个类别的概率。<br>根据训练数据集，我们有：<br>
<br>总样本数 (N = 12)
<br>类别为“是”的样本数 (N_{\text{是}} = 7)
<br>类别为“否”的样本数 (N_{\text{否}} = 5)
<br>先验概率：<br>
<br><br>对于每个类别 (c)，计算给定特征 (X) 的条件概率。<br><br><br><br><br><br><br><br><br><br><br><br>根据贝叶斯定理计算后验概率：<br><br><br>其中：<br><br><br>计算得：<br><br><br>再结合先验概率：<br><br><br>为了比较两个后验概率，我们可以忽略常数并直接比较：<br><br><br>通过计算：<br><br><br>因为 ( P(\text{是}|X) &gt; P(\text{否}|X) )，所以我们预测 (X) 属于“是”类别，即该样本会购买电脑。<br><br>根据后验概率的比较，我们最终选择后验概率较大的类别作为预测结果。<br>所以，样本 (X) 被预测为“是”，即会购买电脑。]]></description><link>technology\collegeproject\机器学习\概念\朴素贝叶斯.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/朴素贝叶斯.md</guid><pubDate>Wed, 03 Jul 2024 13:28:15 GMT</pubDate><enclosure url="lib\media\文档扫描_20240520205016056.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\文档扫描_20240520205016056.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[神经网络与感知机]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<img alt="扫描件_多分类任务_001 1.jpg" src="\lib\media\扫描件_多分类任务_001-1.jpg">]]></description><link>technology\collegeproject\机器学习\概念\神经网络与感知机.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/神经网络与感知机.md</guid><pubDate>Mon, 08 Apr 2024 11:53:37 GMT</pubDate><enclosure url="lib\media\扫描件_多分类任务_001-1.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\扫描件_多分类任务_001-1.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[误差逆传播算法(BP算法)]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<img alt="扫描件_地址仙林校区文苑路1号_003.jpg" src="\lib\media\扫描件_地址仙林校区文苑路1号_003.jpg"><img alt="扫描件_地址仙林校区文苑路1号_002.jpg" src="\lib\media\扫描件_地址仙林校区文苑路1号_002.jpg">]]></description><link>technology\collegeproject\机器学习\概念\误差逆传播算法(bp算法).html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/误差逆传播算法(BP算法).md</guid><pubDate>Wed, 10 Apr 2024 10:32:43 GMT</pubDate><enclosure url="lib\media\扫描件_地址仙林校区文苑路1号_003.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\扫描件_地址仙林校区文苑路1号_003.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[信息增益(ID3决策树)]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br><br>什么是信息增益？根据下图分别计算按照属性A和B划分时的信息增益。ID3决策树学习算法将会选择哪个属性？<br><br><br><br>熵（Entropy）: 衡量的是数据集的纯度。如果一个数据集中只有一类样本，熵最小，为0；如果类均匀分布，其熵最大。<br>
计算公式如下:<br><br>其中是选择该分类的概率。<br><br>信息增益 (Information Gain): 在决策树中，我们希望得到的子节点应比当前节点的熵更低，即数据分布更加均匀。可以使用信息增益来帮助实现这个目标。信息增益是父节点的熵和它的子节点熵之差。<br>
计算公式如下:<br><br>其中D是数据集，A是特征，是针对特征A的某一个可能划分子集。<br>
具体到你的问题，我们可以分别计算使用属性 A 和 B 划分时的信息增益：<br>
计算整个数据集的原始熵。<br>
划分数据集，计算每个子集的熵，然后计算分割后的总熵。<br>
计算信息增益：原始熵 - 分割后的总熵。<br><br>首先是统计一下类别的数据，我们有：<br>
正类：5个<br>
负类：5个<br><br>在公式  中，Pi是数据集D中第i类记录的概率。这里，正类的概率，负类的概率。所以，。<br><br><br>属性A=1的有7个数据点，其中正类有5个，负类有2个。熵计算为  。<br>
属性A=0的有3个数据点，其中负类3个。熵计算为  。<br>
所以，属性A的总熵为 。<br>对于属性B：<br>
属性B=1的有6个数据点，其中正类4个和负类2个。熵计算为 。<br>
属性B=0的有4个数据点，其中正类有1个，负类有3个。熵计算为  。<br>
所以，属性B的总熵为  。<br>
然后，计算信息增益。<br>
对于属性A，信息增益。<br>
对于属性B，信息增益。<br>
从上述计算结果来看，如果用属性A进行划分，其信息增益大于用属性B划分的信息增益，所以属性A在这种情况下是更好的选择。<br>
<img alt="文档扫描_20240428211547533.jpg" src="\lib\media\文档扫描_20240428211547533.jpg">]]></description><link>technology\collegeproject\机器学习\概念\信息增益(id3决策树).html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/信息增益(ID3决策树).md</guid><pubDate>Sun, 28 Apr 2024 13:23:47 GMT</pubDate><enclosure url="lib\media\文档扫描_20240428211547533.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\文档扫描_20240428211547533.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[信息增益率(C4.5决策树)]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<img alt="文档扫描_20240506193003149.jpg" src="\lib\media\文档扫描_20240506193003149.jpg"><br>
<img alt="文档扫描_20240506193003248.jpg" src="\lib\media\文档扫描_20240506193003248.jpg">]]></description><link>technology\collegeproject\机器学习\概念\信息增益率(c4.5决策树).html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/信息增益率(C4.5决策树).md</guid><pubDate>Mon, 06 May 2024 11:32:59 GMT</pubDate><enclosure url="lib\media\文档扫描_20240506193003149.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\文档扫描_20240506193003149.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[支持向量机（核函数&软间隔）]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<img alt="扫描件_WORM ALUN_002.jpg" src="\lib\media\扫描件_worm-alun_002.jpg"><img alt="扫描件_WORM ALUN_001.jpg" src="\lib\media\扫描件_worm-alun_001.jpg">]]></description><link>technology\collegeproject\机器学习\概念\支持向量机（核函数&amp;软间隔）.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/支持向量机（核函数&amp;软间隔）.md</guid><pubDate>Sun, 21 Apr 2024 02:01:27 GMT</pubDate><enclosure url="lib\media\扫描件_worm-alun_002.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\扫描件_worm-alun_002.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[支持向量机拉格朗日乘子法转化为对偶问题]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<img alt="760cd7e201e0e67aa94f3994159ae70a.png" src="\lib\media\760cd7e201e0e67aa94f3994159ae70a.png"><br><img alt="扫描件_地址仙林校区文苑路1号_001(1).jpg" src="\lib\media\扫描件_地址仙林校区文苑路1号_001(1).jpg">]]></description><link>technology\collegeproject\机器学习\概念\支持向量机拉格朗日乘子法转化为对偶问题.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/支持向量机拉格朗日乘子法转化为对偶问题.md</guid><pubDate>Sun, 21 Apr 2024 02:01:24 GMT</pubDate><enclosure url="lib\media\760cd7e201e0e67aa94f3994159ae70a.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\760cd7e201e0e67aa94f3994159ae70a.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[最大次序统计量]]></title><description><![CDATA[ 
 <br>对于总体  服从  的均匀分布，给定样本 ，我们有两个  的无偏估计量：<br>
<br>，其中  是样本均值，即 。
<br>，其中  是样本的最大次序统计量。
<br>我们将验证这两个估计量是无偏的，并比较它们的方差。<br><br> 的无偏性：<br>样本均值  是均匀分布  的样本的平均值。<br>对于均匀分布 ，每个  的期望为：<br>
<br>样本均值  的期望为：<br>
<br>因此， 的期望为：<br>
<br>所以， 是  的无偏估计量。<br> 的无偏性：<br>对于均匀分布 ，最大次序统计量  的期望为：<br>
<br>因此， 的期望为：<br>
<br>所以， 也是  的无偏估计量。<br><br> 的方差：<br>样本均值  的方差为：<br>
<br>对于均匀分布 ，每个  的方差为：<br>
<br>因此，样本均值  的方差为：<br>
<br>所以， 的方差为：<br>
<br> 的方差：<br>最大次序统计量  的方差为：<br>
<br>所以， 的方差为：<br>
<br><br>
<br> 是  的无偏估计量，其方差为 。
<br> 是  的无偏估计量，其方差为 。
<br>通过比较这两个方差，可以看出哪一个估计量在不同样本量  下更有效。<br><br>最大次序统计量  的方差的推导是基于均匀分布的性质和次序统计量的理论。下面是推导的详细步骤：<br><br>对于均匀分布  的随机样本 ，最大次序统计量  的分布是基于样本中最大值的分布。具体地，最大次序统计量  的累积分布函数（CDF）是：<br>
<br>其概率密度函数（PDF）为：<br>
<br>期望的计算：<br><br>做变量替换 ，则  且 ，积分变为：<br>
<br>积分 ，因此：<br>
<br>方差的计算：<br><br>首先计算 ：<br><br>同样做变量替换 ，则  且 ，积分变为：<br>
<br>积分 ，因此：<br>
<br>因此，最大次序统计量  的方差为：<br>
<br>计算得到：<br>
<br>将其化简：<br>
<br>因此，最大次序统计量  的方差为：<br>
<br><br>接下来，我们考虑  的方差：<br><br>将  代入：<br>
<br>所以， 的方差为：<br>
<br><br>
<br>最大次序统计量  的方差为 。
<br>估计量  的方差为 。
<br><br>最大次序统计量  的累积分布函数（CDF）可以通过次序统计量的基本理论来推导。给定一组来自均匀分布  的独立同分布随机变量 ，最大次序统计量  是这组变量中最大的一个。<br><br>为了求最大次序统计量  的累积分布函数，我们首先考虑  的概率。这相当于样本中所有的值都不超过 。<br><br>这是所有  都小于或等于  的概率。<br><br>由于  是独立同分布的，联合概率可以写成单个概率的乘积：<br><br>对于均匀分布 ，单个  的累积分布函数  是：<br><br>因此，<br><br>所以，最大次序统计量  的累积分布函数  是：<br><br><br>通过对累积分布函数求导，我们可以得到概率密度函数（PDF）：<br><br>求导结果是：<br><br><br>期望值<br><br><br>做变量替换 ，则 ，所以 ：<br><br><br>方差<br><br>首先计算 ：<br><br><br>同样做变量替换 ，积分变为：<br><br><br>因此，<br><br><br>化简：<br><br><br><br><br><br>
<br>最大次序统计量  的累积分布函数为：<br>

<br>最大次序统计量  的概率密度函数为：<br>

<br>最大次序统计量  的期望值为：<br>

<br>最大次序统计量  的方差为：<br>

]]></description><link>technology\collegeproject\机器学习\概念\最大次序统计量.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/最大次序统计量.md</guid><pubDate>Thu, 13 Jun 2024 12:11:51 GMT</pubDate></item><item><title><![CDATA[最小二乘法]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<img alt="Pasted image 20240408195108.png" src="\lib\media\pasted-image-20240408195108.png"><br>]]></description><link>technology\collegeproject\机器学习\概念\最小二乘法.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/最小二乘法.md</guid><pubDate>Sun, 12 May 2024 15:17:17 GMT</pubDate><enclosure url="lib\media\pasted-image-20240408195108.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240408195108.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Boosting&Bagging]]></title><description><![CDATA[ 
 <br>集成学习是通过构建并结合多个学习器来完成学习任务的一种机器学习方法。常见的两种集成学习方法是Bagging和Boosting。以下是这两种方法的原理和特点，以及集成学习相对于单个模型的优势和应用场景。<br><br><br>Bagging（Bootstrap Aggregating）是一种并行集成学习方法，它通过对数据集进行自助采样（Bootstrap Sampling）生成多个训练子集，并在每个子集上训练一个基学习器（通常是同类型的，如决策树）。最终的预测结果是通过对所有基学习器的预测结果进行平均（回归任务）或投票（分类任务）得到。<br><br>
<br>并行训练：所有基学习器可以同时训练，训练时间较短。
<br>减少方差：通过集成多个模型，Bagging能有效减少模型的方差，提升稳定性和泛化能力。
<br>抗过拟合：特别适用于容易过拟合的高方差模型，如决策树。
<br><br>
<br>随机森林（Random Forest）：通过Bagging集成多棵决策树，同时引入特征选择的随机性，进一步提高模型性能和鲁棒性。
<br><br><br>Boosting是一种串行集成学习方法，通过逐步训练一系列基学习器，每个基学习器都试图纠正其前一阶段的错误。具体来说，每个新模型在之前模型的基础上进行训练，更多地关注那些被前一阶段模型错误分类的样本。最终的预测结果是所有基学习器的加权和。<br><br>
<br>串行训练：基学习器是顺序训练的，训练时间较长。
<br>减少偏差：Boosting通过逐步校正错误，能有效减少模型的偏差，提高准确性。
<br>强鲁棒性：适用于弱学习器（如简单的决策树），通过集成得到强学习器。
<br><br>
<br>AdaBoost：通过调整样本权重来关注错误分类的样本。
<br>梯度提升（Gradient Boosting）：通过优化损失函数逐步构建集成模型，包括GBDT（Gradient Boosting Decision Tree）和XGBoost等变体。
<br><br>
<br>提高准确性：通过结合多个模型的优点，集成学习通常能获得比单个模型更高的预测准确性。
<br>降低方差和偏差：通过Bagging和Boosting分别降低模型的方差和偏差，集成学习能提高模型的稳定性和泛化能力。
<br>抗噪能力：集成学习能有效处理噪声数据，提高对异常数据的鲁棒性。
<br><br>
<br>金融领域：信用评分、股票价格预测等。
<br>医疗诊断：疾病预测、药物反应预测等。
<br>图像处理：图像分类、目标检测等。
<br>自然语言处理：文本分类、情感分析等。
<br><br>以下是Python中使用Scikit-learn实现Bagging和Boosting的简单示例：<br>from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.ensemble import BaggingClassifier, AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

# 加载数据集
iris = load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Bagging示例
bagging = BaggingClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)
bagging.fit(X_train, y_train)
y_pred_bagging = bagging.predict(X_test)
print(f"Bagging Accuracy: {accuracy_score(y_test, y_pred_bagging):.4f}")

# Boosting示例
boosting = AdaBoostClassifier(base_estimator=DecisionTreeClassifier(), n_estimators=10, random_state=42)
boosting.fit(X_train, y_train)
y_pred_boosting = boosting.predict(X_test)
print(f"Boosting Accuracy: {accuracy_score(y_test, y_pred_boosting):.4f}")
<br><br>
<br>加载数据集：使用Iris数据集进行分类任务。
<br>Bagging示例：使用Bagging集成多个决策树分类器，并计算预测准确性。
<br>Boosting示例：使用AdaBoost集成多个决策树分类器，并计算预测准确性。
<br>通过这种方式，可以直观地比较Bagging和Boosting在同一数据集上的效果。<br><br><br>弱分类器的权重，或叫做弱分类器在最后投票分类结果中的影响力，通过以下公式计算：<br>
<br>弱分类器的错误率<br><br>数据样本的权重，通过以下公式进行更新：<br>
被弱分类器正确分类的样本：<br>
<br>
被弱分类器错误分类的样本：<br>
<br>
这里， 是第 i 个样本标签， 是  弱分类器对第  个样本的预测结果。<br>
由于我们需要  是合法的概率分布，所以最后还需要对  进行归一化处理：<br>
<br>
是  所有元素的和，它的引入是为了确保更新后的权重之和仍然为 1]]></description><link>technology\collegeproject\机器学习\概念\boosting&amp;bagging.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/Boosting&amp;Bagging.md</guid><pubDate>Wed, 03 Jul 2024 13:05:48 GMT</pubDate></item><item><title><![CDATA[BT、GBDT]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<img alt="文档扫描_20240513203455994.jpg" src="\lib\media\文档扫描_20240513203455994.jpg">]]></description><link>technology\collegeproject\机器学习\概念\bt、gbdt.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/BT、GBDT.md</guid><pubDate>Mon, 20 May 2024 11:36:31 GMT</pubDate><enclosure url="lib\media\文档扫描_20240513203455994.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\文档扫描_20240513203455994.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[GMM(高斯混合模型)]]></title><description><![CDATA[ 
 <br><img alt="文档扫描_20240522213821353.jpg" src="\lib\media\文档扫描_20240522213821353.jpg"><br><img alt="文档扫描_20240523102511512.jpg" src="\lib\media\文档扫描_20240523102511512.jpg"><br><img alt="文档扫描_20240523102242884.jpg" src="\lib\media\文档扫描_20240523102242884.jpg"><br><br>估计高斯混合模型（GMM）的参数通常使用期望最大化（EM）算法。对于两个分量的高斯混合模型，我们需要估计以下5个参数：<br>
<br> 和 ：两个高斯分布的混合系数。
<br> 和 ：两个高斯分布的均值。
<br> 和 ：两个高斯分布的方差。
<br>给定观测数据 ，我们可以使用EM算法估计这5个参数。<br><br>首先随机初始化参数 , , , , , 和 。例如：<br>
<br>
<br>
<br>
<br><br>计算每个数据点属于每个高斯分布的后验概率，即责任度：<br><br><br>其中  是正态分布的概率密度函数。<br><br>根据责任度更新参数：<br><br><br><br><br><br><br><br>重复E-step和M-step，直到参数收敛或达到预定的迭代次数。<br><br>下面是使用Python和Scikit-learn实现GMM参数估计的代码示例：<br>import numpy as np
from sklearn.mixture import GaussianMixture

# 观测数据
data = np.array([-67, -48, 6, 8, 14, 16, 23, 24, 28, 29, 41, 49, 56, 60, 75]).reshape(-1, 1)

# 初始化GMM模型
gmm = GaussianMixture(n_components=2, random_state=42)

# 拟合模型
gmm.fit(data)

# 获取参数
weights = gmm.weights_
means = gmm.means_.flatten()
covariances = gmm.covariances_.flatten()

print(f"Weights: {weights}")
print(f"Means: {means}")
print(f"Variances: {covariances}")
<br><br>
<br>数据准备：将观测数据转换为NumPy数组，并将其形状调整为适合Scikit-learn的输入格式。
<br>初始化模型：使用GaussianMixture初始化GMM模型，并指定两个分量。
<br>拟合模型：使用观测数据拟合模型。
<br>获取参数：从拟合后的模型中提取混合系数、均值和方差。
<br>通过这种方式，可以估计出两个分量的高斯混合模型的5个参数。]]></description><link>technology\collegeproject\机器学习\概念\gmm(高斯混合模型).html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/GMM(高斯混合模型).md</guid><pubDate>Wed, 03 Jul 2024 13:50:06 GMT</pubDate><enclosure url="lib\media\文档扫描_20240522213821353.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\文档扫描_20240522213821353.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[轮廓系数（Silhouette Score）]]></title><description><![CDATA[ 
 <br><img alt="Pasted image 20240529002516.png" src="\lib\media\pasted-image-20240529002516.png"><br>
<img alt="扫描件_元南京师范大学_002.jpg" src="\lib\media\扫描件_元南京师范大学_002.jpg"><br>
<img alt="Pasted image 20240529002527.png" src="\lib\media\pasted-image-20240529002527.png"><br>
<img alt="Pasted image 20240529002545.png" src="\lib\media\pasted-image-20240529002545.png"><br>轮廓系数（Silhouette Score）和戴维森堡丁指数（Davies-Bouldin Index）是常用的聚类质量评价指标。它们有各自的衡量标准，用来判断聚类效果的好坏。以下是这两个指标的详细衡量标准：<br><br>轮廓系数的取值范围为 -1 到 1，数值越大表示聚类效果越好。具体衡量标准如下：<br>1 表示样本点非常适合自己所在的簇，并且远离其他簇，聚类效果极佳。<br>
接近 1 表示样本点适合自己所在的簇，并且与其他簇有明显的分离，聚类效果较好。<br>
0 表示样本点处于两个簇的边界上，聚类效果一般。<br>
负值 表示样本点更适合分到其他簇中，聚类效果很差。<br><br>戴维森堡丁指数的取值范围为 0 到正无穷，数值越小表示聚类效果越好。具体衡量标准如下：<br>接近 0 表示簇间的分离度较高且簇内的紧密度较高，聚类效果很好。<br>
较大值 表示簇间的分离度较低且簇内的紧密度较低，聚类效果较差。<br>衡量标准总结<br>轮廓系数：<br>越接近 1，聚类效果越好。<br>
越接近 -1，聚类效果越差。<br>
戴维森堡丁指数：<br>越接近 0，聚类效果越好。<br>
越大，聚类效果越差。<br>DBI &lt; 1：聚类效果通常较好，簇间分离度高，簇内紧密度高。<br>
1 &lt;= DBI &lt; 2：聚类效果一般，可能存在一些簇间重叠，但大多数簇仍然是合理的。<br>
DBI &gt;= 2：聚类效果较差，簇间分离度低，簇内紧密度低，簇间可能存在较多重叠。]]></description><link>technology\collegeproject\机器学习\概念\k-means、dbscan、agnes聚类.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/K-means、DBSCAN、AGNES聚类.md</guid><pubDate>Tue, 04 Jun 2024 07:24:01 GMT</pubDate><enclosure url="lib\media\pasted-image-20240529002516.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240529002516.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[PCA]]></title><description><![CDATA[ 
 <br><br>数据降维是数据预处理中的重要步骤，旨在减少数据的维度，同时尽可能保留数据的主要信息。<br><br>
<br>主成分分析（PCA）：通过线性变换将数据投影到一个新的坐标系中，新的坐标系由数据的主成分构成，主成分是数据协方差矩阵的特征向量。
<br>线性判别分析（LDA）：主要用于监督学习，通过最大化类间散布矩阵和最小化类内散布矩阵来找到最佳投影方向。
<br>非负矩阵分解（NMF）：将数据矩阵分解成两个非负矩阵的乘积，常用于图像处理和文本挖掘。
<br>多维缩放（MDS）：用于探索多维数据中的相似性或差异性，试图保留原始数据点之间的距离。
<br>独立成分分析（ICA）：主要用于信号处理，假设观测数据是若干独立非高斯信号的线性混合。
<br>t-分布随机邻域嵌入（t-SNE）：非线性降维方法，特别适合于高维数据的可视化。
<br>自编码器（Autoencoder）：一种基于神经网络的非线性降维方法。
<br><br>主成分分析（PCA）是一种线性降维技术，以下是其计算流程：<br>
<br>
数据标准化：将数据中的每个特征标准化，使其均值为0，方差为1。

其中， 和  分别是第  个特征的均值和标准差。

<br>
计算协方差矩阵：对标准化后的数据计算协方差矩阵。

其中， 是标准化后的数据矩阵， 是样本数。

<br>
特征值分解：对协方差矩阵进行特征值分解，得到特征值和特征向量。

其中， 是特征值， 是对应的特征向量。

<br>
排序：将特征值按从大到小排序，并相应地对特征向量进行排序。

<br>
选择主成分：选择前  个最大特征值对应的特征向量，组成变换矩阵。


<br>
数据转换：用变换矩阵将原始数据转换到新的  维空间。


<br><br>确定 PCA 降维后的维度  时，通常考虑以下几点：<br>
<br>
累计解释方差：选择特征值累计解释方差达到某一阈值（如95%）时对应的主成分个数。累计解释方差表示选取的主成分所能解释的总方差的比例。

其中， 是第  个特征值， 是总特征值数。

<br>
碎石图（Scree Plot）：绘制特征值从大到小排序的折线图，观察图形的拐点，拐点前的特征值通常用于确定 。

<br>
领域知识：结合具体问题和领域知识，确定合理的降维维度。

<br>通过这些方法，可以合理地选择降维后的维度，确保在最大限度保留数据主要信息的同时，减少数据的复杂性。<br><br>协方差矩阵在PCA中的计算是为了描述数据集各个特征之间的线性关系。其计算方法有助于识别和理解特征间的相关性。以下是协方差矩阵计算的详细解释和推导：<br><br>协方差是用来衡量两个随机变量之间的线性相关性。对于两个变量  和 ，协方差定义为：<br><br>其中，  表示期望（均值）。若协方差为正，表示两个变量正相关；若为负，表示负相关；若为零，表示不相关。<br><br>对于一个有  个特征（变量）的数据集，协方差矩阵是一个  的矩阵，矩阵中的每个元素表示两个特征之间的协方差。协方差矩阵  的形式为：<br><br>这里，  表示第  个特征和第  个特征之间的协方差。<br><br>在计算协方差矩阵之前，通常需要对数据进行标准化（均值为 0，方差为 1），这样可以使每个特征具有相同的尺度。这一步的标准化公式为：<br><br>其中， 是原始数据，  是第  个特征的均值，  是第  个特征的标准差。<br><br>假设我们有一个标准化后的数据矩阵 ，其中每一行是一个样本，每一列是一个特征，数据矩阵的维度是 （  为样本数，  为特征数）。协方差矩阵的计算步骤如下：<br>
<br>
计算数据矩阵的转置： 令  表示  的转置，转置后的矩阵维度是 。

<br>
计算协方差矩阵：

<br><br>其中， 的结果是一个  的矩阵，表示所有特征对之间的内积。通过除以  可以得到特征对之间的协方差。<br><br>
<br>
捕捉特征间的关系：协方差矩阵的每个元素都反映了两个特征之间的线性关系，通过协方差矩阵可以了解数据的结构和特征之间的依赖性。

<br>
数据投影的性质：PCA 的目标是将数据投影到一个新的坐标系中，在新的坐标系中，各主成分是不相关的，即协方差为零。通过对原始数据的协方差矩阵进行特征值分解，可以找到这些正交的主成分。

<br>
特征值和特征向量：协方差矩阵的特征值和特征向量决定了数据在新坐标系中的投影方向和投影长度。特征值越大，对应的特征向量（主成分）能够解释的数据方差就越多。

<br>综上所述，通过计算协方差矩阵，我们可以量化和理解数据中的相关性，并为后续的特征值分解和数据投影提供基础。这样，PCA 能够有效地降维并保留数据的主要信息。<br><br>在计算协方差矩阵时，为什么要使用  而不是  是一个常见的问题。这个选择主要是与统计学中的“不偏估计”有关。以下是详细解释：<br><br>当我们从总体中抽取一个样本来估计总体的协方差时，我们希望我们的估计是“无偏的”，即在多次抽样的期望下，我们的估计值应该等于总体的真实值。<br>假设我们有一个样本  有  个数据点，每个数据点有  个特征。数据矩阵的维度是 。为了计算协方差矩阵，我们首先需要对数据进行中心化，即减去每个特征的均值。<br><br>中心化后的数据矩阵  为：<br><br>其中  是一个  的矩阵，每行都是特征均值的向量。<br><br>中心化后的数据矩阵  的协方差矩阵为：<br><br><br>当我们计算样本协方差时，使用  而不是  是为了得到无偏估计。以下是原因：<br>
<br>
自由度调整：在样本协方差的计算中，我们使用样本的均值来替代总体均值。这意味着我们失去了一个自由度，因为均值是从样本中估计的。因此，为了校正这个估计的偏差，我们使用  而不是 。

<br>
无偏估计：如果我们使用 ，得到的协方差矩阵是偏差估计，即期望值不等于总体协方差。通过使用 ，我们可以确保协方差的期望值是无偏的。

<br>更详细地说，设总体的协方差矩阵为 ，样本均值为 ，总体均值为 ，则样本协方差矩阵的期望值为：<br><br>而使用  的期望值会有所偏差，不等于 。<br><br>可以通过一个简单的例子来直观理解。假设我们有一个变量 ，我们从中抽取两个样本  和 。样本方差为：<br><br>如果我们使用  作为分母，当  时，会低估总体方差，因为计算样本均值时已经消耗了一个自由度。因此，使用  作为分母可以校正这种低估，确保样本方差是总体方差的无偏估计。<br><br>使用  来计算协方差矩阵是为了得到无偏估计，考虑了样本均值对自由度的影响。这一调整使得我们的估计更准确地反映了总体的实际协方差。<br><br>在主成分分析（PCA）中，累计解释方差（Cumulative Explained Variance） 是衡量选择了前  个主成分后所能解释的总方差比例。它帮助我们确定需要保留多少个主成分才能在降维的同时尽量保留原始数据的信息。<br><br>每个主成分的解释方差比例表示该主成分所能解释的原始数据总方差的比例。解释方差比例由主成分对应的特征值（Eigenvalue）决定。<br><br>
<br>
特征值分解：对数据的协方差矩阵进行特征值分解，得到特征值和特征向量。特征值表示相应主成分的方差。
设协方差矩阵的特征值为 ，其中 。

<br>
计算单个主成分的解释方差比例：
对于第  个主成分，其解释方差比例为：


<br>
计算累计解释方差：
前  个主成分的累计解释方差比例为：


<br><br>通常我们希望选择最少的主成分来解释最多的方差。累计解释方差提供了一个标准，常见的方法包括：<br>
<br>设定阈值：例如，选择累计解释方差达到95%或99%的前几个主成分。
<br>碎石图（Scree Plot）：绘制特征值的大小并观察其变化，选择特征值明显下降之前的主成分个数。
<br><br>假设我们有一个数据集，经过PCA分析得到的特征值如下：<br><br>总方差为：<br><br>各个主成分的解释方差比例为：<br><br>前3个主成分的累计解释方差为：<br><br>这意味着，选择前3个主成分可以解释约90.9%的总方差。如果我们认为90.9%的解释方差已经足够高，那么可以选择前3个主成分进行降维。<br><br>累计解释方差是选择主成分数量的重要依据，确保在降维过程中尽可能保留原始数据的主要信息。]]></description><link>technology\collegeproject\机器学习\概念\pca.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/PCA.md</guid><pubDate>Mon, 10 Jun 2024 13:18:13 GMT</pubDate></item><item><title><![CDATA[ROC曲线与混淆矩阵]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br><br><br><br><br><img alt="扫描件_19220423_002.jpg" src="\lib\media\扫描件_19220423_002.jpg">]]></description><link>technology\collegeproject\机器学习\概念\roc曲线与混淆矩阵.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/概念/ROC曲线与混淆矩阵.md</guid><pubDate>Wed, 03 Jul 2024 05:35:41 GMT</pubDate><enclosure url="lib\media\扫描件_19220423_002.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\扫描件_19220423_002.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[上机实验：集成学习]]></title><description><![CDATA[ 
 <br><br><br>已知基于单层决策树的 AdaBoost 算法的伪代码如下：<br>
<br>
初始化所有参数，其中样本权重都为 

<br>
迭代次数 i&lt;itermax:

<br>
调用 buildStump() 函数得到最佳的单层决策树

<br>
将该最佳单层决策树存储到单层决策树数组中

<br>
根据当前单层决策树的错误率 ，并根据该错误率计算 

<br>
更新样本的权重向量 D

<br>
更新累积预测值，并计算前 i 个弱分类器集成得到的错误率

<br>
如果该错误率等于 0.0，则退出循环



<br>
其中在第 t 轮训练中：

<br> <br> <br>其中  为归一化因子。<br>
<br>
假设现在已经实现了基于加权输入值进行决策的最佳单层决策树生成函数 buildStump()与决策函数 stumpClassify()；

<br>
请补全完整的 AdaBoost 训练函数 adaBoostTrainDS()；

<br>
给定一个二分类任务，数据集为描述马疝病的数据集，任务目标为预测患有马疝病的马是否能够存活。现已经把数据集分为训练集 train_data、train_label和测试集test_data、 test_label。其中 train_data 包含 299 个数据样本，21 个特征；test_data 包含 67 个数据样本，21 个特征，数据集的标签取值为 1(存活)和 -1(死亡)；

<br>
请使用 adaBoostTrainDS() 根据马疝病的训练集 train_data、train_label 训练（迭代数为 40）得到一个集成学习模型 weak_clfs；

<br>
根据训练好的集成学习模型 weak_clfs，使用stumpClassify()对测试集test_data进行预测，得到预测结果pred_label并结合真实标记test_label进行评估。

<br>
前序代码：stumpClassify() 和 buildStump()
<br>def stumpClassify(dataMatrix, dimen, threshVal, threshIneq):
    preArray = ones((dataMatrix.shape[0], 1)) # 初始化预测为1
    if threshIneq == 'lt':
        preArray[dataMatrix[:, dimen] &lt;= threshVal] = -1.0
    else:
        preArray[dataMatrix[:, dimen] &gt; threshVal] = -1.0
    return preArray
<br>def buildStump(dataArr,classLabels,D):
    # 先定义之后要用到的一些变量
    dataMatrix = mat(dataArr)
    labelMat = mat(classLabels).T
    m, n = dataMatrix.shape
    numSteps = 10.0
    bestStump = {}
    bestClasEst = mat(zeros((m, 1)))
    minError = inf
    for i in range(n):# 对所有特征进行迭代
        rangeMin = dataMatrix[:, i].min()
        rangeMax = dataMatrix[:, i].max()
        stepSize = (rangeMax - rangeMin)/numSteps # 特征的值变化的步长
        for j in range(-1, int(numSteps)+1):# 对所有特征的值进行迭代
            for inequal in ['lt', 'gt']: # 两种标记方式的切换
                threshVal = (rangeMin + float(j) * stepSize)
                predictedVals = stumpClassify(dataMatrix, i, threshVal, inequal)
                errArr = mat(ones((m, 1)))
                errArr[predictedVals == labelMat] = 0
                weightedError = D.T*errArr  # 计算加权错误率
                # print "split: dim %d, thresh %.2f, thresh ineqal: %s, the weighted error is %.3f" % (i, threshVal, inequal, weightedError)
                if weightedError &lt; minError:
                    minError = weightedError
                    bestClasEst = predictedVals.copy()
                    bestStump['dim'] = i
                    bestStump['thresh'] = threshVal
                    bestStump['ineq'] = inequal
    return bestStump, minError, bestClasEst
<br>#数据加载与预处理 
import pandas as pd
import numpy as np
from sklearn.metrics import classification_report

def load_data(path):
    data = pd.read_csv(path, sep='\t', names=[i for i in range(22)])
    data = np.array(data).tolist()
    x = []; y = []
    for i in range(len(data)):
        y.append(data[i][-1])
        del data[i][-1]
        x.append(data[i])

    x = np.array(x)
    y = np.array(y)

    return x, y
train_data, train_label = load_data('horseColicTraining.txt')
test_data, test_label = load_data('horseColicTest.txt')
<br>
待完善代码
<br>from numpy import mat, zeros, ones, multiply, exp, sign, inf, log

# 请补全下列代码 #
def adaBoostTrainDS(dataArr, classLabels, itermax=40):
    weakClassArr = [] # 准备一个存储所有弱分类器的空列表
    m = dataArr.shape[0] 
    D = mat(ones((m, 1))/m)   # 初始化所有样本为相同的权重
    aggClassEst = mat(zeros((m, 1))) # 最终集成模型的预测向量
    for i in range(itermax): 
        
        # 获得当前最佳的单层决策树beatStump，错误率error，预测结果classEst
        bestStump, error, classEst = buildStump(dataArr, classLabels, D)
        
        # 计算bestStump对应的alpha，并存储在beatStump字典中（注意error=0的情况）
        alpha = float(0.5*np.log((1.0-error)/max(error,1e-16)))
        
        bestStump['alpha'] = alpha
        
        # 将当前的最佳单层决策树放入存储列表中
        weakClassArr.append(bestStump)
        
        # 更新样本权重D classEst为预测结果，classLabels为真实值，D.sum()为Z_t
        expon = np.multiply(-1*alpha*np.mat(classLabels).T,classEst) 
        D = np.multiply(D,np.exp(expon))                              
        D = D/D.sum()
        
        # 计算集成之前i-1个弱分类器预测的错误率errorRate
        aggClassEst += alpha*classEst                                    
        aggErrors = np.multiply(np.sign(aggClassEst) != np.mat(classLabels).T,np.ones((m,1))) 
        errorRate = aggErrors.sum()/m
        print ("total error: ", errorRate)
        
        if errorRate == 0.0: break
    return weakClassArr, aggClassEst

# adaboost模型训练
weak_clfs,_ = adaBoostTrainDS(train_data, train_label)
print(weak_clfs[1])
<br>total error:  0.2842809364548495
total error:  0.2842809364548495
total error:  0.24749163879598662
total error:  0.24749163879598662
total error:  0.25418060200668896
total error:  0.2408026755852843
total error:  0.2408026755852843
total error:  0.22073578595317725
total error:  0.24749163879598662
total error:  0.23076923076923078
total error:  0.2408026755852843
total error:  0.2140468227424749
total error:  0.22742474916387959
total error:  0.21739130434782608
total error:  0.22073578595317725
total error:  0.21739130434782608
total error:  0.22408026755852842
total error:  0.22408026755852842
total error:  0.23076923076923078
total error:  0.22408026755852842
total error:  0.2140468227424749
total error:  0.20735785953177258
total error:  0.22408026755852842
total error:  0.22408026755852842
total error:  0.2140468227424749
total error:  0.22073578595317725
total error:  0.2040133779264214
total error:  0.20735785953177258
total error:  0.21070234113712374
total error:  0.21739130434782608
total error:  0.21070234113712374
total error:  0.21739130434782608
total error:  0.20735785953177258
total error:  0.21070234113712374
total error:  0.20735785953177258
total error:  0.20735785953177258
total error:  0.19732441471571907
total error:  0.19063545150501673
total error:  0.20066889632107024
total error:  0.19732441471571907
{'dim': 17, 'thresh': 52.5, 'ineq': 'gt', 'alpha': 0.3124824504246711}
<br># adaboost模型预测与评估

# 预测标记向量初始化
pred_label=np.zeros((test_label.shape[0],1))
for clf in weak_clfs: 
    # 使用`stumpClassify()`对测试集`test_data`进行预测
    pred_label = stumpClassify(test_data,clf['dim'], clf['thresh'], clf['ineq'])
    # 预测的结果与前面的个体学习器预测结果进行加权融合
    pred_label = clf['alpha']*np.sign(pred_label)

pred_label = np.sign(pred_label)
print(classification_report(test_label, pred_label))

<br>              precision    recall  f1-score   support

        -1.0       0.32      0.65      0.43        20
         1.0       0.73      0.40      0.52        47

    accuracy                           0.48        67
   macro avg       0.52      0.53      0.47        67
weighted avg       0.61      0.48      0.49        67
<br><br>
<br>对病马疝气病数据集使用 sklearn.ensemble 中的 AdaBoostClassifier，构建 AdaBoost 模型，完成预测病马的分类任务；
<br>请尝试使用不同的超参数，以使得最终模型对于测试集的准确率大于等于 0.75，并与自行实现的 AdaBoost分类器结果进行比较。
<br>
待完善代码
<br>from sklearn.metrics import classification_report, accuracy_score
from sklearn.ensemble import AdaBoostClassifier  

# 构建adaboost模型clf，并基于训练集训练
clf = AdaBoostClassifier()
clf = clf.fit(train_data, train_label)
# 使用训练后的clf对测试集进行预测
pred_label = clf.predict(test_data)

# 计算模型的正确率
score = accuracy_score(test_label, pred_label)

print("Accuracy:", score)

# 查看详细的模型评价报告
print(classification_report(test_label, pred_label))
<br>Accuracy: 0.7761194029850746
              precision    recall  f1-score   support

        -1.0       0.62      0.65      0.63        20
         1.0       0.85      0.83      0.84        47

    accuracy                           0.78        67
   macro avg       0.73      0.74      0.74        67
weighted avg       0.78      0.78      0.78        67
<br><br>
<br>加载sklearn中的wine三分类数据集，进行数据集划分；
<br>分别使用sklearn中决策树分类器DecisionTreeClassifier与随机森林分类器RandomForestClassifier进行模型训练；
<br>进行模型评估与比较；
<br>通过交叉验证再次比较决策树分类器与随机森林分类器的分类性能。
<br>from sklearn import tree
from sklearn.datasets import load_wine
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import pandas as pd
import graphviz
import matplotlib.pyplot as plt

wine = load_wine()
# 划分训练集与测试集
x_train, x_valid, y_train, y_valid = train_test_split(wine.data, wine.target, test_size=0.3)

# 样本输出
pd.concat([pd.DataFrame(wine.data), pd.DataFrame(wine.target)], axis=1)
<br>
<br>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
<br>
178 rows × 14 columns
<br>
待完善代码
<br># 实例化决策树分类器与模型训练
clf = DecisionTreeClassifier()
clf.fit(x_train,  y_train)

# 决策树可视化
feature_name = ['酒精', '苹果酸', '灰', '灰的碱性', '镁', '总酚', '类黄素', '非黄烷类分类', '花青素', '颜色强度', '色调', '稀释葡萄酒', '脯氨酸']
dot_data = tree.export_graphviz(clf
                                ,feature_names=feature_name
                                ,class_names=["琴酒", "雪梨", "贝尔摩德"]
                                ,filled=True
                                ,rounded=True
                                )
graph = graphviz.Source(dot_data)
graph
<br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_16_0.svg"><br># 实例化随机森林分类器与模型训练
rfc = RandomForestClassifier(
    criterion="gini",
    n_estimators=10, # 定义个体分类器的个数
    max_depth=10, # 定义树的深度, 可以用来防止过拟合
    min_samples_split=0.05, # 定义至少多少个样本的情况下才继续分叉
    min_weight_fraction_leaf=0.05 # 定义叶子节点最少需要包含多少个样本(使用百分比表达), 防止过拟合
    )
# 模型训练
rfc=rfc.fit(x_train,  y_train)
<br>from sklearn.metrics import roc_auc_score, classification_report
from sklearn.preprocessing import LabelBinarizer

# 决策树分类器对测试样本x_valid与y_valid进行评估
score_c = clf.score(x_valid, y_valid)
print("Single Tree:{}".format(score_c))

# 随机森林分类器对测试样本x_valid与y_valid进行评估
score_r = rfc.score(x_valid, y_valid)
print("Random Forest:{}".format(score_r))

# 使用LabelBinarizer函数将多分类标签转换为one-hot编码向量

# 先进行初始化
encoder = LabelBinarizer()

# 对 y_valid 进行拟合和转换，得到 one-hot 编码
y_valid_one_hot = encoder.fit_transform(y_valid)

# 使用roc_auc_score函数计算随机森林分类器对测试样本的auc结果

y_pred_score = rfc.predict_proba(x_valid)
y_pred_score_positive = y_pred_score[:, 1].reshape(-1, 1)
rfc_roc_auc = roc_auc_score(y_valid_one_hot, y_pred_score_positive)

print ("随机森林 AUC = %2.2f" % rfc_roc_auc)
print(classification_report(y_valid, rfc.predict(x_valid)))

# 思考将随机森林中集成的多个决策树进行可视化（选做）
# 请在下方补充
for i, estimator in enumerate(rfc.estimators_):
    dot_data = tree.export_graphviz(estimator, out_file=None, 
                    feature_names = feature_name,
                    class_names =["琴酒", "雪梨", "贝尔摩德"],
                    filled=True, rounded=True,
                    special_characters=True)
    graph = graphviz.Source(dot_data)
    display(graph)


<br>Single Tree:0.8703703703703703
Random Forest:0.9629629629629629
随机森林 AUC = 0.23
              precision    recall  f1-score   support

           0       0.95      1.00      0.97        19
           1       1.00      0.90      0.95        20
           2       0.94      1.00      0.97        15

    accuracy                           0.96        54
   macro avg       0.96      0.97      0.96        54
weighted avg       0.97      0.96      0.96        54
<br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_1.svg"><br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_2.svg"><br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_3.svg"><br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_4.svg"><br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_5.svg"><br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_6.svg"><br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_7.svg"><br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_8.svg"><br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_9.svg"><br><img alt="svg" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_18_10.svg"><br># 交叉验证
from sklearn.model_selection import cross_val_score
import matplotlib.pyplot as plt

# 使用cross_val_score函数在wine数据上对上述两个分类器进行10折交叉验证
rfc_s = cross_val_score(rfc,wine.data, wine.target,cv=10)
clf_s = cross_val_score(clf,wine.data, wine.target,cv=10)

plt.plot(range(1, 11), rfc_s, label="RandomForest")
plt.plot(range(1, 11), clf_s, label="DecisionTreeClassifier")
plt.legend()
plt.show()
<br><img alt="png" src="\technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_19_0.png"><br>]]></description><link>technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\集成学习随机森林.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/集成学习随机森林/集成学习随机森林.md</guid><pubDate>Sat, 18 May 2024 08:22:43 GMT</pubDate><enclosure url="technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_16_0.svg" length="0" type="image/svg+xml"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\机器学习\机器学习实验\集成学习随机森林\output_16_0.svg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[案例一：房价分析与预测]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br><br><br>
<br>数据准备：导入数据、特征可视化
<br>数据预处理：数据集划分、数据标准化处理
<br>模型训练：线性回归、岭回归、梯度提升决策树GBDT
<br>模型评估与参数选择
<br><br>from sklearn.datasets import load_boston
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

boston = load_boston()
print( boston.DESCR)
<br><br>plt.figure(figsize=(20,10))
for i in range(13):
    plt.subplot(2,7,i+1)
    plt.scatter(boston.data[:,i],boston.target,s=20)
    plt.title(boston.feature_names[i])
plt.savefig('img.png')
plt.show()
<br><br>from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test = train_test_split(boston.data,\
              boston.target,test_size=0.2,random_state=33)

print(X_train.shape, y_train.shape)
print(X_test.shape, y_test.shape)
<br>(404, 13) (404,)
(102, 13) (102,)
<br><br>from sklearn.preprocessing import StandardScaler, MinMaxScaler
#分别初始化对特征值和目标值的标准化器
ss_X = StandardScaler()#MinMaxScaler()
ss_y = StandardScaler()#MinMaxScaler()
#训练数据都是数值型，所以要标准化处理
print(X_train[1,])
X_train = ss_X.fit_transform(X_train)
X_test = ss_X.transform(X_test)
print(X_train[1,])
#目标数据（房价预测值）也是数值型，所以要标准化处理
print(y_train[1,])
y_train = ss_y.fit_transform(y_train.reshape(-1,1))
y_test = ss_y.transform(y_test.reshape(-1,1))
print(X_test.shape)
print(y_test.shape)
<br>[5.3720e-02 0.0000e+00 1.3920e+01 0.0000e+00 4.3700e-01 6.5490e+00
 5.1000e+01 5.9604e+00 4.0000e+00 2.8900e+02 1.6000e+01 3.9285e+02
 7.3900e+00]
[-0.37416455 -0.49216063  0.44433801 -0.28322059 -0.99690206  0.36182909
 -0.6015508   1.05211458 -0.6086759  -0.67176041 -1.1236673   0.36719817
 -0.72029219]
27.1
(102, 13)
(102, 1)
<br><br>from sklearn.linear_model import LinearRegression
lr = LinearRegression()
lr.fit(X_train,y_train)
lr_y_predict = lr.predict(X_test)

# 线性回归模型准确率
from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
print ('the value of R-squared of LR is',r2_score(y_test,lr_y_predict))
print ('the MSE of LR is',mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(lr_y_predict)))
print ('the MAE of LR is',mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(lr_y_predict)))

# 线性回归的相关系数
df_coef = pd.DataFrame()
df_coef['Title'] = boston.feature_names
df_coef['Coef'] = lr.coef_.reshape(-1)
df_coef
<br>the value of R-squared of LR is 0.6922908805512098
the MSE of LR is 22.04257921621327
the MAE of LR is 3.523784431969093
<br>
<br>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
<br>
<br># 可视化预测结果与真实结果对比（一）
hos_pre = pd.DataFrame()
hos_pre['Predict'] = lr_y_predict.reshape(-1)
hos_pre['Truth'] = y_test
hos_pre.plot(figsize=(18,8))
<br>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f77578bba10&gt;
<br># 可视化预测结果与真实结果对比（二）
plt.scatter(y_test, lr_y_predict, label='y')
plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'k--', lw=4,label='predicted')
<br>[&lt;matplotlib.lines.Line2D at 0x7f775573ed50&gt;]
<br><br>from sklearn.linear_model import Ridge
rd = Ridge(alpha=10)
rd.fit(X_train, y_train)
print(rd.coef_)
rd_y_predict = rd.predict(X_test)

# 岭回归模型准确率
from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
print('the value of R-squared of Ridge is',r2_score(y_test,rd_y_predict ))
print ('the MSE of Ridge is',mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(rd_y_predict)))
print ('the MAE of Ridge is',mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(rd_y_predict)))
<br>[[-0.09798846  0.10667403 -0.00347583  0.08748482 -0.15649544  0.3103175
  -0.00952988 -0.30482221  0.22002535 -0.17128915 -0.18803779  0.07911583
  -0.4179327 ]]
the value of R-squared of Ridge is 0.6986350299193227
the MSE of Ridge is 21.588119448310966
the MAE of Ridge is 3.4258013026822347
<br># 交叉验证参数调优
from sklearn.model_selection import cross_val_score 
from sklearn.model_selection import KFold
kf = KFold(n_splits=10, shuffle=True) 

# alpha=10
score_cross_Ridge_10 =cross_val_score(Ridge(alpha=10), X_train, y_train, cv=kf) 
print('the score_cross_Ridge_10 is ')
print(score_cross_Ridge_10)
print('the mean of score_cross_Ridge_10 is',np.mean(score_cross_Ridge_10))
print('the var of score_cross_Ridge_10 is',np.var(score_cross_Ridge_10))
print('the std of score_cross_Ridge_10 is',np.std(score_cross_Ridge_10))

# alpha=5
score_cross_Ridge_5 = cross_val_score(Ridge(alpha=5), X_train, y_train, cv=kf) 
print('the score_cross_Ridge_5 is ')
print(score_cross_Ridge_5)
print('the mean of score_cross_Ridge_5 is',np.mean(score_cross_Ridge_5))
print('the var of score_cross_Ridge_5 is',np.var(score_cross_Ridge_5))
print('the std of score_cross_Ridge_5 is',np.std(score_cross_Ridge_5))
<br>the score_cross_Ridge_10 is 
[0.74178298 0.62190009 0.82724315 0.78999886 0.4507931  0.72340937
 0.79058244 0.78112985 0.78317489 0.5297461 ]
the mean of score_cross_Ridge_10 is 0.7039760837256213
the var of score_cross_Ridge_10 is 0.014532169562606514
the std of score_cross_Ridge_10 is 0.120549448620085
the score_cross_Ridge_5 is 
[0.81671754 0.72231391 0.76771105 0.69089175 0.52517039 0.47427275
 0.7961356  0.75027009 0.77835984 0.71720134]
the mean of score_cross_Ridge_5 is 0.7039044256980395
the var of score_cross_Ridge_5 is 0.011835966616261195
the std of score_cross_Ridge_5 is 0.10879322872431535
<br><br>from sklearn import ensemble
# params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 3,'learning_rate': 0.01, 'loss': 'ls'}
# clf = ensemble.GradientBoostingRegressor(**params)
clf = ensemble.GradientBoostingRegressor()
y_train_1d = np.ravel(y_train)
clf.fit(X_train, y_train)
clf_pre = clf.predict(X_test).reshape(-1,1) #预测值

print(y_test.shape)
print(clf_pre.shape)

# 梯度提升决策树GBDT模型准确率
from sklearn.metrics import r2_score,mean_squared_error,mean_absolute_error
print('the value of R-squared of Ridge is',r2_score(ss_y.inverse_transform(y_test),ss_y.inverse_transform(clf_pre)))
print ('the MSE of Ridge is',mean_squared_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(clf_pre)))
print ('the MAE of Ridge is',mean_absolute_error(ss_y.inverse_transform(y_test),ss_y.inverse_transform(clf_pre)))
<br>(102, 1)
(102, 1)
the value of R-squared of Ridge is 0.8453091349322562
the MSE of Ridge is 11.081197896859102
the MAE of Ridge is 2.104016459524675
<br># 可视化预测结果与真实结果对比
hos_pre = pd.DataFrame()
hos_pre['Predict'] = clf_pre.reshape(-1)
hos_pre['Truth'] = y_test
hos_pre.plot(figsize=(18,8))
<br>&lt;matplotlib.axes._subplots.AxesSubplot at 0x7f7755746310&gt;
<br>]]></description><link>technology\collegeproject\机器学习\机器学习实验\波士顿房价.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/波士顿房价.md</guid><pubDate>Sun, 24 Mar 2024 04:24:47 GMT</pubDate></item><item><title><![CDATA[广告点击率预测]]></title><description><![CDATA[ 
 <br>广告点击率(CTR)预测是广告行业的典型应用，是评估广告效果的一个非常重要的指标。通过历史数据训练预测模型，对于每天的增量数据进行预测，找出广告的CTR符合标准的样本进行投放。<br><br>数据集来自于kaggle，数据包含了10天的Avazu的广告点击数据，训练集10000个，测试集1000个。每一条广告包含：广告id、时间、广告位置等属性。<br><img src="https://ai-studio-static-online.cdn.bcebos.com/1682d3186a5d4fedab10c4ad3a7f3656e3db56852e5c4fdbb4fb26005c0ba811" referrerpolicy="no-referrer"><br><br>
<br>读入训练数据和测试数据，划分data和label
<br>将string类型的特征转化为int型：1）进行 one-hot 编码处理，会得到高维稀疏的特征，增大内存开销；2）使用python内置的hash函数将那些类型为object的特征变量映射为一定范围内的整数(原来的string被映射成了integer)，可以大大降低内存的消耗。
<br>import gzip
import pandas as pd
import random
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn import linear_model
from sklearn.preprocessing import StandardScaler

types_train = {
    'id': np.dtype(int),
    'click': np.dtype(int),         #是否点击,1表示被点击,0表示没被点击
    'hour': np.dtype(int),          #广告被展现的日期+时间
    'C1': np.dtype(int),            #匿名分类变量
    'banner_pos': np.dtype(int),    #广告位置
    'site_id': np.dtype(str),       #站点Id
    'site_domain': np.dtype(str),   #站点域名
    'site_category': np.dtype(str), #站点分类
    'app_id': np.dtype(str),        # appId
    'app_domain': np.dtype(str),    # app域名
    'app_category': np.dtype(str),  # app分类
    'device_id': np.dtype(str),     #设备Id
    'device_ip': np.dtype(str),     #设备Ip
    'device_model': np.dtype(str),  #设备型号
    'device_type': np.dtype(int),   #设备型号
    'device_conn_type': np.dtype(int),
    'C14': np.dtype(int),   #匿名分类变量
    'C15': np.dtype(int),   #匿名分类变量
    'C16': np.dtype(int),   #匿名分类变量
    'C17': np.dtype(int),   #匿名分类变量
    'C18': np.dtype(int),   #匿名分类变量
    'C19': np.dtype(int),   #匿名分类变量
    'C20': np.dtype(int),   #匿名分类变量
    'C21':np.dtype(int)     #匿名分类变量
}

# 添加列名
header_row = ['id', 'click', 'hour', 'C1', 'banner_pos', 'site_id', 'site_domain', 'site_category', \
              'app_id', 'app_domain', 'app_category', 'device_id', 'device_ip', 'device_model',\
              'device_type', 'device_conn_type', 'C14', 'C15', 'C16', 'C17', 'C18', 'C19',\
              'C20', 'C21']

# 读入训练数据和测试数据
train = pd.read_csv('train_data.csv', names=header_row, dtype=types_train)
test = pd.read_csv('test_data.csv', names=header_row, dtype=types_train)
# 去除第0行（表示列的编号，不是样本）
train = train.drop(labels=train.index.values[0])
test = test.drop(labels=test.index.values[0])
print(test.shape)

# 划分data和label
train_data = train.drop(columns=['click']) #去除click 这一列
print(train_data.shape)
train_label = train['click']#提取click 这一列

test_data = test.drop(columns=['click']) #去除click 这一列
print(test_data.shape)
test_label =test['click'] #提取click 这一列


# 数据预处理
# 使用pd.get_dummies对非数值型特征进行 one-hot 编码处理，得到高维稀疏的特征
#因为函数会将string类型的列视为分类数据（categorical data），并对其进行one-hot编码。对于每一个唯一的分类（unique category）在数据中，它将会创建一个新的列。
#但如果该非数值列的类很多，就会被分成很多类，会加很多列，但这些列只有被分入该类的数据会标记为1，其余皆是0，所以会形成高维稀疏矩阵，这不利于计算。
train_data1 = pd.get_dummies(train_data)
print(train_data1.shape)

# 编写convert_obj_to_int()函数将string类型的特征转换为int型
def convert_obj_to_int(self):
    object_list_columns = self.columns
    object_list_dtypes = self.dtypes
    new_col_suffix = '_int'
    for index in range(0, len(object_list_columns)):
        if object_list_dtypes[index] == object:
            # 使用hash和map将string特征变量映射为一定范围内的整数
            self[object_list_columns[index] + new_col_suffix] = self[object_list_columns[index]].map(hash)
            self.drop([object_list_columns[index]], inplace=True, axis=1)
    return self

# 调用convert_obj_to_int()函数，将string类型转换为int型
scaler = StandardScaler()    
train_data = convert_obj_to_int(train_data) 
train_data = scaler.fit_transform(train_data)
print(train_data.shape)
test_data = convert_obj_to_int(test_data) 
test_data = scaler.transform(test_data)
print(test_data.shape)
<br>(1000, 24)
(10000, 23)
(1000, 23)
(10000, 10531)
(10000, 23)
(1000, 23)
<br><br>以广告在网页中的位置(banner_pos)为例，查看banner_pos和最终类标(click)之间的关系。<br>
<br>查看banner_pos在数据集中的取值分布；
<br>查看不同banner_pos对点击率click的贡献。
<br># 查看banner_pos在数据集中的取值分布
print(train.banner_pos.value_counts()/len(train))

# 查看不同banner_pos对点击率click的贡献
banner_pos_val = train.banner_pos.unique()
banner_pos_val.sort()
ctr_avg_list = []
for i in banner_pos_val:
    selected_data = train.loc[train.banner_pos == i]
    ctr_avg = selected_data.click.mean()
    ctr_avg_list.append(ctr_avg)
    print(" banner 位置: {},  点击率: {}".format(i, ctr_avg))
<br>0    0.8041
1    0.1951
2    0.0007
4    0.0001
Name: banner_pos, dtype: float64
 banner 位置: 0,  点击率: 0.16975500559631887
 banner 位置: 1,  点击率: 0.19067145053818554
 banner 位置: 2,  点击率: 0.14285714285714285
 banner 位置: 4,  点击率: 0.0
<br><br>
<br>调用sklearn的逻辑回归函数LogisticRegression()，进行模型训练
<br>对测试集test_data进行预测，计算预测结果的各项指标acc, pre, recall, auc
<br>绘制ROC曲线（使用预测的概率值而不是预测的类标）
<br>选做：自定义逻辑回归函数MyLogisticRegression()，进行模型训练与预测，与上述结果比较。
<br>from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import roc_curve
from sklearn.metrics import auc
# 调用sklearn的逻辑回归函数LogisticRegression()
#clf = LogisticRegression(penalty='l2', C=1, solver='lbfgs',max_iter=1000)
clf = LogisticRegression(solver="liblinear")
# 模型训练
clf.fit(train_data,train_label)
print("Finish Training!")
# 模型预测
pred = clf.predict(test_data)
#预测的概率值
pred_proba = clf.predict_proba(test_data)[:, 1]
# 计算模型的acc, pre, recall, auc，并输出
# 请在下方作答
# 计算 Accuracy
accuracy = accuracy_score(test_label.values, pred)
print('Accuracy: %.3f' % accuracy)

# 计算 Precision
precision = precision_score(test_label.values, pred)
print('Precision: %.3f' % precision)

# 计算 Recall
recall = recall_score(test_label.values, pred)
print('Recall: %.3f' % recall)

# 计算 AUC
Auc = roc_auc_score(test_label.values, pred_proba)
print('AUC: %.3f' % Auc)

# 绘制roc曲线
# 请在下方作答


# 通过roc_curve()函数，得到fpr（假阳性率）、tpr（真阳性率）和阈值
fpr, tpr, thresholds = roc_curve(test_label, pred_proba )

# 计算面积即AUC值
roc_auc = auc(fpr, tpr)

plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--') # 中间的对角线
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic example')
plt.legend(loc="lower right")
plt.show()



<br>Finish Training!
Accuracy: 0.825
Precision: 0.710
Recall: 0.117
AUC: 0.675
<br><img alt="广告点击率预测_5_1.png" src="\lib\media\广告点击率预测_5_1.png"><br><br>class MyLogisticRegression:
    def __init__(self, learning_rate=0.01, n_iterations=1000):
        self.learning_rate = learning_rate
        self.n_iterations = n_iterations
        self.weights, self.bias = None, None

    def _sigmoid(self, x):
        return 1 / (1 + np.exp(-x))

    def fit(self, X, y):
        n_samples, n_features = X.shape

        # 1. 参数初始化
        self.weights = np.zeros(n_features)
        self.bias = 0

        # 2. 梯度下降
        for _ in range(self.n_iterations):
            linear_model = np.dot(X, self.weights) + self.bias
            y_predicted = self._sigmoid(linear_model)

            dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))
            db = (1 / n_samples) * np.sum(y_predicted - y)

            self.weights -= self.learning_rate * dw
            self.bias -= self.learning_rate * db

    def predict(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        y_predicted = self._sigmoid(linear_model)
        y_predicted_cls = [1 if i &gt; 0.5 else 0 for i in y_predicted]
        return y_predicted_cls

    def predict_proba(self, X):
        linear_model = np.dot(X, self.weights) + self.bias
        y_predicted = self._sigmoid(linear_model)
        return y_predicted

model=MyLogisticRegression();
model.fit(train_data, train_label)
print("Finish Training!")
# 模型预测
pred0 = model.predict(test_data)
predict_proba0 = model.predict_proba(test_data)
# 计算 Accuracy
accuracy = accuracy_score(test_label.values, pred0)
print('Accuracy: %.3f' % accuracy)

# 计算 Precision
precision = precision_score(test_label.values, pred0)
print('Precision: %.3f' % precision)

# 计算 Recall
recall = recall_score(test_label.values, pred0)
print('Recall: %.3f' % recall)

# 计算 AUC
Auc = roc_auc_score(test_label.values, pred_proba)
print('AUC: %.3f' % Auc)

# 绘制roc曲线
# 请在下方作答
# 通过roc_curve()函数，得到fpr（假阳性率）、tpr（真阳性率）和阈值
fpr, tpr, thresholds = roc_curve(test_label, predict_proba0 )

# 计算面积即AUC值
roc_auc = auc(fpr, tpr)

plt.figure()
lw = 2
plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--') # 中间的对角线
plt.xlim([0.0, 1.0])
plt.ylim([0.0, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic example')
plt.legend(loc="lower right")
plt.show()

<br>Finish Training!
Accuracy: 0.824
Precision: 0.667
Recall: 0.128
AUC: 0.675
<br><img alt="广告点击率预测_7_1.png" src="\lib\media\广告点击率预测_7_1.png">]]></description><link>technology\collegeproject\机器学习\机器学习实验\广告点击率预测.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/广告点击率预测.md</guid><pubDate>Tue, 02 Apr 2024 04:59:29 GMT</pubDate><enclosure url="https://ai-studio-static-online.cdn.bcebos.com/1682d3186a5d4fedab10c4ad3a7f3656e3db56852e5c4fdbb4fb26005c0ba811" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://ai-studio-static-online.cdn.bcebos.com/1682d3186a5d4fedab10c4ad3a7f3656e3db56852e5c4fdbb4fb26005c0ba811&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1. One-Hot编码]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br><br><br>
<br>使用Pandas中的value_counts()函数，查看data中的特征User continent的取值类型， 并打印输出的内容；
<br>使用pandas中的getdummies()函数对data中的特征User continent进行One-Hot编码，参数prefix为User continent；
<br>将编码后的结果保存在encode_uc中，并输出变量的前5行内容。
<br><br><img src="https://ai-studio-static-online.cdn.bcebos.com/bac5b83fc21a435fabddd64a5ab463600c7d80dc00e44fd6ae1715ae25355db6" referrerpolicy="no-referrer"><br>
<img src="https://ai-studio-static-online.cdn.bcebos.com/2f183364e29348079537f8ad38d9489004d4498e9b5d483fa9432f2bae06654e" referrerpolicy="no-referrer"><br>
补全代码;
<br>import pandas as pd 
data = pd.read_csv('/home/aistudio/user_review.csv')
# 请在下方作答 #
counts_continent=data['User continent'].value_counts()
print(counts_continent)
encode_uc=pd.get_dummies(data['User continent'],prefix='User continent_')
print(encode_uc.head())
<br>North America    296
Europe           118
Oceania           41
Asia              36
Africa             7
South America      6
Name: User continent, dtype: int64
   User continent__Africa  User continent__Asia  User continent__Europe  \
0                       0                     0                       0   
1                       0                     0                       0   
2                       0                     0                       0   
3                       0                     0                       1   
4                       0                     0                       0   

   User continent__North America  User continent__Oceania  \
0                              1                        0   
1                              1                        0   
2                              1                        0   
3                              0                        0   
4                              1                        0   

   User continent__South America  
0                              0  
1                              0  
2                              0  
3                              0  
4                              0  
<br><br><br>
<br>使用pandas中的value_counts()函数打印输出data中的特征Traveler type的取值统计信息， 并查看其是否含有缺失值；
<br>如果存在缺失值，将特征Traveler type在其他样本中取值频数最多的值保存在变量freq_v中，并使用freq_v进行缺失值填充；
<br>再次打印输出特征Traveler type的取值统计信息。
<br><br><img src="https://ai-studio-static-online.cdn.bcebos.com/573d921570d34dc08c44f863ee8732f8d5816c88af7b467aa8cae7a2ce188129" referrerpolicy="no-referrer"><br>
补全代码：
<br>import pandas as pd 
data = pd.read_csv('/home/aistudio/user_review.csv')

# 请在下方作答 #
none=data['Traveler type'].value_counts(dropna=False)
print(none)
freq_v = 'Couples'

### 缺失值填充
data['Traveler type'] = data['Traveler type'].fillna(freq_v)
counts_traveler=data['Traveler type'].value_counts(dropna=False)
### 打印
print(u'缺失值填充完之后：')
print(counts_traveler)
<br>Couples     214
Families    110
Friends      82
Business     74
Solo         21
NaN           3
Name: Traveler type, dtype: int64
缺失值填充完之后：
Couples     217
Families    110
Friends      82
Business     74
Solo         21
Name: Traveler type, dtype: int64
<br><br><br>
<br>使用sklearn中preprocessing模块下的StandardScaler()函数对data的特征Score进行Z-score标准化；
<br>将特征取值的均值保存在变量score_mean中，并打印；
<br>将特征取值的方差保存在变量score_var中，并打印。
<br><br>
补全代码：
<br>import pandas as pd 
from sklearn.preprocessing import StandardScaler
data = pd.read_csv('/home/aistudio/user_review.csv')

# 请在下方作答 #
## 创建Z-score对象，并使用fit()方法
std_scaler = StandardScaler().fit(data[['Score']])

## 特征标准化，使用transform()方法
normal_df = std_scaler.transform(data[['Score']])

## 均值
score_mean =std_scaler.mean_

## 方差
score_var =std_scaler.scale_

## 打印
print (score_mean)
print (score_var)

## 打印前五行内容
normal_df[:5]
<br>[4.12301587]
[1.00630258]





array([[ 0.87149149],
       [-1.11598231],
       [ 0.87149149],
       [-0.12224541],
       [-0.12224541]])
<br><br>
<br>自定义函数min_max()实现MinMax标准化，输入参数data为要进行标准化的数据，输出为标准化后的数据。
<br>使自定义的min_max()函数对data的特征Score进行MinMax标准化，输出结果保存在score_transformed中，并打印变量的前5行内容
<br><br><img src="https://ai-studio-static-online.cdn.bcebos.com/98a830f8c5594920883029b03ae2882f516aef4a6af244ff93061ef21aa09836" referrerpolicy="no-referrer"><br>
补全代码：
<br>import pandas as pd 
data = pd.read_csv('/home/aistudio/user_review.csv')

# 请在下方作答 #
def min_max(data):
    
    ## 最小值
    data_min = data['Score'].min()
    ## 最大值
    data_max = data['Score'].max()
    ## 最大值与最小值之间的差值
    diff=data_max-data_min
    ## 根据MinMax标准化的定义实现
    new_data = (data['Score']-data_min)/diff
    
    ## 返回结果
    return new_data

## 调用min_max()函数
score_transformed = min_max(data)

## 打印变量的前5行内容
score_transformed.head()
<br>0    1.00
1    0.50
2    1.00
3    0.75
4    0.75
Name: Score, dtype: float64
<br><br>
<br>自定义logistic()函数，输入参数为要进行标准化的数据，输出结果为经过标准化后的数据；
<br>使用自定义函数对data的特征Member years进行Logsitic标准化，结果保存在member_transformed中，并输出变量的前5行内容。
<br><br><img src="https://ai-studio-static-online.cdn.bcebos.com/22fd81b1a5614b418f88cbe90bf7f99ba6c553820c2542be80f1a90421779026" referrerpolicy="no-referrer"><br>
补全代码
<br>import pandas as pd 
data = pd.read_csv('/home/aistudio/user_review.csv')

# 请在下方作答 #
def logistic(data):
    
    import numpy as np
    import warnings
    warnings.filterwarnings("ignore")
    
    ## 计算 1 + e^(-x)
    denominator = 1 + np.exp(-data['Member years'])
    
    ## 实现logistic标准化
    new_data = 1/denominator
    ## 返回结果
    return new_data

## 对特征Member years进行logsitic标准化
member_transformed=logistic(data) 
## 打印内容
member_transformed.head()
<br>0    0.999877
1    0.952574
2    0.880797
3    0.997527
4    0.999089
Name: Member years, dtype: float64
<br><br><br>
<br>使用Pandas的qcut()函数对data中的特征Member years进行等频离散化，结果保存在bins中；
<br>使用pd.value_counts()函数统计categorical对象bins的取值信息。
<br><br><img src="https://ai-studio-static-online.cdn.bcebos.com/a4729a315ee6483687f3a819d01d905b025fa5f90da04f3e893a7a80ce5e5107" referrerpolicy="no-referrer"><br>
补全代码：
<br>import pandas as pd 
data = pd.read_csv('/home/aistudio/user_review.csv')

# 请在下方作答 #
import pandas as pd 

## 返回bins
bins = pd.qcut(data['Member years'],4)

## 统计取值信息
categorical=bins.value_counts()
print(categorical)
<br>(-1806.001, 2.0]    156
(6.0, 13.0]         124
(2.0, 4.0]          123
(4.0, 6.0]          101
Name: Member years, dtype: int64
<br><br><br>
<br>使用拉依达准则对data的特征Member years进行离群值检测；
<br>如果存在离群值，输出离群值的个数outlier_num，并将包含离群值的数据记录保存在变量outeliers中，并打印变量内容。
<br><br><img src="https://ai-studio-static-online.cdn.bcebos.com/40e316267fc542339a74291e8438e340109ece96fc2a439591b75414e12085d2" referrerpolicy="no-referrer"><br>
补全代码：
<br>import pandas as pd 
import numpy as np
data = pd.read_csv('/home/aistudio/user_review.csv')
member_data = data[['Member years']]

# 请在下方作答 #
## Z-score标准化
new_data = StandardScaler().fit(member_data)
Z_score=new_data.transform(member_data)

## 写出过滤条件
outlier_judge = (np.abs(Z_score)&gt;=3)

## 统计离群值的个数
outliers = np.where(outlier_judge)
outlier_num = len(outliers[0])

## 包含离群值的数据样本记录
outliers_data = data.iloc[outliers[0]]
## 打印
print("离群值的数量是：", outlier_num)
print("离群值数据：\n", outliers_data)
<br>离群值的数量是： 1
离群值数据：
    User country User continent  Member years Traveler type  \
75          USA  North America         -1806          Solo   

                            Hotel name  Hotel stars  Nr. rooms  Score  
75  Treasure Island- TI Hotel &amp; Casino          4.0       2884      5  
<br>]]></description><link>technology\collegeproject\机器学习\机器学习实验\机器学习数据预处理基础.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/机器学习数据预处理基础.md</guid><pubDate>Sun, 24 Mar 2024 04:25:23 GMT</pubDate><enclosure url="https://ai-studio-static-online.cdn.bcebos.com/bac5b83fc21a435fabddd64a5ab463600c7d80dc00e44fd6ae1715ae25355db6" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://ai-studio-static-online.cdn.bcebos.com/bac5b83fc21a435fabddd64a5ab463600c7d80dc00e44fd6ae1715ae25355db6&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[机器学习中的Python常用库（Numpy, Pandas, PIL, Matplotlib）]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br><br><br>numpy（Numerical Python的简称）是高性能科学计算和数据分析的基础包。其部分功能如下：<br>ndarray，一个具有矢量算术运算和复杂广播能力的快速且节省空间的多维数组。<br>
用于对整组数据进行快速运算的标准数学函数（无需编写循环）。<br>
用于读写磁盘数据的工具以及用于操作内存映射文件的工具。<br>
线性代数、随机数生成以及傅里叶变换功能。<br>
用于集成由C、C++、Fortran等语言编写的代码的工具。<br># 创建ndarray
import numpy as np
data = [1, 2, 3, 4]
arr = np.array(data)
print(arr)
print(type(arr))
<br># 创建全0全1或没有任何具体值的数组
arr_zero = np.zeros((2,2))
print(arr_zero)
print(arr_zero.dtype)
print(type(arr_zero))

arr_one = np.ones((2,2))
print(arr_one)
print(arr_one.dtype)

arr_empty = np.empty((2,2))
print(arr_empty)
print(arr_empty.dtype)
<br># 创建随机数组
arr1 = np.random.rand(2,2) # 创建指定形状的数组(范围在0至1之间)
arr2 = np.random.uniform(0,10) # 创建指定范围内的一个数
arr3 = np.random.randint(0,10) # 创建指定范围内的一个整数
arr4 = np.random.normal(0.5, 0.1, (2,2)) # 给定均值/标准差/维度的正态分布
print('arr1:', arr1)
print('arr2:', arr2)
print('arr3:', arr3)
print('arr4:', arr4)
<br># 查看ndarray的常用属性
print(arr4.size) # 数组元素个数
print(arr4.shape) # 数组形状
print(arr4.ndim) # 数组维度
print(arr4.dtype) # 数组元素类型
<br># 数组和标量之间的运算
# 我们不用编写循环即可对数据执行批量运算。这通常叫做矢量化（vectorization）。大小相等的数组之间的任何算术运算都会将运算应用到元素级。同样，数组与标量的算术运算也会将那个标量值传播到各个元素。
arr = np.array([[1, 2], [3, 4], [5, 6]])
print('arr + arr = ', arr + arr)
print('arr - arr = ', arr - arr)
print('arr * arr = ', arr * arr)
print('arr / arr = ', arr / arr)
print('arr + 1 = ', arr + 1)
print('arr - 1 = ', arr - 1)
print('arr * 2 = ', arr * 2)
print('arr / 2 = ', arr / 2)
print('1 / arr = ', 1 / arr)
print('arr ** 2 = ', arr**2)
<br># 数组的索引和切片
# 跟列表最重要的区别在于，数组切片是原始数组的视图。这意味着数据不会被复制，视图上的任何修改都会直接反映到源数组上
# 将一个标量值赋值给一个切片时，该值会自动传播到整个选区
arr = np.arange(10)
print(arr)
print(arr[2:7])
arr_slice = arr[4:8]
arr_slice[:] = 20
print(arr)
<br># 数学和统计方法
# 可以通过数组上的一组数学函数对整个数组或某个轴向的数据进行统计计算
# sum、mean以及标准差std等聚合计算既可以当做数组的实例方法调用，也可以当做顶级Numpy函数使用
arr = np.random.randn(2,3)
print(arr)
print(np.mean(arr))
print(arr.mean())
print(arr.sum())
print(arr.std())
<br># mean 和 sum 这类的函数可以接受一个 axis 参数（用于计算该轴向上的统计值），最终结果是一个少一维的数组
print(arr.mean(axis=1))
print(arr.sum(0))
<br># cumsum 和 cumprod 之类的方法则不聚合，而是产生一个由中间结果组成的数组
print(arr.cumsum(0))
print(arr.cumprod(1))
<br># 矩阵乘法
# numpy提供了一个用于矩阵乘法的dot函数（既是一个数组方法，也是numpy命名空间中的一个函数）
x = np.array([[1,2],[3,4]])
y = np.array([[5,6],[7,8]])
print(np.dot(x,y))
print(x.dot(y))
<br>
numpy.linalg 中有一组标准的矩阵分解运算以及诸如求逆和行列式之类的东西
<br>
<br>diag	以一维数组的形式返回方阵的对角线（或非对角线）元素，或将一维数组转换为方阵（非对角线元素为0）
<br>dot	矩阵乘法
<br>trace	计算对角线元素的和
<br>det	计算矩阵行列式
<br>eig	计算方阵的特征值和特征向量
<br>inv	计算方阵的逆
<br>svd	计算奇异值分解（SVD）
<br>inv	计算方阵的逆
<br>solve	解线性方程组Ax=b，其中A为一个方阵
<br>lstsq	计算Ax=b的最小二乘解
<br><br>pandas是python第三方库，提供高性能易用数据类型和分析工具<br>
pandas基于numpy实现，常与numpy和matplotlib一同使用<br>
pandas中有两大核心数据结构：Series（一维数据） 和 DataFrame（多特征数据,既有行索引,又有列索引）<br>Series<br><br>DataFrame<br><br>#Series是一种类似于一维数组的对象，它由一维数组（各种numpy数据类型）以及一组与之相关的数据标签（即索引）组成
#Series的创建：
# 使用Python数组创建
# 使用numpy数组创建
# 使用python字典创建
# 与字典不同的是：Series允许索引重复
import pandas as pd
import numpy as np
pds1 = pd.Series([99, 98], index=['xiaoming', 'xiaohong'])
print(pds1)
pds2 = pd.Series(np.arange(3,6))
print(pds2)
pds3 = pd.Series({'name': 'xiaoming', 'age': 21, 'score': 99})
print(pds3)
<br># Series的字符串表现形式为：索引在左边，值在右边
# 如果没有为数据指定索引，则自动创建一个0到N-1（N为数据的长度）的整数型索引
# 可以通过Series的values和index属性获取其数组表示形式和索引对象
# 与普通numpy数组相比，可以通过索引的方式选取Series中的单个或一组值
pds = pd.Series([1, 2, 3, 4])
print(pds.values)
print(pds.index)
print(pds[1])
pds[2] = 10
print(pds[[1,2]])
<br># Series中最重要的一个功能是：它会在算术运算中自动对齐不同索引的数据
stu1 = pd.Series({'math': 100, 'physics': 98, 'chemistry': 90})
stu2 = pd.Series({'math': 95, 'physics': 96, 'chemistry': 94})
print(stu1 + stu2)
<br># DataFrame是一个表格型的数据结构，它含有一组有序的列，每列可以是不同的值类型（数值、字符串、布尔值等） 
# DataFrame既有行索引也有列索引，它可以被看做由Series组成的字典（共用同一个索引）
# 跟其他类似的数据结构相比（如R语言的data.frame），DataFrame中面向行和面向列的操作基本上是平衡的
# DataFrame中的数据是以一个或多个二维块存放的（而不是列表、字典或别的一维数据结构）
data = {'name': ['xiaoming', 'xiaohong', 'xiaobai'], 'score': [100, 99, 98]}
fr = pd.DataFrame(data)
print(fr)
<br># 可以按照指定的列顺序创建DataFrame
fr = pd.DataFrame(data, columns=['score', 'name'])
print(fr)
<br># DataFrame的每一列都可以作为一个Series进行输出
print(fr['name'])
print(type(fr['name']), type(fr['score']))
<br># 可以给DataFrame创建或修改列的值
fr['age'] = [21,22,20]
print(fr)
fr.loc[1, 'age'] = 30
print(fr)
<br># values属性会以二维ndarray的形式返回DataFrame中的数据
fr.values
<br><br>PIL库是一个具有强大图像处理能力的第三方库<br>
在命令行下的安装方法：pip install pillow<br>
在使用过程中的引入方法：from PIL import Image<br>
Image 是 PIL 库中代表一个图像的类（对象）<br>
图像是一个由像素组成的二维矩阵，每个元素是一个RGB值<br># 读取图片
from PIL import Image
import numpy as np
img = Image.open('work/cat.jpg')
print(img)
arr = np.array(img)
print(arr.shape)
print(arr)
<br>img.show() # 本地电脑上可以用该命令调用系统的图片显示工具显示图片
<br>import matplotlib.pyplot as plt
plt.imshow(img)
<br># PIL中还有
dog = Image.open('work/dog.jpg')
plt.imshow(dog)
<br>cat = img.resize((400,300))
dog = dog.resize((400,300))
Image.blend(cat,dog,0.3)
<br># 图片的灰度化处理
gray_cat = cat.convert('L')
plt.imshow(gray_cat)
<br># 获取图片的基本信息
bands = cat.getbands() # 显示该图片的所有通道
print(bands)
bbox = cat.getbbox() # 获取图片左上角和右下角的坐标
print(bbox)
width, height = cat.width, cat.height # 获取图片宽度和高度
print(width, height)
<br># 图片粘贴操作
flower = Image.open('work/flower.jpg')
flower.paste(dog)
plt.imshow(flower)
<br>flower.paste(dog, (300, 300))
plt.imshow(flower)
<br><br>Matplotlib库由各种可视化类构成，内部结构复杂。<br>
受Matlab启发，matplotlib.pylot是绘制各类可视化图形的命令字库，相当于快捷方式。<br># plt.plot() 只有一个输入列表或数组时，参数被当做Y轴，X轴以索引自动生成
# plt.savefig() 将输出图形存储为文件，默认PNG格式，可以通过dpi修改输出质量
import matplotlib.pyplot as plt
plt.plot([3, 2, 5, 8, 10, 6])
plt.xlabel('Time')
plt.ylabel('Meter')
plt.savefig('work/graph', dpi=300)
plt.show()
<br>#subplot在全局绘图区域中创建一个分区体系，并定位到一个子绘图区域
plt.figure()
plt.subplot(231)
plt.plot([1,2,3])
plt.subplot(232)
plt.plot([1,2,1])
plt.subplot(233)
plt.plot([2,2,1])
plt.subplot(212)
plt.plot([1,2,1,3,4,5])
<br># 饼图的绘制
labels = 'apple', 'banana', 'orange', 'peach'
sizes = [3, 5, 6, 2]
explode = (0, 0, 0.2, 0)
plt.pie(sizes, explode=explode, labels=labels, startangle=90)
plt.axis('equal')
plt.show()
<br># 直方图的绘制
np.random.seed(0)
mu, sigma = 10, 2 # 均值和标准差
a = np.random.normal(mu, sigma, size=10)
plt.hist(a, 20)
plt.title('Histogram')
plt.show()
<br># 散点图的绘制
plt.plot(10*np.random.randn(100), 10*np.random.randn(100), 'o')
plt.title('Simple Scatter')
plt.show()
]]></description><link>technology\collegeproject\机器学习\机器学习实验\机器学习中的python常用库.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/机器学习中的Python常用库.md</guid><pubDate>Tue, 12 Mar 2024 09:03:59 GMT</pubDate></item><item><title><![CDATA[决策树算法实现]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a> <br><br><br>决策树模型呈树形结构，其中每个内部节点表示一个特征或属性，每个分支表示一个判断规则，每个叶节点表示一个类别。数据分类过程就是从根节点开始，测试待分类项中相应的特征，然后由此转移到一个子节点，这个过程以此递归，至到达叶节点，取该叶节点的类别作为决策结果。<br>决策树学习通常包括三个步骤：特征选择、决策树生成和决策树剪枝。<br>
<br>
特征选择的目标是选择划分当前数据集的最优特征，通常使用的准则包括信息增益（ID3算法）、信息增益率（C4.5算法）、基尼指数（CART算法）等。

<br>
决策树生成是基于选定的特征对数据集进行划分，生成决策树。

<br>
决策树剪枝是为了解决过拟合问题，通过在生成树的同时或生成树后，对树进行简化操作，剪掉不必要的分支。

<br><br><br>检测数据集中的每个子项是否属于同一分类：
    If so return类标签
    Else
      寻找划分数据集的最好特征
      划分数据集
      创建分支节点
            for每个划分的子集
              调用函数createBranch并增加返回结果到分支节点中
        return分支节点
<br><br><br>def calc_ent(datasets):
        from math import log
        data_length = len(datasets)
        label_count = {}
        for i in range(data_length):
            label = datasets[i][-1]
            if label not in label_count:
                label_count[label] = 0
            label_count[label] += 1
        ent = -sum([(p / data_length) * log(p / data_length, 2) for p in label_count.values()])
        return ent
<br>- 首先，计算数据集中实例的总数。
- 然后，创建一个数据字典，它的键值是最后一列的数值1。如果当前键值不存在，则扩展字典并将当前键值加入字典。每个键值都记录了当前类别出现的次数。
- 最后，使用所有类标签的发生频率计算类别出现的概率。
<br><br># 信息增益
    @staticmethod
    def info_gain(ent, cond_ent):
        print(ent - cond_ent)
        return ent - cond_ent

    def info_gain_train(self, datasets):
        count = len(datasets[0]) - 1
        ent = self.calc_ent(datasets)
        best_feature = []
        for c in range(count):
            c_info_gain = self.info_gain(ent, self.cond_ent(datasets, axis=c))
            best_feature.append((c, c_info_gain))
        # 比较大小
        best_ = max(best_feature, key=lambda x: x[-1])
        return best_

<br><br>def train(self, train_data):
        '''
        input: 数据集 D,特征集 A,阈值 epsilon
        output: 决策树 T
        '''
        # 分割特征和标签
        x_train = train_data[:, :-1]
        y_train = train_data[:, -1]

        # 1. 如果 D 中实例属于同一类 Ck，则 T 为单节点树，并将类 Ck 作为结点的类标记，返回 T
        unique_labels, counts = np.unique(y_train, return_counts=True)
        if len(unique_labels) == 1:
            return Node(root=True, label=unique_labels[0])

        # 2. 如果 A 为空，则 T 为单节点树，将 D 中实例数最大的类 Ck 作为该节点的类标记，返回 T
        if x_train.shape[1] == 0:
            # 找出出现频率最高的标签
            most_common_label = unique_labels[np.argmax(counts)]
            return Node(root=True, label=most_common_label)

        # 3. 计算最大信息增益
        max_feature, max_info_gain = self.info_gain_train(train_data)
        max_feature_name = max_feature

        # 4. 如果 Ag 的信息增益小于阈值 epsilon，则将 D 中实例数最大的类 Ck 作为该节点的类标记，返回 T
        if max_info_gain &lt; self.epsilon:
            most_common_label = unique_labels[np.argmax(counts)]
            return Node(root=True, label=most_common_label)

        # 5. 构建 Ag 子集
        node_tree = Node(root=False, feature_name=max_feature_name, feature=max_feature)

        # 获取特征列中的不同特征值
        feature_list = np.unique(train_data[:, max_feature])

        # 遍历特征列中的不同特征值
        for f in feature_list:
            # 根据特征值过滤出子集
            mask = train_data[:, max_feature] == f
            sub_train_data = train_data[mask]

            # 移除特征列
            sub_train_data = np.delete(sub_train_data, max_feature, axis=1)

            # 递归生成树
            sub_tree = self.train(sub_train_data)
            node_tree.add_node(f, sub_tree)

        return node_tree 
        
]]></description><link>technology\collegeproject\机器学习\机器学习实验\决策树算法实现.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/决策树算法实现.md</guid><pubDate>Sat, 27 Apr 2024 10:21:37 GMT</pubDate></item><item><title><![CDATA[在vscode下将ipynb文件转成markdown]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
<a data-tooltip-position="top" aria-label="https://blog.csdn.net/wtyuong/article/details/134810930" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/wtyuong/article/details/134810930" target="_blank">在vscode下将ipynb文件转成markdown（.md文件）的方法_vscode将notebook转化为markdown-CSDN博客</a><br>jupyter nbconvert --to markdown '文件名.ipynb'
]]></description><link>technology\collegeproject\机器学习\机器学习实验\在vscode下将ipynb文件转成markdown.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/在vscode下将ipynb文件转成markdown.md</guid><pubDate>Tue, 02 Apr 2024 05:03:03 GMT</pubDate></item><item><title><![CDATA[上机实验10--支持向量机]]></title><description><![CDATA[ 
 <br><br><br>
<br>提供一份糖尿病患者数据集diabetes.csv，该数据集有768个数据样本，9个特征(最后一列为目标特征数据)，并且已经存入变量data。特征的具体信息如下：
<br><br>主要任务如下：<br>
<br>请先将数据使用sklearn中的StandardScaler进行标准化；
<br>然后使用sklearn中的svm.SVC支持向量分类器，构建支持向量机模型（所有参数使用默认参数），对测试集进行预测，将预测结果存为pred_y，并对模型进行评价；
<br>最后新建一个svm.SVC实例clf_new，并设置惩罚系数C=0.3，并利用该支持向量分类器对测试集进行预测，将预测结果存为pred_y_new，并比较两个模型的预测效果。
<br>
待补全代码
<br>import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.svm import SVC
from sklearn.model_selection import GridSearchCV
# 读取数据
data = pd.read_csv('diabetes.csv')

# 请在下方作答 #
# 将目标特征与其他特征分离
#X = _______________
#y = _______________
X = data.drop('class',axis=1)
y = data['class']
y= np.where(y == 0, -1,y)
# 划分训练集train_X, train_y和测试集train_X, train_y
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = .2, random_state = 0)

# 训练集标准化，返回结果为scaled_train_X
scaler = StandardScaler()
#________________
#scaled_train_X = _______________
scaler.fit(train_X)
scaled_train_X = scaler.transform(train_X)

# 构建支持向量机模型
clf = SVC(random_state=0)

# 模型训练
clf.fit(train_X,train_y)

# 测试集标准化
scaled_test_X = scaler.transform(test_X)

# 使用模型返回预测值
pred_y = clf.predict(test_X)

# 打印支持向量的个数，返回结果为列表，[-1标签的支持向量，+1标签的支持向量]
print(clf.n_support_)

# 使用classification_report函数进行模型评价
print(classification_report(test_y, pred_y))

# 构建惩罚系数C为0.3的模型，并与之前的模型做比较
clf_new= SVC(C=0.3, random_state=0)
clf_new.fit(train_X,train_y)
pred_y_new = clf_new.predict(test_X)

print(clf_new.n_support_)
print(classification_report(test_y, pred_y_new))

#调整惩罚系数C寻优

# 初始设置为评估的c值
c_range =  np.linspace(1, 10, 10)
param_grid = {'C': c_range}

# 通过GridSearchCV找出最优的C值
clf = GridSearchCV(SVC(kernel='linear', gamma='auto'), param_grid, cv=2)

# 在训练集上训练
clf.fit(train_X, train_y)

# 输出和打印最佳参数
print("最佳参数是：", clf.best_params_)
print("最佳得分是：", clf.best_score_)

# 使用最优C值进行预测
y_true, y_pred = test_y, clf.predict(test_X)
print(classification_report(y_true, y_pred))



<br>[191 190]
              precision    recall  f1-score   support

          -1       0.81      0.92      0.86       107
           1       0.73      0.51      0.60        47

    accuracy                           0.79       154
   macro avg       0.77      0.71      0.73       154
weighted avg       0.78      0.79      0.78       154

[208 209]
              precision    recall  f1-score   support

          -1       0.79      0.91      0.84       107
           1       0.68      0.45      0.54        47

    accuracy                           0.77       154
   macro avg       0.73      0.68      0.69       154
weighted avg       0.75      0.77      0.75       154

最佳参数是： {'C': 7.0}
最佳得分是： 0.755700325732899
              precision    recall  f1-score   support

          -1       0.84      0.91      0.87       107
           1       0.74      0.62      0.67        47

    accuracy                           0.82       154
   macro avg       0.79      0.76      0.77       154
weighted avg       0.81      0.82      0.81       154
<br>
预期结果
<br><img src="https://ai-studio-static-online.cdn.bcebos.com/0768604ae0644fcdb3edd584090f6af7fae81344e0b14da789ec1324ee81bcf0" referrerpolicy="no-referrer"><br><br>
在支持向量分类器中，核函数对其性能有直接的影响。已知径向基函数 RBF 及核矩阵元素为：<br>
且对于核矩阵K，有
<br>主要任务如下：<br>
<br>自定义函数实现径向基函数 rbf_kernel，要求输入参数为两个矩阵 X、Y，以及 gamma；
<br>利用rbf_kernel核函数，计算标准化后的训练集scaled_train_X的核矩阵，并存为 rbf_matrix；
<br>利用rbf_kernel核函数，训练支持向量分类器 clf，并预测标准化后的测试数据 scaled_test_X 的标签，最后评价模型效果。

提示：先计算各自的 Gram 矩阵，然后再使用 np.diag 提取对角线元素，使用 np.tile 将列表扩展成一个矩阵。


<br>
待补全代码
<br>def rbf_kernel(X, Y, gamma=0.24):

     # 获取X和Y的大小
    num1 = X.shape[0]
    num2 = Y.shape[0]
    
     # 计算X和X^T的矩阵乘积
    gram_1 = np.dot(X, X.T)
    
     # 获取gram_1对角线位置的元素，组成大小(num1, 1)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component1
    component1 = np.tile(np.diag(gram_1).reshape(-1, 1), (1, num2))
    
     # 计算Y和Y^T的矩阵乘积
    gram_2 = np.dot(Y, Y.T)
     
     # 获取gram_2对角线位置的元素，组成(1, num2)的列表，并将整个列表复制，扩展为(num1, num2)大小的矩阵component2
    component2 = np.tile(np.diag(gram_2).reshape(1, -1), (num1, 1))
   
     # 计算2X和Y^T的内积 
    component3 = 2*np.dot(X, Y.T)
  
     # 返回结果
    result = np.exp(gamma*(component3 - component1 - component2))
    return result

# 计算糖尿病患者训练数据集的核矩阵
rbf_matrix = rbf_kernel(scaled_train_X, scaled_train_X)

# 训练一个支持向量分类器
clf = SVC(kernel='rbf', gamma=0.24)
clf.fit(scaled_train_X, train_y)

# 在标准化后的测试集上预测标签
pred_y = clf.predict(scaled_test_X)

# 输出预测报告
print(clf.n_support_)
print(classification_report(test_y, pred_y))
<br>[205 191]
              precision    recall  f1-score   support

          -1       0.84      0.88      0.86       107
           1       0.69      0.62      0.65        47

    accuracy                           0.80       154
   macro avg       0.76      0.75      0.76       154
weighted avg       0.79      0.80      0.80       154
<br>
预期结果
<br><img src="https://ai-studio-static-online.cdn.bcebos.com/09cbd0f9a36e4802941289e87082169b6640e370714642d38606e76575bc5632" referrerpolicy="no-referrer"><br><br>主要任务如下：<br>
<br>读取sklearn中的iris数据集，提取特征与标记，并进行数据划分为训练与测试集；
<br>自定义函数实现SVM；
<br>调用SVM函数进行支持向量机训练，并对测试集进行测试。
<br>
待补全代码
<br>import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report
from sklearn.svm import SVC
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt

def create_data():
    iris = load_iris()
    df = pd.DataFrame(iris.data, columns=iris.feature_names)
    df['label'] = iris.target
    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']
    data = np.array(df.iloc[:100, [0, 1, -1]])
    for i in range(len(data)):
        if data[i,-1] == 0:
            data[i,-1] = -1
    # print(data)
    return data[:,:2], data[:,-1]

# 读取数据，拆分数据，训练测试集划分
X, y = create_data()
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)
<br>class SVM:
    def __init__(self, max_iter=100, kernel='linear'):
        self.max_iter = max_iter
        self._kernel = kernel
    
    def init_args(self, features, labels):
        self.m, self.n = features.shape
        self.X = features
        self.Y = labels
        self.b = 0.0
        
        # 将Ei保存在一个列表里
        self.alpha = np.ones(self.m)
        self.E = [self._E(i) for i in range(self.m)]
        # 松弛变量
        self.C = 1.0
        
    def _KKT(self, i):
        y_g = self._g(i)*self.Y[i]
        if self.alpha[i] == 0:
            return y_g &gt;= 1
        elif 0 &lt; self.alpha[i] &lt; self.C:
            return y_g == 1
        else:
            return y_g &lt;= 1
    
    # g(x)预测值，输入xi（X[i]）
    def _g(self, i):
        r = self.b
        for j in range(self.m):
            #r += ____________________________
            r +=self.alpha[j]*self.Y[j]*self.kernel(self.X[i], self.X[j])
        return r
    
    # 核函数
    def kernel(self, x1, x2):
        if self._kernel == 'linear':
            #return ____________________________
            return sum([x1[k]*x2[k] for k in range(self.n)])
        elif self._kernel == 'poly':
            return (sum([x1[k]*x2[k] for k in range(self.n)]) + 1)**2
    
        return 0
    
    # E（x）为g(x)对输入x的预测值和y的差
    def _E(self, i):
        return self._g(i) - self.Y[i]
    
    def _init_alpha(self):
        # 外层循环首先遍历所有满足0&lt;a&lt;C的样本点，检验是否满足KKT
        index_list = [i for i in range(self.m) if 0 &lt; self.alpha[i] &lt; self.C]
        # 否则遍历整个训练集
        non_satisfy_list = [i for i in range(self.m) if i not in index_list]
        index_list.extend(non_satisfy_list)
        
        for i in index_list:
            if self._KKT(i):
                continue
            
            E1 = self.E[i]
            # 如果E2是+，选择最小的；如果E2是负的，选择最大的
            if E1 &gt;= 0:
                j = min(range(self.m), key=lambda x: self.E[x])
            else:
                j = max(range(self.m), key=lambda x: self.E[x])
            return i, j
        
    def _compare(self, _alpha, L, H):
        if _alpha &gt; H:
            return H
        elif _alpha &lt; L:
            return L
        else:
            return _alpha      
    
    def fit(self, features, labels):
        self.init_args(features, labels)
        
        for t in range(self.max_iter):
            # train
            #i1, i2 = ______________
            i1, i2 = self._init_alpha()
            # 边界
            if self.Y[i1] == self.Y[i2]:
                L = max(0, self.alpha[i1]+self.alpha[i2]-self.C)
                H = min(self.C, self.alpha[i1]+self.alpha[i2])
            else:
                L = max(0, self.alpha[i2]-self.alpha[i1])
                H = min(self.C, self.C+self.alpha[i2]-self.alpha[i1])
                
            E1 = self.E[i1]
            E2 = self.E[i2]
            # eta=K11+K22-2K12
            #eta = ____________________________
            eta = self.kernel(self.X[i1], self.X[i1]) + self.kernel(self.X[i2], self.X[i2]) - 2*self.kernel(self.X[i1], self.X[i2])
            if eta &lt;= 0:
                # print('eta &lt;= 0')
                continue
                
            alpha2_new_unc = self.alpha[i2] + self.Y[i2] * (E2 - E1) / eta
            alpha2_new = self._compare(alpha2_new_unc, L, H)
            
            alpha1_new = self.alpha[i1] + self.Y[i1] * self.Y[i2] * (self.alpha[i2] - alpha2_new)
            
            b1_new = -E1 - self.Y[i1] * self.kernel(self.X[i1], self.X[i1]) * (alpha1_new-self.alpha[i1]) - self.Y[i2] * self.kernel(self.X[i2], self.X[i1]) * (alpha2_new-self.alpha[i2])+ self.b 
            b2_new = -E2 - self.Y[i1] * self.kernel(self.X[i1], self.X[i2]) * (alpha1_new-self.alpha[i1]) - self.Y[i2] * self.kernel(self.X[i2], self.X[i2]) * (alpha2_new-self.alpha[i2])+ self.b 
            
            if 0 &lt; alpha1_new &lt; self.C:
                b_new = b1_new
            elif 0 &lt; alpha2_new &lt; self.C:
                b_new = b2_new
            else:
                # 选择中点
                b_new = (b1_new + b2_new) / 2
                
            # 更新参数
            self.alpha[i1] = alpha1_new
            self.alpha[i2] = alpha2_new
            self.b = b_new
            
            self.E[i1] = self._E(i1)
            self.E[i2] = self._E(i2)
        return 'train done!'
            
    def predict(self, data):
        r = self.b
        for i in range(self.m):
            #____________________________
            r += self.alpha[i]*self.Y[i]*self.kernel(data, self.X[i])
        return 1 if r &gt; 0 else -1
    
    def score(self, X_test, y_test):
        right_count = 0
        for i in range(len(X_test)):
            #result = ______________ 
            result = self.predict(X_test[i])
            if result == y_test[i]:
                right_count += 1
        return right_count / len(X_test)
    
    def _weight(self):
        # linear model
        yx = self.Y.reshape(-1, 1)*self.X
        #self.w = ______________
        self.w = sum([self.alpha[i]*yx[i] for i in range(self.m)])
        return self.w
<br># 调用SVM进行模型训练与测试评估
svm = SVM(max_iter=100)
svm.fit(X_train, y_train)
svm.score(X_test, y_test)
<br>0.8
<br>]]></description><link>technology\collegeproject\机器学习\机器学习实验\支持向量机.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/支持向量机.md</guid><pubDate>Sun, 21 Apr 2024 01:57:04 GMT</pubDate><enclosure url="https://ai-studio-static-online.cdn.bcebos.com/0768604ae0644fcdb3edd584090f6af7fae81344e0b14da789ec1324ee81bcf0" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://ai-studio-static-online.cdn.bcebos.com/0768604ae0644fcdb3edd584090f6af7fae81344e0b14da789ec1324ee81bcf0&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[任务：构建GBDT与XGBoost回归模型预测波士顿房价]]></title><description><![CDATA[ 
 <br><br>
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn import ensemble
from sklearn.metrics import mean_squared_error, r2_score
 
 
# 加载sklearn自带的波士顿房价数据集
dataset = load_boston()
 
# 提取特征数据和目标数据
X = dataset.data
y = dataset.target
 
# 将数据集以9:1的比例随机分为训练集和测试集，为了重现随机分配设置随机种子，即random_state参数
#X_train, X_test, y_train, y_test = ____________________
X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.1,random_state=42)
<br>from sklearn.ensemble import GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
from xgboost import XGBRegressor
# 实例化GBDT回归模型
# 可以调整参数，比较模型
params = {'n_estimators': 500, 'max_depth': 4, 'min_samples_split': 2,
          'learning_rate': 0.01, 'loss': 'ls'}
#gbr = ____________________
gbr = GradientBoostingRegressor(**params)
# GBDT回归模型拟合训练数据
#____________________
gbr.fit(X_train,y_train) 

# 训练好的GBDT回归模型对测试数据进行预测
#y_pred = ____________________
y_pred=gbr.predict(X_test)

# 输出特征重要性列表
print(gbr.feature_importances_)

# 输出模型的均方误差与R方分数
#____________________
#____________________
print("Mean squared error: %.2f" % mean_squared_error(y_test, y_pred))
print('R2 score: %.2f' % r2_score(y_test, y_pred))

# 利用Scikit中xgboost构建XGBoost回归模型预测波士顿房价，与GBDT比较性能
# 请在下方补充
#____________________
xgb = XGBRegressor(n_estimators=500, max_depth=4, learning_rate=0.01, n_jobs=-1, verbosity=1)
xgb.fit(X_train,y_train)
y_pred_xgb= xgb.predict(X_test)
print("XGBoost Mean squared error: %.2f" % mean_squared_error(y_test, y_pred_xgb))
print('XGBoost R2 score: %.2f' % r2_score(y_test, y_pred_xgb))
<br>[2.49061561e-02 8.53840928e-05 2.27886200e-03 2.62725626e-04
 2.42163950e-02 4.46755580e-01 7.43100259e-03 8.65401829e-02
 2.96894693e-03 1.59602543e-02 1.95134610e-02 1.42696439e-02
 3.54811405e-01]
Mean squared error: 5.96
R2 score: 0.90
XGBoost Mean squared error: 5.88
XGBoost R2 score: 0.91
<br>]]></description><link>technology\collegeproject\机器学习\机器学习实验\gbdt与xgboost回归模型预测.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/GBDT与XGBoost回归模型预测.md</guid><pubDate>Sun, 12 Jan 2025 03:11:14 GMT</pubDate></item><item><title><![CDATA[上机实验：决策树]]></title><description><![CDATA[ 
 <br><br><br>现有一个数据集 weekend.txt，目标是根据一个人的特征来预测其周末是否出行。<br>所有特征均为二元特征，取值为 0 或 1，其中“status”（目标特征也是类别）表示用户的周末是否出行，1 表示出行，0 表示不出行，“marriageStatus”表示申请人是否已婚、“hasChild”表示申请人是否有小孩、“hasAppointment”表示申请人是否有约、“weather”表示天气是否晴朗。<br>已知信息熵和信息增益的公式为：<br><br><br>请完成以下三个内容：<br>
<br>
请自定义函数 cal_entropy(data, feature_name)计算数据集data关于feature_name的信息熵。输入参数 data 为 DataFrame，feature_name 为目标特征(或类别)的名称；

<br>
请调用 cal_entropy() 函数计算决策树分支之前的信息熵，保存为 data_entropy；

<br>
请自定义函数 cal_infoGain(data, base_entropy) 计算 weekend.txt 中各个特征的信息增益，保存为列表 infogains，并选择信息增益最大的分支节点 best_feature。

<br>
补全代码
<br>import numpy as np
import pandas as pd

# 读取数据
weekend_data = pd.read_table('weekend.txt', sep=' ')
print(weekend_data)
## 自定义计算entropy的函数
def cal_entropy(data, feature_name):
    '''
    data : 数据集变量，DataFrame类型
    featue_name : 目标特征名称
    '''
    
    ## 声明数据集的熵
    entropy = 0
    
    ## 获取data的样本数num
    num = data.shape[0]
    
    ## 使用value_counts()函数获取目标特征`feature_name`取值的频数统计信息freq_stats
    freq_stats = data[feature_name].value_counts()
    #print(freq_stats)
    ## 遍历目标特征的不同取值频数,计算entropy
    for index in range(len(freq_stats)):
        
        ## 获取具体的取值频数freq
        freq = freq_stats[index]
        
        ## 通过频数计算类别概率prob，计算entropy
        ## 请在下方补全代码
        prob=freq/num
        #print(prob)
        entropy-=prob*np.log2(prob)


    ## 返回结果
    return round(entropy, 3)

## 调用cal_entropy函数，计算weekend_data关于周末是否出门的信息熵
data_entropy = cal_entropy(weekend_data, 'status')

## 自定义计算信息增益的函数cal_infoGain
## data: 数据集变量，DataFrame类型
## base_entropy: 数据集的熵
def cal_infoGain(data, base_entropy):
    
    ## 声明数据集特征的信息增益列表
    infogain_list = []
    
    ## 获取数据集的样本数nums, 维度dims
    #______________________________
    num=data.shape[0]
    dims=data.shape[1]


    ## 获取数据集的特征名称，类型为list
    feature_list = list(data.columns.values)
    ## 移除目标特征名称
   # 如果'status'在features_list中则移除
    if 'status' in feature_list:
        feature_list.remove('status')
    
    ## 遍历每个特征
    for feature in feature_list:
        
        ## 保存feature不同取值的加权熵
        sub_entropy = 0
        
        ## 切片数据集，获取特征feature的数据记录feature_data 
        feature_data = data[feature]
        
        ## 使用value_count()函数获取特征feature取值的统计信息freq_stats
        freq_stats = feature_data.value_counts()

        ## 计算信息增益
        ## 请在下方补全代码
        infogain=cal_entropy(data, feature)-base_entropy

        ## infogain取值保留小数点后4位，保存到infogain_list中
        infogain_list.append(round(infogain, 4))
    
    ## 获取infogain_list的最大值所在的位置索引max_index
    ## 根据max_index在feature_list中找到特征的名称best_feature
    ## 请在下方补全代码
    max_feature=-1
    max_index=-1
    for index in range(len(infogain_list)):
        if max_feature&lt;infogain_list[index]:
            max_index=index

    best_feature=feature_list[max_index]
    ## 返回结果
    return infogain_list, best_feature

## 调用cal_infogain()计算各个特征的信息增益infogains，并获取最优的分支节点名称best_feature
#infogains, best_feature = cal_infoGain(weekend_data, data_entropy)

## 打印
infogains,best_feature=cal_infoGain(weekend_data, data_entropy)
print (u'信息增益列表：', infogains)
print ('')
print (u'最优的分支节点名称：', best_feature)
<br>   status  marriageStatus  hasChild  hasAppointment  weather
0       1               0         0               0        0
1       1               0         0               0        0
2       1               1         1               1        0
3       1               1         1               0        0
4       1               1         1               1        1
5       1               1         1               0        0
6       1               0         0               0        0
7       1               1         1               0        0
8       0               0         0               1        1
9       0               1         1               0        0
信息增益列表： [0.249, 0.249, 0.159, 0.0]

最优的分支节点名称： weather
<br>
期望输出：
<br><img src="https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc" referrerpolicy="no-referrer"><br><br>现在有一份有关商品销量的数据集product.csv，数据集的离散型特征信息如下：<br><br>请完成以下三个内容：<br>
<br>请根据提供的商品销量数据集 data，使用 sklearn 中的 DecisionTreeClassifier()函数构建决策树模型，模型选择分支结点的特征以Gini指数为判定准则；
<br>训练模型，并对测试集test_X进行预测，将预测结果存为 pred_y，进行模型评估；
<br>将构建的决策树模型进行可视化。
<br>
补全代码
<br>import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score
from sklearn.metrics import classification_report
data = pd.read_csv('product.csv')

## 对数据集切片，获取除目标特征以外的其他特征的数据记录X
#X = _____________
X=data.drop('销量',axis=1)
## 对数据集切片，获取目标特征`销量`的数据记录y
#y = _____________
y = data[['销量']]

## 使用train_test_split函数划分训练集train_X, train_y和测试集test_X, test_y
## 测试集所占比例为0.1,random_state为0
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size = .1, random_state = 0)

## 构建分支节点选择方法为基尼指数的决策树模型tree_model，进行模型训练、测试与性能评估
## 请在下方补全代码
tree_model=DecisionTreeClassifier(criterion="gini")
tree_model=tree_model.fit(train_X,train_y)
pred_y=tree_model.predict(test_X)
#accuracy = accuracy_score(test_y, pred_y)
#print('Accuracy: %.3f' % accuracy)
report = classification_report(test_y, pred_y, labels=[0, 1])

print(report)
## 决策树可视化
import graphviz
from sklearn.tree import export_graphviz
dot_data = export_graphviz(tree_model
                                ,out_file=None
                                ,feature_names= ["天气","周末","促销"]
                                ,class_names=["销量低","销量高"]
                                ,filled=True
                                ,rounded=True
                               )
graph = graphviz.Source(dot_data)
graph
<br>              precision    recall  f1-score   support

           0       1.00      0.50      0.67         2
           1       0.67      1.00      0.80         2

    accuracy                           0.75         4
   macro avg       0.83      0.75      0.73         4
weighted avg       0.83      0.75      0.73         4
<br>找不到“output_7_1.svg”。<br>
期望输出：
<br><img src="https://ai-studio-static-online.cdn.bcebos.com/f7c9f4d97660416b9ac354a1bcd6c87efcb7a0958cfa4579bf70a83d01ee64f7" referrerpolicy="no-referrer"><br>
<img src="https://ai-studio-static-online.cdn.bcebos.com/eb46fe19bf43414290f904042a511f25140e1908a2eb4c2e81c52450f1de68bd" referrerpolicy="no-referrer"><br><br># 请在下面完成
def id3(data, original_data, features, target, parent_node = None): 
    # 判断各种情况 
    if len(np.unique(data[target])) &lt;= 1: 
        return np.unique(data[target])[0]
    elif len(data)==0: 
        return np.unique(original_data[target])[
            np.argmax(np.unique(original_data[target],return_counts=True)[1])]
    elif len(features) ==0: 
        return parent_node 
    else: 
        parent_node = np.unique(data[target])[
            np.argmax(np.unique(data[target],return_counts=True)[1])] 
        
        # 使用cal_infoGain函数选取最好的特征节点
        _, best_feature = cal_infoGain(data, cal_entropy(data, target))
        
        # 创建决策树结构：只有根结点
        tree = {best_feature:{}}
        
        # 移除已经使用的特征
        features = [i for i in features if i != best_feature]
        
        # 继续创建决策树
        for value in np.unique(data[best_feature]):
            sub_data = data.where(data[best_feature] == value).dropna()
            subtree = id3(sub_data,original_data,features,target,parent_node) 
            tree[best_feature][value] = subtree 

    return(tree)

def classify(instance, tree, default=None):   
    attribute = next(iter(tree))              
    if instance[attribute] in tree[attribute].keys():   
        result = tree[attribute][instance[attribute]]
        if isinstance(result, dict):    
            return classify(instance, result)
        else:                             
            return result
    else:
        return default
<br>data = pd.concat([train_X,train_y], axis=1)  
original_data = data.copy()
features = train_X.columns.tolist() 
target = train_y.columns[0]
#print(features)
tree = id3(data, original_data, features, target) 
data_test=pd.concat([test_X,test_y], axis=1) 
predict_y = data_test.apply(classify, axis=1, args=(tree,"?"))
report = classification_report(test_y, predict_y, labels=[0, 1])
print(report)
<br>              precision    recall  f1-score   support

           0       1.00      1.00      1.00         2
           1       1.00      1.00      1.00         2

    accuracy                           1.00         4
   macro avg       1.00      1.00      1.00         4
weighted avg       1.00      1.00      1.00         4
<br>]]></description><link>technology\collegeproject\机器学习\机器学习实验\id3算法决策树.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验/ID3算法决策树.md</guid><pubDate>Mon, 03 Jun 2024 12:19:41 GMT</pubDate><enclosure url="https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://ai-studio-static-online.cdn.bcebos.com/3d80a48b1b80443eae424c908401e885ea91d3cb4d3a45d698f55e4df46d84fc&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[课程设计报告]]></title><description><![CDATA[ 
 <br><a rel="noopener nofollow" class="external-link" href="https://github.com/waferen/Machine-learning-course-design" target="_blank">https://github.com/waferen/Machine-learning-course-design</a><br><br><br>血容量脉冲（BVP）信号<br>
皮肤电活动（EDA）<br>
皮肤温度（TEMP）<br>
心率（HR）<br>
搏动间隔（IBI）<br>
三轴加速度计（ACC）<br><br>检测高糖——葡萄糖浓度（mg/dl）&gt;=140<br><br>本项目包含一份血糖监测设备记录用户测量值数据集，由16个糖前（或者接近糖前）用户组成，血糖监测设备记录用户的葡萄糖浓度（mg/dl）,穿戴设备记录了血容量脉冲（BVP）信号、皮肤电活动（EDA）、皮肤温度（TEMP）、心率（HR）、搏动间隔（IBI）和三轴加速度计（ACC）。<br>每位用户的文件夹内均有8个csv文件，每个文件中存放着对应特征的记录时间与数值。其中Dexcom文件中保存的是通过血糖监测设备记录的用户真实血糖值，其余的七个csv文件中保存的均为通过穿戴设备记录的特征值，其中Food_Log表示用户饮食的数据，含文本特征，可单独考虑。<br><br>本项目包含一份血糖监测设备记录用户测量值数据集，由16个糖前（或者接近糖前）用户组成，血糖监测设备记录用户的葡萄糖浓度（mg/dl）,穿戴设备记录了血容量脉冲（BVP）信号、皮肤电活动（EDA）、皮肤温度（TEMP）、心率（HR）、搏动间隔（IBI）和三轴加速度计（ACC）。<br>所有数据均保存在big-ideas-lab-glycemic-variability-and-wearable-device-data-1.1.0.zip文件中，请自行解压到data文件夹中。数据压缩包具体内容如下：<br><img src="https://ai-studio-static-online.cdn.bcebos.com/1bcc44c61b3a490f8ced5e5c6561acd0a17a4eaa5bfb452f86df866311e582fa" referrerpolicy="no-referrer"><br>每位用户的特征数据均保存在对应序号的文件夹中，如上图所示，以用户001为例来说明每位用户的具体特征信息，见下图。每位用户的文件夹内均有8个csv文件，每个文件中存放着对应特征的记录时间与数值。其中Dexcom文件中保存的是通过血糖监测设备记录的用户真实血糖值，其余的七个csv文件中保存的均为通过穿戴设备记录的特征值，其中Food表示用户饮食的数据，含文本特征，可单独考虑。<br><img src="https://ai-studio-static-online.cdn.bcebos.com/58eef270ad3b47cf8f0a4eb8d127262c5d0dcbfa7feb4b91aa59430e51981e7f" referrerpolicy="no-referrer"><br>在进行数据预处理等操作时通过pandas读取相应的csv文件即可。<br>具体任务分为以下5点：<br><br>每个表格的采样时间不完全相同，请通过采样和时间匹配完成不同数据表的整合任务。整合每位测量者的多个数据表（TEMP、IBI、HR、EDA、BVP、ACC、Dexcom），最终形成一个完整的属性数据表，每个特征的顺序可自行决定。<br>import pandas as pd

# 定义文件编号列表
file_nums = [f'{i:03d}' for i in range(2, 17)]  # 生成从 '001' 到 '016' 的文件编号

for file_num in file_nums:
    # 读取各个CSV文件
    Dexcom = pd.read_csv(f'data/{file_num}/Dexcom_{file_num}.csv', skiprows=13, header=None)
    Dexcom = Dexcom[[1, 7]]
    Dexcom.columns = ['datetime', 'Glucose Value (mg/dL)']
    Dexcom['datetime'] = pd.to_datetime(Dexcom['datetime'])

    ACC = pd.read_csv(f'data/{file_num}/ACC_{file_num}.csv')
    ACC['datetime'] = pd.to_datetime(ACC['datetime'])

    BVP = pd.read_csv(f'data/{file_num}/BVP_{file_num}.csv')
    BVP['datetime'] = pd.to_datetime(BVP['datetime'])

    EDA = pd.read_csv(f'data/{file_num}/EDA_{file_num}.csv')
    EDA['datetime'] = pd.to_datetime(EDA['datetime'])

    IBI = pd.read_csv(f'data/{file_num}/IBI_{file_num}.csv')
    IBI['datetime'] = pd.to_datetime(IBI['datetime'])

    TEMP = pd.read_csv(f'data/{file_num}/TEMP_{file_num}.csv')
    TEMP['datetime'] = pd.to_datetime(TEMP['datetime'])

    IBI = IBI.sort_values(by='datetime')
    # 合并数据框
    merged_data = Dexcom.merge(ACC, on='datetime', how='inner')
    merged_data = merged_data.merge(BVP, on='datetime', how='inner')
    merged_data = merged_data.merge(EDA, on='datetime', how='inner')
    merged_data = merged_data.merge(TEMP, on='datetime', how='inner')
    merged_data = pd.merge_asof(
        left=merged_data,
        right=IBI,
        on='datetime',
        by=None,
        tolerance=pd.Timedelta('60s'),
        direction='nearest'
    )

    # 处理缺失值
    for column in merged_data.columns:
        if merged_data[column].isna().any():
            mean_value = merged_data[column].mean()
            merged_data[column] = merged_data[column].fillna(mean_value)

    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/processed_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Processed and saved data for file number {file_num}')


<br>Processed and saved data for file number 001
Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
<br><br>请对合并后的特征总表进行缺失值与异常值的检测与处理，完成对表中数据的进一步排查与处理。<br># 请在下方完成任务
# 缺失值补为平均值

# 定义文件编号列表
file_nums = [f'{i:03d}' for i in range(1, 17)]  # 生成从 '001' 到 '016' 的文件编号

for file_num in file_nums:
    # 处理缺失值
    merged_data=pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    for column in merged_data.columns:
        if merged_data[column].isna().any():
            mean_value = merged_data[column].mean()
            merged_data[column] = merged_data[column].fillna(mean_value)

    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/processed_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Processed and saved data for file number {file_num}')

<br>Processed and saved data for file number 001
Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
<br># 增加将三轴加速度矢量合成为acc
import pandas as pd
file_nums = [f'{i:03d}' for i in range(1, 17)]
for file_num in file_nums:
    # 读取文件
    merged_data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    
    # 检查列名是否符合预期
    acc_cols = ['acc_x', 'acc_y', 'acc_z']
    
    # 确保这些列存在
    if all(col in merged_data.columns for col in acc_cols):
        # 合成三轴加速度矢量
        merged_data['acc'] = np.sqrt(
            merged_data[acc_cols[0]]**2 +
            merged_data[acc_cols[1]]**2 +
            merged_data[acc_cols[2]]**2
        )
    
    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/processed_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Processed and saved data for file number {file_num}')
<br>Processed and saved data for file number 001
Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
<br><br>由于数据的不同特征属性值的差异较大，并不利于模型的选择和使用，所以要对数据完成归一化操作。<br># 请在下方完成任务，并保存处理的样本矩阵到本地
file_nums = [f'{i:03d}' for i in range(1, 17)]  # 生成从 '001' 到 '016' 的文件编号

for file_num in file_nums:
    # 读取 CSV 文件
    merged_data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    
    # 对每一列进行归一化处理
    for column in merged_data.columns[2:]:  # 从第三列开始
        if merged_data[column].dtype in ['float64', 'int64']:  # 只对数值类型的数据列进行归一化
            column_max = merged_data[column].max()
            column_min = merged_data[column].min()
            if column_max != column_min:  # 避免除以0的情况
                merged_data[column] = (merged_data[column] - column_min) / (column_max - column_min)
    
    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/normalized_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Normalized and saved data for file number {file_num}')
<br>Normalized and saved data for file number 001
Normalized and saved data for file number 002
Normalized and saved data for file number 003
Normalized and saved data for file number 004
Normalized and saved data for file number 005
Normalized and saved data for file number 006
Normalized and saved data for file number 007
Normalized and saved data for file number 008
Normalized and saved data for file number 009
Normalized and saved data for file number 010
Normalized and saved data for file number 011
Normalized and saved data for file number 012
Normalized and saved data for file number 013
Normalized and saved data for file number 014
Normalized and saved data for file number 015
Normalized and saved data for file number 016
<br><br>不同用户每天的血糖值不断变化。通过可视化来观测不同用户一天血糖值的变化规律、高糖出现的时间、频率等。<br>import pandas as pd
import matplotlib.pyplot as plt

# 定义高糖阈值
gaotang = 140

# 指定要绘制的文件编号
file_num = '001'

# 指定要绘制的一天
target_date = '2020-02-14'

# 读取 CSV 文件
data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')

# 将第一列转换为 datetime 类型
data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

# 过滤出目标日期的数据
day_data = data[data['datetime'].dt.date == pd.to_datetime(target_date).date()]

# 绘制折线图
plt.figure(figsize=(10, 6))
plt.plot(day_data['datetime'], day_data.iloc[:, 1], label='Data Trend')

# 标出高糖值
high_sugar_points = day_data[day_data.iloc[:, 1] &gt;= gaotang]
plt.scatter(high_sugar_points['datetime'], high_sugar_points.iloc[:, 1], color='red', label='High Sugar &gt;= 140')

plt.title(f'Trend of Data with High Sugar Points Marked on {target_date} (File {file_num})')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.grid(True)

# 显示图形
plt.show()
<br><img alt="png" src="\lib\media\output_17_0.png"><br><br>为了预测每人在一天内的不同阶段是否会发生高糖，根据任务点1.4的观测结果，完成时间属性的离散化（阶段化）任务。例如，将一天划分为不同的阶段，分阶段预测是否发生高糖。具体的分段方法可自行决定，例如5分钟、1个小时、半天、上中下晚夜等。<br>
并根据分段结果，构造每个的阶段的目标值（是否高糖），形成一列数据。<br># 请在下方完成任务
#这里默认为五分钟一段，数据量在两千多。时间段太长会导致数据量大大压缩，数据不足。
import pandas as pd

gaotang = 140

file_nums = [f'{i:03d}' for i in range(1, 17)]  # 处理从001到016的文件

for file_num in file_nums:
    # 读取 CSV 文件
    data = pd.read_csv(f'processed_data/normalized_data_{file_num}.csv')
    
    # 将第一列转换为 datetime 类型
    data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

    # 使用条件表达式将大于等于140的值替换为1，其余值替换为0
    data.iloc[:, 1] = (data.iloc[:, 1] &gt;= gaotang).astype(int)

    # 保存处理后的数据到新的CSV文件
    output_file_path = f'processed_data/final_data/final_data_{file_num}.csv'
    data.to_csv(output_file_path, index=False)

    print(f'Processed and saved data for file number {file_num}')
<br>Processed and saved data for file number 001
Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
<br><br><br>数据探索分析是对每个用户整合后的数据表的进一步分析。根据任务需要，首先采样每个时间段内的时间序列进行特征提取，再探究多个特征的相关性分析与判别性分析，从而进行特征选择或降维，同时还将利用Python中绘制图形的库(如Seaborn、Matplotlib)进行一些可视化操作，辅助对数据的分析。<br><br>对于一个属性特征（例如BVP），每个阶段的特征都是一条时间序列，通过可视化分析不同特征的变化规律，并选择合适的特征提取方法提前特征，反映其特点。例如提取时序特征的统计量，如最大值（max）、最小值（min）、均值（mean）、方差（variance）等，或者对时序特征进行建模。<br>参考资料：<br><img src="https://ai-studio-static-online.cdn.bcebos.com/e7a38516c2ec47ae9354dce4c5537406ffec22ffc6d7455da53aa82d4580e6e5" referrerpolicy="no-referrer"><br>
<br>基于统计特征的分类特征提取
<br>基于基本统计量的特征提取方法是最直接的特征提取方法。它是通过提取时间序列数据在统计学上的特征构成特征向量来指导后续的分类。对于时间序列的统计特征来说常常分为两类：时间域和频率域。时域上的特征又可以分为有量纲的特征和无量纲特征，有量纲特征如均值，方差，均方根，峰值等，无量纲特征有脉冲因子，峰值因数，波形因子等；而频率上的特征包括均方频率，均方根频率，频率方差，频率标准差等。<br>
<br>基于构建模型的分类特征提取
<br>基于构建模型的特征提取方法，是通过对时间序列数据构建特定的模型，将对时间序列的特征提取转化为对模型中因子的提取。基于构建模型的特征提取方法首先需要分析数据的特点，然后根据不同数据的特点有针对的构建相应的模型。对于相对稳定的序列，如可以通过ＡＲＭＡ模型（自回归的搰动平均模型）去提取特征，而对于不稳定的序列，则需要先对数据进行差分处理，将其转化成稳定的序列。<br>
<br>基于变换的分类特征提取
<br>基于变换方式的特征提取，是通过把时间序列数据在不同域中进行映射变换，使得特征在某一个维度能够凸显出来。常见的域变换就是时域和频域上的变换，典型的包括傅里叶变换和小波变换。这种变化针对不同的应用场景，又有了不同的应用形式，如ＤＦＴ（离散傅里叶变换），ＦＦＴ（快速傅里叶变换），ＳＴＦＴ（短时傅里叶变换），ＤＷＴ（离散小波变换）等。还有一些基于线性变换的方法，包括ＰＣＡ（主成分分析），Ｋ－Ｌ变换等。<br>
<br>基于分形理论的分类特征提取
<br>分形的对象的特点包括不规则的，有自相似的结构，符合递归生成的原则。分形现象广泛的存在于自然界中，例如海岸线，山脉的轮廓，河流的流向，岩石、闪电的形状等等。随着分形理论的发展，近年来开始应用于时间序列的特征提取。分形理论进行特征提取时, 并不是所有信号都适合. 要看信号在某个尺度下是否具有可分形特征, 即不同状态下的分形维数是不同的, 这样才具有可分性。<br>!pip install seaborn
<br>## 观察一个人不同天的高糖情况
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

# 高糖阈值定义
gaotang = 140

# 指定文件编号
file_num = '002'

# 日期范围
start_date = '2020-02-22'
end_date = '2020-02-27'

# 将日期字符串转换为datetime对象
start_date = datetime.strptime(start_date, '%Y-%m-%d')
end_date = datetime.strptime(end_date, '%Y-%m-%d')

# 读取CSV文件
data = pd.read_csv(f'processed_data0/processed_data_{file_num}.csv')

# 将第一列转换为datetime类型
data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

# 循环绘制每一天的图表
current_date = start_date
while current_date &lt;= end_date:
    # 转换为字符串格式以便比较
    target_date_str = current_date.strftime('%Y-%m-%d')
    
    # 过滤出目标日期的数据
    day_data = data[data['datetime'].dt.date == current_date.date()]
    
    # 如果该天有数据，则绘制图表
    if not day_data.empty:
        plt.figure(figsize=(10, 6))
        plt.plot(day_data['datetime'], day_data.iloc[:, 1], label='Blood Glucose Level', marker='o')
        
        # 标出高于高糖阈值的部分
        high_glucose = day_data[day_data.iloc[:, 1] &gt; gaotang]
        plt.plot(high_glucose['datetime'], high_glucose.iloc[:, 1], 'ro', label=f'High Glucose (&gt; {gaotang} mg/dL)')
        
        # 添加高糖阈值线
        plt.axhline(y=gaotang, color='r', linestyle='--', label=f'Threshold ({gaotang} mg/dL)')
        
        # 设置图表标题和坐标轴标签
        plt.title(f'Blood Glucose Levels on {target_date_str}')
        plt.xlabel('Time')
        plt.ylabel('Glucose Level (mg/dL)')
        plt.legend()
        plt.grid(True)
        plt.show()
    
    # 更新日期
    current_date += timedelta(days=1)
<br><img alt="png" src="\lib\media\output_5_0.png"><br><img alt="png" src="\lib\media\output_5_1.png"><br><img alt="png" src="\lib\media\output_5_2.png"><br><img alt="png" src="\lib\media\output_5_3.png"><br><img alt="png" src="\lib\media\output_5_4.png"><br><img alt="png" src="\lib\media\output_5_5.png"><br>002号样本呈现出深夜及凌晨高糖的趋势，且午饭后的增幅尤其明显。<br>import pandas as pd
import matplotlib.pyplot as plt

# 定义高糖阈值
gaotang = 140

# 指定要绘制的文件编号
file_num = '002'

# 指定要绘制的一天
target_date = '2020-02-22'

# 读取 CSV 文件
data = pd.read_csv(f'processed_data0/processed_data_{file_num}.csv')

# 将第一列转换为 datetime 类型
data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

# 过滤出目标日期的数据
day_data = data[data['datetime'].dt.date == pd.to_datetime(target_date).date()]

# 对每一列进行归一化处理
for column in day_data.select_dtypes(include=['number']).columns:
    min_val = day_data[column].min()
    max_val = day_data[column].max()
    if max_val != min_val:  # 避免除以0的情况
        day_data[column] = (day_data[column] - min_val) / (max_val - min_val)
    else:
        # 如果最大值等于最小值，意味着该列所有的值都是相同的，可以设置为0或1
        day_data[column] = 0  # 或者选择其他合适的值

# 获取所有非时间列
feature_columns = day_data.columns[1:]

# 对于每一个特征列创建一个新的图形
for i, col in enumerate(feature_columns):
    if col != second_column and pd.api.types.is_numeric_dtype(day_data[col]):
        plt.figure(figsize=(10, 6))
        plt.plot(day_data['datetime'], day_data[second_column], label=second_column)
        plt.plot(day_data['datetime'], day_data[col], label=col)
        
        plt.title(f'Trend Comparison Between {second_column} and {col} on {target_date} (File {file_num})')
        plt.xlabel('Time')
        plt.ylabel('Normalized Value')
        plt.legend()
        plt.grid(True)
        
        # 显示图形
        plt.show()
<br>/tmp/ipykernel_265/545300125.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  day_data[column] = (day_data[column] - min_val) / (max_val - min_val)
<br><img alt="png" src="\lib\media\output_7_1.png"><br><img alt="png" src="\lib\media\output_7_2.png"><br><img alt="png" src="\lib\media\output_7_3.png"><br><img alt="png" src="\lib\media\output_7_4.png"><br><img alt="png" src="\lib\media\output_7_5.png"><br><img alt="png" src="\lib\media\output_7_6.png"><br><img alt="png" src="\lib\media\output_7_7.png"><br><img alt="png" src="\lib\media\output_7_8.png"><br>我们抽样001样本的其中一天，其各个特征与血糖值的时序图。试图找出不同特征的时序特征与血糖的时序特征的关系<br>
<br>关于acc，其有明显的白天高，夜晚低的趋势。且波动较大。这是由于白天活动较多，晚上活动较少。思路：可以检测运动，如果是有氧运动则血糖应该有下降趋势，如果是无氧运动应该血糖会有上升趋势
<br>关于bvp，由图，bvp即血容量在一天中十分稳定，只有在部分时间出现了剧烈波动，与其对应的是血糖最低点。猜测bvp的波动与血糖过低有关，或者仅仅只是异常值，可以通过其他数据验证。
<br>关于eda，eda为皮肤电刺激信号，通常与人的压力水平有关。而压力高导致的皮质醇浓度升高会导致血糖升高。由图中可以看出，其与血糖有一定的同峰情况，可以检测eda的高低来辅助推断血糖高低。
<br>关于temp,对于002样本，在早上和入睡时降低明显。但可能是个人体质不一，需要验证。
<br>关于hr和ibi,整体呈负相关，hr在白天高，晚上较低，ibi则相反。
<br><br>通过观察不同特征的分布特点，统计特征之间的相关性系数，再进行可视化展示。<br>
可以通过python中的matplotlib工具包和seaborn工具实现可视化。<br># 请在下方完成任务

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

file_nums = [f'{i:03d}' for i in range(2, 17)]  # 生成从 '001' 到 '016' 的文件编号

for file_num in file_nums:
    # 加载数据，跳过第一列
    data = pd.read_csv(f'processed_data0/processed_data_{file_num}.csv')
    
    # 选择从第二列开始的所有列
    selected_columns = data.columns[1:]
    data_selected = data[selected_columns]
    
    # 计算相关系数矩阵
    correlation_matrix = data_selected.corr()
    
    # 绘制热力图
    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
    plt.title(f'Correlation Matrix Heatmap for File {file_num} (Excluding First Column)')
    plt.show()
        
<br><img alt="png" src="\lib\media\output_10_0.png"><br><img alt="png" src="\lib\media\output_10_1.png"><br><img alt="png" src="\lib\media\output_10_2.png"><br><img alt="png" src="\lib\media\output_10_3.png"><br><img alt="png" src="\lib\media\output_10_4.png"><br><img alt="png" src="\lib\media\output_10_5.png"><br><img alt="png" src="\lib\media\output_10_6.png"><br><img alt="png" src="\lib\media\output_10_7.png"><br><img alt="png" src="\lib\media\output_10_8.png"><br><img alt="png" src="\lib\media\output_10_9.png"><br><img alt="png" src="\lib\media\output_10_10.png"><br><img alt="png" src="\lib\media\output_10_11.png"><br><img alt="png" src="\lib\media\output_10_12.png"><br><img alt="png" src="\lib\media\output_10_13.png"><br><img alt="png" src="\lib\media\output_10_14.png"><br>由相关性热力图可以看出，血糖水平与其他特征几乎没有直接的线性相关关系。只有在11号用户中与temp,ibi由一定正相关性，与eda,hr有一定负相关性。<br>
其他比较稳定的相关性只有hr和ibi有稳定的负相关。<br><br>通过分析不同特征的分布变化对发生高糖的敏感性与相关性，挖掘有判别性的特征。<br>import pandas as pd

# 生成从 '002' 到 '016' 的文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 定义时间段和对应的标签
time_segments = [
    ('00:00:00', '03:59:59', '深夜'),
    ('04:00:00', '05:59:59', '凌晨'),
    ('06:00:00', '10:59:59', '上午'),
    ('11:00:00', '12:59:59', '中午'),
    ('13:00:00', '16:59:59', '下午'),
    ('17:00:00', '18:59:59', '傍晚'),
    ('19:00:00', '23:59:59', '晚上'),
]

# 创建一个映射字典，将时间段标签映射到数字
time_segment_mapping = {label: idx for idx, (_, _, label) in enumerate(time_segments)}

# 定义函数来分配时间段标签
def assign_time_segment(row, segments=time_segments):
    row_time = row['datetime'].time()
    for start, end, label in segments:
        if pd.to_datetime(start, format='%H:%M:%S').time() &lt;= row_time &lt;= pd.to_datetime(end, format='%H:%M:%S').time():
            return label
    return None

# 定义函数来转换标签为数字
def convert_label_to_number(row, mapping=time_segment_mapping):
    return mapping.get(row['time_label'], -1)

# 对每个文件应用时间标签
for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'processed_data0/processed_data_{file_num}.csv')
    
    # 将第一列转换为 datetime 类型
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    # 应用函数并创建新列 'time_label'
    data['time_label'] = data.apply(assign_time_segment, axis=1)
    
    # 转换时间标签为数字编码
    data['time_label_num'] = data.apply(convert_label_to_number, axis=1)
    
    data.drop('time_label', axis=1, inplace=True)
    # 保存修改后的数据
    data.to_csv(f'processed_data0/time_label/processed_data_{file_num}_labeled.csv', index=False)

    print(f'file{file_num} labeled')
<br><br>根据任务2.2、2.3中对特征相关性与判别性的分析，汇总对目标任务有用的特征进行建模；将所有有用属性提取的特征拼接在一起，形成一个完整的样本矩阵，每一行表示一个阶段的观测数据（样本），每一列表示提取的一个特征值。<br>
另外，针对某个时间段的高糖预测，可多采集前一个小时的观测数据，和当前时间段的数据一起作为样本的时序特征，以预测对发生高糖的可能性。<br>import pandas as pd
from datetime import timedelta

# 生成从 '002' 到 '016' 的文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'processed_data0/time_label/processed_data_{file_num}_labeled.csv')
    print(data.head())
    # 将 datetime 列转换为 datetime 对象
    data['datetime'] = pd.to_datetime(data['datetime'])
    data.columns = data.columns.str.strip()  
    if 'hr' in data.columns:
    # Proceed with your calculations
        print('yes')
    else:
        print(f"'hr' column not found in file {file_num}")
    # 定义活动和睡眠的时间范围
    sleep_start = 22
    sleep_end = 6
    
    # 划分睡眠和活动心率
    activity_hr = data[(data['datetime'].dt.hour &gt;= sleep_end) &amp; (data['datetime'].dt.hour &lt; sleep_start)]['hr']
    sleep_hr = data[(data['datetime'].dt.hour &lt; sleep_end) | (data['datetime'].dt.hour &gt;= sleep_start)]['hr']
    
    # 计算平均心率
    avg_activity_hr = activity_hr.mean()
    avg_sleep_hr = sleep_hr.mean()
    
    # 添加新列，用于标识前一小时心率是否升高
    data['elevated_hr_past_hour'] = 0

    for i in range(1, len(data)):
        current_time = data['datetime'].iloc[i]
        one_hour_ago = current_time - timedelta(hours=1)
        past_hour_data = data[(data['datetime'] &gt;= one_hour_ago) &amp; (data['datetime'] &lt; current_time)]

        if not past_hour_data.empty:
            avg_past_hour_hr = past_hour_data['hr'].mean()
            if avg_past_hour_hr &gt; 1.1 * avg_activity_hr:
                data.at[i, 'elevated_hr_past_hour'] = 1
    
    # 保存处理后的数据
    data.to_csv(f'processed_data0/time_label/processed_data_{file_num}_labeled_enhanced.csv', index=False)


<br>import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 初始化一个空的DataFrame用于存储所有数据
data_all = pd.DataFrame()

for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'processed_data0/time_label/processed_data_{file_num}_labeled_enhanced.csv')
    
    # 将数据追加到data_all
    data_all = pd.concat([data_all, data], ignore_index=True)

# 选择目标变量
target = data_all['Glucose Value (mg/dL)']

# 选择特征，移除目标变量和无关特征
features = data_all.drop(columns=['datetime', 'Glucose Value (mg/dL)'])

# 标准化特征
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# 使用 SelectKBest 挑选最好的特征
selector = SelectKBest(score_func=f_classif, k='all')
selector.fit(features_scaled, target)

# 获取特征分数
feature_scores = selector.scores_

# 特征名和对应分数
feature_scores_df = pd.DataFrame({'Feature': features.columns, 'Score': feature_scores})

# 按分数排序并选择前5个最好的特征
best_features = feature_scores_df.sort_values(by='Score', ascending=False)
selected_features = best_features['Feature'].head(5)
print("All Files Combined")
print(best_features.head(5))  # 显示前5个最好的特征



<br>All Files Combined
  Feature     Score
7     ibi  7.062377
4     eda  6.275349
6      hr  6.024911
0   acc_x  5.184487
5    temp  4.605670
<br>import pandas as pd
import os

# 定义最佳特征列表
best_features = ['ibi', 'eda', 'hr', 'acc_x', 'temp', 'time_label_num','Glucose Value (mg/dL)']

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]
# 创建结果文件夹（如果不存在）
result_folder = 'result'
os.makedirs(result_folder, exist_ok=True)

# 对每个文件编号进行处理
for file_num in file_nums:
    # 加载数据
    input_path = f'processed_data0/time_label/processed_data_{file_num}_labeled_enhanced.csv'
    if not os.path.exists(input_path):
        print(f"File not found: {input_path}")
        continue
    
    data = pd.read_csv(input_path)
    
    # 选择最佳特征
    selected_data = data[best_features]
    
    # 保存处理后的数据到结果文件夹
    output_path = os.path.join(result_folder, f'{file_num}.csv')
    selected_data.to_csv(output_path, index=False)
    
    print(f"Processed data has been saved to {output_path}")

<br>Processed data has been saved to result/002.csv
Processed data has been saved to result/003.csv
Processed data has been saved to result/004.csv
Processed data has been saved to result/005.csv
Processed data has been saved to result/006.csv
Processed data has been saved to result/007.csv
Processed data has been saved to result/008.csv
Processed data has been saved to result/009.csv
Processed data has been saved to result/010.csv
Processed data has been saved to result/011.csv
Processed data has been saved to result/012.csv
Processed data has been saved to result/013.csv
Processed data has been saved to result/014.csv
Processed data has been saved to result/015.csv
Processed data has been saved to result/016.csv
]]></description><link>technology\collegeproject\机器学习\课程设计\课程设计报告.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/课程设计/课程设计报告.md</guid><pubDate>Mon, 09 Sep 2024 08:15:47 GMT</pubDate><enclosure url="https://ai-studio-static-online.cdn.bcebos.com/1bcc44c61b3a490f8ced5e5c6561acd0a17a4eaa5bfb452f86df866311e582fa" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://ai-studio-static-online.cdn.bcebos.com/1bcc44c61b3a490f8ced5e5c6561acd0a17a4eaa5bfb452f86df866311e582fa&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数据分析探索]]></title><description><![CDATA[ 
 <br><br>数据探索分析是对每个用户整合后的数据表的进一步分析。根据任务需要，首先采样每个时间段内的时间序列进行特征提取，再探究多个特征的相关性分析与判别性分析，从而进行特征选择或降维，同时还将利用Python中绘制图形的库(如Seaborn、Matplotlib)进行一些可视化操作，辅助对数据的分析。<br><br>对于一个属性特征（例如BVP），每个阶段的特征都是一条时间序列，通过可视化分析不同特征的变化规律，并选择合适的特征提取方法提前特征，反映其特点。例如提取时序特征的统计量，如最大值（max）、最小值（min）、均值（mean）、方差（variance）等，或者对时序特征进行建模。<br>参考资料：<br><img src="https://ai-studio-static-online.cdn.bcebos.com/e7a38516c2ec47ae9354dce4c5537406ffec22ffc6d7455da53aa82d4580e6e5" referrerpolicy="no-referrer"><br>
<br>基于统计特征的分类特征提取
<br>基于基本统计量的特征提取方法是最直接的特征提取方法。它是通过提取时间序列数据在统计学上的特征构成特征向量来指导后续的分类。对于时间序列的统计特征来说常常分为两类：时间域和频率域。时域上的特征又可以分为有量纲的特征和无量纲特征，有量纲特征如均值，方差，均方根，峰值等，无量纲特征有脉冲因子，峰值因数，波形因子等；而频率上的特征包括均方频率，均方根频率，频率方差，频率标准差等。<br>
<br>基于构建模型的分类特征提取
<br>基于构建模型的特征提取方法，是通过对时间序列数据构建特定的模型，将对时间序列的特征提取转化为对模型中因子的提取。基于构建模型的特征提取方法首先需要分析数据的特点，然后根据不同数据的特点有针对的构建相应的模型。对于相对稳定的序列，如可以通过ＡＲＭＡ模型（自回归的搰动平均模型）去提取特征，而对于不稳定的序列，则需要先对数据进行差分处理，将其转化成稳定的序列。<br>
<br>基于变换的分类特征提取
<br>基于变换方式的特征提取，是通过把时间序列数据在不同域中进行映射变换，使得特征在某一个维度能够凸显出来。常见的域变换就是时域和频域上的变换，典型的包括傅里叶变换和小波变换。这种变化针对不同的应用场景，又有了不同的应用形式，如ＤＦＴ（离散傅里叶变换），ＦＦＴ（快速傅里叶变换），ＳＴＦＴ（短时傅里叶变换），ＤＷＴ（离散小波变换）等。还有一些基于线性变换的方法，包括ＰＣＡ（主成分分析），Ｋ－Ｌ变换等。<br>
<br>基于分形理论的分类特征提取
<br>分形的对象的特点包括不规则的，有自相似的结构，符合递归生成的原则。分形现象广泛的存在于自然界中，例如海岸线，山脉的轮廓，河流的流向，岩石、闪电的形状等等。随着分形理论的发展，近年来开始应用于时间序列的特征提取。分形理论进行特征提取时, 并不是所有信号都适合. 要看信号在某个尺度下是否具有可分形特征, 即不同状态下的分形维数是不同的, 这样才具有可分性。<br>!pip install seaborn
<br>## 观察一个人不同天的高糖情况
import pandas as pd
import matplotlib.pyplot as plt
from datetime import datetime, timedelta

# 高糖阈值定义
gaotang = 140

# 指定文件编号
file_num = '002'

# 日期范围
start_date = '2020-02-22'
end_date = '2020-02-27'

# 将日期字符串转换为datetime对象
start_date = datetime.strptime(start_date, '%Y-%m-%d')
end_date = datetime.strptime(end_date, '%Y-%m-%d')

# 读取CSV文件
data = pd.read_csv(f'processed_data0/processed_data_{file_num}.csv')

# 将第一列转换为datetime类型
data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

# 循环绘制每一天的图表
current_date = start_date
while current_date &lt;= end_date:
    # 转换为字符串格式以便比较
    target_date_str = current_date.strftime('%Y-%m-%d')
    
    # 过滤出目标日期的数据
    day_data = data[data['datetime'].dt.date == current_date.date()]
    
    # 如果该天有数据，则绘制图表
    if not day_data.empty:
        plt.figure(figsize=(10, 6))
        plt.plot(day_data['datetime'], day_data.iloc[:, 1], label='Blood Glucose Level', marker='o')
        
        # 标出高于高糖阈值的部分
        high_glucose = day_data[day_data.iloc[:, 1] &gt; gaotang]
        plt.plot(high_glucose['datetime'], high_glucose.iloc[:, 1], 'ro', label=f'High Glucose (&gt; {gaotang} mg/dL)')
        
        # 添加高糖阈值线
        plt.axhline(y=gaotang, color='r', linestyle='--', label=f'Threshold ({gaotang} mg/dL)')
        
        # 设置图表标题和坐标轴标签
        plt.title(f'Blood Glucose Levels on {target_date_str}')
        plt.xlabel('Time')
        plt.ylabel('Glucose Level (mg/dL)')
        plt.legend()
        plt.grid(True)
        plt.show()
    
    # 更新日期
    current_date += timedelta(days=1)
<br><img alt="png" src="\lib\media\output_5_0.png"><br><img alt="png" src="\lib\media\output_5_1.png"><br><img alt="png" src="\lib\media\output_5_2.png"><br><img alt="png" src="\lib\media\output_5_3.png"><br><img alt="png" src="\lib\media\output_5_4.png"><br><img alt="png" src="\lib\media\output_5_5.png"><br>002号样本呈现出深夜及凌晨高糖的趋势，且午饭后的增幅尤其明显。<br>import pandas as pd
import matplotlib.pyplot as plt

# 定义高糖阈值
gaotang = 140

# 指定要绘制的文件编号
file_num = '002'

# 指定要绘制的一天
target_date = '2020-02-22'

# 读取 CSV 文件
data = pd.read_csv(f'processed_data0/processed_data_{file_num}.csv')

# 将第一列转换为 datetime 类型
data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

# 过滤出目标日期的数据
day_data = data[data['datetime'].dt.date == pd.to_datetime(target_date).date()]

# 对每一列进行归一化处理
for column in day_data.select_dtypes(include=['number']).columns:
    min_val = day_data[column].min()
    max_val = day_data[column].max()
    if max_val != min_val:  # 避免除以0的情况
        day_data[column] = (day_data[column] - min_val) / (max_val - min_val)
    else:
        # 如果最大值等于最小值，意味着该列所有的值都是相同的，可以设置为0或1
        day_data[column] = 0  # 或者选择其他合适的值

# 获取所有非时间列
feature_columns = day_data.columns[1:]

# 对于每一个特征列创建一个新的图形
for i, col in enumerate(feature_columns):
    if col != second_column and pd.api.types.is_numeric_dtype(day_data[col]):
        plt.figure(figsize=(10, 6))
        plt.plot(day_data['datetime'], day_data[second_column], label=second_column)
        plt.plot(day_data['datetime'], day_data[col], label=col)
        
        plt.title(f'Trend Comparison Between {second_column} and {col} on {target_date} (File {file_num})')
        plt.xlabel('Time')
        plt.ylabel('Normalized Value')
        plt.legend()
        plt.grid(True)
        
        # 显示图形
        plt.show()
<br>/tmp/ipykernel_265/545300125.py:27: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  day_data[column] = (day_data[column] - min_val) / (max_val - min_val)
<br><img alt="png" src="\lib\media\output_7_1.png"><br><img alt="png" src="\lib\media\output_7_2.png"><br><img alt="png" src="\lib\media\output_7_3.png"><br><img alt="png" src="\lib\media\output_7_4.png"><br><img alt="png" src="\lib\media\output_7_5.png"><br><img alt="png" src="\lib\media\output_7_6.png"><br><img alt="png" src="\lib\media\output_7_7.png"><br><img alt="png" src="\lib\media\output_7_8.png"><br>我们抽样001样本的其中一天，其各个特征与血糖值的时序图。试图找出不同特征的时序特征与血糖的时序特征的关系<br>
<br>关于acc，其有明显的白天高，夜晚低的趋势。且波动较大。这是由于白天活动较多，晚上活动较少。思路：可以检测运动，如果是有氧运动则血糖应该有下降趋势，如果是无氧运动应该血糖会有上升趋势
<br>关于bvp，由图，bvp即血容量在一天中十分稳定，只有在部分时间出现了剧烈波动，与其对应的是血糖最低点。猜测bvp的波动与血糖过低有关，或者仅仅只是异常值，可以通过其他数据验证。
<br>关于eda，eda为皮肤电刺激信号，通常与人的压力水平有关。而压力高导致的皮质醇浓度升高会导致血糖升高。由图中可以看出，其与血糖有一定的同峰情况，可以检测eda的高低来辅助推断血糖高低。
<br>关于temp,对于002样本，在早上和入睡时降低明显。但可能是个人体质不一，需要验证。
<br>关于hr和ibi,整体呈负相关，hr在白天高，晚上较低，ibi则相反。
<br><br>通过观察不同特征的分布特点，统计特征之间的相关性系数，再进行可视化展示。<br>
可以通过python中的matplotlib工具包和seaborn工具实现可视化。<br># 请在下方完成任务

import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

file_nums = [f'{i:03d}' for i in range(2, 17)]  # 生成从 '001' 到 '016' 的文件编号

for file_num in file_nums:
    # 加载数据，跳过第一列
    data = pd.read_csv(f'processed_data0/processed_data_{file_num}.csv')
    
    # 选择从第二列开始的所有列
    selected_columns = data.columns[1:]
    data_selected = data[selected_columns]
    
    # 计算相关系数矩阵
    correlation_matrix = data_selected.corr()
    
    # 绘制热力图
    plt.figure(figsize=(10, 8))
    sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
    plt.title(f'Correlation Matrix Heatmap for File {file_num} (Excluding First Column)')
    plt.show()
        
<br><img alt="png" src="\lib\media\output_10_0.png"><br><img alt="png" src="\lib\media\output_10_1.png"><br><img alt="png" src="\lib\media\output_10_2.png"><br><img alt="png" src="\lib\media\output_10_3.png"><br><img alt="png" src="\lib\media\output_10_4.png"><br><img alt="png" src="\lib\media\output_10_5.png"><br><img alt="png" src="\lib\media\output_10_6.png"><br><img alt="png" src="\lib\media\output_10_7.png"><br><img alt="png" src="\lib\media\output_10_8.png"><br><img alt="png" src="\lib\media\output_10_9.png"><br><img alt="png" src="\lib\media\output_10_10.png"><br><img alt="png" src="\lib\media\output_10_11.png"><br><img alt="png" src="\lib\media\output_10_12.png"><br><img alt="png" src="\lib\media\output_10_13.png"><br><img alt="png" src="\lib\media\output_10_14.png"><br>由相关性热力图可以看出，血糖水平与其他特征几乎没有直接的线性相关关系。只有在11号用户中与temp,ibi由一定正相关性，与eda,hr有一定负相关性。<br>
其他比较稳定的相关性只有hr和ibi有稳定的负相关。<br><br>通过分析不同特征的分布变化对发生高糖的敏感性与相关性，挖掘有判别性的特征。<br>import pandas as pd

# 生成从 '002' 到 '016' 的文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 定义时间段和对应的标签
time_segments = [
    ('00:00:00', '03:59:59', '深夜'),
    ('04:00:00', '05:59:59', '凌晨'),
    ('06:00:00', '10:59:59', '上午'),
    ('11:00:00', '12:59:59', '中午'),
    ('13:00:00', '16:59:59', '下午'),
    ('17:00:00', '18:59:59', '傍晚'),
    ('19:00:00', '23:59:59', '晚上'),
]

# 创建一个映射字典，将时间段标签映射到数字
time_segment_mapping = {label: idx for idx, (_, _, label) in enumerate(time_segments)}

# 定义函数来分配时间段标签
def assign_time_segment(row, segments=time_segments):
    row_time = row['datetime'].time()
    for start, end, label in segments:
        if pd.to_datetime(start, format='%H:%M:%S').time() &lt;= row_time &lt;= pd.to_datetime(end, format='%H:%M:%S').time():
            return label
    return None

# 定义函数来转换标签为数字
def convert_label_to_number(row, mapping=time_segment_mapping):
    return mapping.get(row['time_label'], -1)

# 对每个文件应用时间标签
for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'processed_data0/processed_data_{file_num}.csv')
    
    # 将第一列转换为 datetime 类型
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    # 应用函数并创建新列 'time_label'
    data['time_label'] = data.apply(assign_time_segment, axis=1)
    
    # 转换时间标签为数字编码
    data['time_label_num'] = data.apply(convert_label_to_number, axis=1)
    
    data.drop('time_label', axis=1, inplace=True)
    # 保存修改后的数据
    data.to_csv(f'processed_data0/time_label/processed_data_{file_num}_labeled.csv', index=False)

    print(f'file{file_num} labeled')
<br><br>根据任务2.2、2.3中对特征相关性与判别性的分析，汇总对目标任务有用的特征进行建模；将所有有用属性提取的特征拼接在一起，形成一个完整的样本矩阵，每一行表示一个阶段的观测数据（样本），每一列表示提取的一个特征值。<br>
另外，针对某个时间段的高糖预测，可多采集前一个小时的观测数据，和当前时间段的数据一起作为样本的时序特征，以预测对发生高糖的可能性。<br>import pandas as pd
from datetime import timedelta

# 生成从 '002' 到 '016' 的文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'processed_data0/time_label/processed_data_{file_num}_labeled.csv')
    print(data.head())
    # 将 datetime 列转换为 datetime 对象
    data['datetime'] = pd.to_datetime(data['datetime'])
    data.columns = data.columns.str.strip()  
    if 'hr' in data.columns:
    # Proceed with your calculations
        print('yes')
    else:
        print(f"'hr' column not found in file {file_num}")
    # 定义活动和睡眠的时间范围
    sleep_start = 22
    sleep_end = 6
    
    # 划分睡眠和活动心率
    activity_hr = data[(data['datetime'].dt.hour &gt;= sleep_end) &amp; (data['datetime'].dt.hour &lt; sleep_start)]['hr']
    sleep_hr = data[(data['datetime'].dt.hour &lt; sleep_end) | (data['datetime'].dt.hour &gt;= sleep_start)]['hr']
    
    # 计算平均心率
    avg_activity_hr = activity_hr.mean()
    avg_sleep_hr = sleep_hr.mean()
    
    # 添加新列，用于标识前一小时心率是否升高
    data['elevated_hr_past_hour'] = 0

    for i in range(1, len(data)):
        current_time = data['datetime'].iloc[i]
        one_hour_ago = current_time - timedelta(hours=1)
        past_hour_data = data[(data['datetime'] &gt;= one_hour_ago) &amp; (data['datetime'] &lt; current_time)]

        if not past_hour_data.empty:
            avg_past_hour_hr = past_hour_data['hr'].mean()
            if avg_past_hour_hr &gt; 1.1 * avg_activity_hr:
                data.at[i, 'elevated_hr_past_hour'] = 1
    
    # 保存处理后的数据
    data.to_csv(f'processed_data0/time_label/processed_data_{file_num}_labeled_enhanced.csv', index=False)


<br>import pandas as pd
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 初始化一个空的DataFrame用于存储所有数据
data_all = pd.DataFrame()

for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'processed_data0/time_label/processed_data_{file_num}_labeled_enhanced.csv')
    
    # 将数据追加到data_all
    data_all = pd.concat([data_all, data], ignore_index=True)

# 选择目标变量
target = data_all['Glucose Value (mg/dL)']

# 选择特征，移除目标变量和无关特征
features = data_all.drop(columns=['datetime', 'Glucose Value (mg/dL)'])

# 标准化特征
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# 使用 SelectKBest 挑选最好的特征
selector = SelectKBest(score_func=f_classif, k='all')
selector.fit(features_scaled, target)

# 获取特征分数
feature_scores = selector.scores_

# 特征名和对应分数
feature_scores_df = pd.DataFrame({'Feature': features.columns, 'Score': feature_scores})

# 按分数排序并选择前5个最好的特征
best_features = feature_scores_df.sort_values(by='Score', ascending=False)
selected_features = best_features['Feature'].head(5)
print("All Files Combined")
print(best_features.head(5))  # 显示前5个最好的特征



<br>All Files Combined
  Feature     Score
7     ibi  7.062377
4     eda  6.275349
6      hr  6.024911
0   acc_x  5.184487
5    temp  4.605670
<br>import pandas as pd
import os

# 定义最佳特征列表
best_features = ['ibi', 'eda', 'hr', 'acc_x', 'temp', 'time_label_num','Glucose Value (mg/dL)']

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]
# 创建结果文件夹（如果不存在）
result_folder = 'result'
os.makedirs(result_folder, exist_ok=True)

# 对每个文件编号进行处理
for file_num in file_nums:
    # 加载数据
    input_path = f'processed_data0/time_label/processed_data_{file_num}_labeled_enhanced.csv'
    if not os.path.exists(input_path):
        print(f"File not found: {input_path}")
        continue
    
    data = pd.read_csv(input_path)
    
    # 选择最佳特征
    selected_data = data[best_features]
    
    # 保存处理后的数据到结果文件夹
    output_path = os.path.join(result_folder, f'{file_num}.csv')
    selected_data.to_csv(output_path, index=False)
    
    print(f"Processed data has been saved to {output_path}")

<br>Processed data has been saved to result/002.csv
Processed data has been saved to result/003.csv
Processed data has been saved to result/004.csv
Processed data has been saved to result/005.csv
Processed data has been saved to result/006.csv
Processed data has been saved to result/007.csv
Processed data has been saved to result/008.csv
Processed data has been saved to result/009.csv
Processed data has been saved to result/010.csv
Processed data has been saved to result/011.csv
Processed data has been saved to result/012.csv
Processed data has been saved to result/013.csv
Processed data has been saved to result/014.csv
Processed data has been saved to result/015.csv
Processed data has been saved to result/016.csv
]]></description><link>technology\collegeproject\机器学习\课程设计\数据分析探索.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/课程设计/数据分析探索.md</guid><pubDate>Tue, 03 Sep 2024 07:36:49 GMT</pubDate><enclosure url="https://ai-studio-static-online.cdn.bcebos.com/e7a38516c2ec47ae9354dce4c5537406ffec22ffc6d7455da53aa82d4580e6e5" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://ai-studio-static-online.cdn.bcebos.com/e7a38516c2ec47ae9354dce4c5537406ffec22ffc6d7455da53aa82d4580e6e5&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数据预处理]]></title><description><![CDATA[ 
 <br><br>本项目包含一份血糖监测设备记录用户测量值数据集，由16个糖前（或者接近糖前）用户组成，血糖监测设备记录用户的葡萄糖浓度（mg/dl）,穿戴设备记录了血容量脉冲（BVP）信号、皮肤电活动（EDA）、皮肤温度（TEMP）、心率（HR）、搏动间隔（IBI）和三轴加速度计（ACC）。<br>所有数据均保存在big-ideas-lab-glycemic-variability-and-wearable-device-data-1.1.0.zip文件中，请自行解压到data文件夹中。数据压缩包具体内容如下：<br><img src="https://ai-studio-static-online.cdn.bcebos.com/1bcc44c61b3a490f8ced5e5c6561acd0a17a4eaa5bfb452f86df866311e582fa" referrerpolicy="no-referrer"><br>每位用户的特征数据均保存在对应序号的文件夹中，如上图所示，以用户001为例来说明每位用户的具体特征信息，见下图。每位用户的文件夹内均有8个csv文件，每个文件中存放着对应特征的记录时间与数值。其中Dexcom文件中保存的是通过血糖监测设备记录的用户真实血糖值，其余的七个csv文件中保存的均为通过穿戴设备记录的特征值，其中Food表示用户饮食的数据，含文本特征，可单独考虑。<br><img src="https://ai-studio-static-online.cdn.bcebos.com/58eef270ad3b47cf8f0a4eb8d127262c5d0dcbfa7feb4b91aa59430e51981e7f" referrerpolicy="no-referrer"><br>在进行数据预处理等操作时通过pandas读取相应的csv文件即可。<br>具体任务分为以下5点：<br><br>每个表格的采样时间不完全相同，请通过采样和时间匹配完成不同数据表的整合任务。整合每位测量者的多个数据表（TEMP、IBI、HR、EDA、BVP、ACC、Dexcom），最终形成一个完整的属性数据表，每个特征的顺序可自行决定。<br>import pandas as pd

# 定义文件编号列表
file_nums = [f'{i:03d}' for i in range(2, 17)]  # 生成从 '001' 到 '016' 的文件编号

for file_num in file_nums:
    # 读取各个CSV文件
    Dexcom = pd.read_csv(f'data/{file_num}/Dexcom_{file_num}.csv', skiprows=13, header=None)
    Dexcom = Dexcom[[1, 7]]
    Dexcom.columns = ['datetime', 'Glucose Value (mg/dL)']
    Dexcom['datetime'] = pd.to_datetime(Dexcom['datetime'])

    ACC = pd.read_csv(f'data/{file_num}/ACC_{file_num}.csv')
    ACC['datetime'] = pd.to_datetime(ACC['datetime'])

    BVP = pd.read_csv(f'data/{file_num}/BVP_{file_num}.csv')
    BVP['datetime'] = pd.to_datetime(BVP['datetime'])

    EDA = pd.read_csv(f'data/{file_num}/EDA_{file_num}.csv')
    EDA['datetime'] = pd.to_datetime(EDA['datetime'])

    IBI = pd.read_csv(f'data/{file_num}/IBI_{file_num}.csv')
    IBI['datetime'] = pd.to_datetime(IBI['datetime'])

    TEMP = pd.read_csv(f'data/{file_num}/TEMP_{file_num}.csv')
    TEMP['datetime'] = pd.to_datetime(TEMP['datetime'])

    IBI = IBI.sort_values(by='datetime')
    # 合并数据框
    merged_data = Dexcom.merge(ACC, on='datetime', how='inner')
    merged_data = merged_data.merge(BVP, on='datetime', how='inner')
    merged_data = merged_data.merge(EDA, on='datetime', how='inner')
    merged_data = merged_data.merge(TEMP, on='datetime', how='inner')
    merged_data = pd.merge_asof(
        left=merged_data,
        right=IBI,
        on='datetime',
        by=None,
        tolerance=pd.Timedelta('60s'),
        direction='nearest'
    )

    # 处理缺失值
    for column in merged_data.columns:
        if merged_data[column].isna().any():
            mean_value = merged_data[column].mean()
            merged_data[column] = merged_data[column].fillna(mean_value)

    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/processed_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Processed and saved data for file number {file_num}')


<br>Processed and saved data for file number 001
Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
<br><br>请对合并后的特征总表进行缺失值与异常值的检测与处理，完成对表中数据的进一步排查与处理。<br># 请在下方完成任务
# 缺失值补为平均值

# 定义文件编号列表
file_nums = [f'{i:03d}' for i in range(1, 17)]  # 生成从 '001' 到 '016' 的文件编号

for file_num in file_nums:
    # 处理缺失值
    merged_data=pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    for column in merged_data.columns:
        if merged_data[column].isna().any():
            mean_value = merged_data[column].mean()
            merged_data[column] = merged_data[column].fillna(mean_value)

    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/processed_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Processed and saved data for file number {file_num}')

<br>Processed and saved data for file number 001
Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
<br># 增加将三轴加速度矢量合成为acc
import pandas as pd
file_nums = [f'{i:03d}' for i in range(1, 17)]
for file_num in file_nums:
    # 读取文件
    merged_data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    
    # 检查列名是否符合预期
    acc_cols = ['acc_x', 'acc_y', 'acc_z']
    
    # 确保这些列存在
    if all(col in merged_data.columns for col in acc_cols):
        # 合成三轴加速度矢量
        merged_data['acc'] = np.sqrt(
            merged_data[acc_cols[0]]**2 +
            merged_data[acc_cols[1]]**2 +
            merged_data[acc_cols[2]]**2
        )
    
    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/processed_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Processed and saved data for file number {file_num}')
<br>Processed and saved data for file number 001
Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
<br><br>由于数据的不同特征属性值的差异较大，并不利于模型的选择和使用，所以要对数据完成归一化操作。<br># 请在下方完成任务，并保存处理的样本矩阵到本地
file_nums = [f'{i:03d}' for i in range(1, 17)]  # 生成从 '001' 到 '016' 的文件编号

for file_num in file_nums:
    # 读取 CSV 文件
    merged_data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    
    # 对每一列进行归一化处理
    for column in merged_data.columns[2:]:  # 从第三列开始
        if merged_data[column].dtype in ['float64', 'int64']:  # 只对数值类型的数据列进行归一化
            column_max = merged_data[column].max()
            column_min = merged_data[column].min()
            if column_max != column_min:  # 避免除以0的情况
                merged_data[column] = (merged_data[column] - column_min) / (column_max - column_min)
    
    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/normalized_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Normalized and saved data for file number {file_num}')
<br>Normalized and saved data for file number 001
Normalized and saved data for file number 002
Normalized and saved data for file number 003
Normalized and saved data for file number 004
Normalized and saved data for file number 005
Normalized and saved data for file number 006
Normalized and saved data for file number 007
Normalized and saved data for file number 008
Normalized and saved data for file number 009
Normalized and saved data for file number 010
Normalized and saved data for file number 011
Normalized and saved data for file number 012
Normalized and saved data for file number 013
Normalized and saved data for file number 014
Normalized and saved data for file number 015
Normalized and saved data for file number 016
<br><br>不同用户每天的血糖值不断变化。通过可视化来观测不同用户一天血糖值的变化规律、高糖出现的时间、频率等。<br>import pandas as pd
import matplotlib.pyplot as plt

# 定义高糖阈值
gaotang = 140

# 指定要绘制的文件编号
file_num = '001'

# 指定要绘制的一天
target_date = '2020-02-14'

# 读取 CSV 文件
data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')

# 将第一列转换为 datetime 类型
data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

# 过滤出目标日期的数据
day_data = data[data['datetime'].dt.date == pd.to_datetime(target_date).date()]

# 绘制折线图
plt.figure(figsize=(10, 6))
plt.plot(day_data['datetime'], day_data.iloc[:, 1], label='Data Trend')

# 标出高糖值
high_sugar_points = day_data[day_data.iloc[:, 1] &gt;= gaotang]
plt.scatter(high_sugar_points['datetime'], high_sugar_points.iloc[:, 1], color='red', label='High Sugar &gt;= 140')

plt.title(f'Trend of Data with High Sugar Points Marked on {target_date} (File {file_num})')
plt.xlabel('Time')
plt.ylabel('Value')
plt.legend()
plt.grid(True)

# 显示图形
plt.show()
<br><img alt="png" src="\lib\media\output_17_0.png"><br><br>为了预测每人在一天内的不同阶段是否会发生高糖，根据任务点1.4的观测结果，完成时间属性的离散化（阶段化）任务。例如，将一天划分为不同的阶段，分阶段预测是否发生高糖。具体的分段方法可自行决定，例如5分钟、1个小时、半天、上中下晚夜等。<br>
并根据分段结果，构造每个的阶段的目标值（是否高糖），形成一列数据。<br># 请在下方完成任务
#这里默认为五分钟一段，数据量在两千多。时间段太长会导致数据量大大压缩，数据不足。
import pandas as pd

gaotang = 140

file_nums = [f'{i:03d}' for i in range(1, 17)]  # 处理从001到016的文件

for file_num in file_nums:
    # 读取 CSV 文件
    data = pd.read_csv(f'processed_data/normalized_data_{file_num}.csv')
    
    # 将第一列转换为 datetime 类型
    data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

    # 使用条件表达式将大于等于140的值替换为1，其余值替换为0
    data.iloc[:, 1] = (data.iloc[:, 1] &gt;= gaotang).astype(int)

    # 保存处理后的数据到新的CSV文件
    output_file_path = f'processed_data/final_data/final_data_{file_num}.csv'
    data.to_csv(output_file_path, index=False)

    print(f'Processed and saved data for file number {file_num}')
<br>Processed and saved data for file number 001
Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
]]></description><link>technology\collegeproject\机器学习\课程设计\数据预处理.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/课程设计/数据预处理.md</guid><pubDate>Tue, 03 Sep 2024 07:27:37 GMT</pubDate><enclosure url="https://ai-studio-static-online.cdn.bcebos.com/1bcc44c61b3a490f8ced5e5c6561acd0a17a4eaa5bfb452f86df866311e582fa" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://ai-studio-static-online.cdn.bcebos.com/1bcc44c61b3a490f8ced5e5c6561acd0a17a4eaa5bfb452f86df866311e582fa&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[项目实验报告]]></title><description><![CDATA[ 
 <br><br><a rel="noopener nofollow" class="external-link" href="https://github.com/waferen/Machine-learning-course-design" target="_blank">https://github.com/waferen/Machine-learning-course-design</a><br><br>
<br>学号：19220423
<br>姓名：李世博
<br>专业：人工智能
<br>班级：192204
<br>小组：9
<br><br><br>智能穿戴技术作为一种无创设备为解决糖尿病前期人群的控糖监测提供了便利。TIR、TAR、TBR是动态血糖监测系统的重要参数分别反映了血糖良好控制情况、高血糖和低血糖情况。针对不同的个体情况，应该个性化设定TIR、TAR和TBR。<br><br>本项目从穿戴设备记录的数据中提取特征，训练机器学习模型，测试人群一天内的不同阶段是否发生高糖，进而统计每天高糖的发生次数。<br><br><br>本项目包含一份血糖监测设备记录用户测量值数据集，由16个糖前（或者接近糖前）用户组成，血糖监测设备记录用户的葡萄糖浓度（mg/dl）,穿戴设备记录了血容量脉冲（BVP）信号、皮肤电活动（EDA）、皮肤温度（TEMP）、心率（HR）、搏动间隔（IBI）和三轴加速度计（ACC）。<br>每位用户的文件夹内均有8个csv文件，每个文件中存放着对应特征的记录时间与数值。其中Dexcom文件中保存的是通过血糖监测设备记录的用户真实血糖值，其余的七个csv文件中保存的均为通过穿戴设备记录的特征值，其中Food_Log表示用户饮食的数据，含文本特征，可单独考虑。<br><br>
要求：<br>
（1）观察是否高糖的数据分布，画出柱状图，观察类别是否均衡，如果不均衡，是否会对我们构建的分类模型产生影响？ 请谈谈你的看法。<br>
（2）请简要分析一下不同特征的取值范围和特点，以及对用户是否高糖的影响，画出如下柱状图，观察其内在关联。<br>
（3）针对不同特征在时间序列上的特点，设计两种以上时序特征提取方法，并分析其有效性。<br>
（4）文字内容不限于上述三点，可以根据自己的理解阐述更多内容。
<br><br># 画出每一个用户的高血糖样本数与正常样本数的柱状图
import pandas as pd
import matplotlib.pyplot as plt
# 定义文件编号列表
file_nums = [f'{i:03d}' for i in range(2, 17)]  # 生成从 '002' 到 '016' 的文件编号

for file_num in file_nums:
    # 高血糖标准，&gt;=140为高血糖
    high_blood_sugar = 140
    # 具体数据在processed_data文件夹下
    data = pd.read_csv(f'./processed_data/processed_data_{file_num}.csv')
    # 统计每个用户的高血糖样本数与正常样本数
    high_blood_sugar_count = data[data['Glucose Value (mg/dL)'] &gt;= high_blood_sugar].shape[0]
    normal_count = data[data['Glucose Value (mg/dL)'] &lt; high_blood_sugar].shape[0]
    # 画出柱状图
    plt.bar(['High blood sugar', 'Normal'], [high_blood_sugar_count, normal_count])
    plt.title(f'User {file_num} blood sugar count')
    plt.show()


<br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_0.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_1.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_2.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_3.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_4.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_5.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_6.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_7.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_8.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_9.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_10.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_11.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_12.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_13.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_14.png"><br>由图可知，所有用户的高糖与正常类别都是不平衡的。<br>
类别不平衡可能会导致以下几个问题：<br>
<br>
模型偏向：模型可能会偏向于预测多数类，因为从统计学的角度来看，预测多数类可以得到更高的准确率。这会导致少数类的预测性能较差。

<br>
评估指标失真：使用如准确率（accuracy）这样的评估指标可能会误导人，因为它没有考虑到类别不平衡的影响。例如，即使模型总是预测多数类，也可能得到较高的准确率。

<br>
过拟合少数类：尝试纠正类别不平衡可能导致模型对少数类过拟合，从而牺牲了其在多数类上的表现。

<br>
训练效率低下：模型可能需要更长的时间来收敛，因为它需要学习如何正确地处理不平衡的样本分布。

<br>为了解决类别不平衡问题，通常可以采取以下几种策略：<br>
<br>
重采样技术：包括上采样（增加少数类样本的数量）和下采样（减少多数类样本的数量）。也可以使用SMOTE等技术合成新的少数类样本。

<br>
成本敏感学习：为不同的分类错误赋予不同的权重，使得模型在训练过程中更加重视少数类。

<br>
集成方法：使用多个模型进行投票以提高预测的准确性，这可以帮助缓解类别不平衡带来的影响。

<br>
调整决策阈值：对于概率预测模型，可以通过调整决策阈值来优化对少数类的预测。

<br><br>这里，我们抽样002号用户的2020-02-22这天作为样本，观察这一天中，其各个特征数据与血糖变化的关系<br>import pandas as pd
import matplotlib.pyplot as plt

# 定义高糖阈值
gaotang = 140

# 指定要绘制的文件编号
file_num = '002'

# 指定要绘制的一天
target_date = '2020-02-22'

# 读取 CSV 文件
data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')

# 将第一列转换为 datetime 类型
data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

# 过滤出目标日期的数据
day_data = data[data['datetime'].dt.date == pd.to_datetime(target_date).date()]

# 获取第二列（假设是数值类型）
second_column = day_data.columns[1]

# 检查第二列是否为数值类型
if not pd.api.types.is_numeric_dtype(day_data[second_column]):
    raise ValueError(f"The second column '{second_column}' is not numeric.")

# 对每一列进行归一化处理
for column in day_data.select_dtypes(include=['number']).columns:
    min_val = day_data[column].min()
    max_val = day_data[column].max()
    if max_val != min_val:  # 避免除以0的情况
        day_data[column] = (day_data[column] - min_val) / (max_val - min_val)
    else:
        # 如果最大值等于最小值，意味着该列所有的值都是相同的，可以设置为0或1
        day_data[column] = 0  # 或者选择其他合适的值

# 获取所有非时间列
feature_columns = day_data.columns[1:8]

# 对于每一个特征列创建一个新的图形
for i, col in enumerate(feature_columns):
    if col != second_column and pd.api.types.is_numeric_dtype(day_data[col]):
        plt.figure(figsize=(10, 6))
        plt.plot(day_data['datetime'], day_data[second_column], label=second_column)
        plt.plot(day_data['datetime'], day_data[col], label=col)
        
        plt.title(f'Trend Comparison Between {second_column} and {col} on {target_date} (File {file_num})')
        plt.xlabel('Time')
        plt.ylabel('Normalized Value')
        plt.legend()
        plt.grid(True)
        
        # 显示图形
        plt.show()
<br>C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3031747850.py:34: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  day_data[column] = (day_data[column] - min_val) / (max_val - min_val)
<br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_13_1.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_13_2.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_13_3.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_13_4.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_13_5.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_13_6.png"><br>我们抽样002样本的其中一天，其各个特征与血糖值的时序图。试图找出不同特征的时序特征与血糖的时序特征的关系<br>
<br>关于acc，其有明显的白天高，夜晚低的趋势。且波动较大。这是由于白天活动较多，晚上活动较少。思路：可以检测运动，如果是有氧运动则血糖应该有下降趋势，如果是无氧运动应该血糖会有上升趋势
<br>关于bvp，由图，bvp即血容量在一天中十分稳定，只有在部分时间出现了剧烈波动，与其对应的是血糖最低点。猜测bvp的波动与血糖过低有关，或者仅仅只是异常值，可以通过其他数据验证。
<br>关于eda，eda为皮肤电刺激信号，通常与人的压力水平有关。而压力高导致的皮质醇浓度升高会导致血糖升高。由图中可以看出，其与血糖有一定的同峰情况，可以检测eda的高低来辅助推断血糖高低。
<br>关于temp,对于002样本，在早上和入睡时降低明显。但可能是个人体质不一，需要验证。
<br>关于hr和ibi,整体呈负相关，hr在白天高，晚上较低，ibi则相反。
<br><br>针对时间序列数据的特点，可以设计多种时序特征提取方法来捕捉数据中的不同特性。以下是两种常见的时序特征提取方法及其有效性分析：<br><br>滑动窗口统计特征是一种常用的方法，它通过在时间序列上滑动一个固定长度的窗口，并计算窗口内的统计数据。这种方法可以捕捉数据的局部特性。<br><br>
<br>滑动窗口长度：选择一个合适的窗口长度（这里选用一个小时），并在此窗口内进行统计计算。
<br>统计量：计算窗口内的平均值、标准差、最大值、最小值等统计量。
<br>步长：设定一个窗口移动的步长（这里每五分钟移动一次）。
<br><br>
<br>优点：

<br>局部特性捕捉：能够捕捉数据在短时间内的变化趋势。
<br>异常检测：通过观察统计量的变化，可以更容易地识别出异常情况。
<br>平滑噪声：平均值等统计量有助于平滑噪声，提高信号质量。


<br>缺点：

<br>窗口长度选择：窗口长度的选择会影响结果，需要根据具体应用场景进行调优。
<br>计算复杂度：对于大数据集，滑动窗口计算可能会比较耗时。


<br><br>频域特征是通过对时间序列数据进行傅里叶变换（FFT）来提取的。这种方法可以捕捉数据的周期性和频率成分。<br><br>
<br>傅里叶变换：对时间序列数据进行快速傅里叶变换（FFT），得到频谱。
<br>频谱特征：提取频谱中的峰值频率、功率谱密度等特征。
<br>倒谱分析：对频谱进行再次变换，提取倒谱特征。
<br><br>
<br>优点：

<br>周期性检测：能够有效地检测数据中的周期性成分。
<br>频率信息：提供关于数据频率特性的信息，有助于理解数据的内在结构。
<br>降噪：通过去除高频噪声，可以提高信号的质量。


<br>缺点：

<br>解释难度：频域特征可能较难直接解释，需要专业知识来理解和分析。
<br>计算复杂度：FFT计算复杂度较高，特别是对于长序列数据。


<br><br>通过滑动窗口统计特征和频域特征提取方法，我们可以从不同的角度捕捉时间序列数据的特性。滑动窗口统计特征适合捕捉局部趋势和异常检测，而频域特征则适用于周期性检测和频率成分分析。结合这两种方法，可以更全面地理解和分析时间序列数据。<br>滑动窗口形成的数据在window_data文件夹中，其中是以一小时为窗口时长，5分钟为步长的数据。包含了平均值，标准差，增量，最大值，最小值，频谱特征，一小时内卡路里摄入量，糖分摄入量等特征。具体如下：end_time,acc_x_mean,acc_x_std,acc_x_max,acc_x_min,acc_x_delta,acc_x_peak_freq,acc_y_mean,acc_y_std,acc_y_max,acc_y_min,acc_y_delta,acc_y_peak_freq,acc_z_mean,acc_z_std,acc_z_max,acc_z_min,acc_z_delta,acc_z_peak_freq,bvp_mean,bvp_std,bvp_max,bvp_min,bvp_delta,bvp_peak_freq,eda_mean,eda_std,eda_max,eda_min,eda_delta,eda_peak_freq,temp_mean,temp_std,temp_max,temp_min,temp_delta,temp_peak_freq,ibi_mean,ibi_std,ibi_max,ibi_min,ibi_delta,ibi_peak_freq,calorie_sum,total_carb_sum,sugar_sum,protein_sum<br>目标变量为一小时内的高糖次数glucose_freq<br>通过sklearnSelectKBest最终选出最优特征如下：<br>
Feature      Score<br>
26         eda_max  57.209430<br>
25         eda_std  56.201907<br>
24        eda_mean  39.570719<br>
44       sugar_sum  33.367093<br>
0       acc_x_mean  29.387410<br>
3        acc_x_min  29.065137<br>
43  total_carb_sum  28.688958<br>
12      acc_z_mean  27.616566<br><br>
要求：<br>
（1）请简要分析一下字段缺失值的分布情况，你分别对哪些字段进行了哪些处理？有没有异常？文字介绍具体方法，并展示前后变化。<br>
（2）请简要分析连续型特征中异常值的分布情况，结合当前任务，在项目中你分别进行了怎样的处理？<br>
（3）请简要分析哪些特征之间是相关的？结合当前任务，在项目中你分别进行了怎样的处理？<br>
（4）文字内容不限于上述三点，可以根据自己的理解阐述更多内容。
<br><br><img alt="image.png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\image.png"><img alt="image-2.png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\image-2.png"><br>由图可知，一分钟数据缺失较多，使用五分钟间隔后缺失值明显减少，只对前后有数据的缺失值进行线性插值，其他则删除。<br><br>由于本数据集为真实数据，噪声较大，且数据波动较大，异常值判断较为困难。所以对异常值采取保守态度，没有专门对异常值进行特殊处理。<br><br><img alt="image.png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\image.png"><br>由相关性热力图可以看出，不同特征间除ibi与temp并无明显相关性，大部分构造的特征之间具有强相关。<br><br><br>
要求：文字描述该过程，包括数据划分、模型构建、参数调优、评价指标统计、模型比较，可视化展示结果并进行分析。
<br><br>对于数据划分，选取两个用户为测试集，其他为训练集。由于最后两个用户数据缺失较多，这里选用9,11号用户作为测试集<br><br>模型选用了逻辑回归，SVM,随机森林,效果不好。增加GBDT,XGBoost模型<br><br>对不同模型进行网格搜索调参，参数范围如下：<br>classifiers = {
    'Logistic Regression': {
        'model': LogisticRegression(),
        'params': {'C': [0.001, 0.01], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}
    },
    'Support Vector Machine': {
        'model': SVC(),
        'params': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
    },
    'Random Forest': {
        'model': RandomForestClassifier(),
        'params': {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5]}
    }
    'Gradient Boosting': {
        'model': GradientBoostingClassifier(),
        'params': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
    },
    'XGBoost': {
        'model': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
        'params': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
    }
}

<br><br><img alt="image.png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\image.png"><br>
<img alt="image-2.png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\image-2.png"><br>
<img alt="image-3.png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\image-3.png"><br>
<img alt="image-6.png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\image-6.png"><br>
<img alt="image-5.png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\image-5.png"><br><br>
要求：文字描述该过程，包括数据划分、模型构建、参数调优，可视化展示结果并进行分析。
<br><br>
<br>设定时间窗口：代码设定了每小时的时间窗口来聚合数据，通过回归模型预测每个小时的高糖次数。
<br>处理重复的时间戳：去除了DataFrame中重复的时间戳记录，保留第一次出现的记录。
<br>聚合非营养数据：计算了加速度、血容脉搏、电皮活动、温度、心率、瞬时心率间隔等非营养数据的平均值和方差。
<br>累积营养数据：对卡路里、总碳水化合物、糖分、蛋白质进行了累积求和。
<br>计算高血糖条件计数：计算了每小时内血糖值大于等于140 mg/dL的次数。
<br>添加时间相关特征：增加了表示小时的列。
<br>计算增量：计算了每个小时相对于前一个小时的变化量。
<br>处理缺失值：使用前向填充方法处理了开头的缺失值。
<br>划分测试集训练集，将9，11划为测试集，其他为训练集
<br>过采样训练集
<br><br>
<br>模型初始化：定义了四种回归模型——线性回归、支持向量回归（SVR）、随机森林回归和梯度提升回归。
<br>参数调优：对于需要调优的模型（如SVR、随机森林回归和梯度提升回归），使用了GridSearchCV进行参数调优。通过网格搜索确定了最佳参数组合。
<br>模型训练：使用训练集对每个模型进行训练。对于不需要调优的模型（如线性回归），直接进行训练；对于需要调优的模型，则使用网格搜索找到的最佳参数进行训练。
<br><br>
<br>模型评估：对于每个模型，在测试集上进行预测，并计算均方误差（MSE）和决定系数（R²）作为评估指标。
<br>可视化结果：使用Matplotlib绘制条形图，比较不同模型的MSE和R²得分。
<br>Linear Regression: Mean Squared Error=8.2344, R^2 Score=0.0464<br>Support Vector Regression: Mean Squared Error=9.4818, R^2 Score=-0.0981<br>Random Forest Regression: Mean Squared Error=7.0494, R^2 Score=0.1836<br>Gradient Boosting Regression: Mean Squared Error=7.4915, R^2 Score=0.1324<br><img alt="image.png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\image.png"><br>整体来说随机森林模型均方误差更小，但所有模型的R²都很小<br><br>
要求：文字描述该过程，包括高糖次数预测误差与结果分析。
<br><br><br>
要求：请从项目目的、项目流程、数据处理方法、高糖预测模型构建方法、效果分析和初步结论等方面对本项目进行总结。<br>
项目目的：解决了什么样的实际问题？<br>
项目流程：项目的总体执行流程是怎样的？<br>
数据处理方法：对项目数据进行了怎样的处理？<br>
高糖预测模型构建方法：使用了哪些方法构建高糖预测模型？<br>
效果分析：使用哪些方法对高糖预测模型的效果进行了分析与评估？<br>
初步结论：通过本项目，得到了哪些初步的结论？
<br><br>本项目的目的是开发一个能够有效预测个体血糖水平升高（高糖状态）的模型。<br><br>
<br>需求分析：确定项目目标，明确需要解决的实际问题。
<br>数据预处理：清洗数据，处理缺失值、异常值，统一数据格式，选择合适的时间标签（如time_label列）进行时间序列分析。
<br>特征工程：根据领域知识选取或构造有助于预测的特征,通过selectbestfeature选取最好的几个特征。
<br>模型训练：选择合适的机器学习算法训练模型，如线性回归、随机森林、支持向量机等。
<br>模型验证与优化：通过交叉验证等技术评估模型性能，并通过网格搜索进行调参优化。
<br><br>
<br>数据清洗：去除重复项、处理缺失值，确保数据质量。
<br>特征选择：基于相关性分析和血糖相关因素资料，选择与血糖水平变化最相关的特征。
<br>时间序列处理：利用time_label列进行时间序列分析，考虑时间上的连续性和周期性影响。
<br><br>
<br>算法选择：可能采用线性回归、随机森林、支持向量机、神经网络等算法。
<br>模型训练：使用训练集数据训练模型，确保模型能够泛化到未见过的数据。
<br>超参数调优：使用网格搜索或随机搜索等方法寻找最佳模型参数。
<br><br>
<br>性能指标：使用准确率、精确度、召回率、F1分数等指标评估模型性能。
<br>误差分析：分析模型预测错误的情况，找出原因。
<br>对比实验：与基准模型或其它模型进行比较，验证模型的有效性。
<br><br>
<br>模型有效性：通过上述方法训练出的模型在测试集上表现良好，能够在一定程度上预测高糖状态。
<br>未来工作方向：为进一步提升预测准确性，可以考虑增加更多影响因素的数据，或尝试更复杂的模型结构。
<br><br>
要求：在该项目实施过程中，遇到了哪些问题？你是如何解决这些问题的？经过本次课程设计，你的最大收获是什么？经过本次课程设计，你有哪些体会？
<br><br><br>采样的间隔设置多少合适？<br><br>缺失的数据如何补全，应桉什么规则补全？<br><br>特征工程是最大的问题，俗话说数据和特征决定了模型的上限，算法只是在逼近这个上限。但由于特征与标签的关系并不明显，没有明显的相关性，所以训练效果很差。且每个样本用户的生活习惯各不相同，如果不是针对每一个用户训练模型，而是针对所有数据做一个泛化的预测模型，则时间序列在这里的意义被拉小了。因为有的用户是在夜晚出现高糖，而有的用户是饭后出现高糖，更有多数用户并未出现高糖。<br><br>高糖出现的数据远少于正常的数据，这会导致训练时出现偏执。<br><br>
<br>关于采样，最终我选择了1min间隔和5min间隔两版，但后期发现1min数据运行时间太长，转而用5min
<br>关于缺失数据处理，对于大部分时间序列数据，我根据时间进行线性插值。少数统计次数，如统计一小时内的高糖次数，则补0
<br>关于特征工程，这里我没有找到一个合适的解决方法。模型的表现不佳也多与此有关。我查阅数据挖掘的书，其中针对时间序列数据，均值反应一段时间内的总体情况，方差反应一段时间内的波动情况，增值反应一段时间内的上升下降趋势，对于文本离散数据可以进行哑编码，但由于我都是时间序列数据，有一定的时间顺序，不需要进行哑编码。但以上的构造特征作用都十分有限。于是我转而使用新的数据food_log，这组数据包含了摄入的糖分，卡路里等信息，特征与目标变量的相关性比可穿戴设备采集的所有信息都要强。
<br>关于类别不平衡，我们通过smote过采样到正负样本数量一致。
<br><br>
要求：任务说明+代码及关键代码注释+可视化与运行结果
<br>!pip install imblearn
<br>Defaulting to user installation because normal site-packages is not writeable
Requirement already satisfied: imblearn in c:\users\aimer\appdata\roaming\python\python312\site-packages (0.0)
Requirement already satisfied: imbalanced-learn in g:\anaconda\lib\site-packages (from imblearn) (0.12.3)
Requirement already satisfied: numpy&gt;=1.17.3 in g:\anaconda\lib\site-packages (from imbalanced-learn-&gt;imblearn) (1.26.4)
Requirement already satisfied: scipy&gt;=1.5.0 in g:\anaconda\lib\site-packages (from imbalanced-learn-&gt;imblearn) (1.13.1)
Requirement already satisfied: scikit-learn&gt;=1.0.2 in g:\anaconda\lib\site-packages (from imbalanced-learn-&gt;imblearn) (1.4.2)
Requirement already satisfied: joblib&gt;=1.1.1 in g:\anaconda\lib\site-packages (from imbalanced-learn-&gt;imblearn) (1.4.2)
Requirement already satisfied: threadpoolctl&gt;=2.0.0 in g:\anaconda\lib\site-packages (from imbalanced-learn-&gt;imblearn) (2.2.0)
<br>### 任务点1.1 数据采样与整合
<br># 根据Dexcom五分钟间隔采样，
import pandas as pd

# 定义文件编号列表
file_nums = [f'{i:03d}' for i in range(2, 17)]  # 生成从 '002' 到 '016' 的文件编号

for file_num in file_nums:
    # 读取各个CSV文件
    Dexcom = pd.read_csv(f'data/{file_num}/Dexcom_{file_num}.csv', skiprows=13, header=None)
    Dexcom = Dexcom[[1, 7]]
    Dexcom.columns = ['datetime', 'Glucose Value (mg/dL)']
    Dexcom['datetime'] = pd.to_datetime(Dexcom['datetime'])

    ACC = pd.read_csv(f'data/{file_num}/ACC_{file_num}.csv')
    ACC['datetime'] = pd.to_datetime(ACC['datetime'])

    BVP = pd.read_csv(f'data/{file_num}/BVP_{file_num}.csv')
    BVP['datetime'] = pd.to_datetime(BVP['datetime'])

    EDA = pd.read_csv(f'data/{file_num}/EDA_{file_num}.csv')
    EDA['datetime'] = pd.to_datetime(EDA['datetime'])

    IBI = pd.read_csv(f'data/{file_num}/IBI_{file_num}.csv')
    IBI['datetime'] = pd.to_datetime(IBI['datetime'])

    TEMP = pd.read_csv(f'data/{file_num}/TEMP_{file_num}.csv')
    TEMP['datetime'] = pd.to_datetime(TEMP['datetime'])
    
    HR = pd.read_csv(f'data/{file_num}/HR_{file_num}.csv')
    HR['datetime'] = pd.to_datetime(HR['datetime'])
    
    IBI = IBI.sort_values(by='datetime')
    # 合并数据框
    merged_data = Dexcom.merge(ACC, on='datetime', how='inner')
    merged_data = merged_data.merge(BVP, on='datetime', how='inner')
    merged_data = merged_data.merge(EDA, on='datetime', how='inner')
    merged_data = merged_data.merge(TEMP, on='datetime', how='inner')
    merged_data = merged_data.merge(HR, on='datetime', how='inner')
    merged_data = pd.merge_asof(
        left=merged_data,
        right=IBI,
        on='datetime',
        by=None,
        tolerance=pd.Timedelta('60s'),
        direction='nearest'
    )

    # 处理缺失值
    for column in merged_data.columns:
        if merged_data[column].isna().any():
            mean_value = merged_data[column].mean()
            merged_data[column] = merged_data[column].fillna(mean_value)

    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/processed_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Processed and saved data for file number {file_num}')


<br>Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
<br><br># 请在下方完成任务
# 缺失值补为平均值

# 定义文件编号列表
file_nums = [f'{i:03d}' for i in range(2, 17)]  # 生成从 '001' 到 '016' 的文件编号

for file_num in file_nums:
    # 处理缺失值
    merged_data=pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    for column in merged_data.columns:
        if merged_data[column].isna().any():
            mean_value = merged_data[column].mean()
            merged_data[column] = merged_data[column].fillna(mean_value)

    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/processed_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Processed and saved data for file number {file_num}')

<br>Processed and saved data for file number 002
Processed and saved data for file number 003
Processed and saved data for file number 004
Processed and saved data for file number 005
Processed and saved data for file number 006
Processed and saved data for file number 007
Processed and saved data for file number 008
Processed and saved data for file number 009
Processed and saved data for file number 010
Processed and saved data for file number 011
Processed and saved data for file number 012
Processed and saved data for file number 013
Processed and saved data for file number 014
Processed and saved data for file number 015
Processed and saved data for file number 016
<br><br>由于数据的不同特征属性值的差异较大，并不利于模型的选择和使用，所以要对数据完成归一化操作。<br># 请在下方完成任务，并保存处理的样本矩阵到本地
file_nums = [f'{i:03d}' for i in range(2, 17)]  # 生成从 '002' 到 '016' 的文件编号

for file_num in file_nums:
    # 读取 CSV 文件
    merged_data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    
    # 对每一列进行归一化处理
    for column in merged_data.columns[2:]:  # 从第三列开始
        if merged_data[column].dtype in ['float64', 'int64']:  # 只对数值类型的数据列进行归一化
            column_max = merged_data[column].max()
            column_min = merged_data[column].min()
            if column_max != column_min:  # 避免除以0的情况
                merged_data[column] = (merged_data[column] - column_min) / (column_max - column_min)
    
    # 保存每个文件处理后的数据到单独的CSV文件
    output_file_path = f'processed_data/processed_data_{file_num}.csv'
    merged_data.to_csv(output_file_path, index=False)
    print(f'Normalized and saved data for file number {file_num}')
<br>Normalized and saved data for file number 002
Normalized and saved data for file number 003
Normalized and saved data for file number 004
Normalized and saved data for file number 005
Normalized and saved data for file number 006
Normalized and saved data for file number 007
Normalized and saved data for file number 008
Normalized and saved data for file number 009
Normalized and saved data for file number 010
Normalized and saved data for file number 011
Normalized and saved data for file number 012
Normalized and saved data for file number 013
Normalized and saved data for file number 014
Normalized and saved data for file number 015
Normalized and saved data for file number 016
<br><br>不同用户每天的血糖值不断变化。通过可视化来观测不同用户一天血糖值的变化规律、高糖出现的时间、频率等。<br>import pandas as pd
import matplotlib.pyplot as plt
import os

# 定义高糖阈值
gaotang = 140

# 获取所有文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 对每个文件编号进行处理
for file_num in file_nums:
    # 获取该用户的所有文件
    user_files = [f for f in os.listdir('processed_data') if f.startswith(f'processed_data_{file_num}') and f.endswith('.csv')]
    
    # 存储所有日期
    all_dates = []
    
    # 遍历这些文件
    for target_file in user_files:
        # 读取 CSV 文件
        data = pd.read_csv(os.path.join('processed_data', target_file))
        
        # 将第一列转换为 datetime 类型
        data['datetime'] = pd.to_datetime(data['datetime'])
        
        # 添加日期到列表
        all_dates.extend(data['datetime'].dt.date.unique())
    
    # 去除重复日期并排序
    all_dates = sorted(set(all_dates))
    
    # 取第二天、第三天、第四天的日期
    target_dates = all_dates[1:4]
    
    # 创建一个新的 figure 用于绘制所有目标日期的数据
    plt.figure(figsize=(14, 8))

    # 再次遍历这些文件并绘制图表
    for target_file in user_files:
        # 读取 CSV 文件
        data = pd.read_csv(os.path.join('processed_data', target_file))
        
        # 将第一列转换为 datetime 类型
        data['datetime'] = pd.to_datetime(data['datetime'])
        
        # 遍历目标日期并绘制图形
        for target_date in target_dates:
            # 过滤出目标日期的数据
            day_data = data[data['datetime'].dt.date == target_date]
            
            # 如果该天没有数据，则跳过
            if day_data.empty:
                continue
            
            # 绘制折线图
            plt.plot(day_data['datetime'], day_data.iloc[:, 1], label=target_date.strftime('%Y-%m-%d'))

            # 标出高糖值
            high_sugar_points = day_data[day_data.iloc[:, 1] &gt;= gaotang]
            plt.scatter(high_sugar_points['datetime'], high_sugar_points.iloc[:, 1], color='red')

    plt.title(f'Trend of Data with High Sugar Points Marked (File {file_num})')
    plt.xlabel('Time')
    plt.ylabel('Value')
    plt.legend(title='Date')
    plt.grid(True)

    # 显示图形
    plt.show()
<br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_0.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_1.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_2.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_3.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_4.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_5.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_6.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_7.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_8.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_9.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_10.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_11.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_12.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_13.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_47_14.png"><br><br>为了预测每人在一天内的不同阶段是否会发生高糖，根据任务点1.4的观测结果，完成时间属性的离散化（阶段化）任务。例如，将一天划分为不同的阶段，分阶段预测是否发生高糖。具体的分段方法可自行决定，例如5分钟、1个小时、半天、上中下晚夜等。<br>
并根据分段结果，构造每个的阶段的目标值（是否高糖），形成一列数据。<br># 增加一列time_label_num和hour_label，将时间段分标签，并将时间段标签映射到数字
import pandas as pd

# 生成从 '002' 到 '016' 的文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 定义时间段和对应的标签
time_segments = [
    ('00:00:00', '03:59:59', '深夜'),
    ('04:00:00', '05:59:59', '凌晨'),
    ('06:00:00', '10:59:59', '上午'),
    ('11:00:00', '12:59:59', '中午'),
    ('13:00:00', '16:59:59', '下午'),
    ('17:00:00', '18:59:59', '傍晚'),
    ('19:00:00', '23:59:59', '晚上'),
]

# 创建一个映射字典，将时间段标签映射到数字
time_segment_mapping = {label: idx for idx, (_, _, label) in enumerate(time_segments)}

# 定义函数来分配时间段标签
def assign_time_segment(row, segments=time_segments):
    row_time = row['datetime'].time()
    for start, end, label in segments:
        if pd.to_datetime(start, format='%H:%M:%S').time() &lt;= row_time &lt;= pd.to_datetime(end, format='%H:%M:%S').time():
            return label
    return None

# 定义函数来转换标签为数字
def convert_label_to_number(row, mapping=time_segment_mapping):
    return mapping.get(row['time_label'], -1)

# 对每个文件应用时间标签
for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    
    # 将第一列转换为 datetime 类型
    data['datetime'] = pd.to_datetime(data['datetime'])
    
    # 应用函数并创建新列 'time_label'
    data['time_label'] = data.apply(assign_time_segment, axis=1)
    
    # 转换时间标签为数字编码
    data['time_label_num'] = data.apply(convert_label_to_number, axis=1)
    
    # 从 'datetime' 列中提取小时部分，并创建 'hour_label' 列
    data['hour_label'] = data['datetime'].dt.hour
    
    # 删除临时 'time_label' 列
    data.drop('time_label', axis=1, inplace=True)
    
    # 保存修改后的数据
    data.to_csv(f'processed_data/processed_data_{file_num}.csv', index=False)

    print(f'file{file_num} labeled with hour_label')
<br>file002 labeled with hour_label
file003 labeled with hour_label
file004 labeled with hour_label
file005 labeled with hour_label
file006 labeled with hour_label
file007 labeled with hour_label
file008 labeled with hour_label
file009 labeled with hour_label
file010 labeled with hour_label
file011 labeled with hour_label
file012 labeled with hour_label
file013 labeled with hour_label
file014 labeled with hour_label
file015 labeled with hour_label



---------------------------------------------------------------------------

PermissionError                           Traceback (most recent call last)

Cell In[23], line 54
     51 data.drop('time_label', axis=1, inplace=True)
     53 # 保存修改后的数据
---&gt; 54 data.to_csv(f'processed_data/processed_data_{file_num}.csv', index=False)
     56 print(f'file{file_num} labeled with hour_label')


File g:\Anaconda\Lib\site-packages\pandas\util\_decorators.py:333, in deprecate_nonkeyword_arguments.&lt;locals&gt;.decorate.&lt;locals&gt;.wrapper(*args, **kwargs)
    327 if len(args) &gt; num_allow_args:
    328     warnings.warn(
    329         msg.format(arguments=_format_argument_list(allow_args)),
    330         FutureWarning,
    331         stacklevel=find_stack_level(),
    332     )
--&gt; 333 return func(*args, **kwargs)


File g:\Anaconda\Lib\site-packages\pandas\core\generic.py:3967, in NDFrame.to_csv(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)
   3956 df = self if isinstance(self, ABCDataFrame) else self.to_frame()
   3958 formatter = DataFrameFormatter(
   3959     frame=df,
   3960     header=header,
   (...)
   3964     decimal=decimal,
   3965 )
-&gt; 3967 return DataFrameRenderer(formatter).to_csv(
   3968     path_or_buf,
   3969     lineterminator=lineterminator,
   3970     sep=sep,
   3971     encoding=encoding,
   3972     errors=errors,
   3973     compression=compression,
   3974     quoting=quoting,
   3975     columns=columns,
   3976     index_label=index_label,
   3977     mode=mode,
   3978     chunksize=chunksize,
   3979     quotechar=quotechar,
   3980     date_format=date_format,
   3981     doublequote=doublequote,
   3982     escapechar=escapechar,
   3983     storage_options=storage_options,
   3984 )


File g:\Anaconda\Lib\site-packages\pandas\io\formats\format.py:1014, in DataFrameRenderer.to_csv(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)
    993     created_buffer = False
    995 csv_formatter = CSVFormatter(
    996     path_or_buf=path_or_buf,
    997     lineterminator=lineterminator,
   (...)
   1012     formatter=self.fmt,
   1013 )
-&gt; 1014 csv_formatter.save()
   1016 if created_buffer:
   1017     assert isinstance(path_or_buf, StringIO)


File g:\Anaconda\Lib\site-packages\pandas\io\formats\csvs.py:251, in CSVFormatter.save(self)
    247 """
    248 Create the writer &amp; save.
    249 """
    250 # apply compression and byte/text conversion
--&gt; 251 with get_handle(
    252     self.filepath_or_buffer,
    253     self.mode,
    254     encoding=self.encoding,
    255     errors=self.errors,
    256     compression=self.compression,
    257     storage_options=self.storage_options,
    258 ) as handles:
    259     # Note: self.encoding is irrelevant here
    260     self.writer = csvlib.writer(
    261         handles.handle,
    262         lineterminator=self.lineterminator,
   (...)
    267         quotechar=self.quotechar,
    268     )
    270     self._save()


File g:\Anaconda\Lib\site-packages\pandas\io\common.py:873, in get_handle(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)
    868 elif isinstance(handle, str):
    869     # Check whether the filename is to be opened in binary mode.
    870     # Binary mode does not support 'encoding' and 'newline'.
    871     if ioargs.encoding and "b" not in ioargs.mode:
    872         # Encoding
--&gt; 873         handle = open(
    874             handle,
    875             ioargs.mode,
    876             encoding=ioargs.encoding,
    877             errors=errors,
    878             newline="",
    879         )
    880     else:
    881         # Binary mode
    882         handle = open(handle, ioargs.mode)


PermissionError: [Errno 13] Permission denied: 'processed_data/processed_data_016.csv'
<br># 增加food_log.csv
import pandas as pd
from datetime import timedelta

# 生成从 '002' 到 '016' 的文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 定义一个函数来查找最近的时间点
def find_nearest_time(row, df, time_col='datetime', minutes=5):
    # 获取当前行的时间点
    current_time = row[time_col]
    # 计算时间窗口
    start_time = current_time - pd.Timedelta(minutes=minutes, unit='m')
    end_time = current_time + pd.Timedelta(minutes=minutes, unit='m')
    
    # 在 df 中查找落在时间窗口内的记录
    # 确保 start_time 和 end_time 与 df[time_col] 同a类型
    filtered_df = df.loc[(df[time_col] &gt;= start_time) &amp; (df[time_col] &lt;= end_time)]
    if not filtered_df.empty:
        return filtered_df.iloc[0].name
    else:
        return None


for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    # print(data.head())
    # 将 datetime 列转换为 datetime 对象
    data['datetime'] = pd.to_datetime(data['datetime'])
    data.columns = data.columns.str.strip()  
    # 去遍历food_log.csv 每个时间去找到离它五分钟内的时间，将calorie，total_carb，sugar,protein加到后面去，形成新的特征列
    food_log = pd.read_csv(f'food_log/Food_Log_{file_num}.csv')
    food_log.columns = food_log.columns.str.strip()
    # 我们将它们合并成一个 datetime 对象
    # print(f'{file_num}')
    food_log['datetime'] = pd.to_datetime(food_log['date'] + ' ' + food_log['time'])
     # 将 datetime 列转换为 datetime 对象
    food_log['datetime'] = pd.to_datetime(food_log['datetime'])
    # 应用函数，并创建一个新的索引列以追踪最近的时间点
    food_log['nearest_index'] = food_log.apply(find_nearest_time, axis=1, args=(data,))

    # 基于找到的索引，将营养信息添加到 data DataFrame 中
    data_with_nutrition = data.copy()
    data_with_nutrition['calorie'] = None
    data_with_nutrition['total_carb'] = None
    data_with_nutrition['sugar'] = None
    data_with_nutrition['protein'] = None

    # 遍历 food_log 中的每一行
    for index, row in food_log.iterrows():
        nearest_index = row['nearest_index']
        if nearest_index is not None:
            # 更新 data_with_nutrition 中的相应行
            data_with_nutrition.at[nearest_index, 'calorie'] = row['calorie']
            data_with_nutrition.at[nearest_index, 'total_carb'] = row['total_carb']
            data_with_nutrition.at[nearest_index, 'sugar'] = row['sugar']
            data_with_nutrition.at[nearest_index, 'protein'] = row['protein']

    # 将未匹配到的营养信息列填充为0.0（浮点数）
    data_with_nutrition[['calorie', 'total_carb', 'sugar', 'protein']] = data_with_nutrition[['calorie', 'total_carb', 'sugar', 'protein']].astype(float).fillna(0.0)

    # 保存处理后的数据
    data_with_nutrition.to_csv(f'processed_data/processed_data_{file_num}.csv', index=False)

    print(f'processed_data_{file_num}.csv saved')

<br>processed_data_002.csv saved
processed_data_003.csv saved
processed_data_004.csv saved
processed_data_005.csv saved
processed_data_006.csv saved
processed_data_007.csv saved
processed_data_008.csv saved
processed_data_009.csv saved
processed_data_010.csv saved
processed_data_011.csv saved
processed_data_012.csv saved
processed_data_013.csv saved
processed_data_014.csv saved
processed_data_015.csv saved
processed_data_016.csv saved
<br>最终得到处理过后的数据全部在processed_data中，格式如下：<br>
datetime,Glucose Value (mg/dL), acc_x, acc_y, acc_z, bvp, eda, temp, ibi,time_label_num,hour_label<br>
2020-02-21 11:08:36,186.0,0.3530385433908725,0.5987683562292753,0.9682968788400098,0.5670097914309226,0.0142822433851519,0.8179871520342614,0.2837837487233018,3,11<br><br>对于一个属性特征（例如BVP），每个阶段的特征都是一条时间序列，通过可视化分析不同特征的变化规律，并选择合适的特征提取方法提前特征，反映其特点。例如提取时序特征的统计量，如最大值（max）、最小值（min）、均值（mean）、方差（variance）等，或者对时序特征进行建模。<br>import pandas as pd
import matplotlib.pyplot as plt

# 定义高糖阈值
gaotang = 140

# 指定要绘制的文件编号
file_num = '002'

# 指定要绘制的一天
target_date = '2020-02-22'

# 读取 CSV 文件
data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')

# 将第一列转换为 datetime 类型
data['datetime'] = pd.to_datetime(data.iloc[:, 0], errors='coerce')

# 过滤出目标日期的数据
day_data = data[data['datetime'].dt.date == pd.to_datetime(target_date).date()]

# 获取第二列（假设是数值类型）
second_column = day_data.columns[1]

# 检查第二列是否为数值类型
if not pd.api.types.is_numeric_dtype(day_data[second_column]):
    raise ValueError(f"The second column '{second_column}' is not numeric.")

# 对每一列进行归一化处理
for column in day_data.select_dtypes(include=['number']).columns:
    min_val = day_data[column].min()
    max_val = day_data[column].max()
    if max_val != min_val:  # 避免除以0的情况
        day_data[column] = (day_data[column] - min_val) / (max_val - min_val)
    else:
        # 如果最大值等于最小值，意味着该列所有的值都是相同的，可以设置为0或1
        day_data[column] = 0  # 或者选择其他合适的值

# 获取所有非时间列
feature_columns = day_data.columns[1:8]

# 对于每一个特征列创建一个新的图形
for i, col in enumerate(feature_columns):
    if col != second_column and pd.api.types.is_numeric_dtype(day_data[col]):
        plt.figure(figsize=(10, 6))
        plt.plot(day_data['datetime'], day_data[second_column], label=second_column)
        plt.plot(day_data['datetime'], day_data[col], label=col)
        
        plt.title(f'Trend Comparison Between {second_column} and {col} on {target_date} (File {file_num})')
        plt.xlabel('Time')
        plt.ylabel('Normalized Value')
        plt.legend()
        plt.grid(True)
        
        # 显示图形
        plt.show()
<br>C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3031747850.py:34: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  day_data[column] = (day_data[column] - min_val) / (max_val - min_val)
<br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_53_1.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_53_2.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_53_3.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_53_4.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_53_5.png"><br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_53_6.png"><br>我们抽样002样本的其中一天，其各个特征与血糖值的时序图。试图找出不同特征的时序特征与血糖的时序特征的关系<br>
<br>关于acc，其有明显的白天高，夜晚低的趋势。且波动较大。这是由于白天活动较多，晚上活动较少。思路：可以检测运动，如果是有氧运动则血糖应该有下降趋势，如果是无氧运动应该血糖会有上升趋势
<br>关于bvp，由图，bvp即血容量在一天中十分稳定，只有在部分时间出现了剧烈波动，与其对应的是血糖最低点。猜测bvp的波动与血糖过低有关，或者仅仅只是异常值，可以通过其他数据验证。
<br>关于eda，eda为皮肤电刺激信号，通常与人的压力水平有关。而压力高导致的皮质醇浓度升高会导致血糖升高。由图中可以看出，其与血糖有一定的同峰情况，可以检测eda的高低来辅助推断血糖高低。
<br>关于temp,对于002样本，在早上和入睡时降低明显。但可能是个人体质不一，需要验证。
<br>关于hr和ibi,整体呈负相关，hr在白天高，晚上较低，ibi则相反。
<br>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.signal import welch

# 定义高糖阈值
gaotang = 140

# 生成从 '002' 到 '016' 的文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 窗口大小设置为1小时
window_size = 12  # 1小时，12个数据点

# 步长设置为5分钟
step = 1  # 5分钟，1个数据点

# 需要统计的列名列表
columns_of_interest = ['acc_x', 'acc_y', 'acc_z', 'bvp', 'eda', 'temp', 'ibi','hr']

# 需要累加的列名列表
cumulative_columns = ['calorie', 'total_carb', 'sugar', 'protein']

# 假设采样率为1个数据点/分钟
sampling_rate = 1  # 单位为数据点/分钟

for file_num in file_nums:
    # 读取 CSV 文件
    data = pd.read_csv(f'processed_data/processed_data_{file_num}.csv')
    
    # 立即统一列名格式
    data.columns = data.columns.str.strip().str.replace(' ', '_')
    
    # 将第一列转换为 datetime 类型
    data['datetime'] = pd.to_datetime(data.iloc[:, 0])
    
    # 如果整个文件的数据不足一个窗口大小，则跳过该文件
    if len(data) &lt; window_size:
        print(f"File {file_num}: Insufficient data for sliding window.")
        continue
    
    # 初始化特征列表
    features = []
    
    # 滑动窗口统计特征
    for i in range(0, len(data) - window_size + 1, step):
        window = data.iloc[i:i + window_size]
        
        # 统一窗口内的列名格式
        window.columns = window.columns.str.strip().str.replace(' ', '_')
        
        # 计算血糖值 &gt;= 140 的频数
        glucose_freq = (window['Glucose_Value_(mg/dL)'] &gt;= gaotang).sum()
        
        # 计算其他列的统计量
        stats = {}
        for col in columns_of_interest:
            stats[col] = {
                'mean': window[col].mean(),
                'std': window[col].std(),
                'max': window[col].max(),
                'min': window[col].min(),
                'delta': window[col].iloc[-1] - window[col].iloc[0]
            }
            
            # 计算频谱特征
            freqs, psd = welch(window[col], fs=sampling_rate, nperseg=len(window)//2)
            stats[col]['peak_freq'] = freqs[psd &gt; np.percentile(psd, 90)].tolist()  # 找到前10%的峰值频率
        
        # 计算累积列的和
        cumulative_sum = {}
        for col in cumulative_columns:
            cumulative_sum[col] = window[col].sum()
        
        # 添加滑动窗口结束位置的时间戳
        end_time = window['datetime'].iloc[-1]
        
        # 展开嵌套字典
        flattened_stats = {'glucose_freq': glucose_freq, 'end_time': end_time}
        for col in columns_of_interest:
            for key in stats[col]:
                flattened_stats[f"{col}_{key}"] = stats[col][key]
        
        # 添加累积列的和
        for col in cumulative_columns:
            flattened_stats[f"{col}_sum"] = cumulative_sum[col]
        
        features.append(flattened_stats)
    
    # 转换为DataFrame
    window_features = pd.DataFrame(features)
    
    # 保存到文件
    window_features.to_csv(f'window_data/sliding_window_features_{file_num}.csv', index=False)

    print(f"File {file_num}: Sliding window feature extraction completed with end timestamps and cumulative sums.")
<br>File 002: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 003: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 004: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 005: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 006: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 007: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 008: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 009: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 010: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 011: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 012: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 013: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 014: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 015: Sliding window feature extraction completed with end timestamps and cumulative sums.
File 016: Sliding window feature extraction completed with end timestamps and cumulative sums.
<br><br>通过观察不同特征的分布特点，统计特征之间的相关性系数，再进行可视化展示。<br>
可以通过python中的matplotlib工具包和seaborn工具实现可视化。<br>import pandas as pd

# 生成从 '002' 到 '016' 的文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 定义一个函数来清理包含方括号的字符串
def remove_brackets(value):
    if isinstance(value, str):
        return value.replace('[', '').replace(']', '')
    return value

for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'window_data/sliding_window_features_{file_num}.csv')
    
    # 应用 remove_brackets 函数处理 DataFrame 中的每个元素
    data = data.applymap(remove_brackets)
    
    # 保存修改后的数据回到原文件
    data.to_csv(f'window_data/sliding_window_features_{file_num}.csv', index=False)
<br>C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\3090928809.py:17: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.
  data = data.applymap(remove_brackets)
<br>import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt

# 生成从 '002' 到 '016' 的文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 初始化一个空的 DataFrame 用于存储所有文件的数据
all_data = pd.DataFrame()

for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'window_data/sliding_window_features_{file_num}.csv')
    
    # 选择除了第二列（假设是 'end_time'）之外的所有列
    # 假设第二列是 'end_time'
    selected_columns = [col for col in data.columns if col != 'end_time']
    data_selected = data[selected_columns]
    
    # 将当前文件的数据追加到 all_data 中
    all_data = pd.concat([all_data, data_selected])

# 计算相关系数矩阵
correlation_matrix = all_data.corr()

# 绘制热力图
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=False, fmt=".2f", cmap='coolwarm', square=True)
plt.title('Correlation Matrix Heatmap')
plt.show()
<br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_58_0.png"><br><br>根据任务2.2对特征相关性与判别性的分析，汇总对目标任务有用的特征进行建模；将所有有用属性提取的特征拼接在一起，形成一个完整的样本矩阵，每一行表示一个阶段的观测数据（样本），每一列表示提取的一个特征值。<br>
另外，针对某个时间段的高糖预测，可多采集前一个小时的观测数据，和当前时间段的数据一起作为样本的时序特征，以预测对发生高糖的可能性。<br>import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.feature_selection import SelectKBest, f_classif

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 初始化一个空的DataFrame用于存储所有数据
data_all = pd.DataFrame()

for file_num in file_nums:
    # 加载数据
    data = pd.read_csv(f'window_data/sliding_window_features_{file_num}.csv')
    data.columns = data.columns.str.strip()  
    # 将数据追加到data_all
    data_all = pd.concat([data_all, data], ignore_index=True)

# 选择目标变量
# data_all['glucose_freq'] = np.where(data_all['glucose_freq'] &gt; 0, 1, 0)
data_all = data_all.dropna()
target = data_all['glucose_freq']

# 选择特征，移除目标变量和无关特征
features = data_all.drop(columns=['end_time', 'glucose_freq'])

# 标准化特征
scaler = StandardScaler()
features_scaled = scaler.fit_transform(features)

# 使用 SelectKBest 挑选最好的特征
selector = SelectKBest(score_func=f_classif, k='all')
selector.fit(features_scaled, target)

# 获取特征分数
feature_scores = selector.scores_

# 特征名和对应分数
feature_scores_df = pd.DataFrame({'Feature': features.columns, 'Score': feature_scores})

# 按分数排序并选择前5个最好的特征
best_features = feature_scores_df.sort_values(by='Score', ascending=False)
selected_features = best_features['Feature'].head(6)
print("All Files Combined")
print(best_features.head(6))  # 显示前6个最好的特征



<br>All Files Combined
       Feature      Score
25     eda_std  62.928055
26     eda_max  60.871648
24    eda_mean  44.047621
3    acc_x_min  41.776213
50   sugar_sum  36.973946
12  acc_z_mean  36.168494
<br>import pandas as pd
import os

# 定义最佳特征列表
best_features = ['eda_max', 'eda_std', 'eda_mean', 'sugar_sum', 'acc_x_min', 'acc_z_mean']

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 创建结果文件夹（如果不存在）
result_folder = 'final_data'
os.makedirs(result_folder, exist_ok=True)

# 对每个文件编号进行处理
for file_num in file_nums:
    # 加载数据
    input_path = f'window_data/sliding_window_features_{file_num}.csv'
    if not os.path.exists(input_path):
        print(f"File not found: {input_path}")
        continue
    
    data = pd.read_csv(input_path)
    
    # 选择最佳特征
    # 假设数据中包含以下列： 'datetime', 'glucose_freq', 以及 best_features 列
    selected_data = data[['end_time', 'glucose_freq'] + best_features]
    
    # 保存处理后的数据到结果文件夹
    output_path = os.path.join(result_folder, f'{file_num}.csv')
    selected_data.to_csv(output_path, index=False)
    
    print(f"Processed data has been saved to {output_path}")
<br>Processed data has been saved to final_data\002.csv
Processed data has been saved to final_data\003.csv
Processed data has been saved to final_data\004.csv
Processed data has been saved to final_data\005.csv
Processed data has been saved to final_data\006.csv
Processed data has been saved to final_data\007.csv
Processed data has been saved to final_data\008.csv
Processed data has been saved to final_data\009.csv
Processed data has been saved to final_data\010.csv
Processed data has been saved to final_data\011.csv
Processed data has been saved to final_data\012.csv
Processed data has been saved to final_data\013.csv
Processed data has been saved to final_data\014.csv
Processed data has been saved to final_data\015.csv
Processed data has been saved to final_data\016.csv
<br>import pandas as pd
from sklearn.preprocessing import StandardScaler
import os

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 对每个文件编号进行处理
for file_num in file_nums:
    # 加载数据
    input_path = os.path.join('final_data', f'{file_num}.csv')
    if not os.path.exists(input_path):
        print(f"File not found: {input_path}")
        continue
    
    data = pd.read_csv(input_path)
    
    # 检查是否存在 end_time 列
    if 'end_time' in data.columns:
        # 将 end_time 列转换为 Unix 时间戳
        data['end_time'] = pd.to_datetime(data['end_time'], format='%Y-%m-%d %H:%M:%S').astype('int64') // 10**9
        
        # 如果 end_time 存在，则将其移动到第二列
        cols = data.columns.tolist()
        cols.insert(1, cols.pop(cols.index('end_time')))
        data = data.loc[:, cols]
        data.drop(columns=['end_time'], inplace=True)
        
    # 选择需要标准化的列
    columns_to_standardize = data.columns[1:]  # 从第二列开始
    
    # 初始化 StandardScaler
    scaler = StandardScaler()
    
    # 对需要标准化的列进行标准化处理
    data[columns_to_standardize] = scaler.fit_transform(data[columns_to_standardize])
    
    # 保存处理后的数据到结果文件夹
    result_folder = 'final_data'
    output_path = os.path.join(result_folder, f'{file_num}.csv')
    data.to_csv(output_path, index=False)
    
    print(f"Standardized data has been saved to {output_path}")
<br>Standardized data has been saved to final_data\002.csv
Standardized data has been saved to final_data\003.csv
Standardized data has been saved to final_data\004.csv
Standardized data has been saved to final_data\005.csv
Standardized data has been saved to final_data\006.csv
Standardized data has been saved to final_data\007.csv
Standardized data has been saved to final_data\008.csv
Standardized data has been saved to final_data\009.csv
Standardized data has been saved to final_data\010.csv
Standardized data has been saved to final_data\011.csv
Standardized data has been saved to final_data\012.csv
Standardized data has been saved to final_data\013.csv
Standardized data has been saved to final_data\014.csv
Standardized data has been saved to final_data\015.csv
Standardized data has been saved to final_data\016.csv
<br><br>请完成训练集与测试集划分任务，具体划分要求为同一人的数据不能同时作为训练集和测试集。一共16位用户的数据可以参考4:1或3:2的方式进行划分。<br>
考虑到发生高糖的次数非常少，会造成高糖标记样本远少于低糖标记样本的类别不平衡问题，可通过降采样、过采样SMOTE等方法进行处理。<br>import pandas as pd
from sklearn.model_selection import train_test_split
from imblearn.over_sampling import SMOTE

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 初始化一个空的DataFrame用于存放训练集和测试集数据
train_data = pd.DataFrame()
test_data = pd.DataFrame()

# 对每个文件编号进行处理
for file_num in file_nums:
    # 读取文件
    data = pd.read_csv(f'final_data/{file_num}.csv')
    
    # 将数据追加到相应的DataFrame
    if file_num in ['009', '011']:
        test_data = pd.concat([test_data, data], ignore_index=True)
    else:
        train_data = pd.concat([train_data, data], ignore_index=True)

# 获取第一列的名字
first_column_name = train_data.columns[0]

# 将第一列转换为目标变量二分类，如果&gt;0则标记为1，否则为0
train_data[first_column_name] = (train_data[first_column_name] &gt; 0).astype(int)
test_data[first_column_name] = (test_data[first_column_name] &gt; 0).astype(int)

# 分离特征和目标变量
X_train = train_data.drop(first_column_name, axis=1)
y_train = train_data[first_column_name]

X_test = test_data.drop(first_column_name, axis=1)
y_test = test_data[first_column_name]

# 创建SMOTE实例
sm = SMOTE(sampling_strategy={1: len(y_train[y_train == 0])}, random_state=42)
# 对训练集进行过采样
X_train_res, y_train_res = sm.fit_resample(X_train, y_train)

# 合并过采样后的特征和目标变量
train_resampled = pd.concat([X_train_res, y_train_res], axis=1)

# 查看过采样后的前几行数据
print(train_resampled.head())

# 保存处理后的训练集和测试集
train_resampled.to_csv('train_test_data_binary/train_resampled.csv', index=False)
X_test.to_csv('train_test_data_binary/X_test.csv', index=False)
y_test.to_csv('train_test_data_binary/y_test.csv', index=False)

print("Train and test sets have been processed and saved.")
<br>    eda_max   eda_std  eda_mean  sugar_sum  acc_x_min  acc_z_mean  \
0 -0.544867 -0.485389 -0.514385  -0.450338   0.488968    1.091837   
1 -0.553896 -0.483379 -0.519125   0.900017  -0.218853    0.812283   
2 -0.554717 -0.482878 -0.521699   0.900017  -0.218853    0.547707   
3 -0.554717 -0.480062 -0.524683   0.900017  -0.218853    0.258676   
4 -0.554717 -0.472443 -0.529481   0.900017  -0.218853    0.116224   

   glucose_freq  
0             1  
1             1  
2             1  
3             1  
4             1  
Train and test sets have been processed and saved.
<br><br>import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import (
    classification_report,
    accuracy_score,
    recall_score,
    precision_score,
    f1_score,
    make_scorer
)
from tqdm import tqdm

# 读取训练集和测试集
X_train = pd.read_csv('train_test_data_binary/train_resampled.csv').drop('glucose_freq', axis=1)
y_train = pd.read_csv('train_test_data_binary/train_resampled.csv')['glucose_freq']
X_test = pd.read_csv('train_test_data_binary/X_test.csv')
y_test = pd.read_csv('train_test_data_binary/y_test.csv')['glucose_freq']

# 数据标准化
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 定义分类器和参数网格
classifiers = {
    'Logistic Regression': {
        'model': LogisticRegression(),
        'params': {'C': [0.001, 0.01], 'penalty': ['l1', 'l2'], 'solver': ['liblinear']}
    },
    'Support Vector Machine': {
        'model': SVC(),
        'params': {'C': [0.1, 1, 10], 'kernel': ['linear', 'rbf']}
    },
    'Random Forest': {
        'model': RandomForestClassifier(),
        'params': {'n_estimators': [10, 50, 100], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5]}
    }
}

# 定义评估指标
scoring = {
    'accuracy': make_scorer(accuracy_score),
    'recall': make_scorer(recall_score),
    'precision': make_scorer(precision_score),
    'f1': make_scorer(f1_score)
}

# 交叉验证和网格搜索
for name, classifier_info in tqdm(classifiers.items(), desc="Classifiers"):
    model = classifier_info['model']
    params = classifier_info['params']
    
    # 创建GridSearchCV实例
    grid_search = GridSearchCV(
        estimator=model,
        param_grid=params,
        cv=5,  # 5折交叉验证
        scoring=scoring,  # 使用多个评估指标
        refit='recall'  # 选择最佳模型时使用召回率
    )
    
    # 拟合模型
    grid_search.fit(X_train_scaled, y_train)
    
    # 获取最佳模型和参数
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    
    # 评估最佳模型
    y_pred = best_model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)
    
    # 输出结果
    print(f"Classifier: {name}")
    print(f"Best Parameters: {best_params}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"Classification Report:\n{report}\n")
<br>Classifiers:  33%|███▎      | 1/3 [00:00&lt;00:01,  1.85it/s]

Classifier: Logistic Regression
Best Parameters: {'C': 0.001, 'penalty': 'l1', 'solver': 'liblinear'}
Accuracy: 0.4992
Recall: 0.6331
Precision: 0.3582
F1 Score: 0.4576
Classification Report:
              precision    recall  f1-score   support

           0       0.70      0.43      0.53      2814
           1       0.36      0.63      0.46      1409

    accuracy                           0.50      4223
   macro avg       0.53      0.53      0.50      4223
weighted avg       0.59      0.50      0.51      4223




Classifiers:  67%|██████▋   | 2/3 [13:06&lt;07:42, 462.47s/it]

Classifier: Support Vector Machine
Best Parameters: {'C': 0.1, 'kernel': 'linear'}
Accuracy: 0.4625
Recall: 0.7282
Precision: 0.3522
F1 Score: 0.4748
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.33      0.45      2814
           1       0.35      0.73      0.47      1409

    accuracy                           0.46      4223
   macro avg       0.53      0.53      0.46      4223
weighted avg       0.59      0.46      0.46      4223




Classifiers: 100%|██████████| 3/3 [16:21&lt;00:00, 327.18s/it]

Classifier: Random Forest
Best Parameters: {'max_depth': None, 'min_samples_split': 2, 'n_estimators': 100}
Accuracy: 0.5475
Recall: 0.5422
Precision: 0.3764
F1 Score: 0.4443
Classification Report:
              precision    recall  f1-score   support

           0       0.71      0.55      0.62      2814
           1       0.38      0.54      0.44      1409

    accuracy                           0.55      4223
   macro avg       0.54      0.55      0.53      4223
weighted avg       0.60      0.55      0.56      4223
<br>import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import GradientBoostingClassifier
from xgboost import XGBClassifier
from sklearn.metrics import (
    classification_report,
    accuracy_score,
    recall_score,
    precision_score,
    f1_score,
    make_scorer
)
from tqdm import tqdm

# 读取训练集和测试集
X_train = pd.read_csv('train_test_data_binary/train_resampled.csv').drop('glucose_freq', axis=1)
y_train = pd.read_csv('train_test_data_binary/train_resampled.csv')['glucose_freq']
X_test = pd.read_csv('train_test_data_binary/X_test.csv')
y_test = pd.read_csv('train_test_data_binary/y_test.csv')['glucose_freq']

# 数据标准化
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 定义分类器和参数网格
classifiers = {
    'Gradient Boosting': {
        'model': GradientBoostingClassifier(),
        'params': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
    },
    'XGBoost': {
        'model': XGBClassifier(use_label_encoder=False, eval_metric='logloss'),
        'params': {'n_estimators': [50, 100], 'learning_rate': [0.01, 0.1], 'max_depth': [3, 5]}
    }
}

# 定义评估指标
scoring = {
    'accuracy': make_scorer(accuracy_score),
    'recall': make_scorer(recall_score),
    'precision': make_scorer(precision_score),
    'f1': make_scorer(f1_score)
}

# 交叉验证和网格搜索
for name, classifier_info in tqdm(classifiers.items(), desc="Classifiers"):
    model = classifier_info['model']
    params = classifier_info['params']
    
    # 创建GridSearchCV实例
    grid_search = GridSearchCV(
        estimator=model,
        param_grid=params,
        cv=5,  # 5折交叉验证
        scoring=scoring,  # 使用多个评估指标
        refit='recall'  # 选择最佳模型时使用召回率
    )
    
    # 拟合模型
    grid_search.fit(X_train_scaled, y_train)
    
    # 获取最佳模型和参数
    best_model = grid_search.best_estimator_
    best_params = grid_search.best_params_
    
    # 评估最佳模型
    y_pred = best_model.predict(X_test_scaled)
    accuracy = accuracy_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    report = classification_report(y_test, y_pred)
    
    # 输出结果
    print(f"Classifier: {name}")
    print(f"Best Parameters: {best_params}")
    print(f"Accuracy: {accuracy:.4f}")
    print(f"Recall: {recall:.4f}")
    print(f"Precision: {precision:.4f}")
    print(f"F1 Score: {f1:.4f}")
    print(f"Classification Report:\n{report}\n")
<br>Classifiers:  50%|█████     | 1/2 [03:09&lt;03:09, 189.44s/it]

Classifier: Gradient Boosting
Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}
Accuracy: 0.4430
Recall: 0.6714
Precision: 0.3337
F1 Score: 0.4458
Classification Report:
              precision    recall  f1-score   support

           0       0.67      0.33      0.44      2814
           1       0.33      0.67      0.45      1409

    accuracy                           0.44      4223
   macro avg       0.50      0.50      0.44      4223
weighted avg       0.56      0.44      0.44      4223




C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:36] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:36] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:36] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:36] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:36] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:36] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:37] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:38] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:39] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:40] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:40] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
C:\Users\aimer\AppData\Roaming\Python\Python312\site-packages\xgboost\core.py:158: UserWarning: [23:23:40] WARNING: C:\buildkite-agent\builds\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\xgboost\xgboost-ci-windows\src\learner.cc:740: 
Parameters: { "use_label_encoder" } are not used.

  warnings.warn(smsg, UserWarning)
Classifiers: 100%|██████████| 2/2 [03:13&lt;00:00, 96.74s/it] 

Classifier: XGBoost
Best Parameters: {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 100}
Accuracy: 0.4449
Recall: 0.7048
Precision: 0.3400
F1 Score: 0.4587
Classification Report:
              precision    recall  f1-score   support

           0       0.68      0.31      0.43      2814
           1       0.34      0.70      0.46      1409

    accuracy                           0.44      4223
   macro avg       0.51      0.51      0.44      4223
weighted avg       0.57      0.44      0.44      4223
<br><br>从现有训练集中选取所有出现高糖的时间段，将该时间段的观测序列与血糖值序列构成新的训练集；测试集是从原有测试集中找出所有任务3预测为高糖的时间段的数据。可以看出，任务3的结果影响任务4的测试集，因而任务3主要是把出现高糖的时间段尽可能多地筛选出来，更注重召回率。<br>import pandas as pd

def aggregate_data(df):
    # 设定时间窗口为每小时
    df.set_index('datetime', inplace=True)
    
    # 处理重复的时间戳
    df = df[~df.index.duplicated(keep='first')]
    
    # 聚合非营养数据：计算平均值、方差
    agg_functions = {
        'acc_x': ['mean', 'var'],
        'acc_y': ['mean', 'var'],
        'acc_z': ['mean', 'var'],
        'bvp': ['mean', 'var'],
        'eda': ['mean', 'var'],
        'temp': ['mean', 'var'],
        'hr': ['mean', 'var'],
        'ibi': ['mean', 'var'],
        'elevated_hr_past_hour': ['mean', 'var']
    }
    
    # 累积营养数据
    nutrition_columns = ['calorie', 'total_carb', 'sugar', 'protein']
    df[nutrition_columns] = df[nutrition_columns].cumsum()
    
    # 计算 Glucose Value (mg/dL) 每小时内大于等于140的次数
    # 先按小时进行重采样
    hourly_df = df.resample('h').agg({
        'Glucose Value (mg/dL)': lambda x: (x &gt;= 140).sum(),
        **{col: 'sum' for col in nutrition_columns}
    })
    
    # 重命名列
    hourly_df.rename(columns={'Glucose Value (mg/dL)': 'Glucose Condition Count'}, inplace=True)
    
    # 聚合数据
    hourly_data = df.resample('h').agg(agg_functions)
    
    # 添加营养数据
    for col in nutrition_columns:
        hourly_data[col] = hourly_df[col]
    
    # 添加 Glucose Condition Count 列
    hourly_data['Glucose Condition Count'] = hourly_df['Glucose Condition Count']
    
    # 重置索引以便将时间列放回 DataFrame 中
    hourly_data.reset_index(inplace=True)
    
    # 添加小时列
    hourly_data['hour'] = hourly_data['datetime'].dt.hour
    
    # 将多级索引转换为单级索引，并确保列名唯一
    hourly_data.columns = [' '.join(col).strip() if isinstance(col, tuple) else col for col in hourly_data.columns.values]
    
    # 添加增量列
    for col, functions in agg_functions.items():
        for func in functions:
            if func == 'mean':
                # 使用多级索引访问特定列
                mean_col_name = f'{col} mean'
                if mean_col_name in hourly_data.columns:
                    hourly_data[f'{col} Increment'] = hourly_data[mean_col_name].diff()
    # 补充开头的缺失值，向上补全
    hourly_data.ffill()
    
    return hourly_data

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 主循环
for file_num in file_nums:
    # 加载处理过的数据
    data_with_nutrition = pd.read_csv(f'processed_data1/nutrition/processed_data_{file_num}_nutrition.csv')
    # 将 datetime 列转换为 datetime 对象
    data_with_nutrition['datetime'] = pd.to_datetime(data_with_nutrition['datetime'])
    
    # 聚合数据
    hourly_aggregated_data = aggregate_data(data_with_nutrition)
    
    # 删除包含 NaN 值的行
    hourly_aggregated_data.dropna(inplace=True)
    
    # 保存处理后的数据
    hourly_aggregated_data.to_csv(f'processed_data1/hourly/processed_data_{file_num}_hourly.csv', index=False)
    
    print(f'processed_data_{file_num}_hourly.csv saved')
<br>processed_data_002_hourly.csv saved
processed_data_003_hourly.csv saved
processed_data_004_hourly.csv saved
processed_data_005_hourly.csv saved
processed_data_006_hourly.csv saved
processed_data_007_hourly.csv saved
processed_data_008_hourly.csv saved
processed_data_009_hourly.csv saved
processed_data_010_hourly.csv saved
processed_data_011_hourly.csv saved
processed_data_012_hourly.csv saved
processed_data_013_hourly.csv saved
processed_data_014_hourly.csv saved
processed_data_015_hourly.csv saved
processed_data_016_hourly.csv saved


C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\4250160747.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[nutrition_columns] = df[nutrition_columns].cumsum()
<br># 请在下方完成任务
# 从原本的二分类问题变成回归问题，需要预测出具体的高糖次数
# 具体次数在processed_data1/hourly/processed_data_{file_num}_hourly.csv中的Glucose Condition Count列中


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 初始化一个空的DataFrame用于存放所有数据
data_all = pd.DataFrame()

# 对每个文件编号进行处理
for file_num in file_nums:
    # 读取文件
    data = pd.read_csv(f'processed_data1/hourly/processed_data_{file_num}_hourly.csv')
    # 将数据追加到data_all
    data_all = pd.concat([data_all, data], ignore_index=True)

# 选择特征列
selected_features = ['sugar', 'total_carb', 'calorie', 'protein', 'eda mean', 'acc_x mean','hour']
y_column_name = 'Glucose Condition Count'
X = data_all[selected_features]
data_all[y_column_name].fillna(0)
y = data_all[y_column_name]
# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 标准化训练集和测试集
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 合并过采样后的特征和目标变量
train_resampled = pd.DataFrame(X_train_scaled, columns=selected_features)
train_resampled[y_column_name] = y_train

# 查看过采样后的前几行数据
print(train_resampled.head())

# 保存处理后的训练集和测试集
train_resampled.to_csv('train_test_data_food/train_resampled.csv', index=False)
pd.DataFrame(X_test_scaled, columns=selected_features).to_csv('train_test_data_food/X_test.csv', index=False)
y_test.to_csv('train_test_data_food/y_test.csv', index=False)

print("Train and test sets have been processed and saved.")
<br>      sugar  total_carb   calorie   protein  eda mean  acc_x mean      hour  \
0 -0.840449   -1.007571 -0.999976 -0.920498  0.284381    0.261893 -0.508527   
1  2.425102    2.490811  2.660813  2.373818 -0.295547   -0.074690 -1.387791   
2 -0.752982   -0.702050 -0.813391 -0.798580  0.456923    1.359779 -0.655071   
3 -0.408833   -0.164873 -0.371195 -0.304758 -0.469279   -0.227058 -1.387791   
4  2.465093    1.953941  1.121864  0.283849 -0.333745   -1.348539  0.956913   

   Glucose Condition Count  
0                      2.0  
1                      0.0  
2                      0.0  
3                      0.0  
4                     10.0  
Train and test sets have been processed and saved.
<br><br>可以运用HMM、LSTM等一种时序预测算法，构建一个时间段的高糖时序预测模型，并进行调参；也可以对该时间段内的高糖次数进行回归分析，构建高糖预测回归模型，并进行调参。<br>import pandas as pd
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.svm import SVR
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, r2_score
import matplotlib.pyplot as plt
import numpy as np
import joblib

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 初始化一个空的DataFrame用于存放所有数据
data_all = pd.DataFrame()

# 对每个文件编号进行处理
for file_num in file_nums:
    # 读取文件
    data = pd.read_csv(f'processed_data1/hourly/processed_data_{file_num}_hourly.csv')
    # 将数据追加到data_all
    data_all = pd.concat([data_all, data], ignore_index=True)

# 选择特征列
selected_features = ['sugar', 'total_carb', 'calorie', 'protein', 'eda mean', 'acc_x mean', 'hour']
y_column_name = 'Glucose Condition Count'
X = data_all[selected_features]
y = data_all[y_column_name].fillna(0)

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 标准化训练集和测试集
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 初始化模型列表
models = [
    ('Linear Regression', LinearRegression()),
    ('Support Vector Regression', SVR(kernel='rbf')),
    ('Random Forest Regression', RandomForestRegressor(random_state=42)),
    ('Gradient Boosting Regression', GradientBoostingRegressor(random_state=42))
]

# 定义参数网格
param_grids = {
    'Support Vector Regression': {'C': [1, 10], 'gamma': ['scale', 'auto']},
    'Random Forest Regression': {'n_estimators': [100, 200], 'max_depth': [None, 10]},
    'Gradient Boosting Regression': {'n_estimators': [100, 200], 'learning_rate': [0.1, 0.05]}
}

# 存储结果
results = []

# 训练并评估每个模型
for name, model in models:
    if name in param_grids:
        grid_search = GridSearchCV(estimator=model, param_grid=param_grids[name], cv=5, scoring='neg_mean_squared_error', n_jobs=-1)
        grid_search.fit(X_train_scaled, y_train)
        model = grid_search.best_estimator_
    else:
        model.fit(X_train_scaled, y_train)
    
    y_pred = model.predict(X_test_scaled)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    results.append((name, mse, r2))

    print(f"{name}: Mean Squared Error={mse:.4f}, R^2 Score={r2:.4f}")

# 保存模型
for name, model in models:
    joblib.dump(model, f'{name.lower().replace(" ", "_")}_model.pkl')
    print(f"Model {name} has been saved.")

# 可视化结果
names, mse_scores, r2_scores = zip(*results)
indexes = np.arange(len(names))

plt.figure(figsize=(12, 6))
plt.bar(indexes - 0.2, mse_scores, width=0.4, label='Mean Squared Error')
plt.bar(indexes + 0.2, r2_scores, width=0.4, label='R² Score')
plt.xticks(indexes, names)
plt.legend()
plt.title('Comparison of Regression Models')
plt.xlabel('Models')
plt.ylabel('Scores')
plt.show()
<br>Linear Regression: Mean Squared Error=8.2344, R^2 Score=0.0464
Support Vector Regression: Mean Squared Error=9.4818, R^2 Score=-0.0981
Random Forest Regression: Mean Squared Error=7.0494, R^2 Score=0.1836
Gradient Boosting Regression: Mean Squared Error=7.4915, R^2 Score=0.1324
Model Linear Regression has been saved.
Model Support Vector Regression has been saved.
Model Random Forest Regression has been saved.
Model Gradient Boosting Regression has been saved.
<br><img alt="png" src="\technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_72_1.png"><br><br>运用所训练的细粒度高糖预测模型预测测试集中每个阶段的高糖变化，并计算测试集中每个用户一天发生高糖的次数，与真实值比较，计算误差RMSE和R2分数；<br>import pandas as pd

def aggregate_data_daily(df):
    # 设定时间窗口为每天
    df.set_index('datetime', inplace=True)
    
    # 处理重复的时间戳
    df = df[~df.index.duplicated(keep='first')]
    
    # 聚合非营养数据：计算平均值、方差
    agg_functions = {
        'acc_x': ['mean', 'var'],
        'acc_y': ['mean', 'var'],
        'acc_z': ['mean', 'var'],
        'bvp': ['mean', 'var'],
        'eda': ['mean', 'var'],
        'temp': ['mean', 'var'],
        'hr': ['mean', 'var'],
        'ibi': ['mean', 'var'],
        'elevated_hr_past_hour': ['mean', 'var']
    }
    
    # 累积营养数据
    nutrition_columns = ['calorie', 'total_carb', 'sugar', 'protein']
    df[nutrition_columns] = df[nutrition_columns].cumsum()
    
    # 计算 Glucose Value (mg/dL) 每天内大于等于140的次数
    # 先按天进行重采样
    daily_df = df.resample('D').agg({
        'Glucose Value (mg/dL)': lambda x: (x &gt;= 140).sum(),
        **{col: 'sum' for col in nutrition_columns}
    })
    
    # 重命名列
    daily_df.rename(columns={'Glucose Value (mg/dL)': 'Glucose Condition Count'}, inplace=True)
    
    # 聚合数据
    daily_data = df.resample('D').agg(agg_functions)
    
    # 添加营养数据
    for col in nutrition_columns:
        daily_data[col] = daily_df[col]
    
    # 添加 Glucose Condition Count 列
    daily_data['Glucose Condition Count'] = daily_df['Glucose Condition Count']
    
    # 重置索引以便将时间列放回 DataFrame 中
    daily_data.reset_index(inplace=True)
    
    # 添加天数列
    daily_data['day'] = daily_data['datetime'].dt.day
    
    # 将多级索引转换为单级索引，并确保列名唯一
    daily_data.columns = [' '.join(col).strip() if isinstance(col, tuple) else col for col in daily_data.columns.values]
    
    # 添加增量列
    for col, functions in agg_functions.items():
        for func in functions:
            if func == 'mean':
                # 使用多级索引访问特定列
                mean_col_name = f'{col} mean'
                if mean_col_name in daily_data.columns:
                    daily_data[f'{col} Increment'] = daily_data[mean_col_name].diff()
    # 补充开头的缺失值，向上补全
    daily_data.ffill(inplace=True)
    
    return daily_data

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 主循环
for file_num in file_nums:
    # 加载处理过的数据
    data_with_nutrition = pd.read_csv(f'processed_data1/nutrition/processed_data_{file_num}_nutrition.csv')
    # 将 datetime 列转换为 datetime 对象
    data_with_nutrition['datetime'] = pd.to_datetime(data_with_nutrition['datetime'])
    
    # 聚合数据
    daily_aggregated_data = aggregate_data_daily(data_with_nutrition)
    
    # 删除包含 NaN 值的行
    daily_aggregated_data.dropna(inplace=True)
    
    # 保存处理后的数据
    daily_aggregated_data.to_csv(f'processed_data1/daily/processed_data_{file_num}_daily.csv', index=False)
    
    print(f'processed_data_{file_num}_daily.csv saved')
<br>processed_data_002_daily.csv saved
processed_data_003_daily.csv saved
processed_data_004_daily.csv saved
processed_data_005_daily.csv saved
processed_data_006_daily.csv saved
processed_data_007_daily.csv saved
processed_data_008_daily.csv saved
processed_data_009_daily.csv saved
processed_data_010_daily.csv saved
processed_data_011_daily.csv saved
processed_data_012_daily.csv saved
processed_data_013_daily.csv saved
processed_data_014_daily.csv saved
processed_data_015_daily.csv saved
processed_data_016_daily.csv saved


C:\Users\aimer\AppData\Local\Temp\ipykernel_23896\1911834497.py:25: SettingWithCopyWarning: 
A value is trying to be set on a copy of a slice from a DataFrame.
Try using .loc[row_indexer,col_indexer] = value instead

See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy
  df[nutrition_columns] = df[nutrition_columns].cumsum()
<br>
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from imblearn.over_sampling import SMOTE

# 生成文件编号
file_nums = [f'{i:03d}' for i in range(2, 17)]

# 初始化一个空的DataFrame用于存放所有数据
data_all = pd.DataFrame()

# 对每个文件编号进行处理
for file_num in file_nums:
    # 读取文件
    data = pd.read_csv(f'processed_data1/daily/processed_data_{file_num}_daily.csv')
    # 将数据追加到data_all
    data_all = pd.concat([data_all, data], ignore_index=True)

# 选择特征列
selected_features = ['sugar', 'total_carb', 'calorie', 'protein', 'eda mean', 'acc_x mean']
y_column_name = 'Glucose Condition Count'
X = data_all[selected_features]
data_all[y_column_name].fillna(0)

y = data_all[y_column_name]
print(y)
# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
print(y_train)
# 标准化训练集和测试集
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# 合并过采样后的特征和目标变量
train_resampled = pd.DataFrame(X_train_scaled, columns=selected_features)
train_resampled[y_column_name] = y_train

# 查看过采样后的前几行数据
print(train_resampled.head())

# 保存处理后的训练集和测试集
train_resampled.to_csv('train_test_data_day/train_resampled.csv', index=False)
pd.DataFrame(X_test_scaled, columns=selected_features).to_csv('train_test_data_food/X_test.csv', index=False)
y_test.to_csv('train_test_data_day/y_test.csv', index=False)

print("Train and test sets have been processed and saved.")
<br>0       83
1      108
2       70
3        5
4       52
      ... 
116      2
117      8
118     17
119     16
120     27
Name: Glucose Condition Count, Length: 121, dtype: int64
12      9
15      8
115    21
76     59
98     81
       ..
106    85
14      5
92     23
51      0
102    22
Name: Glucose Condition Count, Length: 96, dtype: int64
      sugar  total_carb   calorie   protein  eda mean  acc_x mean  \
0 -0.929193   -0.633335 -0.928076 -1.037653  0.973228   -1.418392   
1 -0.929193   -0.789156 -1.012085 -1.037653 -0.649889   -0.035150   
2 -0.929193   -1.173146 -1.169824 -1.037653 -0.051783    0.986984   
3 -0.068230   -0.357512 -0.660531 -0.763961  0.324275   -0.829472   
4  1.459040    1.585195  1.938092  2.435242 -0.041635   -0.097710   

   Glucose Condition Count  
0                      NaN  
1                    108.0  
2                     70.0  
3                      5.0  
4                      NaN  
Train and test sets have been processed and saved.
<br>from sklearn.ensemble import RandomForestRegressor
from sklearn.model_selection import GridSearchCV
from sklearn.metrics import mean_squared_error, r2_score

# 定义模型
model = RandomForestRegressor()

# 定义参数网格
param_grid = {
    'n_estimators': [100, 200, 300, 400],  # 树的数量
    'max_depth': [10, 20, 30, None],        # 树的最大深度
    'min_samples_split': [2, 5, 10, 20],    # 内部节点再划分所需最小样本数
    'min_samples_leaf': [1, 2, 4, 10]       # 叶子节点所需的最小样本数
}

# 创建网格搜索对象
grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)

# 拟合模型
grid_search.fit(X_train_scaled, y_train)

# 获取最佳参数
best_params = grid_search.best_params_
print("Best parameters found: ", best_params)

# 使用最佳参数训练模型
best_model = grid_search.best_estimator_

# 预测
y_pred = best_model.predict(X_test_scaled)

# 评估模型
mse = mean_squared_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Mean Squared Error:", mse)
print("R^2 Score:", r2)
<br>Best parameters found:  {'max_depth': None, 'min_samples_leaf': 2, 'min_samples_split': 20, 'n_estimators': 200}
Mean Squared Error: 541.6034449636104
R^2 Score: 0.015191976404741903
]]></description><link>technology\collegeproject\机器学习\课程设计\项目实验报告.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/课程设计/项目实验报告.md</guid><pubDate>Mon, 09 Sep 2024 12:14:04 GMT</pubDate><enclosure url="technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_0.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\机器学习\课程设计\项目实验报告_files\项目实验报告_9_0.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[机器学习]]></title><description><![CDATA[ 
 <br><br><br>
<br><a data-href="最小二乘法" href="\technology\collegeproject\机器学习\概念\最小二乘法.html" class="internal-link" target="_self" rel="noopener nofollow">最小二乘法</a>
<br><a data-href="半监督学习" href="\technology\collegeproject\机器学习\概念\半监督学习.html" class="internal-link" target="_self" rel="noopener nofollow">半监督学习</a>
<br><a data-href="贝叶斯决策论" href="\technology\collegeproject\机器学习\概念\贝叶斯决策论.html" class="internal-link" target="_self" rel="noopener nofollow">贝叶斯决策论</a>
<br><a data-href="度量学习" href="\technology\collegeproject\机器学习\概念\度量学习.html" class="internal-link" target="_self" rel="noopener nofollow">度量学习</a>
<br><a data-href="对数几率回归，极大似然法" href="\technology\collegeproject\机器学习\概念\对数几率回归，极大似然法.html" class="internal-link" target="_self" rel="noopener nofollow">对数几率回归，极大似然法</a>
<br><a data-href="多分类任务与感知机" href="\technology\collegeproject\机器学习\概念\多分类任务与感知机.html" class="internal-link" target="_self" rel="noopener nofollow">多分类任务与感知机</a>
<br><a data-href="多元线性回归与岭回归" href="\technology\collegeproject\机器学习\概念\多元线性回归与岭回归.html" class="internal-link" target="_self" rel="noopener nofollow">多元线性回归与岭回归</a>
<br><a data-href="交叉熵、KL散度" href="\technology\collegeproject\机器学习\概念\交叉熵、kl散度.html" class="internal-link" target="_self" rel="noopener nofollow">交叉熵、KL散度</a>
<br><a data-href="类别不平衡" href="\technology\collegeproject\机器学习\概念\类别不平衡.html" class="internal-link" target="_self" rel="noopener nofollow">类别不平衡</a>
<br><a data-href="卡方检验" href="\technology\collegeproject\机器学习\概念\卡方检验.html" class="internal-link" target="_self" rel="noopener nofollow">卡方检验</a>
<br><a data-href="朴素贝叶斯" href="\technology\collegeproject\机器学习\概念\朴素贝叶斯.html" class="internal-link" target="_self" rel="noopener nofollow">朴素贝叶斯</a>
<br><a data-href="神经网络与感知机" href="\technology\collegeproject\机器学习\概念\神经网络与感知机.html" class="internal-link" target="_self" rel="noopener nofollow">神经网络与感知机</a>
<br><a data-href="误差逆传播算法(BP算法)" href="\technology\collegeproject\机器学习\概念\误差逆传播算法(bp算法).html" class="internal-link" target="_self" rel="noopener nofollow">误差逆传播算法(BP算法)</a>
<br><a data-href="信息增益(ID3决策树)" href="\technology\collegeproject\机器学习\概念\信息增益(id3决策树).html" class="internal-link" target="_self" rel="noopener nofollow">信息增益(ID3决策树)</a>
<br><a data-href="信息增益率(C4.5决策树)" href="\technology\collegeproject\机器学习\概念\信息增益率(c4.5决策树).html" class="internal-link" target="_self" rel="noopener nofollow">信息增益率(C4.5决策树)</a>
<br><a data-href="支持向量机（核函数&amp;软间隔）" href="\technology\collegeproject\机器学习\概念\支持向量机（核函数&amp;软间隔）.html" class="internal-link" target="_self" rel="noopener nofollow">支持向量机（核函数&amp;软间隔）</a>
<br><a data-href="支持向量机拉格朗日乘子法转化为对偶问题" href="\technology\collegeproject\机器学习\概念\支持向量机拉格朗日乘子法转化为对偶问题.html" class="internal-link" target="_self" rel="noopener nofollow">支持向量机拉格朗日乘子法转化为对偶问题</a>
<br><a data-href="最大次序统计量" href="\technology\collegeproject\机器学习\概念\最大次序统计量.html" class="internal-link" target="_self" rel="noopener nofollow">最大次序统计量</a>
<br><a data-href="Boosting&amp;Bagging" href="\technology\collegeproject\机器学习\概念\boosting&amp;bagging.html" class="internal-link" target="_self" rel="noopener nofollow">Boosting&amp;Bagging</a>
<br><a data-href="BT、GBDT" href="\technology\collegeproject\机器学习\概念\bt、gbdt.html" class="internal-link" target="_self" rel="noopener nofollow">BT、GBDT</a>
<br><a data-href="EM算法" href="\technology\collegeproject\机器学习\概念\em算法.html" class="internal-link" target="_self" rel="noopener nofollow">EM算法</a>
<br><a data-href="GMM(高斯混合模型)" href="\technology\collegeproject\机器学习\概念\gmm(高斯混合模型).html" class="internal-link" target="_self" rel="noopener nofollow">GMM(高斯混合模型)</a>
<br><a data-href="K-means、DBSCAN、AGNES聚类" href="\technology\collegeproject\机器学习\概念\k-means、dbscan、agnes聚类.html" class="internal-link" target="_self" rel="noopener nofollow">K-means、DBSCAN、AGNES聚类</a>
<br><a data-href="PCA" href="\technology\collegeproject\机器学习\概念\pca.html" class="internal-link" target="_self" rel="noopener nofollow">PCA</a>
<br><a data-href="ROC曲线与混淆矩阵" href="\technology\collegeproject\机器学习\概念\roc曲线与混淆矩阵.html" class="internal-link" target="_self" rel="noopener nofollow">ROC曲线与混淆矩阵</a>
<br><br><a data-href="项目实验报告" href="\technology\collegeproject\机器学习\课程设计\项目实验报告.html" class="internal-link" target="_self" rel="noopener nofollow">项目实验报告</a>]]></description><link>technology\collegeproject\机器学习\机器学习.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习.md</guid><pubDate>Mon, 09 Sep 2024 12:14:32 GMT</pubDate></item><item><title><![CDATA[机器学习实验问题]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br><br> Pandas 的&nbsp;value_counts()&nbsp;函数用于获取一个序列中各个值的出现次数。<br>以下是一个简单的使用示例：<br>
python<br>import pandas as pd

# 创建一个序列
s = pd.Series(['cat', 'dog', 'cat', 'cat', 'dog', 'rabbit'])

# 使用 value_counts() 函数
counts = s.value_counts()

print(counts)
<br>运行以上代码，你会得到以下输出：<br>cat       3
dog       2
rabbit    1
dtype: int64
<br>在这个例子中，value_counts()&nbsp;函数返回一个新的序列，序列的索引是原序列中的唯一值，序列的值是每个唯一值在原序列中的出现次数。<br>value_counts()&nbsp;函数中有一些可选参数，例如：<br>
<br>normalize：如果设为 True，函数将返回每个唯一值的相对频率而不是出现次数。
<br>sort：如果设为 True（默认值），函数将根据值的数量进行排序；如果设为 False，则会根据值的顺序进行排序。
<br>dropna：如果设为 True（默认值），函数将忽略 NaN 值；如果设为 False，则会包含 NaN 值的计数。
<br>例如，s.value_counts(normalize=True)&nbsp;将返回每个唯一值的相对频率。<br><br>在Pandas中，pd.get_dummies()是一个非常方便的函数，用于对非数值型特征进行One-Hot编码处理。这个函数会将分类变量（通常是字符串或整数编码的类别）扩展成多个二进制列，每个列代表原始分类变量中的一个唯一类别。<br>下面是如何使用pd.get_dummies()对非数值型特征进行One-Hot编码的示例：<br>首先，假设你有一个包含非数值型特征的DataFrame：<br>import pandas as pd    
# 创建一个包含非数值型特征的
DataFrame  df = pd.DataFrame({      'color': ['red', 'green', 'blue', 'red', 'green'],      'size': ['small', 'large', 'small', 'large', 'medium']  })    print("原始DataFrame:")  print(df)
<br>然后，你可以使用pd.get_dummies()函数对这个DataFrame进行One-Hot编码：<br># 使用pd.get_dummies()进行One-Hot编码
df_encoded = pd.get_dummies(df)    print("\nOne-Hot编码后的DataFrame:")  print(df_encoded)
<br>pd.get_dummies()会自动为每个非数值型特征创建新的二进制列，并将原始列从DataFrame中移除。<br>如果你想要保留原始列，可以传入参数drop_first=False（默认是True，它会删除每个分类级别中的第一个，以避免完全共线性）：<br>python复制代码
# 保留原始列进行One-Hot编码
df_encoded_with_original = pd.get_dummies(df, drop_first=False)    print("\nOne-Hot编码后且保留原始列的DataFrame:")  print(df_encoded_with_original)
<br>如果你想对特定的列进行One-Hot编码，而不是对整个DataFrame进行操作，可以这样做：<br>python复制代码
# 仅对'color'列进行One-Hot编码
df_encoded_color = pd.concat([df.drop('color', axis=1), pd.get_dummies(df['color'])], axis=1)    print("\n仅对'color'列进行One-Hot编码后的DataFrame:")  print(df_encoded_color)
<br>在这个例子中，我们首先删除了原始的'color'列，然后使用pd.get_dummies()对'color'列进行One-Hot编码，并将结果与其他列拼接起来。<br>请注意，One-Hot编码会增加数据集的维度，因此在使用它时需要考虑计算资源的限制。同时，如果你的分类变量有很多唯一的类别，One-Hot编码可能会导致非常稀疏的数据集。在这种情况下，可能需要考虑其他编码方法，如标签编码或目标编码。<br><br>因为函数会将string类型的列视为分类数据（categorical data），并对其进行one-hot编码。对于每一个唯一的分类（unique category）在数据中，它将会创建一个新的列。<br>但如果该非数值列的类很多，就会被分成很多类，会加很多列，但这些列只有被分入该类的数据会标记为1，其余皆是0，所以会形成高维稀疏矩阵，这不利于计算。<br>下图可以看出使用one-hot编码后，训练集行数还是10000，列数增大了三个数量级。<br>
<img alt="Pasted image 20240326112025.png" src="\lib\media\pasted-image-20240326112025.png"><br><br>def convert_obj_to_int(self):
object_list_columns = self.columns 
object_list_dtypes = self.dtypes 
new_col_suffix = '_int' 
for index in range(0, len(object_list_columns)): 
	if object_list_dtypes[index] == object: 
	# 使用hash和map将string特征变量映射为一定范围内的整数 
	self[object_list_columns[index] + new_col_suffix] = self[object_list_columns[index]].map(____________) 
	self.drop([object_list_columns[index]], inplace=True, axis=1) 
return self
<br>在Python的pandas库中，DataFrame的dtypes（数据类型）属性会返回每一列的数据类型。在这个属性返回的结果中，"object"代表这一列的数据类型是Python的对象，通常是字符串类型（str）。<br>在你的函数convert_obj_to_int()中，"object"就是用来检查每一列是否是字符串类型。这个函数的作用是遍历每一列的数据类型，如果数据类型是"object"（字符串），就将这一列的字符串通过hash函数转换为整数，并将结果保存在新的列中（新列的列名是在原来的列名后加上_int后缀)，然后删除原来的字符串列。这也是一种特征值的编码方法，可以用于处理包含大量不同值的字符串列，如ID类特征。<br>这个函数的一个副作用是它会改变下标为index的列的类型。如果这个列原是字符串类型（检查到dtype为"object"），那么这一列在函数运行后将会被哈希值代替，并增加了_int的后缀。原来的字符串列会被删除。这样，处理后，原来的字符串列就被対应的哈希值列所替代了，且哈希值列为整数类型。<br>这段代码的主要功能是将字符串类型的列（DataFrame中dtype为object的列）转换为整数，并用新的整数列替换原来的字符串列。这样的操作被广泛应用在机器学习和数据处理中，因为很多机器学习的算法都只接受数值输入。<br>具体步骤如下：<br>
<br>new_col_suffix = '_int'定义了新列的后缀。也就是说，新生成的整数型列名会在原列名的基础上加上_int的后缀。<br>

<br>for index in range(0, len(object_list_columns)):&nbsp;这一行是开始遍历所有列。<br>

<br>if object_list_dtypes[index] == object:&nbsp;这一行是检查当前列是否为字符串列（dtype为object）<br>

<br>若当前列为字符串列，则执行下面的代码：

<br>self[object_list_columns[index] + new_col_suffix] = self[object_list_columns[index]].map(____________)：这一行的作用是创建一个新的列，该列的名字是在原列名字的基础上加上_int的后缀。新列的值通过使用map()函数来从原列的值映射而来。此处的下划线代表要填入一个函数或者字典，这个函数或者字典定义了如何将原列（str类型）的值映射转换为整数。<br>

<br>self.drop([object_list_columns[index]], inplace=True, axis=1): 这一行的作用是删除原来的字符串列。<br>



<br>简单地说，这段代码就是将数据集中的所有字符串特征列转换为以整数表示的特征列。<br># 编写convert_obj_to_int()函数将string类型的特征转换为int型

def convert_obj_to_int(self):

    object_list_columns = self.columns

    object_list_dtypes = self.dtypes

    new_col_suffix = '_int'

    for index in range(0, len(object_list_columns)):

        if object_list_dtypes[index] == object:

            # 使用hash和map将string特征变量映射为一定范围内的整数

            self[object_list_columns[index] + new_col_suffix] = self[object_list_columns[index]].map(hash)

            self.drop([object_list_columns[index]], inplace=True, axis=1)

    return self

  

# 调用convert_obj_to_int()函数，将string类型转换为int型    

train_data = convert_obj_to_int(train_data)

print(train_data.shape)

test_data = convert_obj_to_int(test_data)

print(test_data.shape)
<br><br>LogisticRegression()是sklearn库中的一个函数，用于进行逻辑回归分析。这是一种用于二分类（binary classification）问题的预测模型。<br>在使用LogisticRegression()之前，你需要先对数据进行预处理，确保你的特征矩阵X和目标向量y都已经准备好。然后你可以使用以下步骤实施逻辑回归：<br>首先，你需要引入所需要的模块：<br>from sklearn.linear_model import LogisticRegression
<br>然后，你可以初始化一个LogisticRegression对象：<br>clf = LogisticRegression()
<br>LogisticRegression()函数中有很多的参数可以设置，例如:<br>
<br>penalty：用于指定惩罚项，如'l1'、'l2'、'elasticnet'、'none'。
<br>solver：用于优化问题的算法，如 'newton-cg'、'lbfgs'、'liblinear'、'sag'、'saga'。
<br>C：正则化强度的倒数，较小的值表示强正则化。
<br>设置参数的例子如下：<br>clf = LogisticRegression(penalty='l2', C=1.0, solver='lbfgs')
<br>当你构造了一个逻辑回归分类器对象之后，就可以使用fit方法来训练模型：<br>clf.fit(X_train, y_train)
<br>其中X_train是特征矩阵，y_train是目标向量。<br>在模型训练结束后，你可以通过以下方法获得预测结果和评价模型：<br>
<br>获得预测结果（使用模型对测试集进行预测）：
<br>  y_pred = clf.predict(X_test)
<br>
<br>获得预测概率（获取测试集每个样本点属于每个类别的概率）：
<br>  y_pred_prob = clf.predict_proba(X_test)
<br>
<br>评价模型（此处使用准确率作为评价指标）：
<br>  from sklearn.metrics import accuracy_score
  accuracy = accuracy_score(y_test, y_pred)
<br><br>你可以使用.values或者.to_numpy()将其转换为数组，然后再传入函数。两种方法：<br>方法一：<br>accuracy = accuracy_score(test_label.values, pred)
<br>方法二：<br>accuracy = accuracy_score(test_label.to_numpy(), pred)
<br>这样应该就可以避免产生TypeError的问题了。转换后的test_label现在应该是一个NumPy数组，可以正确地被accuracy_score等函数接收作为参数。]]></description><link>technology\collegeproject\机器学习\机器学习实验问题.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习实验问题.md</guid><pubDate>Thu, 11 Jul 2024 12:04:28 GMT</pubDate><enclosure url="lib\media\pasted-image-20240326112025.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240326112025.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[机器学习与模式识别]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> 
 <br> <a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a><br>
主讲：杨婉琪<br>
邮箱：<a data-tooltip-position="top" aria-label="mailto:yangwq@njnu.edu.cn" rel="noopener nofollow" class="external-link" href="mailto:yangwq@njnu.edu.cn" target="_blank">yangwq@njnu.edu.cn</a><br>
办公室：明理311<br><br><br>
<br>数据稀疏性
<br>高数量高质量标注数据需求
<br>冷启动问题：新产品数据不足
<br><br>
<br>chatgpt：自监督学习
<br>sora：diffusion model+transformer 
<br><br>
<br>模式识别根据已有特征，通过参数或者非参数方法给定模型中的参数，从而达到判别目的。机器学习侧重于特征不明确的情况下，根据样本训练模型。训练模型的过程就是学习。
<br>机器学习通过海量样本发现特征去判别，而模式识别设置好特征描述让机器去判别。模式识别可以认为是早期的机器学习。
<br>]]></description><link>technology\collegeproject\机器学习\机器学习与模式识别.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/机器学习与模式识别.md</guid><pubDate>Mon, 09 Sep 2024 12:27:51 GMT</pubDate></item><item><title><![CDATA[期末复习]]></title><description><![CDATA[ 
 <br> 机器学习与模式识别-课程复习.pptx<br><br>
<br>顶刊：JMLR，TPAMI，TKDE，TNNLS
<br>顶会：ICML,KDD,AAAI,MLA<br>
<img alt="A1707FBA593A84A7E2C536952E9AFAE9.png" src="\lib\media\a1707fba593a84a7e2c536952e9afae9.png">
<br><br><a rel="noopener nofollow" class="external-link" href="https://github.com/zhengjingwei/machine-learning-interview" target="_blank">https://github.com/zhengjingwei/machine-learning-interview</a><br><br>正则化（Regularization）是机器学习中用来防止过拟合的一种技术。它通过对模型的复杂度进行限制，使得模型在训练数据和未见过的数据上都有较好的表现。正则化的主要目标是找到一个折衷，使得模型既不过于复杂（避免过拟合），也不过于简单（避免欠拟合）。<br><br>
<br>防止过拟合：

<br>当模型过于复杂时（例如，参数过多或模型层数过多），它可能会过度拟合训练数据中的噪音，从而在训练数据上表现很好，但在测试数据上表现不佳。正则化通过增加一个惩罚项，使得模型的参数不至于过大，防止模型过度拟合训练数据。


<br>控制模型复杂度：

<br>正则化项实际上是对模型复杂度的一种控制。通过调整正则化强度，可以控制模型的自由度，从而影响模型的表现。


<br><br>
<br>
L1 正则化（Lasso）：

<br>在损失函数中加入参数绝对值的惩罚项，即 。
<br>L1 正则化可以导致某些权重变为零，从而实现特征选择，适合用于高维数据。


<br>
L2 正则化（Ridge）：

<br>在损失函数中加入参数平方和的惩罚项，即 。
<br>L2 正则化会使权重尽可能小，但不为零，适合用于大多数回归问题。


<br>
弹性网络（Elastic Net）：

<br>结合 L1 和 L2 正则化的优点，同时包含两者的惩罚项。


<br><br>
<br>
欠拟合（Underfitting）：当模型太简单，无法捕捉到数据中的复杂模式时，就会发生欠拟合。此时，如果正则化强度过大，模型参数会被过度限制，从而进一步加剧欠拟合现象。因此，在欠拟合的情况下，需要减小正则化强度，甚至取消正则化，以允许模型有更大的自由度去拟合数据。

<br>
过拟合（Overfitting）：当模型过于复杂，能够很好地拟合训练数据中的噪音时，就会发生过拟合。此时，适当地增加正则化强度，可以对模型参数施加限制，减少模型的自由度，从而避免过拟合，提高模型在未见过的数据上的表现。

<br><br>在实践中，通过交叉验证等方法选择合适的正则化参数是很重要的。下面是一个简单的示例，展示了如何在使用 L2 正则化的线性回归模型中调整正则化强度：<br>from sklearn.linear_model import Ridge
from sklearn.model_selection import GridSearchCV
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split

# 生成数据
X, y = make_regression(n_samples=100, n_features=20, noise=0.1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定义模型和参数范围
ridge = Ridge()
parameters = {'alpha': [0.1, 1, 10, 100]}

# 网格搜索
clf = GridSearchCV(ridge, parameters, cv=5)
clf.fit(X_train, y_train)

# 输出最佳参数和性能
print(f"Best parameters: {clf.best_params_}")
print(f"Training score: {clf.score(X_train, y_train)}")
print(f"Test score: {clf.score(X_test, y_test)}")
<br>通过调整 alpha 参数，可以找到最适合的数据集的正则化强度，从而达到平衡欠拟合和过拟合的效果。<br><br>在机器学习和统计学习理论中，模型的结构风险和经验风险是两个重要的概念，用于衡量模型的泛化能力和在未见数据上的表现。它们帮助理解和分析模型的训练和测试过程。<br><br>经验风险也称为训练误差（Training Error），是模型在训练数据集上的平均损失。它直接衡量模型在训练数据上的拟合程度。<br>假设有一个训练数据集 ，损失函数为 ，则经验风险可以表示为：<br><br>经验风险反映了模型在训练数据上的表现，低经验风险意味着模型在训练数据上拟合得很好。然而，过低的经验风险可能导致过拟合，即模型在训练数据上表现优秀，但在测试数据上表现不佳。<br><br>结构风险也称为泛化误差（Generalization Error），是模型在所有可能的数据上的平均损失，即期望损失。由于实际应用中无法获得所有可能的数据分布，因此结构风险通常通过经验风险加上一个正则化项来估计，该正则化项反映了模型的复杂度。<br>结构风险最小化原则（SRM, Structural Risk Minimization）是统计学习理论中的一个核心概念。它试图在经验风险和模型复杂度之间找到一个平衡，以获得良好的泛化性能。<br>结构风险可以表示为：<br><br>其中：<br>
<br> 是经验风险。
<br> 是一个正则化项，衡量模型的复杂度，例如模型参数的范数。
<br> 是一个正则化参数，控制经验风险和正则化项之间的权衡。
<br><br>经验风险和结构风险之间的关系可以帮助理解模型的训练和泛化过程：<br>
<br>低经验风险：意味着模型在训练数据上表现好，但如果模型复杂度太高，可能会导致过拟合。
<br>高经验风险：意味着模型在训练数据上表现不佳，可能是模型过于简单，导致欠拟合。
<br>结构风险最小化：通过在经验风险和正则化项之间找到平衡，选择既不过拟合也不过于简单的模型，从而获得更好的泛化性能。
<br><br>假设我们使用线性回归模型，并采用 L2 正则化（岭回归）来控制模型复杂度。经验风险是模型在训练数据上的均方误差，结构风险则包括均方误差和正则化项。<br>from sklearn.linear_model import Ridge
from sklearn.datasets import make_regression
from sklearn.model_selection import train_test_split
import numpy as np

# 生成数据
X, y = make_regression(n_samples=100, n_features=20, noise=0.1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 定义模型
ridge = Ridge(alpha=1.0)

# 训练模型
ridge.fit(X_train, y_train)

# 计算经验风险（均方误差）
y_train_pred = ridge.predict(X_train)
empirical_risk = np.mean((y_train - y_train_pred)**2)

# 计算结构风险
y_test_pred = ridge.predict(X_test)
generalization_error = np.mean((y_test - y_test_pred)**2)

print(f"Empirical Risk (Training Error): {empirical_risk}")
print(f"Generalization Error (Test Error): {generalization_error}")
<br>通过控制  参数，我们可以调整正则化强度，从而影响模型的复杂度和泛化性能。较小的  值可能导致较低的经验风险和较高的结构风险，而较大的  值可能增加经验风险但减少结构风险，进而找到一个最佳的平衡点。<br><br>L1范数和L2范数是数学中用来度量向量长度（或模型复杂度）的两种常见方式。它们在机器学习和统计学习中有广泛的应用，特别是在正则化方法中。下面是它们的主要区别和各自的特点：<br><br>
<br>
L1范数（Manhattan Distance, Taxicab Norm）：L1范数是向量中各个元素绝对值的和。


<br>
L2范数（Euclidean Distance）：L2范数是向量中各个元素平方和的平方根。


<br><br>
<br>
L1范数：度量一个点到原点的曼哈顿距离，可以看作是在坐标轴上行走的距离。L1范数形成的等值面（等距线）是一个菱形（在二维平面中）。

<br>
L2范数：度量一个点到原点的欧几里得距离，可以看作是直线距离。L2范数形成的等值面（等距线）是一个圆（在二维平面中）或球（在高维空间中）。<br>
<img alt="Pasted image 20240701192628.png" src="\lib\media\pasted-image-20240701192628.png">

<br><br>
<br>
L1正则化（Lasso Regression）：

<br>在损失函数中加入  项。
<br>L1正则化可以导致一些权重精确地变为零，从而实现特征选择，使模型变得稀疏。
<br>适合高维数据，因为它可以自动选择和排除不重要的特征。


<br>
L2正则化（Ridge Regression）：

<br>在损失函数中加入  项。
<br>L2正则化使得权重尽可能小，但不为零，所有特征都会保留在模型中，只是权重大小被调整。
<br>对于存在多重共线性的情况（特征之间高度相关），L2正则化可以稳定模型。


<br><br>
<br>L1正则化：求解 L1 正则化问题通常需要使用特殊的优化算法（如坐标下降法），因为 L1 范数的绝对值函数在零点不可导。
<br>L2正则化：求解 L2 正则化问题相对简单，可以直接使用梯度下降或解析解。
<br><br>
<br>
L1正则化：

<br>适用于特征数量远大于样本数量的高维数据。
<br>需要自动进行特征选择时。
<br>例如，文本分类中的词袋模型（Bag-of-Words）或基因数据分析。


<br>
L2正则化：

<br>适用于特征数量适中且存在多重共线性的情况。
<br>需要所有特征的信息但又要避免过拟合时。
<br>例如，常规的回归问题、图像处理中的像素数据。


<br><br>下面是使用Python的scikit-learn库进行L1和L2正则化的简单示例：<br>import numpy as np
from sklearn.linear_model import Lasso, Ridge
from sklearn.model_selection import train_test_split
from sklearn.datasets import make_regression

# 生成模拟数据
X, y = make_regression(n_samples=100, n_features=20, noise=0.1)
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# L1正则化
lasso = Lasso(alpha=0.1)
lasso.fit(X_train, y_train)
print("L1正则化（Lasso）系数：", lasso.coef_)
print("L1正则化（Lasso）训练得分：", lasso.score(X_train, y_train))
print("L1正则化（Lasso）测试得分：", lasso.score(X_test, y_test))

# L2正则化
ridge = Ridge(alpha=1.0)
ridge.fit(X_train, y_train)
print("L2正则化（Ridge）系数：", ridge.coef_)
print("L2正则化（Ridge）训练得分：", ridge.score(X_train, y_train))
print("L2正则化（Ridge）测试得分：", ridge.score(X_test, y_test))
<br>在这个示例中，我们对比了L1正则化（Lasso）和L2正则化（Ridge）在相同数据集上的表现，可以观察到它们在模型系数、训练得分和测试得分上的不同表现。这种对比有助于理解在实际问题中选择哪种正则化方法更合适。<br><br>在优化过程中应用L1正则化时，通过在损失函数中添加L1范数惩罚，优化算法会尽量使模型的权重向量中的一些元素变为零。这是因为L1正则化项是权重向量中各个权重的绝对值之和，最小化这个正则化项的过程中，优化算法会倾向于让不太重要的权重趋于零。<br><img alt="Pasted image 20240701192746.png" src="\lib\media\pasted-image-20240701192746.png"><br>
<br>
对不太重要的特征权重进行压缩：由于L1正则化项中的绝对值操作，当某个权重 wi​ 对整体损失函数影响较小时，优化算法倾向于将其变为零，以最小化正则化项。

<br>
稀疏性的产生：在优化过程中，一些权重会被压缩为零，导致最终的权重向量具有稀疏性，即包含很多零元素。

<br>这种压缩权重为零的效应使得L1正则化在特征选择方面具有优势，可以让模型更关注对预测目标有更大影响的特征，忽略对预测影响较小的特征，从而降低模型的复杂度。<br><br>自助法（Bootstrap）不仅用于估计统计量，还可以用于模型评估，特别是对模型的泛化性能进行估计。其主要思想是通过对数据集进行有放回的重采样，生成多个训练集和相应的测试集，从而多次训练和评估模型，以获得性能指标的分布。<br><br>
<br>准备数据集：假设有一个包含  个样本的数据集 。
<br>生成自助样本：从数据集  中有放回地抽取  个样本，生成一个自助样本 。重复此步骤  次，生成  个不同的自助样本 。
<br>划分训练集和测试集：对于每个自助样本 ，那些未被抽取到的样本组成测试集 。训练集则为自助样本  本身。
<br>训练模型并评估：对于每个自助样本 ，用它训练模型，并在相应的测试集  上评估模型性能，记录性能指标（如准确率、均方误差等）。
<br>计算性能指标的分布：将所有  个测试结果汇总，计算性能指标的均值、方差、置信区间等。
<br><br>
<br>稳定性和可靠性：通过多次重采样和评估，可以获得性能指标的分布，提供更稳定和可靠的估计。
<br>适用于小样本数据：在样本量较小时，自助法依然能够提供有意义的模型评估。
<br>无分布假设：自助法不依赖于数据的分布假设，适用于各种类型的数据。
<br><br>以下是一个使用自助法进行模型评估的示例，以线性回归模型为例：<br>import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.datasets import make_regression
from sklearn.utils import resample

# 生成模拟数据
X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)

# 自助采样参数
B = 1000  # 重采样次数
n = len(y)
bootstrap_scores = []

# 进行B次自助采样
for _ in range(B):
    # 生成自助样本
    X_resampled, y_resampled = resample(X, y, n_samples=n, replace=True, random_state=42)
    
    # 找出测试集
    mask = np.isin(range(n), np.unique(resample(range(n), n_samples=n, replace=True, random_state=42)), invert=True)
    X_test = X[mask]
    y_test = y[mask]
    
    # 训练模型
    model = LinearRegression()
    model.fit(X_resampled, y_resampled)
    
    # 评估模型
    y_pred = model.predict(X_test)
    score = mean_squared_error(y_test, y_pred)
    bootstrap_scores.append(score)

# 计算性能指标的均值和置信区间
mean_score = np.mean(bootstrap_scores)
std_score = np.std(bootstrap_scores)
conf_interval = np.percentile(bootstrap_scores, [2.5, 97.5])

print(f"Bootstrap Mean Score: {mean_score}")
print(f"Bootstrap Standard Error: {std_score}")
print(f"95% Confidence Interval: {conf_interval}")
<br><br>
<br>生成数据：使用 make_regression 生成一个模拟数据集。
<br>自助采样和训练模型：

<br>使用 resample 进行有放回的重采样，生成自助样本。
<br>通过 np.isin 方法确定测试集（未被采样到的样本）。
<br>用自助样本训练线性回归模型，并在测试集上评估模型性能（均方误差）。


<br>计算性能指标：

<br>收集所有重采样的性能指标，计算均值和标准误。
<br>使用百分位数法计算性能指标的95%置信区间。


<br><br>自助法通过重采样生成多个训练集和测试集，能够有效评估模型的泛化性能。它提供了性能指标的分布，可以计算均值、方差、置信区间等统计量，从而为模型评估提供更稳定和可靠的估计。这在实际应用中，特别是数据量有限的情况下，具有很高的实用价值。<br>自助法在数据量小，难以划分训练集和测试集的时候非常有用，由于改变了数据分布可能会引起估计偏差，所以数据量较大的时候留出法和交叉验证法更常用。<br><br>有放回地采样是自助法的核心，它带来了一些独特的优势和特性，使得自助法在统计学和机器学习中的应用非常广泛。以下是为什么要有放回地采样的主要原因和优点：<br><br>有放回地采样（即每次抽样后放回样本，再进行下一次抽样）可以模拟样本的原始分布。在样本量有限的情况下，通过多次重采样生成的样本集能够更好地反映原始数据的分布特征，从而提供更准确的估计。<br><br>有放回地采样允许某些样本在同一个重采样集（bootstrap sample）中出现多次，同时也意味着某些样本可能不会出现在某个重采样集中。这种特性带来了数据集的多样性，有助于评估统计量的稳定性和模型的泛化性能。<br><br>在机器学习中，自助法生成的每个重采样集都有不同的样本组合，这种多样性有助于特征选择和模型稀疏性。例如，L1正则化（Lasso）在每个重采样集上可能选择不同的特征，从而提供更稳定的特征选择结果。<br><br>通过有放回地采样生成多个重采样集，可以计算统计量的分布，如均值、方差和置信区间。这为估计误差和不确定性提供了一个有效的方法，特别是在数据量有限的情况下。<br><br>多次重采样和评估模型性能可以提供更加稳定和鲁棒的估计结果。这在实际应用中非常重要，因为单一训练集的评估结果可能会受到偶然因素的影响，而通过多次重采样可以减少这种不确定性。<br><br>以下是一个具体的示例，展示了有放回地采样在模型评估中的应用：<br>import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.datasets import make_regression
from sklearn.utils import resample

# 生成模拟数据
X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)

# 自助采样参数
B = 1000  # 重采样次数
n = len(y)
bootstrap_scores = []

# 进行B次自助采样
for _ in range(B):
    # 生成自助样本
    X_resampled, y_resampled = resample(X, y, n_samples=n, replace=True, random_state=42)
    
    # 找出测试集
    mask = np.isin(range(n), np.unique(resample(range(n), n_samples=n, replace=True, random_state=42)), invert=True)
    X_test = X[mask]
    y_test = y[mask]
    
    # 训练模型
    model = LinearRegression()
    model.fit(X_resampled, y_resampled)
    
    # 评估模型
    y_pred = model.predict(X_test)
    score = mean_squared_error(y_test, y_pred)
    bootstrap_scores.append(score)

# 计算性能指标的均值和置信区间
mean_score = np.mean(bootstrap_scores)
std_score = np.std(bootstrap_scores)
conf_interval = np.percentile(bootstrap_scores, [2.5, 97.5])

print(f"Bootstrap Mean Score: {mean_score}")
print(f"Bootstrap Standard Error: {std_score}")
print(f"95% Confidence Interval: {conf_interval}")
<br><br>有放回地采样在自助法中的应用能够生成多样化的数据集，模拟样本的原始分布，从而提供更加稳定和准确的统计量估计和模型评估结果。通过多次重采样，可以有效地估计误差和不确定性，提高模型的泛化性能和鲁棒性。<br><br><img alt="Pasted image 20240701200441.png" src="\lib\media\pasted-image-20240701200441.png"><br><br><img alt="Pasted image 20240701200511.png" src="\lib\media\pasted-image-20240701200511.png"><br>
<img alt="Pasted image 20240701200555.png" src="\lib\media\pasted-image-20240701200555.png"><br><br>泛化误差（Generalization Error）是指机器学习模型在未见过的新数据上的预测误差。它衡量了模型的泛化能力，即模型从训练数据中学到的知识在新数据上表现的好坏。泛化误差是模型评估的重要指标，因为我们通常希望模型不仅在训练数据上表现良好，而且在未知的数据上也能保持良好的性能。<br><br>泛化误差可以分解为以下几个部分：<br>
<br>偏差（Bias）：模型对数据的固有误差。高偏差意味着模型过于简单，无法捕捉数据的复杂模式，通常导致欠拟合。
<br>方差（Variance）：模型对训练数据的敏感度。高方差意味着模型过于复杂，能够很好地拟合训练数据，但在新数据上表现不佳，通常导致过拟合。
<br>噪声（Noise）：数据中固有的随机误差，即无论模型多么复杂，误差总是存在的部分。
<br>公式上可以表示为：<br><br><br>在实际应用中，我们通常使用验证集或测试集上的误差来估计泛化误差。常见的方法包括：<br>
<br>留出法（Holdout Method）：将数据集划分为训练集和测试集，训练集用于训练模型，测试集用于评估模型。
<br>交叉验证（Cross-Validation）：将数据集划分为 k 个子集，进行 k 次训练和评估，每次使用 k-1 个子集训练，1 个子集评估，最后取平均结果。
<br>自助法（Bootstrap Method）：通过有放回地重采样生成多个训练集和测试集，进行多次训练和评估。
<br><br>减少泛化误差通常涉及在偏差和方差之间进行权衡：<br>
<br>
减少偏差：

<br>使用更复杂的模型（增加模型的容量）。
<br>使用更多的特征。
<br>增加训练数据的多样性。


<br>
减少方差：

<br>使用正则化方法（如 L1、L2 正则化）。
<br>减少模型的复杂度。
<br>使用更多的训练数据。
<br>使用集成方法（如 Bagging、Boosting）。


<br><br>以下是一个简单的示例，展示如何使用交叉验证估计泛化误差：<br>import numpy as np
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
from sklearn.model_selection import cross_val_score
from sklearn.datasets import make_regression

# 生成模拟数据
X, y = make_regression(n_samples=100, n_features=10, noise=0.1, random_state=42)

# 线性回归模型
model = LinearRegression()

# 进行5折交叉验证
scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')

# 计算均值和标准误
mean_score = np.mean(scores)
std_score = np.std(scores)

print(f"Mean Squared Error (cross-validated): {-mean_score}")
print(f"Standard Deviation: {std_score}")
<br><br>泛化误差是衡量机器学习模型在新数据上表现的关键指标。通过理解和估计泛化误差，我们可以更好地选择和调整模型，以提高其在未见过的数据上的表现。减少泛化误差通常涉及在偏差和方差之间进行权衡，并采取适当的方法来防止过拟合或欠拟合。<br><br>损失函数描述了最好的参数应该满足的条件<br><br>SMO（Sequential Minimal Optimization）是一种用于训练支持向量机（SVM）的有效算法。其基本思想是将原始的二次规划问题分解为一系列的子问题，每次优化两个拉格朗日乘子，直至达到全局最优解。下面是使用SMO求解支持向量机的步骤：<br><br>给定一个训练集 ，其中  是特征向量，  是标签（取值为 +1 或 -1）。目标是找到一个超平面  来最大化分类间隔。<br><br>SVM的优化问题可以表示为：<br><br>其对偶形式为：<br><br><br>
<br>初始化：设定所有拉格朗日乘子 ，选择一个初始值 。
<br>外循环：遍历每一个  ，检查是否违反了KKT条件（Karush-Kuhn-Tucker条件）。
<br>内循环：如果  违反了KKT条件，从剩余的  中选择另一个  来优化。
<br>优化两个乘子：计算新的  和 ，并更新它们。
<br>更新偏置 ：根据新的  和  更新偏置 。
<br>迭代：重复以上步骤直到所有乘子满足KKT条件或达到最大迭代次数。
<br><br>以下是SMO算法的伪代码：<br>Initialize alpha and b to 0
while not converged:
    for each i in range(0, n):
        if alpha_i violates KKT conditions:
            j = select a second alpha_j randomly
            compute new alpha_i and alpha_j
            update alpha_i and alpha_j
            update threshold b
<br><br>以下是一个简化的Python实现：<br>import numpy as np

def kernel(x1, x2):
    return np.dot(x1, x2)

def smo(X, y, C, tol, max_passes):
    m, n = X.shape
    alpha = np.zeros(m)
    b = 0
    passes = 0

    while passes &lt; max_passes:
        num_changed_alphas = 0
        for i in range(m):
            E_i = np.dot(alpha * y, kernel(X, X[i])) + b - y[i]
            if (y[i] * E_i &lt; -tol and alpha[i] &lt; C) or (y[i] * E_i &gt; tol and alpha[i] &gt; 0):
                j = np.random.choice([l for l in range(m) if l != i])
                E_j = np.dot(alpha * y, kernel(X, X[j])) + b - y[j]

                alpha_i_old, alpha_j_old = alpha[i], alpha[j]
                if y[i] != y[j]:
                    L = max(0, alpha[j] - alpha[i])
                    H = min(C, C + alpha[j] - alpha[i])
                else:
                    L = max(0, alpha[i] + alpha[j] - C)
                    H = min(C, alpha[i] + alpha[j])

                if L == H:
                    continue

                eta = 2 * kernel(X[i], X[j]) - kernel(X[i], X[i]) - kernel(X[j], X[j])
                if eta &gt;= 0:
                    continue

                alpha[j] -= y[j] * (E_i - E_j) / eta
                alpha[j] = np.clip(alpha[j], L, H)

                if abs(alpha[j] - alpha_j_old) &lt; tol:
                    alpha[j] = alpha_j_old
                    continue

                alpha[i] += y[i] * y[j] * (alpha_j_old - alpha[j])

                b1 = b - E_i - y[i] * (alpha[i] - alpha_i_old) * kernel(X[i], X[i]) - y[j] * (alpha[j] - alpha_j_old) * kernel(X[i], X[j])
                b2 = b - E_j - y[i] * (alpha[i] - alpha_i_old) * kernel(X[i], X[j]) - y[j] * (alpha[j] - alpha_j_old) * kernel(X[j], X[j])

                if 0 &lt; alpha[i] &lt; C:
                    b = b1
                elif 0 &lt; alpha[j] &lt; C:
                    b = b2
                else:
                    b = (b1 + b2) / 2

                num_changed_alphas += 1

        if num_changed_alphas == 0:
            passes += 1
        else:
            passes = 0

    return alpha, b

# 示例数据
X = np.array([[2, 3], [3, 3], [2, 1], [1, 1]])
y = np.array([1, 1, -1, -1])
C = 1.0
tol = 0.001
max_passes = 5

alpha, b = smo(X, y, C, tol, max_passes)
print(f'Alpha: {alpha}, b: {b}')
<br>这个代码示例展示了如何使用SMO算法来训练支持向量机。实际应用中，代码可能需要进一步优化和扩展以处理更复杂的数据集和核函数。<br><br>KKT条件（Karush-Kuhn-Tucker conditions）是非线性规划问题的必要条件和充分条件之一，广泛应用于凸优化问题。对于支持向量机（SVM）等机器学习算法，KKT条件用于确保优化问题的解是全局最优的。以下是KKT条件的基本介绍以及在支持向量机中的具体应用。<br><br>首先，考虑一个优化问题：<br><br>其中， 是目标函数， 和  是约束条件。<br><br>构建拉格朗日函数：<br><br>其中， 和  分别是拉格朗日乘子。<br><br>KKT条件包括以下四个部分：<br>
<br>
驻点条件：<br>


<br>
可行性条件：<br>


<br>
拉格朗日乘子非负性：<br>


<br>
互补松弛条件：<br>


<br><br>在支持向量机中，我们的目标是找到一个最大化分类间隔的超平面。其优化问题可以表示为：<br><br>其对偶形式为：<br><br>对于上述对偶问题，其KKT条件为：<br>
<br>
驻点条件：<br>


<br>
可行性条件：<br>


<br>
互补松弛条件：<br>


<br>
拉格朗日乘子非负性：<br>


<br><br>在SMO算法中，KKT条件用于选择需要优化的拉格朗日乘子。算法的主要步骤包括：<br>
<br>选择违反KKT条件的 。
<br>从剩余的  中选择 。
<br>优化  和 。
<br>更新模型参数  和 。
<br>检查新的KKT条件是否满足，如果不满足则继续迭代。
<br>通过反复调整  和  直到所有KKT条件都满足，SMO算法最终收敛于最优解。<br><br>假设我们有一个二分类问题，训练集为 ，标签 。目标是找到最优的  和  来划分数据。<br>在SMO算法中，我们可以用如下步骤来检查KKT条件：<br>def check_KKT_conditions(X, y, alpha, b, C, tol):
    for i in range(len(y)):
        E_i = np.dot(alpha * y, kernel(X, X[i])) + b - y[i]
        r_i = y[i] * E_i

        if (alpha[i] &lt; C and r_i &lt; -tol) or (alpha[i] &gt; 0 and r_i &gt; tol):
            return False

    return True
<br>这个函数检查每个数据点的KKT条件是否满足。如果所有点都满足条件，则算法可以停止。<br>通过理解和应用KKT条件，可以更有效地解决支持向量机的优化问题，并确保得到全局最优解。<br><br>在支持向量机（SVM）和其他机器学习算法中，核函数（Kernel Function）是一个非常重要的概念。核函数用于将低维空间中的数据映射到高维空间，从而使得非线性问题可以在线性高维空间中处理。<br><br>一个核函数  会生成一个核矩阵 ，其中 ，  和  是数据集中的两个样本。为了确保这个核函数是有效的，它必须满足某些条件，其中一个重要条件是半正定性。<br>半正定矩阵：一个矩阵  是半正定的，当且仅当对于所有非零向量 ，都有 。<br><br>一个对称函数  是指 。对于一个对称函数，如果它对应的核矩阵  是半正定的，那么这个对称函数就可以作为核函数来使用。这是因为核函数的半正定性保证了在高维空间中映射后的点之间的距离关系仍然是有效的。<br><br>半正定性的重要性在于它确保了生成的核矩阵可以被用于SVM等算法的优化过程。具体来说：<br>
<br>
凸优化：在SVM的优化过程中，我们需要解决一个二次规划问题（QP问题），该问题的目标函数和约束条件都涉及核矩阵。如果核矩阵不是半正定的，优化问题可能没有解或解不唯一，无法找到最优的分类超平面。

<br>
几何解释：半正定性确保了映射到高维空间的点之间的距离和角度关系是有效的，从而保持了数据的结构和特性。

<br><br>因此，"只要一个对称函数所对应的核矩阵是半正定的，则它就能作为核函数来使用" 的意思是说，核函数必须满足半正定性条件，这样才能确保SVM等算法在使用这个核函数时能够正常工作并找到最优解。半正定性是核函数的一个必要条件，确保了在高维空间中的数据关系和结构的有效性。<br>通过使用半正定的对称函数作为核函数，SVM能够处理复杂的非线性分类问题，同时保持优化过程的稳定性和可靠性。<br><br>要确定一个对称函数的核矩阵，需要遵循以下步骤：<br>
<br>
选择对称函数作为核函数：首先，选择一个对称函数  作为核函数。常见的核函数包括线性核、多项式核、高斯核（RBF核）等。对称函数的特性是 。

<br>
准备数据集：准备一个包含  个样本的数据集 。

<br>
计算核矩阵：核矩阵  是一个  的矩阵，其中第  行第  列的元素  由核函数  计算得到。对于每对样本 ，计算 。

<br>以下是具体步骤及代码示例：<br><br>常见的核函数定义如下：<br>
<br>
线性核函数：<br>


<br>
多项式核函数：<br>
其中， 是常数， 是多项式的度数。

<br>
高斯核函数（RBF核函数）：<br>
其中， 是核宽度参数。

<br><br>假设我们选择高斯核函数来计算核矩阵，下面是Python代码示例：<br>import numpy as np

def rbf_kernel(x, y, sigma):
    return np.exp(-np.linalg.norm(x - y)**2 / (2 * sigma**2))

def compute_kernel_matrix(X, kernel_func, **kwargs):
    n_samples = X.shape[0]
    K = np.zeros((n_samples, n_samples))
    for i in range(n_samples):
        for j in range(n_samples):
            K[i, j] = kernel_func(X[i], X[j], **kwargs)
    return K

# 示例数据
X = np.array([[1, 2], [2, 3], [3, 4]])

# 计算高斯核矩阵
sigma = 1.0
K = compute_kernel_matrix(X, rbf_kernel, sigma=sigma)

print("核矩阵 K:")
print(K)
<br><br>
<br>定义高斯核函数：函数 rbf_kernel 计算两个样本之间的高斯核值。
<br>计算核矩阵：函数 compute_kernel_matrix 计算核矩阵 ，其中每个元素  由核函数计算得到。
<br>示例数据：我们使用示例数据 X 计算核矩阵，并打印结果。
<br>核矩阵  中的每个元素  表示样本  和  在高维空间中的相似度。如果选择的是对称核函数（例如上面示例中的高斯核函数），那么核矩阵  也将是对称的。<br><br>为了确认核矩阵是半正定的，可以检查矩阵的所有特征值是否非负。以下是确认半正定性的代码示例：<br>def is_positive_semidefinite(K):
    eigenvalues = np.linalg.eigvals(K)
    return np.all(eigenvalues &gt;= 0)

# 检查核矩阵是否半正定
is_psd = is_positive_semidefinite(K)
print("核矩阵是半正定的:", is_psd)
<br>通过上述步骤和代码示例，我们可以选择一个对称函数，计算其对应的数据集的核矩阵，并确认该核矩阵是否为半正定。如果核矩阵是半正定的，那么该对称函数可以作为有效的核函数使用。<br><br>不同的核函数在支持向量机（SVM）中的作用是将输入数据映射到不同的高维特征空间，从而使得在低维空间中无法线性可分的数据在高维空间中变得线性可分。每种核函数都有其独特的特性和适用场景。以下是常见的核函数及其区别：<br><br>线性核是最简单的核函数，直接计算输入向量的内积。<br><br>特点：<br>
<br>适用于线性可分的数据。
<br>计算速度快，适合高维稀疏数据（如文本数据）。
<br>应用场景：<br>
<br>文本分类。
<br>图像识别中高维特征数据。
<br><br>多项式核函数通过多项式变换将输入数据映射到高维空间。<br><br>其中， 是常数， 是多项式的度数。<br>特点：<br>
<br>能够处理非线性数据。
<br>参数  和  控制多项式的偏移和复杂度。
<br>应用场景：<br>
<br>图像分类。
<br>非线性模式识别。
<br><br>高斯核（也称径向基函数核，RBF核）是一种常用的非线性核函数，基于输入向量之间的欧氏距离。<br><br>其中， 控制高斯分布的宽度。<br>特点：<br>
<br>能够处理复杂的非线性关系。
<br>参数  控制高维空间的影响范围。
<br>应用场景：<br>
<br>图像识别。
<br>时间序列预测。
<br><br>Sigmoid核函数类似于神经网络中的激活函数。<br><br>其中， 和  是可调参数。<br>特点：<br>
<br>可以模拟神经网络的行为。
<br>参数的选择对模型性能影响较大。
<br>应用场景：<br>
<br>神经网络替代方法。
<br>二分类问题。
<br><br>拉普拉斯核函数是RBF核函数的一种变体。<br><br>特点：<br>
<br>与高斯核相似，但对距离的处理更直接。
<br>应用场景：<br>
<br>与高斯核相似的应用场景。
<br><br>选择适当的核函数取决于数据的分布和特性。以下是一些选择核函数的指导：<br>
<br>数据线性可分：使用线性核。
<br>数据具有非线性关系且维度较高：使用多项式核或高斯核。
<br>希望模拟神经网络：使用Sigmoid核。
<br>尝试不同核函数进行比较：在交叉验证过程中测试不同核函数的表现。
<br><br>以下是一个Python示例代码，展示如何使用不同核函数训练SVM并进行比较：<br>from sklearn import datasets
from sklearn.svm import SVC
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

# 加载示例数据集
iris = datasets.load_iris()
X, y = iris.data, iris.target
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 不同核函数的SVM模型
kernels = ['linear', 'poly', 'rbf', 'sigmoid']
for kernel in kernels:
    model = SVC(kernel=kernel)
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    print(f"Kernel: {kernel}, Accuracy: {accuracy_score(y_test, y_pred):.4f}")
<br>通过上述示例代码，可以比较不同核函数在同一数据集上的表现，选择最适合特定问题的核函数。<br><br>SVR（Support Vector Regression，支持向量回归）是支持向量机（SVM）的一种扩展，用于解决回归问题。与支持向量机用于分类任务不同，支持向量回归的目标是找到一个函数来预测连续值。<br><br>支持向量回归的核心思想是找到一个函数 ，使得大多数数据点  的预测误差在一个容忍范围  内，并且尽量减少模型的复杂度。<br><br>SVR引入了-不敏感损失函数（-insensitive loss function），该函数在误差小于时不计算损失，只有当误差超过时才计算损失。具体来说，损失函数定义为：<br><br><br>SVR的优化目标是找到一个函数 ，使得：<br>
<br>预测误差在容忍范围内。
<br>模型的复杂度最小化，即  最小化。
<br>其优化问题可以表示为：<br><br><br>其中， 和  是松弛变量，用于允许一些数据点超过范围。<br><br>与SVM类似，SVR也可以使用核函数将输入数据映射到高维特征空间，以处理非线性回归问题。常见的核函数包括线性核、多项式核和RBF核。<br><br>以下是一个使用Scikit-learn实现SVR的Python示例代码：<br>import numpy as np
from sklearn.svm import SVR
import matplotlib.pyplot as plt

# 生成示例数据
np.random.seed(0)
X = np.sort(5 * np.random.rand(40, 1), axis=0)
y = np.sin(X).ravel()
y[::5] += 3 * (0.5 - np.random.rand(8))

# 使用线性核、多项式核和RBF核的SVR模型
svr_lin = SVR(kernel='linear', C=100, epsilon=0.1)
svr_poly = SVR(kernel='poly', C=100, degree=3, epsilon=0.1)
svr_rbf = SVR(kernel='rbf', C=100, gamma=0.1, epsilon=0.1)

# 训练模型
y_lin = svr_lin.fit(X, y).predict(X)
y_poly = svr_poly.fit(X, y).predict(X)
y_rbf = svr_rbf.fit(X, y).predict(X)

# 绘制结果
plt.scatter(X, y, color='darkorange', label='data')
plt.plot(X, y_lin, color='navy', lw=2, label='Linear SVR')
plt.plot(X, y_poly, color='c', lw=2, label='Polynomial SVR')
plt.plot(X, y_rbf, color='cornflowerblue', lw=2, label='RBF SVR')
plt.xlabel('data')
plt.ylabel('target')
plt.title('Support Vector Regression')
plt.legend()
plt.show()
<br><br>
<br>生成示例数据：生成一组带有噪声的正弦数据。
<br>训练SVR模型：分别使用线性核、多项式核和RBF核的SVR模型进行训练。
<br>绘制结果：绘制原始数据和不同核函数的SVR模型的拟合曲线。
<br>通过这个示例，可以直观地看到不同核函数在SVR中的效果。选择合适的核函数和参数对于SVR模型的性能至关重要，通常需要通过交叉验证来选择最佳参数。]]></description><link>technology\collegeproject\机器学习\期末复习.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/期末复习.md</guid><pubDate>Thu, 11 Jul 2024 12:04:41 GMT</pubDate><enclosure url="lib\media\a1707fba593a84a7e2c536952e9afae9.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\a1707fba593a84a7e2c536952e9afae9.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[作业]]></title><description><![CDATA[ 
 <br> 课后作业1.docx 课后作业2.docx 课后作业3.docx 课后作业4.docx 课后作业5.docx 课后作业6.docx 课后作业7.docx 课后作业8.docx 课后作业9.docx 课后作业10.docx 课后作业11.docx 课后作业12.docx]]></description><link>technology\collegeproject\机器学习\作业.html</link><guid isPermaLink="false">Technology/CollegeProject/机器学习/作业.md</guid><pubDate>Wed, 03 Jul 2024 04:19:04 GMT</pubDate></item><item><title><![CDATA[1计算机系统基础实验报告一]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/操作系统" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统</a> <a class="tag" href="?query=tag:define" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#define</a> <a class="tag" href="?query=tag:ifdef" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#ifdef</a> <a class="tag" href="?query=tag:gcc" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#gcc</a> 
 <br><a href=".?query=tag:科技\操作系统" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统</a><br><br><br>安装Linux环境并以一简单程序“hello.c**”进行测试。**<br><br>
<br>
使用gedit hello.c命令在主文件夹下创建一个hello.c文件

<br>
在hello.c文件中编写程序后将其保存

<br>
预处理阶段：使用gcc -E hello.c -o hello.i gedit hello.i得到预处理之后hello.i文件文本）

<br>
编译阶段：使用gcc -S hello.i -o hello.s gedit hello.s得到汇编代码（文本）

<br>
汇编阶段：使用gcc -c hello.s -o hello.o gedit hello.o得到可重定向目标程序（二进制）

<br>
链接阶段：使用gcc hello.o -o hello gedit hello得到可执行目标程序（二进制）

<br>
运行阶段：使用./hello得到运行结果

<br><br><br>输入以下代码，生成文件hello.c<br>[root@wahoo test]# vim hello.c<br>#include &lt;stdio.h&gt;

#define DISPLAY "hello c!"

int main(void)

{

    printf("%s\n", DISPLAY);

    return 0;

}

<br><br>对各种预处理指令（#include&nbsp;<a href=".?query=tag:define" class="tag" target="_blank" rel="noopener nofollow">#define</a>&nbsp;<a href=".?query=tag:ifdef" class="tag" target="_blank" rel="noopener nofollow">#ifdef</a> 等#开始的代码行）进行处理，删除注释和多余的空白字符，生成一份新的代码<br>[root@wahoo test]# gcc -E hello.c -o hello.i<br>E 参数 通知gcc对目标文件进行预编译，这里是对文件hello.c文件<br>o 参数 是对命令输出结果进行导入操作，这里是把&nbsp;gcc -E hello.c 操作结果输出到文件hello.i（命名要自定义）中进行保存。<br>&nbsp;这个命令执行完后目录下多了一个文件hello.i，可以查阅一下文件的内容。<br><br>对代码进行语法、语义分析和错误判断，生成汇编代码文件<br>&nbsp;[root@wahoo test]# gcc -S hello.i -o hello.s<br>S 参数 通知gcc对目标文件进行编译，这个命令执行完后目录下多了一个hello.s文件，内容如图<br><br>[root@wahoo test]# gcc -c hello.s -o hello.o<br>c 参数 通知gcc对目标文件执行指令转换操作，此步骤后得到文件hello.o<br><br>[root@wahoo test]<a href=".?query=tag:gcc" class="tag" target="_blank" rel="noopener nofollow">#gcc</a> hello.o -o hello<br>这样就得到了一个可以直接在系统下执行的文件 hello。<br><br>[root@wahoo test]#./hello<br><br>hello c!<br><br>1. 编写c源程序<br><img alt="Pasted image 20240324140529.png" src="\lib\media\pasted-image-20240324140529.png"><br>2. 预编译(Preprocessing)<br><img alt="Pasted image 20240324140725.png" src="\lib\media\pasted-image-20240324140725.png"><br>3. 编译(Compilation)<br><img alt="Pasted image 20240324140906.png" src="\lib\media\pasted-image-20240324140906.png"><br>
4. 汇编(Assembly) 链接(Linking/Build) 程序运行<br>
<img alt="Pasted image 20240324141238.png" src="\lib\media\pasted-image-20240324141238.png"><br>1.6 实验小结<br>
我学习了如何使用cd切换目录，如何使用ls查看当前目录下的文件，如何使用mkdir创建新的目录，如何使用touch创建新的文件等基本命令。<br>接下来我按照这个实验的要求，编写了一个名为hello.c的C程序。<br>写完后，我使用gcc命令将其编译为一个可执行文件。然后我运行./hello命令，成功看到了“Hello, World！”的输出。<br><br>我在这个过程中深化了对Linux的理解，体验到了其强大、灵活的一面。我明白了命令行是如何简化复杂任务的，并且也理解了为何许多开发人员都优先选择使用它。<br>同时，我也体验到了编译并运行一个C程序的过程，我很清楚地看到了程序从代码到可执行文件的转变过程，也理解了作为编程人员，我们是如何通过编程语言表达问题的解决方案，然后通过编译器将其转化为机器能够理解的格式。<br>总的来说，通过这个实验，我加深了对操作系统与编程语言的了解，激发了我对探求更深层次计算机知识的兴趣。我期待接下来的学习和实验过程。]]></description><link>technology\collegeproject\计算机系统基础\计算机系统基础实验报告\1计算机系统基础实验报告一.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/计算机系统基础实验报告/1计算机系统基础实验报告一.md</guid><pubDate>Mon, 08 Apr 2024 02:00:27 GMT</pubDate><enclosure url="lib\media\pasted-image-20240324140529.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240324140529.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[2计算机系统基础实验报告二]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/操作系统" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统</a> 
 <br><a href=".?query=tag:科技\操作系统" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统</a><br><br>完成下列实验，并提交实验报告：<br>1. &nbsp;（1）运行下列代码，并对输出结果进行分析。<br>int x=-1;<br>unsigned u=2147483648;<br>printf("x = %u = %d.\n",x,x);<br>printf("u = %u = %d.\n",u,u);<br>（2）通过反汇编生成对应的文本表示形式，找出各变量赋值以后的机器数（十六进制）。<br>2. **验证以下 4条 表达式的结果，并对结果进行分析，通过反汇编生成对应的文本表示形式，要求报告中补充源程序代码。<br>-1 &lt; 0<br>-1 &lt; 0U<br>2147483647 &gt; -2147483647 - 1<br>2147483647U &gt; -2147483647 - 1<br><br><br><img alt="Pasted image 20240331205317.png" src="\lib\media\pasted-image-20240331205317.png"><br><img alt="Pasted image 20240331205352.png" src="\lib\media\pasted-image-20240331205352.png"><br>这部分代码是程序的main函数的汇编代码。在大致分析下，我们可以明确它的步骤：<br>
<br>前3行（endbr64，push %rbp，mov %rsp,%rbp）为函数的初始化步骤。在一个C函数调用开始时，它首先会保存基指针寄存器（%rbp）的值，然后将栈指针寄存器（%rsp）的值赋给基指针寄存器。这是因为要为函数的局部变量和可能的函数调用做准备，在X86-64架构中，函数调用会改变栈，用这种方式可以在函数调用中保持一个稳定的栈基准。
<br>sub $0x10,%rsp&nbsp;这行是在栈上分配空间以存储局部变量。每个变量分配4个字节（32位）存储空间。
<br>接着有两个movl指令，将两个32位的值存储到分配的局部变量空间中。第一个值是0xffffffff（十进制表示为-1），第二个值是0x80000000（十进制表示为2147483648）。这部分堆栈空间的地址分别是-0x8(%rbp)和-0x4(%rbp)，相对于当前的基指针寄存器的位置。
<br>之后是几个用于移动数据和地址的语句（mov&nbsp;和&nbsp;lea），准备数据供printf函数打印。printf@plt是一个调用printf函数的指令，plt代表程序链接跳转表，用于实现共享库的动态链接。
<br>nop,&nbsp;leave,&nbsp;ret这些指令用于清理调用栈并从函数返回。nop是无操作指令；leave将清理栈帧，即恢复栈指针和基指针寄存器到函数调用前的状态；ret则表示函数结束，返回到调用该函数的那个地方去。
<br><br><br><img alt="Pasted image 20240331212528.png" src="\lib\media\pasted-image-20240331212528.png"><br>这里的movl对应了每一次的赋值操作。如movl $0x0,-0x10(%rbp)：代表数0x0移动到相对于基址指针（%rbp）的偏移量为-0x10的内存地址处。<br>这里的地址位置对应关系如下：<br><br>数值关系对应如下：<br><br>int 与unsigned int参与运算或者比较大小时，int 均转为unsigned int型。<br>赋值运算是将数值先编译成补码，然后根据数据类型（每一个数据类型可以看成一种映射，将数值的补码映射到一个意义。比如同样的2147483648，去补码得0x80000000，对于int这会表示为-2147483648，unsigned int则为2147483648）<br>
<img alt="Pasted image 20240408104857.png" src="\lib\media\pasted-image-20240408104857.png">]]></description><link>technology\collegeproject\计算机系统基础\计算机系统基础实验报告\2计算机系统基础实验报告二.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/计算机系统基础实验报告/2计算机系统基础实验报告二.md</guid><pubDate>Mon, 08 Apr 2024 02:48:58 GMT</pubDate><enclosure url="lib\media\pasted-image-20240331205317.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240331205317.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[3计算机系统基础实验报告三]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/操作系统" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统</a> 
 <br><a href=".?query=tag:科技\操作系统" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统</a><br><br><br>
<br>
熟悉和掌握计算机中数据的位运算；

<br>
熟悉和掌握计算机中补码运算。

<br><br>
<br>写出实验过程（重要步骤用屏幕截图表示）；
<br>提交源程序；
<br>分析或回答问题。
<br><br>完成表1和表2中列出的各函数功能：位操作、补码运算实验，要求编程实现，并能对函数的功能进行验证：<br><br>表1列出了一组位操作函数。“功能”栏给出函数应实现的输出（即功能），“约束条件”栏指出函数实现必须满足的编码规则，“最多操作符数量”指出设计的函数实现中允许使用的操作符的最大数量，编写函数实现对应功能，并进行验证分析。<br>表1 位操作题目列表<br><br><br>表2列出了设计的程序中一组使用整数的补码表示的函数，编写函数实现对应功能，并进行验证分析。<br>表2 补码运算题目<br><br><br><br>
<br>!： 表示逻辑非操作符，当操作数为真时,result为0。否则，result 的值为 1。
<br>~： 表示按位非操作符，对操作数的每一位执行反转操作。
<br>&amp;： 表示按位与操作符，如果两个相应的二进制位都为1，那么结果为1，否则为0。
<br>^： 表示按位异或操作符，如果两个相应的二进制位值相同则为0，不同则为1。
<br>|： 表示按位或操作符，如果两个相应的二进制位有一个为1，则结果为1，否则为0。
<br>+： 表示加法操作符，用于将两个操作数相加。
<br>&lt;&lt;： 表示左移操作符，将左操作数的二进制位向左移动指定的位数。在每次移动后，右侧空出的新位都填充为0。
<br>&gt;&gt;： 表示右移操作符，将左操作数的二进制位向右移动指定的位数。在每次移动后，左侧空出的新位都填充为0或1（取决于数字的符号）。
<br><br><a rel="noopener nofollow" class="external-link" href="https://oi-wiki.org/lang/op/#c-%E8%BF%90%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E7%BA%A7%E6%80%BB%E8%A1%A8" target="_blank">https://oi-wiki.org/lang/op/#c-%E8%BF%90%E7%AE%97%E7%AC%A6%E4%BC%98%E5%85%88%E7%BA%A7%E6%80%BB%E8%A1%A8</a><br><br><br>int LsbZero0(int x){//只有末尾为1可用

    return x &amp; (x - 1);

}

int LsbZero(int x){

    return x &amp; (~1);

}

<br><br><img alt="Pasted image 20240408145814.png" src="\lib\media\pasted-image-20240408145814.png"><br><br><br>int byteNot(int x,int n){

    return x^(0xff&lt;&lt;(n&lt;&lt;3));

}
<br><br><img alt="Pasted image 20240408145610.png" src="\lib\media\pasted-image-20240408145610.png"><br><br><br>int byteXor(int x,int y,int n){

    return !!((x&amp;(0xff&lt;&lt;(n&lt;&lt;3)))^(y&amp;(0xff&lt;&lt;(n&lt;&lt;3))));

}
<br><br><img alt="Pasted image 20240408152110.png" src="\lib\media\pasted-image-20240408152110.png"><br><br>表达式!!(x)是一个经常使用的技巧，主要用于将任何非零整数转换为1，而保持0的值不变。<br>首先，为什么会这样呢？在C语言（以及许多其他语言）中，对于逻辑运算，任何非零的值都被视为真，而0被视为假。<br>!&nbsp;是逻辑非操作符，它会将其操作数的逻辑值求反。也就是说，如果x非零（代表真），!x就会变为0（假）；如果x是0（假），!x则为1（真）。<br>然后再次使用!操作符，再次求反。因此，!!(x)，如果x非零（真），!!x就会变回为1（真）；如果x是0（假），!!x仍然为0（假）。这样，我们就实现了将所有非零值转换为1，而保持0不变的目的。<br><br><br>int logicalAnd(int x,int y){

    return !!(x) &amp; !!(y);

}
<br><br><img alt="Pasted image 20240408172324.png" src="\lib\media\pasted-image-20240408172324.png"><br><br><br>int logicalOr(int x,int y){

    return !!(x) | !!(y);

}
<br><br><img alt="Pasted image 20240408172326.png" src="\lib\media\pasted-image-20240408172326.png"><br><br><br>int rotateLeft(int x,int n){

    return (x &lt;&lt; n) | (x &gt;&gt; (32 + (~n + 1))&amp;((1&lt;&lt;n)+(~1+1)));//取反加一表示减法

}
<br><br>这里确保了移动的位数超过整数的有效数据位部分（n位）会被屏蔽掉。(1 &lt;&lt; n)得到的是将1左移n位之后的值，在此基础上加上1，然后再取反，得到的是一个从最高位开始，前32-n位为0，后n位为1的掩码（mask）。此掩码的作用在于只关注高位32-n位的数据，屏蔽掉x移动出范围的低n位数据。<br><br><img alt="Pasted image 20240408180810.png" src="\lib\media\pasted-image-20240408180810.png"><br><br><br><br>int parityCheck(int x){

    x ^= x &gt;&gt; 16;

    x ^= x &gt;&gt; 8;

    x ^= x &gt;&gt; 4;

    x ^= x &gt;&gt; 2;

    x ^= x &gt;&gt; 1;

    return x &amp; 1;

}
<br>通过不断的折半对比，让相对的一组1归零，如果最后一位剩下0,那么代表所有的1都被消掉，即为偶数个，如果最后一位剩下1，那么为奇数个1，与上1，即可取出最后一位。<br><br><img alt="Pasted image 20240408184620.png" src="\lib\media\pasted-image-20240408184620.png"><br><br><br><br>int mul2OK(int x){
    return (((x^(x&lt;&lt;1))&gt;&gt;31)&amp;1)^1;
}
<br>^1--&gt;取反<br>
^0--&gt;不变<br>
&amp;1--&gt;取最低位<br>
位运算优先级高于按位与、或和异或<br><br><img alt="Pasted image 20240414110309.png" src="\lib\media\pasted-image-20240414110309.png"><br><br><br>int mult3div2(int x){
    int y=x,z;
    z=y=y+(y&lt;&lt;1);
    z=z&gt;&gt;31;
    return ((~z)&amp;(y&gt;&gt;1))+(z&amp;((y&gt;&gt;1)+(y&amp;1)));
}
<br><br><img alt="Pasted image 20240414111052.png" src="\lib\media\pasted-image-20240414111052.png"><br><br><br>int subOK(int x,int y){
    int z=(x+~y+1)&gt;&gt;31;\
    y=y&gt;&gt;31;
    x=x&gt;&gt;31;
    return !((!(y^z))&amp;(x^y));
}
<br><br><img alt="Pasted image 20240414112344.png" src="\lib\media\pasted-image-20240414112344.png"><br><br><br>int subOK(int x,int y){
    int z=(x+~y+1)&gt;&gt;31;\
    y=y&gt;&gt;31;
    x=x&gt;&gt;31;
    return !((!(y^z))&amp;(x^y));
}
<br><br><img alt="Pasted image 20240414112716.png" src="\lib\media\pasted-image-20240414112716.png"><br><br><br>int absVal(int x){
    int y=x;
    y=y&gt;&gt;31;
    return ((~y)&amp;x)+(y&amp;(~x+1));
}
<br>用((~y&amp;x)+(y&amp;(~x+1)）表示一个if判断y表示条件，&amp;后面跟上不同条件对应的操作。<br><br><img alt="Pasted image 20240414112631.png" src="\lib\media\pasted-image-20240414112631.png">]]></description><link>technology\collegeproject\计算机系统基础\计算机系统基础实验报告\3计算机系统基础实验报告三.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/计算机系统基础实验报告/3计算机系统基础实验报告三.md</guid><pubDate>Fri, 06 Dec 2024 06:11:29 GMT</pubDate><enclosure url="lib\media\pasted-image-20240408145814.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240408145814.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[4计算机系统基础实验报告四]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/操作系统" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统</a> 
 <br><a href=".?query=tag:科技\操作系统" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统</a> <br><br><br>
<br>熟悉浮点数值数据在计算机内部的表示方式;
<br>掌握相关的处理语句。
<br><br>
<br>写出实验过程（重要步骤用屏幕截图表示）；
<br>提交源程序；
<br>分析或回答问题。
<br><br>
<br>以下是函数fpower2的C语言源程序（不完整），它用于计算2x的浮点数表示，其中调用了函数u2f，u2f用于将一个无符号整数表示的0/1序列作为float函数返回。请根据题目要求编写出完整的fpower2函数，以使其能正确计算结果。<br>
提交代码，并在程序中以十六进制形式打印变量u的机器数。
<br>float fpower2(int x)
{
    unsigned exp, frac, u;
    if (x&lt;             ) {  /* 值太小，返回0.0 */
        exp=         ; 
        frac=        ;
    } else if (x&lt;           ) { /* 返回非规格化结果 */
        exp=         ; 
        frac=        ;
	} else if (x&lt;           ) { /* 返回规格化结果 */
        exp=         ; 
        frac=        ;
	} else  {  /* 值太大，返回 +∞ */
        exp=         ; 
        frac=        ;
	}
	u=exp&lt;&lt;23 | frac;
	return u2f(u);
}

float u2f(unsigned x) 
{ return *(float *)&amp;x; }
<br>编译运行以下程序，并至少重复运行<br>void main()
{   
	double  x=23.001,  y=24.001,  z=1.0;
	for (int i=0; i&lt;10; i++) {
		if ((y-x)==z)
		 		printf("equal\n");
		else 
			printf("not equal\n");
	    x += z; 	
		y += z; 
		printf("%d, %f , %f\n”, i, x, y);  
	}
} 
<br>要求：<br>
（1）给出每次运行的结果截图。<br>
（2）每次运行过程中，是否每一次循环中的判等结果都一致？为什么？<br>
（3）每次运行过程中，每一次循环输出的i、x和y的结果分别是什么？为什么？<br>
提示: 可以更改输出的浮点数有效位数个数进行观察<br><br><br>#include&lt;stdio.h&gt;
float u2f(unsigned x) 
{ 
    return *(float *)&amp;x; 
}

float fpower2(int x) 
{
    unsigned exp, frac, u;
    /* 指数的偏置值是127 */
    if (x &lt; -149) { /* 值太小，返回0.0 */
        exp = 0; 
        frac = 0;
    } else if (x &lt; -126) { /* 返回非规格化结果 */
        exp = 0; 
        frac = 1 &lt;&lt; (x + 149);
    } else if (x &lt; 128) { /* 返回规格化结果 */
        exp = x + 127; 
        frac = 0;
    } else { /* 值太大，返回+∞ */
        exp = 255; 
        frac = 0;
    }
    u = exp &lt;&lt; 23 | frac;//指数尾数合并
    printf("The hexadecimal form of variable u: %x\n", u);
    return u2f(u);
}


int main() 
{
    int x = 5; 
    float result = fpower2(x);
    printf("2 to the power %d is %.2f\n", x, result);
    return 0;
}
<br><br><img alt="Pasted image 20240505170718.png" src="\lib\media\pasted-image-20240505170718.png"><br><br><br>#include&lt;stdio.h&gt;
void main()
{   
    double  x=23.001,  y=24.001,  z=1.0;
    for (int i=0; i&lt;10; i++) {
        if ((y-x)==z)
		 	printf("equal\n");
        else 
            {
                printf("not equal\n");
                printf("%d, %.16f , %.16f\n", i, x, y);  
            }
	    x += z; 	
        y += z; 
        printf("%d, %f , %f\n", i, x, y);  
    }
} 

<br><br><img alt="Pasted image 20240505171653.png" src="\lib\media\pasted-image-20240505171653.png"><br><br>非规格化浮点数（也称为次正规数）是IEEE 754浮点数标准中，用来表示接近0的浮点数的一种特殊形式。<br>
在IEEE 754单精度浮点数标准中，一个浮点数通常表示为 (-1)^(符号位)  1.(尾数)  2^(指数-127)。这种形式被称为规格化形式。规格化形式的一个重要属性是，浮点数的尾数部分始终以1开头（即1.xxxx...）。根据这个性质，我们可以省略这个“隐藏的1”，只需存储小数点后面的部分。<br>
然而，对于接近0的非常小的浮点数，我们可能需要一个负的指数，这比规格化形式所能表示的最小指数-126（8位指数部分全为0，加上偏置-127）还要小。为了能表示这些接近0的非常小的数，IEEE 754标准引入了非规格化形式。<br>
当指数部分全为0时，我们说这个浮点数是非规格化的。此时，浮点数的表示形式变成了 (-1)^(符号位)  0.(尾数)  2^(1-127)。注意这里尾数的开头没有隐藏的1了，因此尾数前面是0，这使得我们可以表示一个更小的数。<br>
非规格化浮点数的引入有效地扩展了浮点数的表示范围，使得接近0的非常小的浮点数也能被精确地表示出来。<br>设想一下，我们想要表示浮点数 0.000000000000000000000000000000000000001234 在IEEE 754单精度浮点数标准中。这是一个接近于0的非常小的数，如果我们尝试用规格化形式表示，我们会发现其对应的指数比-126还要小，这会超出指数所能表示的最小值。所以，我们必须使用非规格化形式来表示这个数。<br>
在这种情况下，浮点数的表示形式变为 (-1)^(符号位)  0.(尾数)  2^(1-127)。由于我们要表示的数大于0，所以符号位为0。即使我们把尾数所有的位都设为1，也只能得到一个 0.9999999... ，然后乘以 2^(1-127) ，得到的仍然是一个非常接近于0的数，但这个数大于我们原本要表示的数 0.000000000000000000000000000000000000001234 。因此，尾数并不会是全1，尾数会是一个小于0.9999999...的数，以使得乘以2^(1-127)后接近于我们要表示的数。<br>
所以我们可以说，0.000000000000000000000000000000000000001234 在IEEE 754单精度浮点数标准中的表示形式将是非规格化的。]]></description><link>technology\collegeproject\计算机系统基础\计算机系统基础实验报告\4计算机系统基础实验报告四.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/计算机系统基础实验报告/4计算机系统基础实验报告四.md</guid><pubDate>Sun, 05 May 2024 09:59:10 GMT</pubDate><enclosure url="lib\media\pasted-image-20240505170718.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240505170718.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[5计算机系统基础实验报告五]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/操作系统" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统</a> 
 <br><a href=".?query=tag:科技\操作系统" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统</a><br><br><br>（1）分析同一个源程序在不同机器上生成的可执行目标代码是否相同。 提示：从多个方面（如ISA、OS 和编译器）来分析。<br>源程序在不同机器上生成的可执行目标代码可能是不同的，这可能由以下几个因素决定：

指令集体系结构（ISA）: 不同的机器可能具有不同的处理器类型，例如Intel的x86与x64、ARM等，这些处理器使用不同的指令集。不同的指令集可以执行不同的机器代码，这意味着即使源代码相同，不同指令集的机器生成的目标代码也会不同。

操作系统（OS）: 不同的操作系统有不同的系统调用和库函数。例如，Linux和Windows操作系统执行文件读写操作的方法就不同。在Windows系统中，它可能链接到Windows的动态链接库（dll），而在Linux系统中，它可能链接到Linux中的共享对象（so）文件。这将影响可执行文件的结构和内容。

编译器: 各种编译器（如GCC、Clang、MSVC等）对程序的理解和优化策略可能不同，即使在相同的操作系统和指令集下，不同的编译器也可能会产生不同的机器代码。实际上，编译器设计者会做出一些什么特性应该被优先加速的决策，这会影响到生成的代码。

优化级别：在编译源代码时，可以选择不同的优化级别（通常在编译命令中用-O标志标出）。不同的优化级别会导致不同的目标代码生成。例如，-O0优化级别几乎不进行任何优化，而-O3则进行许多复杂的代码变换和优化以提高性能，生成的目标代码可能会相差很大。

静态库和动态库的链接：静态库会在编译时将代码包含在生成的可执行文件中，这会使得在不同机器上生成的目标文件不同。而动态链接库（Linux中的.so文件，Windows中的.dll文件）会在运行时动态加载，相比之下，这会使得可执行文件在不同机器上更趋于一致。
<br>（2）你能在可执行目标文件中找出函数printf ()对应的机器代码段吗？能的话，请标示出来。<br>
<img alt="Pasted image 20240513173618.png" src="\lib\media\pasted-image-20240513173618.png"><br>（3）为什么源程序文件的内容和可执行目标文件的内容完全不同？<br>源程序文件是用某种程序设计语言编写的，其内容是人类可以直接阅读和理解的。这是软件开发人员使用程序设计语言编写的程序代码，用于描述对系统的需求和功能。这种格式易于编程者编写、阅读、修改和理解。
然而，计算机不能直接理解和执行这些源代码，因为计算机只能识别和执行机器指令，这些指令是由二进制代码组成的。因此，我们需要编译器将源代码翻译成机器指令，形成可执行目标文件。
编译器在这个过程中会进行一些优化步骤，例如消除冗余代码，简化计算表达式，重新组织代码顺序等，这样可以让生成的机器代码更高效地执行。编译后的机器指令通常并不能直接对应原来的源代码。所以，当你查看可执行目标文件时，你会发现它的内容与源程序文件的内容完全不同。
另外，可执行目标文件还会包括静态库或动态库链接的信息，以及程序的元数据，这些信息是在编译和链接过程中加入的，无法在源程序文件中找到。
<br><br><img alt="Pasted image 20240513175858.png" src="\lib\media\pasted-image-20240513175858.png"><br><br><br><img alt="Pasted image 20240513174753.png" src="\lib\media\pasted-image-20240513174753.png"><br><br><img alt="Pasted image 20240513174945.png" src="\lib\media\pasted-image-20240513174945.png"><br><br><img alt="Pasted image 20240513175025.png" src="\lib\media\pasted-image-20240513175025.png"><br><br><img alt="Pasted image 20240513175139.png" src="\lib\media\pasted-image-20240513175139.png"><br><br><img alt="Pasted image 20240513175732.png" src="\lib\media\pasted-image-20240513175732.png">]]></description><link>technology\collegeproject\计算机系统基础\计算机系统基础实验报告\5计算机系统基础实验报告五.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/计算机系统基础实验报告/5计算机系统基础实验报告五.md</guid><pubDate>Mon, 13 May 2024 09:59:00 GMT</pubDate><enclosure url="lib\media\pasted-image-20240513173618.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240513173618.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[6计算机系统基础实验报告六]]></title><description><![CDATA[ 
 <br><br>熟悉可重定位目标文件和可执行目标文件的格式，理解链接中引用符号的重定位实现。<br><br>1.说明实验的过程（重要步骤用屏幕截图表示）；<br>
2.提交源程序；<br>
3.分析或回答问题。<br><br><br><br>首先，我们编写两个源文件 swap.c 和 main.c。<br>swap.c:<br>void swap(void);
int buf[2]={1,2};
int main()
{
  swap();
  return 0;
}
<br>main.c:<br>extern int buf[];
int *bufp0=&amp;buf[0];
static int *bufp1;
void swap()
{  
  int temp;
  bufp1=&amp;buf[1];
  temp=*bufp0;
  *bufp0=*bufp1;
  *bufp1=temp;
}
<br><br>使用 gcc 编译这两个源文件为可重定位目标文件：<br>gcc -c swap.c -o swap.o
gcc -c main.c -o main.o
<br><br>使用 gcc 链接两个目标文件生成可执行文件：<br>gcc swap.o main.o -o executable
<br><br>使用 objdump 生成可重定位目标文件和可执行目标文件的反汇编代码：<br>objdump -d swap.o &gt; swapo.txt
objdump -d main.o &gt; maino.txt
objdump -d executable &gt; main.txt
<br><br>使用 readelf 生成可重定位目标文件和可执行目标文件的ELF文件格式信息：<br>readelf -a swap.o &gt; swapoelf.txt
readelf -a main.o &gt; mainoelf.txt
readelf -a executable &gt; mainelf.txt
<br><br>源程序已经在上面的步骤中展示。<br>
<img alt="Pasted image 20240611061001.png" src="\lib\media\pasted-image-20240611061001.png"><br><img alt="Pasted image 20240611061026.png" src="\lib\media\pasted-image-20240611061026.png"><br><br><br>从生成的 ELF 文件中，可以识读出以下重要信息：<br>
<br>ELF头：描述了文件的基本属性，如字长、字节序、入口地址等。<img alt="Pasted image 20240611061256.png" src="\lib\media\pasted-image-20240611061256.png">
<br>节头表：列出了所有的节（section），包括 .text、.data、.bss、.rodata 等节的起始地址、大小等。<img alt="Pasted image 20240611061310.png" src="\lib\media\pasted-image-20240611061310.png">
<br>程序段头表：列出了所有的程序段（segment），这些段将被加载到内存中运行。<img alt="Pasted image 20240611061336.png" src="\lib\media\pasted-image-20240611061336.png">
<br><br>通过阅读 swapoelf.txt 和 mainoelf.txt，可以识别出 swap.c 和 main.c 中的符号定义和引用。<br>
<br>swap.c 定义了 buf 和 main 符号，并引用了 swap 符号。
<br>main.c 定义了 swap 符号，并引用了 buf 符号。
<br><br>对比 swapo.txt、maino.txt 和 main.txt 中 .text 节的内容，可以看到在可重定位目标文件中，涉及符号的指令需要在链接时被重定位（例如，调用 swap 函数的指令），而在可执行文件中，这些指令已经被重定位到正确的地址。<br>
maino.txt,链接文件在链接另外两个文件后同时链接了其他静态库<br><br>对比 swapo.txt、maino.txt 和 main.txt 中 .data 节的内容，可以看到在可重定位目标文件中，数据的地址是相对地址，而在可执行文件中，这些地址已经被转换为绝对地址。<br><br>通过本次实验，我们熟悉了可重定位目标文件和可执行目标文件的格式，理解了链接过程中引用符号的重定位实现。具体地，通过 objdump 和 readelf 工具，我们深入分析了目标文件的各个部分，并识别了符号定义和引用的方式。这些步骤和分析使我们更好地理解了编译、链接和可执行文件生成的整个过程。]]></description><link>technology\collegeproject\计算机系统基础\计算机系统基础实验报告\6计算机系统基础实验报告六.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/计算机系统基础实验报告/6计算机系统基础实验报告六.md</guid><pubDate>Mon, 10 Jun 2024 22:17:21 GMT</pubDate><enclosure url="lib\media\pasted-image-20240611061001.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240611061001.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[基础课程及文档]]></title><description><![CDATA[ 
 <br><br><a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1Xm411f7CM/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1Xm411f7CM/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">01-操作系统概述 [南京大学2024操作系统]_哔哩哔哩_bilibili</a><br><br><a data-tooltip-position="top" aria-label="https://nju-projectn.github.io/ics-pa-gitbook/ics2021/FAQ.html" rel="noopener nofollow" class="external-link" href="https://nju-projectn.github.io/ics-pa-gitbook/ics2021/FAQ.html" target="_blank">https://jyywiki.cn/OS/2024/</a><br><br><a data-tooltip-position="top" aria-label="https://nju-projectn.github.io/ics-pa-gitbook/ics2019/" rel="noopener nofollow" class="external-link" href="https://nju-projectn.github.io/ics-pa-gitbook/ics2019/" target="_blank">[为什么要学习计算机系统基础 · GitBook (nju-projectn.github.io)](https://nju-projectn.github.io/ics-pa-gitbook/ics2019/why.html)</a><br><br>系统层面的认知和设计能力：<br>
<br>能够对软, 硬件功能进行合理划分
<br>能够对系统不同层次进行抽象和封装
<br>能够对系统的整体性能进行分析和调优
<br>能够对系统各层面的错误进行调试和修正
<br>能够根据系统实现机理对用户程序进行准确的性能评估和优化
<br>能够根据不同的应用要求合理构建系统框架
<br>对整个计算机系统实现机理的认识：<br>
<br>对计算机系统整机概念的认识
<br>对计算机系统层次结构的深刻理解
<br>对高级语言程序, ISA, OS, 编译器, 链接器等之间关系的深入掌握
<br>对指令在硬件上执行过程的理解和认识
<br>对构成计算机硬件的基本电路特性和设计方法等的基本了解等 从而能够更深刻地理解时空开销和权衡, 抽象和建模, 分而治之, 缓存和局部性, 吞吐率和时延, 并发和并行, 远程过程调用(RPC), 权限和保护等重要的核心概念, 掌握现代计算机系统中最核心的技术和实现方法
<br><br>提问：<br>
<a data-tooltip-position="top" aria-label="https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/main/README-zh_CN.md" rel="noopener nofollow" class="external-link" href="https://github.com/ryanhanwu/How-To-Ask-Questions-The-Smart-Way/blob/main/README-zh_CN.md" target="_blank">How-To-Ask-Questions-The-Smart-Way/README-zh_CN.md at main · ryanhanwu/How-To-Ask-Questions-The-Smart-Way · GitHub</a><br>讲义资料：<br>
<a data-tooltip-position="top" aria-label="https://nju-projectn.github.io/ics-pa-gitbook/ics2024/1.3.html" rel="noopener nofollow" class="external-link" href="https://nju-projectn.github.io/ics-pa-gitbook/ics2024/1.3.html" target="_blank">RTFSC · GitBook (nju-projectn.github.io)</a><br>课程讲解：<br>
<a data-tooltip-position="top" aria-label="http://why.ink:8080/ICS/2023/" rel="noopener nofollow" class="external-link" href="http://why.ink:8080/ICS/2023/" target="_blank">计算机系统基础习题课 (2023 秋季学期) (why.ink)</a>]]></description><link>technology\collegeproject\计算机系统基础\pa\基础课程及文档.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/PA/基础课程及文档.md</guid><pubDate>Sun, 24 Mar 2024 03:28:58 GMT</pubDate></item><item><title><![CDATA[PA]]></title><description><![CDATA[ 
 <br><br>
<br><a data-href="Technology/CollegeProject/计算机系统基础/PA/基础课程及文档" href="\technology\collegeproject\计算机系统基础\pa\基础课程及文档.html" class="internal-link" target="_self" rel="noopener nofollow">Technology/CollegeProject/计算机系统基础/PA/基础课程及文档</a>
<br><a data-href="Technology/CollegeProject/计算机系统基础/PA/PA0" href="\technology\collegeproject\计算机系统基础\pa\pa0.html" class="internal-link" target="_self" rel="noopener nofollow">Technology/CollegeProject/计算机系统基础/PA/PA0</a>
<br><a data-href="Technology/CollegeProject/计算机系统基础/PA/PA1" href="\technology\collegeproject\计算机系统基础\pa\pa1.html" class="internal-link" target="_self" rel="noopener nofollow">Technology/CollegeProject/计算机系统基础/PA/PA1</a>
]]></description><link>technology\collegeproject\计算机系统基础\pa\pa.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/PA/PA.md</guid><pubDate>Fri, 06 Dec 2024 06:11:09 GMT</pubDate></item><item><title><![CDATA[Linux基础]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具/Linux" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/Linux</a> <a class="tag" href="?query=tag:科技/操作系统/PA" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统/PA</a> <a class="tag" href="?query=tag:科技/工具/Linux" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/Linux</a> <a class="tag" href="?query=tag:科技/PA" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/PA</a> <a class="tag" href="?query=tag:科技/工具/Linux" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/Linux</a> <a class="tag" href="?query=tag:科技/PA" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/PA</a> <a class="tag" href="?query=tag:科技/PA" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/PA</a> <a class="tag" href="?query=tag:科技/工具/Linux" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/Linux</a> <a class="tag" href="?query=tag:科技/PA" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/PA</a> 
 <br><br><br><a href=".?query=tag:科技\工具\Linux" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/Linux</a><br>
<a href=".?query=tag:科技\操作系统\PA" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统/PA</a><br>
<a data-tooltip-position="top" aria-label="https://blog.csdn.net/wkw1125/article/details/53932945" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/wkw1125/article/details/53932945" target="_blank">shell、cmd、dos和脚本语言_dos是cmd吗-CSDN博客</a><br>dg-publish<br><br>操作系统可以分成核心（kernel）和Shell（外壳）两部分，其中，Shell是操作系统与外部的主要接口，位于操作系统的外层，为用户提供与操作系统核心沟通的途径。Shell是一个命令解释器(也是一种应用程序)，处于内核和用户之间，负责把用户的指令传递给内核并且把执行结果回显给用户。同时，shell也可以作为一门强大的编程语言。<br>
Shell分为图形界面shell和命令行shell两大类，如Windows的资源管理器explorer.exe和cmd命令窗口。不同系统有不同的shell，如bash、C shell、windows power shell 等等；在linux系统中，通常是Bourne Again shell ( 即bash)。<br><br>在windows系统中见到的桌面即explorer.exe（资源管理器）是图形shell，而cmd就是命令行shell，而dos本身就是一个系统，这算是cmd与dos的最大区别：一个只是接口、一个是操作系统。只是cmd中的某些命令和dos中的命令相似，因此很多人把二者混为一谈。cmd属于windows系统的一部分，dos本身就是一个系统，在dos系统下可以删除，修复windows系统，而在cmd下则不行。<br><br>在linux/unix平台上，Shell有多种实现，目前多数Linux发行版本默认是bash，即Bourne Again shell。<br>
在Windows平台上，cmd是Command shell的简写，是一个独立的应用程序，它为用户提供对操作系统直接通信的功能，它为基于字符的应用程序和工具提供了非图形界面的运行环境，它执行命令并在屏幕上回显MS-DOS风格的字符。<br>
所以，可以近似地认为linux shell=bash而windows shell=cmd，都是命令行解释器，都是用户与操作系统的交互接口。但是bash要比cmd强大很多，windows也有强大的shell叫windows power shell。<br>
psWindows系统接受shell命令的程序是cmd命令行窗口；而Linux发行版ubuntu中对应的程序是terminal终端。<br><br>编程语言“编写-编译-链接-运行”（编译型），脚本语言是“解释-执行”（解释型）。脚本语言的程序代码即使最终的可执行文件，通过对应的解释器解释执行即可，所以更方便快捷。每种脚本语言都需要其对应的解释器。如Perl、Python、Ruby、JavaScript等都是脚本语言，shell也属于一种比较特殊的脚本语言。<br><br>bash是Linux和Unix下的shell，如果真的想试用，可以在MS windows下安装Cygwin环境，然后再在其下使用。 这时需要注意，Cygwin环境下跟真实的Linux或Unix是有区别的，一些命令会运行不正常。最直接的体验，还是使用Linux来得贴心，几乎可以做任何事情。如果想在MS Windows下使用Shell，建议还是使用微软的PowerShell，它能提供给你操作MS windows的完全功能。<br>需要了解两个命令<br>
盘符: 例如想进入D盘 d:<br>
cd 进入到当前盘某个目录。<br>
cd \ 进入当前盘根目录<br>
cd \windows 进入到当前盘Windows目录<br>
cd.. 退出到上<a data-tooltip-position="top" aria-label="https://www.baidu.com/s?wd=%E4%B8%80%E7%BA%A7%E7%9B%AE%E5%BD%95&amp;tn=SE_PcZhidaonwhc_ngpagmjz&amp;rsv_dl=gh_pc_zhidao" rel="noopener nofollow" class="external-link" href="https://www.baidu.com/s?wd=%E4%B8%80%E7%BA%A7%E7%9B%AE%E5%BD%95&amp;tn=SE_PcZhidaonwhc_ngpagmjz&amp;rsv_dl=gh_pc_zhidao" target="_blank">一级目录</a>  <br>注：进入含有<a data-tooltip-position="top" aria-label="https://www.baidu.com/s?wd=%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6&amp;tn=SE_PcZhidaonwhc_ngpagmjz&amp;rsv_dl=gh_pc_zhidao" rel="noopener nofollow" class="external-link" href="https://www.baidu.com/s?wd=%E7%89%B9%E6%AE%8A%E5%AD%97%E7%AC%A6&amp;tn=SE_PcZhidaonwhc_ngpagmjz&amp;rsv_dl=gh_pc_zhidao" target="_blank">特殊字符</a>目录时需要加引号 例如 cd "c:\program files"<br><br><a href=".?query=tag:科技\工具\Linux" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/Linux</a><br>
<a href=".?query=tag:科技\PA" class="tag" target="_blank" rel="noopener nofollow">#科技/PA</a><br>
<a data-tooltip-position="top" aria-label="https://101.lug.ustc.edu.cn/Spec/writing/" rel="noopener nofollow" class="external-link" href="https://101.lug.ustc.edu.cn/Spec/writing/" target="_blank">章节编写指导 - Linux 101 (ustc.edu.cn)</a><br><br>- 文件管理 -&nbsp;`cd`,&nbsp;`pwd`,&nbsp;`mkdir`,&nbsp;`rmdir`,&nbsp;`ls`,&nbsp;`cp`,&nbsp;`rm`,&nbsp;`mv`,&nbsp;`tar`
- 文件检索 -&nbsp;`cat`,&nbsp;`more`,&nbsp;`less`,&nbsp;`head`,&nbsp;`tail`,&nbsp;`file`,&nbsp;`find`
- 输入输出控制 - 重定向, 管道,&nbsp;`tee`,&nbsp;`xargs`
- 文本处理 -&nbsp;`vim`,&nbsp;`grep`,&nbsp;`awk`,&nbsp;`sed`,&nbsp;`sort`,&nbsp;`wc`,&nbsp;`uniq`,&nbsp;`cut`,&nbsp;`tr`
- 正则表达式
- 系统监控 -&nbsp;`jobs`,&nbsp;`ps`,&nbsp;`top`,&nbsp;`kill`,&nbsp;`free`,&nbsp;`dmesg`,&nbsp;`lsof`
- 上述工具覆盖了程序员绝大部分的需求
- 可以先从简单的尝试开始, 用得多就记住了, 记不住就`man`
<br><br>- 例如，你有一个文件叫`file1.txt`，你想把它重命名为`file2.txt`，你可以使用以下命令：
<br>mv file1.txt file2.txt
<br>如果你想重命名的文件在其他文件夹中，只需要在文件名前添加完整的路径即可，例如：<br>mv /path/to/your/oldname /path/to/your/newname
<br><br>
<br>curl -O [链接地址]
<br><br>mv targetfile destination_directory
<br>例如：<br>mv example.txt /home/user/documents
<br><br>在Linux系统中，man命令是用来查阅手册页(manual pages)的工具。你可以用这个命令来查看系统命令、系统调用、库函数等的使用手册。<br>
使用man命令的基本格式如下：<br>man command_name
<br>其中的command_name替换为你要查询的命令、函数或者文件名。例如，如果你想查阅ls命令的手册页，你可以输入：<br>man ls
<br>这将显示出ls命令的全面详细说明，包括它的描述、选项和用法等。<br>在手册页中，你可以使用上下箭头键来滚动文本，使用/来搜索文本，使用q来退出查看。<br>需要注意的是，man命令显示的内容可能会非常多，如果你只想快速查询某个命令的用法，可以考虑使用--help参数或-h参数来查看命令的简短帮助信息，如：<br>ls --help
<br>这个命令会输出ls命令的简洁版帮助信息，它通常会比man ls输出的内容更简单明了。<br><br>在Linux中，你可以使用chsh命令（change shell的缩写）来更改默认的shell。请按照以下步骤操作：<br>
<br>首先，确定你想要设为默认的shell的完整路径。这可以通过在终端输入命令which shell_name来完成（将shell_name替换为你想要设为默认的shell，比如bash、zsh等）。这条命令会返回shell的完整路径。 例如，如果你想把bash设为默认的shell，你可以输入： bash which bash  这可能会返回/bin/bash。
<br>然后，键入命令chsh -s full_path_to_shell（将full_path_to_shell替换为第一步中获取到的路径）。这个命令会提示你输入你的密码，然后会修改/etc/passwd文件以使更改生效。 如果以bash为例，命令如下： bash chsh -s /bin/bash 
<br>接下来，关掉终端并再次打开，或者注销并重新登录，你就会看到默认shell已经更改为你指定的那一个了。 在运行chsh命令时，如果你遇到需要管理员权限的提示，你可能需要在命令前添加sudo（即sudo chsh -s full_path_to_shell）。但是请注意，使用sudo权限运行chsh命令会更改root用户的默认shell，而不是当前用户的默认shell。因此，一般情况下，你不需要在chsh命令前添加sudo。
<br><br>vi hello_world.c
gcc hello_world.c -o hello world
./hello world
<br><br>vi Makefile
make #编译
./hello world #运行
<br>Makefile是管理编译过程的文件，它主要由规则（rules）组成。每个规则包含了一个目标（target）、依赖（dependencies）和命令（commands）。<br>
一个基本的Makefile编写格式如下：<br>target: dependencies
    commands
<br>
<br>target：目标文件，可以是可执行文件，也可以是一个中间文件（如.o文件）
<br>dependencies：目标文件所依赖的文件。只有当依赖的文件的最后修改时间比目标文件的修改时间要新，或者目标文件不存在时，才会执行后面的命令。
<br>commands：Makefile要执行的命令。必须以TAB字符开头，否则会出错。<br>
例如，以下Makefile规则会将my_program编译成一个可执行文件：
<br>my_program: my_program.c
    gcc my_program.c -o my_program
<br>这个Makefile的意思是，如果my_program.c被修改，那么make命令将执行gcc my_program.c -o my_program命令来构建新的my_program文件。<br>
注意，在Makefile中，每一行都是独立的，如果命令要分成多行写，需要在每一行的后面加上“\”。<br>
你还可以在Makefile中直接定义变量，并在规则中使用，如下面的示例：<br>CC=gcc
CFLAGS=-I.

hello: hello.c
    $(CC) -o hello hello.c $(CFLAGS)
<br>在这个示例中，我们定义了变量CC和CFLAGS，并在规则中使用了他们。$(CC)和$(CFLAGS)在执行时会被它们的值所替换。在这种情况下，make命令等价于gcc -o hello hello.c -I.。<br><br>Now, stop here.&nbsp;<a data-tooltip-position="top" aria-label="https://linuxconfig.org/gdb-debugging-tutorial-for-beginners" rel="noopener nofollow" class="external-link" href="https://linuxconfig.org/gdb-debugging-tutorial-for-beginners" target="_blank">Here</a>&nbsp;is a small tutorial for GDB. GDB is the most common used debugger under GNU/Linux. If you have not used a debugger yet (even in Visual Studio), blame the 程序设计基础 course first, then blame yourself, and finally,&nbsp;read the tutorial to learn to use GDB.<br>GDB是GNU项目的开放源代码调试器，可以用来调试C、C++等编程语言编写的程序。以下是其基本用法：<br>
<br>启动GDB：&nbsp;您可以使用以下命令启动GDB并加载你的程序：
<br>   gdb your_program
<br>如果你的程序需要传入参数，可以在启动GDB后，使用&nbsp;set args&nbsp;命令来设定：<br>   set args arg1 arg2 arg3
<br>
<br>设置断点：&nbsp;在程序运行到某个地方时暂停，你可以使用&nbsp;break&nbsp;命令（或简写&nbsp;b）来设定断点。例如，要在名为&nbsp;main&nbsp;的函数处设置断点：
<br>   break main
<br>或在特定的行设置断点：<br>   break your_file.c:42
<br>
<br>执行程序：&nbsp;使用&nbsp;run&nbsp;命令（或简写&nbsp;r）来开始执行程序。当程序执行到断点处时，它将会暂停。
<br>检查程序状态：&nbsp;当程序暂停时，你可以使用以下命令来查看程序的状态：

<br>print（简写&nbsp;p）命令，展示某个变量的值：&nbsp;print var_name
<br>backtrace（或&nbsp;bt）命令，显示函数的调用堆栈：backtrace
<br>list（或&nbsp;l）命令，显示当前执行到的源码：list


<br>控制程序执行：&nbsp;你可以使用以下命令来控制程序的执行：

<br>continue（简写&nbsp;c）： 继续执行程序，直到遇到下一个断点或程序结束。
<br>step（简写&nbsp;s）： 执行下一行代码，如果下一行代码是一个函数，就会进入该函数。
<br>next（简写&nbsp;n）： 执行下一行代码，函数调用会被当作一行整体执行。


<br>退出GDB：&nbsp;使用&nbsp;quit（或简写&nbsp;q）命令来退出GDB。
<br>以下是一些你可以设置的断点类型：<br>
<br>基础断点：&nbsp;使用break（或简写&nbsp;b）命令设置在特定函数或行号的断点：
<br>   break function
   break filename:linenumber
<br>
<br>临时断点：&nbsp;使用tbreak命令设置临时断点，这个断点只会触发一次，触发后自动删除：
<br>   tbreak function
   tbreak filename:linenumber
<br>以上是GDB的基本用法，GDB还有很多功能和复杂的用法，例如：查看内存、设置条件断点、调试多线程程序等，可以参阅GDB的官方文档或相关教程进行学习。<br><br><a href=".?query=tag:科技\工具\Linux" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/Linux</a><br>
<a href=".?query=tag:科技\PA" class="tag" target="_blank" rel="noopener nofollow">#科技/PA</a><br><br><a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/146545159" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/146545159" target="_blank">[安利] WSL Linux 子系统，真香！完整实操 - 知乎 (zhihu.com)</a><br>
4.1 升级WSL内核<br>wsl --update
<br><br>内核升级完成以后，电脑重启才会生效，这个可以用命令重启<br>wsl -l -shutdown
<br><br>wsl -l -v
<br><br><a href=".?query=tag:科技\PA" class="tag" target="_blank" rel="noopener nofollow">#科技/PA</a> <br>
<br>git branch：列出分支
<br>git add .：将改动加入commit
<br>git commit：提交commit
<br>git merge：合并分支，将分支pa？合并到主分支master上
<br>git checkout master：进入master分支
<br>git status：查看上一次commit更改
<br>git log：查看commit历史
<br>git checkout -b 新建并进入
<br><br><a href=".?query=tag:科技\工具\Linux" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/Linux</a><br>
<a href=".?query=tag:科技\PA" class="tag" target="_blank" rel="noopener nofollow">#科技/PA</a><br>
vim是一个非常强大的文本编辑器，虽然刚开始使用可能觉得有些复杂，但一旦掌握了基础，将会发现其功能和效率极高。以下是一些vim的基础编辑方法：<br>
<br>
打开和退出文件

<br>打开或创建文件:&nbsp;vim filename
<br>退出不保存修改: 按&nbsp;Esc&nbsp;完全回到普通模式, 然后输入:q!，回车即可；
<br>保存并退出: 按&nbsp;Esc&nbsp;完全回到普通模式, 然后输入:wq，回车即可。


<br>
进入插入模式：在vim打开的文件中，你可以通过以下按键进入插入模式：

<br>按&nbsp;i&nbsp;进入插入模式，从光标位置开始插入文本；
<br>按&nbsp;a&nbsp;光标后插入文本；
<br>按&nbsp;o&nbsp;光标下一行插入新行开始插入文本；
<br>按大写&nbsp;A&nbsp;光标所在行的行尾插入文本；
<br>按大写&nbsp;O&nbsp;光标所在行的行首插入新行开始插入文本；
<br>按大写&nbsp;I&nbsp;光标所在行的行首插入文本。


<br>
移动光标：在普通模式下，你可以使用以下按键来移动光标：

<br>按&nbsp;h&nbsp;光标向左移动；
<br>按&nbsp;j&nbsp;光标向下移动；
<br>按&nbsp;k&nbsp;光标向上移动；
<br>按&nbsp;l&nbsp;光标向右移动；
<br>按&nbsp;gg&nbsp;到第一行；
<br>按大写&nbsp;G&nbsp;到最后一行。


<br>
删除、复制和粘贴：

<br>按&nbsp;dd&nbsp;在普通模式下删除光标所在行；
<br>按&nbsp;yy&nbsp;在普通模式下复制光标所在行；
<br>按&nbsp;p&nbsp;的话就是把刚才删除或复制的内容粘贴在光标下一行；
<br>按大写&nbsp;P&nbsp;的话就是把刚才删除或复制的内容粘贴在光标行。


<br>
查找和替换：

<br>查找，使用/键后输入你希望查找的文本，例如/text将查找"text"；
<br>替换，可以使用:s命令, 格式为&nbsp;:s/old/new，将第一次出现的"old"替换为"new"，如果需要替换每一行的所有匹配尝试&nbsp;:s/old/new/g.


]]></description><link>technology\collegeproject\计算机系统基础\pa\pa0.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/PA/PA0.md</guid><pubDate>Mon, 08 Apr 2024 02:00:12 GMT</pubDate></item><item><title><![CDATA[写在前面（要求）]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/操作系统/PA" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统/PA</a> <a class="tag" href="?query=tag:科技/PA" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/PA</a> 
 <br><a href=".?query=tag:科技\操作系统\PA" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统/PA</a><br><br><br>&nbsp;我们其实可以从两个互补的视角来看待同一个程序:<br>
<br>一个是以代码(或指令序列)为表现形式的静态视角, 大家经常说的"写程序"/"看代码", 其实说的都是这个静态视角. 这个视角的一个好处是描述精简, 分支, 循环和函数调用的组合使得我们可以通过少量代码实现出很复杂的功能. 但这也可能会使得我们对程序行为的理解造成困难.
<br>另一个是以状态机的状态转移为运行效果的动态视角, 它直接刻画了"程序在计算机上运行"的本质. 但这一视角的状态数量非常巨大, 程序代码中的所有循环和函数调用都以指令的粒度被完全展开, 使得我们难以掌握程序的整体语义. 但对于程序的局部行为, 尤其是从静态视角来看难以理解的行为, 状态机视角可以让我们清楚地了解相应的细节.
<br><br><br><a href=".?query=tag:科技\PA" class="tag" target="_blank" rel="noopener nofollow">#科技/PA</a><br>代码中nemu/目录下的源文件组织如下(并未列出所有文件):<br>nemu
├── configs                    # 预先提供的一些配置文件
├── include                    # 存放全局使用的头文件
│   ├── common.h               # 公用的头文件
│   ├── config                 # 配置系统生成的头文件, 用于维护配置选项更新的时间戳
│   ├── cpu
│   │   ├── cpu.h
│   │   ├── decode.h           # 译码相关
│   │   ├── difftest.h
│   │   └── ifetch.h           # 取址相关
│   ├── debug.h                # 一些方便调试用的宏
│   ├── device                 # 设备相关
│   ├── difftest-def.h
│   ├── generated
│   │   └── autoconf.h         # 配置系统生成的头文件, 用于根据配置信息定义相关的宏
│   ├── isa.h                  # ISA相关
│   ├── macro.h                # 一些方便的宏定义
│   ├── memory                 # 访问内存相关
│   └── utils.h
├── Kconfig                    # 配置信息管理的规则
├── Makefile                   # Makefile构建脚本
├── README.md
├── resource                   # 一些辅助资源
├── scripts                    # Makefile构建脚本
│   ├── build.mk
│   ├── config.mk
│   ├── git.mk                 # git版本控制相关
│   └── native.mk
├── src                        # 源文件
│   ├── cpu
│   │   └── cpu-exec.c         # 指令执行的主循环
│   ├── device                 # 设备相关
│   ├── engine
│   │   └── interpreter        # 解释器的实现
│   ├── filelist.mk
│   ├── isa                    # ISA相关的实现
│   │   ├── mips32
│   │   ├── riscv32
│   │   ├── riscv64
│   │   └── x86
│   ├── memory                 # 内存访问的实现
│   ├── monitor
│   │   ├── monitor.c
│   │   └── sdb                # 简易调试器
│   │       ├── expr.c         # 表达式求值的实现
│   │       ├── sdb.c          # 简易调试器的命令处理
│   │       └── watchpoint.c   # 监视点的实现
│   ├── nemu-main.c            # 你知道的...
│   └── utils                  # 一些公共的功能
│       ├── log.c              # 日志文件相关
│       ├── rand.c
│       ├── state.c
│       └── timer.c
└── tools                      # 一些工具
    ├── fixdep                 # 依赖修复, 配合配置系统进行使用
    ├── gen-expr
    ├── kconfig                # 配置系统
    ├── kvm-diff
    ├── qemu-diff
    └── spike-diff
<br><br><br><br>在pa1将游戏rom文件mario.nes移至~/ics2022/fceux-am/nes/rom文件下，并回到~/ics2022/fceux-am下执行make ARCH=native run mainargs=mario进行编译这一步。<br>
在运行make ARCH=native run mainargs=mario遇到了问题，报错如下：<br>
An error occurred while loading the file.Exit code = ffh<br>
make: * [/home/waferen/ics2023/abstract-machine/scripts/native.mk:25: run] Error 255**<br>我检查了native.mk文件，这个文件具体的代码如下：<br>AM_SRCS := native/trm.c \
           native/ioe.c \
           native/cte.c \
           native/trap.S \
           native/vme.c \
           native/mpe.c \
           native/platform.c \
           native/ioe/input.c \
           native/ioe/timer.c \
           native/ioe/gpu.c \
           native/ioe/uart.c \
           native/ioe/audio.c \
           native/ioe/disk.c \

CFLAGS  += -fpie
ASFLAGS += -fpie -pie
comma = ,
LDFLAGS_CXX = $(addprefix -Wl$(comma), $(LDFLAGS))

image:
	@echo + LD "-&gt;" $(IMAGE_REL)
	@g++ -pie -o $(IMAGE) -Wl,--whole-archive $(LINKAGE) -Wl,-no-whole-archive $(LDFLAGS_CXX) -lSDL2 -ldl

run: image
	$(IMAGE)

gdb: image
	gdb -ex "handle SIGUSR1 SIGUSR2 SIGSEGV noprint nostop" $(IMAGE)
<br>其中第25行可能存在问题，这行代码如下：	$(IMAGE)<br>
即链接文件IMAGE可能存在问题。我想问下这个问题是否是因为IMAGE文件权限不够，没有能成功执行还是其他原因。如果是的话应该如何修改链接文件的权限呢？<br><br>发现.tar.bz2文件没有解压，应该将解压得到的nes文件放入rom文件夹。<br>
在解压得到的文件当中，mario.nes仍无法运行出正常画面，但mario3.nes却可以。初步判定mario.nes文件有问题。<br><br>今天解决了内存扫描的基本代码，再一次RTFSC。<br>
但是还有问题尚未解决：<br>
<br>#include "nemu/include/memory/paddr.h"头文件无法引用不知道原因。
]]></description><link>technology\collegeproject\计算机系统基础\pa\pa1.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/PA/PA1.md</guid><pubDate>Fri, 06 Dec 2024 06:11:29 GMT</pubDate></item><item><title><![CDATA[计算机系统基础复习]]></title><description><![CDATA[ 
 <br> 第1章计算机系统概论 1.pptx<br>
 第2章数据的机器级表示与处理.pptx<br>
 第3章程序的转换与机器级表示.pptx<br>
 2024-第4章程序的链接-上课.pptx<br><br><br><img alt="Pasted image 20240707141353.png" src="\lib\media\pasted-image-20240707141353.png"><br><br><img alt="Pasted image 20240707141501.png" src="\lib\media\pasted-image-20240707141501.png"><br><br><img alt="Pasted image 20240707141554.png" src="\lib\media\pasted-image-20240707141554.png"><br><br><img alt="Pasted image 20240707141756.png" src="\lib\media\pasted-image-20240707141756.png"><br>
<img alt="Pasted image 20240710151121.png" src="\lib\media\pasted-image-20240710151121.png"><br><br>CPI即每条指令需要的时钟周期数<br>
<img alt="Pasted image 20240707172129.png" src="\lib\media\pasted-image-20240707172129.png"><br>
<img alt="Pasted image 20240707172935.png" src="\lib\media\pasted-image-20240707172935.png"><br>
<img alt="Pasted image 20240707201113.png" src="\lib\media\pasted-image-20240707201113.png"><br>
<br>
<br>
Timeofall=4<br>
<br><br><br><img alt="Pasted image 20240707203247.png" src="\lib\media\pasted-image-20240707203247.png"><br>
<img alt="Pasted image 20240708001451.png" src="\lib\media\pasted-image-20240708001451.png"><br><br><img alt="Pasted image 20240708001252.png" src="\lib\media\pasted-image-20240708001252.png"><br><br><img alt="Pasted image 20240708001624.png" src="\lib\media\pasted-image-20240708001624.png"><br><br><img alt="Pasted image 20240708002409.png" src="\lib\media\pasted-image-20240708002409.png"><br><br><img alt="Pasted image 20240708002926.png" src="\lib\media\pasted-image-20240708002926.png"><br>
<img alt="Pasted image 20240708002946.png" src="\lib\media\pasted-image-20240708002946.png"><br>
所以说对于带符号整数减法0111 0000 - 0110 0000=0111 0000 +(0 1000 0000-0110 0000)=0111 0000 +0010 0000(即不带符号位取反加一，即变减法为加法)<br>
<img alt="Pasted image 20240708003945.png" src="\lib\media\pasted-image-20240708003945.png"><br>
<img alt="Pasted image 20240709172416.png" src="\lib\media\pasted-image-20240709172416.png"><br>
<img alt="Pasted image 20240709172853.png" src="\lib\media\pasted-image-20240709172853.png"><br>
<img alt="Pasted image 20240709172926.png" src="\lib\media\pasted-image-20240709172926.png"><br><br><img alt="Pasted image 20240709175420.png" src="\lib\media\pasted-image-20240709175420.png"><br>
<img alt="Pasted image 20240709182303.png" src="\lib\media\pasted-image-20240709182303.png"><br><br><img alt="Pasted image 20240709195441.png" src="\lib\media\pasted-image-20240709195441.png"><br><img alt="Pasted image 20240709194245.png" src="\lib\media\pasted-image-20240709194245.png"><br><br><img alt="Pasted image 20240709195008.png" src="\lib\media\pasted-image-20240709195008.png"><br>
<img alt="Pasted image 20240709195046.png" src="\lib\media\pasted-image-20240709195046.png"><br><br><img alt="Pasted image 20240709195627.png" src="\lib\media\pasted-image-20240709195627.png"><br>
<img alt="Pasted image 20240709201157.png" src="\lib\media\pasted-image-20240709201157.png"><br>
非规格数阶码为0<br><br><img alt="Pasted image 20240709202853.png" src="\lib\media\pasted-image-20240709202853.png"><br>
<img alt="Pasted image 20240709203138.png" src="\lib\media\pasted-image-20240709203138.png"><br>
无符号：1000 0110 - 1111 0110=1000 0110+(2^8-1111 0110)=1000 0110+(0000 1010)=1001 0000  CF无符号溢出=1，OF=0,SF=1(最高位为1)<br>
带符号：1000 0110 - 1111 0110=1000 0110 +(1 0000 0000 -1111 0110)=1000 0110+0000 1010=1001 0000 加法器不知道其是补码还是原码，都是统一运算的。但是对于减一个数相当于加上这个负数的补码，对其取原码-&gt;取反加一，1110 1111+1=1111 0000<br>
-2...8=1000 0000 0000<br>
<img alt="Pasted image 20240710141402.png" src="\lib\media\pasted-image-20240710141402.png"><br>
<img alt="Pasted image 20240710131741.png" src="\lib\media\pasted-image-20240710131741.png"><br><br>字（Word）、字节（Byte）和比特（Bit）之间的换算关系以及字长的概念如下：<br><br>
<br>比特是计算机中最小的信息单位。一个比特可以表示两种状态：0或1。
<br><br>
<br>1字节（Byte）= 8比特（Bits）。
<br>字节是计算机中用于表示数据的基本单位之一。通常一个字节可以表示256种不同的状态（2^8）。
<br><br>
<br>字（Word）是计算机中处理数据的基本单位，通常由多个字节组成。字的长度（字长）因计算机的体系结构而异。
<br>常见的字长有16位（2字节）、32位（4字节）和64位（8字节）。
<br><br>
<br>字长是计算机一次能够处理的二进制数的位数。它决定了处理器的数据处理能力和计算精度。
<br>例如：

<br>一个16位字长的处理器可以一次处理16位数据。
<br>一个32位字长的处理器可以一次处理32位数据。
<br>一个64位字长的处理器可以一次处理64位数据。


<br><br>
<br>1比特（Bit） = 1/8字节（Byte）。
<br>1字节（Byte） = 8比特（Bits）。
<br>字（Word）的长度是体系结构决定的，可以是2字节（16位）、4字节（32位）或8字节（64位）等。<br>
<img alt="Pasted image 20240710103731.png" src="\lib\media\pasted-image-20240710103731.png"><br>
<img alt="Pasted image 20240710104141.png" src="\lib\media\pasted-image-20240710104141.png">
<br><br><img alt="Pasted image 20240710105621.png" src="\lib\media\pasted-image-20240710105621.png"><br>
对于大端方式，这里要存100 101 102 103 ，从左到右为字节从高到低，所以100是最高字节，103是最低字节，所以相当于把最高字节100存放在最低地址单元FF。<br>
对于小端方式，这里要存103 102 101 100 ，从左到右为字节从高到低，所以103是最高字节，100是最低字节，所以相当于把最高字节103存放在最低地址单元FF。<br><br><img alt="Pasted image 20240710110941.png" src="\lib\media\pasted-image-20240710110941.png"><br><br><br><img alt="Pasted image 20240710151613.png" src="\lib\media\pasted-image-20240710151613.png"><br><br><img alt="Pasted image 20240710151837.png" src="\lib\media\pasted-image-20240710151837.png"><br><img alt="Pasted image 20240710152433.png" src="\lib\media\pasted-image-20240710152433.png"><br>
在AT&amp;T汇编语言中，M和R通常用于指示操作数的类型和地址模式。具体来说：<br><br>
<br>M表示内存操作数。这意味着操作数位于内存中，可以是通过某种内存寻址方式访问的数据。
<br>内存操作数可以包括直接寻址、间接寻址、基址加偏移量等复杂的寻址方式。
<br>例如：<br>movl $0x1234, 0x5678       # 将立即数0x1234移动到内存地址0x5678
movl %eax, (%ebx)          # 将寄存器eax的值移动到ebx寄存器所指向的内存位置
<br><br>
<br>R表示寄存器操作数。这意味着操作数是一个寄存器的内容。
<br>寄存器操作数可以是通用寄存器、段寄存器、控制寄存器等。
<br>例如：<br>movl %eax, %ebx            # 将寄存器eax的值移动到寄存器ebx
addl %ecx, %edx            # 将寄存器ecx的值加到寄存器edx
<br><br>
<br>
内存操作数 (M)
movl $0x1234, 0x5678    # 将立即数0x1234移动到内存地址0x5678
movl %eax, 0x5678       # 将寄存器eax的值移动到内存地址0x5678
movl (%eax), %ebx       # 将eax寄存器指向的内存位置的值移动到寄存器ebx


<br>
寄存器操作数 (R)
movl %eax, %ebx         # 将寄存器eax的值移动到寄存器ebx
addl %ecx, %edx         # 将寄存器ecx的值加到寄存器edx
subl %ebx, %eax         # 将寄存器ebx的值从寄存器eax中减去


<br>即M操作时，是拿着算出来或者直接给的地址按图索骥，找到操作数。movl (%eax), %ebx，对于这种（）里的就表示找操作数。<br>
而R操作代表了直接把寄存器里的机器数进行相减，并不访问内存。<br><br>这两种操作对应了movl和leal，movl 0x18(%edx), %eax，是将0x18(%edx)的内容给eax，比如这个内存存的是数字4，就是将4这个值给eax。<br>
leal则将 0x18(%edx)处的内容，比如是数字4，将4的地址给eax，其实就是不访问内存，只是将 0x18(%edx)算出的地址赋给后面的eax。<br>也就是说只有当用()这种寻址操作的时候，才是对内存里的数进行处理，其他都是对地址的操作。<br>简单的说就是 movl是把访问的内存内容赋值给寄存器， leal是將地址赋值给寄存器<br>
举个例子<br>
movl 0x18(%edx), %eax<br>
leal 0x18(%edx), %eax<br>
leal将 0x18(%edx)处的内容，比如是数字4，将4的地址给eax<br>
movl则是将0x18(%edx)的内容直接给eax，比如是数字4，就是将4这个值给eax<br><br><br>
<br>je (jump if equal): 相等时跳转
<br>jne (jump if not equal): 不相等时跳转
<br>jg (jump if greater): 大于时跳转（有符号）
<br>jge (jump if greater or equal): 大于或等于时跳转（有符号）
<br>jl (jump if less): 小于时跳转（有符号）
<br>jle (jump if less or equal): 小于或等于时跳转（有符号）
<br>ja (jump if above): 大于时跳转（无符号）
<br>jae (jump if above or equal): 大于或等于时跳转（无符号）
<br>jb (jump if below): 小于时跳转（无符号）
<br>jbe (jump if below or equal): 小于或等于时跳转（无符号）
<br><img alt="Pasted image 20240710175536.png" src="\lib\media\pasted-image-20240710175536.png"><br>
<img alt="Pasted image 20240710175604.png" src="\lib\media\pasted-image-20240710175604.png"><br>
<img alt="Pasted image 20240710175718.png" src="\lib\media\pasted-image-20240710175718.png"><br>
<img alt="Pasted image 20240710175730.png" src="\lib\media\pasted-image-20240710175730.png"><br>
<img alt="Pasted image 20240710181327.png" src="\lib\media\pasted-image-20240710181327.png"><br>
<img alt="Pasted image 20240710180903.png" src="\lib\media\pasted-image-20240710180903.png"><br>
<img alt="Pasted image 20240710181238.png" src="\lib\media\pasted-image-20240710181238.png"><br>
<img alt="Pasted image 20240710181508.png" src="\lib\media\pasted-image-20240710181508.png"><br><br>int add(int x, int y) {
    return x + y;
}

int caller() {
    int t1 = 125;
    int t2 = 80;
    int sum = add(t1, t2);
    return sum;
}

<br>.section .data
.section .bss
.section .text
.globl add
.globl caller

add:
    # 函数 prologue
    pushl %ebp                # 保存旧的基址指针
    movl %esp, %ebp           # 设置新的基址指针

    # 计算 x + y
    movl 8(%ebp), %eax        # 加载第一个参数 x 到 eax
    addl 12(%ebp), %eax       # 加上第二个参数 y

    # 函数 epilogue
    movl %ebp, %esp           # 恢复栈指针
    popl %ebp                 # 恢复旧的基址指针
    ret                       # 返回结果在 eax 中

caller:
    # 函数 prologue
    pushl %ebp                # 保存旧的基址指针
    movl %esp, %ebp           # 设置新的基址指针

    # 设置局部变量 t1 和 t2
    subl $12, %esp            # 给局部变量分配空间
    movl $125, -4(%ebp)       # t1 = 125
    movl $80, -8(%ebp)        # t2 = 80

    # 调用 add 函数
    movl -4(%ebp), %eax       # 加载 t1 到 eax
    pushl %eax                # 压入参数 t1
    movl -8(%ebp), %eax       # 加载 t2 到 eax
    pushl %eax                # 压入参数 t2
    call add                  # 调用 add 函数
    addl $8, %esp             # 清理参数（恢复栈）

    # 保存结果到 sum
    movl %eax, -12(%ebp)      # sum = add(t1, t2)

    # 返回 sum
    movl -12(%ebp), %eax      # 将 sum 加载到 eax

    # 函数 epilogue
    movl %ebp, %esp           # 恢复栈指针
    popl %ebp                 # 恢复旧的基址指针
    ret                       # 返回结果在 eax 中

<br><img alt="Pasted image 20240710183121.png" src="\lib\media\pasted-image-20240710183121.png"><br><br><img alt="Pasted image 20240710183426.png" src="\lib\media\pasted-image-20240710183426.png"><br><br><img alt="Pasted image 20240710184228.png" src="\lib\media\pasted-image-20240710184228.png"><br><br><img alt="Pasted image 20240710184403.png" src="\lib\media\pasted-image-20240710184403.png"><br><br><img alt="Pasted image 20240710190138.png" src="\lib\media\pasted-image-20240710190138.png"><br>
<img alt="Pasted image 20240710190419.png" src="\lib\media\pasted-image-20240710190419.png"><br>
<img alt="Pasted image 20240710190503.png" src="\lib\media\pasted-image-20240710190503.png"><br><br><br><img alt="Pasted image 20240710191340.png" src="\lib\media\pasted-image-20240710191340.png"><br>
<img alt="Pasted image 20240710191433.png" src="\lib\media\pasted-image-20240710191433.png"><br><br><img alt="Pasted image 20240706132222.png" src="\lib\media\pasted-image-20240706132222.png"><br>
<img alt="Pasted image 20240706132232.png" src="\lib\media\pasted-image-20240706132232.png"><br><br><img alt="Pasted image 20240706132517.png" src="\lib\media\pasted-image-20240706132517.png"><br><br><img alt="Pasted image 20240706132607.png" src="\lib\media\pasted-image-20240706132607.png"><br><br><img alt="Pasted image 20240706132920.png" src="\lib\media\pasted-image-20240706132920.png"><br><br><img alt="Pasted image 20240710191740.png" src="\lib\media\pasted-image-20240710191740.png"><br>
<img alt="Pasted image 20240710191951.png" src="\lib\media\pasted-image-20240710191951.png"><br><br><img alt="Pasted image 20240710192244.png" src="\lib\media\pasted-image-20240710192244.png"><img alt="Pasted image 20240710192304.png" src="\lib\media\pasted-image-20240710192304.png"><br><br><br>假设 x 为一个 int 型变量，请给出一个用来计算 x /32的值的函数div32。要求不能使用除法、乘法、模运算、比较运算、循环语句和条件语句，可以使用右移、加法以及任何按位运算。<br>要计算 x / 32 而不使用除法、乘法、模运算、比较运算、循环语句和条件语句，可以利用右移操作符来实现，因为整数除以 32 等同于向右移动 5 位（2^5 = 32）。不过，考虑到可能存在的负数情况，单纯的右移可能会导致问题，所以我们需要进行一些调整。<br>以下是计算 x / 32 的函数 div32：<br>int div32(int x) {
    // 先右移5位相当于除以32
    int result = x &gt;&gt; 5;

    // 为了处理负数情况，如果 x 是负数且对32有余数，需要将结果加1
    int bias = ((x &amp; 31) != 0) &amp;&amp; (x &lt; 0);

    // 将 bias 转换为整数（0 或 1）并添加到 result
    return result + bias;
}
<br><br>
<br>右移5位：x &gt;&gt; 5，这相当于除以32。
<br>处理负数的偏移量：

<br>x &amp; 31：这相当于计算 x 除以32的余数。
<br>((x &amp; 31) != 0) &amp;&amp; (x &lt; 0)：这部分代码检查 x 是否为负数并且对32的余数不为零。如果条件为真，bias 为1，否则为0。


<br>调整结果：将 bias 添加到 result 中。
<br>通过这种方式，我们可以在不使用除法、乘法、模运算、比较运算、循环语句和条件语句的情况下实现 x / 32 的计算。<br><br>x &amp; 31 实际上是获取 x 除以 32 后的余数，这是因为 31 的二进制表示是 11111（二进制的五个 1），只保留了 x 的最低五位。对于任何整数 x，x &amp; 31 的值范围在 0 到 31 之间，这正好是 x 除以 32 的余数。<br>让我们举一些例子来说明：<br><br>
<br>-34 的二进制表示（假设32位机器）：11111111 11111111 11111111 11011110（注意这是补码表示）
<br>31 的二进制表示：00000000 00000000 00000000 00011111
<br>-34 &amp; 31 的结果：00000000 00000000 00000000 00011110（即 30）
<br>所以，-34 除以 32 的余数是 30（-34 % 32 = 30）。<br><br>
<br>x &amp; 31：计算 x 除以 32 的余数。
<br>(x &amp; 31) != 0：判断是否存在余数。
<br>x &lt; 0：判断 x 是否为负数。
<br>has_remainder &amp; is_negative：如果 x 是负数并且有余数，则为 1，否则为 0。
<br>将这个值添加到 result 中，以调整负数除法的结果。
<br>这样，我们可以在不使用除法、乘法、模运算、比较运算、循环语句和条件语句的情况下实现 x / 32 的计算，同时正确处理负数情况。<br><br><img alt="文档扫描_20240710144933530_edit_5489733790230550.jpg" src="\lib\media\文档扫描_20240710144933530_edit_5489733790230550.jpg"><br>
<img alt="扫描件_25512712723000X21001_001.jpg" src="\lib\media\扫描件_25512712723000x21001_001.jpg"><br>
我们需要分析这个代码片段，并根据具体的条件和操作填写缺失的部分。该代码的目的是计算 (2^x) 的浮点表示，涉及到浮点数的位级表示。<br><br>根据浮点数的 IEEE 754 标准，一个单精度浮点数的表示格式如下：<br>
<br>1 位符号位
<br>8 位指数位
<br>23 位尾数位
<br>要计算 (2^x) 的浮点表示，我们需要设置适当的指数和尾数位。<br><br><br>当 x 非常小（小于最小的可表示的指数），将返回 0.0。<br>if (x &lt; -149) {
    exp = 0;
    frac = 0;
}
<br><br>当 x在之间时，返回一个非规格化的结果。<br>else if (x &lt; -126) {
    exp = 0;
    frac = 1 &lt;&lt; (x + 149); // 计算尾数部分
}
<br><br>当 x在  之间时，返回一个规格化的结果。<br>else if (x &lt;= 127) {
    exp = x + 127; // 将指数偏移 127
    frac = 0;
}
<br><br>当 x 大于 127 时，返回正无穷大。<br>else {
    exp = 255;
    frac = 0;
}
<br><br>float fpower2(int x)
{
    unsigned exp, frac, u;

    if (x &lt; -149) { /* 值太小, 返回 0.0 */
        exp = 0;
        frac = 0;
    } else if (x &lt; -126) { /* 返回非规格化结果 */
        exp = 0;
        frac = 1 &lt;&lt; (x + 149);
    } else if (x &lt;= 127) { /* 返回规格化结果 */
        exp = x + 127;
        frac = 0;
    } else { /* 值太大, 返回 +∞ */
        exp = 255;
        frac = 0;
    }

    u = (exp &lt;&lt; 23) | frac;
    return u2f(u);
}
<br><br>fpower2 函数根据输入的整数 x 计算 (2^x) 的浮点表示。它将 x 转换为适当的指数和尾数部分，再通过 u2f 函数将其转换为浮点数并返回。根据 x 的值范围不同，函数处理了值太小、非规格化、规格化和值太大的情况。<br><br>在IEEE 754标准的32位浮点数表示中，非规格化数用于表示非常接近于零的小数。对于单精度浮点数，非规格化数的指数部分全为0，且尾数部分用于表示实际的数值。<br>非规格化数的表示形式为：<br><br>其中，S 是符号位，0.f 是尾数位，2^{-126} 是固定的基数。这种表示法允许我们表示极小的数值，这些数值太小而无法用规格化形式表示。<br>在你的代码中，float fpower2(int x) 的目标是生成一个值为 2^x 的浮点数。为了理解为什么尾数是 1 &lt;&lt; (x + 149)，我们需要了解非规格化数的范围和如何计算非规格化数。<br><br>对于非规格化数，指数位为0，尾数部分决定了实际的数值。尾数部分表示的是一个小数点后的二进制值。例如，如果尾数部分是 0.00000000000000000000001，这对应的二进制数值是 2^{-23}。当你希望表示的数值是 2^x 且 x 在 -149 到 -126 之间时，你需要设置尾数部分。<br>由于尾数部分有23位，最小的非规格化数可以表示的是 2^{-149}，而最大的非规格化数可以表示的是 2^{-126}（仅使用尾数部分）。为了计算非规格化数的尾数部分，我们使用如下公式：<br>[ \text{尾数部分} = 1 &lt;&lt; (x + 149) ]<br>这意味着我们希望将1左移 (x + 149) 位，以便在正确的位置设置尾数部分，使其表示 2^x。让我们举一个例子来说明这一点。<br><br>假设 x = -148：<br>
<br>x + 149 = 1。
<br>1 &lt;&lt; 1 即将 1 左移 1 位，结果是 0b10，对应于小数 0.00000000000000000000010，即 2^{-148}。
<br>假设 x = -130：<br>
<br>x + 149 = 19。
<br>1 &lt;&lt; 19 即将 1 左移 19 位，结果是 0b10000000000000000000，对应于小数 0.00000000000000000010000，即 2^{-130}。
<br>通过将 1 左移 (x + 149) 位，我们能够准确地表示 2^x 在非规格化数的尾数部分。<br><br>32位浮点数（即单精度浮点数，通常按照IEEE 754标准表示）由一个符号位、8个指数位和23个尾数位组成。<br><br>32位浮点数的最大表示数是当符号位为0（正数），指数位全为1且尾数位全为1时。具体计算如下：<br>
<br>符号位：0（正数）
<br>指数位：最大非特殊值 254，即 11111110 （注意指数是有偏移的，偏移量为127，即偏移后的指数是 254 - 127 = 127）
<br>尾数位：全为1，即 23位的 1
<br>计算方法：<br>
<br><br>32位浮点数的最小表示数可以分为以下几种情况：<br><br>次正规数时，指数位全为0，尾数位为1（最小的次正规数）。<br>
<br>符号位：0（正数）
<br>指数位：全为0（此时指数值为 -126，偏移量为127，即偏移后的指数是 0 - 127 + 1 = -126）
<br>尾数位：最小的次正规数为 0.00000000000000000000001（二进制，23位）
<br>计算方法：<br>
<br><br>最小的正规数时，指数位全为0，尾数位为0。<br>
<br>符号位：0（正数）
<br>指数位：1（即 00000001，偏移量为127，即偏移后的指数是 1 - 127 = -126）
<br>尾数位：全为0
<br>计算方法：<br>
<br><br>
<br>最大正浮点数 ≈ (3.4 \times 10^{38})
<br>最小正非零次正规数 ≈ (1.4 \times 10^{-45})
<br>最小正正规数 ≈ (1.2 \times 10^{-38})
<br>因此，32位浮点数的表示范围非常广，从极小的正数到极大的正数，可以表示极大的数字和极小的数字。]]></description><link>technology\collegeproject\计算机系统基础\计算机系统基础复习.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/计算机系统基础复习.md</guid><pubDate>Wed, 10 Jul 2024 13:44:08 GMT</pubDate><enclosure url="lib\media\pasted-image-20240707141353.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240707141353.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[计算机系统概述]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/人工智能" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能</a> 
 <br><a href=".?query=tag:科技\人工智能" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能</a> <br><br>IntelliSense 配置<br><br><br>
<br>计算机由运算器，控制器，存储器，输入设备，和输出设备组成<br>
<img alt="IMG_20240311_094858_edit_87768396851710.jpg" src="\lib\media\img_20240311_094858_edit_87768396851710.jpg">
<br><br><img alt="IMG_20240311_100127_edit_87980068915741.jpg" src="\lib\media\img_20240311_100127_edit_87980068915741.jpg"><br><br><br>寄存器 ebx 和 bx 都是 x86 架构中的寄存器，但它们有一些关键的区别。<br>
<br>
位宽:

<br>ebx 是一个 32 位寄存器，位于 x86 架构的 32 位模式（如 IA-32）。
<br>bx 是 ebx 的低 16 位部分，也就是一个 16 位寄存器，在 x86 架构的 16 位模式下（如实模式或保护模式的 16 位段）使用。


<br>
组成部分:

<br>ebx 可以分为两个 16 位寄存器和四个 8 位寄存器：

<br>ebx (32 位): 包括以下部分：

<br>bx (16 位): 包括以下部分：

<br>bh (高 8 位)
<br>bl (低 8 位)







换句话说，bx 是 ebx 的低 16 位，bh 是 bx 的高 8 位，bl 是 bx 的低 8 位。

<br>
使用场景:

<br>在 16 位编程中（如 DOS 程序或 BIOS 编程），bx 常被用作基址寄存器。
<br>在 32 位编程中（如操作系统内核或现代应用程序），ebx 常用于通用数据存储。


<br>
指令集:

<br>访问 ebx 会涉及 32 位操作指令，如 mov ebx, eax。
<br>访问 bx 会涉及 16 位操作指令，如 mov bx, ax。
<br>访问 bh 和 bl 会涉及 8 位操作指令，如 mov bl, al 或 mov bh, ah。


<br>总结起来，ebx 是一个 32 位的寄存器，bx 是它的低 16 位部分。这两者的使用取决于程序的运行环境和具体的位宽需求。<br><br>在x86架构中，指令 orw 通常用于执行16位的按位“或”操作。对于32位操作系统和寄存器（如 ebx），需要明确以下几点：<br>
<br>
orw 指令:

<br>orw 指令专门对16位数据进行操作。它对寄存器、内存位置或立即数执行按位“或”操作，并将结果存储在目标位置。


<br>
寄存器之间的按位“或”操作:

<br>如果你对 bx 和一个32位的立即数进行 orw 操作，只会涉及 bx 的16位部分，32位立即数会被截断为16位。


<br>
具体示例:

<br>假设 ebx = 0x12345678
<br>32位立即数：0x0000FFFF
<br>orw bx, 0xFFFF 的操作会是：

<br>截断立即数为16位：0xFFFF
<br>bx 的当前值（假设为 0x5678）
<br>按位“或”操作：bx = 0x5678 OR 0xFFFF = 0xFFFF
<br>最终结果是 bx = 0xFFFF




<br>
寄存器状态变化:

<br>由于 bx 是 ebx 的低16位部分，所以执行上述操作后，ebx 的值会改变。
<br>原来的 ebx = 0x12345678
<br>新的 ebx = 0x1234FFFF


<br><br>执行 orw bx, 立即数 时，即使立即数是32位，实际操作只会用到其低16位。这会修改 bx 的值，而 bx 的值变动也会影响到包含 bx 的32位寄存器 ebx 的低16位部分。<br><br>mov ebx, 0x12345678  ; 初始值
orw bx, 0xFFFF       ; 对 bx 进行 16 位 OR 操作
; 结果: ebx = 0x1234FFFF
<br>此代码中，orw 操作只作用于 bx 寄存器的16位部分，从而影响 ebx 的低16位。<br><br>指令助记符是汇编语言中用来表示指令的缩写或符号。它是一种助记符号，用来代表二进制机器指令的操作码。不同的处理器具有不同的指令集，因此会使用不同的助记符来表示这些指令。例如，一些常见的指令助记符包括ADD（加法）、B（跳转）、BLT（小于时跳转）、SVC（超级调用）、MOVE（移动）、LDR（加载寄存器）等。指令助记符在汇编语言中起到了简化和标识指令的作用，使程序员能够更容易地编写和理解代码。<br>"mov" 和 "push" 都是汇编语言中常见的指令助记符。在汇编语言中，"mov" 用于将数据从一个位置移动到另一个位置，而 "push" 则用于将数据压入堆栈（stack）。这些指令助记符帮助程序员编写指令，使得操作更加直观和易于理解。mov和push是汇编语言中常用的操作，用于数据传输和堆栈操作。<br><br>在汇编语言中，指令助记符的长度后缀用于指定指令操作数的大小。根据不同的后缀，可以指定操作数的字节大小，例如：<br>
<br>"b"：表示字节（8位）
<br>"w"：表示字（16位）
<br>"l"：表示长字（32位）
<br>"q"：表示四字（64位）
<br>这些后缀可以帮助程序员明确指定操作数的大小，以便正确执行指令。例如，"movb" 表示移动一个字节的数据，而 "movl" 表示移动一个长字（32位）的数据。这些后缀在汇编语言中是非常常见的，用于指定指令操作数的大小。<a data-tooltip-position="top" aria-label="https://docs.oracle.com/cd/E19120-01/open.solaris/817-5477/ennby/index.html" rel="noopener nofollow" class="external-link" href="https://docs.oracle.com/cd/E19120-01/open.solaris/817-5477/ennby/index.html" target="_blank">2</a><br><br><img alt="IMG_20240602_140601 1.jpg" src="\lib\media\img_20240602_140601-1.jpg"><br><br>在汇编语言中，指令 "mov 8(%ebp,%ebx,4), %ax" 的意思是将存储在内存地址 %ebp + %ebx*4 + 8 处的数据加载到寄存器 %ax 中。这是一个典型的基址加比例变址加位移，其中 %ebp 是基址寄存器，%ebx 是索引寄存器，4 是比例因子，8 是偏移量。通过这种寻址方式，程序可以有效地访问内存中的数据并执行相应的操作。<br><br>在汇编语言中，指令 "mov %al, 12(%ebp)" 的意思是将寄存器 %al 中的数据移动到内存地址 %ebp + 12 处。这是一个典型的直接偏移寻址方式，其中 %ebp 是基址寄存器，12 是偏移量。通过这条指令，程序将 %al 寄存器中的数据存储到 %ebp 寄存器指定的内存地址偏移 12 处。<br><br>在汇编语言中，指令 "add (,%ebx,4), %ebx" 的意思是将内存地址 %ebx*4 处的数据与寄存器 %ebx 中的数据相加，并将结果存储回寄存器 %ebx 中。这是一个典型的间接偏移寻址方式，其中 %ebx 是索引寄存器，4 是比例因子。通过这条指令，程序可以对内存中的数据进行加法操作，并将结果存储回寄存器中。<br><br>在 x86 汇编语言中，add (,%ebx,4), %ebx 指令的操作如下：<br>
<br>
%ebx 的初始值：

<br>假设 %ebx 当前保存的是一个地址，比如 0x1000。


<br>
计算内存地址：

<br>(,%ebx,4) 表示以 %ebx 的值乘以 4 作为内存地址。
<br>如果 %ebx 的值是 0x1000，那么计算出来的内存地址是 0x1000 * 4 = 0x4000。


<br>
读取内存内容：

<br>读取内存地址 0x4000 处的值，假设这个值是 10。


<br>
执行加法操作：

<br>将读取到的值 10 加到 %ebx 当前的值 0x1000 上。


<br>
存储结果：

<br>结果存储在 %ebx 中。


<br>因此，加法操作会将 10 加到 %ebx 的当前值 0x1000 上。<br> %ebx = 0x1000 + 10 = 0x100A<br><br>如果 %ebx 最初的值是 0x1000，并且 (,%ebx,4) 计算出的内存地址 0x4000 处的值是 10，那么执行 add (,%ebx,4), %ebx 指令后，%ebx 的值会变为 0x100A。<br><br>section .data
    array dd 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10  ; 假设这是内存中某个地方的数组，地址 0x4000 处的值是 10

section .text
    global _start

_start:
    mov ebx, 0x1000       ; 将 0x1000 加载到寄存器 %ebx 中
    add (,%ebx,4), ebx    ; 将内存地址 0x1000 * 4 (即 0x4000) 处的值 (10) 加到 %ebx 中
                          ; %ebx = 0x1000 + 10 = 0x100A

    ; 此时 %ebx 的值为 0x100A

    ; 退出程序（Linux 系统调用）
    mov eax, 1            ; 系统调用号 (sys_exit)
    xor ebx, ebx          ; 状态码 0
    int 0x80              ; 调用内核
<br>在这个示例中，内存地址 0x4000 处的值是 10。执行 add (,%ebx,4), %ebx 后，%ebx 的值从 0x1000 变为 0x100A。<br><br>在汇编语言中，指令 "or (%ebx), %dh" 的意思是将内存地址 %ebx 处的数据与寄存器 %dh 中的数据进行按位或操作。这条指令执行逻辑或运算，将内存中的数据与 %dh 寄存器中的数据进行位运算，并将结果存储回 %dh 寄存器中。<br><br>将寄存器 eax 自身与自己进行按位与运算。<br>
如果 eax 是零，则设置零标志（ZF）。<br>
如果 eax 是负数，则设置符号标志（SF）。<br><br>在 x86 汇编语言中，指令 lea 8(%ebx,%esi), %eax 的作用是计算内存地址表达式 8(%ebx,%esi) 并将结果存入寄存器 %eax 中。lea 指令不会访问内存，只会计算有效地址。<br><br>
<br>
指令格式:

<br>lea destination, source
<br>destination 是目标寄存器，在这个例子中是 %eax。
<br>source 是内存地址表达式，在这个例子中是 8(%ebx,%esi)。


<br>
内存地址表达式:

<br>8(%ebx,%esi) 是一种基址加变址寻址模式。
<br>计算方式：8 + %ebx + %esi。


<br><br>
<br>取寄存器 %ebx 的值。
<br>取寄存器 %esi 的值。
<br>将两个值相加，然后再加上立即数 8。
<br>将计算结果存入寄存器 %eax。
<br><br>假设：<br>
<br>%ebx = 0x1000
<br>%esi = 0x2000
<br>执行 lea 8(%ebx,%esi), %eax 后：<br>
<br>计算 8 + %ebx + %esi
<br>结果是 8 + 0x1000 + 0x2000 = 0x3008
<br>将 0x3008 存入 %eax
<br><br>section .data
    ; 没有数据段定义，因为 lea 不涉及实际数据存取

section .text
    global _start

_start:
    mov ebx, 0x1000        ; 将 0x1000 加载到寄存器 %ebx
    mov esi, 0x2000        ; 将 0x2000 加载到寄存器 %esi
    lea eax, 8(ebx, esi)   ; 计算 8 + %ebx + %esi 的值，存入 %eax

    ; 退出程序（Linux 系统调用）
    mov eax, 1             ; 系统调用号 (sys_exit)
    xor ebx, ebx           ; 状态码 0
    int 0x80               ; 调用内核
<br>在这个示例中：<br>
<br>mov ebx, 0x1000 将 0x1000 加载到 %ebx。
<br>mov esi, 0x2000 将 0x2000 加载到 %esi。
<br>lea eax, 8(%ebx, %esi) 计算 8 + %ebx + %esi 的值并将结果存入 %eax，即 0x3008。
<br><br>指令 lea 8(%ebx,%esi), %eax 计算出地址表达式 8 + %ebx + %esi 的值，并将结果存入寄存器 %eax 中。lea 指令常用于指针运算、数组访问和复杂地址计算，而不实际访问内存。<br><br><br>(简答题)假设某个C语言函数func的原型声明如<br>
下:void func(int *xptr,int *yptr, int *zptr);函<br>
数 func 的过程体对应的机器级代码用AT&amp;T汇编形<br>
式表示如下:<br>
1 mol 8(%ebp)%eax<br>
2 movl 12(%ebp)%ebx<br>
3 movl 16(%ebp)%ex<br>
4 movl (%ebx)%edx<br>
5 movl (%ecx)%esi<br>
6 movl (%eax)%edi<br>
7 movl %edi(%ebx)<br>
8 movl %edx(%ecx)<br>
9 movl %esi(%eax)<br>
请回答下列问题或完成下列任务<br>
(1)在过程体开始时三个入口参数对应实参所存放<br>
的存储单元地址是什么?(提示: 当前栈帧底部由帧指<br>
针寄存器 EBP 指示)<br>
(2)根据上述机器级代码写出函数 func的C语言代<br>
码<br><br>在分析给出的汇编代码并将其转换为C语言代码之前，我们需要理解每条汇编指令的含义以及它们在函数调用过程中如何操作。这有助于我们确定函数参数的存储地址，并将汇编代码转换为等价的C语言代码。<br><br>在x86汇编中，函数参数通常通过栈传递。在函数调用期间，参数被压入栈中，随后调用者的返回地址和帧指针（EBP）也被压入栈中。当前函数的栈帧底部由帧指针寄存器EBP指示。<br>给出的汇编代码如下：<br>1. movl 8(%ebp), %eax
2. movl 12(%ebp), %ebx
3. movl 16(%ebp), %ecx
4. movl (%ebx), %edx
5. movl (%ecx), %esi
6. movl (%eax), %edi
7. movl %edi, (%ebx)
8. movl %edx, (%ecx)
9. movl %esi, (%eax)
<br>从代码中可以看出：<br>
<br>8(%ebp) 是第一个参数 xptr 的地址。
<br>12(%ebp) 是第二个参数 yptr 的地址。
<br>16(%ebp) 是第三个参数 zptr 的地址。
<br><br>为了将这些汇编指令转换为C语言代码，我们需要逐行理解它们的操作：<br>
<br>movl 8(%ebp), %eax：将 xptr 的地址存入 eax。
<br>movl 12(%ebp), %ebx：将 yptr 的地址存入 ebx。
<br>movl 16(%ebp), %ecx：将 zptr 的地址存入 ecx。
<br>movl (%ebx), %edx：将 *yptr 的值存入 edx。
<br>movl (%ecx), %esi：将 *zptr 的值存入 esi。
<br>movl (%eax), %edi：将 *xptr 的值存入 edi。
<br>movl %edi, (%ebx)：将 edi 的值（即 *xptr 的值）存入 *yptr。
<br>movl %edx, (%ecx)：将 edx 的值（即 *yptr 的值）存入 *zptr。
<br>movl %esi, (%eax)：将 esi 的值（即 *zptr 的值）存入 *xptr。
<br>综上所述，这段汇编代码实现了三个指针指向的值的交换，具体来说，它将 *xptr 的值赋给 *yptr，将 *yptr 的值赋给 *zptr，将 *zptr 的值赋给 *xptr。因此，等价的C语言代码如下：<br>void func(int *xptr, int *yptr, int *zptr) {
    int temp1 = *yptr;
    int temp2 = *zptr;
    int temp3 = *xptr;
    *yptr = temp3;
    *zptr = temp1;
    *xptr = temp2;
}
<br>这个C语言函数 func 实现了对三个整数指针指向的值的循环交换。<br><br>lea（Load Effective Address）和mov（Move）是x86汇编语言中两条不同的指令，它们有着不同的作用和用法。<br><br>
<br>
作用：

<br>lea 指令用于计算并加载有效地址到指定的寄存器中，但不会访问内存。
<br>mov 指令用于将数据从一个位置复制到另一个位置，可以是寄存器之间的数据传递，也可以是寄存器和内存之间的数据传递。


<br>
操作数：

<br>lea 指令的源操作数是内存地址表达式，用于计算有效地址。
<br>mov 指令的操作数可以是寄存器、立即数或内存地址。


<br>
副作用：

<br>lea 指令不会改变内存或寄存器中的数据，只会计算有效地址并将其加载到指定寄存器中。
<br>mov 指令会将源操作数的值复制到目标操作数中，可能会覆盖目标操作数中原有的值。


<br>
效率：

<br>lea 指令通常比 mov 指令执行得更快，因为它不需要访问内存，只需要进行简单的地址计算。


<br><br>
<br>使用 lea 进行地址计算：
lea eax, [ebx + ecx*4 + 8]  ; 计算并加载地址表达式 ebx + ecx*4 + 8 到 eax


<br>使用 mov 进行数据传递：
mov eax, ebx  ; 将 ebx 寄存器的值复制到 eax 寄存器中
mov dword [ebx], 10  ; 将立即数 10 存储到 ebx 寄存器所指向的内存地址中


<br><br>
<br>lea 主要用于计算地址，而 mov 主要用于数据传递。
<br>lea 不会访问内存，只进行地址计算，因此通常比 mov 执行得更快。
<br>在需要进行地址计算而不需要实际数据传递的情况下，应优先选择使用 lea 指令。
<br><br>sall 是 x86 汇编语言中的一条指令，用于对目标操作数进行左移操作。sall 是 sal 指令的别名，代表 "Shift Arithmetic Left"（算术左移）。sal 和 shl（Shift Logical Left）指令在 x86 架构中是等价的，功能完全相同。<br><br>sall 指令将目标操作数左移指定的位数，右边用零填充。左移操作会将二进制位向左移动，低位用零填充，高位溢出位丢弃。<br><br>sall imm8, reg/mem
sall %cl, reg/mem
<br>
<br>imm8：表示立即数，用于指定左移的位数。
<br>%cl：表示寄存器 CL，用于动态指定左移的位数。
<br>reg/mem：表示可以是寄存器或者内存操作数。
<br><br>
<br>立即数左移
<br>movl $0x00000001, %eax  ; 将立即数 1 装载到寄存器 %eax
sall $2, %eax           ; 将 %eax 左移 2 位，%eax 变成 0x00000004
<br>
<br>使用 CL 寄存器左移
<br>movl $0x00000001, %eax  ; 将立即数 1 装载到寄存器 %eax
movb $2, %cl            ; 将立即数 2 装载到寄存器 %cl
sall %cl, %eax          ; 将 %eax 左移 %cl 指定的位数（2 位），%eax 变成 0x00000004
<br><br>sall 指令会影响以下标志位：<br>
<br>CF (Carry Flag): 置位为最后一个被移出的位。
<br>OF (Overflow Flag): 当移位数为1时，如果最高有效位 (sign bit) 在移位前和移位后不同，则置位。
<br>ZF (Zero Flag): 如果结果为零，置位。
<br>SF (Sign Flag): 结果的最高有效位（符号位）。
<br>PF (Parity Flag): 结果的最低8位中的奇偶校验。
<br><br>
<br>sall 指令用于将目标操作数向左移位。
<br>左移操作使二进制位向左移动，低位用零填充。
<br>该指令影响多个标志位，具体取决于操作结果。
<br><br>在 x86 汇编语言中，shrl 指令用于对寄存器或内存中的数据进行逻辑右移操作。shr 指令的全称是 "Shift Logical Right"。右移操作会将位向右移动，并在左侧用零填充。<br><br>shrl 指令的常见形式包括：<br>
<br>
立即数与寄存器：
shrl $imm, %reg

例如：
shrl $1, %eax


<br>
CL寄存器与寄存器：
shrl %cl, %reg

例如：
shrl %cl, %eax


<br>
立即数与内存：
shrl $imm, mem

例如：
shrl $1, 0x10(%ebp)


<br><br>shrl 指令对指定寄存器或内存地址中的数据执行逻辑右移操作。逻辑右移会将所有位向右移动，并在左侧用零填充。右移后的位超出目标寄存器或内存大小的部分会被丢弃。<br><br>
<br>CF（Carry Flag）：设置为从最低有效位（最右边的位）移出的位值。
<br>ZF（Zero Flag）：如果结果为0，ZF被设置（1）；否则清除（0）。
<br>SF（Sign Flag）：逻辑右移不会影响符号标志。
<br>OF（Overflow Flag）：对于多于1位的移位操作，OF被清除；对于1位的移位操作，OF被设置为原最高有效位（最高位）。
<br><br>
<br>
立即数与寄存器：
movl $0x8, %eax  ; 将 8 装入 EAX 寄存器 (二进制为 0000 1000)
shrl $1, %eax    ; 将 EAX 右移 1 位 (二进制为 0000 0100), EAX 现在为 4


<br>
CL寄存器与寄存器：
movl $0x10, %eax ; 将 16 装入 EAX 寄存器 (二进制为 0001 0000)
movb $2, %cl     ; 将 2 装入 CL 寄存器
shrl %cl, %eax   ; 将 EAX 右移 CL 指定的 2 位 (二进制为 0000 0100), EAX 现在为 4


<br>
立即数与内存：
movl $0x20, 0x10(%ebp) ; 将 32 装入内存地址 0x10(%ebp) (二进制为 0010 0000)
shrl $2, 0x10(%ebp)    ; 将内存地址 0x10(%ebp) 右移 2 位 (二进制为 0000 1000), 内存内容现在为 8


<br><br>
<br>shrl 指令用于对寄存器或内存中的数据进行逻辑右移操作，将数据向右移动并在左侧用零填充。
<br>语法：可以是立即数与寄存器、CL寄存器与寄存器或立即数与内存。
<br>影响的标志位：包括 CF、ZF、SF、OF。
<br>通过这种方式，shrl 指令可以用于高效地执行位移操作，适用于各种位操作应用场景。<br><br>imull 是 x86 汇编指令，用于执行带符号的整数乘法。该指令有多种变体，允许在不同操作数之间执行乘法，并且可以将结果存储在不同的位置。<br><br>imull 指令有以下几种常见的格式：<br>
<br>
双操作数形式（寄存器或内存与寄存器相乘，结果存储在目标寄存器中）：
imull source, destination


<br>
三操作数形式（立即数与寄存器或内存相乘，结果存储在目标寄存器中）：
imull immediate, source, destination


<br>
单操作数形式（AX/EAX/RAX与源操作数相乘，结果存储在DX:AX/EDX:EAX/RDX:RAX中）：
imull source


<br><br><br>movl $5, %eax       ; 将立即数 5 装入 EAX 寄存器
movl $3, %ebx       ; 将立即数 3 装入 EBX 寄存器
imull %ebx, %eax    ; EAX = EAX * EBX = 5 * 3 = 15
                    ; 结果存储在 EAX 寄存器中，EAX = 15
<br><br>movl $5, %eax       ; 将立即数 5 装入 EAX 寄存器
imull $3, %eax, %ebx; EBX = EAX * 3 = 5 * 3 = 15
                    ; 结果存储在 EBX 寄存器中，EBX = 15
<br><br>movl $5, %eax       ; 将立即数 5 装入 EAX 寄存器
movl $3, %ebx       ; 将立即数 3 装入 EBX 寄存器
imull %ebx          ; EDX:EAX = EAX * EBX = 5 * 3 = 15
                    ; 结果存储在 EAX 和 EDX 寄存器中，低32位存储在 EAX 中
<br><br>
<br>CF (Carry Flag) 和 OF (Overflow Flag): 如果结果超过目的操作数的容量，则设置这些标志。
<br>ZF (Zero Flag)、SF (Sign Flag)、PF (Parity Flag): 不受影响。
<br><br>
<br>imull 是带符号乘法指令。
<br>该指令有单操作数、双操作数和三操作数形式。
<br>结果存储在指定的寄存器中。
<br>影响 CF 和 OF 标志，其他标志位不受影响。
<br><br>在 x86 汇编语言中，test 指令用于按位测试两个操作数的每一位，并根据结果设置标志寄存器。test 指令执行按位与操作，但它不会改变操作数的值，只是设置处理器状态标志。<br><br>test 指令有几种常见的形式：<br>
<br>
寄存器与寄存器：
test reg1, reg2

例如：
test %eax, %ebx


<br>
内存与寄存器：
test mem, reg

例如：
test 0x10(%ebp), %eax


<br>
立即数与寄存器：
test imm, reg

例如：
test $0x1, %eax


<br>
立即数与内存：
test imm, mem

例如：
test $0x1, 0x10(%ebp)


<br><br>test 指令的作用是将两个操作数进行按位与运算，并设置标志寄存器，但不存储结果。具体来说，它影响以下标志：<br>
<br>ZF（Zero Flag）：如果结果为0，ZF被设置（1）；否则清除（0）。
<br>SF（Sign Flag）：设置为结果的最高有效位（符号位）。
<br>PF（Parity Flag）：设置为结果的最低8位中1的奇偶校验。
<br>OF（Overflow Flag）和CF（Carry Flag）：总是清除（0）。
<br><br>
<br>
寄存器与寄存器：
test %eax, %eax

这是一个常见的用法，测试寄存器自身，用于检查寄存器的值是否为零。

<br>
立即数与寄存器：
test $0x1, %eax

测试 EAX 寄存器的最低位是否为1。

<br>
内存与寄存器：
test 0x10(%ebp), %eax

测试内存地址 0x10(%ebp) 的值与 EAX 寄存器值的按位与结果。

<br><br>
<br>条件跳转：test 指令通常与条件跳转指令一起使用，如 je（跳转如果相等），jne（跳转如果不相等），用于根据特定位的状态进行条件分支。
<br>检查位状态：test 指令可以用于检查特定位是否被设置（1）或清除（0），例如用于检查标志寄存器或特定标志位。
<br><br>mov $0x4, %eax  ; 将 4 装入 EAX 寄存器
test $0x1, %eax ; 测试 EAX 的最低位
jz zero_flag   ; 如果最低位为 0，跳转到 zero_flag 标签
<br>在上述代码中，test $0x1, %eax 将测试 EAX 寄存器的最低位，如果最低位为 0，则设置 ZF，并且 jz zero_flag 指令将跳转到 zero_flag 标签。<br><br>
<br>test 指令执行按位与操作，并设置处理器状态标志。
<br>它不改变操作数的值。
<br>常用于检查特定位是否被设置或清除，并与条件跳转指令一起使用。
<br><br>在 x86 汇编语言中，%esp 和 (%esp) 表示不同的含义：<br><br>%esp 是栈指针寄存器，存储栈顶的地址。在 x86 架构中，栈是向下增长的，所以栈指针通常指向栈的顶部。对 %esp 的操作会改变栈顶地址。<br>例如：<br>movl $0x1000, %esp  ; 将立即数 0x1000 装入 %esp 寄存器
<br>这条指令将数值 0x1000 直接放入栈指针寄存器 %esp 中。<br><br>(%esp) 是一种间接寻址方式，表示内存地址由栈指针寄存器 %esp 指向的那个位置的值。也就是说，(%esp) 表示栈顶地址处存储的数据。<br>例如：<br>movl (%esp), %eax  ; 将 %esp 指向的内存地址中的值移动到 %eax 寄存器中
<br>这条指令会读取栈顶地址（由 %esp 指向的地址）处的 32 位数据，并将其存储到寄存器 %eax 中。<br><br>假设 %esp 的值是 0x08048000，而栈顶地址 0x08048000 处存储的值是 0x12345678。<br>
<br>%esp 表示 0x08048000（栈顶的地址）。
<br>(%esp) 表示 0x12345678（栈顶地址 0x08048000 处存储的数据）。
<br><br>movl $0x12345678, (%esp)  ; 将立即数 0x12345678 存储到 %esp 指向的内存地址
movl %esp, %eax           ; 将 %esp 寄存器的值移动到 %eax 中
movl (%esp), %ebx         ; 将 %esp 指向的内存地址中的值移动到 %ebx 中
<br>假设 %esp 的初始值是 0x08048000：<br>
<br>movl $0x12345678, (%esp)：将 0x12345678 存储到地址 0x08048000。
<br>movl %esp, %eax：将 0x08048000 赋值给寄存器 %eax。
<br>movl (%esp), %ebx：将地址 0x08048000 处的值 0x12345678 赋值给寄存器 %ebx。
<br>结果是：<br>
<br>%eax 将包含值 0x08048000。
<br>%ebx 将包含值 0x12345678。
<br><br>
<br>%esp 是栈指针寄存器，存储栈顶的地址。
<br>(%esp) 表示由 %esp 指向的内存地址处的数据。
<br>它们的区别在于一个是指向栈顶的地址（%esp），另一个是栈顶地址处存储的数据（(%esp)）。<br><br>在 x86 汇编语言中，call refunc 是一个调用指令，它用于调用名为 refunc 的函数或子程序。这个指令会执行以下步骤：<br>
<br>
将返回地址压入栈：call 指令首先会将下一条指令的地址（即调用 refunc 指令的下一条指令地址）压入栈中。这个返回地址是函数执行完毕后返回的位置。

<br>
跳转到目标函数：然后 call 指令会跳转到名为 refunc 的函数的入口地址，开始执行该函数的代码。

<br><br>假设有一个函数 refunc 定义在程序的其他部分，并且当前指令在地址 0x08048010，下一条指令在 0x08048015。执行 call refunc 后会进行以下操作：<br>
<br>将返回地址 0x08048015 压入栈中。
<br>跳转到 refunc 函数的入口地址，开始执行 refunc 的代码。
<br><br>假设栈指针 %esp 当前值是 0x08048000：<br>
<br>
压入返回地址：

<br>栈指针 %esp 会递减4（因为 x86 使用向下增长的栈）。
<br>将 0x08048015 存储到新栈顶地址 0x08047ffc。


<br>
跳转到 refunc：

<br>程序计数器 EIP 跳转到 refunc 的地址。


<br>执行 call refunc 后：<br>
<br>栈指针 %esp = 0x08047ffc
<br>内存地址 0x08047ffc 的值 = 0x08048015
<br><br>section .text
global _start

_start:
    call refunc  ; 调用 refunc 函数
    ; 继续执行其他代码

refunc:
    ; 函数体
    ret          ; 从函数返回
<br>在这个示例中：<br>
<br>call refunc：调用 refunc 函数。
<br>refunc 函数体执行。
<br>ret：从 refunc 返回，将栈顶的返回地址 0x08048015 弹出到 EIP，继续执行下一条指令。
<br><br>
<br>call refunc 指令用于调用一个名为 refunc 的函数。
<br>它会将返回地址压入栈，然后跳转到 refunc 函数的入口地址。
<br>函数执行完毕后，ret 指令会从栈中弹出返回地址，返回调用位置继续执行。
<br>这种机制支持子程序调用和返回，是实现函数调用和递归的基础。<br><br>在汇编语言中，条件判断和循环通常通过使用跳转（jump）指令和条件标志来实现。以下是实现条件判断和循环的一些基本方法和示例。<br><br>条件判断通常使用比较指令（如 cmp）和条件跳转指令（如 je, jne, jg, jl 等）。<br><br>假设我们要实现以下 C 语言的 if-else 语句：<br>if (a == b) {
    // do something
} else {
    // do something else
}
<br>对应的汇编代码：<br>movl a, %eax        ; 将变量 a 的值加载到寄存器 %eax
cmpl b, %eax        ; 比较 %eax 和变量 b
je equal            ; 如果 %eax == b，跳转到 equal 标签

; 如果不相等，执行 else 部分
; do something else
jmp end_if          ; 跳转到 end_if

equal:
; do something
end_if:
; 继续执行其他代码
<br><br>循环通常使用比较指令和条件跳转指令来控制循环的执行。<br><br>假设我们要实现以下 C 语言的 while 循环：<br>while (a &lt; b) {
    // do something
    a++;
}
<br>对应的汇编代码：<br>start_while:
cmpl b, a           ; 比较 a 和 b
jge end_while       ; 如果 a &gt;= b，跳转到 end_while

; do something

incl a              ; a++
jmp start_while     ; 跳转回 start_while

end_while:
; 继续执行其他代码
<br><br>假设我们要实现以下 C 语言的 for 循环：<br>for (int i = 0; i &lt; n; i++) {
    // do something
}
<br>对应的汇编代码：<br>movl $0, %ecx       ; i = 0
movl n, %edx        ; 将 n 加载到 %edx

start_for:
cmpl %edx, %ecx     ; 比较 i 和 n
jge end_for         ; 如果 i &gt;= n，跳转到 end_for

; do something

incl %ecx           ; i++
jmp start_for       ; 跳转回 start_for

end_for:
; 继续执行其他代码
<br><br>
<br>je (jump if equal): 相等时跳转
<br>jne (jump if not equal): 不相等时跳转
<br>jg (jump if greater): 大于时跳转（有符号）
<br>jge (jump if greater or equal): 大于或等于时跳转（有符号）
<br>jl (jump if less): 小于时跳转（有符号）
<br>jle (jump if less or equal): 小于或等于时跳转（有符号）
<br>ja (jump if above): 大于时跳转（无符号）
<br>jae (jump if above or equal): 大于或等于时跳转（无符号）
<br>jb (jump if below): 小于时跳转（无符号）
<br>jbe (jump if below or equal): 小于或等于时跳转（无符号）
<br><br>
<br>条件判断：通过比较指令（如 cmp）设置条件标志，然后使用条件跳转指令（如 je, jne 等）进行跳转。
<br>循环：通过比较指令和条件跳转指令控制循环的开始和结束位置。
<br>通过结合这些指令，可以在汇编语言中实现各种复杂的控制结构。]]></description><link>technology\collegeproject\计算机系统基础\计算机系统基础理论.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机系统基础/计算机系统基础理论.md</guid><pubDate>Sat, 08 Jun 2024 03:19:29 GMT</pubDate><enclosure url="lib\media\img_20240311_094858_edit_87768396851710.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\img_20240311_094858_edit_87768396851710.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[存储器层次结构]]></title><description><![CDATA[ 
 <br><img alt="{DEE7C90B-F043-4894-8325-775FF879C8F5}.png" src="\lib\media\{dee7c90b-f043-4894-8325-775ff879c8f5}.png"><br>
<img alt="扫描件_第四章. (计组).4.61113.18_001(1).jpg" src="\lib\media\扫描件_第四章.-(计组).4.61113.18_001(1).jpg"><br><img alt="{B59921B6-6933-45B9-A67F-2616AD18E85A}.png" src="\lib\media\{b59921b6-6933-45b9-a67f-2616ad18e85a}.png"><br>
<img alt="扫描件_7101111hit一次命中1今车CaC_001.jpg" src="\lib\media\扫描件_7101111hit一次命中1今车cac_001.jpg"><br><img alt="{F42A51F6-A4A1-4C5D-88B8-C5064577F2FF}.png" src="\lib\media\{f42a51f6-a4a1-4c5d-88b8-c5064577f2ff}.png"><img alt="{C0431A05-1C97-473D-AF39-4C65621DEEBE}.png" src="\lib\media\{c0431a05-1c97-473d-af39-4c65621deebe}.png"><br>
<img alt="{86E3D5E1-C2AC-46AD-9833-F0BA091200FE}.png" src="\lib\media\{86e3d5e1-c2ac-46ad-9833-f0ba091200fe}.png"><br>
<img alt="{2FDA5429-D538-47F1-A011-17AECFE0B6F3}.png" src="\lib\media\{2fda5429-d538-47f1-a011-17aecfe0b6f3}.png"><br>
<img alt="扫描件_字节_001.jpg" src="\lib\media\扫描件_字节_001.jpg">]]></description><link>technology\collegeproject\计算机组成原理\课内习题\存储器层次结构.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机组成原理/课内习题/存储器层次结构.md</guid><pubDate>Mon, 04 Nov 2024 11:34:23 GMT</pubDate><enclosure url="lib\media\{dee7c90b-f043-4894-8325-775ff879c8f5}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{dee7c90b-f043-4894-8325-775ff879c8f5}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验1：设计ALU]]></title><description><![CDATA[ 
 <br><br><br>本实验旨在设计和实现一个基本的算术逻辑单元（ALU），并验证其功能。ALU是计算机处理器中的一个重要组件，负责执行基本的算术和逻辑运算。通过本实验，将学习如何使用硬件描述语言（HDL）设计和仿真ALU，并将其部署到FPGA上进行实际测试。<br><br>
<br>软件

<br>Quartus II（或其他FPGA开发软件）
<br>ModelSim（或其他仿真工具）


<br><br><br>
<br>
定义模块接口

<br>输入：

<br>A 和 B：32位数据输入。
<br>ALUctrl：3位控制信号，用于选择操作类型。


<br>输出：

<br>ALUout：32位输出结果。
<br>Zero：1位输出，表示结果是否为零。
<br>Overflow：1位输出，表示是否有溢出。




<br>
编写Verilog代码

<br>创建一个名为 ALU.v 的Verilog文件，实现ALU模块。

module ALU(
    input wire [31:0] A, B,
    input wire [2:0] ALUctrl,
    output reg [31:0] ALUout,
    output reg Zero,
    output reg Overflow
);

wire [31:0] addResult, subResult, orResult, sltuResult, slltResult;

assign addResult = A + B;
assign subResult = A - B;
assign orResult = A | B;
assign sltuResult = (A &lt; B) ? 1'b1 : 1'b0;
assign slltResult = ($signed(A) &lt; $signed(B)) ? 1'b1 : 1'b0;

always @* begin
    case(ALUctrl)
        3'b000: begin // addu
            ALUout = addResult;
            Zero = (addResult == 0);
            Overflow = 0;
        end
        3'b001: begin // add
            ALUout = addResult;
            Zero = (addResult == 0);
            Overflow = (A[31] &amp; B[31] &amp; ~addResult[31]) | (~A[31] &amp; ~B[31] &amp; addResult[31]);
        end
        3'b010: begin // or
            ALUout = orResult;
            Zero = (orResult == 0);
            Overflow = 0;
        end
        3'b100: begin // subu
            ALUout = subResult;
            Zero = (subResult == 0);
            Overflow = 0;
        end
        3'b101: begin // sub
            ALUout = subResult;
            Zero = (subResult == 0);
            Overflow = (A[31] &amp; ~B[31] &amp; ~subResult[31]) | (~A[31] &amp; B[31] &amp; subResult[31]);
        end
        3'b110: begin // sltu
            ALUout = {31'b0, sltuResult}; // Extend to 32 bits
            Zero = (sltuResult == 0);
            Overflow = 0;
        end
        3'b111: begin // sllt
            ALUout = {31'b0, slltResult}; // Extend to 32 bits
            Zero = (slltResult == 0);
            Overflow = 0;
        end
        default: begin
            ALUout = 0;
            Zero = 1;
            Overflow = 0;
        end
    endcase
end

endmodule


<br><img alt="{B87FD227-EC0B-4585-90D8-EB65FA1A6288}.png" src="\lib\media\{b87fd227-ec0b-4585-90d8-eb65fa1a6288}.png"><br><br>仿真测试有两种方式：<br>
<br>一种是编写testbench文件，通过ModelSim进行测试。
<br>另一种是使用Quartus自带的仿真软件进行测试。
<br>
<br>
创建测试平台文件

<br>创建一个名为 ALU_testbench.v 的Verilog文件，编写测试平台代码。

module ALU_testbench;

    // Inputs
    reg [31:0] A;
    reg [31:0] B;
    reg [2:0] ALUctrl;

    // Outputs
    wire [31:0] ALUout;
    wire Zero;
    wire Overflow;

    // Instantiate the ALU module
    ALU uut (
        .A(A),
        .B(B),
        .ALUctrl(ALUctrl),
        .ALUout(ALUout),
        .Zero(Zero),
        .Overflow(Overflow)
    );

    // Initialize test data
    initial begin
        // Initialize inputs
        A = 32'b0;
        B = 32'b0;
        ALUctrl = 3'b000;

        // Test cases
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b000; // addu
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b001; // add
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b010; // or
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b100; // subu
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b101; // sub
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b110; // sltu
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b111; // sllt

        // Add more test cases as needed
        #10 $stop;
    end

    // Monitor outputs
    initial begin
        $monitor("At time %0t, A=%b, B=%b, ALUctrl=%b, ALUout=%b, Zero=%b, Overflow=%b", $time, A, B, ALUctrl, ALUout, Zero, Overflow);
    end

endmodule


<br><br>
<br>
编译项目

<br>打开Quartus II，创建一个新的项目。
<br>添加 ALU.v 和 ALU_testbench.v 文件。
<br>选择 Processing -&gt; Start -&gt; Start Analysis &amp; Elaboration。


<br>
创建波形文件

<br>选择 File -&gt; New -&gt; Vector Waveform File，创建一个波形文件 ALU_waveform.vwf。
<br>添加测试平台中的信号到波形文件中。


<br>
运行仿真

<br>在波形编辑器中，选择 Simulate -&gt; Run Simulation。
<br>选择 Functional Simulation 。
<br>点击 OK 开始仿真。


<br><br><img alt="{5FBD348F-D595-47A5-9CBB-1917CA44E430}.png" src="\lib\media\{5fbd348f-d595-47a5-9cbb-1917ca44e430}.png"><br>
<img alt="{E0FE90E5-4A2E-4D12-A942-29861AC2857A}.png" src="\lib\media\{e0fe90e5-4a2e-4d12-a942-29861ac2857a}.png"><br>
<br>
仿真结果

<br>观察波形文件中的信号变化，确保ALU的输出结果符合预期。
<br>记录每个测试用例的输出结果，并与预期结果进行比较。


<br>
分析

<br>分析仿真和实际测试结果的一致性。
<br>讨论可能出现的问题及其解决方案。


<br><br>通过本实验，深入了解ALU的设计和实现过程，掌握使用HDL进行数字系统设计的方法。<br>
遇到的问题：<br>
<br>Quartus的仿真编译问题<img alt="{21B7BF11-17C5-4007-B40B-D5A617C0FC5A} 1.png" src="\lib\media\{21b7bf11-17c5-4007-b40b-d5a617c0fc5a}-1.png"><img alt="{519ABBF6-9E37-41BA-B6BD-076F9534EBD7}.png" src="\lib\media\{519abbf6-9e37-41ba-b6bd-076f9534ebd7}.png">在这里将-novopt去掉即可
]]></description><link>technology\collegeproject\计算机组成原理\实验\实验1：设计alu.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机组成原理/实验/实验1：设计ALU.md</guid><pubDate>Thu, 12 Dec 2024 15:59:14 GMT</pubDate><enclosure url="lib\media\{b87fd227-ec0b-4585-90d8-eb65fa1a6288}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{b87fd227-ec0b-4585-90d8-eb65fa1a6288}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验2: <strong>寄存器组和存储器模块设计实验</strong>]]></title><description><![CDATA[ 
 <br><br><br>存储器设计，完成对寄存器组、数据存储器的设计和实现。掌握CPU存储部件原理与设计方法。<br><br>
<br>理解并掌握计算机存储器部件的设计与实现，尤其是寄存器组和数据存储器的设计。
<br>熟悉Verilog HDL语言的使用，能独立编写并仿真验证存储器模块。
<br>掌握CPU存储部件的原理与设计方法，了解数据存储的读取与写入操作流程。
<br>通过使用Quartus II和ModelSim工具，完成硬件设计与仿真验证。
<br><br><br>寄存器组用于存储CPU的临时数据和地址信息。设计寄存器组的关键是理解寄存器的读写操作：<br>
<br>读操作：从指定的寄存器地址读取数据。
<br>写操作：将数据写入指定的寄存器。
<br>在Verilog中，寄存器组的设计通常是通过一个数组来存储多个寄存器，通过信号控制读写操作。<br><br>数据存储器是用于存储程序数据的硬件部件。通常通过地址总线来选择存储单元，通过数据总线传输数据。设计数据存储器的关键是如何实现读写操作，并控制存储器内容的访问。<br>
<br>读操作：根据给定地址读取数据。
<br>写操作：根据给定地址写入数据。
<br><br>
<br>设计一个32位寄存器组（Registers_32）模块，用于存储CPU内部数据。寄存器组支持读写操作，通过5位地址来选择不同寄存器。
<br>设计一个32位数据存储器（DataMemory）模块，用于存储CPU访问的数据。数据存储器具有256个32位的存储单元，支持数据的读写操作。
<br>将寄存器组与数据存储器连接起来，形成完整的存储部件。
<br>编写顶层模块computer_organization_test2，将所有部件集成到一个完整的系统中。
<br>编写测试平台computer_organization_test2_tb.v，对设计进行仿真验证。
<br><br><br>module Registers_32(Clk, wr, Ra, Rb, Rw, busW, busA, busB);
    parameter n = 32;
    parameter num = 32;
    
    input Clk, wr;
    input [4:0] Ra, Rb, Rw;
    input [n-1:0] busW;
    output reg [n-1:0] busA, busB;
    
    reg [n-1:0] register[num-1:0];
    
    // 初始化寄存器
    initial
        for (i = 0; i &lt; num; i = i + 1)
            register[i] &lt;= i;
    
    // 读操作
    always @(Ra or Rb)
    begin
        busA = register[Ra]; // 读取寄存器Ra
        busB = register[Rb]; // 读取寄存器Rb
    end
    
    // 写操作
    always @(negedge Clk)
    begin
        if (wr)
            register[Rw] &lt;= busW; // 将数据写入寄存器Rw
    end
endmodule
<br><br>module DataMemory(DataIn, Clk, WrEn, Adr, DataOut);

    parameter n = 32;
    input WrEn, Clk;
    input [n-1:0] DataIn;
    input [31:0] Adr;
    output [n-1:0] DataOut;
    
    reg [n-1:0] MemReg[255:0]; // 256个32位存储单元
    integer i;
    
    // 初始化存储器
    initial
        for (i = 0; i &lt; 256; i = i + 1)
            MemReg[i] = i;
    
    // 写操作
    always @(negedge Clk)
    begin
        if (WrEn)
            MemReg[Adr] &lt;= DataIn; // 写入数据
    end
    
    // 读操作
    assign DataOut = MemReg[Adr]; // 从指定地址读取数据

endmodule
<br><br>module computer_organization_test2();
    reg Clk;
    reg WrEn;
    reg [4:0] Ra, Rb, Rw;
    reg [31:0] Adr;
    reg [31:0] busW;
    wire [31:0] busA, busB;
    wire [31:0] DataOut;
    
    // 实例化寄存器组
    Registers_32 reg32 (
        .Clk(Clk),
        .wr(WrEn),
        .Ra(Ra),
        .Rb(Rb),
        .Rw(Rw),
        .busW(busW),
        .busA(busA),
        .busB(busB)
    );
    
    // 实例化数据存储器
    DataMemory dataMem (
        .DataIn(busB),
        .Clk(Clk),
        .WrEn(WrEn),
        .Adr(Adr),
        .DataOut(DataOut)
    );
    
    // 时钟生成
    always
        #5 Clk = ~Clk; // 生成时钟信号
    
    initial begin
        Clk = 0;
        WrEn = 0;
        Adr = 32'd0;
        busW = 32'hA5A5A5A5; // 数据写入寄存器
        Ra = 5'd1; Rb = 5'd2; Rw = 5'd3; // 寄存器操作
        #10 WrEn = 1; // 写操作
        #10 WrEn = 0; // 停止写操作
        #10 Adr = 32'd4; // 访问内存地址4
        #20 $finish;
    end
endmodule
<br><br>
<br>编写测试平台，生成时钟信号，并模拟对寄存器组和数据存储器的读写操作。
<br>使用$display语句输出仿真结果，验证设计的正确性。
<br><br>
<br>在Quartus中创建新工程，将所有Verilog文件添加到项目中。
<br>选择ModelSim或Questa作为仿真工具，并进行仿真。
<br><br><br>仿真中，通过ModelSim或Questa工具生成了波形图，显示了寄存器组与数据存储器的读写过程。以下是仿真输出的部分波形截图（具体截图请附上在报告中）：<br>
<br>时钟信号Clk
<br>写使能信号WrEn
<br>数据输入信号DataIn
<br>数据输出信号DataOut
<br><br>仿真结果表明，寄存器组和数据存储器都能够正确地处理数据读写操作。例如，在某些时刻，寄存器组的值正确地传递到数据存储器，并且数据存储器中的数据成功地被读取。<br><img alt="image-20241212175832852" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212175832852.png" referrerpolicy="no-referrer"><br><br>
<br>寄存器组设计：寄存器组设计简单明了，通过5位地址线可以选择32个寄存器。每个寄存器都是32位宽，支持读写操作。在仿真中，数据能够正确地从一个寄存器传输到另一个寄存器。
<br>数据存储器设计：数据存储器的设计采用了256个32位单元，能够有效地存储数据。在仿真中，数据的读写操作顺利完成，验证了存储器的功能。
<br>时序问题：在设计中，使用negedge Clk来控制写操作，这避免了时序冲突。仿真结果也验证了时序控制的有效性。
<br>仿真工具使用：通过Quartus与ModelSim的集成，仿真过程顺利进行。ModelSim提供了详细的波形图，有助于调试和验证设计。
<br><br>通过本次实验，我深入理解了计算机组成原理中存储器部件的设计与实现。成功设计并验证了一个32位寄存器组和数据存储器模块，掌握了Verilog HDL的使用及仿真工具ModelSim的操作。实验结果表明，设计的寄存器组和数据存储器能够正确地完成数据的存储和读取操作。]]></description><link>technology\collegeproject\计算机组成原理\实验\实验2-寄存器组和存储器模块设计实验.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机组成原理/实验/实验2 寄存器组和存储器模块设计实验.md</guid><pubDate>Sun, 12 Jan 2025 03:11:44 GMT</pubDate><enclosure url="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212175832852.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212175832852.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验3：取指部件设计实验]]></title><description><![CDATA[ 
 <br><br><br>本实验旨在完成程序计数器（PC）、指令存储器及下地址逻辑的设计和实现，掌握取指部件的原理与设计方法。通过实现一个简单的指令取出流程，进一步理解计算机系统中的指令取指部分如何工作。<br><br>
<br>硬件描述语言：Verilog
<br>仿真工具：QuartusII
<br><br><br>本实验设计了一个基本的指令取指部件，包含以下模块：<br>
<br>程序计数器（PC）：保持当前指令的地址，并根据时钟信号递增，或者根据分支、跳转指令修改PC的值。
<br>指令存储器（IM）：存储指令，并根据PC提供的地址返回相应的指令。
<br>下地址逻辑（Address Logic）：根据分支、跳转等条件，计算下一个PC的值。
<br><br>顶层模块集成了程序计数器（PC）、指令存储器（IM）和下地址逻辑。其工作流程如下：<br>
<br>程序计数器（PC）：根据时钟和复位信号，更新PC的值，指向下一条要执行的指令。
<br>指令存储器（IM）：根据当前PC的地址从指令存储器中取出指令。
<br>下地址逻辑（Address Logic）：根据控制信号（如分支、跳转信号），决定下一个PC的值。
<br><br><br>module program_counter (
    input clk,                // 时钟信号
    input reset,              // 重置信号
    input [31:0] next_pc,     // 下一个PC地址
    output reg [31:0] pc      // 当前PC值
);

    always @(posedge clk or posedge reset) begin
        if (reset)
            pc &lt;= 32'h00000000;   // 重置PC为0
        else
            pc &lt;= next_pc;        // 更新PC
    end

endmodule
<br><br>module instruction_memory (
    input [31:0] addr,         // 地址输入
    output [31:0] instruction  // 输出指令
);

    reg [31:0] mem [0:255];    // 256条32位指令

    assign instruction = mem[addr[31:2]];  // 根据地址读取指令

    initial begin
        // 初始化指令存储器，假设只有前两条指令
        mem[0] = 32'h00000001;
        mem[1] = 32'h00000002;
        // 可以继续初始化其他指令
    end

endmodule
<br><br>module address_logic (
    input [31:0] current_pc,   // 当前PC值
    input [31:0] branch_addr,  // 分支跳转地址
    input branch_taken,        // 分支是否成立
    output [31:0] next_pc      // 输出下一个PC地址
);

    assign next_pc = branch_taken ? branch_addr : current_pc + 4; // 如果分支成立，跳转到branch_addr，否则PC递增4

endmodule
<br><br>module top_module (
    input clk,            // 时钟信号
    input reset,          // 重置信号
    input branch,         // 分支信号
    input jump,           // 跳转信号
    input zero,           // 零标志信号
    input [31:0] jump_addr, // 跳转地址
    output [31:0] pc,     // 当前PC值
    output [31:0] instruction  // 输出的指令
);

    wire [31:0] next_pc;      // 计算出的下一个PC地址

    // 程序计数器（PC）模块
    program_counter pc_module (
        .clk(clk),
        .reset(reset),
        .next_pc(next_pc),   // 下一个PC地址
        .pc(pc)               // 当前PC值
    );

    // 指令存储器（IM）模块
    instruction_memory im (
        .addr(pc),            // 通过PC获取地址
        .instruction(instruction) // 输出指令
    );

    // 下地址逻辑（Address Logic）模块
    address_logic addr_logic (
        .current_pc(pc),      // 当前PC值
        .branch_addr(jump_addr), // 跳转地址
        .branch_taken(branch &amp; zero), // 判断是否分支
        .next_pc(next_pc)     // 下一个PC值
    );

endmodule
<br><img alt="image-20241212183816950" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212183816950.png" referrerpolicy="no-referrer"><br><br>module tb_top_module;

    reg clk;                 // 时钟信号
    reg reset;               // 重置信号
    reg branch;              // 分支信号
    reg jump;                // 跳转信号
    reg zero;                // 零标志信号
    reg [31:0] jump_addr;    // 跳转地址
    wire [31:0] pc;          // 当前PC值
    wire [31:0] instruction; // 输出指令

    // 实例化顶层模块
    top_module uut (
        .clk(clk),
        .reset(reset),
        .branch(branch),
        .jump(jump),
        .zero(zero),
        .jump_addr(jump_addr),
        .pc(pc),
        .instruction(instruction)
    );

    // 时钟生成
    always begin
        #5 clk = ~clk;  // 每5个单位反转时钟
    end

    // 初始化信号
    initial begin
        clk = 0;
        reset = 0;
        branch = 0;
        jump = 0;
        zero = 0;
        jump_addr = 32'h00000004;

        // 测试用例
        #10 reset = 1;     // 激活复位信号
        #10 reset = 0;     // 释放复位信号

        // 模拟顺序执行
        #20 branch = 0;    // 不发生分支
        #20 branch = 1;    // 发生分支
        #20 jump = 1;      // 发生跳转
        #20 zero = 1;      // 零标志信号为1
        #50 jump = 0;      // 不跳转
        #100 $finish;      // 结束仿真
    end

    // 监视输出
    initial begin
        $monitor("At time %t, PC = %h, Instruction = %h", $time, pc, instruction);
    end

endmodule
<br><br>
<br>编写各个模块：首先编写程序计数器、指令存储器和下地址逻辑模块，每个模块都具有明确的功能。
<br>集成顶层模块：将各个模块集成到一个顶层模块中，并确保它们之间的信号正确连接。
<br>编写测试平台：编写测试平台进行仿真，模拟时钟信号、重置信号和其他控制信号，观察PC和指令的输出。
<br>仿真与调试：使用Vivado或其他仿真工具进行仿真，观察波形，检查PC更新、指令取出等是否符合预期。
<br><br><img alt="image-20241212184249317" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212184249317.png" referrerpolicy="no-referrer"><br><br>
<br>在时钟信号变化时，程序计数器（PC）根据控制信号（如跳转、分支）更新其值。
<br>当复位信号被激活时，PC会被重置为0。
<br><br>
<br>程序计数器每次时钟脉冲后会递增4，除非发生跳转或分支。
<br>跳转或分支时，PC值根据跳转地址或分支条件更新。
<br><br>
<br>指令存储器根据当前PC的地址从内存中取出对应的指令，并输出。
<br><br>
<br>下地址逻辑根据分支信号和零标志信号计算下一个PC值。如果发生分支并且零标志信号为1，PC会跳转到分支地址；否则，PC会递增。
<br><br>仿真波形显示了PC的变化，指令输出以及跳转/分支是否按照设计要求执行。<br><br>通过本实验，成功实现了一个基本的取指部件设计，包括程序计数器、指令存储器以及下地址逻辑。通过仿真验证了各个模块的正确性，掌握了计算机系统中指令取出和跳转、分支控制的基本原理。]]></description><link>technology\collegeproject\计算机组成原理\实验\实验3-取指部件设计实验.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机组成原理/实验/实验3 取指部件设计实验.md</guid><pubDate>Sun, 12 Jan 2025 03:11:45 GMT</pubDate><enclosure url="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212183816950.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212183816950.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验4：CPU 数据通路设计实验]]></title><description><![CDATA[ 
 <br><br><br>本实验旨在将算术逻辑单元（ALU）、存储器、取指部件互连，完成一个完整的CPU数据通路设计。通过实现一个简化的CPU数据通路，掌握指令的数据通路设计与实现方法。<br><br>
<br>硬件描述语言：Verilog
<br>仿真工具：Vivado（或其他Verilog仿真工具）
<br>目标平台：FPGA（如果需要实现实际硬件）
<br><br><br>本实验设计的CPU包含以下基本模块：<br>
<br>程序计数器（PC）：保持当前指令的地址，并根据时钟信号递增或修改PC的值（通过分支或跳转）。
<br>指令存储器（IM）：存储指令，根据PC地址读取对应的指令。
<br>算术逻辑单元（ALU）：执行算术和逻辑操作，如加法、减法、与、或等。
<br>寄存器文件（RegFile）：存储数据寄存器，提供读写功能。
<br>数据存储器（DataMemory）：用于数据存储操作，可以进行读取和写入。
<br><br>整个CPU的工作流程为：<br>
<br>程序计数器（PC）：根据当前PC值和控制信号计算下一个PC值。
<br>指令存储器（IM）：根据PC值取出指令。
<br>寄存器文件（RegFile）：根据指令读取和写入寄存器。
<br>ALU：执行指令中的算术逻辑运算。
<br>数据存储器（DataMemory）：执行数据存取指令，写回数据。
<br>顶层设计将这些模块通过数据和控制信号互联，形成一个完整的CPU数据通路。<br><br><br>module program_counter (
    input clk,                // 时钟信号
    input reset,              // 重置信号
    input [31:0] next_pc,     // 下一个PC地址
    output reg [31:0] pc      // 当前PC值
);

    always @(posedge clk or posedge reset) begin
        if (reset)
            pc &lt;= 32'h00000000;   // 重置PC为0
        else
            pc &lt;= next_pc;        // 更新PC
    end

endmodule
<br><br>module instruction_memory (
    input [31:0] addr,         // 地址输入
    output [31:0] instruction  // 输出指令
);

    reg [31:0] mem [0:255];    // 256条32位指令

    assign instruction = mem[addr[31:2]];  // 根据地址读取指令

    initial begin
        // 初始化指令存储器，假设只有前两条指令
        mem[0] = 32'h00000001;
        mem[1] = 32'h00000002;
        // 可以继续初始化其他指令
    end

endmodule
<br><br>module ALU (
    input [31:0] A,           // 操作数A
    input [31:0] B,           // 操作数B
    input [3:0] ALU_Control,  // ALU控制信号
    output reg [31:0] ALU_Result,  // ALU输出结果
    output reg Zero           // 结果是否为零
);

    always @(*) begin
        case (ALU_Control)
            4'b0000: ALU_Result = A + B;        // 加法
            4'b0001: ALU_Result = A - B;        // 减法
            4'b0010: ALU_Result = A &amp; B;        // 与
            4'b0011: ALU_Result = A | B;        // 或
            4'b0100: ALU_Result = A ^ B;        // 异或
            default: ALU_Result = 32'b0;        // 默认值
        endcase
        Zero = (ALU_Result == 32'b0);  // 检查结果是否为零
    end

endmodule
<br><br>module register_file (
    input clk,               // 时钟信号
    input reset,             // 重置信号
    input reg_write,         // 寄存器写入使能信号
    input [4:0] rs,          // 源寄存器地址
    input [4:0] rt,          // 目标寄存器地址
    input [4:0] rd,          // 目的寄存器地址
    input [31:0] write_data, // 写入数据
    output [31:0] read_data1, // 读出源寄存器数据
    output [31:0] read_data2  // 读出目标寄存器数据
);

    reg [31:0] regs [31:0];  // 32个32位寄存器

    assign read_data1 = regs[rs];  // 读出源寄存器数据
    assign read_data2 = regs[rt];  // 读出目标寄存器数据

    always @(posedge clk or posedge reset) begin
        if (reset)
            regs[0] &lt;= 32'b0;  // 寄存器0初始化为0
        else if (reg_write)
            regs[rd] &lt;= write_data;  // 写入数据
    end

endmodule
<br><br>module data_memory (
    input clk,               // 时钟信号
    input [31:0] addr,       // 存储器地址
    input [31:0] write_data, // 写入数据
    input mem_write,         // 存储器写使能信号
    input mem_read,          // 存储器读使能信号
    output reg [31:0] read_data // 读出数据
);

    reg [31:0] mem [0:255];  // 存储器，共256个32位单元

    always @(posedge clk) begin
        if (mem_write)
            mem[addr] &lt;= write_data;  // 写数据到存储器
        if (mem_read)
            read_data &lt;= mem[addr];   // 从存储器读取数据
    end

endmodule
<br><br>module top_cpu (
    input clk,                // 时钟信号
    input reset,              // 重置信号
    output [31:0] pc,         // 当前PC值
    output [31:0] instruction, // 输出指令
    output [31:0] ALU_Result  // ALU计算结果
);

    wire [31:0] next_pc;          // 计算出的下一个PC地址
    wire [31:0] reg_data1, reg_data2; // 寄存器读取的数据
    wire [31:0] alu_input2;       // ALU的输入
    wire [3:0] ALU_Control;       // ALU控制信号
    wire reg_write;               // 寄存器写使能信号
    wire mem_read, mem_write;     // 存储器读写使能信号

    // 程序计数器（PC）模块
    program_counter pc_module (
        .clk(clk),
        .reset(reset),
        .next_pc(next_pc),
        .pc(pc)
    );

    // 指令存储器（IM）模块
    instruction_memory im (
        .addr(pc),
        .instruction(instruction)
    );

    // 寄存器文件（RegFile）模块
    register_file reg_file (
        .clk(clk),
        .reset(reset),
        .reg_write(reg_write),
        .rs(instruction[25:21]),  // 假设rs是指令的第6-10位
        .rt(instruction[20:16]),  // 假设rt是指令的第11-15位
        .rd(instruction[15:11]),  // 假设rd是指令的第16-20位
        .write_data(ALU_Result),
        .read_data1(reg_data1),
        .read_data2(reg_data2)
    );

    // ALU模块
    ALU alu (
        .A(reg_data1),
        .B(alu_input2),
        .ALU_Control(ALU_Control),
        .ALU_Result(ALU_Result),
        .Zero() // 可扩展
    );

    // 数据存储器（DataMemory）模块
    data_memory dm (
        .clk(clk),
        .addr(reg_data1),    // 假设ALU结果作为地址
        .write_data(reg_data2),
        .mem_write(mem_write),
        .mem_read(mem_read),
        .read_data(ALU_Result)
    );

    // 控制信号生成逻辑（简化版）
    // 可以根据需要进一步扩展

    assign next_pc = pc + 4;  // 简单的PC递增实现

endmodule
<br><img alt="image-20241212193225009" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212193225009.png" referrerpolicy="no-referrer"><br><img alt="image-20241212193520532" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212193520532.png" referrerpolicy="no-referrer"><br><br>通过本实验，成功实现了一个简化版的CPU数据通路设计。仿真结果表明，各个模块能够正确交互，ALU能够执行运算，寄存器文件能够读写数据，数据存储器能够正确存储和读取数据。实验过程加深了对CPU数据通路设计及其各个模块功能的理解，并为进一步的CPU架构设计和优化奠定了基础。]]></description><link>technology\collegeproject\计算机组成原理\实验\实验4：单周期-cpu-数据通路设计实验.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机组成原理/实验/实验4：单周期 CPU 数据通路设计实验.md</guid><pubDate>Sun, 12 Jan 2025 03:11:45 GMT</pubDate><enclosure url="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212193225009.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212193225009.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验5：单周期 CPU 控制部件设计与实现]]></title><description><![CDATA[ 
 <br><br><br>本实验旨在通过使用 Verilog HDL 设计一个简单的单周期 CPU 控制部件。该 CPU 将包括指令译码、控制信号生成、ALU 操作、寄存器文件操作、存储器访问等模块。在设计过程中，通过实现每条指令的执行过程，结合指令的控制信号与指令编码的关系，设计出完整的控制信号生成单元。实验还将重点掌握译码器的组合逻辑设计方法，完成单周期 CPU 的基本设计和调试。<br><br>
<br>开发工具：Quartus Prime 20.1
<br>语言：Verilog HDL
<br>操作系统：Windows 11 / Linux（支持Quartus开发）
<br><br>本实验的目标是设计并实现一个简单的单周期 CPU，该 CPU 包括以下几个主要模块：<br>
<br>程序计数器（PC）：用于存储和更新当前执行的指令地址。
<br>指令寄存器：存储从内存读取的当前指令。
<br>控制单元：生成控制信号，根据指令的操作码（opcode）确定 ALU 操作、寄存器写使能等。
<br>寄存器文件：存储寄存器值，支持从指定寄存器读取数据并将 ALU 结果写回。
<br>ALU（算术逻辑单元）：执行算术和逻辑运算。
<br>数据存储器：读写内存的数据。
<br>结果选择器：根据控制信号选择从内存或 ALU 输出的最终结果。
<br><br>
<br>控制单元 (Control Unit)： 控制单元根据指令的操作码（opcode）生成控制信号，包括：

<br>ALUSrc: ALU 输入的选择。
<br>MemRead, MemWrite: 控制内存的读写操作。
<br>RegWrite: 控制寄存器的写使能。
<br>MemToReg: 控制数据选择，是从内存获取结果还是 ALU 结果。


<br>寄存器文件 (Register File)： 包括读寄存器和写寄存器的操作。每个寄存器都包含一个 32 位的数据。寄存器文件通过控制信号决定是否写入 ALU 的结果或存储器的结果。
<br>ALU： ALU 根据控制信号执行基本的算术和逻辑运算，如加法、减法、与、或等。
<br>数据存储器 (Data Memory)： 存储器用于存取数据。它提供读和写操作接口，通过 ALU 结果作为地址进行内存访问。
<br>结果选择器： 根据 MemToReg 控制信号，选择是从内存读取数据还是使用 ALU 计算结果作为最终的写回数据。
<br><br>`timescale 1 ps/ 1 ps

module top_cpu (
    input clk,
    input rst,
    input branch,
    input [31:0] branch_addr,
    input jump,
    input [31:0] jump_addr,
    input mem_read,
    input mem_write,
    input [4:0] read_addr_1,
    input [4:0] read_addr_2,
    input [4:0] write_addr,
    input [31:0] write_data,
    input write_enable,
    output [31:0] ALU_result,
    output [31:0] PC,
    output [31:0] instruction,
    output [31:0] mem_read_data,
    output [31:0] read_data_1,
    output [31:0] read_data_2
);


    reg [31:0] pc;
    always @(posedge clk or posedge rst) begin
        if (rst) begin
            pc &lt;= 32'b0; 
        end else if (branch) begin
            pc &lt;= branch_addr; 
        end else if (jump) begin
            pc &lt;= jump_addr; 
        end else begin
            pc &lt;= pc + 4; 
        end
    end

    assign PC = pc; 

 
    reg [31:0] instruction_memory [0:31];
    

    initial begin
        instruction_memory[0] = 32'h00000001; 
        instruction_memory[1] = 32'h00000002;
        instruction_memory[2] = 32'h00000003;
        instruction_memory[3] = 32'h00000004;

    end

    assign instruction = instruction_memory[pc[6:2]]; 


    wire ALU_op;
    wire mem_to_reg;
    wire mem_read_out;
    wire mem_write_out;
    wire reg_write;
    wire reg_dst;
    wire branch_out;
    wire jump_out;
    
    control_unit CU (
        .opcode(instruction[31:26]),
        .ALU_op(ALU_op),
        .mem_to_reg(mem_to_reg),
        .mem_read(mem_read_out),
        .mem_write(mem_write_out),
        .reg_write(reg_write),
        .reg_dst(reg_dst),
        .branch(branch_out),
        .jump(jump_out)
    );

    // ALU
    wire [31:0] ALU_input1, ALU_input2;
    assign ALU_input1 = read_data_1;
    assign ALU_input2 = (reg_dst) ? read_data_2 : write_data; 

    alu ALU (
        .ALU_op(ALU_op),
        .input1(ALU_input1),
        .input2(ALU_input2),
        .result(ALU_result)
    );


    register_file rf (
        .clk(clk),
        .rst(rst),
        .read_addr_1(read_addr_1),
        .read_addr_2(read_addr_2),
        .write_addr(write_addr),
        .write_data(ALU_result), 
        .write_enable(reg_write),
        .read_data_1(read_data_1),
        .read_data_2(read_data_2)
    );

 
    data_memory dm (
        .clk(clk),
        .rst(rst),
        .addr(ALU_result), 
        .write_data(write_data),
        .mem_read(mem_read_out),
        .mem_write(mem_write_out),
        .read_data(mem_read_data)
    );

endmodule



module control_unit (
    input [5:0] opcode, 
    output reg ALU_op,
    output reg mem_to_reg,
    output reg mem_read,
    output reg mem_write,
    output reg reg_write,
    output reg reg_dst,
    output reg branch,
    output reg jump
);

    always @(*) begin
        case (opcode)
            6'b000000: begin 
                ALU_op = 1;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 0;
                reg_write = 1;
                reg_dst = 1;
                branch = 0;
                jump = 0;
            end
            6'b100011: begin
                ALU_op = 0;
                mem_to_reg = 1;
                mem_read = 1;
                mem_write = 0;
                reg_write = 1;
                reg_dst = 0;
                branch = 0;
                jump = 0;
            end
            6'b101011: begin
                ALU_op = 0;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 1;
                reg_write = 0;
                reg_dst = 0;
                branch = 0;
                jump = 0;
            end
            6'b000100: begin 
                ALU_op = 0;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 0;
                reg_write = 0;
                reg_dst = 0;
                branch = 1;
                jump = 0;
            end
            6'b000010: begin 
                ALU_op = 0;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 0;
                reg_write = 0;
                reg_dst = 0;
                branch = 0;
                jump = 1;
            end
            default: begin
                ALU_op = 0;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 0;
                reg_write = 0;
                reg_dst = 0;
                branch = 0;
                jump = 0;
            end
        endcase
    end

endmodule


module alu (
    input ALU_op,
    input [31:0] input1,
    input [31:0] input2,
    output reg [31:0] result
);

    always @(*) begin
        if (ALU_op) begin
            result = input1 + input2; 
        end else begin
            result = input1 - input2; 
        end
    end

endmodule


module register_file (
    input clk,
    input rst,
    input [4:0] read_addr_1,
    input [4:0] read_addr_2,
    input [4:0] write_addr,
    input [31:0] write_data,
    input write_enable,
    output reg [31:0] read_data_1,
    output reg [31:0] read_data_2
);

    reg [31:0] registers [31:0];

    always @(*) begin
        read_data_1 = registers[read_addr_1];
        read_data_2 = registers[read_addr_2];
    end

    always @(posedge clk or posedge rst) begin
        if (rst) begin
            registers[0] &lt;= 32'b0; 
        end else if (write_enable) begin
            registers[write_addr] &lt;= write_data;
        end
    end

endmodule

module data_memory (
    input clk,
    input rst,
    input [31:0] addr,
    input [31:0] write_data,
    input mem_read,
    input mem_write,
    output reg [31:0] read_data
);

    reg [31:0] memory [31:0];
    
    integer i;
    always @(posedge clk or posedge rst) begin
        if (rst) begin
            for (i = 0; i &lt; 32; i = i + 1) begin
                memory[i] &lt;= 32'b0;
            end
        end else if (mem_write) begin
            memory[addr] &lt;= write_data;
        end
    end

    always @(posedge clk) begin
        if (mem_read) begin
            read_data &lt;= memory[addr];
        end
    end

endmodule


<br><br><img alt="image-20241212235438698" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212235438698.png" referrerpolicy="no-referrer"><br>通过对各模块进行仿真测试，发现设计能够成功实现指令的取值、译码、控制信号的生成以及指令执行过程中的各个操作。最终，单周期 CPU 在指定的测试用例下能够正确执行。<br><br>通过本次实验，我们完成了一个简化版的单周期 CPU 的设计。实验过程中，掌握了如何使用 Verilog 语言设计各个硬件模块，并调试了每个模块以<br>确保其正常工作。通过这次实验，加深了对 CPU 内部操作流程的理解，为后续的多周期 CPU 设计奠定了基础。]]></description><link>technology\collegeproject\计算机组成原理\实验\实验5-单周期-cpu-控制部件设计.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机组成原理/实验/实验5 单周期 CPU 控制部件设计.md</guid><pubDate>Sun, 12 Jan 2025 03:11:46 GMT</pubDate><enclosure url="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212235438698.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212235438698.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验1：设计ALU]]></title><description><![CDATA[ 
 <br><br><br>本实验旨在设计和实现一个基本的算术逻辑单元（ALU），并验证其功能。ALU是计算机处理器中的一个重要组件，负责执行基本的算术和逻辑运算。通过本实验，将学习如何使用硬件描述语言（HDL）设计和仿真ALU，并将其部署到FPGA上进行实际测试。<br><br>
<br>软件

<br>Quartus II（或其他FPGA开发软件）
<br>ModelSim（或其他仿真工具）


<br><br><br>
<br>
定义模块接口

<br>输入：

<br>A 和 B：32位数据输入。
<br>ALUctrl：3位控制信号，用于选择操作类型。


<br>输出：

<br>ALUout：32位输出结果。
<br>Zero：1位输出，表示结果是否为零。
<br>Overflow：1位输出，表示是否有溢出。




<br>
编写Verilog代码

<br>创建一个名为 ALU.v 的Verilog文件，实现ALU模块。

module ALU(
    input wire [31:0] A, B,
    input wire [2:0] ALUctrl,
    output reg [31:0] ALUout,
    output reg Zero,
    output reg Overflow
);

wire [31:0] addResult, subResult, orResult, sltuResult, slltResult;

assign addResult = A + B;
assign subResult = A - B;
assign orResult = A | B;
assign sltuResult = (A &lt; B) ? 1'b1 : 1'b0;
assign slltResult = ($signed(A) &lt; $signed(B)) ? 1'b1 : 1'b0;

always @* begin
    case(ALUctrl)
        3'b000: begin // addu
            ALUout = addResult;
            Zero = (addResult == 0);
            Overflow = 0;
        end
        3'b001: begin // add
            ALUout = addResult;
            Zero = (addResult == 0);
            Overflow = (A[31] &amp; B[31] &amp; ~addResult[31]) | (~A[31] &amp; ~B[31] &amp; addResult[31]);
        end
        3'b010: begin // or
            ALUout = orResult;
            Zero = (orResult == 0);
            Overflow = 0;
        end
        3'b100: begin // subu
            ALUout = subResult;
            Zero = (subResult == 0);
            Overflow = 0;
        end
        3'b101: begin // sub
            ALUout = subResult;
            Zero = (subResult == 0);
            Overflow = (A[31] &amp; ~B[31] &amp; ~subResult[31]) | (~A[31] &amp; B[31] &amp; subResult[31]);
        end
        3'b110: begin // sltu
            ALUout = {31'b0, sltuResult}; // Extend to 32 bits
            Zero = (sltuResult == 0);
            Overflow = 0;
        end
        3'b111: begin // sllt
            ALUout = {31'b0, slltResult}; // Extend to 32 bits
            Zero = (slltResult == 0);
            Overflow = 0;
        end
        default: begin
            ALUout = 0;
            Zero = 1;
            Overflow = 0;
        end
    endcase
end

endmodule


<br><img alt="{B87FD227-EC0B-4585-90D8-EB65FA1A6288}.png" src="\lib\media\{b87fd227-ec0b-4585-90d8-eb65fa1a6288}.png"><br><br>仿真测试有两种方式：<br>
<br>一种是编写testbench文件，通过ModelSim进行测试。
<br>另一种是使用Quartus自带的仿真软件进行测试。
<br>
<br>
创建测试平台文件

<br>创建一个名为 ALU_testbench.v 的Verilog文件，编写测试平台代码。

module ALU_testbench;

    // Inputs
    reg [31:0] A;
    reg [31:0] B;
    reg [2:0] ALUctrl;

    // Outputs
    wire [31:0] ALUout;
    wire Zero;
    wire Overflow;

    // Instantiate the ALU module
    ALU uut (
        .A(A),
        .B(B),
        .ALUctrl(ALUctrl),
        .ALUout(ALUout),
        .Zero(Zero),
        .Overflow(Overflow)
    );

    // Initialize test data
    initial begin
        // Initialize inputs
        A = 32'b0;
        B = 32'b0;
        ALUctrl = 3'b000;

        // Test cases
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b000; // addu
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b001; // add
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b010; // or
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b100; // subu
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b101; // sub
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b110; // sltu
        #10 A = 32'd5; B = 32'd3; ALUctrl = 3'b111; // sllt

        // Add more test cases as needed
        #10 $stop;
    end

    // Monitor outputs
    initial begin
        $monitor("At time %0t, A=%b, B=%b, ALUctrl=%b, ALUout=%b, Zero=%b, Overflow=%b", $time, A, B, ALUctrl, ALUout, Zero, Overflow);
    end

endmodule


<br><br>
<br>
编译项目

<br>打开Quartus II，创建一个新的项目。
<br>添加 ALU.v 和 ALU_testbench.v 文件。
<br>选择 Processing -&gt; Start -&gt; Start Analysis &amp; Elaboration。


<br>
创建波形文件

<br>选择 File -&gt; New -&gt; Vector Waveform File，创建一个波形文件 ALU_waveform.vwf。
<br>添加测试平台中的信号到波形文件中。


<br>
运行仿真

<br>在波形编辑器中，选择 Simulate -&gt; Run Simulation。
<br>选择 Functional Simulation 。
<br>点击 OK 开始仿真。


<br><br><img alt="{5FBD348F-D595-47A5-9CBB-1917CA44E430}.png" src="\lib\media\{5fbd348f-d595-47a5-9cbb-1917ca44e430}.png"><br>
<img alt="{E0FE90E5-4A2E-4D12-A942-29861AC2857A}.png" src="\lib\media\{e0fe90e5-4a2e-4d12-a942-29861ac2857a}.png"><br>
<br>
仿真结果

<br>观察波形文件中的信号变化，确保ALU的输出结果符合预期。
<br>记录每个测试用例的输出结果，并与预期结果进行比较。


<br>
分析

<br>分析仿真和实际测试结果的一致性。
<br>讨论可能出现的问题及其解决方案。


<br><br>通过本实验，深入了解ALU的设计和实现过程，掌握使用HDL进行数字系统设计的方法。<br>
遇到的问题：<br>
<br>Quartus的仿真编译问题<img alt="{21B7BF11-17C5-4007-B40B-D5A617C0FC5A} 1.png" src="\lib\media\{21b7bf11-17c5-4007-b40b-d5a617c0fc5a}-1.png"><img alt="{519ABBF6-9E37-41BA-B6BD-076F9534EBD7}.png" src="\lib\media\{519abbf6-9e37-41ba-b6bd-076f9534ebd7}.png">在这里将-novopt去掉即可
<br><br><br>存储器设计，完成对寄存器组、数据存储器的设计和实现。掌握CPU存储部件原理与设计方法。<br><br>
<br>理解并掌握计算机存储器部件的设计与实现，尤其是寄存器组和数据存储器的设计。
<br>熟悉Verilog HDL语言的使用，能独立编写并仿真验证存储器模块。
<br>掌握CPU存储部件的原理与设计方法，了解数据存储的读取与写入操作流程。
<br>通过使用Quartus II和ModelSim工具，完成硬件设计与仿真验证。
<br><br><br>寄存器组用于存储CPU的临时数据和地址信息。设计寄存器组的关键是理解寄存器的读写操作：<br>
<br>读操作：从指定的寄存器地址读取数据。
<br>写操作：将数据写入指定的寄存器。
<br>在Verilog中，寄存器组的设计通常是通过一个数组来存储多个寄存器，通过信号控制读写操作。<br><br>数据存储器是用于存储程序数据的硬件部件。通常通过地址总线来选择存储单元，通过数据总线传输数据。设计数据存储器的关键是如何实现读写操作，并控制存储器内容的访问。<br>
<br>读操作：根据给定地址读取数据。
<br>写操作：根据给定地址写入数据。
<br><br>
<br>设计一个32位寄存器组（Registers_32）模块，用于存储CPU内部数据。寄存器组支持读写操作，通过5位地址来选择不同寄存器。
<br>设计一个32位数据存储器（DataMemory）模块，用于存储CPU访问的数据。数据存储器具有256个32位的存储单元，支持数据的读写操作。
<br>将寄存器组与数据存储器连接起来，形成完整的存储部件。
<br>编写顶层模块computer_organization_test2，将所有部件集成到一个完整的系统中。
<br>编写测试平台computer_organization_test2_tb.v，对设计进行仿真验证。
<br><br><br>module Registers_32(Clk, wr, Ra, Rb, Rw, busW, busA, busB);
    parameter n = 32;
    parameter num = 32;
    
    input Clk, wr;
    input [4:0] Ra, Rb, Rw;
    input [n-1:0] busW;
    output reg [n-1:0] busA, busB;
    
    reg [n-1:0] register[num-1:0];
    
    // 初始化寄存器
    initial
        for (i = 0; i &lt; num; i = i + 1)
            register[i] &lt;= i;
    
    // 读操作
    always @(Ra or Rb)
    begin
        busA = register[Ra]; // 读取寄存器Ra
        busB = register[Rb]; // 读取寄存器Rb
    end
    
    // 写操作
    always @(negedge Clk)
    begin
        if (wr)
            register[Rw] &lt;= busW; // 将数据写入寄存器Rw
    end
endmodule
<br><br>module DataMemory(DataIn, Clk, WrEn, Adr, DataOut);

    parameter n = 32;
    input WrEn, Clk;
    input [n-1:0] DataIn;
    input [31:0] Adr;
    output [n-1:0] DataOut;
    
    reg [n-1:0] MemReg[255:0]; // 256个32位存储单元
    integer i;
    
    // 初始化存储器
    initial
        for (i = 0; i &lt; 256; i = i + 1)
            MemReg[i] = i;
    
    // 写操作
    always @(negedge Clk)
    begin
        if (WrEn)
            MemReg[Adr] &lt;= DataIn; // 写入数据
    end
    
    // 读操作
    assign DataOut = MemReg[Adr]; // 从指定地址读取数据

endmodule
<br><br>module computer_organization_test2();
    reg Clk;
    reg WrEn;
    reg [4:0] Ra, Rb, Rw;
    reg [31:0] Adr;
    reg [31:0] busW;
    wire [31:0] busA, busB;
    wire [31:0] DataOut;
    
    // 实例化寄存器组
    Registers_32 reg32 (
        .Clk(Clk),
        .wr(WrEn),
        .Ra(Ra),
        .Rb(Rb),
        .Rw(Rw),
        .busW(busW),
        .busA(busA),
        .busB(busB)
    );
    
    // 实例化数据存储器
    DataMemory dataMem (
        .DataIn(busB),
        .Clk(Clk),
        .WrEn(WrEn),
        .Adr(Adr),
        .DataOut(DataOut)
    );
    
    // 时钟生成
    always
        #5 Clk = ~Clk; // 生成时钟信号
    
    initial begin
        Clk = 0;
        WrEn = 0;
        Adr = 32'd0;
        busW = 32'hA5A5A5A5; // 数据写入寄存器
        Ra = 5'd1; Rb = 5'd2; Rw = 5'd3; // 寄存器操作
        #10 WrEn = 1; // 写操作
        #10 WrEn = 0; // 停止写操作
        #10 Adr = 32'd4; // 访问内存地址4
        #20 $finish;
    end
endmodule
<br><br>
<br>编写测试平台，生成时钟信号，并模拟对寄存器组和数据存储器的读写操作。
<br>使用$display语句输出仿真结果，验证设计的正确性。
<br><br>
<br>在Quartus中创建新工程，将所有Verilog文件添加到项目中。
<br>选择ModelSim或Questa作为仿真工具，并进行仿真。
<br><br><br>仿真中，通过ModelSim或Questa工具生成了波形图，显示了寄存器组与数据存储器的读写过程。以下是仿真输出的部分波形截图（具体截图请附上在报告中）：<br>
<br>时钟信号Clk
<br>写使能信号WrEn
<br>数据输入信号DataIn
<br>数据输出信号DataOut
<br><br>仿真结果表明，寄存器组和数据存储器都能够正确地处理数据读写操作。例如，在某些时刻，寄存器组的值正确地传递到数据存储器，并且数据存储器中的数据成功地被读取。<br><img alt="image-20241212175832852" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212175832852.png" referrerpolicy="no-referrer"><br><br>
<br>寄存器组设计：寄存器组设计简单明了，通过5位地址线可以选择32个寄存器。每个寄存器都是32位宽，支持读写操作。在仿真中，数据能够正确地从一个寄存器传输到另一个寄存器。
<br>数据存储器设计：数据存储器的设计采用了256个32位单元，能够有效地存储数据。在仿真中，数据的读写操作顺利完成，验证了存储器的功能。
<br>时序问题：在设计中，使用negedge Clk来控制写操作，这避免了时序冲突。仿真结果也验证了时序控制的有效性。
<br>仿真工具使用：通过Quartus与ModelSim的集成，仿真过程顺利进行。ModelSim提供了详细的波形图，有助于调试和验证设计。
<br><br>通过本次实验，我深入理解了计算机组成原理中存储器部件的设计与实现。成功设计并验证了一个32位寄存器组和数据存储器模块，掌握了Verilog HDL的使用及仿真工具ModelSim的操作。实验结果表明，设计的寄存器组和数据存储器能够正确地完成数据的存储和读取操作。<br><br><br>本实验旨在完成程序计数器（PC）、指令存储器及下地址逻辑的设计和实现，掌握取指部件的原理与设计方法。通过实现一个简单的指令取出流程，进一步理解计算机系统中的指令取指部分如何工作。<br><br>
<br>硬件描述语言：Verilog
<br>仿真工具：QuartusII
<br><br><br>本实验设计了一个基本的指令取指部件，包含以下模块：<br>
<br>程序计数器（PC）：保持当前指令的地址，并根据时钟信号递增，或者根据分支、跳转指令修改PC的值。
<br>指令存储器（IM）：存储指令，并根据PC提供的地址返回相应的指令。
<br>下地址逻辑（Address Logic）：根据分支、跳转等条件，计算下一个PC的值。
<br><br>顶层模块集成了程序计数器（PC）、指令存储器（IM）和下地址逻辑。其工作流程如下：<br>
<br>程序计数器（PC）：根据时钟和复位信号，更新PC的值，指向下一条要执行的指令。
<br>指令存储器（IM）：根据当前PC的地址从指令存储器中取出指令。
<br>下地址逻辑（Address Logic）：根据控制信号（如分支、跳转信号），决定下一个PC的值。
<br><br><br>module program_counter (
    input clk,                // 时钟信号
    input reset,              // 重置信号
    input [31:0] next_pc,     // 下一个PC地址
    output reg [31:0] pc      // 当前PC值
);

    always @(posedge clk or posedge reset) begin
        if (reset)
            pc &lt;= 32'h00000000;   // 重置PC为0
        else
            pc &lt;= next_pc;        // 更新PC
    end

endmodule
<br><br>module instruction_memory (
    input [31:0] addr,         // 地址输入
    output [31:0] instruction  // 输出指令
);

    reg [31:0] mem [0:255];    // 256条32位指令

    assign instruction = mem[addr[31:2]];  // 根据地址读取指令

    initial begin
        // 初始化指令存储器，假设只有前两条指令
        mem[0] = 32'h00000001;
        mem[1] = 32'h00000002;
        // 可以继续初始化其他指令
    end

endmodule
<br><br>module address_logic (
    input [31:0] current_pc,   // 当前PC值
    input [31:0] branch_addr,  // 分支跳转地址
    input branch_taken,        // 分支是否成立
    output [31:0] next_pc      // 输出下一个PC地址
);

    assign next_pc = branch_taken ? branch_addr : current_pc + 4; // 如果分支成立，跳转到branch_addr，否则PC递增4

endmodule
<br><br>module top_module (
    input clk,            // 时钟信号
    input reset,          // 重置信号
    input branch,         // 分支信号
    input jump,           // 跳转信号
    input zero,           // 零标志信号
    input [31:0] jump_addr, // 跳转地址
    output [31:0] pc,     // 当前PC值
    output [31:0] instruction  // 输出的指令
);

    wire [31:0] next_pc;      // 计算出的下一个PC地址

    // 程序计数器（PC）模块
    program_counter pc_module (
        .clk(clk),
        .reset(reset),
        .next_pc(next_pc),   // 下一个PC地址
        .pc(pc)               // 当前PC值
    );

    // 指令存储器（IM）模块
    instruction_memory im (
        .addr(pc),            // 通过PC获取地址
        .instruction(instruction) // 输出指令
    );

    // 下地址逻辑（Address Logic）模块
    address_logic addr_logic (
        .current_pc(pc),      // 当前PC值
        .branch_addr(jump_addr), // 跳转地址
        .branch_taken(branch &amp; zero), // 判断是否分支
        .next_pc(next_pc)     // 下一个PC值
    );

endmodule
<br><img alt="image-20241212183816950" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212183816950.png" referrerpolicy="no-referrer"><br><br>module tb_top_module;

    reg clk;                 // 时钟信号
    reg reset;               // 重置信号
    reg branch;              // 分支信号
    reg jump;                // 跳转信号
    reg zero;                // 零标志信号
    reg [31:0] jump_addr;    // 跳转地址
    wire [31:0] pc;          // 当前PC值
    wire [31:0] instruction; // 输出指令

    // 实例化顶层模块
    top_module uut (
        .clk(clk),
        .reset(reset),
        .branch(branch),
        .jump(jump),
        .zero(zero),
        .jump_addr(jump_addr),
        .pc(pc),
        .instruction(instruction)
    );

    // 时钟生成
    always begin
        #5 clk = ~clk;  // 每5个单位反转时钟
    end

    // 初始化信号
    initial begin
        clk = 0;
        reset = 0;
        branch = 0;
        jump = 0;
        zero = 0;
        jump_addr = 32'h00000004;

        // 测试用例
        #10 reset = 1;     // 激活复位信号
        #10 reset = 0;     // 释放复位信号

        // 模拟顺序执行
        #20 branch = 0;    // 不发生分支
        #20 branch = 1;    // 发生分支
        #20 jump = 1;      // 发生跳转
        #20 zero = 1;      // 零标志信号为1
        #50 jump = 0;      // 不跳转
        #100 $finish;      // 结束仿真
    end

    // 监视输出
    initial begin
        $monitor("At time %t, PC = %h, Instruction = %h", $time, pc, instruction);
    end

endmodule
<br><br>
<br>编写各个模块：首先编写程序计数器、指令存储器和下地址逻辑模块，每个模块都具有明确的功能。
<br>集成顶层模块：将各个模块集成到一个顶层模块中，并确保它们之间的信号正确连接。
<br>编写测试平台：编写测试平台进行仿真，模拟时钟信号、重置信号和其他控制信号，观察PC和指令的输出。
<br>仿真与调试：使用Vivado或其他仿真工具进行仿真，观察波形，检查PC更新、指令取出等是否符合预期。
<br><br><img alt="image-20241212184249317" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212184249317.png" referrerpolicy="no-referrer"><br><br>
<br>在时钟信号变化时，程序计数器（PC）根据控制信号（如跳转、分支）更新其值。
<br>当复位信号被激活时，PC会被重置为0。
<br><br>
<br>程序计数器每次时钟脉冲后会递增4，除非发生跳转或分支。
<br>跳转或分支时，PC值根据跳转地址或分支条件更新。
<br><br>
<br>指令存储器根据当前PC的地址从内存中取出对应的指令，并输出。
<br><br>
<br>下地址逻辑根据分支信号和零标志信号计算下一个PC值。如果发生分支并且零标志信号为1，PC会跳转到分支地址；否则，PC会递增。
<br><br>仿真波形显示了PC的变化，指令输出以及跳转/分支是否按照设计要求执行。<br><br>通过本实验，成功实现了一个基本的取指部件设计，包括程序计数器、指令存储器以及下地址逻辑。通过仿真验证了各个模块的正确性，掌握了计算机系统中指令取出和跳转、分支控制的基本原理。<br><br><br>本实验旨在将算术逻辑单元（ALU）、存储器、取指部件互连，完成一个完整的CPU数据通路设计。通过实现一个简化的CPU数据通路，掌握指令的数据通路设计与实现方法。<br><br>
<br>硬件描述语言：Verilog
<br>仿真工具：Vivado（或其他Verilog仿真工具）
<br>目标平台：FPGA（如果需要实现实际硬件）
<br><br><br>本实验设计的CPU包含以下基本模块：<br>
<br>程序计数器（PC）：保持当前指令的地址，并根据时钟信号递增或修改PC的值（通过分支或跳转）。
<br>指令存储器（IM）：存储指令，根据PC地址读取对应的指令。
<br>算术逻辑单元（ALU）：执行算术和逻辑操作，如加法、减法、与、或等。
<br>寄存器文件（RegFile）：存储数据寄存器，提供读写功能。
<br>数据存储器（DataMemory）：用于数据存储操作，可以进行读取和写入。
<br><br>整个CPU的工作流程为：<br>
<br>程序计数器（PC）：根据当前PC值和控制信号计算下一个PC值。
<br>指令存储器（IM）：根据PC值取出指令。
<br>寄存器文件（RegFile）：根据指令读取和写入寄存器。
<br>ALU：执行指令中的算术逻辑运算。
<br>数据存储器（DataMemory）：执行数据存取指令，写回数据。
<br>顶层设计将这些模块通过数据和控制信号互联，形成一个完整的CPU数据通路。<br><br><br>module program_counter (
    input clk,                // 时钟信号
    input reset,              // 重置信号
    input [31:0] next_pc,     // 下一个PC地址
    output reg [31:0] pc      // 当前PC值
);

    always @(posedge clk or posedge reset) begin
        if (reset)
            pc &lt;= 32'h00000000;   // 重置PC为0
        else
            pc &lt;= next_pc;        // 更新PC
    end

endmodule
<br><br>module instruction_memory (
    input [31:0] addr,         // 地址输入
    output [31:0] instruction  // 输出指令
);

    reg [31:0] mem [0:255];    // 256条32位指令

    assign instruction = mem[addr[31:2]];  // 根据地址读取指令

    initial begin
        // 初始化指令存储器，假设只有前两条指令
        mem[0] = 32'h00000001;
        mem[1] = 32'h00000002;
        // 可以继续初始化其他指令
    end

endmodule
<br><br>module ALU (
    input [31:0] A,           // 操作数A
    input [31:0] B,           // 操作数B
    input [3:0] ALU_Control,  // ALU控制信号
    output reg [31:0] ALU_Result,  // ALU输出结果
    output reg Zero           // 结果是否为零
);

    always @(*) begin
        case (ALU_Control)
            4'b0000: ALU_Result = A + B;        // 加法
            4'b0001: ALU_Result = A - B;        // 减法
            4'b0010: ALU_Result = A &amp; B;        // 与
            4'b0011: ALU_Result = A | B;        // 或
            4'b0100: ALU_Result = A ^ B;        // 异或
            default: ALU_Result = 32'b0;        // 默认值
        endcase
        Zero = (ALU_Result == 32'b0);  // 检查结果是否为零
    end

endmodule
<br><br>module register_file (
    input clk,               // 时钟信号
    input reset,             // 重置信号
    input reg_write,         // 寄存器写入使能信号
    input [4:0] rs,          // 源寄存器地址
    input [4:0] rt,          // 目标寄存器地址
    input [4:0] rd,          // 目的寄存器地址
    input [31:0] write_data, // 写入数据
    output [31:0] read_data1, // 读出源寄存器数据
    output [31:0] read_data2  // 读出目标寄存器数据
);

    reg [31:0] regs [31:0];  // 32个32位寄存器

    assign read_data1 = regs[rs];  // 读出源寄存器数据
    assign read_data2 = regs[rt];  // 读出目标寄存器数据

    always @(posedge clk or posedge reset) begin
        if (reset)
            regs[0] &lt;= 32'b0;  // 寄存器0初始化为0
        else if (reg_write)
            regs[rd] &lt;= write_data;  // 写入数据
    end

endmodule
<br><br>module data_memory (
    input clk,               // 时钟信号
    input [31:0] addr,       // 存储器地址
    input [31:0] write_data, // 写入数据
    input mem_write,         // 存储器写使能信号
    input mem_read,          // 存储器读使能信号
    output reg [31:0] read_data // 读出数据
);

    reg [31:0] mem [0:255];  // 存储器，共256个32位单元

    always @(posedge clk) begin
        if (mem_write)
            mem[addr] &lt;= write_data;  // 写数据到存储器
        if (mem_read)
            read_data &lt;= mem[addr];   // 从存储器读取数据
    end

endmodule
<br><br>module top_cpu (
    input clk,                // 时钟信号
    input reset,              // 重置信号
    output [31:0] pc,         // 当前PC值
    output [31:0] instruction, // 输出指令
    output [31:0] ALU_Result  // ALU计算结果
);

    wire [31:0] next_pc;          // 计算出的下一个PC地址
    wire [31:0] reg_data1, reg_data2; // 寄存器读取的数据
    wire [31:0] alu_input2;       // ALU的输入
    wire [3:0] ALU_Control;       // ALU控制信号
    wire reg_write;               // 寄存器写使能信号
    wire mem_read, mem_write;     // 存储器读写使能信号

    // 程序计数器（PC）模块
    program_counter pc_module (
        .clk(clk),
        .reset(reset),
        .next_pc(next_pc),
        .pc(pc)
    );

    // 指令存储器（IM）模块
    instruction_memory im (
        .addr(pc),
        .instruction(instruction)
    );

    // 寄存器文件（RegFile）模块
    register_file reg_file (
        .clk(clk),
        .reset(reset),
        .reg_write(reg_write),
        .rs(instruction[25:21]),  // 假设rs是指令的第6-10位
        .rt(instruction[20:16]),  // 假设rt是指令的第11-15位
        .rd(instruction[15:11]),  // 假设rd是指令的第16-20位
        .write_data(ALU_Result),
        .read_data1(reg_data1),
        .read_data2(reg_data2)
    );

    // ALU模块
    ALU alu (
        .A(reg_data1),
        .B(alu_input2),
        .ALU_Control(ALU_Control),
        .ALU_Result(ALU_Result),
        .Zero() // 可扩展
    );

    // 数据存储器（DataMemory）模块
    data_memory dm (
        .clk(clk),
        .addr(reg_data1),    // 假设ALU结果作为地址
        .write_data(reg_data2),
        .mem_write(mem_write),
        .mem_read(mem_read),
        .read_data(ALU_Result)
    );

    // 控制信号生成逻辑（简化版）
    // 可以根据需要进一步扩展

    assign next_pc = pc + 4;  // 简单的PC递增实现

endmodule
<br><img alt="image-20241212193225009" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212193225009.png" referrerpolicy="no-referrer"><br><img alt="image-20241212193520532" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212193520532.png" referrerpolicy="no-referrer"><br><br>通过本实验，成功实现了一个简化版的CPU数据通路设计。仿真结果表明，各个模块能够正确交互，ALU能够执行运算，寄存器文件能够读写数据，数据存储器能够正确存储和读取数据。实验过程加深了对CPU数据通路设计及其各个模块功能的理解，并为进一步的CPU架构设计和优化奠定了基础。<br><br><br>本实验旨在通过使用 Verilog HDL 设计一个简单的单周期 CPU 控制部件。该 CPU 将包括指令译码、控制信号生成、ALU 操作、寄存器文件操作、存储器访问等模块。在设计过程中，通过实现每条指令的执行过程，结合指令的控制信号与指令编码的关系，设计出完整的控制信号生成单元。实验还将重点掌握译码器的组合逻辑设计方法，完成单周期 CPU 的基本设计和调试。<br><br>
<br>开发工具：Quartus Prime 20.1
<br>语言：Verilog HDL
<br>操作系统：Windows 11 / Linux（支持Quartus开发）
<br><br>本实验的目标是设计并实现一个简单的单周期 CPU，该 CPU 包括以下几个主要模块：<br>
<br>程序计数器（PC）：用于存储和更新当前执行的指令地址。
<br>指令寄存器：存储从内存读取的当前指令。
<br>控制单元：生成控制信号，根据指令的操作码（opcode）确定 ALU 操作、寄存器写使能等。
<br>寄存器文件：存储寄存器值，支持从指定寄存器读取数据并将 ALU 结果写回。
<br>ALU（算术逻辑单元）：执行算术和逻辑运算。
<br>数据存储器：读写内存的数据。
<br>结果选择器：根据控制信号选择从内存或 ALU 输出的最终结果。
<br><br>
<br>控制单元 (Control Unit)： 控制单元根据指令的操作码（opcode）生成控制信号，包括：

<br>ALUSrc: ALU 输入的选择。
<br>MemRead, MemWrite: 控制内存的读写操作。
<br>RegWrite: 控制寄存器的写使能。
<br>MemToReg: 控制数据选择，是从内存获取结果还是 ALU 结果。


<br>寄存器文件 (Register File)： 包括读寄存器和写寄存器的操作。每个寄存器都包含一个 32 位的数据。寄存器文件通过控制信号决定是否写入 ALU 的结果或存储器的结果。
<br>ALU： ALU 根据控制信号执行基本的算术和逻辑运算，如加法、减法、与、或等。
<br>数据存储器 (Data Memory)： 存储器用于存取数据。它提供读和写操作接口，通过 ALU 结果作为地址进行内存访问。
<br>结果选择器： 根据 MemToReg 控制信号，选择是从内存读取数据还是使用 ALU 计算结果作为最终的写回数据。
<br><br>`timescale 1 ps/ 1 ps

module top_cpu (
    input clk,
    input rst,
    input branch,
    input [31:0] branch_addr,
    input jump,
    input [31:0] jump_addr,
    input mem_read,
    input mem_write,
    input [4:0] read_addr_1,
    input [4:0] read_addr_2,
    input [4:0] write_addr,
    input [31:0] write_data,
    input write_enable,
    output [31:0] ALU_result,
    output [31:0] PC,
    output [31:0] instruction,
    output [31:0] mem_read_data,
    output [31:0] read_data_1,
    output [31:0] read_data_2
);


    reg [31:0] pc;
    always @(posedge clk or posedge rst) begin
        if (rst) begin
            pc &lt;= 32'b0; 
        end else if (branch) begin
            pc &lt;= branch_addr; 
        end else if (jump) begin
            pc &lt;= jump_addr; 
        end else begin
            pc &lt;= pc + 4; 
        end
    end

    assign PC = pc; 

 
    reg [31:0] instruction_memory [0:31];
    

    initial begin
        instruction_memory[0] = 32'h00000001; 
        instruction_memory[1] = 32'h00000002;
        instruction_memory[2] = 32'h00000003;
        instruction_memory[3] = 32'h00000004;

    end

    assign instruction = instruction_memory[pc[6:2]]; 


    wire ALU_op;
    wire mem_to_reg;
    wire mem_read_out;
    wire mem_write_out;
    wire reg_write;
    wire reg_dst;
    wire branch_out;
    wire jump_out;
    
    control_unit CU (
        .opcode(instruction[31:26]),
        .ALU_op(ALU_op),
        .mem_to_reg(mem_to_reg),
        .mem_read(mem_read_out),
        .mem_write(mem_write_out),
        .reg_write(reg_write),
        .reg_dst(reg_dst),
        .branch(branch_out),
        .jump(jump_out)
    );

    // ALU
    wire [31:0] ALU_input1, ALU_input2;
    assign ALU_input1 = read_data_1;
    assign ALU_input2 = (reg_dst) ? read_data_2 : write_data; 

    alu ALU (
        .ALU_op(ALU_op),
        .input1(ALU_input1),
        .input2(ALU_input2),
        .result(ALU_result)
    );


    register_file rf (
        .clk(clk),
        .rst(rst),
        .read_addr_1(read_addr_1),
        .read_addr_2(read_addr_2),
        .write_addr(write_addr),
        .write_data(ALU_result), 
        .write_enable(reg_write),
        .read_data_1(read_data_1),
        .read_data_2(read_data_2)
    );

 
    data_memory dm (
        .clk(clk),
        .rst(rst),
        .addr(ALU_result), 
        .write_data(write_data),
        .mem_read(mem_read_out),
        .mem_write(mem_write_out),
        .read_data(mem_read_data)
    );

endmodule



module control_unit (
    input [5:0] opcode, 
    output reg ALU_op,
    output reg mem_to_reg,
    output reg mem_read,
    output reg mem_write,
    output reg reg_write,
    output reg reg_dst,
    output reg branch,
    output reg jump
);

    always @(*) begin
        case (opcode)
            6'b000000: begin 
                ALU_op = 1;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 0;
                reg_write = 1;
                reg_dst = 1;
                branch = 0;
                jump = 0;
            end
            6'b100011: begin
                ALU_op = 0;
                mem_to_reg = 1;
                mem_read = 1;
                mem_write = 0;
                reg_write = 1;
                reg_dst = 0;
                branch = 0;
                jump = 0;
            end
            6'b101011: begin
                ALU_op = 0;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 1;
                reg_write = 0;
                reg_dst = 0;
                branch = 0;
                jump = 0;
            end
            6'b000100: begin 
                ALU_op = 0;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 0;
                reg_write = 0;
                reg_dst = 0;
                branch = 1;
                jump = 0;
            end
            6'b000010: begin 
                ALU_op = 0;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 0;
                reg_write = 0;
                reg_dst = 0;
                branch = 0;
                jump = 1;
            end
            default: begin
                ALU_op = 0;
                mem_to_reg = 0;
                mem_read = 0;
                mem_write = 0;
                reg_write = 0;
                reg_dst = 0;
                branch = 0;
                jump = 0;
            end
        endcase
    end

endmodule


module alu (
    input ALU_op,
    input [31:0] input1,
    input [31:0] input2,
    output reg [31:0] result
);

    always @(*) begin
        if (ALU_op) begin
            result = input1 + input2; 
        end else begin
            result = input1 - input2; 
        end
    end

endmodule


module register_file (
    input clk,
    input rst,
    input [4:0] read_addr_1,
    input [4:0] read_addr_2,
    input [4:0] write_addr,
    input [31:0] write_data,
    input write_enable,
    output reg [31:0] read_data_1,
    output reg [31:0] read_data_2
);

    reg [31:0] registers [31:0];

    always @(*) begin
        read_data_1 = registers[read_addr_1];
        read_data_2 = registers[read_addr_2];
    end

    always @(posedge clk or posedge rst) begin
        if (rst) begin
            registers[0] &lt;= 32'b0; 
        end else if (write_enable) begin
            registers[write_addr] &lt;= write_data;
        end
    end

endmodule

module data_memory (
    input clk,
    input rst,
    input [31:0] addr,
    input [31:0] write_data,
    input mem_read,
    input mem_write,
    output reg [31:0] read_data
);

    reg [31:0] memory [31:0];
    
    integer i;
    always @(posedge clk or posedge rst) begin
        if (rst) begin
            for (i = 0; i &lt; 32; i = i + 1) begin
                memory[i] &lt;= 32'b0;
            end
        end else if (mem_write) begin
            memory[addr] &lt;= write_data;
        end
    end

    always @(posedge clk) begin
        if (mem_read) begin
            read_data &lt;= memory[addr];
        end
    end

endmodule


<br><br><img alt="image-20241212235438698" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212235438698.png" referrerpolicy="no-referrer"><br>通过对各模块进行仿真测试，发现设计能够成功实现指令的取值、译码、控制信号的生成以及指令执行过程中的各个操作。最终，单周期 CPU 在指定的测试用例下能够正确执行。<br><br>通过本次实验，我们完成了一个简化版的单周期 CPU 的设计。实验过程中，掌握了如何使用 Verilog 语言设计各个硬件模块，并调试了每个模块以<br>确保其正常工作。通过这次实验，加深了对 CPU 内部操作流程的理解，为后续的多周期 CPU 设计奠定了基础。]]></description><link>technology\collegeproject\计算机组成原理\实验\实验报告汇总.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机组成原理/实验/实验报告汇总.md</guid><pubDate>Sun, 12 Jan 2025 03:11:50 GMT</pubDate><enclosure url="lib\media\{b87fd227-ec0b-4585-90d8-eb65fa1a6288}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{b87fd227-ec0b-4585-90d8-eb65fa1a6288}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[脑图]]></title><description><![CDATA[ 
 <br> 0.大纲.emmx<br> 1.计算机系统概论.emmx<br> 2.数据的表示和运算.emmx<br> 3.存储系统.emmx<br> 4.指令系统.emmx<br> 5.中央处理器.emmx<br> 6.总线.emmx<br> 7.输入输出系统.emmx]]></description><link>technology\collegeproject\计算机组成原理\脑图.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机组成原理/脑图.md</guid><pubDate>Thu, 26 Sep 2024 01:22:32 GMT</pubDate></item><item><title><![CDATA[第1章 计算机系统概述]]></title><description><![CDATA[ 
 <br><br><br><img alt="{5365BCAB-9D08-4F91-89C7-41F9D1E7A12F}.png" src="\lib\media\{5365bcab-9d08-4f91-89c7-41f9d1e7a12f}.png"><br><br><img alt="{C42417D0-138E-497B-9870-94B0095EC4B6}.png" src="\lib\media\{c42417d0-138e-497b-9870-94b0095ec4b6}.png"><br>
<img alt="{37C0D018-001B-49B6-AC35-F9A4A14508A4}.png" src="\lib\media\{37c0d018-001b-49b6-ac35-f9a4a14508a4}.png"><br>
<img alt="{A3BFE0EB-C2AF-49BE-B238-47F03206ED19}.png" src="\lib\media\{a3bfe0eb-c2af-49be-b238-47f03206ed19}.png"><br><br><img alt="{C4791A6C-1192-47DA-9C45-5C4435725AC8}.png" src="\lib\media\{c4791a6c-1192-47da-9c45-5c4435725ac8}.png"><br><br><img alt="{53DB4876-87C1-463D-9E58-511A6B8347ED}.png" src="\lib\media\{53db4876-87c1-463d-9e58-511a6b8347ed}.png"><br><br><img alt="{CFC3DA7C-E686-4891-94B6-F2CCB06A721B}.png" src="\lib\media\{cfc3da7c-e686-4891-94b6-f2ccb06a721b}.png"><br>
<img alt="{0A176053-E161-4BE4-A491-EBE4D55C660C}.png" src="\lib\media\{0a176053-e161-4be4-a491-ebe4d55c660c}.png"><br>
<img alt="{A013B299-33D0-48A8-99C3-406476760D82}.png" src="\lib\media\{a013b299-33d0-48a8-99c3-406476760d82}.png"><br><br><img alt="{8AC24673-6E15-43B5-B897-5BDC283C583E}.png" src="\lib\media\{8ac24673-6e15-43b5-b897-5bdc283c583e}.png"><br>
<img alt="{45C61FD0-1177-4ADF-BAA8-84F405E070C8}.png" src="\lib\media\{45c61fd0-1177-4adf-baa8-84f405e070c8}.png"><br><br><img alt="{6306BD4B-9726-4A44-8032-22C33CE329A8}.png" src="\lib\media\{6306bd4b-9726-4a44-8032-22c33ce329a8}.png"><br><br>注意：字、字节、字长的辨析<br>
<img alt="{92D3D8DF-9D6F-4B15-A95D-5B9294781938}.png" src="\lib\media\{92d3d8df-9d6f-4b15-a95d-5b9294781938}.png"><br>
<img alt="{F8EED59C-CDFE-4486-A711-D353DE4827CE}.png" src="\lib\media\{f8eed59c-cdfe-4486-a711-d353de4827ce}.png"><br><br><img alt="{9FA8083A-14EE-4EE3-B19C-D1E1B6BD0C89}.png" src="\lib\media\{9fa8083a-14ee-4ee3-b19c-d1e1b6bd0c89}.png"><br><br><img alt="{69D6121E-3BE9-4FC9-97DC-E6BFCE2A90E0}.png" src="\lib\media\{69d6121e-3be9-4fc9-97dc-e6bfce2a90e0}.png"><br><br><img alt="{7BC42E31-A894-45A4-A4DA-A407ECCB93FD}.png" src="\lib\media\{7bc42e31-a894-45a4-a4da-a407eccb93fd}.png"><br>
<img alt="{1084AF68-70EB-4A9E-AFB7-EB41B4C87211}.png" src="\lib\media\{1084af68-70eb-4a9e-afb7-eb41b4c87211}.png"><br>
<img alt="{1C5DC7C2-0B3F-435C-9894-E60BA82FB818}.png" src="\lib\media\{1c5dc7c2-0b3f-435c-9894-e60ba82fb818}.png"><br>
<img alt="{52EF2B39-459B-495B-88B4-1EDFFF17E008}.png" src="\lib\media\{52ef2b39-459b-495b-88b4-1edfff17e008}.png"><br>
<img alt="{61EDFA46-9B3F-4F5E-A006-2093B03E9CAD}.png" src="\lib\media\{61edfa46-9b3f-4f5e-a006-2093b03e9cad}.png"><br>
<img alt="{BBFFB28F-BA4B-4400-8E2A-956C7A26FC56}.png" src="\lib\media\{bbffb28f-ba4b-4400-8e2a-956c7a26fc56}.png"><br><br><img alt="{225F0750-E6BC-4AAF-8488-13A150F430AA}.png" src="\lib\media\{225f0750-e6bc-4aaf-8488-13a150f430aa}.png"><br><br><img alt="{D10999DD-40F1-44AD-8F7A-0B62886F507A}.png" src="\lib\media\{d10999dd-40f1-44ad-8f7a-0b62886f507a}.png"><br><br><img alt="{B72A7F1D-C1F7-4E90-A4CD-C72ECDF36526}.png" src="\lib\media\{b72a7f1d-c1f7-4e90-a4cd-c72ecdf36526}.png"><br><br><img alt="{32E54660-BB09-4F0D-91D3-A4A7EB143E68}.png" src="\lib\media\{32e54660-bb09-4f0d-91d3-a4a7eb143e68}.png"><br><br><img alt="{C1EE37BA-3D4D-482B-B55D-A382A14C19C1}.png" src="\lib\media\{c1ee37ba-3d4d-482b-b55d-a382a14c19c1}.png"><br>
<img alt="{FB59DF2F-2473-48F0-AFA8-1F70F968DBA3}.png" src="\lib\media\{fb59df2f-2473-48f0-afa8-1f70f968dba3}.png"><br>
存储器的单位变化K，M，G差2^10<br><br><img alt="{B360694C-6E21-4C3A-B4AC-A3AED86C0953}.png" src="\lib\media\{b360694c-6e21-4c3a-b4ac-a3aed86c0953}.png"><br>
<img alt="{80048F1B-91E4-498A-BA49-DF6AF12DBE29}.png" src="\lib\media\{80048f1b-91e4-498a-ba49-df6af12dbe29}.png"><br>
<img alt="{581D5B7E-9778-4C6E-BC82-3D7ED45B1302}.png" src="\lib\media\{581d5b7e-9778-4c6e-bc82-3d7ed45b1302}.png"><br>CPU计算速度的单位变化K，M，G差10^3，CPU主频的G也是10^9<br><br><img alt="{0E8181D1-6912-4260-83AA-A2C65FCB755B}.png" src="\lib\media\{0e8181d1-6912-4260-83aa-a2c65fcb755b}.png"><br><br><img alt="{FA060E6D-1BBD-4E62-AA25-10DAFB6CC67A}.png" src="\lib\media\{fa060e6d-1bbd-4e62-aa25-10dafb6cc67a}.png"><br><br><img alt="{CAE25D43-071A-4ACD-8E68-DC69F2FAA9D5}.png" src="\lib\media\{cae25d43-071a-4acd-8e68-dc69f2faa9d5}.png"><br><br><br><img alt="{B11DD657-8DD7-43B8-B6AD-4568C3EFB01B}.png" src="\lib\media\{b11dd657-8dd7-43b8-b6ad-4568c3efb01b}.png"><br><br><img alt="{15B338DF-727A-4322-BFF6-CF971846636F}.png" src="\lib\media\{15b338df-727a-4322-bff6-cf971846636f}.png"><br>
<img alt="{19C934D4-5F90-47DC-A4ED-BDD2F9C2F49A}.png" src="\lib\media\{19c934d4-5f90-47dc-a4ed-bdd2f9c2f49a}.png"><br>
<img alt="{F638E208-7EB8-4D3F-9F3D-6699D8816597}.png" src="\lib\media\{f638e208-7eb8-4d3f-9f3d-6699d8816597}.png"><br><br><img alt="{58D4B4B4-03B1-442B-8EF2-4A6F2ED950D6}.png" src="\lib\media\{58d4b4b4-03b1-442b-8ef2-4a6f2ed950d6}.png"><br>
<img alt="{B88C4D80-4911-4B02-852B-F70C03AA20B8}.png" src="\lib\media\{b88c4d80-4911-4b02-852b-f70c03aa20b8}.png"><br>
<img alt="{97D167FB-1B33-43EA-BA4D-98A45DDBB8FC}.png" src="\lib\media\{97d167fb-1b33-43ea-ba4d-98a45ddbb8fc}.png"><br>
<img alt="{F1E9570C-ACBA-4F7B-98E6-4B01756FB302}.png" src="\lib\media\{f1e9570c-acba-4f7b-98e6-4b01756fb302}.png"><br><br><img alt="{9B0D30AD-90E3-4351-93FD-8443F2D4F36F}.png" src="\lib\media\{9b0d30ad-90e3-4351-93fd-8443f2d4f36f}.png"><br><br><img alt="{BBB37C36-AAD6-4374-BF24-E7FB5F6A9752}.png" src="\lib\media\{bbb37c36-aad6-4374-bf24-e7fb5f6a9752}.png"><br><br><img alt="{3D9AD5AD-102D-4E80-9545-ABA118681739}.png" src="\lib\media\{3d9ad5ad-102d-4e80-9545-aba118681739}.png"><br><br>8421分别代表不同位的权值<br>
<img alt="{10F5D6F4-4C85-4E99-91EE-78FEEBCF2912}.png" src="\lib\media\{10f5d6f4-4c85-4e99-91ee-78feebcf2912}.png"><br><br>（即8421码加3）<br>
<img alt="{1ED68B68-2864-4418-8577-888F5D3D1D26}.png" src="\lib\media\{1ed68b68-2864-4418-8577-888f5d3d1d26}.png"><br><br>1-4位第一位都为0，5-9位第一位都为1<br>
<img alt="{FAD35FAB-638F-4875-A7E7-BD0B77B92643}.png" src="\lib\media\{fad35fab-638f-4875-a7e7-bd0b77b92643}.png"><br><br><img alt="{9883C6FB-5BB3-4289-8C64-E064C75B2E34}.png" src="\lib\media\{9883c6fb-5bb3-4289-8c64-e064c75b2e34}.png"><br><br>计算机硬件支持的无符号整数位上限位机器字长，一般为64位或者32位<br>
<img alt="{FADBCDD8-1CAF-43E2-82DA-D02E07DC4218}.png" src="\lib\media\{fadbcdd8-1caf-43e2-82da-d02e07dc4218}.png"><br>
<img alt="{4BB8F589-190F-401A-958B-E5E2AF3CFB1D}.png" src="\lib\media\{4bb8f589-190f-401a-958b-e5e2af3cfb1d}.png"><br><br>本质上就像是钟表往后拨2等同于往前拨10，取反加一就是用12-2<br>
<img alt="{860B4BEF-036E-4ABE-A667-591D1B36AD94}.png" src="\lib\media\{860b4bef-036e-4abe-a667-591d1b36ad94}.png"><br><br><img alt="{8D49A93A-477C-4528-BD49-70287FA8CFDD}.png" src="\lib\media\{8d49a93a-477c-4528-bd49-70287fa8cfdd}.png"><br><br><img alt="{D4EF5F56-ED88-49CA-9547-91A6A2B1C4C2}.png" src="\lib\media\{d4ef5f56-ed88-49ca-9547-91a6a2b1c4c2}.png"><br><br>原码的缺点：原码的符号位不能参与运算<br>
<img alt="{C271FFFB-B708-44B3-A44A-B5F5E064BDE7}.png" src="\lib\media\{c271fffb-b708-44b3-a44a-b5f5e064bde7}.png"><br><br>注意：负数的原码到反码转变只对数值位取反。符号位不变。<br>
<img alt="{D0612691-FB70-4DA0-BAD7-BF443E221822}.png" src="\lib\media\{d0612691-fb70-4da0-bad7-bf443e221822}.png"><br>
<img alt="{A621805C-FCFD-4BD4-B356-DCAEB4480BA7}.png" src="\lib\media\{a621805c-fcfd-4bd4-b356-dcaeb4480ba7}.png"><br><br><img alt="{2C7EC359-89C5-4C21-8C21-86B5C4908EA7}.png" src="\lib\media\{2c7ec359-89c5-4c21-8c21-86b5c4908ea7}.png"><img alt="{825A26F7-37E3-4F76-B427-B9598BF92819}.png" src="\lib\media\{825a26f7-37e3-4f76-b427-b9598bf92819}.png"><br><br><img alt="{439A3E7A-7FDF-4941-AB45-87C109EF0CBB}.png" src="\lib\media\{439a3e7a-7fdf-4941-ab45-87c109ef0cbb}.png"><br>
注意：这里是全部为取反，可以使用之前的原-&gt;补的快速转换方式，但是注意这个是要从右往左找到第一个1，在这个1左边的全部位按位取反。原-&gt;补则是这个1左边的除符号位按位取反。<br>
<img alt="{1C20EE12-A802-4447-9583-9C19D452BDFA}.png" src="\lib\media\{1c20ee12-a802-4447-9583-9c19d452bdfa}.png"><br><br><img alt="{5D726635-912B-4ED6-B348-538AE2256B7E}.png" src="\lib\media\{5d726635-912b-4ed6-b348-538ae2256b7e}.png"><br><br><img alt="{FCE7992E-843E-456C-93CA-135A7D85D07A}.png" src="\lib\media\{fce7992e-843e-456c-93ca-135a7d85d07a}.png"><br>
<img alt="{519E3058-9DF2-4C42-95EB-E644AD063802}.png" src="\lib\media\{519e3058-9df2-4c42-95eb-e644ad063802}.png"><br>
<img alt="{59085A8E-915E-4CDE-8DF9-6E6FC452A32E}.png" src="\lib\media\{59085a8e-915e-4cde-8df9-6e6fc452a32e}.png"><img alt="{68622733-9A18-493B-A609-2C3CA1C354EE}.png" src="\lib\media\{68622733-9a18-493b-a609-2c3ca1c354ee}.png"><br><br>定点小数的本质就是小数点位置从末尾变成了符号位后。其他与带符号整数都一样。<br>
<img alt="{DC4F1EE1-CE98-4C42-82A3-0AAEB146FCCF}.png" src="\lib\media\{dc4f1ee1-ce98-4c42-82a3-0aaeb146fccf}.png"><br><br><img alt="{8EA3559F-E9B5-4C1C-9BEE-560DD2F53154}.png" src="\lib\media\{8ea3559f-e9b5-4c1c-9bee-560dd2f53154}.png"><br>
<img alt="{D3718F9B-440D-4A46-934B-F627BCEA9C8F}.png" src="\lib\media\{d3718f9b-440d-4a46-934b-f627bcea9c8f}.png"><br><br><img alt="{68364CE5-E957-4111-95A0-5FD90FF34C16}.png" src="\lib\media\{68364ce5-e957-4111-95a0-5fd90ff34c16}.png"><br>
<img alt="{60D0C77D-17CB-424F-A697-354B3B0165B0}.png" src="\lib\media\{60d0c77d-17cb-424f-a697-354b3b0165b0}.png"><br><br><img alt="{65223148-F3D6-401B-A896-D74054FF2ABC}.png" src="\lib\media\{65223148-f3d6-401b-a896-d74054ff2abc}.png"><br><br><img alt="{2D3F74E3-126C-4F46-9D8B-D2B366F83DF3}.png" src="\lib\media\{2d3f74e3-126c-4f46-9d8b-d2b366f83df3}.png"><br><br><img alt="{882AE461-8D2C-4A96-B9BD-71BC8099ED28}.png" src="\lib\media\{882ae461-8d2c-4a96-b9bd-71bc8099ed28}.png"><br>
<img alt="{67E88A7C-7591-431B-A9DB-4E6C9B7A977B}.png" src="\lib\media\{67e88a7c-7591-431b-a9db-4e6c9b7a977b}.png"><br><br><img alt="{9612E951-D0D7-40F9-923F-600CD0A4751D}.png" src="\lib\media\{9612e951-d0d7-40f9-923f-600cd0a4751d}.png"><br><br><img alt="{3AF42E07-3715-480A-9C34-610A664B553A}.png" src="\lib\media\{3af42e07-3715-480a-9c34-610a664b553a}.png"><br>
寄存器的位数一般与ALU字长保持一致。<br><br><img alt="{5678BFEC-07FB-4510-892F-AC2E7564D7EE}.png" src="\lib\media\{5678bfec-07fb-4510-892f-ac2e7564d7ee}.png"><br><img alt="{BFE3E92D-56C7-4E15-9CFC-BB041A4E3FB5}.png" src="\lib\media\{bfe3e92d-56c7-4e15-9cfc-bb041a4e3fb5}.png"><br>
<img alt="{A09E87F8-B068-417C-93A7-16C2BB597B9B}.png" src="\lib\media\{a09e87f8-b068-417c-93a7-16c2bb597b9b}.png"><br><br><img alt="{9B4590C9-0299-4BDE-979E-67BC5E049E22}.png" src="\lib\media\{9b4590c9-0299-4bde-979e-67bc5e049e22}.png"><br><br><img alt="{01499CB2-F1FE-442C-8241-B827B53EE235}.png" src="\lib\media\{01499cb2-f1fe-442c-8241-b827b53ee235}.png"><br><br><img alt="{3EC5A9E9-FBA9-40AA-9002-328EDCA400EF}.png" src="\lib\media\{3ec5a9e9-fba9-40aa-9002-328edca400ef}.png"><br><br><img alt="{FF8D4310-5963-436F-AC52-AE326A164582}.png" src="\lib\media\{ff8d4310-5963-436f-ac52-ae326a164582}.png"><br>
<img alt="{4C5F5703-AEFA-41B5-A97B-7DA3346D05DF}.png" src="\lib\media\{4c5f5703-aefa-41b5-a97b-7da3346d05df}.png"><br><br><img alt="{04D37275-C1B2-45C0-8B67-2157DD265CC2}.png" src="\lib\media\{04d37275-c1b2-45c0-8b67-2157dd265cc2}.png"><br><br><img alt="{52D014A4-8B50-4F3F-82BF-4DC1524FFFC5}.png" src="\lib\media\{52d014a4-8b50-4f3f-82bf-4dc1524fffc5}.png"><br>无符号数的加减运算器与这个完全一致<br>
但两者判断溢出有所不同<br>
<img alt="{7B5AB463-C6CB-4AB7-9EF9-A1F140983C2F}.png" src="\lib\media\{7b5ab463-c6cb-4ab7-9ef9-a1f140983c2f}.png"><br><br><img alt="{05AC8239-A5D8-4364-A0B9-29381DFAA4C1}.png" src="\lib\media\{05ac8239-a5d8-4364-a0b9-29381dfaa4c1}.png"><br><br><img alt="{AD27D5C9-FB7F-4589-A5CC-294ED7A5E560}.png" src="\lib\media\{ad27d5c9-fb7f-4589-a5cc-294ed7a5e560}.png"><br><br><img alt="{33A877C2-36C3-41C1-A642-2E44B59B3D3B}.png" src="\lib\media\{33a877c2-36c3-41c1-a642-2e44b59b3d3b}.png"><br><br><img alt="{CE60E840-4BE1-4205-9ED2-FFC45F2F1FA6}.png" src="\lib\media\{ce60e840-4be1-4205-9ed2-ffc45f2f1fa6}.png"><br>
<img alt="{362815D8-9E5F-4838-AED5-951A30989D45}.png" src="\lib\media\{362815d8-9e5f-4838-aed5-951a30989d45}.png"><br><br><img alt="{B7FEA58F-9E59-42FC-A1B2-D0455B3A33E7}.png" src="\lib\media\{b7fea58f-9e59-42fc-a1b2-d0455b3a33e7}.png"><br><br><img alt="{4D999C4D-F224-42E7-8BEA-CD32278C5866}.png" src="\lib\media\{4d999c4d-f224-42e7-8bea-cd32278c5866}.png"><br><br><img alt="Pasted image 20241023081520.png" src="\lib\media\pasted-image-20241023081520.png"><br>
<img alt="Pasted image 20241023080706.png" src="\lib\media\pasted-image-20241023080706.png"><br><br>注意：只有在有符号运算时才有意义<br>
<img alt="Pasted image 20241023080736.png" src="\lib\media\pasted-image-20241023080736.png"><br>
<img alt="Pasted image 20241023080859.png" src="\lib\media\pasted-image-20241023080859.png"><br><br>注意：只有在有符号运算时才有意义<br>
取运算结果最高位即可。<br><br>注意：只在无符号运算时才有意义。<br>
CF=最高位进位异或上Sub标志<br><br><img alt="Pasted image 20241023083427.png" src="\lib\media\pasted-image-20241023083427.png"><br><br><img alt="Pasted image 20241023081737.png" src="\lib\media\pasted-image-20241023081737.png"><br><br><br><img alt="Pasted image 20241023082007.png" src="\lib\media\pasted-image-20241023082007.png"><br><br><img alt="Pasted image 20241023082130.png" src="\lib\media\pasted-image-20241023082130.png"><br><br>负数补位补1。<br>
<img alt="Pasted image 20241023082246.png" src="\lib\media\pasted-image-20241023082246.png"><br><br><img alt="Pasted image 20241023082612.png" src="\lib\media\pasted-image-20241023082612.png"><br><br><img alt="Pasted image 20241023083047.png" src="\lib\media\pasted-image-20241023083047.png"><br><br><img alt="Pasted image 20241023083336.png" src="\lib\media\pasted-image-20241023083336.png"><br><br><br><img alt="Pasted image 20241023083832.png" src="\lib\media\pasted-image-20241023083832.png"><br>
错位的本质就是小数点对齐，可以用移位实现<br>
<img alt="Pasted image 20241023084213.png" src="\lib\media\pasted-image-20241023084213.png"><br><br><img alt="Pasted image 20241023084536.png" src="\lib\media\pasted-image-20241023084536.png"><br><br><img alt="Pasted image 20241023084924.png" src="\lib\media\pasted-image-20241023084924.png"><br>
<img alt="Pasted image 20241023084954.png" src="\lib\media\pasted-image-20241023084954.png"><br>
<img alt="Pasted image 20241023085146.png" src="\lib\media\pasted-image-20241023085146.png"><br><br><img alt="Pasted image 20241023085702.png" src="\lib\media\pasted-image-20241023085702.png"><br><br><img alt="Pasted image 20241023090037.png" src="\lib\media\pasted-image-20241023090037.png"><br>
<img alt="Pasted image 20241023090411.png" src="\lib\media\pasted-image-20241023090411.png"><br>
<img alt="Pasted image 20241023090700.png" src="\lib\media\pasted-image-20241023090700.png"><br>
<img alt="Pasted image 20241023091048.png" src="\lib\media\pasted-image-20241023091048.png"><br>
<img alt="Pasted image 20241023091337.png" src="\lib\media\pasted-image-20241023091337.png"><br><br><img alt="Pasted image 20241023100924.png" src="\lib\media\pasted-image-20241023100924.png"><br>
<img alt="Pasted image 20241023100945.png" src="\lib\media\pasted-image-20241023100945.png"><br><br><img alt="Pasted image 20241023101544.png" src="\lib\media\pasted-image-20241023101544.png"><br>
<img alt="Pasted image 20241023101616.png" src="\lib\media\pasted-image-20241023101616.png"><img alt="Pasted image 20241023101720.png" src="\lib\media\pasted-image-20241023101720.png"><img alt="Pasted image 20241023101935.png" src="\lib\media\pasted-image-20241023101935.png"><img alt="Pasted image 20241023101858.png" src="\lib\media\pasted-image-20241023101858.png"><img alt="{FA63CD35-28D4-4508-96A6-2253ED4D2A72}.png" src="\lib\media\{fa63cd35-28d4-4508-96a6-2253ed4d2a72}.png"><br>
<img alt="{5E5264B1-632F-45F4-899C-278C36CFD9F3}.png" src="\lib\media\{5e5264b1-632f-45f4-899c-278c36cfd9f3}.png"><br><br><img alt="{00A839ED-CFDA-422D-9307-CA3CB0526CB8}.png" src="\lib\media\{00a839ed-cfda-422d-9307-ca3cb0526cb8}.png"><br>
<img alt="{1B3E94E1-37CA-4634-BDD9-1A0379294305}.png" src="\lib\media\{1b3e94e1-37ca-4634-bdd9-1a0379294305}.png"><br>
<img alt="{D32365A2-38C3-40BF-8394-0205CD655B40}.png" src="\lib\media\{d32365a2-38c3-40bf-8394-0205cd655b40}.png"><br><br><img alt="{C9CD7F51-1DD9-4CDF-B939-220396ABEA81}.png" src="\lib\media\{c9cd7f51-1dd9-4cdf-b939-220396abea81}.png"><br>
<img alt="{B2E66FF6-401A-480A-BBD4-FD55F234940A}.png" src="\lib\media\{b2e66ff6-401a-480a-bbd4-fd55f234940a}.png"><br><br><img alt="{2A3533FA-E656-447C-97CB-3883C8BFA3BC}.png" src="\lib\media\{2a3533fa-e656-447c-97cb-3883c8bfa3bc}.png"><br><br><br>最高有效字节（MSB），最低有效字节（LSB）。分别指按顺序最前面的，和按顺序最后面的。<br>
大端的顺序便于人类阅读。顺序和地址顺序一致。<br>
小端则相反。<br>
<img alt="{FF6D701F-830A-46FC-9524-EE4A52E60E85}.png" src="\lib\media\{ff6d701f-830a-46fc-9524-ee4a52e60e85}.png"><br><br><img alt="{39611C4E-D8CD-4D0A-BD5E-9D6443D207F8}.png" src="\lib\media\{39611c4e-d8cd-4d0a-bd5e-9d6443d207f8}.png"><br>
例子：<br>
边界对齐的本质是空间换时间<br>
<img alt="{5515A1FA-0F94-4E56-BD59-AC096C6078E5}.png" src="\lib\media\{5515a1fa-0f94-4e56-bd59-ac096c6078e5}.png"><br>
<img alt="{44E53F3C-DA3B-4BBA-95FA-00FCEDBF6576}.png" src="\lib\media\{44e53f3c-da3b-4bba-95fa-00fcedbf6576}.png"><br>
边界不对齐则可以将某一个多字节变量拆到两个字中存储，但是访存的时候需要访问两次。<br>
<img alt="{FADC67F4-474A-449A-9B0D-EAD4F8C09A51}.png" src="\lib\media\{fadc67f4-474a-449a-9b0d-ead4f8c09a51}.png"><br><br><br><img alt="{742B828E-06F2-4FDD-BCD1-2F9723EAA09B}.png" src="\lib\media\{742b828e-06f2-4fdd-bcd1-2f9723eaa09b}.png"><br><br><img alt="{D2773808-92C9-4470-AAA9-CD4A4266044A}.png" src="\lib\media\{d2773808-92c9-4470-aaa9-cd4a4266044a}.png"><br><br><img alt="{6F9A0CF7-A991-4AFD-8E7E-39DD1AE1CDDD}.png" src="\lib\media\{6f9a0cf7-a991-4afd-8e7e-39dd1ae1cddd}.png"><br><br><img alt="{D4C94C4C-E6D9-4E8E-A425-11E9520C7525}.png" src="\lib\media\{d4c94c4c-e6d9-4e8e-a425-11e9520c7525}.png"><br><br><img alt="{E8CDA75A-57E3-45F4-9711-FC7A135DAA24}.png" src="\lib\media\{e8cda75a-57e3-45f4-9711-fc7a135daa24}.png"><br><br><img alt="{3EEAB796-70A6-4CA6-BA04-2ACFE525D888}.png" src="\lib\media\{3eeab796-70a6-4ca6-ba04-2acfe525d888}.png"><br><br><img alt="{A0FA6DA1-D98E-4FB0-B768-2539DDD62E90}.png" src="\lib\media\{a0fa6da1-d98e-4fb0-b768-2539ddd62e90}.png"><br><br><img alt="{05C19866-28F3-4F72-A2FF-FBF9778ACDB2}.png" src="\lib\media\{05c19866-28f3-4f72-a2ff-fbf9778acdb2}.png"><br><br><img alt="{8FB2D1B3-68E2-4686-BF00-8E0C99625C6E}.png" src="\lib\media\{8fb2d1b3-68e2-4686-bf00-8e0c99625c6e}.png"><br>
<img alt="{0E0074DA-3304-4EB4-84E8-853B25F41B1A}.png" src="\lib\media\{0e0074da-3304-4eb4-84e8-853b25f41b1a}.png"><br>
<img alt="{580157EE-8AEC-4A4C-9196-9DCC3F74AFB5}.png" src="\lib\media\{580157ee-8aec-4a4c-9196-9dcc3f74afb5}.png"><br>
<img alt="{41458A34-EAEB-4E9B-A55A-7DC5BDF91BFC}.png" src="\lib\media\{41458a34-eaeb-4e9b-a55a-7dc5bdf91bfc}.png"><br>
<img alt="{E2CF1E2D-27F2-4661-A9CF-AB88D58ECB3E}.png" src="\lib\media\{e2cf1e2d-27f2-4661-a9cf-ab88d58ecb3e}.png"><br><br><img alt="{906FE433-B8A8-4CBA-B038-2ABA818CF5C4}.png" src="\lib\media\{906fe433-b8a8-4cba-b038-2aba818cf5c4}.png"><br><br><img alt="{EE2518E6-2AC9-4AD7-9AFB-3C2BD70136E6} 1.png" src="\lib\media\{ee2518e6-2ac9-4ad7-9afb-3c2bd70136e6}-1.png"><br><br><img alt="{830334B7-40E5-4427-9295-5BF4F4B02610}.png" src="\lib\media\{830334b7-40e5-4427-9295-5bf4f4b02610}.png"><br>核心区别：<br>
DRAM芯片：使用栅极电容存储信息<br>
SRAM芯片：使用双稳态触发器存储信息<br><br><img alt="{06AA69D1-5A03-4B23-B07F-CA31E16D92F5}.png" src="\lib\media\{06aa69d1-5a03-4b23-b07f-ca31e16d92f5}.png"><br>
<img alt="{ABDBE005-0AEB-4A99-8C48-67FB5EA2AA0A}.png" src="\lib\media\{abdbe005-0aeb-4a99-8c48-67fb5ea2aa0a}.png"><br><br><img alt="{BB58E2B2-5F03-4E32-8B62-2942FEA54E98}.png" src="\lib\media\{bb58e2b2-5f03-4e32-8b62-2942fea54e98}.png"><br>
<img alt="{A4AB9538-1640-4BCB-B79C-E0BBF4C94B06}.png" src="\lib\media\{a4ab9538-1640-4bcb-b79c-e0bbf4c94b06}.png"><br><br><img alt="{45A4483B-5722-47BD-B65E-24369CE6FFF9}.png" src="\lib\media\{45a4483b-5722-47bd-b65e-24369ce6fff9}.png"><br><br><img alt="{EE2518E6-2AC9-4AD7-9AFB-3C2BD70136E6}.png" src="\lib\media\{ee2518e6-2ac9-4ad7-9afb-3c2bd70136e6}.png"><br><br><img alt="{E61E6C6E-B48E-42CF-8DE0-C6F8EDACE4A5}.png" src="\lib\media\{e61e6c6e-b48e-42cf-8de0-c6f8edace4a5}.png"><br><br><img alt="{76262FE9-3D5D-48CF-9DE9-ECD92BBBFACE}.png" src="\lib\media\{76262fe9-3d5d-48cf-9de9-ecd92bbbface}.png"><br>
<img alt="{E63B2878-B277-4F30-B26E-662D28DC9CCB}.png" src="\lib\media\{e63b2878-b277-4f30-b26e-662d28dc9ccb}.png"><br><br><img alt="{686397CA-C3F7-4F20-929F-2474E7ACAFE9}.png" src="\lib\media\{686397ca-c3f7-4f20-929f-2474e7acafe9}.png"><br><br><img alt="{7C5FCABF-6B75-433A-B7F8-16C7E1FC461C}.png" src="\lib\media\{7c5fcabf-6b75-433a-b7f8-16c7e1fc461c}.png"><br><br><img alt="{B38B0F8B-DAE2-4C04-8E82-C62EE01B6D22}.png" src="\lib\media\{b38b0f8b-dae2-4c04-8e82-c62ee01b6d22}.png"><br><br><img alt="{11B4B2C4-0085-4E75-A8DB-8BE87333A15D}.png" src="\lib\media\{11b4b2c4-0085-4e75-a8db-8be87333a15d}.png"><br>
在连续访问的时候，低位交叉编址要比高位快接近四倍，其宏观读写一个字的时间接近r。<br>
这种连续访问一般是针对数组等连续存储的数据。<br>
<img alt="{56CDAD7C-1B12-4956-912D-8B4FB456DDA3}.png" src="\lib\media\{56cdad7c-1b12-4956-912d-8b4fb456dda3}.png"><br><br><img alt="{D08CAD37-6DB1-4B95-BF18-49BC6600DDEB}.png" src="\lib\media\{d08cad37-6db1-4b95-bf18-49bc6600ddeb}.png"><br><img alt="{E948573A-E2FB-4FFC-B91E-B4A82F02A3A9}.png" src="\lib\media\{e948573a-e2fb-4ffc-b91e-b4a82f02a3a9}.png"><br><br><img alt="{4608BA86-2154-4A9E-A241-CA3B7783ACB6}.png" src="\lib\media\{4608ba86-2154-4a9e-a241-ca3b7783acb6}.png"><br><br><img alt="{1CA71325-A95E-47B5-B03D-05CA8F28AA55}.png" src="\lib\media\{1ca71325-a95e-47b5-b03d-05ca8f28aa55}.png"><br><br><img alt="{8BB297BB-7755-4462-80B7-31215C4055FB}.png" src="\lib\media\{8bb297bb-7755-4462-80b7-31215c4055fb}.png"><br><br><img alt="{44B0FDC0-EB70-42C8-B589-718B753CF7DF}.png" src="\lib\media\{44b0fdc0-eb70-42c8-b589-718b753cf7df}.png"><br>
<img alt="{6E139BC8-1569-4426-9ACE-E4EA15EE7846}.png" src="\lib\media\{6e139bc8-1569-4426-9ace-e4ea15ee7846}.png"><br><br><img alt="{192412C0-A765-454D-811A-BFFE267E5871}.png" src="\lib\media\{192412c0-a765-454d-811a-bffe267e5871}.png"><br>
<img alt="{9D9D5BDA-3BD8-4BFD-9E7D-2B2D9724E564}.png" src="\lib\media\{9d9d5bda-3bd8-4bfd-9e7d-2b2d9724e564}.png"><br><br><img alt="{6B6B444F-4278-49C4-A4DD-64A48B503C56}.png" src="\lib\media\{6b6b444f-4278-49c4-a4dd-64a48b503c56}.png"><br><img alt="{43AF15BE-A129-4769-A650-53FDF5DE8642}.png" src="\lib\media\{43af15be-a129-4769-a650-53fdf5de8642}.png"><br>
线选法存在线路浪费。<br>
改进为译码片选法<br>
<img alt="{6437537C-CC72-4008-9207-FB14293603D4}.png" src="\lib\media\{6437537c-cc72-4008-9207-fb14293603d4}.png"><br><img alt="{FE403A49-BEB7-4BB7-9B77-0224E52FDD76}.png" src="\lib\media\{fe403a49-beb7-4bb7-9b77-0224e52fdd76}.png"><br><br><img alt="{D110B000-45A9-4B56-A5BD-3CB9618BABE0}.png" src="\lib\media\{d110b000-45a9-4b56-a5bd-3cb9618babe0}.png"><br><br><img alt="{B4713337-97A5-4E16-8943-915D3748E8D2}.png" src="\lib\media\{b4713337-97a5-4e16-8943-915d3748e8d2}.png"><br>
<img alt="{144B60BD-CAFD-4B86-820C-1CB2A083329B}.png" src="\lib\media\{144b60bd-cafd-4b86-820c-1cb2a083329b}.png"><br>
<img alt="{16076432-FE0B-4E01-8B00-449460AC6F07}.png" src="\lib\media\{16076432-fe0b-4e01-8b00-449460ac6f07}.png"><br><br><img alt="{4829C1FF-D26C-4A2C-AB43-95138820FBBF}.png" src="\lib\media\{4829c1ff-d26c-4a2c-ab43-95138820fbbf}.png"><br><br><img alt="{190BC578-DEBC-4149-81F6-0B84D128092C}.png" src="\lib\media\{190bc578-debc-4149-81f6-0b84d128092c}.png"><br>
<img alt="{2E8F1D3D-6EA4-4E89-A6AE-8A18C43193CB}.png" src="\lib\media\{2e8f1d3d-6ea4-4e89-a6ae-8a18c43193cb}.png"><br>
<img alt="{83BD6FCE-1967-4E3F-851F-98C7930F5D32}.png" src="\lib\media\{83bd6fce-1967-4e3f-851f-98c7930f5d32}.png"><br><br><img alt="{FDBFC77F-2245-4914-A078-2656806BF976}.png" src="\lib\media\{fdbfc77f-2245-4914-a078-2656806bf976}.png"><br><br><img alt="{E2D6C39F-F912-4D69-8920-D2D4CED96CF0}.png" src="\lib\media\{e2d6c39f-f912-4d69-8920-d2d4ced96cf0}.png"><br>
<img alt="{7E4FBEFC-C593-42A1-B49B-C78370AD1B6E}.png" src="\lib\media\{7e4fbefc-c593-42a1-b49b-c78370ad1b6e}.png"><br>
<img alt="{5C9B0FF5-A1E9-4C08-87D5-483EED780102}.png" src="\lib\media\{5c9b0ff5-a1e9-4c08-87d5-483eed780102}.png"><br><br><img alt="{94D07D3F-7224-4917-B7DC-6408F89A3A9C}.png" src="\lib\media\{94d07d3f-7224-4917-b7dc-6408f89a3a9c}.png"><br><br><img alt="{6F01CA0A-58B1-4547-AECC-03EBEEC3BFDA}.png" src="\lib\media\{6f01ca0a-58b1-4547-aecc-03ebeec3bfda}.png"><br>
要以块为单位擦除。<br><br><img alt="{E89D2733-0D94-4D29-A33F-62D24A641FE5}.png" src="\lib\media\{e89d2733-0d94-4d29-a33f-62d24a641fe5}.png"><br><br><img alt="{84B4F786-C8CF-4BA8-9DB8-2E147179CE40}.png" src="\lib\media\{84b4f786-c8cf-4ba8-9db8-2e147179ce40}.png"><br><br><img alt="{3812B3B6-8F55-4E89-849F-B4A6387EA59A}.png" src="\lib\media\{3812b3b6-8f55-4e89-849f-b4a6387ea59a}.png"><br><br><img alt="{FB7B7DE2-3A2B-4C3D-BB49-B5D8E0B4B0D7}.png" src="\lib\media\{fb7b7de2-3a2b-4c3d-bb49-b5d8e0b4b0d7}.png"><br><br><img alt="{38297CEB-ED93-4246-99F9-2FE7423DFAD2}.png" src="\lib\media\{38297ceb-ed93-4246-99f9-2fe7423dfad2}.png"><br>
<img alt="{4AAF244B-7A85-441D-82EF-B98C5AD54DB5}.png" src="\lib\media\{4aaf244b-7a85-441d-82ef-b98c5ad54db5}.png"><br><br><img alt="{847EB631-4FB4-4D89-9E0A-0C3FF3E9C3FD}.png" src="\lib\media\{847eb631-4fb4-4d89-9e0a-0c3ff3e9c3fd}.png"><br>
<img alt="{F8E66D32-237F-49EC-A984-6B9E72C664EB}.png" src="\lib\media\{f8e66d32-237f-49ec-a984-6b9e72c664eb}.png"><br>
<img alt="{76AA09A3-00B0-47D9-BCE4-3EECAB4428BE}.png" src="\lib\media\{76aa09a3-00b0-47d9-bce4-3eecab4428be}.png"><br><br><img alt="{B5FF05BF-24C9-45F9-806A-D7381FBAA031}.png" src="\lib\media\{b5ff05bf-24c9-45f9-806a-d7381fbaa031}.png"><br><img alt="{7D6C1105-D194-4D8B-960A-1B9300AE00FE}.png" src="\lib\media\{7d6c1105-d194-4d8b-960a-1b9300ae00fe}.png"><br><br><img alt="{1EF036D9-5129-455D-89C2-D8096DA771E6}.png" src="\lib\media\{1ef036d9-5129-455d-89c2-d8096da771e6}.png"><br><br><img alt="{C0C4F6B6-DEAC-4BD5-9902-28CD5D058A45}.png" src="\lib\media\{c0c4f6b6-deac-4bd5-9902-28cd5d058a45}.png"><br><br><img alt="{F076BBD0-A719-4A6D-9F78-EE7574112E0D}.png" src="\lib\media\{f076bbd0-a719-4a6d-9f78-ee7574112e0d}.png"><br><br><img alt="{F8F75019-CD6E-47C7-898B-568FCCD738BB}.png" src="\lib\media\{f8f75019-cd6e-47c7-898b-568fccd738bb}.png"><br>
<img alt="{8AC37E1B-4A76-4648-BC5F-9F82C3A938B4}.png" src="\lib\media\{8ac37e1b-4a76-4648-bc5f-9f82c3a938b4}.png"><br><br><img alt="{3487609A-B78B-42D0-8CBE-D1B733351D5D}.png" src="\lib\media\{3487609a-b78b-42d0-8cbe-d1b733351d5d}.png"><br><br><img alt="{81F3C532-2C97-49E7-A630-B5B6174EDD6F}.png" src="\lib\media\{81f3c532-2c97-49e7-a630-b5b6174edd6f}.png"><br><br><img alt="{940FD26A-E368-4CA7-AAB1-5A5269598083}.png" src="\lib\media\{940fd26a-e368-4ca7-aab1-5a5269598083}.png"><br>
<img alt="{0ADCF580-9321-4F28-8D10-5B516D996218}.png" src="\lib\media\{0adcf580-9321-4f28-8d10-5b516d996218}.png"><br>
<img alt="{DBBE9145-F589-4FCC-A3D2-5014E2AF2FB7}.png" src="\lib\media\{dbbe9145-f589-4fcc-a3d2-5014e2af2fb7}.png"><br><br><img alt="{A650A83C-F3E2-406D-87AB-C681F4F6FCDD}.png" src="\lib\media\{a650a83c-f3e2-406d-87ab-c681f4f6fcdd}.png"><br>
<img alt="{20303F34-AADE-4395-A440-8DFBC6C6609C}.png" src="\lib\media\{20303f34-aade-4395-a440-8dfbc6c6609c}.png"><br><br><img alt="{D7F7C5E9-CE05-4AC8-9732-60ACDBBB0FB8}.png" src="\lib\media\{d7f7c5e9-ce05-4ac8-9732-60acdbbb0fb8}.png"><br>
<img alt="{3AAF60B9-9FC1-4399-9957-2A8D7D3699F5}.png" src="\lib\media\{3aaf60b9-9fc1-4399-9957-2a8d7d3699f5}.png"><br>
<img alt="{D3F56858-5327-48B1-A763-A8968D8BCD28}.png" src="\lib\media\{d3f56858-5327-48b1-a763-a8968d8bcd28}.png"><br><br><br><img alt="{2463A373-DC01-4267-9791-2FCBB3634E76}.png" src="\lib\media\{2463a373-dc01-4267-9791-2fcbb3634e76}.png"><br><br><img alt="{202C9661-0F6D-4D55-9C92-9CACB0036262}.png" src="\lib\media\{202c9661-0f6d-4d55-9c92-9cacb0036262}.png"><br>
<img alt="{CB570430-A511-4EAF-AFAE-3ADA40CC3FED}.png" src="\lib\media\{cb570430-a511-4eaf-afae-3ada40cc3fed}.png"><br><br><br><img alt="{C95A8474-83EB-4D09-B079-3CA5346BB390}.png" src="\lib\media\{c95a8474-83eb-4d09-b079-3ca5346bb390}.png"><br><br><img alt="{7AF8CC62-BA97-42BB-B264-6503B3018E49}.png" src="\lib\media\{7af8cc62-ba97-42bb-b264-6503b3018e49}.png"><br><br><img alt="{CDBB9373-A773-4732-A6A4-524CFB940C8F}.png" src="\lib\media\{cdbb9373-a773-4732-a6a4-524cfb940c8f}.png"><br><br><img alt="{9B832D0B-62F5-4469-8F09-AEB8A98643C4}.png" src="\lib\media\{9b832d0b-62f5-4469-8f09-aeb8a98643c4}.png"><br><img alt="{EE688600-C030-4338-A184-BD5D1F3F582E}.png" src="\lib\media\{ee688600-c030-4338-a184-bd5d1f3f582e}.png"><br><br><img alt="{914DB264-E08B-4F35-B1AA-7F27D3A085CE}.png" src="\lib\media\{914db264-e08b-4f35-b1aa-7f27d3a085ce}.png"><br><br><img alt="{BD49A60A-5F8F-4DEA-AF12-B42F2E2CC388}.png" src="\lib\media\{bd49a60a-5f8f-4dea-af12-b42f2e2cc388}.png"><br><br><img alt="{8A37C7CF-5693-460A-8628-99311C806766}.png" src="\lib\media\{8a37c7cf-5693-460a-8628-99311c806766}.png"><br><br><img alt="{B0B0A77C-7E1D-4672-8F1B-0AC0162790FC}.png" src="\lib\media\{b0b0a77c-7e1d-4672-8f1b-0ac0162790fc}.png"><br><br><img alt="{61D98060-792B-40A9-BDF3-A60861C6FB85}.png" src="\lib\media\{61d98060-792b-40a9-bdf3-a60861c6fb85}.png"><br><br><img alt="{EB2EDD12-8403-4BB4-AF58-A09820ABF56D}.png" src="\lib\media\{eb2edd12-8403-4bb4-af58-a09820abf56d}.png"><br><img alt="{9B4AF5D9-732C-4660-BB26-EECBDAE5B145}.png" src="\lib\media\{9b4af5d9-732c-4660-bb26-eecbdae5b145}.png"><br><br><img alt="{CAA33D69-157A-49D4-8DAD-D04D592BE7F7}.png" src="\lib\media\{caa33d69-157a-49d4-8dad-d04d592be7f7}.png"><br><br><img alt="{19A1850B-4AC4-4597-ADD9-F22C8DB9AD0B}.png" src="\lib\media\{19a1850b-4ac4-4597-add9-f22c8db9ad0b}.png"><br>
<img alt="{6FC4A94B-96FE-4810-8DD9-5895EFE5924D}.png" src="\lib\media\{6fc4a94b-96fe-4810-8dd9-5895efe5924d}.png"><br><br><img alt="{9FAE47B4-969F-4341-909D-0F93768ED7DD}.png" src="\lib\media\{9fae47b4-969f-4341-909d-0f93768ed7dd}.png"><br><br><br><img alt="{3FEB6314-901D-4A5E-AA68-7F9019E28AC4}.png" src="\lib\media\{3feb6314-901d-4a5e-aa68-7f9019e28ac4}.png"><br><br><img alt="{82D82351-B232-4A78-B795-144C291B82C5}.png" src="\lib\media\{82d82351-b232-4a78-b795-144c291b82c5}.png"><br><br><img alt="{8511ABC5-C4F5-4024-B5F8-83CE8F833000}.png" src="\lib\media\{8511abc5-c4f5-4024-b5f8-83ce8f833000}.png"><br><br><img alt="{0EE452B0-8C07-482E-87CE-CDEDB70B926C}.png" src="\lib\media\{0ee452b0-8c07-482e-87ce-cdedb70b926c}.png"><br><br><img alt="{A23BFB22-2B4E-4A22-9371-9B6871DA37BC}.png" src="\lib\media\{a23bfb22-2b4e-4a22-9371-9b6871da37bc}.png"><br><br><img alt="{C40B47F5-78E3-423E-B1D6-D87991220AFD}.png" src="\lib\media\{c40b47f5-78e3-423e-b1d6-d87991220afd}.png"><br><br><img alt="{649FD85E-8548-4DEB-A001-36C4850BD796}.png" src="\lib\media\{649fd85e-8548-4deb-a001-36c4850bd796}.png"><br><br><img alt="{E2CD0D92-E18A-4F14-B21F-A7D2BAB94E2C}.png" src="\lib\media\{e2cd0d92-e18a-4f14-b21f-a7d2bab94e2c}.png"><br><br><img alt="{A737575C-1362-48DD-AE8E-DF2B1E327953}.png" src="\lib\media\{a737575c-1362-48dd-ae8e-df2b1e327953}.png"><br><br><img alt="{D8D82F5B-760E-4843-BED4-27424CED21E7}.png" src="\lib\media\{d8d82f5b-760e-4843-bed4-27424ced21e7}.png"><br><br><img alt="{27E0AF2D-550B-4005-8D9A-12E37EE8414B}.png" src="\lib\media\{27e0af2d-550b-4005-8d9a-12e37ee8414b}.png"><br>
<img alt="{8BDA9938-0975-409D-AF9C-50580132A624}.png" src="\lib\media\{8bda9938-0975-409d-af9c-50580132a624}.png"><br>
联系哈夫曼树<br>
<img alt="{69513DDE-4D30-4BD2-B622-F6BDA1A18E85}.png" src="\lib\media\{69513dde-4d30-4bd2-b622-f6bda1a18e85}.png"><br><img alt="{F0CCD0D3-1AEF-4920-A204-8615D66E3EAE}.png" src="\lib\media\{f0ccd0d3-1aef-4920-a204-8615d66e3eae}.png"><br>
有两行是因为A1为1100～1110时，A2取0000～1111。A1取1111时，A2取0000～1101<br>
<img alt="{9D19CE33-285A-4255-A705-403925C2996F}.png" src="\lib\media\{9d19ce33-285a-4255-a705-403925c2996f}.png"><br><br><img alt="{5C1B5C49-EF59-4CFE-8E2D-9D3D00F03F37}.png" src="\lib\media\{5c1b5c49-ef59-4cfe-8e2d-9d3d00f03f37}.png"><br><br><img alt="{6F22081F-E212-4258-93CA-F35AC962BF42}.png" src="\lib\media\{6f22081f-e212-4258-93ca-f35ac962bf42}.png"><br><br><img alt="{3AC0B2E6-4CAF-4998-A0F6-CABD99D872ED}.png" src="\lib\media\{3ac0b2e6-4caf-4998-a0f6-cabd99d872ed}.png"><br>
<img alt="{E691C1D6-AF3F-4AEB-9CA6-9867FE01F7AD}.png" src="\lib\media\{e691c1d6-af3f-4aeb-9ca6-9867fe01f7ad}.png"><br><br><img alt="{7AD7C8F9-6ABE-4B71-8B89-DB3388AA725F}.png" src="\lib\media\{7ad7c8f9-6abe-4b71-8b89-db3388aa725f}.png"><br><br><img alt="{A0706AC7-CBD3-49F8-932F-C385375B4B17}.png" src="\lib\media\{a0706ac7-cbd3-49f8-932f-c385375b4b17}.png"><br><img alt="{3AE5F78F-D693-411E-9EC4-F7E44F0547DF}.png" src="\lib\media\{3ae5f78f-d693-411e-9ec4-f7e44f0547df}.png"><br>
<img alt="{2C002370-F6D2-456C-BF0D-C3F875613A0B}.png" src="\lib\media\{2c002370-f6d2-456c-bf0d-c3f875613a0b}.png"><br><br><img alt="{649879FA-365B-465A-9BB1-29CA34EF8D7F}.png" src="\lib\media\{649879fa-365b-465a-9bb1-29ca34ef8d7f}.png"><br><br><img alt="{8A48EFB8-14A8-4DBB-882D-47128AC59C98}.png" src="\lib\media\{8a48efb8-14a8-4dbb-882d-47128ac59c98}.png"><br><br><img alt="{577F067A-65C4-4EAA-BC42-21F5C8F5B198}.png" src="\lib\media\{577f067a-65c4-4eaa-bc42-21f5c8f5b198}.png"><br><br><img alt="{CB5DF78D-937A-40B5-999C-E61A880A984B}.png" src="\lib\media\{cb5df78d-937a-40b5-999c-e61a880a984b}.png"><br><br><img alt="{6652E529-06B2-46F0-A74D-5480A13CEB0D}.png" src="\lib\media\{6652e529-06b2-46f0-a74d-5480a13ceb0d}.png"><br><br><img alt="{7D1FFEDF-1F02-479D-993A-D43520528BE6}.png" src="\lib\media\{7d1ffedf-1f02-479d-993a-d43520528be6}.png"><br><br><img alt="{1C45DC11-4137-48CA-A3B7-86124EFE9D47}.png" src="\lib\media\{1c45dc11-4137-48ca-a3b7-86124efe9d47}.png"><br>
<img alt="{C6215396-5589-4496-8A03-7E0838EDF10E}.png" src="\lib\media\{c6215396-5589-4496-8a03-7e0838edf10e}.png"><br><br><img alt="{A737D705-8E42-4CCD-8B9F-E5D9C3522498}.png" src="\lib\media\{a737d705-8e42-4ccd-8b9f-e5d9c3522498}.png"><br><img alt="{9177F4DE-5F0B-4536-BCC5-80D2E6FD7231}.png" src="\lib\media\{9177f4de-5f0b-4536-bcc5-80d2e6fd7231}.png"><br>
<img alt="{9D6D50D6-855C-4FF0-92CA-6A891C38B47F}.png" src="\lib\media\{9d6d50d6-855c-4ff0-92ca-6a891c38b47f}.png"><br><br><img alt="{96FBAE73-D230-45A1-84E7-12CC6A5B9B84}.png" src="\lib\media\{96fbae73-d230-45a1-84e7-12cc6a5b9b84}.png"><br>
<img alt="{C402709A-CB35-47D0-B7DE-204849749B03}.png" src="\lib\media\{c402709a-cb35-47d0-b7de-204849749b03}.png"><br>
<img alt="{E0762559-5AD1-476B-9392-D2748FED2E8A}.png" src="\lib\media\{e0762559-5ad1-476b-9392-d2748fed2e8a}.png"><br><br><img alt="{730C7A76-CD21-44AF-B8A4-84C3D918758D}.png" src="\lib\media\{730c7a76-cd21-44af-b8a4-84c3d918758d}.png"><br>
<img alt="{F6595BF9-0942-4E58-8840-E024B321E9DF}.png" src="\lib\media\{f6595bf9-0942-4e58-8840-e024b321e9df}.png"><br>
<img alt="{73414869-5BF2-4112-B2DE-EBBDDB9FFEF2}.png" src="\lib\media\{73414869-5bf2-4112-b2de-ebbddb9ffef2}.png"><br>
<img alt="{C58915E4-AA08-430B-83D0-1D0BA7173E20}.png" src="\lib\media\{c58915e4-aa08-430b-83d0-1d0ba7173e20}.png"><br><br><img alt="{536D4994-E3CB-42E7-A492-B850C13C3B71}.png" src="\lib\media\{536d4994-e3cb-42e7-a492-b850c13c3b71}.png"><br>
<img alt="{D4D8A74C-BB95-485E-82EA-79E51A63ACC3}.png" src="\lib\media\{d4d8a74c-bb95-485e-82ea-79e51a63acc3}.png"><br><br><br><img alt="{C10D4CFC-A660-4C7C-B973-DBCFA52A711A}.png" src="\lib\media\{c10d4cfc-a660-4c7c-b973-dbcfa52a711a}.png"><br>
硬堆栈是将栈放在寄存器中，不用访存<br><br><img alt="{27149ACC-73F4-468F-A3BC-C3A4AB7617E6}.png" src="\lib\media\{27149acc-73f4-468f-a3bc-c3a4ab7617e6}.png"><br><img alt="{A2803841-E0ED-4EEE-A8A8-A90084B29B02}.png" src="\lib\media\{a2803841-e0ed-4eee-a8a8-a90084b29b02}.png"><br><br><img alt="附件/{C731D61D-309E-4959-A5F1-20EDC22FC43D}.png" src="\lib\media\{c731d61d-309e-4959-a5f1-20edc22fc43d}.png"><br>
汇编语言和机器语言是一一对应的。汇编语言也是机器级代码。<br>
<br>只需要关注x86汇编语言
<br>能够结合c语言看懂汇编语言
<br>分析汇编语言指令格式和寻址方式<br>
<img alt="附件/{52888014-C6E1-4F16-9586-973B51C762A3}.png" src="\lib\media\{52888014-c6e1-4f16-9586-973b51c762a3}.png"><br>
<img alt="附件/{07F4AC85-2FCA-4A05-83D5-5EEEE0C23E78}.png" src="\lib\media\{07f4ac85-2fca-4a05-83d5-5eeee0c23e78}.png">
<br><br><img alt="附件/{9012051C-DD44-435C-81F6-4B74615DAC94}.png" src="\lib\media\{9012051c-dd44-435c-81f6-4b74615dac94}.png"><br>
<img alt="附件/{90BEAF32-7740-4C0E-A64A-1B21AE1FCBF9}.png" src="\lib\media\{90beaf32-7740-4c0e-a64a-1b21ae1fcbf9}.png"><br><br>E开头就是32bit。<br>
X结尾是存什么未知所以是通用寄存器。<br>
I结尾是Index是变址寄存器<br>
EBP,栈基指针<br>
ESP,栈顶指针<br>
<img alt="附件/{2B74B488-BF23-463C-8EE5-52880B87B0AD}.png" src="\lib\media\{2b74b488-bf23-463c-8ee5-52880b87b0ad}.png"><img alt="附件/{5FEFA600-D878-4646-8077-AA5A651D5D8B}.png" src="\lib\media\{5fefa600-d878-4646-8077-aa5a651d5d8b}.png"><img alt="附件/{F3C3464B-CBB3-4384-B66D-90134BD7A9E6}.png" src="\lib\media\{f3c3464b-cbb3-4384-b66d-90134bd7a9e6}.png"><img alt="附件/{B8C31671-7C16-43B4-8AF1-BCEB2B690C75}.png" src="\lib\media\{b8c31671-7c16-43b4-8af1-bceb2b690c75}.png"><br><br><br><img alt="Pasted image 20241127123755.png" src="\lib\media\pasted-image-20241127123755.png"><br>
除法只有一个操作数，即除数。而除法开始前需要将被除数扩展到64位，存在edx:eax，商最后会得到在eax中，余数存入edx。所以除法默认被除数已经存入edx:eax。<br><img alt="Pasted image 20241127124751.png" src="\lib\media\pasted-image-20241127124751.png"><br><br><img alt="Pasted image 20241127125115.png" src="\lib\media\pasted-image-20241127125115.png"><br><br><img alt="Pasted image 20241127125352.png" src="\lib\media\pasted-image-20241127125352.png"><br><br><img alt="Pasted image 20241127131853.png" src="\lib\media\pasted-image-20241127131853.png"><br>
<img alt="Pasted image 20241127174059.png" src="\lib\media\pasted-image-20241127174059.png"><br><br><img alt="Pasted image 20241127174533.png" src="\lib\media\pasted-image-20241127174533.png"><br>
<img alt="Pasted image 20241127175055.png" src="\lib\media\pasted-image-20241127175055.png"><br>
<img alt="Pasted image 20241127175329.png" src="\lib\media\pasted-image-20241127175329.png"><br>
<img alt="Pasted image 20241127175819.png" src="\lib\media\pasted-image-20241127175819.png"><br><br><img alt="Pasted image 20241128094216.png" src="\lib\media\pasted-image-20241128094216.png"><br>
<img alt="Pasted image 20241128094154.png" src="\lib\media\pasted-image-20241128094154.png"><br><img alt="Pasted image 20241128094721.png" src="\lib\media\pasted-image-20241128094721.png"><br><br><img alt="Pasted image 20241128095903.png" src="\lib\media\pasted-image-20241128095903.png"><br><br><img alt="Pasted image 20241128100512.png" src="\lib\media\pasted-image-20241128100512.png"><br>
<img alt="Pasted image 20241128100641.png" src="\lib\media\pasted-image-20241128100641.png"><br><img alt="Pasted image 20241128101956.png" src="\lib\media\pasted-image-20241128101956.png"><br><br><img alt="Pasted image 20241130173747.png" src="\lib\media\pasted-image-20241130173747.png"><br><br><img alt="Pasted image 20241130174430.png" src="\lib\media\pasted-image-20241130174430.png"><br>
<img alt="Pasted image 20241130174458.png" src="\lib\media\pasted-image-20241130174458.png"><br><br><img alt="Pasted image 20241130174545.png" src="\lib\media\pasted-image-20241130174545.png"><br><br><img alt="Pasted image 20241130174945.png" src="\lib\media\pasted-image-20241130174945.png"><br><br><img alt="Pasted image 20241130175927.png" src="\lib\media\pasted-image-20241130175927.png"><br>
<img alt="Pasted image 20241130180037.png" src="\lib\media\pasted-image-20241130180037.png"><br><br><img alt="Pasted image 20241130180146.png" src="\lib\media\pasted-image-20241130180146.png"><br><br><img alt="Pasted image 20241130175825.png" src="\lib\media\pasted-image-20241130175825.png"><br><br><img alt="Pasted image 20241130180331.png" src="\lib\media\pasted-image-20241130180331.png"><br><br>这部分建议直接看视频<br>
<a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1ps4y1d73V?spm_id_from=333.788.player.switch&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea&amp;p=58" target="_blank">https://www.bilibili.com/video/BV1ps4y1d73V?spm_id_from=333.788.player.switch&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea&amp;p=58</a><br>
<img alt="附件/{32C6FABA-C995-4C37-8FC3-C8DDE332B95C}.png" src="\lib\media\{32c6faba-c995-4c37-8fc3-c8dde332b95c}.png"><br>
<img alt="附件/{DAE4FCAF-FC2E-48D4-B8FE-D5734830299C}.png" src="\lib\media\{dae4fcaf-fc2e-48d4-b8fe-d5734830299c}.png"><br><br><img alt="附件/{9AB613ED-EB18-4336-8970-B1C2B4E9F00B}.png" src="\lib\media\{9ab613ed-eb18-4336-8970-b1c2b4e9f00b}.png"><br>
<img alt="附件/{80E13DB7-B744-4E9C-8C7E-C6AFB299E69F}.png" src="\lib\media\{80e13db7-b744-4e9c-8c7e-c6afb299e69f}.png"><br>
<img alt="附件/{4838D8EB-4113-4DF6-9542-D995C4172BBE}.png" src="\lib\media\{4838d8eb-4113-4df6-9542-d995c4172bbe}.png"><br>
<img alt="附件/{75CC08A1-886C-474A-8008-5EDA0069A2AE}.png" src="\lib\media\{75cc08a1-886c-474a-8008-5eda0069a2ae}.png"><br>
<img alt="附件/{9ABC2EDC-2C02-4535-94F9-EA8C7FFA086E}.png" src="\lib\media\{9abc2edc-2c02-4535-94f9-ea8c7ffa086e}.png"><br>
<img alt="附件/{BB3C7B42-AEF0-42C5-A89B-BC7135575673}.png" src="\lib\media\{bb3c7b42-aef0-42c5-a89b-bc7135575673}.png"><br><br><img alt="附件/{834CB1C8-264B-4467-8B91-1C22D026991A}.png" src="\lib\media\{834cb1c8-264b-4467-8b91-1c22d026991a}.png"><br>
<img alt="附件/{49DC0F2F-29B6-4445-BA86-EC7829B6A9C0}.png" src="\lib\media\{49dc0f2f-29b6-4445-ba86-ec7829b6a9c0}.png"><br><br><br><img alt="附件/{C9BA8ECB-835C-4916-ADE1-47D39DD6DB03}.png" src="\lib\media\{c9ba8ecb-835c-4916-ade1-47d39dd6db03}.png"><br>
<img alt="附件/{B88533A7-9501-4951-A7EC-6B81A950A30F}.png" src="\lib\media\{b88533a7-9501-4951-a7ec-6b81a950a30f}.png"><br>
<img alt="附件/{E29B0D94-6592-4F80-B564-DC980AE2632A}.png" src="\lib\media\{e29b0d94-6592-4f80-b564-dc980ae2632a}.png"><br>
<img alt="附件/{E16520DA-39AC-44A3-9D85-D15D30B6E7D3}.png" src="\lib\media\{e16520da-39ac-44a3-9d85-d15d30b6e7d3}.png"><br><br><img alt="附件/{DD393254-7281-4F0C-9936-3F9033F52708}.png" src="\lib\media\{dd393254-7281-4f0c-9936-3f9033f52708}.png"><br>
<img alt="附件/{3FF904C3-B512-4438-9409-8DB33C808361}.png" src="\lib\media\{3ff904c3-b512-4438-9409-8db33c808361}.png"><br>
<img alt="附件/{E7F61937-E26A-414C-BBD5-D0AB140B0045}.png" src="\lib\media\{e7f61937-e26a-414c-bbd5-d0ab140b0045}.png"><br><br><img alt="附件/{E1F88E35-0ED4-44F7-AB22-F3F04BD6608E}.png" src="\lib\media\{e1f88e35-0ed4-44f7-ab22-f3f04bd6608e}.png"><br><br><img alt="附件/{279FAF44-2A00-4B6C-B72A-A6C848AA9548}.png" src="\lib\media\{279faf44-2a00-4b6c-b72a-a6c848aa9548}.png"><br><br><img alt="附件/{97622FB9-D180-4675-9543-890CA5380364}.png" src="\lib\media\{97622fb9-d180-4675-9543-890ca5380364}.png"><br><br><img alt="附件/{14BB8DD9-07A8-4773-B7AA-5DE5FE552ECE}.png" src="\lib\media\{14bb8dd9-07a8-4773-b7aa-5de5fe552ece}.png"><br><br>程序状态字寄存器<br><br><img alt="附件/{8E8D5DA8-B901-4EEC-B5C4-E64CFD52BBFF}.png" src="\lib\media\{8e8d5da8-b901-4eec-b5c4-e64cfd52bbff}.png"><br><br><img alt="附件/{1DA489AC-2F30-444A-8DF4-C1A8832B6164}.png" src="\lib\media\{1da489ac-2f30-444a-8df4-c1a8832b6164}.png"><img alt="附件/{75D58488-7867-4E5D-AA79-F25829699E6E}.png" src="\lib\media\{75d58488-7867-4e5d-aa79-f25829699e6e}.png"><br><br><img alt="附件/{A2752E6D-D4BF-475F-8908-E5EA5C19CDDD}.png" src="\lib\media\{a2752e6d-d4bf-475f-8908-e5ea5c19cddd}.png"><br><br><img alt="附件/{B51DE822-9839-41B0-BED1-D48A6FFA0021}.png" src="\lib\media\{b51de822-9839-41b0-bed1-d48a6ffa0021}.png"><br>
<img alt="附件/{9B99F5C6-9CD9-4750-AD56-6C62DB06D853}.png" src="\lib\media\{9b99f5c6-9cd9-4750-ad56-6c62db06d853}.png"><br>
<img alt="附件/{6B788CB1-6B63-4EBE-B95D-665789091AC3}.png" src="\lib\media\{6b788cb1-6b63-4ebe-b95d-665789091ac3}.png"><br>
<img alt="附件/{53157EAF-928C-45FC-B2F7-626F5FCF8B29}.png" src="\lib\media\{53157eaf-928c-45fc-b2f7-626f5fcf8b29}.png"><br>
<img alt="附件/{ECBDB34F-1B7A-4A3B-B42C-89A90E75BF8B}.png" src="\lib\media\{ecbdb34f-1b7a-4a3b-b42c-89a90e75bf8b}.png"><br><br><img alt="附件/{F199D7BD-5A63-4F19-A43A-5E07435CCD65}.png" src="\lib\media\{f199d7bd-5a63-4f19-a43a-5e07435ccd65}.png"><br><br><img alt="附件/{8B8E3FFB-0D66-46AA-9E71-FF97FA2BBF87}.png" src="\lib\media\{8b8e3ffb-0d66-46aa-9e71-ff97fa2bbf87}.png"><br><br><img alt="附件/{0771A510-6861-4535-B346-0BB5614055FD}.png" src="\lib\media\{0771a510-6861-4535-b346-0bb5614055fd}.png"><br><br><img alt="附件/{F2A7F100-B962-4929-946D-1E3C7ED97630}.png" src="\lib\media\{f2a7f100-b962-4929-946d-1e3c7ed97630}.png"><br>
<img alt="附件/{0B6175FD-4677-43E8-B8A2-FF5B6B6DD4ED}.png" src="\lib\media\{0b6175fd-4677-43e8-b8a2-ff5b6b6dd4ed}.png"><br><br><img alt="附件/{137957D0-498A-4A77-A476-9F2EBD7BC3EA}.png" src="\lib\media\{137957d0-498a-4a77-a476-9f2ebd7bc3ea}.png"><br><br><img alt="附件/{37E6E67A-FECE-4097-9C4C-BCA9C4937203}.png" src="\lib\media\{37e6e67a-fece-4097-9c4c-bca9c4937203}.png"><br>
<img alt="附件/{D1C3A41B-A71A-49F2-8591-887F71C10C1D}.png" src="\lib\media\{d1c3a41b-a71a-49f2-8591-887f71c10c1d}.png"><br>
<img alt="附件/{9FEDC1DD-AFC9-47A6-A623-BF67A7A0A822}.png" src="\lib\media\{9fedc1dd-afc9-47a6-a623-bf67a7a0a822}.png"><br>
<img alt="附件/{498DF04B-2AA9-4174-BCA0-4832E8A01F02}.png" src="\lib\media\{498df04b-2aa9-4174-bca0-4832e8a01f02}.png"><br><br><img alt="附件/{2B89D870-2215-4F2F-8596-289F74C0972A}.png" src="\lib\media\{2b89d870-2215-4f2f-8596-289f74c0972a}.png"><br>
<img alt="附件/{B498A352-F069-4F8A-BF53-10FC146AF3A4}.png" src="\lib\media\{b498a352-f069-4f8a-bf53-10fc146af3a4}.png"><br>
<img alt="附件/{626D3CF8-B059-4CC0-96F6-F4A5527E2A45}.png" src="\lib\media\{626d3cf8-b059-4cc0-96f6-f4a5527e2a45}.png"><br><br><img alt="附件/{150BA1BE-6A80-428F-A31C-CFA1FC7F9C1B}.png" src="\lib\media\{150ba1be-6a80-428f-a31c-cfa1fc7f9c1b}.png"><br>
<img alt="附件/{26FB6112-DEB4-4A85-A97A-3413DDC6BFD8}.png" src="\lib\media\{26fb6112-deb4-4a85-a97a-3413ddc6bfd8}.png"><br><br><img alt="附件/{96414319-70CB-4CC1-996F-A8DCC4789FEC}.png" src="\lib\media\{96414319-70cb-4cc1-996f-a8dcc4789fec}.png"><br>
<img alt="附件/{9D9B63F7-F2BA-4DE6-936E-D9BC3F6AF62B}.png" src="\lib\media\{9d9b63f7-f2ba-4de6-936e-d9bc3f6af62b}.png"><br>
<img alt="附件/{980E871D-1AE3-41BC-85AB-F6095DEBD405}.png" src="\lib\media\{980e871d-1ae3-41bc-85ab-f6095debd405}.png"><br>
<img alt="附件/{97D367B5-C7C7-45F9-AC25-07D4C0255048}.png" src="\lib\media\{97d367b5-c7c7-45f9-ac25-07d4c0255048}.png"><br>
<img alt="附件/{1E324024-A1CC-4332-BEC1-1A0B1BE19944}.png" src="\lib\media\{1e324024-a1cc-4332-bec1-1a0b1be19944}.png"><br>
<img alt="附件/{A120F531-4D24-4709-A3F5-D20E1ABF17FA}.png" src="\lib\media\{a120f531-4d24-4709-a3f5-d20e1abf17fa}.png"><img alt="附件/{B013C610-8391-419B-8A39-B202CD655F3F}.png" src="\lib\media\{b013c610-8391-419b-8a39-b202cd655f3f}.png"><img alt="附件/{08634CFD-AB8D-495D-AA46-3958C4D986F7}.png" src="\lib\media\{08634cfd-ab8d-495d-aa46-3958c4d986f7}.png"><br><br><img alt="附件/{28D86E66-312E-4382-807B-4A8CC04CDBED}.png" src="\lib\media\{28d86e66-312e-4382-807b-4a8cc04cdbed}.png"><br>
<img alt="附件/{C0BA7C83-8231-4BE4-A03E-414B542C91E0}.png" src="\lib\media\{c0ba7c83-8231-4be4-a03e-414b542c91e0}.png"><br><br><img alt="附件/{14870421-6C14-4FBD-86BF-0F17D66D6775}.png" src="\lib\media\{14870421-6c14-4fbd-86bf-0f17d66d6775}.png"><br><br><img alt="附件/{10E56D28-AA30-49B2-A98E-98E8AFFA093A}.png" src="\lib\media\{10e56d28-aa30-49b2-a98e-98e8affa093a}.png"><br><br><img alt="附件/{18933CA9-A24C-4CE0-B962-CB5E593E7081}.png" src="\lib\media\{18933ca9-a24c-4ce0-b962-cb5e593e7081}.png"><br><br><img alt="附件/{666B61F6-51D5-4422-AADF-C2923ABA9604}.png" src="\lib\media\{666b61f6-51d5-4422-aadf-c2923aba9604}.png"><img alt="附件/{7E093164-59DD-4C18-BB15-F29C34482A2A}.png" src="\lib\media\{7e093164-59dd-4c18-bb15-f29c34482a2a}.png"><br>
<img alt="附件/{CA69934D-9F43-4756-88EC-59E93E9AA254}.png" src="\lib\media\{ca69934d-9f43-4756-88ec-59e93e9aa254}.png"><br><br><img alt="附件/{BEA0F5B7-F9E9-4ECA-8B26-50D43AFF462E}.png" src="\lib\media\{bea0f5b7-f9e9-4eca-8b26-50d43aff462e}.png"><br>
使用组合逻辑设计<br><br><img alt="附件/{973BFD7E-D3D2-44C5-8404-B8505A364311}.png" src="\lib\media\{973bfd7e-d3d2-44c5-8404-b8505a364311}.png"><br><br><br><img alt="附件/{963DEEA1-A0F9-490C-9008-FBA72F8098BE}.png" src="\lib\media\{963deea1-a0f9-490c-9008-fba72f8098be}.png"><br><br><img alt="附件/{7453D1FE-4ED9-4FA8-9EA5-031CAE068C64}.png" src="\lib\media\{7453d1fe-4ed9-4fa8-9ea5-031cae068c64}.png"><br><br><img alt="附件/{39AD15F0-CCF3-4B09-81E1-5449CEDA0CAA}.png" src="\lib\media\{39ad15f0-ccf3-4b09-81e1-5449ceda0caa}.png"><br><br><img alt="附件/{14DECEB3-C541-42C3-99F7-CC2845EA68BA}.png" src="\lib\media\{14deceb3-c541-42c3-99f7-cc2845ea68ba}.png"><br><br><img alt="附件/{D6C1CEDC-8618-4947-8AF7-E3183A4D67A6}.png" src="\lib\media\{d6c1cedc-8618-4947-8af7-e3183a4d67a6}.png"><br><br><img alt="附件/{7B2D5184-6EB3-454F-A794-8BBCEDD4F8CB}.png" src="\lib\media\{7b2d5184-6eb3-454f-a794-8bbcedd4f8cb}.png"><br><br><img alt="附件/{2FCA749D-5BFF-4159-939B-9EF2F50995A4}.png" src="\lib\media\{2fca749d-5bff-4159-939b-9ef2f50995a4}.png"><br>
<img alt="附件/{14D8170B-6508-4B03-B353-1909CC9CCC69}.png" src="\lib\media\{14d8170b-6508-4b03-b353-1909cc9ccc69}.png"><br>
硬布线是纯硬件设计，微程序控制器引入软件思想，将每一条汇编指令对应成一个微程序。<br>
<img alt="附件/{85DE19C6-95F7-4174-BB2B-1E090BD46EBD}.png" src="\lib\media\{85de19c6-95f7-4174-bb2b-1e090bd46ebd}.png"><br><br><img alt="附件/{0009192E-EE05-4D9E-8B35-7B89B94F444F}.png" src="\lib\media\{0009192e-ee05-4d9e-8b35-7b89b94f444f}.png"><br>
<img alt="附件/{3145B1DC-56BC-425C-8FAD-797E1018F28C}.png" src="\lib\media\{3145b1dc-56bc-425c-8fad-797e1018f28c}.png"><br>
<img alt="附件/{87E69861-5A28-4EA6-816F-FD7F832DA694}.png" src="\lib\media\{87e69861-5a28-4ea6-816f-fd7f832da694}.png"><br><br><img alt="附件/{68B196A1-E5E2-4D38-82C2-30021DE54350}.png" src="\lib\media\{68b196a1-e5e2-4d38-82c2-30021de54350}.png"><br>
<img alt="附件/{2363E443-3999-4A8F-A207-7E0AB1C06999}.png" src="\lib\media\{2363e443-3999-4a8f-a207-7e0ab1c06999}.png"><br><br><img alt="附件/{01FD8894-4949-43D7-B3E8-E4EE97E6A228}.png" src="\lib\media\{01fd8894-4949-43d7-b3e8-e4ee97e6a228}.png"><br><br><br><img alt="附件/{D36ACA89-17FC-4679-8B66-A06CC23F0EA2}.png" src="\lib\media\{d36aca89-17fc-4679-8b66-a06cc23f0ea2}.png"><br><br><img alt="附件/{1008975F-C080-4978-8B13-6B811B930863}.png" src="\lib\media\{1008975f-c080-4978-8b13-6b811b930863}.png"><br><br><img alt="附件/{3D972489-AB55-4ED5-97CF-808CF72DED4E}.png" src="\lib\media\{3d972489-ab55-4ed5-97cf-808cf72ded4e}.png"><br><br><img alt="附件/{716B4D3D-CCF2-437B-AFD8-1E74A0D48CB1}.png" src="\lib\media\{716b4d3d-ccf2-437b-afd8-1e74a0d48cb1}.png"><br><br><img alt="附件/{146C06A3-57D5-4CBD-AAF9-AD903245AB2D}.png" src="\lib\media\{146c06a3-57d5-4cbd-aaf9-ad903245ab2d}.png"><br>
<img alt="附件/{9033576B-28D5-4251-B9FE-EC456835B4E8}.png" src="\lib\media\{9033576b-28d5-4251-b9fe-ec456835b4e8}.png"><br><br><img alt="附件/{0E17452E-57C7-484D-8B82-E786FA770A12}.png" src="\lib\media\{0e17452e-57c7-484d-8b82-e786fa770a12}.png"><br><br><img alt="附件/{C5A66812-5113-4D81-8482-2E0E8FB9189B}.png" src="\lib\media\{c5a66812-5113-4d81-8482-2e0e8fb9189b}.png"><br><img alt="附件/{6E964263-7E9E-4E0A-BB41-8AD6CDA4463C}.png" src="\lib\media\{6e964263-7e9e-4e0a-bb41-8ad6cda4463c}.png"><br>
<img alt="附件/{3C7D4ED4-C688-4EEA-8376-19C5F62DF2CF}.png" src="\lib\media\{3c7d4ed4-c688-4eea-8376-19c5f62df2cf}.png"><img alt="附件/{D0198C4D-B19F-4DBC-BD34-ADF9A8A6C18A}.png" src="\lib\media\{d0198c4d-b19f-4dbc-bd34-adf9a8a6c18a}.png"><br>
<img alt="附件/{4627071D-16DD-4301-9458-5FE6DDC8D896}.png" src="\lib\media\{4627071d-16dd-4301-9458-5fe6ddc8d896}.png"><br>
<img alt="附件/{29CB7630-61BC-4672-B1D5-F6F9D63D50C8}.png" src="\lib\media\{29cb7630-61bc-4672-b1d5-f6f9d63d50c8}.png"><br>
<img alt="附件/{F371DA70-1688-4B18-BE6B-046EE0944369}.png" src="\lib\media\{f371da70-1688-4b18-be6b-046ee0944369}.png"><br><br><img alt="附件/{0409CDD0-7DF1-4E88-8FB5-08DB7DF80999}.png" src="\lib\media\{0409cdd0-7df1-4e88-8fb5-08db7df80999}.png"><img alt="附件/{3F4959C5-62AC-4A86-A900-B6D1FE387DDE}.png" src="\lib\media\{3f4959c5-62ac-4a86-a900-b6d1fe387dde}.png"><br>
<img alt="附件/{67BD30B1-6D77-4E0E-B51A-054BB81A0DEE}.png" src="\lib\media\{67bd30b1-6d77-4e0e-b51a-054bb81a0dee}.png"><br>
<img alt="附件/{28FA860B-66E5-4318-A1CE-BC90E20E070F}.png" src="\lib\media\{28fa860b-66e5-4318-a1ce-bc90e20e070f}.png"><br>
<img alt="附件/{5F2672D7-58A5-4C03-AB30-9A8D9502E97D}.png" src="\lib\media\{5f2672d7-58a5-4c03-ab30-9a8d9502e97d}.png"><br>
<img alt="附件/{EEB6A7B9-BDA8-49C5-B6E3-58CB5D26D468}.png" src="\lib\media\{eeb6a7b9-bda8-49c5-b6e3-58cb5d26d468}.png"><br>
<img alt="附件/{80252163-3FFD-4188-BB12-D10A5545AC8F}.png" src="\lib\media\{80252163-3ffd-4188-bb12-d10a5545ac8f}.png"><br>
<img alt="附件/{7FA72E99-F26C-4E01-B913-1ED388CFBE50}.png" src="\lib\media\{7fa72e99-f26c-4e01-b913-1ed388cfbe50}.png"><br><br><img alt="附件/{278979CB-430B-493D-AD10-AD5CB17E4973}.png" src="\lib\media\{278979cb-430b-493d-ad10-ad5cb17e4973}.png"><br>
<img alt="附件/{D1A8C72A-FF59-4C9D-8CD4-A7E55A2BC2FC}.png" src="\lib\media\{d1a8c72a-ff59-4c9d-8cd4-a7e55a2bc2fc}.png"><br>
<img alt="附件/{C7B1631A-1DB7-4A69-B447-7A77D6675B50}.png" src="\lib\media\{c7b1631a-1db7-4a69-b447-7a77d6675b50}.png"><br><br><img alt="附件/{8BB71496-88FC-48EC-B5EE-05A11BFF73CF}.png" src="\lib\media\{8bb71496-88fc-48ec-b5ee-05a11bff73cf}.png"><br>
<img alt="附件/{0CA72ABF-B28F-4BB7-93B7-235A7A97288A}.png" src="\lib\media\{0ca72abf-b28f-4bb7-93b7-235a7a97288a}.png"><br>
<img alt="附件/{20707531-6884-48C7-A87E-D8FE773D7FDB}.png" src="\lib\media\{20707531-6884-48c7-a87e-d8fe773d7fdb}.png"><img alt="附件/{E7231A2C-D339-4F76-8E09-0889152EB726}.png" src="\lib\media\{e7231a2c-d339-4f76-8e09-0889152eb726}.png"><img alt="附件/{FF15BCC4-88E0-4BE8-A20E-8B2807A2FE1D}.png" src="\lib\media\{ff15bcc4-88e0-4be8-a20e-8b2807a2fe1d}.png"><img alt="附件/{1F03C7A5-F7F5-4F72-96A4-2AE23225797A}.png" src="\lib\media\{1f03c7a5-f7f5-4f72-96a4-2ae23225797a}.png"><img alt="附件/{E832C64C-8A7B-4C96-9CBA-B8E7F11420A0}.png" src="\lib\media\{e832c64c-8a7b-4c96-9cba-b8e7f11420a0}.png"><br>
<img alt="附件/{DFC480B6-EE2E-4F75-ADDF-19D78E0AFD18}.png" src="\lib\media\{dfc480b6-ee2e-4f75-addf-19d78e0afd18}.png"><br><img alt="附件/{6D5C69C4-834D-43F5-A2ED-B654E68C6D2A}.png" src="\lib\media\{6d5c69c4-834d-43f5-a2ed-b654e68c6d2a}.png"><br><br><img alt="附件/{EE1F79EE-D6E5-4EFD-B20D-8DD52A0FB223}.png" src="\lib\media\{ee1f79ee-d6e5-4efd-b20d-8dd52a0fb223}.png"><br><img alt="附件/{7DD59572-BA00-4CDB-8421-A871BE285CDB}.png" src="\lib\media\{7dd59572-ba00-4cdb-8421-a871be285cdb}.png"><br>
<img alt="附件/{9B080268-76C0-45BF-BBB0-DF4E57368064}.png" src="\lib\media\{9b080268-76c0-45bf-bbb0-df4e57368064}.png"><br>
<img alt="附件/{4EC7F0FF-DD95-45D2-A552-505E9C93727D}.png" src="\lib\media\{4ec7f0ff-dd95-45d2-a552-505e9c93727d}.png"><br>
<img alt="附件/{60B46DA2-85B4-454C-B7A2-3B7D93D53702}.png" src="\lib\media\{60b46da2-85b4-454c-b7a2-3b7d93d53702}.png"><br>
<img alt="附件/{4DBB7C51-FAAA-448E-BE39-50C7CE7E620B}.png" src="\lib\media\{4dbb7c51-faaa-448e-be39-50c7ce7e620b}.png"><br><br><img alt="Pasted image 20241215180038.png" src="\lib\media\pasted-image-20241215180038.png"><br><br><img alt="Pasted image 20241215181154.png" src="\lib\media\pasted-image-20241215181154.png"><br><br><img alt="Pasted image 20241215181737.png" src="\lib\media\pasted-image-20241215181737.png"><br><br><img alt="Pasted image 20241215182039.png" src="\lib\media\pasted-image-20241215182039.png"><br><br><img alt="Pasted image 20241215182733.png" src="\lib\media\pasted-image-20241215182733.png"><br>
<img alt="Pasted image 20241215183051.png" src="\lib\media\pasted-image-20241215183051.png"><br><br><img alt="Pasted image 20241215183347.png" src="\lib\media\pasted-image-20241215183347.png"><br><br><img alt="Pasted image 20241215184543.png" src="\lib\media\pasted-image-20241215184543.png"><br>
<img alt="Pasted image 20241215184615.png" src="\lib\media\pasted-image-20241215184615.png"><br><br><img alt="Pasted image 20241215190944.png" src="\lib\media\pasted-image-20241215190944.png"><br>
<img alt="Pasted image 20241215191214.png" src="\lib\media\pasted-image-20241215191214.png"><br>
<img alt="Pasted image 20241215191248.png" src="\lib\media\pasted-image-20241215191248.png"><br><br><img alt="Pasted image 20241215190123.png" src="\lib\media\pasted-image-20241215190123.png"><br><br><img alt="Pasted image 20241215190145.png" src="\lib\media\pasted-image-20241215190145.png"><br><br><img alt="Pasted image 20241215190454.png" src="\lib\media\pasted-image-20241215190454.png"><br>
<img alt="Pasted image 20241215190729.png" src="\lib\media\pasted-image-20241215190729.png"><br><br><img alt="Pasted image 20241215191021.png" src="\lib\media\pasted-image-20241215191021.png"><br><br><img alt="Pasted image 20241215191600.png" src="\lib\media\pasted-image-20241215191600.png"><br>
<img alt="Pasted image 20241215191618.png" src="\lib\media\pasted-image-20241215191618.png"><br>
<img alt="Pasted image 20241215192226.png" src="\lib\media\pasted-image-20241215192226.png"><br>
<img alt="Pasted image 20241215192449.png" src="\lib\media\pasted-image-20241215192449.png"><br><br><br><img alt="Pasted image 20241215194426.png" src="\lib\media\pasted-image-20241215194426.png"><br>
<img alt="Pasted image 20241215194535.png" src="\lib\media\pasted-image-20241215194535.png"><br>
<img alt="Pasted image 20241215194655.png" src="\lib\media\pasted-image-20241215194655.png"><br><br><img alt="Pasted image 20241215195144.png" src="\lib\media\pasted-image-20241215195144.png"><br><br><img alt="附件/{28821F13-9624-49A7-9E29-BD537C762B6D}.png" src="\lib\media\{28821f13-9624-49a7-9e29-bd537c762b6d}.png"><br><br><img alt="附件/{D667D478-A1C9-4845-8CA8-559A00DC3DE2}.png" src="\lib\media\{d667d478-a1c9-4845-8ca8-559a00dc3de2}.png"><br><img alt="附件/{188571C9-77B4-4FC4-84B5-1281295740F5}.png" src="\lib\media\{188571c9-77b4-4fc4-84b5-1281295740f5}.png"><br>
<img alt="附件/{244885FE-A522-4219-988D-93253B1A97F9}.png" src="\lib\media\{244885fe-a522-4219-988d-93253b1a97f9}.png"><br>
<img alt="附件/{D4D61376-836A-46C0-A5C4-DC6B74E5873E}.png" src="\lib\media\{d4d61376-836a-46c0-a5c4-dc6b74e5873e}.png"><br>
第六章探讨的主要是系统总线<br><br><img alt="附件/{03B5E242-00BF-4CE4-9F48-CEE09D75A016}.png" src="\lib\media\{03b5e242-00bf-4ce4-9f48-cee09d75a016}.png"><br>
<img alt="附件/{EB8BCE12-9A6E-4130-BBC7-0A07C629CBD9}.png" src="\lib\media\{eb8bce12-9a6e-4130-bbc7-0a07c629cbd9}.png"><br>
<img alt="附件/{51A4B840-0AC2-46D6-9624-8D60E7A0D456}.png" src="\lib\media\{51a4b840-0ac2-46d6-9624-8d60e7a0d456}.png"><br>
<img alt="附件/{DCE44E11-2CDC-428E-9993-BA142DD57DB1}.png" src="\lib\media\{dce44e11-2cdc-428e-9993-ba142dd57db1}.png"><br><br><img alt="附件/{7FA59372-1B2C-4D42-908B-5E7C0B89E88C}.png" src="\lib\media\{7fa59372-1b2c-4d42-908b-5e7c0b89e88c}.png"><br><br><img alt="附件/{D23DEE38-9531-446E-B646-18F313352A57}.png" src="\lib\media\{d23dee38-9531-446e-b646-18f313352a57}.png"><br>
<img alt="附件/{53886E79-DD42-4667-91B3-7BB263CE78DB}.png" src="\lib\media\{53886e79-dd42-4667-91b3-7bb263ce78db}.png"><br>
<img alt="附件/{809D4648-A6FD-4E0E-9325-9F06EDD531E3}.png" src="\lib\media\{809d4648-a6fd-4e0e-9325-9f06edd531e3}.png"><br><br><img alt="附件/{812C173A-789F-47B3-9787-0E597F41CD16}.png" src="\lib\media\{812c173a-789f-47b3-9787-0e597f41cd16}.png"><br>
<img alt="附件/{340E1C74-59A3-4988-BC04-A76D66B648EA}.png" src="\lib\media\{340e1c74-59a3-4988-bc04-a76d66b648ea}.png"><br><br><img alt="附件/{0E71B690-3EF7-4BE2-B6EB-EE9959F1F789}.png" src="\lib\media\{0e71b690-3ef7-4be2-b6eb-ee9959f1f789}.png"><br><br><img alt="附件/{FFA7FAEF-2A05-4E87-BA3A-3F08FDE1C621}.png" src="\lib\media\{ffa7faef-2a05-4e87-ba3a-3f08fde1c621}.png"><br>
<img alt="附件/{F7B179C0-4AF6-4890-A871-507C54B04A19}.png" src="\lib\media\{f7b179c0-4af6-4890-a871-507c54b04a19}.png"><br><br><img alt="附件/{1B52CE75-3891-4BBB-A0F1-8B8303356E5A}.png" src="\lib\media\{1b52ce75-3891-4bbb-a0f1-8b8303356e5a}.png"><br>
<img alt="附件/{159D4ED9-F605-46A6-B6EF-086198B603FE}.png" src="\lib\media\{159d4ed9-f605-46a6-b6ef-086198b603fe}.png"><img alt="附件/{159D4ED9-F605-46A6-B6EF-086198B603FE} 1.png" src="\lib\media\{159d4ed9-f605-46a6-b6ef-086198b603fe}-1.png"><br><br><img alt="附件/{10EADDC6-E8A8-444B-9F2E-AA9ADCCBFFA7}.png" src="\lib\media\{10eaddc6-e8a8-444b-9f2e-aa9adccbffa7}.png"><br><br><img alt="附件/{453669BC-57F8-47B6-BD82-3A86FD426FF1}.png" src="\lib\media\{453669bc-57f8-47b6-bd82-3a86fd426ff1}.png"><br><br><img alt="附件/{2BF4529A-3EE5-497B-A603-32F340BBB3D1}.png" src="\lib\media\{2bf4529a-3ee5-497b-a603-32f340bbb3d1}.png"><br><br><br><br><img alt="附件/{142B285C-74AD-4A20-906D-F5F41989F875}.png" src="\lib\media\{142b285c-74ad-4a20-906d-f5f41989f875}.png"><br><br><img alt="附件/{3AFFEE40-7B22-43E8-B797-CD359EF0C6EC}.png" src="\lib\media\{3affee40-7b22-43e8-b797-cd359ef0c6ec}.png"><br>
<img alt="附件/{732B868F-6219-434E-B44E-EFE6C4121FB7}.png" src="\lib\media\{732b868f-6219-434e-b44e-efe6c4121fb7}.png"><br><br><img alt="附件/{F7875674-7EF1-4F58-B27B-D481C2368E73}.png" src="\lib\media\{f7875674-7ef1-4f58-b27b-d481c2368e73}.png"><br>
<img alt="附件/{8A0A116C-03B2-457A-A219-7DE15130911C}.png" src="\lib\media\{8a0a116c-03b2-457a-a219-7de15130911c}.png"><br><br><img alt="附件/{7CEEDD02-CA6B-41B9-B84F-84324181B535}.png" src="\lib\media\{7ceedd02-ca6b-41b9-b84f-84324181b535}.png"><img alt="附件/{7CEEDD02-CA6B-41B9-B84F-84324181B535} 1.png" src="\lib\media\{7ceedd02-ca6b-41b9-b84f-84324181b535}-1.png"><br>
<img alt="附件/{00B9A524-7BDD-4BE5-8AF6-3BFB5EAF816E}.png" src="\lib\media\{00b9a524-7bdd-4be5-8af6-3bfb5eaf816e}.png"><br><br><img alt="附件/{2FF0355F-20E4-4893-9444-43E19D7E7F80}.png" src="\lib\media\{2ff0355f-20e4-4893-9444-43e19d7e7f80}.png"><br><br><img alt="附件/{903837C7-FF81-4DC6-BC63-14FC4F405A93}.png" src="\lib\media\{903837c7-ff81-4dc6-bc63-14fc4f405a93}.png"><br><br><img alt="附件/{3150AAA7-667D-412F-BDF4-576B31C3E598}.png" src="\lib\media\{3150aaa7-667d-412f-bdf4-576b31c3e598}.png"><img alt="附件/{3D4E344E-AD6D-4874-9087-97AE25C2A1E3}.png" src="\lib\media\{3d4e344e-ad6d-4874-9087-97ae25c2a1e3}.png"><br><br><img alt="附件/{DCE3D0DC-034A-4DA5-9655-B66621EE2062}.png" src="\lib\media\{dce3d0dc-034a-4da5-9655-b66621ee2062}.png"><img alt="附件/{C35D5B88-539E-4E37-BE05-C1F2C59270EF}.png" src="\lib\media\{c35d5b88-539e-4e37-be05-c1f2c59270ef}.png"><br>
<img alt="附件/{F5454944-8436-4ED2-BD3E-58D0482D5D21}.png" src="\lib\media\{f5454944-8436-4ed2-bd3e-58d0482d5d21}.png"><br>
<img alt="附件/{6BA54A2D-EA11-4148-BD3C-B6D758FD5B3A}.png" src="\lib\media\{6ba54a2d-ea11-4148-bd3c-b6d758fd5b3a}.png"><br><br><img alt="附件/{3387C81E-F618-491F-AA9D-122D94892A2C}.png" src="\lib\media\{3387c81e-f618-491f-aa9d-122d94892a2c}.png"><br>
<img alt="附件/{5DAB8BB0-14DE-4FC2-8501-AC572573E4EF}.png" src="\lib\media\{5dab8bb0-14de-4fc2-8501-ac572573e4ef}.png"><br><br><img alt="附件/{A6D46A06-1059-4346-8DA5-EA6A2D45006E}.png" src="\lib\media\{a6d46a06-1059-4346-8da5-ea6a2d45006e}.png"><br><br><br><img alt="附件/{5515D9B1-E411-4C5A-8176-F15FC5BCBB59}.png" src="\lib\media\{5515d9b1-e411-4c5a-8176-f15fc5bcbb59}.png"><br><br><img alt="附件/{9E36C1B6-CF98-4BED-B662-FC82804C7252}.png" src="\lib\media\{9e36c1b6-cf98-4bed-b662-fc82804c7252}.png"><br>
<img alt="附件/{1D19A658-682A-4497-8BF7-F0DB6B7BF4D8}.png" src="\lib\media\{1d19a658-682a-4497-8bf7-f0db6b7bf4d8}.png"><br><br><img alt="附件/{BE3D652D-B42F-4A1C-A4D6-85591D9044BE}.png" src="\lib\media\{be3d652d-b42f-4a1c-a4d6-85591d9044be}.png"><br><br><img alt="附件/{046BDE84-3C61-499B-BE94-F880B5F5A13A}.png" src="\lib\media\{046bde84-3c61-499b-be94-f880b5f5a13a}.png"><br><br><img alt="附件/{A43ECB1D-E739-4770-9875-9060E482ED49}.png" src="\lib\media\{a43ecb1d-e739-4770-9875-9060e482ed49}.png"><br><img alt="附件/{5C1A1F32-DC11-4E15-9081-C5E3031305AF}.png" src="\lib\media\{5c1a1f32-dc11-4e15-9081-c5e3031305af}.png"><br>
<img alt="附件/{77A7AE63-D3B1-4040-A22E-B8DD523381D3}.png" src="\lib\media\{77a7ae63-d3b1-4040-a22e-b8dd523381d3}.png"><br><br><img alt="附件/{1713FF71-33DA-4478-8629-6E68DB792152}.png" src="\lib\media\{1713ff71-33da-4478-8629-6e68db792152}.png"><br><br><img alt="附件/{DC7C9E7A-4C91-4AEB-8E83-AA69C6EBBF08}.png" src="\lib\media\{dc7c9e7a-4c91-4aeb-8e83-aa69c6ebbf08}.png"><br><br><img alt="Pasted image 20241216181703.png" src="\lib\media\pasted-image-20241216181703.png"><br><img alt="Pasted image 20241216182808.png" src="\lib\media\pasted-image-20241216182808.png"><br>
<img alt="Pasted image 20241216182939.png" src="\lib\media\pasted-image-20241216182939.png"><br>
<img alt="Pasted image 20241216184620.png" src="\lib\media\pasted-image-20241216184620.png"><br>
<img alt="Pasted image 20241216184727.png" src="\lib\media\pasted-image-20241216184727.png"><br><br><img alt="Pasted image 20241216184810.png" src="\lib\media\pasted-image-20241216184810.png"><br><img alt="Pasted image 20241216204731.png" src="\lib\media\pasted-image-20241216204731.png"><br><br><img alt="Pasted image 20241216190457.png" src="\lib\media\pasted-image-20241216190457.png"><br><br><img alt="Pasted image 20241216204812.png" src="\lib\media\pasted-image-20241216204812.png"><br>
<img alt="Pasted image 20241216204836.png" src="\lib\media\pasted-image-20241216204836.png"><br>
<img alt="Pasted image 20241216205156.png" src="\lib\media\pasted-image-20241216205156.png"><br><img alt="Pasted image 20241216205432.png" src="\lib\media\pasted-image-20241216205432.png"><br><br><img alt="Pasted image 20241216205721.png" src="\lib\media\pasted-image-20241216205721.png"><br>
关于中断隐指令：<br>
问题一：PC的值如何保存，保存在什么地方？<br>
问题二：应该如何找到对应的中断服务程序的入口地址？<br>
<img alt="Pasted image 20241216210015.png" src="\lib\media\pasted-image-20241216210015.png"><br>
<img alt="Pasted image 20241216210528.png" src="\lib\media\pasted-image-20241216210528.png"><br>
为什么要间接寻址呢？<br>
因为为了保证中断服务程序的可变性。以此可以引申，所有的需要保证程序可变性的寻址方式都可以使用间接寻址保证后期的维护方便。<br><img alt="Pasted image 20241216211056.png" src="\lib\media\pasted-image-20241216211056.png"><br><img alt="Pasted image 20241216211438.png" src="\lib\media\pasted-image-20241216211438.png"><br><br><img alt="Pasted image 20241216211548.png" src="\lib\media\pasted-image-20241216211548.png"><br>
<img alt="Pasted image 20241216211718.png" src="\lib\media\pasted-image-20241216211718.png"><br>
<img alt="Pasted image 20241216212151.png" src="\lib\media\pasted-image-20241216212151.png"><br>
<img alt="Pasted image 20241216212301.png" src="\lib\media\pasted-image-20241216212301.png"><br>
<img alt="Pasted image 20241216212611.png" src="\lib\media\pasted-image-20241216212611.png"><br>
<img alt="Pasted image 20241216212854.png" src="\lib\media\pasted-image-20241216212854.png"><br><br><img alt="Pasted image 20241216213134.png" src="\lib\media\pasted-image-20241216213134.png"><br>
<img alt="Pasted image 20241216213345.png" src="\lib\media\pasted-image-20241216213345.png"><br><br><img alt="Pasted image 20241216213013.png" src="\lib\media\pasted-image-20241216213013.png"><br><br><img alt="Pasted image 20241216214121.png" src="\lib\media\pasted-image-20241216214121.png"><br>
<img alt="Pasted image 20241216215512.png" src="\lib\media\pasted-image-20241216215512.png"><br>
<img alt="Pasted image 20241216215530.png" src="\lib\media\pasted-image-20241216215530.png"><br><br><img alt="Pasted image 20241216215625.png" src="\lib\media\pasted-image-20241216215625.png"><br><img alt="Pasted image 20241216220154.png" src="\lib\media\pasted-image-20241216220154.png"><br><br><img alt="Pasted image 20241216220509.png" src="\lib\media\pasted-image-20241216220509.png"><br>
<img alt="Pasted image 20241216220758.png" src="\lib\media\pasted-image-20241216220758.png"><br><img alt="Pasted image 20241216220950.png" src="\lib\media\pasted-image-20241216220950.png"><br>如果采用三总线结构，会产生CPU与DMA对主存的访问冲突<br>
如何解决？<br><br><img alt="Pasted image 20241216221213.png" src="\lib\media\pasted-image-20241216221213.png"><br><br><img alt="Pasted image 20241216221231.png" src="\lib\media\pasted-image-20241216221231.png"><br><br><img alt="Pasted image 20241216221452.png" src="\lib\media\pasted-image-20241216221452.png"><br><br><img alt="Pasted image 20241216221525.png" src="\lib\media\pasted-image-20241216221525.png">]]></description><link>technology\collegeproject\计算机组成原理\王道计算机组成原理笔记.html</link><guid isPermaLink="false">Technology/CollegeProject/计算机组成原理/王道计算机组成原理笔记.md</guid><pubDate>Mon, 16 Dec 2024 14:51:37 GMT</pubDate><enclosure url="lib\media\{5365bcab-9d08-4f91-89c7-41f9d1e7a12f}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{5365bcab-9d08-4f91-89c7-41f9d1e7a12f}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数电元件整理]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具</a> 
 <br><a href=".?query=tag:科技\工具" class="tag" target="_blank" rel="noopener nofollow">#科技/工具</a> ]]></description><link>technology\collegeproject\数电\数电元件整理.html</link><guid isPermaLink="false">Technology/CollegeProject/数电/数电元件整理.md</guid><pubDate>Tue, 16 Jan 2024 03:18:08 GMT</pubDate></item><item><title><![CDATA[基本语法看：<a data-href="Verilog HDL语言" href="technology/collegeproject/数电/verilog-hdl语言.html" class="internal-link" target="_self" rel="noopener nofollow">Verilog HDL语言</a>]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具</a> 
 <br><a href=".?query=tag:科技\工具" class="tag" target="_blank" rel="noopener nofollow">#科技/工具</a> <br><br><br>书p518,1.3开始有介绍<br>
<a data-tooltip-position="top" aria-label="https://blog.csdn.net/qq_45445505/article/details/117195919" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/qq_45445505/article/details/117195919" target="_blank">EDA初学，新建工程，Quartus软件应用_eda仿真的复位信号怎么设置-CSDN博客</a>]]></description><link>technology\collegeproject\数电\eda电路仿真.html</link><guid isPermaLink="false">Technology/CollegeProject/数电/EDA电路仿真.md</guid><pubDate>Thu, 21 Dec 2023 10:02:03 GMT</pubDate></item><item><title><![CDATA[基本语法规则]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具</a> 
 <br><a href=".?query=tag:科技\工具" class="tag" target="_blank" rel="noopener nofollow">#科技/工具</a> <br><br>
<br>
间隔符:&nbsp; Verilog 的间隔符主要起分隔文本的作用，可以使文本错落有致，便于阅读与修改。间隔符包括空格符（\b）、TAB 键（\t）、换行符（\n）及换页符。

<br>
注释与C语言一致。

<br>
逻辑值集合<br>
<img alt="Pasted image 20231126161636.png" src="\lib\media\pasted-image-20231126161636.png"> 

<br>
常量表示<br>
<img alt="Pasted image 20231126162054.png" src="\lib\media\pasted-image-20231126162054.png">

<br>
变量<br>
<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/72012739#:~:text=wire%E6%98%AFwire%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E7%A1%AE%E8%AE%A4%E7%AC%A6%EF%BC%8C%20%5Bn-1%3A0%5D%E5%92%8C,%5Bn%3A1%5D%E4%BB%A3%E8%A1%A8%E8%AF%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E4%BD%8D%E5%AE%BD%20%EF%BC%8C%E5%8D%B3%E8%AF%A5%E6%95%B0%E6%8D%AE%E6%9C%89%E5%87%A0%E4%BD%8D%E3%80%82" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/72012739#:~:text=wire%E6%98%AFwire%E5%9E%8B%E6%95%B0%E6%8D%AE%E7%9A%84%E7%A1%AE%E8%AE%A4%E7%AC%A6%EF%BC%8C%20%5Bn-1%3A0%5D%E5%92%8C,%5Bn%3A1%5D%E4%BB%A3%E8%A1%A8%E8%AF%A5%E6%95%B0%E6%8D%AE%E7%9A%84%E4%BD%8D%E5%AE%BD%20%EF%BC%8C%E5%8D%B3%E8%AF%A5%E6%95%B0%E6%8D%AE%E6%9C%89%E5%87%A0%E4%BD%8D%E3%80%82" target="_blank">Verilog语法之三：变量 - 知乎 (zhihu.com)</a>

<br>
线网类型wire，指输出始终根据输入变化而更新的变量。<br>
<img alt="Pasted image 20231126162334.png" src="\lib\media\pasted-image-20231126162334.png"><br>
wire a; //定义了一个一位的wire型数据<br>
wire[4:1]b; //定义了一个八位的wire型数据<br>
wire [4:1] c, d; //定义了二个四位的wire型数据

<br>
寄存器类型reg、integer、real、time。寄存器变量对应的是具有状态保持作用的电路元件等，如触发器。注：寄存器变量只能在initial或者always内部被赋值。<br>
<img alt="Pasted image 20231126164406.png" src="\lib\media\pasted-image-20231126164406.png">
always可以认为是一个时序循环，它的循环条件在括号中，一般为时序条件，如某个时序变量clock的上升沿或者下降沿。它是可以并行的，即多个always并行。这与if else不同。

<br>
寄存器型数据与线网型数据的区别在于：寄存器型数据保持最后一次的赋值，而连线型数据需要有持续的驱动。寄存器型数据的驱动可以通过过程赋值语句实现，过程赋值语句只能出现在过程语句后面的过程块语句中。<br>
<img alt="Pasted image 20231126164650.png" src="\lib\media\pasted-image-20231126164650.png">

<br>
wire用法总结



<br>
wire可以在Verilog中表示任意宽度的单线/总线

<br>
wire可以用于模块的输入和输出端口以及一些其他元素并在实际模块声明中

<br>
wire不能存储值（无状态），并且不能在always @块内赋值（=或&lt;=）左侧使用。

<br>
wire是assign语句左侧唯一的合法类型

<br>
wire只能用于组合逻辑



<br>reg用法总结


<br>
类似于电线，但可以存储信息（有内存，有状态）允许连接到模块的输入端口，但不能连接到实例化的输出

<br>
在模块声明中，reg可以用作输出，但不能用作输入

<br>
在always@(......)语句块内，= 或者 &lt;= 赋值语句的左边必须是是reg变量，在initial语句块内，= 赋值语句的左边必须是是reg变量

<br>
Reg不能用于assign赋值语句的左侧

<br>
当与@（posedge clock）块一起使用时，reg可用于创建寄存器

<br>
reg可用于组合逻辑和时序逻辑



<br>
运算符<br>
<img alt="Pasted image 20231127182409.png" src="\lib\media\pasted-image-20231127182409.png"><br>
缩位运算符：包括&amp;(与缩位)、~&amp;(与非缩位)、|(或缩位)、~|(或非缩位)、^~或~^(同或缩位)5种。位运算和缩位运算虽然运算符相同,但是运算过程不同。位运算的操作数有两个,操作数是几位,运算结果也是几位。而缩位运算只有一个操作数,运算时对一个操作数由左向右进行运算,运算结果为1位。

<br>
优先级<br>
<img alt="Pasted image 20231127182516.png" src="\lib\media\pasted-image-20231127182516.png">

<br>
门元件<br>
<img alt="Pasted image 20231127183214.png" src="\lib\media\pasted-image-20231127183214.png">

<br><br>模块是Verilog描述电路的基本单元。对数字电路建模时，用一个或多个模块。不同模块之间通过端口进行连接。<br>
<br>每个模块先要进行端口的定义，并说明输入(input)和输出(output),然后对模块功能进行描述。
<br>除了endmodule语句外，每个语句后必须有分号。
<br>一般语法结构：<br>
<img alt="Pasted image 20231127183532.png" src="\lib\media\pasted-image-20231127183532.png">
<br>门电路描述法<br>
<img alt="Pasted image 20231127184637.png" src="\lib\media\pasted-image-20231127184637.png">
<br>assign描述法<br>
<img alt="Pasted image 20231127184710.png" src="\lib\media\pasted-image-20231127184710.png"><br>
即直接写出逻辑表达式。
<br>行为描述方式<br>
<img alt="Pasted image 20231127185127.png" src="\lib\media\pasted-image-20231127185127.png"><br>
即在已经推理出电路作用后，通过if else等逻辑词表示出电路功能。<br>
其中always @(S or D0 or D1)表示在S或者D0或者D1中有任何一个输入即做一次循环。
]]></description><link>technology\collegeproject\数电\verilog-hdl语言.html</link><guid isPermaLink="false">Technology/CollegeProject/数电/Verilog HDL语言.md</guid><pubDate>Fri, 01 Dec 2023 11:55:02 GMT</pubDate><enclosure url="lib\media\pasted-image-20231126161636.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20231126161636.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[介绍]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a><br><a data-tooltip-position="top" aria-label="https://mp.weixin.qq.com/s/gUwLfi25TYamq8AJVIopfA" rel="noopener nofollow" class="external-link" href="https://mp.weixin.qq.com/s/gUwLfi25TYamq8AJVIopfA" target="_blank">Union-Find 并查集算法详解 (qq.com)</a><br><br>现在我们的 Union-Find 算法主要需要实现这两个 API：  <br>class UF {  
    /* 将 p 和 q 连接 */  
    public void union(int p, int q);  
    /* 判断 p 和 q 是否连通 */  
    public boolean connected(int p, int q);  
    /* 返回图中有多少个连通分量 */  
    public int count();  
}

<br>这里所说的「连通」是一种等价关系，也就是说具有如下三个性质：<br>1、自反性：节点p和p是连通的。<br>2、对称性：如果节点p和q连通，那么q和p也连通。<br>3、传递性：如果节点p和q连通，q和r连通，那么p和r也连通。<br>比如说之前那幅图，0～9 任意两个不同的点都不连通，调用connected都会返回 false，连通分量为 10 个。<br>如果现在调用union(0, 1)，那么 0 和 1 被连通，连通分量降为 9 个。<br>再调用union(1, 2)，这时 0,1,2 都被连通，调用connected(0, 2)也会返回 true，连通分量变为 8 个。<br><img alt="图片" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gibkIz0MVqdHbnHaPibsAQHPibgTF6OUYzMCbWLeLia7gepcenJbcSqQjf7pCqRibiamBtdQUWpUwMQaRclwlVPX0Kwg/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" referrerpolicy="no-referrer"><br>判断这种「等价关系」非常实用，比如说编译器判断同一个变量的不同引用，比如社交网络中的朋友圈计算等等。  <br>这样，你应该大概明白什么是动态连通性了，Union-Find 算法的关键就在于union和connected函数的效率。那么用什么模型来表示这幅图的连通状态呢？用什么数据结构来实现代码呢？<br><br>注意我刚才把「模型」和具体的「数据结构」分开说，这么做是有原因的。因为我们使用森林（若干棵树）来表示图的动态连通性，用数组来具体实现这个森林。<br>怎么用森林来表示连通性呢？我们设定树的每个节点有一个指针指向其父节点，如果是根节点的话，这个指针指向自己。<br>比如说刚才那幅 10 个节点的图，一开始的时候没有相互连通，就是这样：<br>class UF {  
    // 记录连通分量  
    private int count;  
    // 节点 x 的节点是 parent[x]  
    private int[] parent;  
  
    /* 构造函数，n 为图的节点总数 */  
    public UF(int n) {  
        // 一开始互不连通  
        this.count = n;  
        // 父节点指针初始指向自己  
        parent = new int[n];  
        for (int i = 0; i &lt; n; i++)  
            parent[i] = i;  
    }  
  
    /* 其他函数 */  
}
<br><img alt="图片" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gibkIz0MVqdHbnHaPibsAQHPibgTF6OUYzM9eKbTGLMLZrFoEXKvia6YYBNM86r5WUruKPlHrrJzD03G1RibWMibWGxw/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" referrerpolicy="no-referrer"><br>如果某两个节点被连通，则让其中的（任意）一个节点的根节点接到另一个节点的根节点上：<br>public void union(int p, int q) {  
    int rootP = find(p);  
    int rootQ = find(q);  
    if (rootP == rootQ)  
        return;  
    // 将两棵树合并为一棵  
    parent[rootP] = rootQ;  
    // parent[rootQ] = rootP 也一样  
    count--; // 两个分量合二为一  
}  
  
/* 返回某个节点 x 的根节点 */  
private int find(int x) {  
    // 根节点的 parent[x] == x  
    while (parent[x] != x)  
        x = parent[x];  
    return x;  
}  
  
/* 返回当前的连通分量个数 */  
public int count() {   
    return count;  
}
<br><img alt="图片" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gibkIz0MVqdHbnHaPibsAQHPibgTF6OUYzMC5nGrbBiaau4Lp9vgf8uYXWJqb2oqoeyKGIicNskUsIsQ9G2Ex1drpTw/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" referrerpolicy="no-referrer"><br>这样，如果节点p和q连通的话，它们一定拥有相同的根节点：<br>public boolean connected(int p, int q) {  
    int rootP = find(p);  
    int rootQ = find(q);  
    return rootP == rootQ;  
}
<br>那么这个算法的复杂度是多少呢？我们发现，主要 APIconnected和union中的复杂度都是find函数造成的，所以说它们的复杂度和find一样。<br>find主要功能就是从某个节点向上遍历到树根，其时间复杂度就是树的高度。我们可能习惯性地认为树的高度就是logN，但这并不一定。logN的高度只存在于平衡二叉树，对于一般的树可能出现极端不平衡的情况，使得「树」几乎退化成「链表」，树的高度最坏情况下可能变成N。<br><img alt="图片" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gibkIz0MVqdHbnHaPibsAQHPibgTF6OUYzMk8VCNRmTgQpV7xRobklibXTSaNn43OzVFpXfJzsaaDwLFWVkOkePhlA/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" referrerpolicy="no-referrer"><br>所以说上面这种解法，find,union,connected的时间复杂度都是 O(N)。这个复杂度很不理想的，你想图论解决的都是诸如社交网络这样数据规模巨大的问题，对于union和connected的调用非常频繁，每次调用需要线性时间完全不可忍受。  <br>问题的关键在于，如何想办法避免树的不平衡呢？只需要略施小计即可。<br><br>我们要知道哪种情况下可能出现不平衡现象，关键在于union过程：<br>public void union(int p, int q) {  
    int rootP = find(p);  
    int rootQ = find(q);  
    if (rootP == rootQ)  
        return;  
    // 将两棵树合并为一棵  
    parent[rootP] = rootQ;  
    // parent[rootQ] = rootP 也可以  
    count--;
<br>我们一开始就是简单粗暴的把p所在的树接到q所在的树的根节点下面，那么这里就可能出现「头重脚轻」的不平衡状况，比如下面这种局面：<br><img alt="图片" src="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gibkIz0MVqdHbnHaPibsAQHPibgTF6OUYzMEoaSbJlKUa0kHcvOLWvGsWtcFSgTULsiaXicib31fMnk6ic5dP16sq92tA/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" referrerpolicy="no-referrer"><br>长此以往，树可能生长得很不平衡。我们其实是希望，小一些的树接到大一些的树下面，这样就能避免头重脚轻，更平衡一些。解决方法是额外使用一个size数组，记录每棵树包含的节点数，我们不妨称为「重量」：  <br>class UF {  
    private int count;  
    private int[] parent;  
    // 新增一个数组记录树的“重量”  
    private int[] size;  
  
    public UF(int n) {  
        this.count = n;  
        parent = new int[n];  
        // 最初每棵树只有一个节点  
        // 重量应该初始化 1  
        size = new int[n];  
        for (int i = 0; i &lt; n; i++) {  
            parent[i] = i;  
            size[i] = 1;  
        }  
    }  
    /* 其他函数 */  
}
<br>比如说size[3] = 5表示，以节点3为根的那棵树，总共有5个节点。这样我们可以修改一下union方法：<br>public void union(int p, int q) {  
    int rootP = find(p);  
    int rootQ = find(q);  
    if (rootP == rootQ)  
        return;  
  
    // 小树接到大树下面，较平衡  
    if (size[rootP] &gt; size[rootQ]) {  
        parent[rootQ] = rootP;  
        size[rootP] += size[rootQ];  
    } else {  
        parent[rootP] = rootQ;  
        size[rootQ] += size[rootP];  
    }  
    count--;  
}

<br>这样，通过比较树的重量，就可以保证树的生长相对平衡，树的高度大致在logN这个数量级，极大提升执行效率。<br>此时，find,union,connected的时间复杂度都下降为 O(logN)，即便数据规模上亿，所需时间也非常少。]]></description><link>technology\collegeproject\数据结构\其他算法\并查集算法.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/其他算法/并查集算法.md</guid><pubDate>Sun, 17 Mar 2024 07:10:18 GMT</pubDate><enclosure url="https://mmbiz.qpic.cn/sz_mmbiz_jpg/gibkIz0MVqdHbnHaPibsAQHPibgTF6OUYzMCbWLeLia7gepcenJbcSqQjf7pCqRibiamBtdQUWpUwMQaRclwlVPX0Kwg/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1" length="0" type="false"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://mmbiz.qpic.cn/sz_mmbiz_jpg/gibkIz0MVqdHbnHaPibsAQHPibgTF6OUYzMCbWLeLia7gepcenJbcSqQjf7pCqRibiamBtdQUWpUwMQaRclwlVPX0Kwg/640?wx_fmt=jpeg&amp;wxfrom=5&amp;wx_lazy=1&amp;wx_co=1&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[逆序对个数（归并排序）]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a><br>int countInversions(vector&lt;int&gt;&amp;A,int l,int r){  
    int mid=(r+l)/2;  
    int n1=mid-l+1;  
    int n2=r-mid;  
    vector&lt;int&gt;L(n1);  
    vector&lt;int&gt;R(n2);  
    for (int i = 0; i &lt; n1; i++)  
        L[i] = A[l + i];  
    for (int j = 0; j &lt; n2; j++)  
        R[j] = A[mid + 1 + j];  
    int count=0;  
    int i = 0, j = 0, k = l;  
    while (i &lt; n1 &amp;&amp; j &lt; n2) {  
        if (L[i] &lt;= R[j]) {  
            A[k++] = L[i++];  
        }         else {  
            A[k++] = R[j++];  
            count += (mid - i + 1); // 关键：统计逆序对的数量,即从此刻的i开始到左序列结束都为逆序  
        }  
    }  
    while (i &lt; n1) A[k++] = L[i++];  
    while (j &lt; n2) A[k++] = R[j++];  
    return count;  
}  
int MergesortAndCount(vector&lt;int&gt;A,int left,int right){  
    int count=0;  
    if(left&lt;right){  
        int mid = left + (right - left) / 2;//防止溢出  
        count += MergeSortAndCount(A, left, mid);//左序列逆序数  
        count += MergeSortAndCount(A, mid + 1, right);//右序列逆序数  
        count += countInversions(A, left,right);//左右之间逆序数  
    }  
    return count;  
}
<br>假设两个有序对<br>
1 5 6 7   ||   2 3 4 5<br>
检查1和2<br>
将1放入<br>
检查5和2，将2放入的同时，表明第一个序列从5开始后面的与2都为逆序，所以加上<br>
mid-i+1]]></description><link>technology\collegeproject\数据结构\其他算法\逆序对个数（归并排序）.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/其他算法/逆序对个数（归并排序）.md</guid><pubDate>Sun, 17 Mar 2024 07:10:22 GMT</pubDate></item><item><title><![CDATA[平衡二叉树]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a><br><a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/343216590" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/343216590" target="_blank">平衡二叉树 通俗易懂 - 知乎 (zhihu.com)</a>]]></description><link>technology\collegeproject\数据结构\其他算法\平衡二叉树.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/其他算法/平衡二叉树.md</guid><pubDate>Sun, 17 Mar 2024 07:10:24 GMT</pubDate></item><item><title><![CDATA[Dijkstra算法]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a> <br>基本思想：每次从 「未求出最短路径的点」中&nbsp;取出&nbsp;距离起点&nbsp;最小路径的点，以这个点为桥梁&nbsp;刷新「未求出最短路径的点」的距离。<br>
参考：<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/454373256" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/454373256" target="_blank">【看完必懂】Dijkstra算法（附案例详解） - 知乎 (zhihu.com)</a><br>
主要步骤：<br>
<br>建立集合S，我们的最短路径算法就是不断往S中添加新的元素。初始先将起始点放入S.
<br>初始化dist数组，按照起点的边集初始化。
<br>主循环中，第一部分是找到dist数组中最小值，这个最小值代表了已经确定的最短路径集S，这里可以理解成一个割到另一个割中最短的交叉边。这个交叉边代表，这是一条局部最短边，是起点到这个点的最短路径的最后一部分。
<br>找到最小值之后，我们将这个点加入S，并更新dist数组，数组的更新关键在于一行代码edges[imin][i]+dist[imin]&lt;dist[i].即判断新加入节点的边集与S中dist该点的距离之和与原来这个点的dist哪个大。<br>
我的代码（未调试）：
<br>void dijkstra(int v,int u){  
        vector&lt;int&gt;dist;  
        dist.resize(vexnum);  
        vector&lt;int&gt;S;//集合S  
        S.push_back(v);  
        for(int i=0;i&lt;vexnum;i++){  
            dist[i]=edges[v][i];  
        }  
        vector&lt;int&gt;path;  
        path.resize(vexnum);  
        int tmp=v;  
        while(int(S.size())&lt;vexnum){  
            int min=INFINITY;  
            int imin=-1;  
            for(int i=0;i&lt;vexnum;i++){  
                if(dist[i]&lt;min){  
                    min=dist[i];  
                    imin=i;  
                }             }//找最短边  
            S.push_back(imin);  
            path[imin]=tmp;  
            tmp=imin;  
            for(int i=0;i&lt;vexnum;i++){  
                if(edges[imin][i]+dist[imin]&lt;dist[i]){  
                    dist[i]=edges[imin][i]+dist[imin];  
                }  
            }//更新dist数组  
        }  
        stack&lt;int&gt;Path;  
        Path.push(u);  
        int i=u;  
        while(path[i]!=v){  
            Path.push(path[i]);  
            i=path[i];  
        }//回溯最短路径  
        cout&lt;&lt;v;  
        while(!Path.empty()){  
            cout&lt;&lt;"-&gt;"&lt;&lt;Path.top();  
            Path.pop();  
        }  
    }
]]></description><link>technology\collegeproject\数据结构\最短路径算法\dijkstra算法.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/最短路径算法/Dijkstra算法.md</guid><pubDate>Sun, 17 Mar 2024 07:10:11 GMT</pubDate></item><item><title><![CDATA[Floyd算法]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a> <br><a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/87480486" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/87480486" target="_blank">短小精悍的多源最短路径算法—Floyd算法 - 知乎 (zhihu.com)</a>在图论中，在寻路最短路径中除了Dijkstra算法以外，还有Floyd算法也是非常经典，然而两种算法还是有区别的，Floyd主要计算多源最短路径。<br>在单源正权值最短路径，我们会用<a data-href="Dijkstra算法" href="\technology\collegeproject\数据结构\最短路径算法\dijkstra算法.html" class="internal-link" target="_self" rel="noopener nofollow">Dijkstra算法</a>来求最短路径，并且算法的思想很简单——贪心算法:每次确定最短路径的一个点然后维护(更新)这个点周围点的距离加入预选队列，等待下一次的抛出确定。但是虽然思想很简单，实现起来是非常复杂的，我们需要邻接矩阵(表)储存长度，需要优先队列(或者每次都比较)维护一个预选点的集合。还要用一个boolean数组标记是否已经确定、还要---------<br>总之，Dijkstra算法的思想上是很容易接受的，但是实现上其实是非常麻烦的。但是单源最短路径没有更好的办法。复杂度也为O(n2)<br>而在n节点多源最短路径中,如果从Dijkstra算法的角度上，只需要将Dijkstra封装，然后执行n次Dijkstra算法即可,复杂度为O(n3)。但是这样感觉很臃肿，代码量巨大，占用很多空间内存。有没有啥方法能够稍微变变口味呢？<br>答案是有的，这就是易写但稍需要理解的Floyd算法。一个求多元最短路径算法。<br>而算法的具体思想为：<br>
<br>邻接矩阵dist储存路径，同时最终状态代表点点的最短路径。如果没有直接相连的两点那么默认为一个很大的值(不要溢出)！而自己的长度为0.
<br>从第1个到第n个点依次加入图中。每个点加入进行试探是否有路径长度被更改。
<br>而上述试探具体方法为遍历图中每一个点(i,j双重循环)，判断每一个点对距离是否因为加入的点而发生最小距离变化。如果发生改变，那么两点(i,j)距离就更改。
<br>重复上述直到最后插点试探完成。
<br>其中第三步的状态转移方程为:<br>
<br>dp[i][j]=min(dp[i][j],dp[i][k]+dp[k][j])<br>
其中dp[x][y]的意思可以理解为x到y的最短路径。所以dp[i][k]的意思可以理解为i到k的最短路径dp[k][j]的意思可以理解为k到j的最短路径.
<br>咱们图解一个案例：<br>
<img alt="Pasted image 20231211110124.png" src="\lib\media\pasted-image-20231211110124.png"><br>
默认的最短长度初始为邻接矩阵初始状态<br>
<br>加入第一个节点1,大家可以发现，由于1的加入，使得本来不连通的2，3点对和2，4点对变得联通，并且加入1后距离为当前最小。(可以很直观加入5之后2，4，更短但是还没加入)。为了更好的描述其实此时的直接联通点多了两条。(2,3)和(2,4).我们在dp中不管这个结果是通过前面那些步骤来的，但是在这个状态，这两点的最短距离就算它<img alt="Pasted image 20231211110247.png" src="\lib\media\pasted-image-20231211110247.png">
<br>

<br>同时你可以发现加入1其中也使得3,1,4这样联通，但是&nbsp;3,1,4联通的话距离为9远远大于本来的(3,4)为2，所以不进行更新。


<br>咱们继续加入第二个节点。在加入的初始态为：<img alt="Pasted image 20231211110347.png" src="\lib\media\pasted-image-20231211110347.png">
<br>进行遍历插入看看是否更新节点<img alt="Pasted image 20231211110425.png" src="\lib\media\pasted-image-20231211110425.png">
<br>实际上这个时候图中的连线就比较多了。当然这些连线都是代表当前的最短路径。&nbsp;这也和我们的需求贴合，我们最终要的是所有节点的最短路径。每个节点最终都应该有6条指向不同节点的边！&nbsp;表示邻接矩阵的最终结果。
<br>至于算法的模拟两部核心已经告诉大家了，大家可以自行模拟剩下的<br>我的代码（未调试）：<br>void Floyd(){  
        int dp[vexnum][vexnum];  
        int path[vexnum][vexnum];  
        for(int i=0;i&lt;vexnum;i++){  
            for(int j=0;j&lt;vexnum;j++){  
                dp[i][j]=edges[i][j];  
                if(dp[i][j]&lt;INFINITY){  
                    path[i][j]=j;  
                }  
                else path[i][j]=-1;  
            }  
        }  
        for(int i=0;i&lt;vexnum;i++){  
            for(int j=0;j&lt;=vexnum;j++){  
                if(i!=j){  
                    for(int k=0;k&lt;vexnum;k++){  
                        dp[j][k]=min(dp[j][k],dp[j][i]+dp[i][k]);  
                        if(dp[j][k]&gt;dp[j][i]+dp[i][k]) path[j][k]=path[j][i];  
                    }                    }  
            }  
        }  
    }
]]></description><link>technology\collegeproject\数据结构\最短路径算法\floyd算法.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/最短路径算法/Floyd算法.md</guid><pubDate>Sun, 17 Mar 2024 07:10:15 GMT</pubDate><enclosure url="lib\media\pasted-image-20231211110124.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20231211110124.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[kruskal算法]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a><br>
<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/455640440" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/455640440" target="_blank">最小生成树之 Kruskal 算法 - 知乎 (zhihu.com)</a><br>
Kruskal 算法其实很容易理解和记忆，其关键是要熟悉并查集算法，如果不熟悉，建议先看下前文&nbsp;<a data-href="并查集算法" href="\technology\collegeproject\数据结构\其他算法\并查集算法.html" class="internal-link" target="_self" rel="noopener nofollow">并查集算法</a>。]]></description><link>technology\collegeproject\数据结构\最小生成树算法\kruskal算法.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/最小生成树算法/kruskal算法.md</guid><pubDate>Tue, 12 Dec 2023 01:55:51 GMT</pubDate></item><item><title><![CDATA[Prim算法]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a><br>
Prim算法又称为加边法，即每次选择最小权值的边加入到生成树中，然后再更新权值，如此反复，保证每次最优来达到最优解。<br>
<a data-tooltip-position="top" aria-label="https://blog.csdn.net/lady_killer9/article/details/102995984" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/lady_killer9/article/details/102995984" target="_blank">最小生成树-Prim算法详解（含全部代码）_prim算法代码-CSDN博客</a><br>代码：<br>//最小生成树-Prim算法 参数：图G
void Prim(Graph G)
{
	int v=0;//初始节点
	closedge C[MaxVerNum];
	int mincost = 0; //记录最小生成树的各边权值之和
	//初始化
	for (int i = 0; i &lt; G.vexnum; i++)
	{
		C[i].adjvex = v;
		C[i].lowcost = G.Edge[v][i];
	}
	cout &lt;&lt; "最小生成树的所有边:"&lt;&lt; endl;
	//初始化完毕，开始G.vexnum-1次循环
	for (int i = 1; i &lt; G.vexnum; i++)
	{
		int k;
		int min = INF;
		//求出与集合U权值最小的点 权值为0的代表在集合U中
		for (int j = 0; j&lt;G.vexnum; j++)
		{
			if (C[j].lowcost != 0 &amp;&amp; C[j].lowcost&lt;min)
			{
				min = C[j].lowcost;
				k = j;
			}
		}
		//输出选择的边并累计权值
		cout &lt;&lt; "(" &lt;&lt; G.Vex[k] &lt;&lt; "," &lt;&lt; G.Vex[C[k].adjvex]&lt;&lt;") ";
		mincost += C[k].lowcost;
		//更新最小边
		for (int j = 0; j&lt;G.vexnum; j++)
		{
			if (C[j].lowcost != 0 &amp;&amp; G.Edge[k][j]&lt;C[j].lowcost)
			{   
				C[j].adjvex = k;
				C[j].lowcost= G.Edge[k][j];
			}
		}
 
	}
	cout &lt;&lt; "最小生成树权值之和:" &lt;&lt; mincost &lt;&lt; endl;
}
<br>总结：<br>
prim数组的本质就是贪心策略，主要任务是维护一个数组。这个数组如下图所示：<br>
<img alt="Pasted image 20231209122418.png" src="\lib\media\pasted-image-20231209122418.png"><br>
prim算法的底层逻辑是，对于一个图，将它分成两个割，这两个割最小的交叉边一定是确保这两个割连通的最小权重边，由于最小生成树需要保证全部节点的连通，所以最小生成树的算法也可以按照这个逻辑构建：<br>
<br>我们将初始节点，如v0单独放入一个割为U，其他节点在另一个割中V-U。
<br>在lowcost中存入U这个割与另一个割的交叉边权值。内部节点则赋为0，不直接可达则赋为INF。
<br>找到交叉边中权重最小的，将它加入集合U。
<br>遍历新加入的节点的可达点，更新lowcost数组。将被更新的lowcost对应的adjvex改为新节点的序号。如下图：<img alt="Pasted image 20231209124601.png" src="\lib\media\pasted-image-20231209124601.png">
<br>循环遍历直到所有点加入U。
<br>将加入集合U的边的顺序存储下来，即可得到最小生成树。根据adjvex数组，起始为adjvex中数据，终点为顶点数组下标，权重为lowcost。
]]></description><link>technology\collegeproject\数据结构\最小生成树算法\prim算法.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/最小生成树算法/Prim算法.md</guid><pubDate>Tue, 12 Dec 2023 01:55:51 GMT</pubDate><enclosure url="lib\media\pasted-image-20231209122418.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20231209122418.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数据结构]]></title><description><![CDATA[<a class="tag" href="?query=tag:CollegeProjectNotes" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#CollegeProjectNotes</a> 
 <br><a href=".?query=tag:CollegeProjectNotes" class="tag" target="_blank" rel="noopener nofollow">#CollegeProjectNotes</a> <br>


<br>平时 20%（出勤、作业、实验）
<br>期中 20%
<br>期末 60%

<br><br><br><br>对于当前的数据之间的关系进行分析，进而思考应该如何存储<br>
<br>集合
<br>线性结构
<br>树形结构
<br>图结构
<br><br>设计一定的方法存储到程序中<br>
<br>存储内容

<br>数值存储
<br>数据与数据之间关系域的存储


<br>存储方式

<br>顺序存储
<br>链式存储
<br>树形存储
<br>图存储


<br><br>设计算法计算实现<br><br>约束：值集 + 运算集<br>数据类型 （DT）：一般编程语言已经实现好了<br>抽象数据类型 （ADT）：数据结构+算法操作<br><br>
<br>
正确性

<br>
健壮性（鲁棒性）：对于不合法、异常的输入也有处理能力

<br>
可读性

<br>
可扩展性

<br>
高效率

<br>
空间复杂度

<br>
时间复杂度 ，其中有三种表示时间复杂度的公式

<br> upper bound：最坏的时间复杂度
<br> lower bound：最好的时间复杂度
<br> average bound：平均时间复杂度




<br><br><img style="zoom:50%;" alt="image-20230920231245137" src="https://s2.loli.net/2023/12/04/4Nn73PGspUM2Cwl.png" referrerpolicy="no-referrer"><br><br>有一个头结点，尾结点，且每一个结点只有一个前驱结点和一个后继结点。<br><br><br>存储在一维地址连续的存储单元里<br>特点：逻辑位置相邻，物理位置也相邻<br>数据结构：一个一个一维数组 + 一个长度变量 n<br>template&lt;class T, int MaxSize&gt;
class SeqList
{
    T data[MazSize];
    int length;
public:
    ...
}
<br>顺序表可以直接存储元素与关系<br>链表的元素存储也是可以直接实现的，但是关系要通过指针域来实现<br><br>
<br>
单链表：默认有一个头结点，不存储数据

<br>
循环链表

<br>
双向链表

<br><br><br>
<br>
顺序表初始化构造

<br>
求顺序表长度

<br>
按位查找

<br>
按值查找

<br>
遍历顺序表

<br>
插入

<br>
删除

<br><br>
<br>
单链表初始化构造
head = new Node&lt;T&gt;;
head-&gt;next = nullptr;


<br>
头插法
head = new Node&lt;T&gt;;
head-&gt;next = nullptr;


<br>
尾插法
head = new Node&lt;T&gt;;
rear = head;




<br>
求单链表长度

<br>
按位查找

<br>
按值查找

<br>
遍历单链表

<br>
插入

<br>
删除

<br>
单链表的析构函数

<br>
其他操作

<br>
双向链表操作

<br>
插入
  <img style="zoom:50%;" alt="image-20230925092012868" src="https://s2.loli.net/2023/12/04/7d4ygetnDPANTzU.png" referrerpolicy="no-referrer">
// 插入当前结点 s
s-&gt;prior = p;
s-&gt;next = p-&gt;next;
p-&gt;next-&gt;prior = s;
p-&gt;next = s;


<br>
删除
  <img style="zoom:50%;" alt="image-20230925091955866" src="https://s2.loli.net/2023/12/04/CiJzh1HXaGqvURB.png" referrerpolicy="no-referrer">
// 删除当前结点 p
p-&gt;next-&gt;prior = p-&gt;prior;
p-&gt;prior-&gt;next = p-&gt;next;




<br><br><br><br><img alt="image-20230928095521363" src="https://s2.loli.net/2023/12/04/MuQ7ZHX6xNKSqbf.png" referrerpolicy="no-referrer"><br>卡特兰数：假设  表示第 k 个数最后一个出栈的总个数，则 <br><br><br>
<br>
顺序存储
<img style="zoom:67%;" alt="image-20230928095919380" src="https://s2.loli.net/2023/12/04/DGIASXO27NbC8Ji.png" referrerpolicy="no-referrer">

<br>
链式存储
<img style="zoom:67%;" alt="image-20230928100849337" src="https://s2.loli.net/2023/12/04/o8mYC2XQvqUJ5BL.png" referrerpolicy="no-referrer">

<br><br>
<br>顺序栈的操作
<br>链栈的操作
<br><br>
<br>
括号匹配

<br>
算数表达式求值

<br>
中缀表达式求值

双栈思路，算符优先法

<br>
遇到数字，直接入数栈

<br>
遇到符号

<br>如果是括号，左括号直接入栈，右括号进行运算直到遇到左括号
<br>如果是算符，在入算符栈之前，需要进行运算操作直到算符栈顶元素等级小于当前算符等级





<br>
中缀表达式转后缀表达式

算符栈即可
后缀先遇到就直接计算的运算符  中缀表达式需要先算的运算符，于是转化思路就是：

<br>遇到数字，直接构造后缀表达式
<br>遇到算符

<br>如果是括号，左括号直接入栈，右括号进行后缀表达式构造直到遇到左括号
<br>如果是算符，在入算符栈之前，需要进行后缀表达式构造操作直到算符栈顶元素等级小于当前算符等级





<br>
后缀表达式求值

数栈即可
遇到数字直接入数栈，遇到算符直接进行运算




<br>
栈与递归
递归工作栈

<br><br><br>先进先出<br><br>
<br>
顺序存储
<img style="zoom:67%;" alt="image-20231007091939711" src="https://s2.loli.net/2023/12/04/GJh3alEndfXKCMq.png" referrerpolicy="no-referrer">
<img style="zoom:67%;" alt="image-20231007091951161" src="https://s2.loli.net/2024/01/14/2DNAL7e1UBlECas.png" referrerpolicy="no-referrer">

<br>
链式存储
<img style="zoom:67%;" alt="image-20231007090752380" src="https://s2.loli.net/2023/12/04/h1rZ6A3FVN9mRaq.png" referrerpolicy="no-referrer">

<br><br>
<br>
循环队列的操作

循环队列的三个注意点

<br>解决假溢出：采用循环队列，即在入队的时候不是单纯的指针 +1，而是+1后 % MaxSize
<br>解决队空队满的冲突（真溢出）：

<br>浪费一个元素空间：测试rear+1是否==head，
<br>设置一个辅助标志变量
<br>设置一个计数器





<br>初始化：头尾全部初始化为0
<br>入队push
<br>出队pop
<br>取队头front
<br>长度size
<br>队空empty


<br>
链队列的操作

<br><br>
<br>
报数问题：报到 0 的出队，报到 1 的重新入队，求解出队顺序

<br>
迷宫最短路问题：开一个记忆数组  表示从起点  到终点  点的最短路径的长度。可以将求最短路看做一个波心扩散的物理场景，队列中的每一个点都可以作为一个波心，从而实现“两点之间线段最短”的物理场景

<br>为什么用队列：逐层搜索，每次搜素到的点就是当前点可以搜索到的最短的点，先搜到的点先扩展，于是就是队列的数据结构
<br>为什么最短：对于每一个点探索到的点都是最短的点，最终的搜索出来的路径就是最短的路径


<br><br><br>由字符组成的串<br>
<br>子串（连续）
<br>主串
<br>位置
<br><br><br>使用固定长度的数组来存储，3种存储字符串长度的方法如下：<br><img style="zoom:50%;" alt="image-20231012095542232" src="https://s2.loli.net/2023/12/04/lwkEMtF2mXjPpaz.png" referrerpolicy="no-referrer"><br><img style="zoom:50%;" alt="image-20231012095512268" src="https://s2.loli.net/2023/12/04/vbFg17sAwLBModl.png" referrerpolicy="no-referrer"><br><img style="zoom:50%;" alt="image-20231012095528625" src="https://s2.loli.net/2023/12/04/DIQATWxkN5J3eH1.png" referrerpolicy="no-referrer"><br><br><br>
<br>
非压缩形式：一个结点存一个字符
// 存储密度为：1/9 （64位操作系统）
struct String {
    char data;
    String* next;
};


<br>
压缩形式（块链）：一个结点存储指定长度的字符
// 存储密度为：4/12 （64位操作系统）
const int MaxSize = 4;
struct String {
    char data[MaxSize];
    String* next;
}


<br><br><br>
<br>串连接
<br>串比较
<br>串拷贝
<br><br>
<br>
BF算法（Brute - Force）
<img style="zoom:60%;" alt="image-20231012105536936" src="https://s2.loli.net/2023/12/04/NemPEzIdOpLh3Vb.png" referrerpolicy="no-referrer">
// 返回匹配上的所有位置下标（下标从0开始）
vector&lt;int&gt; BF(string&amp; s, string&amp; t) {
	vector&lt;int&gt; res;
	int i = 0, j = 0, n = s.size(), m = t.size();
    
	while (i &lt; n &amp;&amp; j &lt; m) {
		if (s[i] == t[j]) i++, j++;
		else i = i - j + 1, j = 0;
            
		if (j == m) {
			res.emplace_back(i - j);
			j = 0;
		}
	}

    return res;
}


<br>
KMP算法
 <img style="zoom:80%;" alt="image-20231012194432323" src="https://s2.loli.net/2023/12/04/X2VvgtLuKnH1NwJ.png" referrerpolicy="no-referrer">

优化思想：
先看暴力思想，我们需要每次将模式串 t 后移一位重新进行比较，其中浪费了已匹配的串数据，优化就是从这块已匹配的串数据入手。而已匹配的串数据就是模式串本身的串数据，因为我们可以直接从模式串本身入手。
初步猜想：
根据模式串的性质，构造一个数表 next，存储模式串应该后移的指针数 k
算法实现：

<br>递推求 next 数组
<br>KMP 中 i 指针不回溯，j 回溯到 next[j]


// 求 next 数组	下标从1开始
for (int i = 2, j = 0; i &lt;= m; i++) {
    while (j &amp;&amp; t[i] != t[j + 1])
        // 未匹配上则不断回溯
        j = ne[j];
    
    if (t[i] == t[j + 1])
        // 匹配上了则j指针后移一位
        j++;
    
    ne[i] = j;
}

// KMP 匹配		 下标从1开始
for (int i = 1, j = 0; i &lt;= n; i++) {
    while (j &amp;&amp; news[i] != newt[j + 1])
        // 未匹配上则不断回溯
        j = ne[j];
    
    if (news[i] == newt[j + 1])
        // 匹配上了则j指针后移一位
        j++;

    if (j == m) {
        // 匹配完全，则统计并且回溯
        cnt++;
        j = ne[j];
    }
}


<br><br><br><br>typedef int arr[m][n];
// 等价于
typedef int arr1[n];
typedef arr1 arr2[m];
<br><br>
<br>行优先：按行存储
<br>列优先：按列存储
<br>可以按照下标的关系，只需要知道第一个元素的地址，通过矩阵的大小关系即可直接计算出  的地址<br><br>对于多个相同的非零元素只分配一个存储空间，对零元素不分配空间<br><br><img style="zoom:50%;" alt="image-20231016092313887" src="https://s2.loli.net/2023/12/04/TKBNSHyJ7RcdFu3.png" referrerpolicy="no-referrer"><br>假设现在有一个 n*n 的对称矩阵<br>存：行优先存储 data[n * (n + 1) / 2]<br>取：我们如果要取 data[i][j]<br>
<br>
对于上三角

<br>
i &gt;= j：data[i * (i + 1) / 2 + j]

<br>
i &lt;  j：data[j * (j + 1) / 2 + i]



<br>
对于下三角

<br>
i &gt;= j：data[i * (i + 1) / 2 + j]

<br>
i &lt;  j：data[j * (j + 1) / 2 + i]



<br><br><img style="zoom:50%;" alt="image-20231019094830937" src="https://s2.loli.net/2023/12/04/6OPLDYtrKld1iGv.png" referrerpolicy="no-referrer"><br>假设现在有一个 n*n 的三角矩阵（上三角或下三角为常数c）<br>存：行优先存储，常数 c 存储到最后 data[n * (n + 1) / 2 + 1]<br><br><img style="zoom:50%;" alt="image-20231019094859766" src="https://s2.loli.net/2023/12/04/PwcA7Tu5XBZ2q8y.png" referrerpolicy="no-referrer"><br>假设现在有一个 n*n 的对角矩阵（围绕主对角线有数据，其余数据均为0）<br><br>假设现在有一个 n*m 的稀疏矩阵（很多零的一个矩阵）<br>
<br>
三元组顺序表
按行存储两个信息，一个是非零元素的数值，还有一个是具体的坐标 (i, j)

<br>
十字链表
定义两个指针数组，定义两个指针数组，存储行列的头指针即可 vector&lt;CrossNode&lt;T&gt;*&gt; cheads, rheads

<br><br><br>
<br>与以往的线性表的区别在于：线性表的元素只能是DT或ADT。而对于广义表，元素还可以是一个广义表，即可递归结构
<br>表头、表尾：对于当前序列，第一个元素就是表头，其余元素的集合就是表尾
<br>特点：层次结构、共享结构、递归结构
<br><br><br>采用联合结构体存储结点类型<br><img style="zoom:50%;" alt="image-20231023084427729" src="https://s2.loli.net/2023/12/04/Gjiltk6f74yO5L9.png" referrerpolicy="no-referrer"><br><br><img style="zoom: 67%;" alt="image-20231023090301534" src="https://s2.loli.net/2023/12/04/G9yUhn4mzEDPBxo.png" referrerpolicy="no-referrer"><br><br>
<br>直接递归法 - 原子直接操作，子表循环成原子进行操作
<br>减治法 - 先处理第一个元素（原子：直接操作  子表：递归操作），最后递归操作剩余的元素
<br><br>
<br>复制广义表
<br>计算广义表的长度
<br>计算广义表的深度 - 原子深度为0，空表深度为1
<br>释放广义表的存储空间
<br><br><br><br><br>
<br>结点的度和树的度

<br>结点的度：每一个结点孩子结点的数量
<br>树的度：一棵树中结点度数的最大值


<br>孩子、双亲、兄弟结点
<br>路径和路径长度
<br>子孙结点和祖先结点
<br>结点的层次和树的高度
<br>有序树和无序树

<br>有序树：子集不可以随意交换
<br>无序树：子集可以随意交换


<br>森林

<br>多棵树


<br><br><br><br><br>
<br>
根是第一层。第  层最多有  个结点

<br>
树中叶子结点的个数为 ，度数为2的结点的个数为 。已知树的点数为 ，边数为 ，则 。而 ，，则 ，则


<br>
满二叉树：每一层都是满结点
<img style="zoom: 50%;" alt="image-20231030085031394" src="https://s2.loli.net/2023/12/04/dECpXhRImnJHxiw.png" referrerpolicy="no-referrer">

<br>
完全二叉树：对于一个  层的二叉树， 都是满的，第  层从左到右连接叶子结点
 <img style="zoom:50%;" alt="image-20231030085057862" src="https://s2.loli.net/2023/12/04/2xWt4QInCRXKulf.png" referrerpolicy="no-referrer">
结点数固定，则完全二叉树的形状唯一
<img style="zoom:67%;" alt="image-20231030090400650" src="https://s2.loli.net/2023/12/04/qDFBM34ghjwkCzR.png" referrerpolicy="no-referrer">
若  为奇数，且 ，则左兄弟就是 
若  为偶数，则右兄弟就是 

<br><br><br>
<br>对于一般的二叉树，将其转化为完全二叉树进行存储即可
<br>插入删除操作都不方便
<br><br><br><br><br>
<br>先中后遍历

<br>递归遍历
<br>栈式遍历


<br>层序遍历
<br><br>
<br>
由含空指针标记的单个遍历序列构造二叉树
可以从遍历的逻辑进行逆推。在遍历到空指针的时候输出一个编制符号，然后在构造的时候按照遍历序列进行递归构造即可，如图
先序序列进行构造：按照遍历的思路来，对于先序序列而言，第一个元素一定是根元素，因此首先根据“当前局面”的第一个元素创建根结点，接着递归创建左子树和右子树即可。注意传递的序列起始下标是引用类型的变量
<img style="zoom:75%;" alt="image-20231102112448133" src="https://s2.loli.net/2024/01/14/45xM2KrThuV8mkF.png" referrerpolicy="no-referrer">
<img style="zoom:75%;" alt="image-20231102112515427" src="https://s2.loli.net/2023/12/04/EIX38hF67pVitun.png" referrerpolicy="no-referrer">
**中序序列**进行构造：
 不可以，因为不能确定根节点以及左子树和右子树的部分
后序序列进行构造：与上述先序序列进行构建的逻辑一致，只不过有一个小 trick，即我们从后序序列的最后一个元素开始创建，那么得到的第一个元素就是根结点的值，然后首先递归创建右子树，再递归创建左子树即可。同样需要注意的是传递参数时，序列起始下标是引用类型的变量
与先序序列构造逻辑相同，只是递归的顺序需要调整一下

<br>
由两个遍历序列构造二叉树

<br>先+中：构造逻辑与上述带标记的序列构造逻辑几乎一致，只不过区别在于如何进行递归中参数的传递。传递的参数除了先序和中序的字符串，还有当前局面先序序列的起始下标与当前局面中序序列的起始下标，以及以当前序列进行构造时子树的结点个数。很容易就可以找到当前序列的根结点，接着就是利用很简单的下标关系得到上述的三个参数的过程，最后将新得到的三个参数传递给递归函数进行递归构建左右子树即可，当前的根结点是 pre[ipre]
<br>后+中：逻辑与上述一致，只不过当前的根结点是 post[ipost+n-1]


<br>
由顺序结构构造链式结构

<br>
拷贝构造

<br>
析构

<br><br>
<br>计算二叉树的结点数

<br>有返回值的递归
<br>无返回值的递归


<br>计算二叉树的高度

<br>有返回值的递归
<br>无返回值的递归


<br>根据关键值查找结点
<br>查找结点的父结点
<br><br><br>将空指针域用前驱 or 后继结点的地址进行覆盖<br><br>依旧是链式存储，只不过增加了结点域中的指针类型，分为链接类型Link与线索类型Thread<br><br>
中序线索化的二叉树
<br>
<br>
线索化算法
设置一个全局变量 pre，为了简化思维，我们可以将一个中序遍历的过程想象成一个线性结构。前驱为pre，当前为p。

<br>p的左子树为空，则p的前驱为pre
<br>pre的右子树为空，则pre的后继为p


<br>
求后继结点和前驱结点的算法

<br>
遍历算法

<br>
求父结点的算法

<br>首先，若已知当前是左子树，则父结点一定是当前右孩子的中序前驱线索；若已知当前是右子树，则父结点一定是当前左孩子的中序前驱线索
<br>但是在未知当前结点的位置（未知左右子树）时，同时搜索两边的父结点，然后根据试探出来的父结点，特判父结点的子结点是否是当前结点即可


<br><br><br>
<br>
多叉链表表示法
将每一个结点的子结点都预设置为一个定值（树的最大度数）：浪费空间

<br>
孩子链表表示法
自顶向下存储边的信息
template&lt;class T&gt;
struct CTBox {
    T data;
    CTNode* firstchild;
};
struct CTNode {
    int child;
    CTNode* next;
};

<img style="zoom:50%;" alt="image-20231109115729850" src="https://s2.loli.net/2023/12/04/eKfb6koTwzBUAOV.png" referrerpolicy="no-referrer">

<br>
双亲表示法
自下向上存储边的信息
<img style="zoom:50%;" alt="image-20231109115759641" src="https://s2.loli.net/2023/12/04/Pc4ZMp2eQE1aCfN.png" referrerpolicy="no-referrer">

<br>
孩子兄弟表示法
左结点存储孩子，右结点存储兄弟

<br><br>
<br>构造
<br>计算树的高度
<br>计算树中所有结点的度
<br><br><br>树的路径长度：叶子结点到根结点的路径之和<br>
<br>树的带权路径长度  ：叶子结点到根结点的路径之和  叶子结点的权重，整体之和
<br> 最小的树就叫做哈夫曼树：对于一个结点序列n，每次选择其中的两个权值最小的两个结点进行合并，在进行了n-1次以后，得到的二叉树就是哈夫曼树
<br>哈夫曼编码：

<br>编码：利用二叉树进行前缀编码 - 避免解码时的二义性
<br>解码：根据编码的二叉trie树，进行解码


<br><br>
<br>构造 Huffman 树
<br>编码
<br>解码
<br><br><br><br><br>完全无向图：<br>完全有向图：<br><br>
<br>
带权图称为网

<br>
连通图和连通分量：

<br>
无向图

<br>
连通图：每一个顶点之间都有路径可达

<br>
连通分量：极大连通子图



<br>
强连通图和强连通分量：

<br>
有向图

<br>
强连通图：每一个顶点之间都有路径可达

<br>
强连通分量：极大强连通子图



<br><br>教材中的点编号统一从  开始<br><br>
<br>
无向图的度：第  行（列）的非标记数的个数

<br>
有向图的度：

<br>入度：第  行的非标记数的个数
<br>出度：第  列的非标记数的个数


<br>
类定义：
  <img style="zoom:67%;" alt="image-20231123111517468" src="https://s2.loli.net/2023/11/23/bR61nTfc34wNVgH.png" referrerpolicy="no-referrer">
  <img style="zoom:67%;" alt="image-20231123111541444" src="https://s2.loli.net/2023/11/23/O3HzLeM87SyUqN6.png" referrerpolicy="no-referrer">

<br><br>
<br>
存储出边表（邻接表）

<br>
存储入编表（逆邻接表）

<br>
类定义：
  <img style="zoom:67%;" alt="image-20231123113744911" src="https://s2.loli.net/2023/11/23/g5Hw6kdlGj8XvfQ.png" referrerpolicy="no-referrer">

<br><br><br>每个结点只能访问一次，故需要开启标记数组用来记录是否访问的情况<br><br><img style="zoom:67%;" alt="image-20231127083412848" src="https://s2.loli.net/2023/12/04/hXzEj7fZQqrJl3u.png" referrerpolicy="no-referrer"><br>
<br>
邻接矩阵：

<br>
时间复杂度：

<br>
针对邻接矩阵的一个无向连通图的搜索代码示例
  <img style="zoom:67%;" alt="image-20231127083039909" src="https://s2.loli.net/2023/12/04/IqEmULWtYw5Chv9.png" referrerpolicy="no-referrer">



<br>
邻接表：

<br>
时间复杂度：

<br>
针对邻接表的一个无向连通图的搜索代码示例
template&lt;class T&gt;
void ALGraph::DFS(int v, bool* visited) {
    cout &lt;&lt; vexs[v];
    visited[v] = true;
    // 遍历所有的边
}




<br><br>
<br>通过队列实现
<br>时间复杂度与上述 DFS 算法类似
<br><br>
<br>
求 (u,v) 的所有简单路径
dfs+回溯法的简单应用

<br>
染色法求二部图

bfs的简单应用
当然dfs也是可以的，只需要在染色之后判断是否有相同颜色的邻接点即可


<br><br><br><br>证明：<br><img style="zoom: 67%;" alt="image-20231130114331973" src="https://s2.loli.net/2023/11/30/YjIDAz6dsPUbTOB.png" referrerpolicy="no-referrer"><br>对于上述的一个割，选择其中权值最小的交叉边。从而对于所有的状态，每次选择最小交叉边即可。<br><br>算法标签：<br>
<br>
构造  个割的状态

<br>
起始状态为：顶点集合  含  个顶点，顶点集合  含  个顶点

<br>
状态转移为：

<br>选完最小交叉边之后，将这条边在集合  中的顶点加入到最小生成树集合  中
<br>更新最小交叉边数组 


<br>
时间复杂度：

<br><br>算法流标签：<br>
<br>初始化  个顶点作为  个连通分量
<br>按照边的权值升序进行选择

<br>如果选出的边的两个顶点不在同一个集合，则加入最小生成树
<br>如果选出的边的两个顶点在同一个集合，则不选择（如果选了就会使得生成树形成回路）


<br>时间复杂度：
<br><br><br>单源最短路<br>
 算法无法求解含负边权的单源最短路
 算法支持负边权的单源最短路求解
 算法同样支持负边权的单元最短路，属于  算法的优化
<br>多源最短路<br>
 适用于求解含负边权的多源最短路
<br><br>算法标签：  <br>
其实就是  的另一种应用

<br> 是只存储交叉边的最小值
<br> 是存储交叉边的最小值  这条边在集合 S 中的点已经记录的值

<br>
<br>
朴素版：

<br>
邻接矩阵

<br>
定义  表示从起点到当前i号点的最短路径的长度

<br>
将顶点分为两个集合， 和 ，其中  表示已经更新了最短路径长度的顶点集合

<br>
迭代更新过程：依次更新每一个结点，对于当前结点 ，在集合  中的所有结点中，选择其中到当前结点路径最短的顶点 ，则 d[i]=d[j]+edges[j][i]

<br>
时间复杂度：



<br>
堆优化：

<br>
邻接表

<br>
时间复杂度：



<br><br>算法标签：<br>
多阶段决策共  个阶段，dp[i][j] 表示每一个阶段 ，从  到  的选择前  个顶点后的最短路径的长度
<br>对于当前阶段 ，我们利用阶段  的状态进行转移更新，其实就是对于新增加的顶点  是否选择的过程<br>
<br>选择 ，则 dp[i][j] = dp[i][k] + dp[k][j]
<br>不选 ，则 dp[i][j] 就是  状态下的 dp[i][j]
<br><br><br>
<br>有向无环图：
<br>AOV网： 
<br>应用场景：在时间先后上有约束关系的工程管理问题
<br><br>
<br>定义：顶点线性化
<br>应用：判环、判断一个图是否可以进行动态规划
<br>算法设计：对于有向图，从所有的入度为 0 的点开始删点删边，到最后判断有多少点被删除即可
<br>算法实现：可以采用 dfs 进行缩点删边，也可以采用 bfs 进行缩点删边
<br>时间复杂度：
<br><br><br>定义：只支持查询和修改，不支持删除与插入<br><br><br><br>结合顺序查找与分块查找的一种方法<br><img style="zoom:67%;" alt="image-20231225093347357" src="https://s2.loli.net/2023/12/25/dkaKtQWFMbAR2Hh.png" referrerpolicy="no-referrer"><br>
<br>索引表可以折半或者顺序查找
<br>块内部只能顺序查找
<br><br><br>定义：根结点比左子树所有结点的值都大，比右子树所有结点的值都小。关键字唯一<br>操作：查找、插入、删除<br>判定：想要判定一棵二叉树是否为二叉排序树，只需要判断中序遍历的结果是不是递增的即可，可以采取中序遍历序列比对的方法，也可以在递归遍历二叉树的过程中通过记录前驱结点的值直接进行比较判断。时间复杂度：<br><br>定义：平衡因子为左子树的高度 - 右子树的高度，平衡二叉树的平衡因子绝对值 &lt;= 1<br>构建：当插入结点进行构建时出现了有结点平衡因子的绝对值超过了1，则进行“旋转”调整，旋转共分为4种<br><img style="zoom:50%;" alt="image-20240104125111608" src="https://s2.loli.net/2024/01/04/z29qmNZYl1xpKDh.png" referrerpolicy="no-referrer"><br><img style="zoom:50%;" alt="image-20240104125140305" src="https://s2.loli.net/2024/01/04/7AaqC84f6eit13s.png" referrerpolicy="no-referrer"><br><img style="zoom:50%;" alt="image-20240104125159728" src="https://s2.loli.net/2024/01/04/kP98Y7MBTcm2VQI.png" referrerpolicy="no-referrer">
尝试模拟一遍下列序列的构造过程就可以理解了<br><img style="zoom:50%;" alt="image-20240114231458389" src="https://s2.loli.net/2024/01/14/AfC6nZv3FaU1MYo.png" referrerpolicy="no-referrer"><br><br>定义：装填因子 ，其中  表示待填入表中的结点数， 表示哈希表的空间大小<br>哈希函数应该满足以下两点：第一、映射出来的地址不会越界；第二、映射出来的地址是唯一的<br><br>常用的哈希函数<br>
<br>
直接地址法 - 线性函数一对一映射
优点。计算简单且不可能产生冲突
缺点。对于空间的要求极高，如果数据过于离散，则会造成很大的空间浪费

<br>
数字分析法 - 按照数位中的数值分布情况进行哈希
缺点。需要预先知道数据的数字分布情况

<br>
平方取中法 - 对于  的哈希空间，可以将数字平方后取中间  位进行哈希存储

<br>
折叠法

<br>
移位法：将一个数字按照数位拆分为几个部分，然后将几个部分的数值累加出一个数即可，高位抹去不用

<br>
间隔法：与移位法几乎一致，只不过将其中的部分意义间隔的进行数值反转，最后累计即可，高位抹去不用



<br>
除留余数法 - 按照数值  后的数值进行哈希，假设哈希表空间大小为  ，则  一般取  的质数

<br>处理冲突<br>
<br>开放定址法 - 探测开放地址，一般有三种

<br>连续序列进行线性探测
<br>左右倍增序列进行探测
<br>伪随机序列进行探测
<br>双 hash 探测法


<br>拉链法

<br>定义：将产生 hash 冲突的元素放入同一个子集，通过单链表进行存储
<br>优点：没有堆积现象，从而减少了很多不必要的比价，提升比较效率；适合一开始不知道表长的情况；除结点更加容易。


<br><br>按照构造相同的逻辑进行查找即可<br><br><br>关键字：<br>
<br>主关键字：每一个待排序的该关键字是独一无二的
<br>次关键字：每一个待排序的该关键字可能是重复的
<br>稳定性：<br>
<br>场景：只针对次关键字的情况
<br>稳定：按照次关键字排序后，原来相同关键字的顺序不变
<br>不稳定：按照次关键字排序后，原来相同关键字的顺序可能会改变
<br>内外排序：<br>
<br>内排序：数据全部存放在内存
<br>外排序：数据量过大时，待排序的数据在内存与外存之间不断转换
<br><br>基于交换的思路进行<br>稳定的<br><br>
<br>
选择第 1 小的数放在第一个位置，...，选择第 i 小的数放在第 i 个位置

<br>
共选择 n-1 次

<br><br>
<br>直接插入排序：依次向前缀已经排好序的序列中进行插入 - 
<br>折半插入排序：同上，只是选择插入位置的使用二分 - 
<br>递归插入排序：排序 [1,i] 等价于先排好 [1,i-1]，然后插入当前 num[i] 即可
<br>稳定的<br><br>基于插入直接排序的优点：<br>
<br>当序列基本有序时，效率很高
<br>当待排序数很少时，效率很高
<br>于是希尔（Shell）就得出来以下的希尔排序算法：<br>
<br>将序列划分一定次数，从 d&lt;n 到 1
<br>每次划分都对组内的元素进行直接插入排序
<br>最后分为 1 组时，直接排序一趟以后就可以得到 sortrd sequence
<br>不稳定<br><br>分治法三步骤：divide、conquer and combine<br>每次选择一个 pivot 进行 partition，递归两个 partition<br>void Sort(int l, int r) {
    if (l &gt;= r) return;

    int i = l - 1, j = r + 1, x = a[l + r &gt;&gt; 1];
    while (i &lt; j) {
        while (a[++i] &lt; x);
        while (a[--j] &gt; x);
        if (i &lt; j) swap(a[i], a[j]);            
    }
    
    Sort(l, j), Sort(j + 1, r);
}
<br>不稳定<br><br>堆与堆排序的定义<br>
首先我们得知道什么是堆结构。堆是具有下面性质（对于任意的  ）的完全二叉树

<br>
 叫做 小顶堆

<br>
 叫做 大顶堆


因此一个堆结构可以采用线性的单元进行存储与维护
而堆排序利用堆顶是最值这一性质，通过不断的取堆顶，调整堆的方式获得最终的排好序的序列
<br>建立初始堆<br>
由于完全二叉树中，每一个叶子结点都已经是堆结构，因此直接从第一个非叶子结点开始建堆即可。对每一个元素与左孩子、 右孩子进行比较

<br>如果当前结点的值比左右孩子都大，那么无需修改，当前位置就是堆顶
<br>如果当前结点的值比左孩子或者右孩子中的最大值小，则将最大的孩子作为堆顶，并将当前值不断的“下沉”即可

<br>交换堆顶与记录位置后重新建堆<br>
交换记录值获取当前堆中最值以后，需要将除了已记录的值的结点以外的所有结点重新调整为堆结构

<br>调整为堆结构的过程与上述初始建堆的过程完全一致，只是结点数每次 -1

<br>时间复杂度 <br>不稳定<br><br>递归<br>
同样采用分治法，我们按照分治法的三个步骤进行讨论

<br>divide: 将当前序列划分为左右两部分
<br>conquer: 递归处理上述划分出来的两部分
<br>combine: 归并上述递归完的两部分

时间复杂度 
<br>非递归<br>
就是模拟上述递归的过程，可以拆分为三步

<br>归并
<br>按照指定的长度处理整个序列
<br>划分局部排序的长度

<br>稳定的]]></description><link>technology\collegeproject\数据结构\数据结构.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/数据结构.md</guid><pubDate>Tue, 16 Jan 2024 03:34:22 GMT</pubDate><enclosure url="https://s2.loli.net/2023/12/04/4Nn73PGspUM2Cwl.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://s2.loli.net/2023/12/04/4Nn73PGspUM2Cwl.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[图]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a> <br>从后往前复习<br><br><br>
<br>网：即带权图
<br>完全图：任意两顶点均有一条边。
<br>连通分量：无向图中，可能含有多个分立的连通图，每一个连通子图叫做一个连通分量。
<br>强连通分量：有向图中，分立的连通子图。

<br>注：不同连通分量一定不连通，而不同强连通分量可能连通


<br>生成树：即具有G中全部n个节点且边数为n-1的连通子图。
<br>最小生成树：即边权之和最小的生成树。对应<a data-href="Prim算法" href="\technology\collegeproject\数据结构\最小生成树算法\prim算法.html" class="internal-link" target="_self" rel="noopener nofollow">Prim算法</a>
<br>最短路径树：取一点v0，以各点到v0的最短路径构成的树，注意与最小生成树区分。对应<a data-href="Dijkstra算法" href="\technology\collegeproject\数据结构\最短路径算法\dijkstra算法.html" class="internal-link" target="_self" rel="noopener nofollow">Dijkstra算法</a>.
<br>割：一个连通图成为两个或多个非连通图，每个连通子图称为割。
<br><br><br>
<br>基本思想：引入两个数组，用于记录各顶点信息的一维数组，称为顶点表。另一个用于表示图中各个顶点之间关系的二维数组，称为邻接矩阵。
<br>构造及基础操作代码：
<br>enum GraphType{undigraph,digraph,undinetwork,dinetwork};  
const int INFINITY=1e9;  
  
class MGraph {  
    struct EdgeType{  
        int head,tail;  
        int cost;  
        EdgeType(int h,int t,int c){  
            head=h;tail=t;cost=c;  
        }  
    };  
    int vexnum,edgenum;  
    GraphType kind;  
    vector&lt;vector&lt;int&gt;&gt;edges;  
    vector&lt;int&gt;vexs;  
    void DFS(int v,bool *visited);  
public:  
    MGraph(GraphType t,int v[],int n,int e){  
        vexnum=n;  
        edgenum=e;  
        kind=t;  
        vexs.resize(vexnum);  
        edges.resize(vexnum);  
        for(int i=0;i&lt;n;i++){  
            vexs[i]=v[i];  
            edges[i].resize(vexnum);  
        }  
        for(int i=0;i&lt;n;i++){  
            for(int j=0;j&lt;n;j++){  
                if(i==j){  
                    edges[i][j]=0;  
                }  
                else edges[i][j]=INFINITY;  
            }  
        }  
    };  
    void addEdge(int v,int u,int weight){  
        edges[v][u]=weight;  
        if(kind==dinetwork||kind==undinetwork){  
            edges[u][v]=weight;  
        }  
    }  
    void print(){  
        for(int i=0;i&lt;vexnum;i++){  
            for(int j=0;j&lt;vexnum;j++){  
                cout&lt;&lt;edges[i][j]&lt;&lt;' ';  
            }  
            cout&lt;&lt;endl;  
        }  
    }
}
<br><br>
<br>基础思想：对每个节点储存一个单链表，即边表。
<br>声明及构造代码：
<br>enum GraphType{undigraph,digraph,undinetwork,dinetwork};  
  
class ALGraph {  
    int vexnum,edgenum;  
    struct AdjlistNode{
        int adjvex;//边终点；即下一个点 
        int weight;//边权  
        AdjlistNode *next; //下一个点 
    };  
    struct Adjlist{  
        int data;//顶点信息； 用来防止删除节点造成的顶点前移问题  
        AdjlistNode *first;//第一条边  
    };
    GraphType kind;  
    vector&lt;Adjlist&gt;Graph;  
    void DFS(int v,bool visit[]);  
    bool Pathofk(int v,int end,bool visit[],int k,int &amp;deep);  
public:  
    ALGraph(int vex=0,GraphType type=undigraph);  
    void printGraph();     
    void addEdge(int start,int end);  
    void DFSTraverse();     
    void BFSTraverse();     
    bool ispathexist(int start,int end);  
    bool pathofk(int start,int end ,int k);  
};

ALGraph::ALGraph(int vex,GraphType type) {  
    vexnum=vex;  
    kind=type;  
    Graph.resize(vexnum);  
    for(int i=0;i&lt;vexnum;i++){  
        Graph[i].data=i;  
    }  
}  
  
void ALGraph::addEdge(int start,int end){  
    int i=0;  
    while(i&lt;vexnum){  
        if(i==start){  
            AdjlistNode *p=new AdjlistNode;  
            p-&gt;adjvex=end;  
            p-&gt;next=Graph[start].first;  
            Graph[start].first=p;  
        }  
        if(i==end&amp;&amp;(kind==digraph||kind==dinetwork)){  
            AdjlistNode *p=new AdjlistNode;  
            p-&gt;adjvex=start;  
            p-&gt;next=Graph[end].first;  
            Graph[end].first=p;  
        }  
        i++;  
    }  
}

void ALGraph::DFS(int v,bool visit[]) {  
    if(visit[v]==true){  
        return;
    }  
    cout&lt;&lt;Graph[v].data&lt;&lt;' ';  
    visit[v]=true;
    AdjlistNode *p=Graph[v].first;  
    while(p){
        DFS(p-&gt;adjvex,visit);  
        p=p-&gt;next;  
    }  
}  
  
void ALGraph::DFSTraverse() {  
    bool *visit=new bool[vexnum];  
    memset(visit, false, vexnum * sizeof(bool));  
    for(int i=0;i&lt;vexnum;i++){  
        if(!visit[i]){  
            DFS(i,visit);  
        }  
    }  
}
<br><br>DFS和BFS是两个基础的图遍历算法。它们是多数图算法的基础。图遍历算法为了保证不重复访问，设置访问数组visited。<br><br>DFS可以类比为树中的先序遍历。它的基本过程如下：<br>
<br>访问当前节点
<br>判断邻接点是否访问过
<br>对未访问节点进行递归
<br>如果一遍DFS后仍有visited为false，则从该点开始再DFS<br>
注意：DFS中有两个处理时机，一个是在第一次发现该节点时，第二个是彻底遍历完这个点的邻接点时。后者可用来回溯。<br>
具体示例代码如下：
<br>void MGraph&lt;T&gt;::DFS(int v,bool*visited){
	if(!visited[v]){
		return; 
	}//如果访问过直接return
	//处理时机一，Discovering
	for(int i=0;i&lt;vexnum;i++){
		if(edges[v][i]==1 &amp;&amp; !visited[v]){//遍历邻接点
			cout&lt;&lt;vexs[v];
			DFS(i,visted);
		}
	}
	//处理时机二，Finishing
}

void MGraph&lt;T&gt;::DFSTraverse(){
	bool *visited=new bool[vexnum];
	for(int v=0;v&lt;vexnum;v++){
		visited[v]=false;
	}
	for(int v=0;v&lt;vexnum;v++){
		if(!visited[v]){//这里加入计数可以求出连通分量个数
			DFS(v,visited);
		}
	}
	delete[]visited;
}
<br><br>BFS可以类比层次遍历，都是基于队列的入队出队实现的。基本过程如下：<br>
<br>访问出发点，放入队列。
<br>访问邻接点，将未访问过的邻接点放入队尾。队头出队。
<br>重复上述过程。
<br>最后外层套一个循环用来防止非连通情况。<br>
具体代码如下：
<br>void MGraph&lt;T&gt;::BFSTraverse(){
	queue&lt;int&gt;q;
	bool* visited=new bool[vexnum];
	for(int i=0;i&lt;vexnum;i++){
		visited[i]=false;
	}
	for(int i=0;i&lt;vexnum;i++){
		if(!visited[i]){
			cout&lt;&lt;vexs[i];
			visited[i]=true;
			q.push(i);
			while(!q.empty()){
				int u=q.pop();
				for(int j=0;j&lt;vexnum;j++){
					if(edges[u][j]==1 &amp;&amp; !visited[j]){
						cout&lt;&lt;vexs[i];
						visited[j]=true;
						q.push(j);
					}
				}
			}
		}
	}
	delete[]visited;
}
<br>]]></description><link>technology\collegeproject\数据结构\数据结构期末复习.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/数据结构期末复习.md</guid><pubDate>Sun, 17 Mar 2024 07:10:29 GMT</pubDate></item><item><title><![CDATA[数据结构实验二]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a> <br><br>利用hash技术和二分查找技术统计某个C源程序中关键词出现的频度<br>具体描述：
扫描一个C源程序，利用两种方法统计该源程序中关键词出现频度，并比较各自查找的比较次数。
(1)用hash表存储源程序中出现的关键词，利用hash查找统计该程序中的关键词出现频度。用线性探测法解决hash冲突。设置hash函数为：
Hash(key)=[(key的第一个字母序号)*100+(key的最后一个字母序号)]%41
(2)用顺序表存储源程序中出现的关键字，利用二分查找技术统计该程序中的关键字出现的频度。
<br><br>
<br>如何设计一个可供用户选择文件的交互？可以让用户给出文件路径。
<br>如何扫描一个cpp程序？可以用getline一行一行扫。
<br>hash表开多大？根据这个hash函数，总共有41位hash地址。
<br>是否会溢出，不同文件是否使用不同大小的hash表？
<br>如何判定一个关键词，两个非字母之间的字符串可以抽象成一个关键词。
<br>hash表的存储信息有哪些？hash表的下标是地址，需要存两个东西，一个是key即这个string关键词，一个是出现次数num，还有hash表大小size。
<br>如何构造有序的二分查找顺序表？以字典序为序，遍历文件，遇到新的关键词按照字典序插入，老关键词就次数加一，最后得到以key字典序为序的顺序表，并有相应的出现次数。
<br>二分查找顺序表的顺序具体怎么确定？这里的字典序是先按照第一个字母顺序排，相同第一个字母按第二个字母排，如果存在空位，那么空位优先。即if排在ifelse前。
<br>如何进行二分查找关键词？二分查找关键词key，将顺序表不断折半，比较mid和key的关键词字典序大小。从而确定key的位置及出现次数。
<br><br>
<br>采用Hash表存储源程序中出现的关键字，统计关键字出现的频度。```
<br>a. 首先，为了存储关键字，需要实现一个哈希表。根据题目要求，需要设定哈希函数 Hash(key)=[(key的第一个字母序号)×100+(key的最后一个字母序号)] % size。size为hash表大小，每一个元素可以是一个键值对，表示关键字及其出现的频率。

b. 然后，需要读取C源程序，将源程序的每一个单词作为关键字进行哈希。

c. 对每一个关键字，首先计算其哈希值，然后根据哈希值放置到哈希表中相应的位置。如果该位置已经有其他关键字占据（也就是发生了哈希冲突），那么需要使用线性探测法查找下一个空位置。

d. 每当一个关键字被放置到哈希表中，其出现频率就增加1。

e. 最后，通过查找哈希表，可以得到关键字出现的频数。

<br>
<br>采用顺序表存储源程序中出现的关键字，统计关键字出现的频度。```
<br>a. 顺序表是一种简单的存储结构，只需要一个数组就可以实现，这里使用vector容器存储。每一个元素可以是一个键值对，可以用一个结构体表示，表示关键字及其出现的频率。

b. 同样，需要读取C源程序，将源程序的每一个单词作为关键字加入到顺序表中。

c. 每当一个关键字被放置到顺序表中，需要使用二分查找技术查找该关键字是否已存在。如果已经存在，那么频率增加1；否则需要插入到顺序表中相应的位置，以保持顺序表的有序性（以关键字的字典序为序）。

d. 最后，通过二分查找顺序表，可以得到关键字出现的频数。
<br><br>
<br>Hash.h文件应该包含一个Hash类，这个类封装了关于hash表的构建、存储与查找。在main函数中只需创建一个Hash类即可得到一个空的Hash表。
<br>Seq.h文件应该包含一个Seq类，这个类封装了关于二分查找顺序表的构建、存储与查找。在main函数中只需创建一个Seq类即可得到一个空的顺序表，对它插入word将都是有序的，且可以进行二分查找。
<br>test.cpp文件为测试文件，作为程序调试的测试文件，需要在100行至200行左右的源代码，关键词量在100以内。测试完成后，将随机测试任何.cpp或.h文件。
<br>main.cpp文件为主函数文件，它将集成整个程序的运行。它主要负责程序的交互与运行逻辑，必要时调用其他文件。
<br><br>测试文件为广义表的主体文件，总体量为165行，关键词数64。具体代码如下：<br>#include&lt;iostream&gt;  
#include&lt;iostream&gt;  
using namespace std;  
template&lt;class T&gt;  
#define LIST 1  
#define ATOM 0  
class GList {  
    struct GListNode{  
        bool type;  
        union{  
            T data;  
            GListNode *sublist;  
        };  
        GListNode*next;  
    };  
    GListNode *head;  
    GListNode* Creat(char s[],int &amp;i) {  
        GListNode *p;  
        while(s[i]==' '||s[i]==','){  
            i++;  
        }  
        char e=s[i];  
        i++;  
        //终止条件  
        if(e==')'||e=='\0') return NULL;  
                //处理当前节点  
        //子表  
        if(e=='('){  
            p=new GListNode;  
            p-&gt;type=LIST;  
            p-&gt;sublist=Creat(s,i);  
        }  
        //原子  
        else{  
            p=new GListNode;  
            p-&gt;type=ATOM;  
            p-&gt;data=e;  
        }  
                //处理p之后的元素  
        p-&gt;next=Creat(s,i);  
        return p;  
    }  
    void Delete(GListNode *p){  
        if(p==NULL) return;  
        GListNode *tmp=p-&gt;next;  
        if(p-&gt;type==ATOM){  
            delete p;  
        }  
        else{  
            Delete(p-&gt;sublist);  
            delete p;  
        }  
        Delete(tmp);  
    }  
    int deep(GListNode*p){  
        if(p-&gt;type==ATOM) return 0;  
        int maxdepth=0;  
        GListNode *q;  
        q=p-&gt;sublist;  
        while(q){  
            int depth=deep(q);  
            if(depth&gt;maxdepth)  
                maxdepth=depth;  
            q=q-&gt;next;  
        }  
        return maxdepth+1;//因为递归操作，这里返回的不一定是最终结果，+1操作是加上了本层的深度。没有则深度一直为0。  
    }  
    void extract(string &amp;s,GListNode *p){  
        if(p==NULL) {  
            s.push_back(')');  
            return;  
        }  
        if(p-&gt;type==LIST){  
            s.push_back('(');  
            extract(s,p-&gt;sublist);  
        }  
        if(p-&gt;type==ATOM){  
            s.push_back(p-&gt;data);  
            if(p-&gt;next!=NULL)  
                s.push_back(',');  
        }  
        extract(s,p-&gt;next);  
        return;  
    }  
    void ppop(T x,GListNode*p,GListNode*q){  
        if(p==NULL) {  
            return;  
        }  
        if(p-&gt;type==LIST){  
            ppop(x,p-&gt;sublist,p);  
        }  
        if(p-&gt;type==ATOM){  
            if(p-&gt;data==x){  
                if(q-&gt;type==ATOM){  
                    q-&gt;next=p-&gt;next;  
                    delete p;  
                    p=q-&gt;next;  
                }  
                else{  
                    q-&gt;sublist=p-&gt;next;  
                    delete p;  
                    p=q-&gt;sublist;  
                }  
            }  
        }  
        ppop(x,p-&gt;next,p);  
        return;  
    }  
    void change(GListNode*p,T aim,T x){  
        if(p==NULL)return;  
        if(p-&gt;type==ATOM){  
            if(p-&gt;data==x){  
                p-&gt;data=aim;  
            }  
        }  
        else change(p-&gt;sublist,aim,x);  
        change(p-&gt;next,aim,x);  
        return;  
    }  
public:  
    GList(char s[]=nullptr){  
        int i=0;  
        head=Creat(s,i);  
    }  
    ~GList() {  
        Delete(head);  
    }  
    int length() {  
        GListNode *p;  
        p=head-&gt;sublist;  
        int length=0;  
        while(p){  
            p=p-&gt;next;  
            length++;  
        }  
        return length;  
    }  
    int  depth(){  
        return deep(head);  
    }  
    bool equal(GList&amp; a){  
        string tmp;  
        string other;  
        tmp.pop_back();  
        other.pop_back();  
        extract(tmp,head);  
        extract(other,a.head);  
        return tmp==other;  
    }  
    void pop(T x){  
        ppop(x,head-&gt;sublist,head);  
    }  
    void print(){  
        string a;  
        extract(a,head);  
        a.pop_back();  
        cout&lt;&lt;a&lt;&lt;endl;  
    }  
    void exchange(T aim,T x){  
        change(head-&gt;sublist,aim,x);  
    }  
};
<br>结果展示：<br>总关键词数量：64
请输入您要搜索的关键词:include
查找结果:
该关键词出现频度:2
Hash查找次数:0
二分查找次数:6

请输入您要搜索的关键词:print
查找结果:
该关键词出现频度:1
Hash查找次数:23
二分查找次数:6

请输入您要搜索的关键词:GList
查找结果:
该关键词出现频度:4
Hash查找次数:0
二分查找次数:4

请输入您要搜索的关键词:return
查找结果:
该关键词出现频度:14
Hash查找次数:4
二分查找次数:6

请输入您要搜索的关键词:sjfoia
未找到该关键词
<br><br><br>
<br>对于解决具体问题的能力有了一定提升。
<br>对于C++一些具体操作更加熟练，比如fstream文件流操作、vector插入操作、string的比较操作。
<br>对哈希技术和二分查找技术在实际应用中的优势与弱势有了更深入的理解。
<br><br>哈希技术是一种非常强大的数据结构和算法，它提供了非常快的（理论上是常数时间的）查找、插入和删除操作。在这个问题中，我用哈希视为词典来存储源程序中的关键词，每个关键词和它出现的频率做为一对键值对存储。这样，我只需要扫描源程序一次，每找到一个关键词就更新哈希表中对应项的频率，如果关键词尚未在哈希表中，就将其添加进去。线性探测法用来解决哈希冲突的问题，当两个关键词的哈希值相同，就寻找下一个空的哈希地址，这虽然会增加查找和插入的时间复杂度，但我发现在实际操作中影响并不大。<br>对于二分查找与顺序表结合的方法，虽然在数据量非常大的时候，二分查找相较于顺序查找对效率的提升更加明显。而且，二分查找要求顺序表中的关键词必须是有序的，这意味着在新的关键词插入时都需要进行排序，这无疑增加了额外的处理开销，尤其在插入的关键词非常多的时候。因此，在这种情况下，哈希表的优势就体现出来了，它无需在新的关键词插入时进行排序，大大提高了程序的运行效率。<br>通过处理这个问题，我更深入地理解了不同查找技术适用不同实际应用的场景，哈希技术适合处理大数据并且无序的情况，而二分查找更适合处理量较小而且有序的情况。它们各有优张和短处，能灵活运用并能根据实际应用场景选择最优的查找技术是非常重要的。总的来说，这个问题让我对这两种技术有了更深入的理解和实践，相信未来我在面对类似问题时会更有信心和能力去处理。<br><br>hash表建构时的存储代码 <br>    void storage(string word) {  
        int adress = (word[0] * 100 + word.back()) % size;  
        int start = adress;  
                do {  
            // 如果找到相同的词条，增加其频次并返回  
            if (Hashtable[adress].flag == HashItem::ACTIVE &amp;&amp; Hashtable[adress].key == word) {  
                Hashtable[adress].num++;  
                return;  
            }  
            // 如果找到空闲的哈希地址，存储新的词条并返回  
            if (Hashtable[adress].flag == HashItem::EMPTY) {  
                Hashtable[adress].key = word;  
                Hashtable[adress].num++;  
                Hashtable[adress].flag = HashItem::ACTIVE;  
                return;  
            }  
            // 如果哈希地址已被其他词条占据，检查下一个哈希地址  
            adress = (adress + 1) % size;  
        } while (adress != start);  // 如果全部哈希地址都已检查过，退出循环  
                // 如果哈希表已满，无法存储新的词条，可以选择抛出异常或返回错误信息  
        throw std::runtime_error("Hashtable is full");  
    }
<br>hash表查找代码<br>pair&lt;int,int&gt; find(string word){  
        int adress=(word[0]*100+word.back())%size;  
        int tmp=adress;bool flag=true;int count=0;  
        while(word!=Hashtable[adress].key){  
            adress=(adress+1)%size;  
            count++;  
            if(adress==tmp) {  
                flag=false;break;  
            }  
        }  
        pair&lt;int,int&gt;res;  
        if(flag==true){  
            res.first=Hashtable[adress].num;  
            res.second=count;  
            return res;  
        }  
        else  
        {  
            res.first=-1;  
            res.second=-1;  
            return res;  
        }  
    }
<br>Seq存储代码<br>void stroage(string word) {  
        if (Seq.empty()) {  
            Seq.push_back({1, word});  
            return;  
        }  
        int left=0;int right=Seq.size()-1;bool flag=false;  
        while(left&lt;right&amp;&amp;!Seq.empty()){  
            int mid=(left+right)/2;  
            if(word&lt;Seq[mid].key){  
                right=mid;  
            }  
            if(word&gt;Seq[mid].key){  
                left=mid+1;  
            }  
            if(word==Seq[mid].key){  
                flag=true;  
                Seq[mid].num++;  
                break;  
            }  
        }  
        if (flag == false) {  
            Item tmp;  
            tmp.key=word;  
            tmp.num=1;  
            if (left == int(Seq.size()) || Seq[left].key&gt;=word) {  
                Seq.insert(Seq.begin()+left,tmp);  
            } else {  
                Seq.insert(Seq.begin()+left+1,tmp);  
            }  
        }  
    }
<br>二分查找代码<br>pair&lt;int,int&gt; find(string keyword){  
        int left=0;int right=Seq.size()-1;int count=0;  
        while(left&lt;right&amp;&amp;!Seq.empty()){  
            int mid=(left+right)/2;count++;  
            if(keyword&lt;Seq[mid].key){  
                right=mid;  
            }  
            if(keyword&gt;Seq[mid].key){  
                left=mid+1;  
            }  
            if(keyword==Seq[mid].key){  
                pair&lt;int,int&gt; res;  
                res.first=Seq[mid].num;  
                res.second=count;  
                return res;  
            }  
        }  
        pair&lt;int,int&gt;res;  
        res.first=-1;  
        res.second=-1;  
        return res;  
    }
<br>主函数逻辑代码<br>int main(){  
        string filepath;//filepath为接下来用户输入的文件地址  
    cout&lt;&lt;"请输入您的文件地址:";  
    getline(cin, filepath);  
        ifstream file(filepath);//打开文件，这里使用ifstream构造函数，构造文件流输入操作file，且将它链接到filepath这个文件地址上，即打开filepath  
        if (file.fail()) {  
        cerr &lt;&lt; "未能打开文件" &lt;&lt; endl;  
        return 1;  
    }            Hash hashtable;//构建hash表  
    Seqlist seqlist;//构建顺序表            string line;//用来存储文件中读入的行信息  
  
    while(getline(file,line)){  
        int i=0;string word;bool flag=false;  
        cout&lt;&lt;line&lt;&lt;endl;  
        while(i&lt;int(line.size())){  
            if(('a'&lt;=line[i]&amp;&amp;line[i]&lt;='z')||('A'&lt;=line[i]&amp;&amp;line[i]&lt;='Z')){  
                flag=true;  
                word.push_back(line[i]);  
                i++;  
                continue;  
            }  
            if(flag==true){  
                //存储word并清空word  
                hashtable.storage(word);  
                seqlist.stroage(word);  
                word.clear();  
            }  
            flag=false;  
            i++;//如果是false则是连续的空格或符号则只用i++即可  
        }  
    };//具体对每一行进行操作  
    cout&lt;&lt;"总关键词数量："&lt;&lt;seqlist.size()&lt;&lt;endl;  
    char answer='y';  
    while(answer=='y'){  
        cout&lt;&lt;"请输入您要搜索的关键词:";  
        string keyword;  
        cin&gt;&gt;keyword;  
        //两种查找方式进行查找，并返回查找次数，返回该关键词出现的次数  
        pair&lt;int,int&gt;res1=hashtable.find(keyword);  
        pair&lt;int,int&gt;res2=seqlist.find(keyword);  
        if(res1.first==-1||res2.first==-1){  
            cout&lt;&lt;"未找到该关键词"&lt;&lt;endl;  
        }  
        else{  
            cout&lt;&lt;"查找结果:"&lt;&lt;endl;  
            cout&lt;&lt;"该关键词出现频度:"&lt;&lt;res1.first&lt;&lt;endl;  
            cout&lt;&lt;"Hash查找次数:"&lt;&lt;res1.second&lt;&lt;endl;  
            cout&lt;&lt;"二分查找次数:"&lt;&lt;res2.second&lt;&lt;endl;  
        }  
                cout&lt;&lt;"是否继续查找?[y/n] ";  
        cin&gt;&gt;answer;  
    }  
            file.close();//关闭文件  
        return 0;  
    }
]]></description><link>technology\collegeproject\数据结构\数据结构实验二.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/数据结构实验二.md</guid><pubDate>Tue, 27 Feb 2024 03:45:15 GMT</pubDate></item><item><title><![CDATA[数据结构实验一]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> 
 <br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a> <br><br>编程实现希尔、快速、堆排序、归并排序算法。要求随机产生10000个数据存入磁盘文件，然后读入数据文件，分别采用不同的排序方法进行排序，并将结果存入文件中。<br><br>
<br>希尔排序：本质是将待排序序列划分为若干小序列，在这些小序列中进行插入排序，然后逐步扩大小序列长度，减少小序列个数。
<br>快速排序：本质是从待排序序列中选择一个中间值k，通过partition操作将小于k的序列放到k之前，大于k的放到k之后，然后不断对子序列进行划分操作，本质是分治思想。
<br>堆排序：本质是改进的选择排序。主要过程是将无序序列构造成堆，然后不断将堆顶元素取走，剩下的元素重新建堆，相当于把前一次的比较结果通过堆结构保留下来，以减少关键词比较次数。
<br>归并排序：本质是将两个有序序列进行归并，则可以通过递归排序两个子序列，再将子序列归并为一个有序序列。
<br><br>
<br>main.cpp中需要有这几个函数，随机数生成器，文件生成器。
<br>Sort.h中包含所有的排序函数。
<br><br>排序过程中，随机生成的数据储存在random_numbers.txt文件中，排完序的数据分别储存在各自排序名称命名的txt文件中。<br>关于不同排序算法运行速度进行了测试，结果如下：<img alt="Pasted image 20240228171022.png" src="\lib\media\pasted-image-20240228171022.png"><br>
总体而言快速排序为速度最快的排序算法。<br><br>我对四种排序算法——希尔排序、快速排序、堆排序和归并排序有了更加深入的理解。通过亲自编程实现，我不仅强化了我对这些算法原理的理解，还了解到了它们的具体实现细节。<br>
对于希尔排序，我认识到增量选择的重要性。在这次实践中，我了解到折半选择增量的效果较好，能使得元素尽可能地选择在正确的位置上。<br>
快速排序的实现让我体会到了分治算法的魅力。只需简单的一次划分，便可将问题简化，大大减少了排序的复杂度。<br>
堆排序则向我展示了完全二叉树在排序中的应用，也体现了一切皆可以为算法的理念。<br>
归并排序则是典型的自下而上的解决问题的思维模式，首先解决小规模问题，然后再合并最终结果。<br>
此外，通过在文件中读取和写入数据，我掌握了如何利用C++进行文件操作，了解了磁盘IO对程序效率的影响。<br>
我还进一步增强了自己的编程能力，如何设计和组织代码，以及如何分析和处理出现的问题。<br><br><br>//希尔排序  
void ShellSort(int n,int a[]){//希尔排序的本质就是把插入排序分成几部分，通过不断缩小d来使分组越来越多。即在插入排序外面套一个d的循环  
    for(int d=n/2;d&gt;=1;d=d/2){  
        for(int i=d;i&lt;n;i++){//从d开始是因为0到d-1是每一组里的第一个，不需要排，之后的每一个元素都要遍历到  
            int tmp=a[i];  
            int j=i-d;  
            for(;j&gt;=0&amp;&amp;tmp&lt;a[j];j-=d){  
                a[j+d]=a[j];  
            }  
            a[j+d]=tmp;  
        }  
    }  
}
<br><br>//快速排序  
void Quick_Sort(int q[],int l,int r)  
{  
    if(l&gt;=r){  
        return;  
    }  
    int x=q[(l+r)/2],i=l-1,j=r+1;  
    while(i&lt;j)  
    {  
        do i++;while(q[i]&lt;x);  
        do j--;while(q[j]&gt;x);  
        if(i&lt;j){  
            int temp=q[i];  
            q[i]=q[j];  
            q[j]=temp;  
        }        }  
    Quick_Sort(q,l,j);  
    Quick_Sort(q,j+1,r);  
}  
  
void quick_sort(int n,int a[]){  
    Quick_Sort(a,0,n-1);  
}
<br><br>//堆排序  
void Shift(int m,int k,int a[]){//m为当前堆最大下标，k为要筛选的节点，大顶堆-&gt;得到从小到大的排序  
    int i=k;  
    int j=2*i;  
    while(j&lt;=m){  
        if(j&lt;m&amp;&amp;a[j]&lt;a[j+1]) j++;//j&lt;m防止越界，如果j==m即j为最后一位，不需要再j++  
        if(a[j]&lt;=a[i])break;  
        else{  
            swap(a[i],a[j]);  
            i=j;  
            j=2*i;  
        }  
    }  
}//shift函数本质上是从根节点，从上到下的比较过程

void HeapSort(int n,int a[]){  
    for(int i=n/2;i&gt;=0;i--){  
        Shift(n,i,a);  
    }//构造无序堆  
    int length=n-1;  
    while(length){  
        swap(a[length],a[0]);  
        length--;  
        Shift(length,0,a);  
    }//筛选  
}
<br><br>//归并排序  
void Merge(int a[], int start, int mid, int end) {  
    int left_length = mid - start + 1;  
    int right_length = end - mid;  
    int* left = new int[left_length];  
    int* right = new int[right_length];  
        //复制数据到子数组中  
    for (int i = 0; i &lt; left_length; i++)         left[i] = a[start + i];  
    for (int i = 0; i &lt; right_length; i++)  
        right[i] = a[mid + 1 + i];  
        // 归并至目标数组  
    int i = 0;  
    int j = 0;  
    int k = start;  
    while (i &lt; left_length &amp;&amp; j &lt; right_length) {  
        if (left[i] &lt;= right[j])  
            a[k++] = left[i++];  
        else  
            a[k++] = right[j++];  
    }  
        // 复制剩余的元素  
    while(i&lt;left_length)  
        a[k++] = left[i++];  
    while(j&lt;right_length)  
        a[k++] = right[j++];  
        // 清理内存  
    delete[] left;  
    delete[] right;  
}  
  
void merge_sort(int a[], int start, int end) {  
    if(start&lt;end){  
        int mid = start + (end - start) / 2;//防溢出  
        merge_sort(a, start, mid);  
        merge_sort(a, mid+1, end);  
        Merge(a, start, mid, end);  
    }  
}

void MergeSort(int n,int a[]){  
    merge_sort(a,0,n-1);  
}
]]></description><link>technology\collegeproject\数据结构\数据结构实验一.html</link><guid isPermaLink="false">Technology/CollegeProject/数据结构/数据结构实验一.md</guid><pubDate>Wed, 28 Feb 2024 09:20:56 GMT</pubDate><enclosure url="lib\media\pasted-image-20240228171022.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240228171022.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验3：工厂场景的管理信息系统（MIS）设计]]></title><description><![CDATA[ 
 <br><br>1．	熟悉数据库设计的基本步骤和流程、熟练掌握ER模型设计工具。<br>
2．	体会数据模型和数据模式在数据库设计中的作用，以及与数据库管理系统之间的关系。<br><br>
<br>WSL2操作系统
<br>数据库管理系统PostgreSQL
<br>ER设计工具：EZDML
<br><br><br>假设某工厂有各种零件加工业务。每种零件有编号、名称、单价、类型等信息。工厂根据每一次工程的需要，从不同的供应商处批发零件。这些供应商和工厂长期合作，因此工厂有他们的名称、地址、电话等信息。每次批发都有一定的进货量。零件平时存放在各个仓库中，仓库有库房号、地址等信息。每个仓库都有一些职工，这些职工有职工号、姓名、性别、进厂时间以及不同的职称，每个仓库都设置了一个职工为组长，负责本仓库职工的管理。<br>
进行需求分析是软件开发过程中的重要步骤，它帮助我们明确系统的目标、功能和需求。对于您描述的工厂零件加工业务，我们将从以下几个方面进行需求分析：<br><br><br>
<br>零件信息管理：记录每种零件的编号、名称、单价、类型等信息。
<br>零件查询：根据零件编号、名称、类型等条件查询零件信息。
<br>零件维护：添加、修改、删除零件信息。
<br><br>
<br>供应商信息管理：记录供应商的编号、名称、地址、电话等信息。
<br>供应商查询：根据供应商编号、名称等条件查询供应商信息。
<br>供应商维护：添加、修改、删除供应商信息。
<br><br>
<br>进货记录管理：记录每次进货的编号、零件编号、供应商编号、进货日期、进货数量等信息。
<br>进货查询：根据进货编号、零件编号、供应商编号、进货日期等条件查询进货记录。
<br>进货维护：添加、修改、删除进货记录。
<br><br>
<br>仓库信息管理：记录仓库的编号、地址等信息。
<br>仓库查询：根据仓库编号、地址等条件查询仓库信息。
<br>仓库维护：添加、修改、删除仓库信息。
<br><br>
<br>职工信息管理：记录职工的编号、姓名、性别、进厂时间、职称等信息。
<br>职工查询：根据职工编号、姓名、职称等条件查询职工信息。
<br>职工维护：添加、修改、删除职工信息。
<br>组长管理：指定每个仓库的组长，负责本仓库职工的管理。
<br><br><br>
<br>识别实体：确定系统中需要管理的主要对象。
<br>识别属性：确定每个实体的属性。
<br>识别关系：确定实体之间的关系。
<br>绘制实体关系图（ER图）：使用图形化的方式展示实体、属性和关系。
<br><br>
<br>零件 (Parts)
<br>供应商 (Suppliers)
<br>进货记录 (Purchases)
<br>仓库 (Warehouses)
<br>职工 (Employees)
<br><br><br>
<br>PartID (零件编号)
<br>Name (名称)
<br>Price (单价)
<br>Type (类型)
<br><br>
<br>SupplierID (供应商编号)
<br>Name (名称)
<br>Address (地址)
<br>Phone (电话)
<br><br>
<br>PurchaseID (进货编号)
<br>PartID (零件编号)
<br>SupplierID (供应商编号)
<br>PurchaseDate (进货日期)
<br>Quantity (进货数量)
<br><br>
<br>WarehouseID (仓库编号)
<br>Address (地址)
<br>SupervisorID (组长编号)
<br><br>
<br>EmployeeID (职工编号)
<br>Name (姓名)
<br>Gender (性别)
<br>JoinDate (进厂时间)
<br>Title (职称)
<br>WarehouseID (所属仓库编号)
<br><br><br>
<br>进货记录：零件和供应商之间通过进货记录表建立关系。
<br><br>
<br>职工管理：每个仓库有一个组长，负责管理该仓库的职工。
<br><br>下面是一个简化的ER图，展示了各个实体及其关系：<br>+----------------+          +-----------------+          +----------------+
|     Parts      |          |   Suppliers     |          |   Purchases    |
|----------------|          |-----------------|          |----------------|
| PartID (PK)    |          | SupplierID (PK) |          | PurchaseID (PK)|
| Name           |          | Name            |          | PartID (FK)    |
| Price          |          | Address         |          | SupplierID (FK)|
| Type           |          | Phone           |          | PurchaseDate   |
+----------------+          +-----------------+          | Quantity       |
        |                             |                  +----------------+
        |                             |                           |
        +-----------------------------+--------------------------+
                                      |
                                      v
                              +-----------------+
                              |   Warehouses    |
                              |-----------------|
                              | WarehouseID (PK)|
                              | Address         |
                              | SupervisorID (FK)|
                              +-----------------+
                                      |
                                      v
                              +-----------------+
                              |   Employees     |
                              |-----------------|
                              | EmployeeID (PK) |
                              | Name            |
                              | Gender          |
                              | JoinDate        |
                              | Title           |
                              | WarehouseID (FK)|
                              +-----------------+
<br><br>
<br>
零件 (Parts)：

<br>PartID：主键，唯一标识每个零件。
<br>Name：零件的名称。
<br>Price：零件的单价。
<br>Type：零件的类型。


<br>
供应商 (Suppliers)：

<br>SupplierID：主键，唯一标识每个供应商。
<br>Name：供应商的名称。
<br>Address：供应商的地址。
<br>Phone：供应商的电话。


<br>
进货记录 (Purchases)：

<br>PurchaseID：主键，唯一标识每次进货记录。
<br>PartID：外键，引用零件表的主键。
<br>SupplierID：外键，引用供应商表的主键。
<br>PurchaseDate：进货日期。
<br>Quantity：进货数量。


<br>
仓库 (Warehouses)：

<br>WarehouseID：主键，唯一标识每个仓库。
<br>Address：仓库的地址。
<br>SupervisorID：外键，引用职工表的主键，表示仓库的组长。


<br>
职工 (Employees)：

<br>EmployeeID：主键，唯一标识每个职工。
<br>Name：职工的姓名。
<br>Gender：职工的性别。
<br>JoinDate：职工的进厂时间。
<br>Title：职工的职称。
<br>WarehouseID：外键，引用仓库表的主键，表示职工所属的仓库。


<br><br><br><img alt="Pasted image 20241110100115.png" src="\lib\media\pasted-image-20241110100115.png"><br><br><br>使用 service 命令<br>
<br>
启动 PostgreSQL 服务：
sudo service postgresql start


<br>
检查 PostgreSQL 服务状态：
sudo service postgresql status


<br>
重启PostgreSQL服务:
sudo service postgresql restart


<br><br>
<br>
切换到 PostgreSQL 用户：
sudo -i -u postgres


<br>
创建数据库用户：
createuser -P your_username


<br>按提示输入密码。


<br>
创建数据库：
createdb -O your_username factory_management


<br>
退出 PostgreSQL 用户：
exit


<br><br>
<br>
连接到 PostgreSQL 数据库：
psql -U your_username -d factory_management

ps:如果失败则请配置pg_hba.conf文件，修改其中的peer权限验证为md5即可

<br>
创建表：
-- 创建零件表
CREATE TABLE Parts (
    PartID SERIAL PRIMARY KEY,
    Name VARCHAR(100) NOT NULL,
    Price DECIMAL(10, 2) NOT NULL,
    Type VARCHAR(50)
);

-- 创建供应商表
CREATE TABLE Suppliers (
    SupplierID SERIAL PRIMARY KEY,
    Name VARCHAR(100) NOT NULL,
    Address TEXT,
    Phone VARCHAR(20)
);

-- 创建进货记录表
CREATE TABLE Purchases (
    PurchaseID SERIAL PRIMARY KEY,
    PartID INT REFERENCES Parts(PartID),
    SupplierID INT REFERENCES Suppliers(SupplierID),
    PurchaseDate DATE NOT NULL,
    Quantity INT NOT NULL
);

-- 创建仓库表
CREATE TABLE Warehouses (
    WarehouseID SERIAL PRIMARY KEY,
    Address TEXT,
    SupervisorID INT
);

-- 创建职工表
CREATE TABLE Employees (
    EmployeeID SERIAL PRIMARY KEY,
    Name VARCHAR(100) NOT NULL,
    Gender CHAR(1),
    JoinDate DATE NOT NULL,
    Title VARCHAR(50),
    WarehouseID INT REFERENCES Warehouses(WarehouseID)
);

-- 添加外键约束到仓库表
ALTER TABLE Warehouses
ADD CONSTRAINT fk_supervisor
FOREIGN KEY (SupervisorID) REFERENCES Employees(EmployeeID);


<br><br>
<br>
插入零件数据
INSERT INTO Parts (Name, Price, Type) VALUES
('螺丝', 0.10, '紧固件'),
('螺母', 0.15, '紧固件'),
('轴承', 1.50, '机械部件');


<br>
插入供应商数据
INSERT INTO Suppliers (Name, Address, Phone) VALUES
('供应商A', '上海市浦东新区', '1234567890'),
('供应商B', '北京市朝阳区', '0987654321');


<br>
插入进货记录数据
INSERT INTO Purchases (PartID, SupplierID, PurchaseDate, Quantity) VALUES
(1, 1, '2023-10-01', 1000),
(2, 2, '2023-10-02', 500),
(3, 1, '2023-10-03', 200);


<br>
插入职工数据
INSERT INTO Employees (Name, Gender, JoinDate, Title, WarehouseID) VALUES
('张三', 'M', '2020-01-01', '组长', 1),
('李四', 'F', '2021-02-01', '员工', 1),
('王五', 'M', '2022-03-01', '员工', 2);


<br>
插入仓库数据
INSERT INTO Warehouses (Address, SupervisorID) VALUES
('仓库A地址', 1),
('仓库B地址', 2);


<br><br>
<br>
查询零件数据
SELECT * FROM Parts;

<img alt="{CD84AA70-8DEF-4DA3-B08B-58881467AA2A}.png" src="\lib\media\{cd84aa70-8def-4da3-b08b-58881467aa2a}.png">

<br>
查询供应商数据
SELECT * FROM Suppliers;

<img alt="{F3077D95-EE78-4389-B87E-8FE041D97379}.png" src="\lib\media\{f3077d95-ee78-4389-b87e-8fe041d97379}.png">

<br>
查询进货记录数据
SELECT * FROM Purchases;

<img alt="{66CE0F97-8D00-40A8-8C2A-1532A3294944}.png" src="\lib\media\{66ce0f97-8d00-40a8-8c2a-1532a3294944}.png">

<br>
查询职工数据
SELECT * FROM Employees;

<img alt="{12115291-1DD0-4E2D-A6EE-8A7F59655141}.png" src="\lib\media\{12115291-1dd0-4e2d-a6ee-8a7f59655141}.png">

<br>
查询仓库数据
SELECT * FROM Warehouses;

<img alt="{4041D4A7-1BA6-4423-AFA5-5D995A5D60F2}.png" src="\lib\media\{4041d4a7-1ba6-4423-afa5-5d995a5d60f2}.png">

<br><br><br>这个问题造成了外键不匹配报错。<br>
<img alt="{68704BCF-4DA6-4505-9F5A-82929F25166B}.png" src="\lib\media\{68704bcf-4da6-4505-9f5a-82929f25166b}.png"><br>
Employeeid出现了问题，从7开始。<br>
我们将seq重置为1，可以发现恢复了正常。<br>
<img alt="{F9F7AD64-8969-406A-A011-EA314D7C96BD}.png" src="\lib\media\{f9f7ad64-8969-406a-a011-ea314d7c96bd}.png"><br><br><img alt="{6176495C-F7F9-484B-88C6-57D4B992AA97}.png" src="\lib\media\{6176495c-f7f9-484b-88c6-57d4b992aa97}.png"><br>
建好的数据库无法访问的问题。<br> sudo vim /etc/postgresql/12/main/pg_hba.conf
<br>验证方法从peer改为md5即可<br>
<img alt="{27CEE009-0A12-4B1D-BC87-573E61C029B0}.png" src="\lib\media\{27cee009-0a12-4b1d-bc87-573e61c029b0}.png">]]></description><link>technology\collegeproject\数据库\实验3：工厂场景的管理信息系统（mis）设计.html</link><guid isPermaLink="false">Technology/CollegeProject/数据库/实验3：工厂场景的管理信息系统（MIS）设计.md</guid><pubDate>Thu, 12 Dec 2024 08:13:11 GMT</pubDate><enclosure url="lib\media\pasted-image-20241110100115.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241110100115.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验4：工厂场景的管理信息系统（MIS）设计与开发]]></title><description><![CDATA[ 
 <br><br><br>1． 熟悉数据库设计与开发的基本步骤和流程。<br>2． 熟练掌握数据库开发语言与工具。<br>3． 体会数据模型和数据模式在数据库设计中的作用，以及与数据库管理系统之间的关系。<br><br>
<br>
Linux操作系统

<br>
Python语言

<br>
数据库管理系统PostgreSQL

<br>
ER设计工具（如EZDML，<a rel="noopener nofollow" class="external-link" href="http://www.ezdml.com/" target="_blank">http://www.ezdml.com/</a>）。

<br><br>实验3中，假设某工厂有各种零件加工业务。零件从不同的供应商处进货，存放在各个仓库中，每个仓库都有一些职工，这些职工有不同的职称，每个仓库都有一个职工是负责人。<br>阅读“图书借阅系统数据库设计.pdf”，仿照图书管理系统，完成工厂场景下，数据库管理系统设计与开发的全过程。<br>
<br>
具有图形化的用户交互界面。

<br>
实现完整的业务功能。

<br>
可以粘贴必要的关键代码，但不要粘贴大段过多的代码。

<br><br>（1）独立完成，严禁相互抄袭（如有发现抄袭和被抄袭均判为0分），以及从网络上直接摘抄别人的观点和总结（该行为将影响报告成绩）。<br>（2）实验报告符合学术写作的排版要求，请参考群文件中的“报告模板.docx”和“参考文献格式.docx”的排版格式。<br>（3）实验报告内容详实，采用图文混合的方式叙述安装和配置过程。<br>Tip：Win+Shift+S 在Windows中可以快速截屏。<br>（4）报告文件见附件，提交报告时请以附件形式插入到超星作业中。<br><br>报告标题：工厂场景的管理信息系统（MIS）设计与开发<br>学号：19220423<br>姓名：李世博<br>日期：2024/11/26<br><br>
<br>操作系统：
<br>WSL<br>
<br>数据库管理软件（含版本号）：
<br>psql (PostgreSQL) 12.20 (Ubuntu 12.20-0ubuntu0.20.04.1)<br>
<br>设计与开发工具：
<br>PostgreSQL，Python，EZDML<br><br>为了实现一个基于PostgreSQL的MIS（管理信息系统）功能表设计，我们首先需要设计一个数据库模型来存储零件、供应商、仓库、职工等信息。然后，我们可以通过Python与PostgreSQL进行交互，实现相应的功能。以下是系统的功能表设计和相关实现思路。<br><br>基于上述数据库表结构，MIS系统可以包括以下基本功能模块：<br>
<br>零件管理

<br>添加、删除、修改零件信息
<br>查询零件信息（按编号、名称、类型等）


<br>供应商管理

<br>添加、删除、修改供应商信息
<br>查询供应商信息（按供应商名称、地址等）


<br>仓库管理

<br>添加、删除、修改仓库信息
<br>查询仓库信息（按仓库名称、地址等）


<br>职工管理

<br>添加、删除、修改职工信息
<br>查询职工信息（按职工编号、姓名、性别等）
<br>查询仓库组长（即is_manager字段）


<br>进货管理

<br>添加进货记录（零件、数量、供应商）
<br>查询进货记录（按零件、供应商、日期等）


<br>库存管理

<br>查询某仓库的零件库存
<br>更新零件库存


<br>![Image_903380691070490_edit_903398740001108](D:/QQ file/Downloads/Image_903380691070490_edit_903398740001108.png)<br><br>首先，设计数据库表结构。以下是一些基本的表结构：<br><br>用于存储零件的基本信息。<br>CREATE TABLE parts (
    part_id SERIAL PRIMARY KEY,  -- 零件编号
    part_name VARCHAR(100) NOT NULL,  -- 零件名称
    price DECIMAL(10, 2) NOT NULL,  -- 单价
    part_type VARCHAR(50),  -- 零件类型
    supplier_id INT REFERENCES suppliers(supplier_id)  -- 关联供应商
);
<br><br>用于存储供应商信息。<br>CREATE TABLE suppliers (
    supplier_id SERIAL PRIMARY KEY,  -- 供应商编号
    supplier_name VARCHAR(100) NOT NULL,  -- 供应商名称
    address VARCHAR(255),  -- 地址
    phone VARCHAR(20)  -- 电话
);
<br><br>用于存储仓库信息。<br>CREATE TABLE warehouses (
    warehouse_id SERIAL PRIMARY KEY,  -- 仓库编号
    warehouse_name VARCHAR(100) NOT NULL,  -- 仓库名称
    address VARCHAR(255)  -- 仓库地址
);
<br><br>用于存储职工信息。<br>CREATE TABLE employees (
    employee_id SERIAL PRIMARY KEY,  -- 职工编号
    name VARCHAR(100) NOT NULL,  -- 职工姓名
    gender VARCHAR(10),  -- 性别
    hire_date DATE NOT NULL,  -- 进厂时间
    title VARCHAR(50),  -- 职称
    warehouse_id INT REFERENCES warehouses(warehouse_id),  -- 关联仓库
    is_manager BOOLEAN DEFAULT FALSE  -- 是否为仓库组长
);
<br><br>用于记录批发进货信息。<br>CREATE TABLE purchases (
    purchase_id SERIAL PRIMARY KEY,  -- 进货编号
    part_id INT REFERENCES parts(part_id),  -- 关联零件
    supplier_id INT REFERENCES suppliers(supplier_id),  -- 关联供应商
    quantity INT NOT NULL,  -- 进货量
    purchase_date DATE NOT NULL  -- 进货日期
);
<br><br>用于记录仓库中的零件库存。<br>CREATE TABLE warehouse_stock (
    stock_id SERIAL PRIMARY KEY,  -- 库存记录编号
    warehouse_id INT REFERENCES warehouses(warehouse_id),  -- 关联仓库
    part_id INT REFERENCES parts(part_id),  -- 关联零件
    quantity INT NOT NULL  -- 库存数量
);
<br><br>在数据库中设置一个用户表，用来存储用户名、密码和角色信息。你可以使用一个简单的用户表 users，它包含以下字段：<br>CREATE TABLE users (
    user_id SERIAL PRIMARY KEY,
    username VARCHAR(50) NOT NULL,
    password VARCHAR(50) NOT NULL,
    role VARCHAR(20) NOT NULL -- 'manager' 或 'staff'
);

<br><img alt="image-20241126210703463" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126210703463.png" referrerpolicy="no-referrer"><br><br>使用Python与PostgreSQL进行交互时，可以使用psycopg2库。以下是安装和简单操作的步骤。<br><br>在Linux系统中，可以使用pip安装psycopg2库：<br>pip install psycopg2
<br><br>我们将设计一个包含以下模块的界面：<br>
<br>主界面（Main Window）

<br>导航菜单，选择不同的功能模块。


<br>登录界面
<br>零件管理界面（Parts Management）

<br>显示零件列表。
<br>添加、删除、修改零件。


<br>供应商管理界面（Suppliers Management）

<br>显示供应商列表。
<br>添加、删除、修改供应商。


<br>仓库管理界面（Warehouse Management）

<br>显示仓库列表。
<br>添加、删除、修改仓库。


<br><br>import tkinter as tk
from tkinter import messagebox
import psycopg2

# Connect to the database
def connect_db():
    try:
        conn = psycopg2.connect(dbname="factorymis", user="postgres", password="020222", host="localhost")
        return conn
    except Exception as e:
        messagebox.showerror("Error", f"Error connecting to database: {e}")
        return None

# User login check
def login(username, password):
    conn = connect_db()
    if conn:
        cursor = conn.cursor()
        cursor.execute("SELECT role FROM users WHERE username = %s AND password = %s", (username, password))
        result = cursor.fetchone()
        cursor.close()
        conn.close()
        if result:
            return result[0]  # Return the role: 'manager' or 'staff'
        else:
            return None
    return None

# 登录回调函数
def on_login(username, password, root):
    # 调用 login 函数进行数据库验证
    role = login(username, password)
    if role:
        messagebox.showinfo("Login Success", f"Welcome, {role.capitalize()}!")
        root.destroy()  # 销毁主窗口
        main_window(role)  # 打开主窗口，根据用户角色显示不同的操作界面
    else:
        messagebox.showerror("Login Failed", "Invalid credentials")

# 创建登录窗口
def login_window():
    root = tk.Tk()
    root.title("Login")
    
    tk.Label(root, text="Username").grid(row=0, column=0)
    username_entry = tk.Entry(root)
    username_entry.grid(row=0, column=1)
    
    tk.Label(root, text="Password").grid(row=1, column=0)
    password_entry = tk.Entry(root, show="*")
    password_entry.grid(row=1, column=1)
    
    login_button = tk.Button(root, text="Login", 
                             command=lambda: on_login(username_entry.get(), password_entry.get(), root))
    login_button.grid(row=2, column=0, columnspan=2)
    
    root.mainloop()

# Main window based on user role
def main_window(role):
    root = tk.Tk()
    root.title("Factory Management System")
    root.geometry("900x600")  # Set window size

    font = ('Noto Sans', 14)

    # Show options based on user role
    if role == 'manager':
        tk.Button(root, text="Parts Management", width=30, command=show_parts_window, font=font).pack(pady=20)
        tk.Button(root, text="Suppliers Management", width=30, command=show_suppliers_window, font=font).pack(pady=20)
        tk.Button(root, text="Warehouse Management", width=30, command=show_warehouse_window, font=font).pack(pady=20)
    elif role == 'staff':
        # For staff, only allow them to view their warehouse and personal info
        tk.Button(root, text="View My Information", width=30, command=view_staff_info, font=font).pack(pady=20)
        tk.Button(root, text="View My Warehouse", width=30, command=view_warehouse_for_staff, font=font).pack(pady=20)
    
    root.mainloop()
# Show Staff Information window
def view_staff_info():
    staff_info_window = tk.Toplevel()
    staff_info_window.title("My Information")

    def load_staff_info():
        conn = connect_db()
        if conn:
            cursor = conn.cursor()
            cursor.execute("SELECT username, full_name, position FROM users WHERE username = %s", ("staff_user",))  # Example staff user
            info = cursor.fetchone()
            cursor.close()
            conn.close()

            if info:
                tk.Label(staff_info_window, text=f"Username: {info[0]}").grid(row=0, column=0, padx=10, pady=5)
                tk.Label(staff_info_window, text=f"Full Name: {info[1]}").grid(row=1, column=0, padx=10, pady=5)
                tk.Label(staff_info_window, text=f"Position: {info[2]}").grid(row=2, column=0, padx=10, pady=5)
            else:
                messagebox.showwarning("No Data", "No information found for this user.")

    load_staff_info()

# Show Warehouse window for Staff
def view_warehouse_for_staff():
    warehouse_window = tk.Toplevel()
    warehouse_window.title("My Warehouse")

    def load_warehouse_info():
        conn = connect_db()
        if conn:
            cursor = conn.cursor()
            cursor.execute("SELECT w.warehouse_id, w.warehouse_name, w.location "
                           "FROM warehouses w JOIN users u ON w.warehouse_id = u.warehouse_id "
                           "WHERE u.username = %s", ("staff_user",))  # Example staff user
            warehouse_info = cursor.fetchone()
            cursor.close()
            conn.close()

            if warehouse_info:
                tk.Label(warehouse_window, text=f"Warehouse ID: {warehouse_info[0]}").grid(row=0, column=0, padx=10, pady=5)
                tk.Label(warehouse_window, text=f"Warehouse Name: {warehouse_info[1]}").grid(row=1, column=0, padx=10, pady=5)
                tk.Label(warehouse_window, text=f"Location: {warehouse_info[2]}").grid(row=2, column=0, padx=10, pady=5)
            else:
                messagebox.showwarning("No Data", "No warehouse information found for this user.")

    load_warehouse_info()

# Show Parts Management window
def show_parts_window():
    parts_window = tk.Toplevel()
    parts_window.title("Parts Management")

    def load_parts():
        conn = connect_db()
        if conn:
            cursor = conn.cursor()
            cursor.execute("SELECT part_id, part_name, price, part_type FROM parts")
            parts = cursor.fetchall()
            for row in parts:
                parts_listbox.insert(tk.END, row)
            cursor.close()
            conn.close()

    def delete_part():
        selected = parts_listbox.curselection()
        if selected:
            part_id = parts_listbox.get(selected[0])[0]
            conn = connect_db()
            if conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM parts WHERE part_id = %s", (part_id,))
                conn.commit()
                cursor.close()
                conn.close()
                parts_listbox.delete(selected[0])
                messagebox.showinfo("Success", "Part deleted successfully.")

    def add_part():
        part_name = part_name_entry.get()
        price = price_entry.get()
        part_type = part_type_entry.get()
        if part_name and price and part_type:
            conn = connect_db()
            if conn:
                cursor = conn.cursor()
                cursor.execute("INSERT INTO parts (part_name, price, part_type) VALUES (%s, %s, %s)", 
                               (part_name, price, part_type))
                conn.commit()
                cursor.close()
                conn.close()
                parts_listbox.delete(0, tk.END)
                load_parts()
                messagebox.showinfo("Success", "Part added successfully.")
        else:
            messagebox.showwarning("Input Error", "Please fill in all fields.")

    # Layout
    tk.Label(parts_window, text="Part Name").grid(row=0, column=0)
    tk.Label(parts_window, text="Price").grid(row=1, column=0)
    tk.Label(parts_window, text="Part Type").grid(row=2, column=0)

    part_name_entry = tk.Entry(parts_window)
    part_name_entry.grid(row=0, column=1)
    price_entry = tk.Entry(parts_window)
    price_entry.grid(row=1, column=1)
    part_type_entry = tk.Entry(parts_window)
    part_type_entry.grid(row=2, column=1)

    tk.Button(parts_window, text="Add Part", command=add_part).grid(row=3, column=0, columnspan=2)
    
    parts_listbox = tk.Listbox(parts_window, width=50, height=10)
    parts_listbox.grid(row=4, column=0, columnspan=2)
    tk.Button(parts_window, text="Delete Selected", command=delete_part).grid(row=5, column=0, columnspan=2)
    
    load_parts()

# Show Suppliers Management window
def show_suppliers_window():
    suppliers_window = tk.Toplevel()
    suppliers_window.title("Suppliers Management")

    def load_suppliers():
        conn = connect_db()
        if conn:
            cursor = conn.cursor()
            cursor.execute("SELECT supplier_id, supplier_name, contact_number, address FROM suppliers")
            suppliers = cursor.fetchall()
            for row in suppliers:
                suppliers_listbox.insert(tk.END, row)
            cursor.close()
            conn.close()

    def delete_supplier():
        selected = suppliers_listbox.curselection()
        if selected:
            supplier_id = suppliers_listbox.get(selected[0])[0]
            conn = connect_db()
            if conn:
                cursor = conn.cursor()
                cursor.execute("DELETE FROM suppliers WHERE supplier_id = %s", (supplier_id,))
                conn.commit()
                cursor.close()
                conn.close()
                suppliers_listbox.delete(selected[0])
                messagebox.showinfo("Success", "Supplier deleted successfully.")

    def add_supplier():
        supplier_name = supplier_name_entry.get()
        contact_number = contact_number_entry.get()
        address = address_entry.get()
        if supplier_name and contact_number and address:
            conn = connect_db()
            if conn:
                cursor = conn.cursor()
                cursor.execute("INSERT INTO suppliers (supplier_name, contact_number, address) VALUES (%s, %s, %s)", 
                               (supplier_name, contact_number, address))
                conn.commit()
                cursor.close()
                conn.close()
                suppliers_listbox.delete(0, tk.END)
                load_suppliers()
                messagebox.showinfo("Success", "Supplier added successfully.")
        else:
            messagebox.showwarning("Input Error", "Please fill in all fields.")

    # Layout
    tk.Label(suppliers_window, text="Supplier Name").grid(row=0, column=0)
    tk.Label(suppliers_window, text="Contact Number").grid(row=1, column=0)
    tk.Label(suppliers_window, text="Address").grid(row=2, column=0)

    supplier_name_entry = tk.Entry(suppliers_window)
    supplier_name_entry.grid(row=0, column=1)
    contact_number_entry = tk.Entry(suppliers_window)
    contact_number_entry.grid(row=1, column=1)
    address_entry = tk.Entry(suppliers_window)
    address_entry.grid(row=2, column=1)

    tk.Button(suppliers_window, text="Add Supplier", command=add_supplier).grid(row=3, column=0, columnspan=2)
    
    suppliers_listbox = tk.Listbox(suppliers_window, width=50, height=10)
    suppliers_listbox.grid(row=4, column=0, columnspan=2)
    tk.Button(suppliers_window, text="Delete Selected", command=delete_supplier).grid(row=5, column=0, columnspan=2)
    
    load_suppliers()

# Show Warehouse Management window
def show_warehouse_window():
    warehouse_window = tk.Toplevel()
    warehouse_window.title("Warehouse Management")

    def load_warehouse():
        conn = connect_db()
        if conn:
            cursor = conn.cursor()
            cursor.execute("SELECT warehouse_id, warehouse_name, location FROM warehouses")
            warehouses = cursor.fetchall()
            for row in warehouses:
                warehouse_listbox.insert(tk.END, row)
            cursor.close()
            conn.close()

    warehouse_listbox = tk.Listbox(warehouse_window, width=50, height=10)
    warehouse_listbox.grid(row=0, column=0, columnspan=2)
    
    load_warehouse()

# Run login window
if __name__ == "__main__":
    login_window()

<br><br>接下来，我们可以使用以下 SQL 语句插入一些示例用户数据。假设我们想添加一些管理员 (manager) 和普通员工 (staff) 用户。<br>INSERT INTO users (username, password, role) VALUES 
('admin1', 'password123', 'manager'),
('admin2', 'password456', 'manager'),
('staff1', 'password789', 'staff'),
('staff2', 'password101', 'staff');
<br>上述SQL语句将会插入4个用户，其中2个是管理员，2个是普通员工。<br><img alt="image-20241126210240024" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126210240024.png" referrerpolicy="no-referrer"><br><br><img alt="image-20241126212033283" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126212033283.png" referrerpolicy="no-referrer"><br><img alt="image-20241126212051337" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126212051337.png" referrerpolicy="no-referrer"><br><img alt="image-20241126212000767" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126212000767.png" referrerpolicy="no-referrer"><br><img alt="image-20241126212115259" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126212115259.png" referrerpolicy="no-referrer"><br><img alt="image-20241126212203974" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126212203974.png" referrerpolicy="no-referrer"><br><img alt="image-20241126212237742" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126212237742.png" referrerpolicy="no-referrer"><br><br>当然，总结实验中遇到的问题及其解决思路是非常重要的，这有助于改进系统并提高未来项目的成功率。以下是两个示例问题的总结：<br><br><br>在将供应商数据导入数据库时，发现有些供应商记录出现了重复，导致数据冗余和不一致。<br><br>
<br>原因：

<br>数据源中存在重复记录。
<br>导入过程中没有进行唯一性校验。
<br>数据清洗不彻底。


<br>难点：

<br>如何高效地检测和删除重复记录。
<br>如何在导入过程中自动防止重复记录的插入。


<br>挑战：

<br>数据量较大时，性能问题可能会成为一个瓶颈。
<br>需要确保数据的一致性和完整性。


<br><br>
<br>数据清洗：

<br>在导入前对数据源进行预处理，使用脚本或工具删除重复记录。
<br>使用SQL查询检测和删除重复记录，例如：
DELETE FROM Suppliers
WHERE supplier_id NOT IN (
    SELECT MIN(id)
    FROM Suppliers
    GROUP BY supplier_name, address, phone
);




<br>唯一性约束：

<br>在数据库表中添加唯一性约束，确保关键字段的唯一性。
ALTER TABLE Suppliers ADD CONSTRAINT unique_supplier UNIQUE (supplier_name, address, phone);




<br>批量导入时的校验：

<br>在导入数据时，先查询数据库中是否存在相同的记录，如果不存在再插入新记录。
<br>使用事务管理，确保数据的一致性。


<br><br><br>在多仓库环境中，不同仓库的库存数据同步不及时，导致库存信息不一致，影响生产计划和销售订单的处理。<br><br>
<br>原因：

<br>数据同步机制不完善。
<br>网络延迟或中断导致数据同步失败。
<br>缺乏实时监控和报警机制。


<br>难点：

<br>实现高效的实时数据同步。
<br>处理网络不稳定带来的数据丢失问题。


<br>挑战：

<br>确保数据同步的可靠性和一致性。
<br>提高系统的容错能力。


<br><br>
<br>实时同步机制：

<br>使用消息队列（如RabbitMQ、Kafka）实现库存数据的实时同步。
<br>在每个仓库的库存变化时，发布一条消息到消息队列，其他仓库订阅该消息并更新自己的库存数据。


<br>数据校验和补偿：

<br>定期进行数据校验，确保各仓库的库存数据一致。
<br>如果发现数据不一致，使用补偿机制进行修复。


<br>监控和报警：

<br>实施实时监控系统，监控数据同步的状态和性能。
<br>设置报警机制，当数据同步失败或延迟超过阈值时，发送警报通知相关人员进行处理。


<br><br><br><br>在系统运行过程中，随着数据量的增加，查询和操作的响应时间逐渐变慢，影响用户体验。<br><br>
<br>原因：

<br>查询语句不够优化。
<br>索引设计不合理。
<br>硬件资源不足。


<br>难点：

<br>如何高效地优化查询语句。
<br>如何选择合适的索引。


<br>挑战：

<br>在不影响系统正常运行的情况下进行性能优化。


<br><br>
<br>查询优化：

<br>使用EXPLAIN分析查询语句，找出性能瓶颈。
<br>优化查询逻辑，减少不必要的数据扫描。


<br>索引优化：

<br>根据查询频率和条件，合理添加索引。
<br>定期检查和优化索引，避免过度索引导致的性能下降。


<br>硬件升级：

<br>增加内存和CPU资源，提高系统处理能力。
<br>使用更快的存储介质，如SSD。


<br>分布式架构：

<br>考虑使用分布式数据库或缓存系统（如Redis），分散数据访问压力。
<br>实现负载均衡，提高系统的整体性能。


]]></description><link>technology\collegeproject\数据库\实验4：工厂场景的管理信息系统（mis）设计与开发.html</link><guid isPermaLink="false">Technology/CollegeProject/数据库/实验4：工厂场景的管理信息系统（MIS）设计与开发.md</guid><pubDate>Tue, 26 Nov 2024 13:30:46 GMT</pubDate><enclosure url="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126210703463.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241126210703463.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验5：查询计划执行]]></title><description><![CDATA[ 
 <br><br><br>(1)  学习并掌握数据库管理系统中查询处理与查询优化的基本知识和方法。<br>(2)  通过查询计划执行工具（explain）体会不同优化策略对查询执行性能的影响，掌握基本的查询优化方法。<br><br>
<br>
Linux操作系统

<br>
Python语言

<br>
数据库管理系统PostgreSQL

<br>
ER设计工具（如EZDML，<a rel="noopener nofollow" class="external-link" href="http://www.ezdml.com/" target="_blank">http://www.ezdml.com/</a>）。

<br><br>利用 explain工具，对比不同连接算法在SQL查询语句执行中的作用。<br>(1)  针对Nested Loop Join，Hash Join，Merge Sort Join三种连接进行比较，可以选择其中两种，也可以选择全部三种参与实验，自行决定。<br>(2)  实验采用的数据库及其基本表自行决定。<br>(3)  通过实验展现不同情况下（包括大小表、有无索引、不同的连接比较条件）物理优化的效果，对实验步骤及其结果进行必要说明和解释（包括时间代价、存取路径的策略等），最终实现实验目的达成。<br><br>（1）独立完成，严禁相互抄袭（如有发现抄袭和被抄袭均判为0分），以及从网络上直接摘抄别人的观点和总结（该行为将影响报告成绩）。<br>（2）实验报告符合学术写作的排版要求，请参考群文件中的“报告模板.docx”和“参考文献格式.docx”的排版格式。<br>（3）实验报告内容详实，采用图文混合的方式叙述安装和配置过程。<br>Tip：Win+Shift+S 在Windows中可以快速截屏。<br>（4）报告文件见附件，提交报告时请以附件形式插入到超星作业中。<br><br>报告标题：工厂场景的管理信息系统（MIS）设计与开发<br>学号：19220423<br>姓名：李世博<br>日期：2024/11/26<br><br>
<br>操作系统：
<br>WSL<br>
<br>数据库管理软件（含版本号）：
<br>psql (PostgreSQL) 12.20 (Ubuntu 12.20-0ubuntu0.20.04.1)<br>
<br>设计与开发工具：
<br>PostgreSQL，Python，EZDML<br><br>为了比较SQL查询中不同连接算法（Nested Loop Join, Hash Join, Merge Sort Join）的作用，我们可以设计一组实验，分析在不同条件下（如大小表、有无索引、不同连接条件）这些连接算法的表现。以下是设计实验的详细步骤和说明：<br><br><br>我们选择一个包含多个表的数据库，并设计适当的表结构。为了实验的通用性，假设我们使用一个简单的订单管理数据库，包括如下两个表：<br>
<br>
Customers 表：包含顾客信息。
CREATE TABLE Customers (
    customer_id INT PRIMARY KEY,
    customer_name VARCHAR(100),
    city VARCHAR(100)
);


<br>
Orders 表：包含顾客订单信息。
CREATE TABLE Orders (
    order_id INT PRIMARY KEY,
    customer_id INT,
    order_date DATE,
    total_amount DECIMAL(10, 2)
);


<br><br>
<br>小表：Customers表只有100条记录。
<br>大表：Orders表包含1000条记录。
<br><br>
<br>比较三种连接算法（Nested Loop Join, Hash Join, Merge Sort Join）的性能： 主要评估在不同数据量和不同条件下的执行时间、存取路径和策略。
<br>考虑索引影响： 分析当连接条件上有索引时和没有索引时，三种连接算法的表现差异。
<br>比较不同连接条件的影响： 分析当连接条件不同（例如，单一条件 vs 多条件）时的执行时间差异。
<br><br><br>我们首先在数据库中创建并插入测试数据。采用循环插入。<br>DO $$ 
DECLARE 
    i INT := 1;
BEGIN
    WHILE i &lt;= 100 LOOP
        INSERT INTO Customers (customer_id, customer_name, city)
        VALUES (i, 'Customer ' || i, 'City ' || i);
        i := i + 1;
    END LOOP;
END $$;


DO $$ 
DECLARE 
    i INT := 1;
BEGIN
    WHILE i &lt;= 1000 LOOP
        INSERT INTO Orders (order_id, customer_id, order_date, total_amount)
        VALUES (
            i,  -- Order ID
            (i % 100) + 1,  -- Customer ID, 假设有100个顾客
            '2023-10-' || LPAD((i % 30) + 1, 2, '0'),  -- 随机生成日期
            round(random() * 500, 2)  -- 随机生成订单金额（0到500之间）
        );
        i := i + 1;
    END LOOP;
END $$;
<br><img alt="image-20241212162446624" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212162446624.png" referrerpolicy="no-referrer"><br><img alt="image-20241212162413891" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212162413891.png" referrerpolicy="no-referrer"><br><br>实验中，我们考虑在连接条件上创建索引，测试不同情况的效果。<br>-- 在Orders表的customer_id列上创建索引
CREATE INDEX idx_customer_id ON Orders(customer_id);
<br><img alt="image-20241212162521902" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212162521902.png" referrerpolicy="no-referrer"><br><br>我们使用三种连接算法（Nested Loop Join, Hash Join, Merge Sort Join）执行如下SQL查询，并分别测试它们的执行时间：<br>-- 使用 Nested Loop Join
EXPLAIN ANALYZE
SELECT *
FROM Customers c
JOIN Orders o ON c.customer_id = o.customer_id;

-- 使用 Hash Join
EXPLAIN ANALYZE
SELECT *
FROM Customers c
JOIN Orders o ON c.customer_id = o.customer_id;

-- 使用 Merge Sort Join
EXPLAIN ANALYZE
SELECT *
FROM Customers c
JOIN Orders o ON c.customer_id = o.customer_id;
<br><img alt="image-20241212162557655" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212162557655.png" referrerpolicy="no-referrer"><br><img alt="image-20241212162619027" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212162619027.png" referrerpolicy="no-referrer"><br><img alt="image-20241212162638532" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212162638532.png" referrerpolicy="no-referrer"><br>在EXPLAIN ANALYZE的输出中，我们可以看到每种连接的执行计划，包括：<br>
<br>连接类型： 是否是嵌套循环连接、哈希连接还是归并连接。
<br>访问路径： 查询使用的是全表扫描、索引扫描，还是其他优化路径。
<br>时间代价： 每一步操作的时间代价。
<br>行数估算： 各个阶段的行数估算。
<br><br><br>EXPLAIN ANALYZE的输出会告诉我们数据库选择了哪个连接算法及其执行路径。对于每种连接算法，我们可以通过以下指标来进行比较：<br>
<br>时间代价（Time Cost）： 表示执行查询所需的时间，通常嵌套循环连接的代价较高，尤其是在没有索引的情况下。
<br>IO操作： 如果选择了全表扫描或大规模的磁盘访问，代价将较高。
<br>并行度： 数据库是否能够通过并行化操作加速某些连接操作（例如哈希连接）。
<br><br>不同的连接算法在不同的情况下一定会表现出不同的时间开销：<br>
<br>Nested Loop Join（嵌套循环连接）： 如果没有索引，嵌套循环连接会对每个外层行进行内层查找，时间复杂度是O(N * M)，通常在小表和有索引的情况下表现较好。
<br>Hash Join（哈希连接）： 当没有合适的索引时，哈希连接通常表现较好，因为它将数据分成多个桶并进行散列，但对内存的需求较高。
<br>Merge Sort Join（归并排序连接）： 归并连接通常在两张表都已排序时效果最好，因此在有索引的情况下效果更好。
<br><br>
<br>无索引时： 查询往往会选择全表扫描（Seq Scan），连接操作可能使用嵌套循环连接（Nested Loop），这会导致较高的时间代价。
<br>有索引时： 查询优化器可能选择索引扫描（Index Scan），此时哈希连接或归并连接的表现较好。
<br><br>通过上述实验，我们可以得出结论：<br>
<br>无索引时， 嵌套循环连接可能会因为大量的全表扫描而效率低下。
<br>有索引时， 哈希连接和归并排序连接可能会由于使用索引扫描而表现较好，尤其是在大表中。
<br>连接条件的复杂性（例如多条件连接）也会影响执行计划的选择，通常需要通过EXPLAIN来进一步调整优化。
]]></description><link>technology\collegeproject\数据库\实验5：查询计划执行.html</link><guid isPermaLink="false">Technology/CollegeProject/数据库/实验5：查询计划执行.md</guid><pubDate>Sun, 12 Jan 2025 03:12:21 GMT</pubDate><enclosure url="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212162446624.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\aimer\AppData\Roaming\Typora\typora-user-images\image-20241212162446624.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[PostgreSQL基本操作]]></title><description><![CDATA[ 
 <br><br><br>
<br>
更新包列表：<br>
打开终端，运行以下命令来更新你的包列表：
sudo apt update


<br>
安装 PostgreSQL：<br>
运行以下命令来安装 PostgreSQL 及其贡献包（额外的功能和工具）：
sudo apt install postgresql postgresql-contrib


<br>
验证安装：<br>
安装完成后，可以检查 PostgreSQL 服务的状态以确认它是否已自动启动：
sudo systemctl status postgresql

如果服务没有启动，你可以手动启动它：
sudo systemctl start postgresql


<br>
设置开机自启：<br>
确保 PostgreSQL 服务在系统重启后能够自动启动：
sudo systemctl enable postgresql


<br><br>使用 service 命令<br>
<br>
启动 PostgreSQL 服务：
sudo service postgresql start


<br>
检查 PostgreSQL 服务状态：
sudo service postgresql status


<br><br>
<br>
切换到 postgres 用户：<br>
默认情况下，PostgreSQL 创建了一个名为 postgres 的 Linux 用户。你需要切换到这个用户才能使用 psql 工具：
sudo -i -u postgres


<br>
使用 psql 登录数据库：<br>
切换到 postgres 用户后，可以直接使用 psql 命令登录到默认的 postgres 数据库：
psql

如果你想以特定的用户名和数据库登录，可以使用以下命令：
psql -h localhost -p 5432 -U your_username -d your_database

其中：

<br>-h 是主机名或 IP 地址。
<br>-p 是端口号，默认为 5432。
<br>-U 是要使用的用户名。
<br>-d 是要连接的数据库名。

根据提示输入密码即可完成登录。

<br><br>
<br>
定位 postgresql.conf 文件：<br>
首先需要找到 postgresql.conf 文件的位置。通常位于 /etc/postgresql/&lt;version&gt;/main/ 目录下，例如对于 PostgreSQL 14，路径可能是：
/etc/postgresql/14/main/postgresql.conf


<br>
编辑 postgresql.conf 文件：<br>
使用你喜欢的文本编辑器打开 postgresql.conf 文件。例如，使用 nano 编辑器：
sudo nano /etc/postgresql/14/main/postgresql.conf


<br>
更改语言设置：<br>
找到或添加 lc_messages 参数，并将其设置为 'C' 或 'en_US.UTF-8' 来将消息输出转为英文：
lc_messages = 'C'
# 或者
lc_messages = 'en_US.UTF-8'


<br>
保存并退出：<br>
保存文件并退出编辑器（在 nano 中按 Ctrl+O 保存，然后按 Ctrl+X 退出）。

<br>
重启 PostgreSQL 服务：<br>
使配置更改生效，需要重启 PostgreSQL 服务：
sudo systemctl restart postgresql


<br>
验证更改：<br>
重新登录到 psql 并运行 \d 命令来列出所有数据库对象，确保输出信息是英文的。

]]></description><link>technology\collegeproject\数据库\postgresql基本操作.html</link><guid isPermaLink="false">Technology/CollegeProject/数据库/PostgreSQL基本操作.md</guid><pubDate>Sun, 10 Nov 2024 00:48:48 GMT</pubDate></item><item><title><![CDATA[数据挖掘实验二]]></title><description><![CDATA[ 
 <br><br><br>
<br>PassengerId: 乘客ID (整数)
<br>Survived: 是否存活 (0 = No, 1 = Yes) - 这是我们要预测的目标变量
<br>Pclass: 船票等级 (1 = 1st, 2 = 2nd, 3 = 3rd) - 有序类别
<br>Name: 姓名 (字符串) - 通常不用于建模
<br>Sex: 性别 (male, female) - 二元类别
<br>Age: 年龄 (浮点数) - 连续数值
<br>SibSp: 兄弟姐妹/配偶在船上的数量 (整数) - 离散数值
<br>Parch: 父母/子女在船上的数量 (整数) - 离散数值
<br>Ticket: 票号 (字符串) - 通常不用于建模
<br>Fare: 票价 (浮点数) - 连续数值
<br>Cabin: 客舱号 (字符串) - 可能包含缺失值，通常不用于建模
<br>Embarked: 登船港口 (C = Cherbourg, Q = Queenstown, S = Southampton) - 名义类别
<br><br>首先，我们需要加载数据并执行一些预处理步骤，包括：<br>
<br>删除不必要的列 (PassengerId, Name, Ticket, Cabin)
<br>处理缺失值（删除或填充）
<br>将类别特征转换为数值
<br>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.preprocessing import LabelEncoder, StandardScaler, OneHotEncoder
from sklearn.pipeline import Pipeline
from sklearn.compose import ColumnTransformer
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
# 加载数据
data = pd.read_csv('Titanic.csv')

# 删除不需要的列
data.drop(columns=['PassengerId', 'Name', 'Ticket', 'Cabin'], inplace=True)

# 删除带有缺失值的样本
data.dropna(inplace=True)

# 将类别特征转换为数值
le = LabelEncoder()
data['Sex'] = le.fit_transform(data['Sex'])
data['Embarked'] = le.fit_transform(data['Embarked'])

# 准备特征和标签
X = data.drop('Survived', axis=1)
y = data['Survived']

# 划分训练集和测试集
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 查看数据集的基本信息
print(data.info())
# 检查缺失值
print(data.isnull().sum())
<br>&lt;class 'pandas.core.frame.DataFrame'&gt;
Index: 712 entries, 0 to 890
Data columns (total 8 columns):
 #   Column    Non-Null Count  Dtype  
---  ------    --------------  -----  
 0   Survived  712 non-null    int64  
 1   Pclass    712 non-null    int64  
 2   Sex       712 non-null    int32  
 3   Age       712 non-null    float64
 4   SibSp     712 non-null    int64  
 5   Parch     712 non-null    int64  
 6   Fare      712 non-null    float64
 7   Embarked  712 non-null    int32  
dtypes: float64(2), int32(2), int64(4)
memory usage: 44.5 KB
None
Survived    0
Pclass      0
Sex         0
Age         0
SibSp       0
Parch       0
Fare        0
Embarked    0
dtype: int64
<br><br>由于KNN是基于距离的算法，所以我们需要对数值特征进行标准化。<br># 定义数值特征和类别特征
numeric_features = ['Age', 'SibSp', 'Parch', 'Fare']
categorical_features = ['Pclass', 'Sex', 'Embarked']

# 创建一个预处理器来处理不同类型的特征
numeric_transformer = Pipeline(steps=[
    ('scaler', StandardScaler())
])

categorical_transformer = Pipeline(steps=[
    ('onehot', OneHotEncoder(handle_unknown='ignore'))
])

preprocessor = ColumnTransformer(
    transformers=[
        ('num', numeric_transformer, numeric_features),
        ('cat', categorical_transformer, categorical_features)
    ])

# 使用交叉验证选择最佳的K值
k_values = list(range(1, 31))
cv_scores = []

for k in k_values:
    knn = KNeighborsClassifier(n_neighbors=k)
    pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                               ('classifier', knn)])
    scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='accuracy')
    cv_scores.append(scores.mean())

# 找到最佳K值
best_k = k_values[np.argmax(cv_scores)]
print(f'Best K in train_data: {best_k}')

# 根据k曲线图挑选k值，不一定训练集上好的k在测试集就一定好
final_knn = KNeighborsClassifier(n_neighbors=4)
final_pipeline = Pipeline(steps=[('preprocessor', preprocessor),
                                 ('classifier', final_knn)])

# 训练最终模型
final_pipeline.fit(X_train, y_train)

# 预测
y_pred = final_pipeline.predict(X_test)

# 计算准确率
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy on test set: {accuracy:.2f}')

# 可视化部分

# 1. 交叉验证分数与 k 值的关系
plt.figure(figsize=(10, 6))
plt.plot(k_values, cv_scores, marker='o')
plt.title('Cross-Validation Scores for Different K Values')
plt.xlabel('K Value')
plt.ylabel('Cross-Validation Accuracy')
plt.grid(True)
plt.show()

# 2. 混淆矩阵
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.show()

# 3. 重要特征的分布
# 数值特征的分布
plt.figure(figsize=(12, 8))
for i, feature in enumerate(numeric_features, 1):
    plt.subplot(2, 2, i)
    sns.histplot(data[feature], kde=True)
    plt.title(f'Distribution of {feature}')
plt.tight_layout()
plt.show()

# 类别特征的分布
plt.figure(figsize=(12, 4))
for i, feature in enumerate(categorical_features, 1):
    plt.subplot(1, 3, i)
    sns.countplot(data=data, x=feature)
    plt.title(f'Distribution of {feature}')
plt.tight_layout()
plt.show()

# 打印分类报告
print(classification_report(y_test, y_pred))
<br>Best K in train_data: 12
Accuracy on test set: 0.78
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验二_files\实验二_5_1.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验二_files\实验二_5_2.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验二_files\实验二_5_3.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验二_files\实验二_5_4.png"><br>              precision    recall  f1-score   support

           0       0.75      0.91      0.82        80
           1       0.85      0.62      0.72        63

    accuracy                           0.78       143
   macro avg       0.80      0.77      0.77       143
weighted avg       0.79      0.78      0.78       143
]]></description><link>technology\collegeproject\数据挖掘\数据挖掘实验\实验二.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘实验/实验二.md</guid><pubDate>Mon, 23 Sep 2024 04:01:12 GMT</pubDate><enclosure url="technology\collegeproject\数据挖掘\数据挖掘实验\实验二_files\实验二_5_1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数据挖掘\数据挖掘实验\实验二_files\实验二_5_1.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验六]]></title><description><![CDATA[ 
 <br><br><br>对circles_dataset，moons_dataset和blobs_dataset数据集进行可视化，了解真实的簇结构；<br>import os

# 设置环境变量以避免 KMeans 的内存泄漏警告
os.environ['OMP_NUM_THREADS'] = '12'
import pandas as pd
import numpy as np

## 导入数据
blobs_data = pd.read_csv('blobs_dataset.csv')
circles_data = pd.read_csv('circles_dataset.csv')
moons_data = pd.read_csv('moons_dataset.csv')

## 可视化
import matplotlib.pyplot as plt

# 可视化 blobs_data
plt.figure(figsize=(12, 4))

plt.subplot(1, 3, 1)
plt.scatter(blobs_data['Feature1'], blobs_data['Feature2'], c=blobs_data['Label'], cmap='viridis')
plt.title('Blobs Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

# 可视化 circles_data
plt.subplot(1, 3, 2)
plt.scatter(circles_data['Feature1'], circles_data['Feature2'], c=circles_data['Label'], cmap='viridis')
plt.title('Circles Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

# 可视化 moons_data
plt.subplot(1, 3, 3)
plt.scatter(moons_data['Feature1'], moons_data['Feature2'], c=moons_data['Label'], cmap='viridis')
plt.title('Moons Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.tight_layout()
plt.show()
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_1_0.png"><br><br>假设知道簇的数量，分别使用Kmeans，AGNES和DBSCAN进行聚类分析，并分析三种算法在三个数据集上的效果；<br><br><br>import numpy as np
from sklearn.neighbors import NearestNeighbors
import matplotlib.pyplot as plt

def plot_k_distance(data, min_samples=1):
    # Fit NearestNeighbors model
    neighbors = NearestNeighbors(n_neighbors=min_samples)
    neighbors_fit = neighbors.fit(data)
    
    # Calculate distances to the k-th nearest neighbor
    distances, _ = neighbors_fit.kneighbors(data)
    
    # Sort the distances for plotting
    distances = np.sort(distances[:, -1], axis=0)
    
    # Calculate the first derivative (difference between consecutive distances)
    gradient = np.diff(distances)
    
    # Calculate the second derivative (change of the gradient)
    second_derivative = np.diff(gradient)
    
    # Find the index of the maximum second derivative (the inflection point)
    inflection_point_idx = np.argmax(second_derivative)
    
    # Plot the distances
    plt.plot(distances)
    plt.ylabel('Distance to {}th neighbor'.format(min_samples))
    plt.xlabel('Points sorted by distance')
    
    # Mark the inflection point
    plt.axvline(x=inflection_point_idx, color='r', linestyle='--', label='Inflection Point')
    plt.legend()
    plt.show()
    
    # Output the index and value of the inflection point
    print(f"Inflection point occurs at index {inflection_point_idx}, distance: {distances[inflection_point_idx]}")

# Example usage:
plot_k_distance(blobs_data[['Feature1', 'Feature2']], min_samples=3)
plot_k_distance(circles_data[['Feature1', 'Feature2']], min_samples=3)
plot_k_distance(moons_data[['Feature1', 'Feature2']], min_samples=3)

<br>​<br>
<img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_5_0.png"><br>
​    <br>Inflection point occurs at index 2997, distance: 1.0945077140524362
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_5_2.png"><br>Inflection point occurs at index 2995, distance: 0.06193251578477369
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_5_4.png"><br>Inflection point occurs at index 2997, distance: 0.1985668815521702
<br><br>from sklearn.cluster import KMeans
from sklearn.cluster import AgglomerativeClustering
from sklearn.cluster import DBSCAN

# 假设知道簇的数量
n_clusters_blobs = 3
n_clusters_circles = 2
n_clusters_moons = 2

# KMeans 聚类
kmeans_blobs = KMeans(n_clusters=n_clusters_blobs).fit(blobs_data[['Feature1', 'Feature2']])
kmeans_circles = KMeans(n_clusters=n_clusters_circles).fit(circles_data[['Feature1', 'Feature2']])
kmeans_moons = KMeans(n_clusters=n_clusters_moons).fit(moons_data[['Feature1', 'Feature2']])

# AGNES 聚类
agnes_blobs = AgglomerativeClustering(n_clusters=n_clusters_blobs).fit(blobs_data[['Feature1', 'Feature2']])
agnes_circles = AgglomerativeClustering(n_clusters=n_clusters_circles).fit(circles_data[['Feature1', 'Feature2']])
agnes_moons = AgglomerativeClustering(n_clusters=n_clusters_moons).fit(moons_data[['Feature1', 'Feature2']])

# DBSCAN 聚类
dbscan_blobs = DBSCAN(eps=1.0945077140524362, min_samples=4).fit(blobs_data[['Feature1', 'Feature2']])
dbscan_circles = DBSCAN(eps=0.037, min_samples=4).fit(circles_data[['Feature1', 'Feature2']])
dbscan_moons = DBSCAN(eps=0.0385668815521702, min_samples=4).fit(moons_data[['Feature1', 'Feature2']])

<br><br>import matplotlib.pyplot as plt

# 可视化 KMeans 聚类结果
plt.figure(figsize=(18, 5))

# KMeans 聚类结果可视化
plt.subplot(1, 3, 1)
plt.scatter(blobs_data['Feature1'], blobs_data['Feature2'], c=kmeans_blobs.labels_, cmap='viridis')
plt.title('KMeans - Blobs Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.subplot(1, 3, 2)
plt.scatter(circles_data['Feature1'], circles_data['Feature2'], c=kmeans_circles.labels_, cmap='viridis')
plt.title('KMeans - Circles Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.subplot(1, 3, 3)
plt.scatter(moons_data['Feature1'], moons_data['Feature2'], c=kmeans_moons.labels_, cmap='viridis')
plt.title('KMeans - Moons Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.tight_layout()
plt.show()

# 可视化 AGNES 聚类结果
plt.figure(figsize=(18, 5))

plt.subplot(1, 3, 1)
plt.scatter(blobs_data['Feature1'], blobs_data['Feature2'], c=agnes_blobs.labels_, cmap='viridis')
plt.title('AGNES - Blobs Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.subplot(1, 3, 2)
plt.scatter(circles_data['Feature1'], circles_data['Feature2'], c=agnes_circles.labels_, cmap='viridis')
plt.title('AGNES - Circles Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.subplot(1, 3, 3)
plt.scatter(moons_data['Feature1'], moons_data['Feature2'], c=agnes_moons.labels_, cmap='viridis')
plt.title('AGNES - Moons Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.tight_layout()
plt.show()

# 可视化 DBSCAN 聚类结果
plt.figure(figsize=(18, 5))

plt.subplot(1, 3, 1)
plt.scatter(blobs_data['Feature1'], blobs_data['Feature2'], c=dbscan_blobs.labels_, cmap='viridis')
plt.title('DBSCAN - Blobs Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.subplot(1, 3, 2)
plt.scatter(circles_data['Feature1'], circles_data['Feature2'], c=dbscan_circles.labels_, cmap='viridis')
plt.title('DBSCAN - Circles Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.subplot(1, 3, 3)
plt.scatter(moons_data['Feature1'], moons_data['Feature2'], c=dbscan_moons.labels_, cmap='viridis')
plt.title('DBSCAN - Moons Dataset')
plt.xlabel('Feature1')
plt.ylabel('Feature2')

plt.tight_layout()
plt.show()
<br>​<br>
<img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_9_0.png"><br>
​    <br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_9_1.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_9_2.png"><br>可以看出：<br>
<br>KMeans和AGNES在Blobs数据集上聚类效果更好，而DBSCAN难以分别两组距离太近的样本
<br>而在circles和moons上的分类则不准确
<br>DBSCAN可以看出能分出circles和moons但是由于参数不是最佳和一些边缘样本导致分类效果也不好
<br><br>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import DBSCAN
from sklearn.metrics import adjusted_rand_score

# 1. 加载数据
data = pd.read_csv('circles_dataset.csv')  # 假设数据保存在your_data.csv文件中
X = data[['Feature1', 'Feature2']].values
y = data['Label'].values

# 2. 定义eps范围并进行聚类
eps_values = np.linspace(0.001, 0.2, 2000)  # 从0.001到0.2，200个不同的eps值
best_ari = -1  # 初始最好的ARI值
best_eps = None
best_labels = None

ari_scores = []  # 用于存储不同eps下的ARI分数

for eps in eps_values:
    # 使用固定min_samples=4，调整eps
    dbscan = DBSCAN(eps=eps, min_samples=4)
    labels = dbscan.fit_predict(X)

    # 计算ARI（调整后的Rand指数）
    ari = adjusted_rand_score(y, labels)
    ari_scores.append(ari)

    # 更新最好的结果
    if ari &gt; best_ari:
        best_ari = ari
        best_eps = eps
        best_labels = labels

# 3. 输出最好的结果
print(f"Best ARI: {best_ari}")
print(f"Best eps: {best_eps}")

# 4. 绘制ARI值随eps变化的曲线
plt.figure(figsize=(10, 6))
plt.plot(eps_values, ari_scores, label='ARI score')
plt.xlabel('eps')
plt.ylabel('Adjusted Rand Index (ARI)')
plt.title('ARI Score vs. eps for DBSCAN')
plt.grid(True)
plt.legend()
plt.show()

# 5. 可视化最佳聚类结果
plt.figure(figsize=(8, 6))
plt.scatter(X[:, 0], X[:, 1], c=best_labels, cmap='viridis')
plt.title(f'Best DBSCAN Clustering (eps={best_eps})')
plt.xlabel('Feature1')
plt.ylabel('Feature2')
plt.show()


data = pd.read_csv('moons_dataset.csv')  # 假设数据保存在your_data.csv文件中
X = data[['Feature1', 'Feature2']].values
y = data['Label'].values

# 2. 定义eps范围并进行聚类
eps_values = np.linspace(0.001, 0.2, 2000)  # 从0.001到0.2，200个不同的eps值
best_ari = -1  # 初始最好的ARI值
best_eps = None
best_labels = None

ari_scores = []  # 用于存储不同eps下的ARI分数

for eps in eps_values:
    # 使用固定min_samples=4，调整eps
    dbscan = DBSCAN(eps=eps, min_samples=4)
    labels = dbscan.fit_predict(X)

    # 计算ARI（调整后的Rand指数）
    ari = adjusted_rand_score(y, labels)
    ari_scores.append(ari)

    # 更新最好的结果
    if ari &gt; best_ari:
        best_ari = ari
        best_eps = eps
        best_labels = labels

# 3. 输出最好的结果
print(f"Best ARI: {best_ari}")
print(f"Best eps: {best_eps}")

# 4. 绘制ARI值随eps变化的曲线
plt.figure(figsize=(10, 6))
plt.plot(eps_values, ari_scores, label='ARI score')
plt.xlabel('eps')
plt.ylabel('Adjusted Rand Index (ARI)')
plt.title('ARI Score vs. eps for DBSCAN')
plt.grid(True)
plt.legend()
plt.show()

# 5. 可视化最佳聚类结果
plt.figure(figsize=(8, 6))
plt.scatter(X[:, 0], X[:, 1], c=best_labels, cmap='viridis')
plt.title(f'Best DBSCAN Clustering (eps={best_eps})')
plt.xlabel('Feature1')
plt.ylabel('Feature2')
plt.show()
<br>Best ARI: 0.5467324349006474
Best eps: 0.03534467233616809
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_12_1.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_12_2.png"><br>Best ARI: 0.7857236346354486
Best eps: 0.05386093046523262
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_12_4.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_12_5.png"><br><br>假设不知道簇的数量，测试不同K值下Kmeans，AGNES和DBSCAN在三个数据集上的效果，使用轮廓系数作为评价指标。 <br>import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN
from sklearn.metrics import silhouette_score
from sklearn.preprocessing import StandardScaler

# 导入数据集
blobs_data = pd.read_csv('blobs_dataset.csv')
circles_data = pd.read_csv('circles_dataset.csv')
moons_data = pd.read_csv('moons_dataset.csv')

# 标准化数据
scaler = StandardScaler()
blobs_data_scaled = scaler.fit_transform(blobs_data[['Feature1', 'Feature2']])
circles_data_scaled = scaler.fit_transform(circles_data[['Feature1', 'Feature2']])
moons_data_scaled = scaler.fit_transform(moons_data[['Feature1', 'Feature2']])

# KMeans 聚类
k_values = range(2, 11)  # 测试 K 值从 2 到 10
kmeans_scores = []
agnes_scores = []
dbscan_scores = []

for k in k_values:
    # KMeans
    kmeans = KMeans(n_clusters=k, random_state=42)
    kmeans_labels = kmeans.fit_predict(blobs_data_scaled)
    kmeans_scores.append(silhouette_score(blobs_data_scaled, kmeans_labels))

    # AGNES
    agnes = AgglomerativeClustering(n_clusters=k)
    agnes_labels = agnes.fit_predict(blobs_data_scaled)
    agnes_scores.append(silhouette_score(blobs_data_scaled, agnes_labels))

# DBSCAN
eps_values = np.arange(0.1, 1.1, 0.1)
dbscan_scores_blobs = []

for eps in eps_values:
    dbscan = DBSCAN(eps=eps, min_samples=5)
    dbscan_labels = dbscan.fit_predict(blobs_data_scaled)
    if len(set(dbscan_labels)) &gt; 1:  # 确保有多个簇
        dbscan_scores_blobs.append(silhouette_score(blobs_data_scaled, dbscan_labels))
    else:
        dbscan_scores_blobs.append(-1)  # 如果只有一个簇，轮廓系数为 -1

# 可视化结果
plt.figure(figsize=(15, 5))

# KMeans 轮廓系数
plt.subplot(1, 3, 1)
plt.plot(k_values, kmeans_scores, marker='o')
plt.title('KMeans Silhouette Scores')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Silhouette Score')
plt.xticks(k_values)

# AGNES 轮廓系数
plt.subplot(1, 3, 2)
plt.plot(k_values, agnes_scores, marker='o')
plt.title('AGNES Silhouette Scores')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('Silhouette Score')
plt.xticks(k_values)

# DBSCAN 轮廓系数
plt.subplot(1, 3, 3)
plt.plot(eps_values, dbscan_scores_blobs, marker='o')
plt.title('DBSCAN Silhouette Scores')
plt.xlabel('Epsilon (eps)')
plt.ylabel('Silhouette Score')
plt.xticks(eps_values)

plt.tight_layout()
plt.show()
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_14_1.png"><br>可以明显看出，随着k的增大，KMeans和AGNES的轮廓系数都在明显降低。]]></description><link>technology\collegeproject\数据挖掘\数据挖掘实验\实验六.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘实验/实验六.md</guid><pubDate>Mon, 18 Nov 2024 10:01:02 GMT</pubDate><enclosure url="technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_1_0.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数据挖掘\数据挖掘实验\实验六_files\实验六_1_0.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[了解CreditCardFraud 数据集中属性的含义]]></title><description><![CDATA[ 
 <br><br>import pandas as pd

# 载入数据
df = pd.read_csv('creditcard.csv')

# 查看前几行数据
print(df.head())

<br>   Time        V1        V2        V3        V4        V5        V6        V7  \
0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   
1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   
2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   
3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   
4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   

         V8        V9  ...       V21       V22       V23       V24       V25  \
0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   
1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   
2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   
3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   
4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   

        V26       V27       V28  Amount  Class  
0 -0.189115  0.133558 -0.021053  149.62      0  
1  0.125895 -0.008983  0.014724    2.69      0  
2 -0.139097 -0.055353 -0.059752  378.66      0  
3 -0.221929  0.062723  0.061458  123.50      0  
4  0.502292  0.219422  0.215153   69.99      0  

[5 rows x 31 columns]
<br>其中 284,807 笔交易中有 492 笔欺诈。数据集高度不平衡，正类（欺诈）占所有交易的 0.172%。功能 V1、V2、...V28 是使用 PCA 获得的主成分，唯一未使用 PCA 转换的特征是 'Time' 和 'Amount'。特征 'Time' 包含数据集中每个事务与第一个事务之间经过的秒数。功能 'Amount' 是交易金额。特征 'Class' 是响应变量，在欺诈的情况下取值 1，否则取值 0。<br><br><br>import matplotlib.pyplot as plt
import seaborn as sns
# 查看 Class 列中正常和异常样本的比例
print(df['Class'].value_counts())

# 检查缺失值
print(df.isnull().sum())
# 绘制 Amount 列的直方图
plt.figure(figsize=(10,6))
plt.hist(df['Amount'], bins=50, color='skyblue', edgecolor='black')
plt.title('Transaction Amount Distribution')
plt.xlabel('Amount')
plt.ylabel('Frequency')
plt.show()


# 绘制 Class 列的分布
plt.figure(figsize=(6,4))
sns.countplot(x='Class', data=df)
plt.title('Normal vs Fraudulent Transactions')
plt.xlabel('Class (0: Normal, 1: Fraud)')
plt.ylabel('Frequency')
plt.show()
<br>Class
0    284315
1       492
Name: count, dtype: int64
Time      0
V1        0
V2        0
V3        0
V4        0
V5        0
V6        0
V7        0
V8        0
V9        0
V10       0
V11       0
V12       0
V13       0
V14       0
V15       0
V16       0
V17       0
V18       0
V19       0
V20       0
V21       0
V22       0
V23       0
V24       0
V25       0
V26       0
V27       0
V28       0
Amount    0
Class     0
dtype: int64
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验七_files\实验七_5_1.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验七_files\实验七_5_2.png"><br><br>from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

# 分离正常样本和异常样本
normal_samples = df[df['Class'] == 0]
fraud_samples = df[df['Class'] == 1]

# 提取特征列（去除 'Class' 和 'Time' 列）
features = df.drop(columns=['Class', 'Time'])

# 对特征进行标准化
scaler = StandardScaler()
scaled_features = scaler.fit_transform(features)

# 将标准化后的特征放回原数据框
df_scaled = pd.DataFrame(scaled_features, columns=features.columns)


<br><br># 将 'Class' 列添加回标准化后的数据框
df_scaled['Class'] = df['Class']

# 分别对正常样本和异常样本进行划分，90%作为训练集，10%作为测试集
normal_train, normal_test = train_test_split(normal_samples, test_size=0.1, random_state=42)
fraud_train, fraud_test = train_test_split(fraud_samples, test_size=0.1, random_state=42)

# 合并训练集和测试集
train_data = pd.concat([normal_train, fraud_train])
test_data = pd.concat([normal_test, fraud_test])

# 打乱数据
train_data = train_data.sample(frac=1, random_state=42).reset_index(drop=True)
test_data = test_data.sample(frac=1, random_state=42).reset_index(drop=True)

# 提取特征和标签
X_train = train_data.drop(columns=['Class', 'Time'])
y_train = train_data['Class']
X_test = test_data.drop(columns=['Class', 'Time'])
y_test = test_data['Class']

# 检查训练集和测试集的类别分布
print("训练集类别分布：")
print(train_data['Class'].value_counts())
print("\n测试集类别分布：")
print(test_data['Class'].value_counts())
<br>训练集类别分布：
Class
0    255883
1       442
Name: count, dtype: int64

测试集类别分布：
Class
0    28432
1       50
Name: count, dtype: int64
<br><br>from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
import pandas as pd
from sklearn.ensemble import IsolationForest
from sklearn.neighbors import LocalOutlierFactor
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import classification_report, confusion_matrix

# 载入数据（已经标准化并划分为训练集和测试集）

# ------------------- Isolation Forest -------------------
# 创建 Isolation Forest 模型
iforest = IsolationForest(n_estimators=100, contamination=0.01, random_state=42)

# 训练模型并进行预测
y_pred_iforest_train = iforest.fit_predict(X_train)
y_pred_iforest_test = iforest.predict(X_test)

# 预测结果，-1 表示异常，1 表示正常
y_pred_iforest_train = [1 if i == -1 else 0 for i in y_pred_iforest_train]
y_pred_iforest_test = [1 if i == -1 else 0 for i in y_pred_iforest_test]

# ------------------- Local Outlier Factor (LOF) -------------------
# 创建 Local Outlier Factor 模型
lof = LocalOutlierFactor(n_neighbors=20, contamination=0.01)

# 训练模型并进行预测
y_pred_lof_train = lof.fit_predict(X_train)
y_pred_lof_test = lof.fit_predict(X_test)

# 预测结果，-1 表示异常，1 表示正常
y_pred_lof_train = [1 if i == -1 else 0 for i in y_pred_lof_train]
y_pred_lof_test = [1 if i == -1 else 0 for i in y_pred_lof_test]

# ------------------- 可视化结果 -------------------

# 将检测结果添加到数据框中
train_data['IForest Prediction'] = y_pred_iforest_train
test_data['IForest Prediction'] = y_pred_iforest_test

train_data['LOF Prediction'] = y_pred_lof_train
test_data['LOF Prediction'] = y_pred_lof_test

# 设置画布大小
plt.figure(figsize=(14, 6))

# 绘制 Isolation Forest 的检测结果 - 训练集
plt.subplot(1, 2, 1)
sns.scatterplot(x=train_data.index, y=train_data['Amount'], hue=train_data['IForest Prediction'], palette='coolwarm', s=50, marker='o')
plt.title('Isolation Forest - Training Set')
plt.xlabel('Sample Index')
plt.ylabel('Amount')
plt.legend(title='Prediction', loc='upper right')

# 绘制 Local Outlier Factor (LOF) 的检测结果 - 训练集
plt.subplot(1, 2, 2)
sns.scatterplot(x=train_data.index, y=train_data['Amount'], hue=train_data['LOF Prediction'], palette='coolwarm', s=50, marker='o')
plt.title('Local Outlier Factor (LOF) - Training Set')
plt.xlabel('Sample Index')
plt.ylabel('Amount')
plt.legend(title='Prediction', loc='upper right')

# 显示图表
plt.tight_layout()
plt.show()

# ------------------- 性能评估 -------------------

# 性能评估 - Isolation Forest
print("Isolation Forest - Performance (Train):")
print(classification_report(train_data['Class'], y_pred_iforest_train))
print(confusion_matrix(train_data['Class'], y_pred_iforest_train))

print("\nIsolation Forest - Performance (Test):")
print(classification_report(test_data['Class'], y_pred_iforest_test))
print(confusion_matrix(test_data['Class'], y_pred_iforest_test))

# 性能评估 - LOF
print("\nLocal Outlier Factor (LOF) - Performance (Train):")
print(classification_report(train_data['Class'], y_pred_lof_train))
print(confusion_matrix(train_data['Class'], y_pred_lof_train))

print("\nLocal Outlier Factor (LOF) - Performance (Test):")
print(classification_report(test_data['Class'], y_pred_lof_test))
print(confusion_matrix(test_data['Class'], y_pred_lof_test))

<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验七_files\实验七_11_0.png"><br>Isolation Forest - Performance (Train):
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.09      0.54      0.16       442

    accuracy                           0.99    256325
   macro avg       0.55      0.77      0.58    256325
weighted avg       1.00      0.99      0.99    256325

[[253559   2324]
 [   202    240]]

Isolation Forest - Performance (Test):
              precision    recall  f1-score   support

           0       1.00      0.99      0.99     28432
           1       0.10      0.58      0.17        50

    accuracy                           0.99     28482
   macro avg       0.55      0.79      0.58     28482
weighted avg       1.00      0.99      0.99     28482

[[28167   265]
 [   21    29]]

Local Outlier Factor (LOF) - Performance (Train):
              precision    recall  f1-score   support

           0       1.00      0.99      0.99    255883
           1       0.04      0.24      0.07       442

    accuracy                           0.99    256325
   macro avg       0.52      0.61      0.53    256325
weighted avg       1.00      0.99      0.99    256325

[[253424   2459]
 [   337    105]]

Local Outlier Factor (LOF) - Performance (Test):
              precision    recall  f1-score   support

           0       1.00      0.99      1.00     28432
           1       0.12      0.68      0.20        50

    accuracy                           0.99     28482
   macro avg       0.56      0.84      0.60     28482
weighted avg       1.00      0.99      0.99     28482

[[28181   251]
 [   16    34]]
<br><br># ------------------- 调整 Isolation Forest 参数 -------------------
# 初始化 Isolation Forest 模型
n_estimators_range = [50, 100, 150]
contamination_range = [0.01, 0.02, 0.05]
max_samples_range = [0.5, 0.75, 1.0]

# 测试不同参数组合
for n_estimators in n_estimators_range:
    for contamination in contamination_range:
        for max_samples in max_samples_range:
            # 创建模型
            iforest = IsolationForest(n_estimators=n_estimators,
                                      contamination=contamination,
                                      max_samples=max_samples,
                                      random_state=42)
            
            # 训练并预测
            y_pred_iforest_train = iforest.fit_predict(X_train)
            y_pred_iforest_train = [1 if i == -1 else 0 for i in y_pred_iforest_train]  # 转换为二分类（正常：0, 异常：1）
            
            # 性能评估
            print(f"Isolation Forest - Params: n_estimators={n_estimators}, contamination={contamination}, max_samples={max_samples}")
            print(classification_report(y_train, y_pred_iforest_train))
            print(confusion_matrix(y_train, y_pred_iforest_train))

# ------------------- 调整 Local Outlier Factor 参数 -------------------
# 初始化 LOF 模型
n_neighbors_range = [10, 20, 30]
contamination_range = [0.01, 0.02, 0.05]

# 测试不同参数组合
for n_neighbors in n_neighbors_range:
    for contamination in contamination_range:
        # 创建模型
        lof = LocalOutlierFactor(n_neighbors=n_neighbors,
                                 contamination=contamination)
            
        # 训练并预测
        y_pred_lof_train = lof.fit_predict(X_train)
        y_pred_lof_train = [1 if i == -1 else 0 for i in y_pred_lof_train]  # 转换为二分类（正常：0, 异常：1）
            
        # 性能评估
        print(f"Local Outlier Factor - Params: n_neighbors={n_neighbors}, contamination={contamination}")
        print(classification_report(y_train, y_pred_lof_train))
        print(confusion_matrix(y_train, y_pred_lof_train))
<br>Isolation Forest - Params: n_estimators=50, contamination=0.01, max_samples=0.5
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.12      0.68      0.20       442

    accuracy                           0.99    256325
   macro avg       0.56      0.83      0.60    256325
weighted avg       1.00      0.99      0.99    256325

[[253619   2264]
 [   142    300]]
Isolation Forest - Params: n_estimators=50, contamination=0.01, max_samples=0.75
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.12      0.69      0.20       442

    accuracy                           0.99    256325
   macro avg       0.56      0.84      0.60    256325
weighted avg       1.00      0.99      0.99    256325

[[253623   2260]
 [   138    304]]
Isolation Forest - Params: n_estimators=50, contamination=0.01, max_samples=1.0
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.14      0.79      0.23       442

    accuracy                           0.99    256325
   macro avg       0.57      0.89      0.61    256325
weighted avg       1.00      0.99      0.99    256325

[[253666   2217]
 [    95    347]]
Isolation Forest - Params: n_estimators=50, contamination=0.02, max_samples=0.5
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.07      0.81      0.13       442

    accuracy                           0.98    256325
   macro avg       0.53      0.89      0.56    256325
weighted avg       1.00      0.98      0.99    256325

[[251112   4771]
 [    86    356]]
Isolation Forest - Params: n_estimators=50, contamination=0.02, max_samples=0.75
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.07      0.80      0.13       442

    accuracy                           0.98    256325
   macro avg       0.53      0.89      0.56    256325
weighted avg       1.00      0.98      0.99    256325

[[251109   4774]
 [    89    353]]
Isolation Forest - Params: n_estimators=50, contamination=0.02, max_samples=1.0
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.07      0.83      0.13       442

    accuracy                           0.98    256325
   macro avg       0.54      0.90      0.56    256325
weighted avg       1.00      0.98      0.99    256325

[[251121   4762]
 [    77    365]]
Isolation Forest - Params: n_estimators=50, contamination=0.05, max_samples=0.5
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.03      0.85      0.06       442

    accuracy                           0.95    256325
   macro avg       0.51      0.90      0.52    256325
weighted avg       1.00      0.95      0.97    256325

[[243441  12442]
 [    67    375]]
Isolation Forest - Params: n_estimators=50, contamination=0.05, max_samples=0.75
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.03      0.84      0.06       442

    accuracy                           0.95    256325
   macro avg       0.51      0.90      0.52    256325
weighted avg       1.00      0.95      0.97    256325

[[243438  12445]
 [    70    372]]
Isolation Forest - Params: n_estimators=50, contamination=0.05, max_samples=1.0
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.03      0.87      0.06       442

    accuracy                           0.95    256325
   macro avg       0.51      0.91      0.52    256325
weighted avg       1.00      0.95      0.97    256325

[[243449  12434]
 [    59    383]]
Isolation Forest - Params: n_estimators=100, contamination=0.01, max_samples=0.5
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.12      0.68      0.20       442

    accuracy                           0.99    256325
   macro avg       0.56      0.84      0.60    256325
weighted avg       1.00      0.99      0.99    256325

[[253621   2262]
 [   140    302]]
Isolation Forest - Params: n_estimators=100, contamination=0.01, max_samples=0.75
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.12      0.69      0.20       442

    accuracy                           0.99    256325
   macro avg       0.56      0.84      0.60    256325
weighted avg       1.00      0.99      0.99    256325

[[253626   2257]
 [   135    307]]
Isolation Forest - Params: n_estimators=100, contamination=0.01, max_samples=1.0
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.13      0.74      0.22       442

    accuracy                           0.99    256325
   macro avg       0.56      0.87      0.61    256325
weighted avg       1.00      0.99      0.99    256325

[[253646   2237]
 [   115    327]]
Isolation Forest - Params: n_estimators=100, contamination=0.02, max_samples=0.5
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.07      0.80      0.13       442

    accuracy                           0.98    256325
   macro avg       0.53      0.89      0.56    256325
weighted avg       1.00      0.98      0.99    256325

[[251109   4774]
 [    89    353]]
Isolation Forest - Params: n_estimators=100, contamination=0.02, max_samples=0.75
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.07      0.82      0.13       442

    accuracy                           0.98    256325
   macro avg       0.54      0.90      0.56    256325
weighted avg       1.00      0.98      0.99    256325

[[251118   4765]
 [    80    362]]
Isolation Forest - Params: n_estimators=100, contamination=0.02, max_samples=1.0
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.07      0.82      0.13       442

    accuracy                           0.98    256325
   macro avg       0.54      0.90      0.56    256325
weighted avg       1.00      0.98      0.99    256325

[[251119   4764]
 [    79    363]]
Isolation Forest - Params: n_estimators=100, contamination=0.05, max_samples=0.5
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.03      0.86      0.06       442

    accuracy                           0.95    256325
   macro avg       0.51      0.90      0.52    256325
weighted avg       1.00      0.95      0.97    256325

[[243444  12439]
 [    64    378]]
Isolation Forest - Params: n_estimators=100, contamination=0.05, max_samples=0.75
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.03      0.86      0.06       442

    accuracy                           0.95    256325
   macro avg       0.51      0.91      0.52    256325
weighted avg       1.00      0.95      0.97    256325

[[243446  12437]
 [    62    380]]
Isolation Forest - Params: n_estimators=100, contamination=0.05, max_samples=1.0
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.03      0.86      0.06       442

    accuracy                           0.95    256325
   macro avg       0.51      0.91      0.52    256325
weighted avg       1.00      0.95      0.97    256325

[[243446  12437]
 [    62    380]]
Isolation Forest - Params: n_estimators=150, contamination=0.01, max_samples=0.5
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.12      0.69      0.20       442

    accuracy                           0.99    256325
   macro avg       0.56      0.84      0.60    256325
weighted avg       1.00      0.99      0.99    256325

[[253624   2259]
 [   137    305]]
Isolation Forest - Params: n_estimators=150, contamination=0.01, max_samples=0.75
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.12      0.70      0.20       442

    accuracy                           0.99    256325
   macro avg       0.56      0.84      0.60    256325
weighted avg       1.00      0.99      0.99    256325

[[253627   2256]
 [   134    308]]
Isolation Forest - Params: n_estimators=150, contamination=0.01, max_samples=1.0
              precision    recall  f1-score   support

           0       1.00      0.99      1.00    255883
           1       0.13      0.73      0.21       442

    accuracy                           0.99    256325
   macro avg       0.56      0.86      0.60    256325
weighted avg       1.00      0.99      0.99    256325

[[253641   2242]
 [   120    322]]
Isolation Forest - Params: n_estimators=150, contamination=0.02, max_samples=0.5
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.07      0.81      0.13       442

    accuracy                           0.98    256325
   macro avg       0.53      0.89      0.56    256325
weighted avg       1.00      0.98      0.99    256325

[[251113   4770]
 [    85    357]]
Isolation Forest - Params: n_estimators=150, contamination=0.02, max_samples=0.75
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.07      0.81      0.13       442

    accuracy                           0.98    256325
   macro avg       0.53      0.90      0.56    256325
weighted avg       1.00      0.98      0.99    256325

[[251116   4767]
 [    82    360]]
Isolation Forest - Params: n_estimators=150, contamination=0.02, max_samples=1.0
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.07      0.82      0.13       442

    accuracy                           0.98    256325
   macro avg       0.54      0.90      0.56    256325
weighted avg       1.00      0.98      0.99    256325

[[251118   4765]
 [    80    362]]
Isolation Forest - Params: n_estimators=150, contamination=0.05, max_samples=0.5
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.03      0.86      0.06       442

    accuracy                           0.95    256325
   macro avg       0.51      0.90      0.52    256325
weighted avg       1.00      0.95      0.97    256325

[[243445  12438]
 [    63    379]]
Isolation Forest - Params: n_estimators=150, contamination=0.05, max_samples=0.75
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.03      0.87      0.06       442

    accuracy                           0.95    256325
   macro avg       0.51      0.91      0.52    256325
weighted avg       1.00      0.95      0.97    256325

[[243451  12432]
 [    57    385]]
Isolation Forest - Params: n_estimators=150, contamination=0.05, max_samples=1.0
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.03      0.86      0.06       442

    accuracy                           0.95    256325
   macro avg       0.51      0.91      0.52    256325
weighted avg       1.00      0.95      0.97    256325

[[243448  12435]
 [    60    382]]
Local Outlier Factor - Params: n_neighbors=10, contamination=0.01
              precision    recall  f1-score   support

           0       1.00      0.99      0.99    255883
           1       0.02      0.13      0.04       442

    accuracy                           0.99    256325
   macro avg       0.51      0.56      0.52    256325
weighted avg       1.00      0.99      0.99    256325

[[253376   2507]
 [   385     57]]
Local Outlier Factor - Params: n_neighbors=10, contamination=0.02
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.02      0.22      0.04       442

    accuracy                           0.98    256325
   macro avg       0.51      0.60      0.51    256325
weighted avg       1.00      0.98      0.99    256325

[[250854   5029]
 [   344     98]]
Local Outlier Factor - Params: n_neighbors=10, contamination=0.05
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.01      0.31      0.02       442

    accuracy                           0.95    256325
   macro avg       0.50      0.63      0.50    256325
weighted avg       1.00      0.95      0.97    256325

[[243202  12681]
 [   306    136]]
Local Outlier Factor - Params: n_neighbors=20, contamination=0.01
              precision    recall  f1-score   support

           0       1.00      0.99      0.99    255883
           1       0.04      0.24      0.07       442

    accuracy                           0.99    256325
   macro avg       0.52      0.61      0.53    256325
weighted avg       1.00      0.99      0.99    256325

[[253424   2459]
 [   337    105]]
Local Outlier Factor - Params: n_neighbors=20, contamination=0.02
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.03      0.30      0.05       442

    accuracy                           0.98    256325
   macro avg       0.51      0.64      0.52    256325
weighted avg       1.00      0.98      0.99    256325

[[250889   4994]
 [   309    133]]
Local Outlier Factor - Params: n_neighbors=20, contamination=0.05
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.01      0.35      0.02       442

    accuracy                           0.95    256325
   macro avg       0.51      0.65      0.50    256325
weighted avg       1.00      0.95      0.97    256325

[[243220  12663]
 [   288    154]]
Local Outlier Factor - Params: n_neighbors=30, contamination=0.01
              precision    recall  f1-score   support

           0       1.00      0.99      0.99    255883
           1       0.05      0.27      0.08       442

    accuracy                           0.99    256325
   macro avg       0.52      0.63      0.54    256325
weighted avg       1.00      0.99      0.99    256325

[[253437   2446]
 [   324    118]]
Local Outlier Factor - Params: n_neighbors=30, contamination=0.02
              precision    recall  f1-score   support

           0       1.00      0.98      0.99    255883
           1       0.03      0.33      0.05       442

    accuracy                           0.98    256325
   macro avg       0.51      0.65      0.52    256325
weighted avg       1.00      0.98      0.99    256325

[[250901   4982]
 [   297    145]]
Local Outlier Factor - Params: n_neighbors=30, contamination=0.05
              precision    recall  f1-score   support

           0       1.00      0.95      0.97    255883
           1       0.01      0.38      0.03       442

    accuracy                           0.95    256325
   macro avg       0.51      0.67      0.50    256325
weighted avg       1.00      0.95      0.97    256325

[[243234  12649]
 [   274    168]]
]]></description><link>technology\collegeproject\数据挖掘\数据挖掘实验\实验七.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘实验/实验七.md</guid><pubDate>Wed, 04 Dec 2024 02:33:39 GMT</pubDate><enclosure url="technology\collegeproject\数据挖掘\数据挖掘实验\实验七_files\实验七_5_1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数据挖掘\数据挖掘实验\实验七_files\实验七_5_1.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验四]]></title><description><![CDATA[ 
 <br><br>假设最小支持度阈值为0.1，复现Apriori算法并在杂货店商品数据集中找出所有的频繁项集，可参考以下流程：<br>1）找出数据集中的频繁1-项集；<br>2）根据频繁1-项集生成候选2-项集；<br>3）判断是否可对候选2-项集进行剪枝操作，然后计算剩余候选2-项集的支持度计数，最后筛选出频繁-2项集；<br>4）重复以上过程直至候选k-项集为空，最后输出所有的频繁项集。<br>Apriori 先验原理如下:如果一个项集是频繁的，则它的所有子集一定也是频繁的;相反，如果一个项集是非频繁的，则它的所有超集也一定是非频繁的。也就是说，如果{0,1}是频繁的，那么{0}，{1}也一定是频繁的。<br>Aprior算法提出了一个逐层搜索的方法，如何逐层搜索呢?包含两个步骤:<br>1)自连接获取候选集。第一轮的候选集就是数据集D中的项，而其他轮次的候选集则由前一轮次频繁集自连接得到(频繁集由候选集剪枝得到)。<br>2)对候选集进行剪枝。如何剪枝呢?对于候选集的每一条记录T，如果它的支持度小于最小支持度，那么就会被剪掉。此外，如果对于一条记录T，它的子集有非频繁项集，也会被剪掉。算法的终止条件是，如果自连接得到的已经不再是频繁集，那么取最后一次得到的频繁集作为结果。<br><img alt="{3BDE661D-9FD1-467B-B6D4-9F271E3EC52C}.png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\实验四_files\{3bde661d-9fd1-467b-b6d4-9f271e3ec52c}.png"><br>import csv
from collections import defaultdict


def load_data(filename):
    transactions = []
    with open(filename, 'r') as file:
        reader = csv.reader(file)
        for row in reader:
            transactions.append(set(row))
    return transactions

def get_frequent_itemsets(transactions, min_support):
    item_counts = defaultdict(int)
    frequent_itemsets = []

    # Step 1: Generate 1-itemsets and their counts
    for transaction in transactions:
        for item in transaction:
            item_counts[item] += 1

    # Step 2: Filter frequent 1-itemsets
    for item, count in item_counts.items():
        if count / len(transactions) &gt;= min_support:
            frequent_itemsets.append((frozenset([item]), count))

    k = 2
    while True:
        # Step 3: Generate candidate k-itemsets
        candidates = set()
        for i in range(len(frequent_itemsets)):
            for j in range(i + 1, len(frequent_itemsets)):
                l1 = list(frequent_itemsets[i][0])
                l2 = list(frequent_itemsets[j][0])
                l1.sort()
                l2.sort()
                if l1[:k-2] == l2[:k-2]:
                    candidates.add(frozenset(l1[:k-2] + [l1[k-2], l2[k-2]]))

        # Step 4: Count support of each candidate
        candidate_counts = defaultdict(int)
        for candidate in candidates:
            for transaction in transactions:
                if candidate.issubset(transaction):
                    candidate_counts[candidate] += 1

        # Step 5: Filter frequent k-itemsets
        new_frequent_itemsets = []
        for candidate, count in candidate_counts.items():
            if count / len(transactions) &gt;= min_support:
                new_frequent_itemsets.append((candidate, count))
        # k-项集为空，终止
        if not new_frequent_itemsets:
            break

        frequent_itemsets.extend(new_frequent_itemsets)
        k += 1

    return frequent_itemsets

filename = 'GroceryStoreDataSet.csv'
min_support = 0.1
transactions = load_data(filename)
# print(transactions)
frequent_itemsets = get_frequent_itemsets(transactions, min_support)

for itemset, count in frequent_itemsets:
    print(f'Itemset: {itemset}, Support: {count/len(transactions):.2f}')

<br>Itemset: frozenset({'BREAD,TEA,BOURNVITA'}), Support: 0.10
Itemset: frozenset({'COFFEE,COCK,BISCUIT,CORNFLAKES'}), Support: 0.10
Itemset: frozenset({'BREAD,COFFEE,SUGER'}), Support: 0.10
]]></description><link>technology\collegeproject\数据挖掘\数据挖掘实验\实验四.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘实验/实验四.md</guid><pubDate>Sun, 27 Oct 2024 11:40:01 GMT</pubDate><enclosure url="technology\collegeproject\数据挖掘\数据挖掘实验\实验四_files\{3bde661d-9fd1-467b-b6d4-9f271e3ec52c}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数据挖掘\数据挖掘实验\实验四_files\{3bde661d-9fd1-467b-b6d4-9f271e3ec52c}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验五]]></title><description><![CDATA[ 
 <br>（1）了解Groceries_dataset.csv中事务集的属性信息，根据每个用户每天的购买记录构造事务（比如用户1000在2015年3月15日对应的事务为{‘sausage’，’whole milk’，’semi-finished bread’，’yogurt’}），然后按照用户ID递增，时间递增的方式对事务进行排序；<br>import pandas as pd
from mlxtend.frequent_patterns import apriori, fpgrowth, association_rules
from mlxtend.preprocessing import TransactionEncoder
import time

# 读取数据集
data = pd.read_csv('Groceries_dataset.csv')

# 构造事务集
# 将数据按照Member_number和Date分组，并将每组的itemDescription聚合为列表
transactions = data.groupby(['Member_number', 'Date'])['itemDescription'].apply(list).reset_index()

# 将事务转换为集合
transactions['Transaction'] = transactions['itemDescription'].apply(set)

# 排序
transactions = transactions.sort_values(by=['Member_number', 'Date'])

# 设置支持度阈值
support_threshold = 0.03  # 可以根据数据集的特点进行调整
<br>（2）选择事务集中前100条事务，选择合适的支持度阈值，使用Apriori算法和FP-growth算法挖掘频繁项集（推荐使用mlxtend包的apriori和fpgrowth函数），并对比apriori算法和fpgrowth算法的时间复杂度；<br># 定义一个函数来执行频繁项集挖掘并计算时间
def run_frequent_itemset_analysis(transactions, support_threshold):
    # 构建编码矩阵
    encoder = TransactionEncoder()
    encoded_array = encoder.fit(transactions).transform(transactions)
    encoded_df = pd.DataFrame(encoded_array, columns=encoder.columns_)

    # 使用Apriori算法
    start_time_apriori = time.time()
    frequent_itemsets_apriori = apriori(encoded_df, min_support=support_threshold, use_colnames=True)
    apriori_time = time.time() - start_time_apriori

    # 使用FP-growth算法
    start_time_fpgrowth = time.time()
    frequent_itemsets_fpgrowth = fpgrowth(encoded_df, min_support=support_threshold, use_colnames=True)
    fpgrowth_time = time.time() - start_time_fpgrowth

    return apriori_time, fpgrowth_time, frequent_itemsets_apriori, frequent_itemsets_fpgrowth

<br>（3）重复步骤（2），依次选择前500条，前1000条事务，对比apriori算法和fpgrowth算法的时间复杂度；<br># 选择前100条事务
top_100_transactions = transactions['Transaction'].head(100).tolist()
apriori_time_100, fpgrowth_time_100, frequent_itemsets_apriori_100, frequent_itemsets_fpgrowth_100 = run_frequent_itemset_analysis(top_100_transactions, support_threshold)


# 选择前500条事务
top_500_transactions = transactions['Transaction'].head(500).tolist()
apriori_time_500, fpgrowth_time_500, frequent_itemsets_apriori_500, frequent_itemsets_fpgrowth_500 = run_frequent_itemset_analysis(top_500_transactions, support_threshold)

# 选择前1000条事务
top_1000_transactions = transactions['Transaction'].head(1000).tolist()
apriori_time_1000, fpgrowth_time_1000, frequent_itemsets_apriori_1000, frequent_itemsets_fpgrowth_1000 = run_frequent_itemset_analysis(top_1000_transactions, support_threshold)

# 打印结果
print("前100条事务：")
print("Apriori执行时间: ", apriori_time_100)
print("FP-Growth执行时间: ", fpgrowth_time_100)

# 打印结果
print("前500条事务：")
print("Apriori执行时间: ", apriori_time_500)
print("FP-Growth执行时间: ", fpgrowth_time_500)

print("\n前1000条事务：")
print("Apriori执行时间: ", apriori_time_1000)
print("FP-Growth执行时间: ", fpgrowth_time_1000)
<br>前100条事务：
Apriori执行时间:  0.0025594234466552734
FP-Growth执行时间:  0.0009601116180419922
前500条事务：
Apriori执行时间:  0.0010161399841308594
FP-Growth执行时间:  0.005002498626708984

前1000条事务：
Apriori执行时间:  0.0019998550415039062
FP-Growth执行时间:  0.004000186920166016
<br># 打印前100条事务的频繁项集print("前100条事务的频繁项集（Apriori算法）：\n", frequent_itemsets_apriori_100)
print("\n前100条事务的频繁项集（FP-Growth算法）：\n", frequent_itemsets_apriori_100)
<br>前100条事务的频繁项集（FP-Growth算法）：
     support                           itemsets
0      0.03                         (UHT-milk)
1      0.04                             (beef)
2      0.04                     (bottled beer)
3      0.05                    (bottled water)
4      0.04                           (butter)
5      0.03                      (butter milk)
6      0.03                            (candy)
7      0.06                      (canned beer)
8      0.03                          (chicken)
9      0.04                        (chocolate)
10     0.04                             (curd)
11     0.03                          (dessert)
12     0.04                    (domestic eggs)
13     0.07                      (frankfurter)
14     0.04                     (frozen meals)
15     0.03                (frozen vegetables)
16     0.03            (fruit/vegetable juice)
17     0.03                   (hamburger meat)
18     0.08                 (other vegetables)
19     0.04                           (pastry)
20     0.05                        (pip fruit)
21     0.03                   (red/blush wine)
22     0.19                       (rolls/buns)
23     0.09                  (root vegetables)
24     0.03                      (salty snack)
25     0.08                          (sausage)
26     0.06                    (shopping bags)
27     0.06                             (soda)
28     0.08                   (tropical fruit)
29     0.06               (whipped/sour cream)
30     0.03                      (white bread)
31     0.18                       (whole milk)
32     0.11                           (yogurt)
33     0.04            (chocolate, rolls/buns)
34     0.03              (rolls/buns, sausage)
35     0.04           (rolls/buns, whole milk)
36     0.03  (root vegetables, tropical fruit)
37     0.03              (sausage, whole milk)
38     0.03           (yogurt, tropical fruit)
39     0.03               (yogurt, whole milk)
<br>（4）使用前100条事务时，选择合适的置信度阈值，利用挖掘到的频繁项集生成强关联规则（推荐使用mlxtend包的association_rules函数）。然后使用提升度、全置信度、最大置信度、Kluc度量和余弦度量评估这些强关联规则。<br># 生成强关联规则
confidence_threshold = 0.5
strong_rules = association_rules(frequent_itemsets_apriori_100, metric="confidence", min_threshold=confidence_threshold)

# 评估强关联规则
strong_rules['lift'] = strong_rules['confidence'] / strong_rules['consequent support']  # 计算提升度
strong_rules['cosine'] = strong_rules['support'] / (strong_rules['antecedent support'] * strong_rules['consequent support'])  # 计算余弦相似度

# 打印强关联规则
print("Strong Association Rules:\n", strong_rules[['antecedents', 'consequents', 'support', 'confidence', 'lift', 'cosine']])
<br>Strong Association Rules:
    antecedents   consequents  support  confidence      lift    cosine
0  (chocolate)  (rolls/buns)     0.04         1.0  5.263158  5.263158
]]></description><link>technology\collegeproject\数据挖掘\数据挖掘实验\实验五.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘实验/实验五.md</guid><pubDate>Mon, 04 Nov 2024 12:41:15 GMT</pubDate></item><item><title><![CDATA[数据挖掘实验一]]></title><description><![CDATA[ 
 <br><br><br>
<br>
PassengerId:

<br>解释: 这是一个唯一的标识符，用来区分每一位乘客。
<br>示例: 1 表示第一个乘客。


<br>
Survived:

<br>解释: 乘客是否幸存，0 表示未幸存，1 表示幸存。
<br>示例: 0 表示乘客未幸存；1 表示乘客幸存。


<br>
Pclass:

<br>解释: 乘客的船票等级，1 表示头等舱，2 表示二等舱，3 表示三等舱。
<br>示例: 3 表示乘客乘坐的是三等舱。


<br>
Name:

<br>解释: 乘客的名字。
<br>示例: Braund, Mr. Owen Harris 表示乘客名字为Owen Harris，称谓为Mr。


<br>
Sex:

<br>解释: 乘客的性别。
<br>示例: male 表示男性；female 表示女性。


<br>
Age:

<br>解释: 乘客的年龄。
<br>示例: 22.0 表示乘客年龄为22岁。


<br>
SibSp:

<br>解释: 乘客同行的兄弟姐妹或配偶的数量。
<br>示例: 1 表示乘客有一名兄弟姐妹或配偶同行。


<br>
Parch:

<br>解释: 乘客同行的父母或子女的数量。
<br>示例: 0 表示乘客没有父母或子女同行。


<br>
Ticket:

<br>解释: 乘客的船票号码。
<br>示例: A/5 21171 表示乘客持有的船票号码。


<br>
Fare:

<br>解释: 乘客支付的票价。
<br>示例: 7.2500 表示乘客支付的票价为7.25英镑。


<br>
Cabin:

<br>解释: 乘客的船舱号码。
<br>示例: C85 表示乘客的船舱位于C甲板第85号舱室。


<br>
Embarked:

<br>解释: 乘客登船的港口。
<br>示例: S 表示乘客从Southampton港登船；C 表示从Cherbourg登船；Q 表示从Queenstown登船。


<br><br>以您提供的第一行数据为例：<br>PassengerId: 1
Survived: 0
Pclass: 3
Name: Braund, Mr. Owen Harris
Sex: male
Age: 22.0
SibSp: 1
Parch: 0
Ticket: A/5 21171
Fare: 7.2500
Cabin: NaN
Embarked: S
<br>
<br>PassengerId: 1
<br>Survived: 0（未幸存）
<br>Pclass: 3（三等舱）
<br>Name: Braund, Mr. Owen Harris
<br>Sex: male
<br>Age: 22.0 岁
<br>SibSp: 1（有一名兄弟姐妹或配偶同行）
<br>Parch: 0（没有父母或子女同行）
<br>Ticket: A/5 21171
<br>Fare: 7.2500 英镑
<br>Cabin: 缺失值（NaN）
<br>Embarked: S（从Southampton港登船）
<br>这些特征一起提供了关于乘客背景及其在灾难中的命运的详细信息。通过分析这些特征，我们可以更好地理解哪些因素影响了乘客的生存概率。<br><br>import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
plt.rcParams['font.sans-serif'] = ['Microsoft YaHei'] # 指定默认字体：解决plot不能显示中文问题
plt.rcParams['axes.unicode_minus'] = False # 解决保存图像是负号'-'显示为方块的问题
# 读取数据
data = pd.read_csv('Titanic.csv')

<br><br># 查看数据集的基本信息
print(data.info())
# 检查缺失值
print(data.isnull().sum())
# 检查Ticket列是否每个乘客都不一样
num_unique_tickets = data['Ticket'].nunique()
num_passengers = len(data)

if num_unique_tickets == num_passengers:
    print("每个乘客的Ticket都是唯一的。")
else:
    print(f"存在重复的Ticket。共有 {num_passengers} 名乘客，但只有 {num_unique_tickets} 个唯一的Ticket。")

# 打印重复的Ticket及其出现次数
duplicate_tickets = data['Ticket'].value_counts()[lambda x: x &gt; 1]
print(duplicate_tickets)
<br>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 891 entries, 0 to 890
Data columns (total 12 columns):
 #   Column       Non-Null Count  Dtype  
---  ------       --------------  -----  
 0   PassengerId  891 non-null    int64  
 1   Survived     891 non-null    int64  
 2   Pclass       891 non-null    int64  
 3   Name         891 non-null    object 
 4   Sex          891 non-null    object 
 5   Age          714 non-null    float64
 6   SibSp        891 non-null    int64  
 7   Parch        891 non-null    int64  
 8   Ticket       891 non-null    object 
 9   Fare         891 non-null    float64
 10  Cabin        204 non-null    object 
 11  Embarked     889 non-null    object 
dtypes: float64(2), int64(5), object(5)
memory usage: 83.7+ KB
None
PassengerId      0
Survived         0
Pclass           0
Name             0
Sex              0
Age            177
SibSp            0
Parch            0
Ticket           0
Fare             0
Cabin          687
Embarked         2
dtype: int64
存在重复的Ticket。共有 891 名乘客，但只有 681 个唯一的Ticket。
Ticket
347082             7
CA. 2343           7
1601               7
3101295            6
CA 2144            6
                  ..
248738             2
12749              2
19996              2
S.C./PARIS 2079    2
349237             2
Name: count, Length: 134, dtype: int64
<br>以上为数据集基本信息，12列，891行。其中缺失值主要是年龄和船舱的较多，同时tiket表示船票的编号，但是只有681个乘客是有唯一编号的。其他数据都正常。<br><br><br>##画图
# Pclass属性的饼图
plt.figure(figsize=(6, 6))
data['Pclass'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140)
plt.title('乘客等级分布')
plt.ylabel('')  # 移除默认的“频数”标签
plt.show()

# Sex属性的饼图
plt.figure(figsize=(6, 6))
data['Sex'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140)
plt.title('性别分布')
plt.ylabel('')
plt.show()

# Age属性的直方图
plt.figure(figsize=(10, 6))
sns.histplot(data=data, x='Age', bins=20, kde=True)
plt.title('年龄分布')
plt.xlabel('年龄')
plt.ylabel('人数')
plt.show()

# SibSp属性的直方图
plt.figure(figsize=(8, 6))
data['SibSp'].value_counts().sort_index().plot(kind='bar')
plt.title('兄弟姐妹/配偶数量分布')
plt.xlabel('兄弟姐妹/配偶数量')
plt.ylabel('人数')
plt.show()

# Fare属性的直方图
plt.figure(figsize=(10, 6))
sns.histplot(data=data, x='Fare', bins=20, kde=True)
plt.title('票价分布')
plt.xlabel('票价')
plt.ylabel('人数')
plt.show()

# Embarked属性的饼图
plt.figure(figsize=(6, 6))
data['Embarked'].value_counts().plot(kind='pie', autopct='%1.1f%%', startangle=140)
plt.title('登船地点分布')
plt.ylabel('')
plt.show()
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_4_0.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_4_1.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_4_3.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_4_4.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_4_6.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_4_7.png"><br><br># 年龄与生存情况的关系
plt.figure(figsize=(10, 6))
sns.boxplot(x='Survived', y='Age', data=data)
plt.title('年龄与生存情况的关系')
plt.xlabel('生存情况')
plt.ylabel('年龄')
plt.show()

# 计算生存和未生存乘客的平均年龄和标准差
survived_age_stats = data[data['Survived'] == 1]['Age'].describe()
not_survived_age_stats = data[data['Survived'] == 0]['Age'].describe()

print("生存乘客的年龄统计:")
print(survived_age_stats)
print("\n未生存乘客的年龄统计:")
print(not_survived_age_stats)
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_5_0.png"><br>生存乘客的年龄统计:
count    290.000000
mean      28.343690
std       14.950952
min        0.420000
25%       19.000000
50%       28.000000
75%       36.000000
max       80.000000
Name: Age, dtype: float64

未生存乘客的年龄统计:
count    424.000000
mean      30.626179
std       14.172110
min        1.000000
25%       21.000000
50%       28.000000
75%       39.000000
max       74.000000
Name: Age, dtype: float64
<br># 性别与生存情况的关系
survival_by_sex = data.groupby(['Sex', 'Survived']).size().unstack()
print(survival_by_sex)

plt.figure(figsize=(8, 6))
sns.barplot(x='Sex', y='Survived', data=data)
plt.title('性别与生存情况的关系')
plt.xlabel('性别')
plt.ylabel('生存率')
plt.show()
<br>Survived    0    1
Sex               
female     81  233
male      468  109
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_6_1.png"><br># 社会地位（乘客等级）与生存情况的关系
survival_by_pclass = data.groupby(['Pclass', 'Survived']).size().unstack()
print(survival_by_pclass)

plt.figure(figsize=(8, 6))
sns.barplot(x='Pclass', y='Survived', data=data)
plt.title('社会地位与生存情况的关系')
plt.xlabel('乘客等级')
plt.ylabel('生存率')
plt.show()
<br>Survived    0    1
Pclass            
1          80  136
2          97   87
3         372  119
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_7_1.png"><br><br># 票价与其他属性的相关性
from sklearn.preprocessing import LabelEncoder

# 创建LabelEncoder对象
le = LabelEncoder()

# 将Embarked列转换为数值类型
data['Embarked'] = le.fit_transform(data['Embarked'])

correlation_matrix = data[['Fare', 'SibSp', 'Parch', 'Age','Pclass','Embarked']].corr()
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')
plt.title('票价与其他属性的相关性')
plt.show()

# 票价与乘客等级的关系
plt.figure(figsize=(8, 6))
sns.boxplot(x='Pclass', y='Fare', data=data)
plt.title('票价与乘客等级的关系')
plt.xlabel('乘客等级')
plt.ylabel('票价')
plt.show()
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_8_0.png"><br>可见与Pclass的相关性最强，这也符合常理，船舱数越小，等级越高，票价自然越高。<br><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_8_1.png"><br><br>
<br>船舱等级为三号舱的乘客最多占比达到55%。
<br>性别分布整体男性较多女性较少。
<br>年龄分布整体中青年较多，儿童和老人较少。
<br>大多数乘客没有携带兄弟姐妹和配偶。
<br>票价分布整体符合船舱分布。
<br>在S港登船人数占大多数。
<br>幸存下来的乘客比未幸存乘客年龄低一些，但没低多少。但老年人明显幸存较少。
<br>女性幸存率远大于男性。
<br>船舱等级越高，幸存率越高。
<br>票价与船舱等级具有强相关，且头等舱有明显的非常高的离群值。
]]></description><link>technology\collegeproject\数据挖掘\数据挖掘实验\数据挖掘实验一.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘实验/数据挖掘实验一.md</guid><pubDate>Sat, 14 Sep 2024 03:47:57 GMT</pubDate><enclosure url="technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_4_0.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数据挖掘\数据挖掘实验\test_files\test_4_0.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数据预处理]]></title><description><![CDATA[ 
 <br><br>
<br>明确数据集中每个属性的含义
<br>缺失值处理
<br>判断哪些属性需要规范化，选择合适的方法对这些属性进行数据规范化
<br>判断哪些属性可以离散化，选择合适的方法对这些属性进行数据离散化；
<br>import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler,StandardScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error
import numpy as np
import matplotlib.pyplot as plt
# 导入数据
df = pd.read_csv('housing.csv')

# 明确数据集中每个属性的含义
print(df.info())

# 缺失值查找
print(df.isnull().sum())


<br>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 20640 entries, 0 to 20639
Data columns (total 10 columns):
 #   Column              Non-Null Count  Dtype  
---  ------              --------------  -----  
 0   longitude           20640 non-null  float64
 1   latitude            20640 non-null  float64
 2   housing_median_age  20640 non-null  float64
 3   total_rooms         20640 non-null  float64
 4   total_bedrooms      20433 non-null  float64
 5   population          20640 non-null  float64
 6   households          20640 non-null  float64
 7   median_income       20640 non-null  float64
 8   median_house_value  20640 non-null  float64
 9   ocean_proximity     20640 non-null  object 
dtypes: float64(9), object(1)
memory usage: 1.6+ MB
None
longitude               0
latitude                0
housing_median_age      0
total_rooms             0
total_bedrooms        207
population              0
households              0
median_income           0
median_house_value      0
ocean_proximity         0
dtype: int64
<br><br>有一个包含20640条记录的Pandas DataFrame，其中有10个列，9个是浮点数类型（float64），1个是对象类型（object），可能是字符串或分类数据。此外，total_bedrooms 列有207个缺失值，而其他列没有缺失值<br># 缺失值处理（中位数）
median_bedrooms = df['total_bedrooms'].median()
df['total_bedrooms'] = df['total_bedrooms'].fillna(median_bedrooms)

# 将 ocean_proximity 转换为类别类型
df['ocean_proximity'] = df['ocean_proximity'].astype('category')

# 对 ocean_proximity 进行独热编码
df = pd.get_dummies(df, columns=['ocean_proximity'])

# 规范化连续特征
scaler = MinMaxScaler()
continuous_features = ['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']
df[continuous_features] = scaler.fit_transform(df[continuous_features])
# 或者使用 StandardScaler 进行标准化
# scaler = StandardScaler()
# df[['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']] = scaler.fit_transform(
#     df[['longitude', 'latitude', 'housing_median_age', 'total_rooms', 'total_bedrooms', 'population', 'households', 'median_income']]
# )


<br><br>将数据集的前70%作为训练集，剩余的30%作为测试集（去掉包含缺失值的样本）。对训练集分别随机抽取10%，30%，50%和80%的样本作为训练子集，利用训练子集训练线性回归模型，然后在测试集上预测房价属性。以MSE作为评估指标，观察不同采样率下模型性能的变化；<br># 划分训练集和测试集
train_df, test_df = train_test_split(df, test_size=0.3, random_state=42)

# 特征和目标变量
X_train = train_df.drop(columns=['median_house_value'])
y_train = train_df['median_house_value']

X_test = test_df.drop(columns=['median_house_value'])
y_test = test_df['median_house_value']

# 训练并评估不同采样率下的线性回归模型
sampling_rates = [0.1, 0.3, 0.5, 0.8]
mse_scores = []

for rate in sampling_rates:
    # 随机抽样
    sample_X_train, _, sample_y_train, _ = train_test_split(X_train, y_train, train_size=rate, random_state=42)
    
    # 创建并训练模型
    model = LinearRegression()
    model.fit(sample_X_train, sample_y_train)
    
    # 在测试集上预测
    predictions = model.predict(X_test)
    
    # 计算MSE
    mse = mean_squared_error(y_test, predictions)
    mse_scores.append(mse)
    print(f'Sampling Rate: {rate * 100}%, MSE: {mse}')

# 输出所有MSE分数
print("MSE scores for different sampling rates:", mse_scores)

# 绘制预测值和真实值的对比图
plt.figure(figsize=(10, 6))
plt.scatter(y_test, predictions, alpha=0.5, label='Predicted vs Actual')
plt.plot([min(y_test), max(y_test)], [min(y_test), max(y_test)], color='red', linestyle='--', linewidth=2, label='Perfect Prediction')
plt.xlabel('Actual Median House Value (in $100,000s)')
plt.ylabel('Predicted Median House Value (in $100,000s)')
plt.title('Actual vs Predicted Median House Values')
plt.legend()
plt.show()
<br>Sampling Rate: 10.0%, MSE: 4805741281.524673
Sampling Rate: 30.0%, MSE: 4768419864.567593
Sampling Rate: 50.0%, MSE: 4753008975.729645
Sampling Rate: 80.0%, MSE: 4736354667.992623
MSE scores for different sampling rates: [4805741281.524673, 4768419864.567593, 4753008975.729645, 4736354667.992623]
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘实验\california-housing_files\california-housing_5_1.png">]]></description><link>technology\collegeproject\数据挖掘\数据挖掘实验\california-housing.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘实验/California Housing.md</guid><pubDate>Fri, 18 Oct 2024 09:02:28 GMT</pubDate><enclosure url="technology\collegeproject\数据挖掘\数据挖掘实验\california-housing_files\california-housing_5_1.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数据挖掘\数据挖掘实验\california-housing_files\california-housing_5_1.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数据挖掘大作业]]></title><description><![CDATA[ 
 <br><br><br>本实验为kaggle 12月份Tabular Playground比赛"Regression with an Insurance Dataset",是通过各种特征对保险金额做回归。<br><br>本次比赛（训练和测试）的数据集是根据在 Insurance Premium Prediction 数据集上训练的深度学习模型生成的。特征分布与原始分布接近，但不完全相同。<br><br>
<br>train.csv - 训练数据集;保费金额是持续目标
<br>test.csv - 测试数据集;目标是预测每行的目标 Premium Amount
<br>sample_submission.csv - 正确格式的样本提交文件
<br><br>这是一个包含保险客户信息的数据集。每个特征代表了客户的不同信息或行为。以下是每个特征的解释：<br>
<br>
id: 客户的唯一标识符。通常是一个数字，用于区分不同的客户。

<br>
Age: 客户的年龄（以年为单位）。这个特征提供了客户的年龄信息，可能影响其保险需求和保费计算。

<br>
Gender: 客户的性别。常见的取值为"Male"（男性）和"Female"（女性）。性别在某些保险产品的定价上可能会有所影响。

<br>
Annual Income: 客户的年收入（以货币单位表示）。收入通常与客户的支付能力、保费支付能力等相关。

<br>
Marital Status: 客户的婚姻状况。常见的取值为"Single"（单身）和"Married"（已婚）和"Divorced"（离婚）。婚姻状况可能影响家庭保险的类型或其他相关服务。

<br>
Number of Dependents: 客户的抚养人数。这个数字表示客户需要抚养的孩子或其他家庭成员的数量，这可能影响家庭保险的需求。

<br>
Education Level: 客户的教育程度。常见的取值有"High School"（高中）、"Bachelor's"（学士）、"Master's"（硕士）等。教育水平可能与收入、健康状况、保险需求等有一定关系。

<br>
Occupation: 客户的职业。示例中的"Self-Employed"表示自雇人士。职业可能影响客户的收入、健康状况以及风险评估。

<br>
Health Score: 客户的健康评分（可能是根据体检或健康状况评估的一个数值）。高健康评分可能意味着较低的保险风险。

<br>
Location: 客户的地理位置或居住地类型。示例中为"Urban"（城市）。不同地理位置可能会影响保险需求和保费。

<br>
Policy Type: 保险类型。示例中为"Premium"（优质型）。可能还有其他类型，如"Basic"（基础型）、"Standard"（标准型）等。不同保险类型的覆盖范围、费用和条件不同。

<br>
Previous Claims: 客户之前是否有过保险理赔记录。数值通常表示理赔次数。理赔次数多的客户可能被视为更高风险客户。

<br>
Vehicle Age: 车辆的年龄（以年为单位）。这通常适用于汽车保险，车辆的年龄与保险费用和理赔概率有关。

<br>
Credit Score: 客户的信用评分。信用评分是衡量客户信用状况的重要指标，通常影响贷款、信用卡申请等，也可能影响保险定价。

<br>
Insurance Duration: 客户购买保险的持续时间（以年为单位）。较长的保险持续时间可能表示客户对保险产品有较高的忠诚度或长期的需求。

<br>
Policy Start Date: 保险开始的日期。通常是客户购买保险的日期。该日期可能影响保险的条款和保费。

<br>
Customer Feedback: 客户反馈。这是客户对保险公司服务的评价，可能有多个值，如"Good"（好）、"Fair"（一般）、"Poor"（差）。反馈的质量可能影响客户满意度和保险公司的服务调整。

<br>
Smoking Status: 客户是否吸烟。示例中为"No"（不吸烟）。吸烟状态通常与健康相关，可能影响人寿保险的定价。

<br>
Exercise Frequency: 客户的运动频率。示例中为"Weekly"（每周）。运动频率通常与健康状况相关，较频繁的运动可能意味着较低的健康风险。

<br>
Property Type: 客户居住的房产类型。示例中为"House"（住宅）。其他类型可能包括"Apartment"（公寓）、"Condo"（公寓式住宅）等。

<br>
Premium Amount: 客户支付的保险费用金额。该数值通常与客户的年龄、健康状况、保险类型等因素相关，是保险合同中规定的金额。

<br>这些特征共同构成了客户的个人和保险信息，可以用于分析客户的需求、行为模式以及保险公司可能的风险评估。<br><br><br>针对每个特征进行分析，打印mean，std，max，min，缺失值数量，并画出分布图。<br>import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os
# 设置图表的显示样式
sns.set_theme(style="whitegrid")

data_path_train='/kaggle/input/data-list/train.csv'
data_path_test ='/kaggle/input/data-list/test.csv'
data_output='/kaggle/working'
# 读取数据
df = pd.read_csv(data_path_train)


# 检查数据结构
df.info()
# 删除包含缺失值的行
df = df.dropna()
# 选择数值型特征
numeric_cols = df.select_dtypes(include=[np.number]).columns

# 计算并打印数值型特征的统计量
for col in numeric_cols:
    print(f"--- {col} ---")
    print(f"Mean: {df[col].mean()}")
    print(f"Std: {df[col].std()}")
    print(f"Max: {df[col].max()}")
    print(f"Min: {df[col].min()}")
    print(f"Missing values: {df[col].isnull().sum()}\n")

# 选择数值型特征，跳过 'id' 列
numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()
numeric_cols.remove('id')  # 去除 'id' 列

# 画数值型特征的分布
for col in numeric_cols:
    plt.figure(figsize=(10, 6))
    # 复制一份数据
    df_cleaned = df.copy()
    # 画直方图
    sns.histplot(df_cleaned[col].dropna(), kde=True, bins=30, color='skyblue', label=col)
    
    # 设置标题和标签
    plt.title(f'Distribution of {col}')
    plt.xlabel(col)
    plt.ylabel('Frequency')
    
    # 显示图例
    plt.legend()

    # 显示当前图
    plt.show()

# 绘制类别型特征的分布图
categorical_cols = df.select_dtypes(include=[object]).columns.tolist()
categorical_cols.remove('Policy Start Date')

# 画类别型特征的饼图
for col in categorical_cols:
    plt.figure(figsize=(8, 8))
    df_cleaned = df.copy()
    
    # 计算每个类别的频率
    value_counts = df_cleaned[col].dropna().value_counts()
    
    # 绘制饼图
    plt.pie(value_counts, 
            labels=value_counts.index,
            autopct='%1.1f%%',
            colors=plt.cm.Paired.colors,
            startangle=90,
            shadow=True,  # 添加阴影效果
            explode=[0.05] * len(value_counts))  # 稍微分离饼图各部分
    
    # 设置标题
    plt.title(f'Distribution of {col}', pad=20, size=12)
    
    # 确保饼图是圆形的
    plt.axis('equal')
    
    # 显示当前图
    plt.show()


<br>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 1200000 entries, 0 to 1199999
Data columns (total 21 columns):
 #   Column                Non-Null Count    Dtype  
---  ------                --------------    -----  
 0   id                    1200000 non-null  int64  
 1   Age                   1181295 non-null  float64
 2   Gender                1200000 non-null  object 
 3   Annual Income         1155051 non-null  float64
 4   Marital Status        1181471 non-null  object 
 5   Number of Dependents  1090328 non-null  float64
 6   Education Level       1200000 non-null  object 
 7   Occupation            841925 non-null   object 
 8   Health Score          1125924 non-null  float64
 9   Location              1200000 non-null  object 
 10  Policy Type           1200000 non-null  object 
 11  Previous Claims       835971 non-null   float64
 12  Vehicle Age           1199994 non-null  float64
 13  Credit Score          1062118 non-null  float64
 14  Insurance Duration    1199999 non-null  float64
 15  Policy Start Date     1200000 non-null  object 
 16  Customer Feedback     1122176 non-null  object 
 17  Smoking Status        1200000 non-null  object 
 18  Exercise Frequency    1200000 non-null  object 
 19  Property Type         1200000 non-null  object 
 20  Premium Amount        1200000 non-null  float64
dtypes: float64(9), int64(1), object(11)
memory usage: 192.3+ MB
--- id ---
Mean: 599960.9926563265
Std: 346158.47158530116
Max: 1199990
Min: 0
Missing values: 0

--- Age ---
Mean: 41.13939438130853
Std: 13.531632036789356
Max: 64.0
Min: 18.0
Missing values: 0

--- Annual Income ---
Mean: 33072.90008697826
Std: 32370.321641987335
Max: 149997.0
Min: 2.0
Missing values: 0

--- Number of Dependents ---
Mean: 2.014088394912553
Std: 1.4154778446794853
Max: 4.0
Min: 0.0
Missing values: 0

--- Health Score ---
Mean: 25.58009385308614
Std: 12.194086048674123
Max: 58.4524782003252
Min: 2.0244152291796618
Missing values: 0

--- Previous Claims ---
Mean: 0.9962474349225529
Std: 0.9781609047689324
Max: 8.0
Min: 0.0
Missing values: 0

--- Vehicle Age ---
Mean: 9.561679045009948
Std: 5.7740092300972155
Max: 19.0
Min: 0.0
Missing values: 0

--- Credit Score ---
Mean: 594.0128201789564
Std: 149.60769574556605
Max: 849.0
Min: 300.0
Missing values: 0

--- Insurance Duration ---
Mean: 5.020356558785846
Std: 2.5965249447953083
Max: 9.0
Min: 1.0
Missing values: 0

--- Premium Amount ---
Mean: 1113.1870162810803
Std: 868.6883587214742
Max: 4997.0
Min: 20.0
Missing values: 0



/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context('mode.use_inf_as_na', True):
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_2.png"><br>/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context('mode.use_inf_as_na', True):
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_4.png"><br>/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context('mode.use_inf_as_na', True):
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_6.png"><br>/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context('mode.use_inf_as_na', True):
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_8.png"><br>/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context('mode.use_inf_as_na', True):
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_10.png"><br>/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context('mode.use_inf_as_na', True):
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_12.png"><br>/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context('mode.use_inf_as_na', True):
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_14.png"><br>/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context('mode.use_inf_as_na', True):
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_16.png"><br>/opt/conda/lib/python3.10/site-packages/seaborn/_oldcore.py:1119: FutureWarning: use_inf_as_na option is deprecated and will be removed in a future version. Convert inf values to NaN before operating instead.
  with pd.option_context('mode.use_inf_as_na', True):
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_18.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_19.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_20.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_21.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_22.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_23.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_24.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_25.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_26.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_27.png"><br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_28.png"><br><br>检查测试集是否有缺失值，进行数据预处理：<br>包括缺失值处理，对非数值型变量进行哑编码，数据标准化。<br>import pandas as pd
import numpy as np

# 读取测试数据
test_df = pd.read_csv(data_path_test)

# 1. 显示数据基本信息
print("数据基本信息:")
print(test_df.info())

# 2. 检查每列的缺失值数量和百分比
missing_values = pd.DataFrame({
    'Missing Values': test_df.isnull().sum(),
    'Percentage': (test_df.isnull().sum() / len(test_df)) * 100
})
missing_values = missing_values.sort_values('Missing Values', ascending=False)

print("\n缺失值统计:")
print(missing_values[missing_values['Missing Values'] &gt; 0])

# 3. 分类型统计缺失值
numeric_cols = test_df.select_dtypes(include=[np.number]).columns
categorical_cols = test_df.select_dtypes(include=[object]).columns

print("\n数值型特征的缺失值:")
print(test_df[numeric_cols].isnull().sum()[test_df[numeric_cols].isnull().sum() &gt; 0])

print("\n类别型特征的缺失值:")
print(test_df[categorical_cols].isnull().sum()[test_df[categorical_cols].isnull().sum() &gt; 0])

# 4. 计算总的缺失值比例
total_missing = test_df.isnull().sum().sum()
total_cells = np.product(test_df.shape)
print(f"\n总缺失值比例: {(total_missing/total_cells)*100:.2f}%")

# 5. 检查是否有完全缺失的列
completely_missing = test_df.columns[test_df.isnull().sum() == len(test_df)]
if len(completely_missing) &gt; 0:
    print("\n完全缺失的列:")
    print(completely_missing)
<br>数据基本信息:
&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 800000 entries, 0 to 799999
Data columns (total 20 columns):
 #   Column                Non-Null Count   Dtype  
---  ------                --------------   -----  
 0   id                    800000 non-null  int64  
 1   Age                   787511 non-null  float64
 2   Gender                800000 non-null  object 
 3   Annual Income         770140 non-null  float64
 4   Marital Status        787664 non-null  object 
 5   Number of Dependents  726870 non-null  float64
 6   Education Level       800000 non-null  object 
 7   Occupation            560875 non-null  object 
 8   Health Score          750551 non-null  float64
 9   Location              800000 non-null  object 
 10  Policy Type           800000 non-null  object 
 11  Previous Claims       557198 non-null  float64
 12  Vehicle Age           799997 non-null  float64
 13  Credit Score          708549 non-null  float64
 14  Insurance Duration    799998 non-null  float64
 15  Policy Start Date     800000 non-null  object 
 16  Customer Feedback     747724 non-null  object 
 17  Smoking Status        800000 non-null  object 
 18  Exercise Frequency    800000 non-null  object 
 19  Property Type         800000 non-null  object 
dtypes: float64(8), int64(1), object(11)
memory usage: 122.1+ MB
None

缺失值统计:
                      Missing Values  Percentage
Previous Claims               242802   30.350250
Occupation                    239125   29.890625
Credit Score                   91451   11.431375
Number of Dependents           73130    9.141250
Customer Feedback              52276    6.534500
Health Score                   49449    6.181125
Annual Income                  29860    3.732500
Age                            12489    1.561125
Marital Status                 12336    1.542000
Vehicle Age                        3    0.000375
Insurance Duration                 2    0.000250

数值型特征的缺失值:
Age                      12489
Annual Income            29860
Number of Dependents     73130
Health Score             49449
Previous Claims         242802
Vehicle Age                  3
Credit Score             91451
Insurance Duration           2
dtype: int64

类别型特征的缺失值:
Marital Status        12336
Occupation           239125
Customer Feedback     52276
dtype: int64

总缺失值比例: 5.02%
<br>import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler

# 读取训练集和测试集
train_df = pd.read_csv(data_path_train)
test_df = pd.read_csv(data_path_test)

# 删除日期列和目标变量
train_df = train_df.drop(['Policy Start Date'], axis=1)
test_df = test_df.drop(['Policy Start Date'], axis=1)

# 直接删除id列
train_df = train_df.drop(['id'], axis=1)
test_df = test_df.drop(['id'], axis=1)

# 分离训练集的特征和目标变量
X_train = train_df.drop(['Premium Amount'], axis=1)
y_train = train_df['Premium Amount']

# 分离数值型、类别型
numeric_cols = X_train.select_dtypes(include=[np.number]).columns.tolist()
categorical_cols = X_train.select_dtypes(include=[object]).columns.tolist()

# 处理训练集和测试集的缺失值
# 创建数据副本
X_train_processed = X_train.copy()
X_test_processed = test_df.copy()

# 用训练集的均值填充数值型特征的缺失值
for col in numeric_cols:
    mean_value = X_train_processed[col].mean()
    X_train_processed[col] = X_train_processed[col].fillna(mean_value)
    X_test_processed[col] = X_test_processed[col].fillna(mean_value)

# 用训练集的众数填充类别型特征的缺失值
for col in categorical_cols:
    mode_value = X_train_processed[col].mode()[0]
    X_train_processed[col] = X_train_processed[col].fillna(mode_value)
    X_test_processed[col] = X_test_processed[col].fillna(mode_value)

# 对类别型变量进行独热编码
# 合并训练集和测试集以确保编码一致
combined_data = pd.concat([X_train_processed, X_test_processed])
combined_encoded = pd.get_dummies(combined_data, columns=categorical_cols, drop_first=True)

# 分离回训练集和测试集
X_train_encoded = combined_encoded[:len(X_train_processed)]
X_test_encoded = combined_encoded[len(X_train_processed):]

# 处理布尔型变量：将布尔类型变量转换为整数类型（使用 .loc）
bool_columns = X_train_encoded.select_dtypes(include='bool').columns

# 显式将布尔列转换为整数类型
X_train_encoded.loc[:, bool_columns] = X_train_encoded.loc[:, bool_columns].astype(int)
X_test_encoded.loc[:, bool_columns] = X_test_encoded.loc[:, bool_columns].astype(int)
# 标准化数值特征
scaler = StandardScaler()
numeric_cols_to_scale = [col for col in numeric_cols if col != 'id']
X_train_encoded.loc[:, numeric_cols_to_scale] = scaler.fit_transform(X_train_encoded[numeric_cols_to_scale])
X_test_encoded.loc[:, numeric_cols_to_scale] = scaler.transform(X_test_encoded[numeric_cols_to_scale])

# 显示处理后的数据信息
print("训练集处理后的数据形状:", X_train_encoded.shape)
print("测试集处理后的数据形状:", X_test_encoded.shape)
print(X_train_encoded.head())
print(X_test_encoded.head())

# 检查是否还有缺失值
print("\n训练集缺失值检查:")
print(X_train_encoded.isnull().sum().sum())
print("\n测试集缺失值检查:")
print(X_test_encoded.isnull().sum().sum())

# 保存处理后的数据
X_train_encoded.to_csv(os.path.join(data_output,'processed_train_features.csv'), index=False)
X_test_encoded.to_csv(os.path.join(data_output,'processed_test_features.csv'), index=False)
y_train.to_csv(os.path.join(data_output,'train_target.csv'), index=False)

<br>训练集处理后的数据形状: (1200000, 28)
测试集处理后的数据形状: (800000, 28)
        Age  Annual Income  Number of Dependents  Health Score  \
0 -1.648471      -0.718893             -0.747535     -0.255071   
1 -0.159711      -0.033804              0.732830     -0.849704   
2 -1.350719      -0.226258              0.732830      1.824212   
3 -1.499595       3.456006             -0.007353     -1.241521   
4 -1.499595       0.218738             -0.747535     -0.443102   

   Previous Claims  Vehicle Age  Credit Score  Insurance Duration  \
0         1.215746     1.286338 -1.565702e+00           -0.007023   
1        -0.003278     0.420713  7.163281e-01           -1.163391   
2        -0.003278     0.766963 -1.611408e-15           -0.777935   
3        -0.003278    -1.656787 -1.601137e+00           -1.548847   
4        -1.222302    -0.271787  3.597138e-02           -0.392479   

   Gender_Male  Marital Status_Married  ...  Policy Type_Comprehensive  \
0            0                       1  ...                          0   
1            0                       0  ...                          1   
2            1                       0  ...                          0   
3            1                       1  ...                          0   
4            1                       0  ...                          0   

   Policy Type_Premium  Customer Feedback_Good  Customer Feedback_Poor  \
0                    1                       0                       1   
1                    0                       0                       0   
2                    1                       1                       0   
3                    0                       0                       1   
4                    1                       0                       1   

   Smoking Status_Yes  Exercise Frequency_Monthly  Exercise Frequency_Rarely  \
0                   0                           0                          0   
1                   1                           1                          0   
2                   1                           0                          0   
3                   1                           0                          0   
4                   1                           0                          0   

   Exercise Frequency_Weekly  Property Type_Condo  Property Type_House  
0                          1                    0                    1  
1                          0                    0                    1  
2                          1                    0                    1  
3                          0                    0                    0  
4                          1                    0                    1  

[5 rows x 28 columns]
        Age  Annual Income  Number of Dependents  Health Score  \
0 -0.978529      -0.964023              1.473012     -1.519011   
1 -0.755215       2.954788             -0.007353     -1.034831   
2  0.435792      -0.495809             -1.487718     -0.106539   
3 -0.978529      -0.073524              0.732830     -1.732344   
4 -1.276281      -0.693110             -0.007353     -1.164875   

   Previous Claims  Vehicle Age  Credit Score  Insurance Duration  \
0    -5.413556e-16     1.632588 -1.611408e-15           -1.548847   
1    -5.413556e-16     0.766963 -1.565702e+00            1.149346   
2    -5.413556e-16     1.113213  1.602209e+00            1.534802   
3    -3.278064e-03    -1.137412  1.254944e+00           -0.007023   
4    -5.413556e-16     0.766963  1.148638e+00            0.763889   

   Gender_Male  Marital Status_Married  ...  Policy Type_Comprehensive  \
0            0                       0  ...                          0   
1            0                       1  ...                          0   
2            0                       0  ...                          1   
3            0                       0  ...                          1   
4            1                       0  ...                          0   

   Policy Type_Premium  Customer Feedback_Good  Customer Feedback_Poor  \
0                    0                       0                       1   
1                    1                       1                       0   
2                    0                       0                       0   
3                    0                       0                       1   
4                    1                       0                       0   

   Smoking Status_Yes  Exercise Frequency_Monthly  Exercise Frequency_Rarely  \
0                   1                           0                          0   
1                   1                           0                          1   
2                   1                           1                          0   
3                   1                           0                          0   
4                   0                           0                          0   

   Exercise Frequency_Weekly  Property Type_Condo  Property Type_House  
0                          1                    0                    1  
1                          0                    0                    0  
2                          0                    1                    0  
3                          0                    0                    1  
4                          1                    0                    1  

[5 rows x 28 columns]

训练集缺失值检查:
0

测试集缺失值检查:
0
<br><br>from sklearn.tree import DecisionTreeRegressor
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
import pandas as pd

# 读取训练数据和目标
X_train_encoded = pd.read_csv(os.path.join(data_output,'processed_train_features.csv'))
y_train = pd.read_csv(os.path.join(data_output,'train_target.csv'))

# 划分训练集和验证集（80%训练集，20%验证集）
X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_train_encoded, y_train, test_size=0.1, random_state=42)

# 配置决策树回归模型的参数
model = DecisionTreeRegressor(
    random_state=42,
    max_depth=10,             # 最大深度，防止过拟合
    min_samples_split=20,     # 每次划分所需的最小样本数
    min_samples_leaf=10,      # 叶节点上的最小样本数
    max_features='sqrt',      # 每次分裂时随机选择的最大特征数，改为'sqrt'
    max_leaf_nodes=20,        # 限制树的最大叶子节点数
    splitter='best'           # 分裂策略，选择最佳分裂
)

# 在训练集上训练模型
model.fit(X_train_final, y_train_final)

# 在验证集上评估模型
y_val_pred = model.predict(X_val_final)
mse = mean_squared_error(y_val_final, y_val_pred)
r2 = r2_score(y_val_final, y_val_pred)

print(f"验证集均方误差 (MSE): {mse}")
print(f"验证集决定系数 (R^2): {r2}")

# 读取测试集数据
X_test_encoded = pd.read_csv(os.path.join(data_output,'processed_test_features.csv'))
test = pd.read_csv(data_path_test)

# 在测试集上进行预测
y_test_pred = model.predict(X_test_encoded)

# 保存预测结果
test_predictions = pd.DataFrame({
    'id': test['id'],  # 保留测试集的 ID 列
    'Premium Amount': y_test_pred.ravel()  # 确保 y_test_pred 是一维数组
})

# 保存预测结果到CSV文件
test_predictions.to_csv('test_predictions.csv', index=False)

# 打印预测结果的一部分
print(test_predictions.head())

<br>验证集均方误差 (MSE): 745621.2477003287
验证集决定系数 (R^2): 0.0022548091292917682
        id  Premium Amount
0  1200000     1221.422302
1  1200001     1096.357007
2  1200002     1083.216709
3  1200003     1083.216709
4  1200004     1083.216709
<br><br>import torch
import torch.nn as nn
import torch.optim as optim
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error, r2_score
from torch.utils.data import DataLoader, TensorDataset
from torch.optim.lr_scheduler import StepLR

# 读取处理后的数据
X_train_encoded = pd.read_csv(os.path.join(data_output,'processed_train_features.csv'))
y_train = pd.read_csv('train_target.csv')

# 将数据转换为 numpy 数组
X_train_encoded = X_train_encoded.values
y_train = y_train.values

# 划分训练集和验证集（80%训练集，20%验证集）
X_train_final, X_val_final, y_train_final, y_val_final = train_test_split(X_train_encoded, y_train, test_size=0.1, random_state=42)

# 转换为 Tensor
X_train_final = torch.tensor(X_train_final, dtype=torch.float32)
y_train_final = torch.tensor(y_train_final, dtype=torch.float32).view(-1, 1)  # 修正目标形状
X_val_final = torch.tensor(X_val_final, dtype=torch.float32)
y_val_final = torch.tensor(y_val_final, dtype=torch.float32).view(-1, 1)  # 修正目标形状

# 使用 DataLoader 打包数据
train_dataset = TensorDataset(X_train_final, y_train_final)
val_dataset = TensorDataset(X_val_final, y_val_final)

train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)

# 定义神经网络模型
class SimpleNN(nn.Module):
    def __init__(self, input_dim):
        super(SimpleNN, self).__init__()
        self.layer1 = nn.Linear(input_dim, 128)  # 输入到第一个隐藏层
        self.layer2 = nn.Linear(128, 64)         # 第一个隐藏层到第二个隐藏层
        self.layer3 = nn.Linear(64, 32)          # 第二个隐藏层到第三个隐藏层
        self.output_layer = nn.Linear(32, 1)     # 输出层

    def forward(self, x):
        x = torch.relu(self.layer1(x))  # ReLU 激活
        x = torch.relu(self.layer2(x))  # ReLU 激活
        x = torch.relu(self.layer3(x))  # ReLU 激活
        x = self.output_layer(x)        # 输出层
        return x

# 检查是否有可用的GPU
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 实例化模型并将其移至GPU
input_dim = X_train_final.shape[1]  # 特征数量
model = SimpleNN(input_dim).to(device)

# 定义损失函数和优化器，设置初始较高的学习率
criterion = nn.MSELoss()  # 均方误差损失函数
optimizer = optim.Adam(model.parameters(), lr=0.005)  # 初始较高的学习率

# 使用 StepLR 学习率调度器，每10个epoch将学习率减半
scheduler = StepLR(optimizer, step_size=50, gamma=0.5)

# 训练模型
epochs = 50
print('Start Training-------------------------------')
for epoch in range(epochs):
    model.train()
    running_loss = 0.0
    for inputs, targets in train_loader:
        # 将数据移至GPU
        inputs, targets = inputs.to(device), targets.to(device)

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, targets)  # 目标和输出已是 (batch_size, 1) 形状
        loss.backward()
        optimizer.step()
        running_loss += loss.item()
    
    # 更新学习率
    scheduler.step()

    # 在每个 epoch 结束时打印训练集损失
    print(f"Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}, LR: {optimizer.param_groups[0]['lr']:.6f}")

print('Finish Training-----------------------------')

# 在验证集上评估模型
model.eval()
y_val_pred = []
with torch.no_grad():
    for inputs, targets in val_loader:
        # 将数据移至GPU
        inputs, targets = inputs.to(device), targets.to(device)
        
        outputs = model(inputs)
        y_val_pred.append(outputs)
y_val_pred = torch.cat(y_val_pred, dim=0)

# 转换预测结果为 numpy 数组
y_val_pred = y_val_pred.cpu().numpy().ravel()  # 移回 CPU 进行后续处理

# 计算验证集的均方误差（MSE）和 R²
mse = mean_squared_error(y_val_final, y_val_pred)
r2 = r2_score(y_val_final, y_val_pred)

print(f"验证集均方误差 (MSE): {mse}")
print(f"验证集决定系数 (R^2): {r2}")

# 进行测试
print('Strat Testing--------------------------------')
X_test_encoded = pd.read_csv(os.path.join(data_output,'processed_test_features.csv'))
test = pd.read_csv(data_path_test)

# 将测试集转换为 Tensor
X_test_encoded = torch.tensor(X_test_encoded.values, dtype=torch.float32).to(device)

# 在测试集上进行预测
model.eval()
with torch.no_grad():
    y_test_pred = model(X_test_encoded).cpu().numpy().ravel()  # 移回 CPU 进行后续处理

# 保存预测结果
test_predictions = pd.DataFrame({
    'id': test['id'],  # 保留测试集的 ID 列
    'Premium Amount': y_test_pred  # 确保 y_test_pred 是一维数组
})

# 保存预测结果到 CSV 文件
test_predictions.to_csv('test_predictions.csv', index=False)
print('Finish Testing--------------------------------')
# 打印部分预测结果
print(test_predictions.head())

<br>Start Training-------------------------------
Epoch [1/50], Loss: 750468.6892, LR: 0.005000
Epoch [2/50], Loss: 744148.9429, LR: 0.005000
Epoch [3/50], Loss: 742300.7349, LR: 0.005000
Epoch [4/50], Loss: 741076.8997, LR: 0.005000
Epoch [5/50], Loss: 740483.2739, LR: 0.005000
Epoch [6/50], Loss: 739889.0180, LR: 0.005000
Epoch [7/50], Loss: 739355.1135, LR: 0.005000
Epoch [8/50], Loss: 738748.6160, LR: 0.005000
Epoch [9/50], Loss: 738242.3698, LR: 0.005000
Epoch [10/50], Loss: 737529.2075, LR: 0.005000
Epoch [11/50], Loss: 736634.0499, LR: 0.005000
Epoch [12/50], Loss: 735737.4630, LR: 0.005000
Epoch [13/50], Loss: 735062.3034, LR: 0.005000
Epoch [14/50], Loss: 734577.6543, LR: 0.005000
Epoch [15/50], Loss: 734082.1198, LR: 0.005000
Epoch [16/50], Loss: 733720.8554, LR: 0.005000
Epoch [17/50], Loss: 733153.8253, LR: 0.005000
Epoch [18/50], Loss: 732810.7735, LR: 0.005000
Epoch [19/50], Loss: 732208.7655, LR: 0.005000
Epoch [20/50], Loss: 731770.1129, LR: 0.005000
Epoch [21/50], Loss: 731034.8865, LR: 0.005000
Epoch [22/50], Loss: 730339.5605, LR: 0.005000
Epoch [23/50], Loss: 729742.7733, LR: 0.005000
Epoch [24/50], Loss: 729159.2402, LR: 0.005000
Epoch [25/50], Loss: 728798.6417, LR: 0.005000
Epoch [26/50], Loss: 728132.8087, LR: 0.005000
Epoch [27/50], Loss: 727713.5761, LR: 0.005000
Epoch [28/50], Loss: 727256.9815, LR: 0.005000
Epoch [29/50], Loss: 727047.5950, LR: 0.005000
Epoch [30/50], Loss: 726763.8287, LR: 0.005000
Epoch [31/50], Loss: 726592.3864, LR: 0.005000
Epoch [32/50], Loss: 726316.7858, LR: 0.005000
Epoch [33/50], Loss: 726225.6537, LR: 0.005000
Epoch [34/50], Loss: 725943.4599, LR: 0.005000
Epoch [35/50], Loss: 725915.8083, LR: 0.005000
Epoch [36/50], Loss: 725674.9357, LR: 0.005000
Epoch [37/50], Loss: 725600.3300, LR: 0.005000
Epoch [38/50], Loss: 725445.2246, LR: 0.005000
Epoch [39/50], Loss: 725450.6353, LR: 0.005000
Epoch [40/50], Loss: 725129.3618, LR: 0.005000
Epoch [41/50], Loss: 725140.4384, LR: 0.005000
Epoch [42/50], Loss: 725041.8287, LR: 0.005000
Epoch [43/50], Loss: 724951.9165, LR: 0.005000
Epoch [44/50], Loss: 724960.9640, LR: 0.005000
Epoch [45/50], Loss: 724696.5248, LR: 0.005000
Epoch [46/50], Loss: 724579.1877, LR: 0.005000
Epoch [47/50], Loss: 724417.9881, LR: 0.005000
Epoch [48/50], Loss: 724295.7307, LR: 0.005000
Epoch [49/50], Loss: 724326.7615, LR: 0.005000
Epoch [50/50], Loss: 724117.5928, LR: 0.002500
Finish Training-----------------------------
验证集均方误差 (MSE): 730612.8125
验证集决定系数 (R^2): 0.02233819935731518
Strat Testing--------------------------------
Finish Testing--------------------------------
        id  Premium Amount
0  1200000     1305.557251
1  1200001     1135.996216
2  1200002     1033.700439
3  1200003     1046.217896
4  1200004     1045.205688
]]></description><link>technology\collegeproject\数据挖掘\数据挖掘大作业.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘大作业.md</guid><pubDate>Sat, 28 Dec 2024 03:04:59 GMT</pubDate><enclosure url="technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_2.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数据挖掘\数据挖掘大作业_files\数据挖掘大作业_3_2.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[<strong>1. 数据集及问题介绍:</strong>]]></title><description><![CDATA[ 
 <br><br>在深入研究数据之前，我们需要了解我们试图解决的问题以及我们的分析目标。这有助于指导我们的探索和识别相关模式。对于此数据集，是关于一家向其客户提供车辆保险的保险公司的。我们试图回答以下两个问题：<br>
<br>现在我们需要构建一个模型来预测过去一年的投保人（客户）是否也会对公司提供的车辆保险感兴趣。即是一个二元分类问题。(本问题是kaggle playground中的一个比赛问题。)
<br>哪些因素与客户是否投保最相关。
<br><br>import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
import sklearn
import os
from matplotlib import rcParams
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))
<br>/kaggle/input/health-insurance-cross-sell-prediction-data/train.csv
/kaggle/input/health-insurance-cross-sell-prediction-data/test.csv
<br>df_test = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction-data/test.csv')
df = pd.read_csv('/kaggle/input/health-insurance-cross-sell-prediction-data/train.csv')
<br><br># prompt: check head of df

df.head()

<br>
<br>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
<br>
<br>df.info()
<br>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 381109 entries, 0 to 381108
Data columns (total 12 columns):
 #   Column                Non-Null Count   Dtype  
---  ------                --------------   -----  
 0   id                    381109 non-null  int64  
 1   Gender                381109 non-null  object 
 2   Age                   381109 non-null  int64  
 3   Driving_License       381109 non-null  int64  
 4   Region_Code           381109 non-null  float64
 5   Previously_Insured    381109 non-null  int64  
 6   Vehicle_Age           381109 non-null  object 
 7   Vehicle_Damage        381109 non-null  object 
 8   Annual_Premium        381109 non-null  float64
 9   Policy_Sales_Channel  381109 non-null  float64
 10  Vintage               381109 non-null  int64  
 11  Response              381109 non-null  int64  
dtypes: float64(3), int64(6), object(3)
memory usage: 34.9+ MB
<br>df.dtypes
<br>id                        int64
Gender                   object
Age                       int64
Driving_License           int64
Region_Code             float64
Previously_Insured        int64
Vehicle_Age              object
Vehicle_Damage           object
Annual_Premium          float64
Policy_Sales_Channel    float64
Vintage                   int64
Response                  int64
dtype: object
<br>df.shape
<br>(381109, 12)
<br><br><br>df.duplicated().sum()
df.drop_duplicates(inplace=True)
df.shape
<br>(381109, 12)
<br>missing_values = df.isnull().sum()
missing_values
<br>id                      0
Gender                  0
Age                     0
Driving_License         0
Region_Code             0
Previously_Insured      0
Vehicle_Age             0
Vehicle_Damage          0
Annual_Premium          0
Policy_Sales_Channel    0
Vintage                 0
Response                0
dtype: int64
<br>正如我们所看到的，没有重复值和缺失值<br><br>sns.set(style="whitegrid")
<br># 抽取1000行数据进行均匀抽样
df_sampled = df.sample(n=1000, random_state=42)  # 可以设置random_state确保可复现

# 绘制pairplot
sns.pairplot(df_sampled)

# 显示图形
plt.show()
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_16_0.png"><br>plt.figure(figsize=(7, 4))
sns.boxplot(x=df['Annual_Premium'])
plt.title('Distribution of Annual_Premium')
plt.xlabel('Annual_Premium')
plt.ylabel('Frequency')
plt.show()
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_17_0.png"><br>plt.figure(figsize=(10, 6))
sns.histplot(df['Age'], kde=False, bins=10)
plt.title('Distribution of Age')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_18_0.png"><br>plt.figure(figsize=(10, 6))
sns.histplot(df['Region_Code'], kde=False, bins=12)
plt.title('Distribution of Region_Code')
plt.xlabel('Region_Code')
plt.ylabel('Frequency')
plt.show()
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_19_0.png"><br>plt.figure(figsize=(10, 6))
sns.histplot(df['Vehicle_Age'], kde=False, bins=10)
plt.title('Distribution of Vehicle_Age')
plt.xlabel('Vehicle_Age')
plt.ylabel('Frequency')
plt.show()
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_20_0.png"><br>#检查类别平衡
response_data = df['Response'].value_counts()
plt.figure(figsize=(6,6))
fig, ax = plt.subplots()
ax.pie(response_data, labels = [0,1])
ax.set_title('Checking Imbalance in Training Data Or Response')

<br>Text(0.5, 1.0, 'Checking Imbalance in Training Data Or Response')




&lt;Figure size 600x600 with 0 Axes&gt;
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_21_2.png"><br><br>df.info()
print('\n')
df.head()

<br>&lt;class 'pandas.core.frame.DataFrame'&gt;
RangeIndex: 381109 entries, 0 to 381108
Data columns (total 12 columns):
 #   Column                Non-Null Count   Dtype  
---  ------                --------------   -----  
 0   id                    381109 non-null  int64  
 1   Gender                381109 non-null  object 
 2   Age                   381109 non-null  int64  
 3   Driving_License       381109 non-null  int64  
 4   Region_Code           381109 non-null  float64
 5   Previously_Insured    381109 non-null  int64  
 6   Vehicle_Age           381109 non-null  object 
 7   Vehicle_Damage        381109 non-null  object 
 8   Annual_Premium        381109 non-null  float64
 9   Policy_Sales_Channel  381109 non-null  float64
 10  Vintage               381109 non-null  int64  
 11  Response              381109 non-null  int64  
dtypes: float64(3), int64(6), object(3)
memory usage: 34.9+ MB
<br>
<br>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
<br>
<br># 统计 'Policy_Sales_Channel' 列的不同输出及其计数
policy_sales_channel_counts = df['Policy_Sales_Channel'].value_counts()

# 打印统计结果
# print(policy_sales_channel_counts)
# 查看不同值的数量
num_unique_values = len(df['Policy_Sales_Channel'].unique())
print(f"不同的值的数量: {num_unique_values}")

<br>不同的值的数量: 155
<br># 1. 二元特征处理
df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})
df['Vehicle_Damage'] = df['Vehicle_Damage'].map({'Yes': 1, 'No': 0})

<br># 2. 序数特征处理（Label Encoding）
vehicle_age_map = {'&lt; 1 Year': 0, '1-2 Year': 1, '&gt; 2 Years': 2}
df['Vehicle_Age'] = df['Vehicle_Age'].map(vehicle_age_map)

<br># 3. 标称特征处理，由于类别太多这里使用目标编码
# 计算每个 'Region_Code' 的响应率（'Response' 的均值）
region_mean_encoding = df.groupby('Region_Code')['Response'].mean()

# 将编码应用到 'Region_Code' 列
df['Region_Code_Encoded'] = df['Region_Code'].map(region_mean_encoding)

# 使用目标编码，将每个 'Policy_Sales_Channel' 替换为该类别的响应率（'Response' 的均值）
channel_mean_encoding = df.groupby('Policy_Sales_Channel')['Response'].mean()

# 将编码应用到数据框中
df['Policy_Sales_Channel_Encoded'] = df['Policy_Sales_Channel'].map(channel_mean_encoding)

# 删除原始列
df = df.drop(columns=['Region_Code','Policy_Sales_Channel'])


<br># 4. 数值特征处理由于是比率标度
from sklearn.preprocessing import MinMaxScaler

# 创建归一化器，将数据归一化到 [0, 1] 范围
scaler = MinMaxScaler()

# 对数值特征进行归一化
df[['Age', 'Annual_Premium', 'Vintage']] = scaler.fit_transform(df[['Age', 'Annual_Premium', 'Vintage']])
<br># 复制 df 的预处理步骤到 df_test 中

# 1. 二元特征处理
df_test['Gender'] = df_test['Gender'].map({'Male': 1, 'Female': 0})
df_test['Vehicle_Damage'] = df_test['Vehicle_Damage'].map({'Yes': 1, 'No': 0})

# 2. 序数特征处理（Label Encoding）
vehicle_age_map = {'&lt; 1 Year': 0, '1-2 Year': 1, '&gt; 2 Years': 2}
df_test['Vehicle_Age'] = df_test['Vehicle_Age'].map(vehicle_age_map)

# 3. 标称特征处理
# 将目标编码应用到 df_test
df_test['Region_Code_Encoded'] = df_test['Region_Code'].map(region_mean_encoding)
df_test['Policy_Sales_Channel_Encoded'] = df_test['Policy_Sales_Channel'].map(channel_mean_encoding)

# 删除原始的 'Region_Code' 和 'Policy_Sales_Channel' 列
df_test = df_test.drop(columns=['Region_Code', 'Policy_Sales_Channel'])

# 4. 数值特征处理（归一化）
df_test[['Age', 'Annual_Premium', 'Vintage']] = scaler.transform(df_test[['Age', 'Annual_Premium', 'Vintage']])

# 查看处理后的 df_test 数据框
print(df_test.head())

<br>       id  Gender       Age  Driving_License  Previously_Insured  Vehicle_Age  \
0  381110       1  0.076923                1                   1            0   
1  381111       1  0.307692                1                   0            1   
2  381112       1  0.415385                1                   0            1   
3  381113       1  0.061538                1                   1            0   
4  381114       1  0.107692                1                   1            0   

   Vehicle_Damage  Annual_Premium   Vintage  Region_Code_Encoded  \
0               0        0.061682  0.148789             0.112760   
1               1        0.057916  0.349481             0.187163   
2               1        0.069614  0.653979             0.187163   
3               1        0.064602  0.612457             0.074035   
4               0        0.105048  0.993080             0.187163   

   Policy_Sales_Channel_Encoded  
0                      0.028624  
1                      0.113892  
2                      0.189148  
3                      0.028624  
4                      0.028624  
<br>df.head()
<br>
<br>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
<br>
<br>df_test.head()
<br>
<br>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
<br>
<br><br># 1. 准备特征和标签
X_train = df.drop(columns=['Response', 'id'])  # 特征（去掉目标变量和 id 列）
y_train = df['Response']  # 目标变量
# 对 df_test 使用相同的特征列
X_test = df_test.drop(columns=['id'])  # 去掉 id 列（没有目标变量）
y_test = None  # df_test 中没有 'Response' 列，因此我们没有目标变量

<br>y_train.head()
<br>0    1
1    0
2    1
3    0
4    0
Name: Response, dtype: int64
<br><br>import imblearn
from imblearn.over_sampling import SMOTE
smote = SMOTE()
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)
print(y_train.value_counts())
print()
print(y_train_smote.value_counts())
<br>Response
0    334399
1     46710
Name: count, dtype: int64

Response
1    334399
0    334399
Name: count, dtype: int64
<br>X_train_smote.head()
<br>
<br>.dataframe tbody tr th {
    vertical-align: top;
}

.dataframe thead th {
    text-align: right;
}
<br>
<br><br>from sklearn.preprocessing import StandardScaler, MinMaxScaler
scaler = StandardScaler()
<br>X_train_scaled = scaler.fit_transform(X_train_smote)
data_scaled = scaler.fit_transform(df)
<br>print(X_train_scaled[:5]) 
<br>[[ 0.86749168  0.22462304  0.03969193 -0.59678146  2.20262459  0.64098987
   0.55354585  0.75145668  1.25030283  0.62117121]
 [ 0.86749168  2.45774571  0.03969193 -0.59678146  0.43464892 -1.56008705
   0.14966237  0.34507368 -0.04638815  0.62117121]
 [ 0.86749168  0.43397829  0.03969193 -0.59678146  2.20262459  0.64098987
   0.42744173 -1.51950713  1.25030283  0.62117121]
 [ 0.86749168 -1.38043388  0.03969193  1.67565528 -1.33332675 -1.56008705
  -0.13739965  0.5841225  -0.37113865 -1.46783135]
 [-1.1527488  -0.82215321  0.03969193  1.67565528 -1.33332675 -1.56008705
  -0.20296211 -1.37607784 -0.17465046 -1.46783135]]
<br><br>from sklearn.model_selection import train_test_split
x_train, x_val, y_train, y_val = train_test_split(X_train_scaled, y_train_smote, test_size=0.2, random_state=42)
<br>print(x_train.shape, y_train.shape, x_val.shape, y_val.shape)
<br>(535038, 10) (535038,) (133760, 10) (133760,)
<br>from sklearn import metrics
from sklearn.metrics import *
from sklearn.metrics import accuracy_score
from sklearn.metrics import precision_score
from sklearn.metrics import recall_score
from sklearn.metrics import f1_score
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.linear_model import LogisticRegression
<br>def model_prediction(model):
    model.fit(x_train,y_train)
    print('ok')
    x_train_pred = model.predict(x_train)
    x_val_pred = model.predict(x_val)
    y_val_prob = model.predict_proba(x_val)[:, 1]
    # 获取每个特征的回归系数
    coefficients = model.coef_[0]
    
    # 输出特征和对应的回归系数
    for i, coef in enumerate(coefficients):
        print(f"Feature {i} 的回归系数: {coef}")
        
    a = accuracy_score(y_train,x_train_pred)*100
    b = accuracy_score(y_val,x_val_pred)*100
    c = precision_score(y_val,x_val_pred)
    d = recall_score(y_val,x_val_pred)
    e = roc_auc_score(y_val, y_val_prob)
    print(f"Accuracy_Score of {model} model on Training Data is:",a)
    print(f"Accuracy_Score of {model} model on valing Data is:",b)
    print(f"Precision Score of {model} model is:",c)
    print(f"Recall Score of {model} model is:",d)
    print(f"AUC Score of {model} model is:", e)
    print("\n------------------------------------------------------------------------")
    print(f"Confusion Matrix of {model} model is:")
    cm = confusion_matrix(y_val,x_val_pred)
    plt.figure(figsize=(8,4))
    sns.heatmap(cm,annot=True,fmt="g",cmap="Greens")
    plt.show()
<br>model_prediction(LogisticRegression())
<br>ok
Feature 0 的回归系数: 0.0503105935607198
Feature 1 的回归系数: -0.338949759585482
Feature 2 的回归系数: 0.04626501704666287
Feature 3 的回归系数: -1.7121504747558645
Feature 4 的回归系数: 0.1835189037045931
Feature 5 的回归系数: 0.8777706595809806
Feature 6 的回归系数: 0.03605631228720499
Feature 7 的回归系数: -0.007719710401669024
Feature 8 的回归系数: 0.1279785245290343
Feature 9 的回归系数: 0.5307554520385265
Accuracy_Score of LogisticRegression() model on Training Data is: 79.11643658955066
Accuracy_Score of LogisticRegression() model on valing Data is: 79.45050837320574
Precision Score of LogisticRegression() model is: 0.7312420963889279
Recall Score of LogisticRegression() model is: 0.9323132044487572
AUC Score of LogisticRegression() model is: 0.8475529906657522

------------------------------------------------------------------------
Confusion Matrix of LogisticRegression() model is:
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_47_1.png"><br>import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score

# 模型评估函数
def model_prediction(model, model_name, x_train, y_train, x_val, y_val):
    # 训练模型
    model.fit(x_train, y_train)
    
    # 预测训练集和验证集
    x_train_pred = model.predict(x_train)
    x_val_pred = model.predict(x_val)
    y_val_prob = model.predict_proba(x_val)[:, 1] if hasattr(model, "predict_proba") else None
    
    # 计算评价指标
    accuracy = accuracy_score(y_val, x_val_pred)
    precision = precision_score(y_val, x_val_pred)
    recall = recall_score(y_val, x_val_pred)
    auc = roc_auc_score(y_val, y_val_prob) if y_val_prob is not None else None
    
    # 打印每个模型的评估结果
    print(f"Model: {model_name}")
    print(f"Accuracy: {accuracy * 100:.2f}%")
    print(f"Precision: {precision:.2f}")
    print(f"Recall: {recall:.2f}")
    print(f"AUC: {auc:.2f}")
    print("\n" + "-"*50)
    
    return accuracy, precision, recall, auc

# 模型列表，增加更多模型
models = [
    ('Logistic Regression', LogisticRegression()),
    ('Decision Tree', DecisionTreeClassifier()),
    ('AdaBoost', AdaBoostClassifier()),
]

# 存储每个模型的评估指标
metrics_dict = {
    'Model': [],
    'Accuracy': [],
    'Precision': [],
    'Recall': [],
    'AUC': []
}

# 计算每个模型的评估指标并打印
for model_name, model in models:
    accuracy, precision, recall, auc = model_prediction(model, model_name, x_train, y_train, x_val, y_val)
    metrics_dict['Model'].append(model_name)
    metrics_dict['Accuracy'].append(accuracy)
    metrics_dict['Precision'].append(precision)
    metrics_dict['Recall'].append(recall)
    metrics_dict['AUC'].append(auc)

# 将指标字典转化为DataFrame
import pandas as pd
metrics_df = pd.DataFrame(metrics_dict)

# 绘制图表
plt.figure(figsize=(12, 6))
metrics_df.set_index('Model').plot(kind='bar', figsize=(12, 6))
plt.title('Model Comparison: Accuracy, Precision, Recall, AUC')
plt.ylabel('Score')
plt.xlabel('Model')
plt.xticks(rotation=45)
plt.tight_layout()
plt.show()

<br>Model: Logistic Regression
Accuracy: 79.45%
Precision: 0.73
Recall: 0.93
AUC: 0.85

--------------------------------------------------
Model: Decision Tree
Accuracy: 88.78%
Precision: 0.88
Recall: 0.90
AUC: 0.89

--------------------------------------------------
Model: AdaBoost
Accuracy: 81.73%
Precision: 0.76
Recall: 0.93
AUC: 0.90

--------------------------------------------------



&lt;Figure size 1200x600 with 0 Axes&gt;
<br><img alt="png" src="\technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_48_2.png"><br><br><br>实验中使用了三种不同的分类模型来进行训练和预测，结果如下：<br><br>
<br>准确率 (Accuracy): 79.45%
<br>精确率 (Precision): 0.73
<br>召回率 (Recall): 0.93
<br>AUC (Area Under the Curve): 0.85
<br>逻辑回归的表现较为平衡，虽然准确率相对较低，但其召回率较高（0.93），意味着该模型在识别正类（可能是目标类别）时非常成功。然而，精确率稍低（0.73），表示模型在预测正类时也会有一定的错误。<br><br>
<br>准确率 (Accuracy): 88.78%
<br>精确率 (Precision): 0.88
<br>召回率 (Recall): 0.90
<br>AUC: 0.89
<br>决策树表现出色，具有较高的准确率（88.78%）和精确率（0.88）。此外，召回率和AUC也都很高，表明该模型对正类和负类的预测都非常有效，且决策树能够很好地区分各个类别。<br><br>
<br>准确率 (Accuracy): 81.73%
<br>精确率 (Precision): 0.76
<br>召回率 (Recall): 0.93
<br>AUC: 0.90
<br>AdaBoost模型表现出较高的召回率（0.93），意味着它也能够很好地识别正类。然而，精确率略低（0.76），这表明其可能会出现一些误报（即预测为正类但实际上是负类）。<br><br>在逻辑回归模型中，特征的回归系数代表了每个特征在模型预测中的重要性和方向。系数的符号（正或负）表示该特征与目标变量之间的关系类型：正系数意味着该特征值增加时，预测的目标值更可能是1（正类），负系数则意味着该特征值增加时，目标值更可能是0（负类）。<br>
<br>Gender（性别）的系数为 0.0503，表明性别对目标变量有轻微的正向影响。
<br>Age（年龄）的系数为 -0.3389，表明随着年龄的增长，预测为正类的可能性略微降低。
<br>Driving_License（是否有驾照）的系数为 0.0463，表明有驾照的个体预测为正类的概率略高。
<br>Previously_Insured（是否曾投保）的系数为 -1.7122，意味着曾经投保的个体，预测为正类的概率显著较低。
<br>Vehicle_Age（车辆年龄）的系数为 0.1835，表明车辆年龄越大，预测为正类的概率较高。
<br>Vehicle_Damage（车辆是否曾经受损）的系数为 0.8778，表明车辆受损的个体更可能被预测为正类。
<br>Annual_Premium（年保费）的系数为 0.0361，表明年保费的增加会略微提高预测为正类的概率。
<br>Vintage（客户年资）的系数为 -0.0077，表明客户年资与预测为正类的概率关系较弱，且是负相关。
<br>Region_Code_Encoded（地区编码）的系数为 0.1280，表明地区编码对预测正类有轻微的正向影响。
<br>Policy_Sales_Channel_Encoded（销售渠道编码）的系数为 0.5308，表明销售渠道编码与预测正类之间有正相关关系。
<br><br>根据回归系数的大小和符号，你可以做出以下几点结论：<br>
<br>决策性强的特征：Previously_Insured、Vehicle_Damage 和 Policy_Sales_Channel_Encoded 是影响模型预测的重要特征，特别是 Previously_Insured 和 Vehicle_Damage 对预测目标有显著影响。
<br>影响较弱的特征：如 Vintage（客户年资），该特征的系数接近零，表明它对目标变量的预测影响较小。
<br>正向影响和负向影响：Gender、Age、Vehicle_Age、Annual_Premium 和 Region_Code_Encoded 都有正向的影响，而 Previously_Insured 和 Vintage 则表现出负向影响。
<br><br>
<br>决策树模型是此实验中表现最为优秀的模型，具有最高的准确率、精确率、召回率和AUC，证明了决策树在该任务中的良好表现。
<br>逻辑回归提供了回归系数的可解释性，但其在准确性和精确率方面稍逊于决策树。
<br>AdaBoost通过提升弱学习器的性能，尽管召回率很高，但精确率略低，适合在高召回率场景下使用。
<br>整体而言Vehicle_Damage与是否投保相关性最高。
]]></description><link>technology\collegeproject\数据挖掘\数据挖掘大作业2.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘大作业2.md</guid><pubDate>Tue, 31 Dec 2024 15:18:33 GMT</pubDate><enclosure url="technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_16_0.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数据挖掘\数据挖掘大作业2_files\数据挖掘大作业2_16_0.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数据挖掘复习]]></title><description><![CDATA[ 
 <br><img alt="Pasted image 20241229120313.png" src="\lib\media\pasted-image-20241229120313.png"><br><br><img alt="f377141b-1614-4f54-887e-ddf51c0fdb7c.png" src="\lib\media\f377141b-1614-4f54-887e-ddf51c0fdb7c.png"><br>
<img alt="a3f10af8-970d-44d6-8aca-4721afccf2c5.png" src="\lib\media\a3f10af8-970d-44d6-8aca-4721afccf2c5.png"><br>
<img alt="428f61be-4fde-44c7-8114-efe9e6f269b0.png" src="\lib\media\428f61be-4fde-44c7-8114-efe9e6f269b0.png"><br><br><img alt="Pasted image 20241229120519.png" src="\lib\media\pasted-image-20241229120519.png"><br><br><img alt="Pasted image 20241229120550.png" src="\lib\media\pasted-image-20241229120550.png"><br><img alt="Pasted image 20241229120615.png" src="\lib\media\pasted-image-20241229120615.png"><br>
<img alt="Pasted image 20241229120628.png" src="\lib\media\pasted-image-20241229120628.png"><br>
<img alt="Pasted image 20241229120644.png" src="\lib\media\pasted-image-20241229120644.png"><br>
<img alt="Pasted image 20241229120738.png" src="\lib\media\pasted-image-20241229120738.png"><br>
<img alt="Pasted image 20241229121125.png" src="\lib\media\pasted-image-20241229121125.png"><br>
<img alt="Pasted image 20241229121144.png" src="\lib\media\pasted-image-20241229121144.png"><br>
<img alt="Pasted image 20241229121201.png" src="\lib\media\pasted-image-20241229121201.png"><br>
<img alt="Pasted image 20241229121458.png" src="\lib\media\pasted-image-20241229121458.png"><br>
<img alt="Pasted image 20241229121530.png" src="\lib\media\pasted-image-20241229121530.png"><br>
<img alt="Pasted image 20241229121549.png" src="\lib\media\pasted-image-20241229121549.png"><br>
<img alt="Pasted image 20241229121626.png" src="\lib\media\pasted-image-20241229121626.png"><br><br>太多了看ppt<br><br><img alt="Pasted image 20241229122301.png" src="\lib\media\pasted-image-20241229122301.png"><br><br><img alt="Pasted image 20241229122428.png" src="\lib\media\pasted-image-20241229122428.png"><br>
<img alt="Pasted image 20241229122454.png" src="\lib\media\pasted-image-20241229122454.png"><br><br><img alt="Pasted image 20241229122827.png" src="\lib\media\pasted-image-20241229122827.png"><br><br><img alt="Pasted image 20241229122948.png" src="\lib\media\pasted-image-20241229122948.png"><br><br>内容太多自己看<br><br><img alt="Pasted image 20241229123207.png" src="\lib\media\pasted-image-20241229123207.png"><br>
看PPT 4.1 4.2<br><br><img alt="Pasted image 20241229123335.png" src="\lib\media\pasted-image-20241229123335.png"><br><br><img alt="Pasted image 20241229123354.png" src="\lib\media\pasted-image-20241229123354.png"><br><br><img alt="Pasted image 20241229123415.png" src="\lib\media\pasted-image-20241229123415.png">]]></description><link>technology\collegeproject\数据挖掘\数据挖掘复习.html</link><guid isPermaLink="false">Technology/CollegeProject/数据挖掘/数据挖掘复习.md</guid><pubDate>Sun, 29 Dec 2024 04:34:16 GMT</pubDate><enclosure url="lib\media\pasted-image-20241229120313.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20241229120313.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验一  图像基本变换]]></title><description><![CDATA[ 
 <br>一、算法原理<br>
<br>
色彩通道互换

<br>通过交换RGB图像中的颜色通道，可以改变图像的颜色表现。


<br>
灰度化处理

<br>将彩色图像转换为灰度图像是通过计算每个像素点的亮度值来实现的。在RGB模型中，通常使用加权平均的方法来计算灰度值。


<br>
几何变换（旋转与缩放）

<br>几何变换包括旋转和平移等，可以通过矩阵变换来实现。旋转是绕某一点旋转一定角度，而缩放则是按照一定的比例放大或缩小图像。
<br>不同的插值方法会影响变换后图像的质量。常用的插值方法有最近邻插值（Nearest Neighbor）、双线性插值（Bilinear）和双三次插值（Bicubic）。


<br>
代数运算

<br>图像之间的代数运算包括加法、减法、乘法和除法。这些运算是逐像素进行的，并且要求参与运算的图像尺寸相同，结果需要被裁剪到有效范围[0, 255]内。


<br>二、程序流程<br>
<br>加载两幅图像Image1和Image2。
<br>对Image1执行色彩通道互换并显示。
<br>将Image1转换为灰度图像并显示。
<br>对图像应用旋转和缩放变换，并使用不同插值方法。
<br>如果Image1和Image2尺寸相同，则执行加法、减法、乘法和除法操作，并显示结果。
<br>三、算法各部分主要函数代码及功能注释<br>% 读取两幅不同大小的图像
image1 = imread('image1.jpg');
image2 = imread('image2.jpg');

% 获取两幅图像的尺寸
[height1, width1, ~] = size(image1);
[height2, width2, ~] = size(image2);

% 确定统一的目标尺寸
target_height = max(height1, height2);
target_width = max(width1, width2);

% 调整图像大小到目标尺寸
image1_resized = imresize(image1, [target_height, target_width]);
image2_resized = imresize(image2, [target_height, target_width]);

% (1) 红绿通道互换
image2_swapped = image1_resized;
image2_swapped(:,:,1) = image1_resized(:,:,2);
image2_swapped(:,:,2) = image1_resized(:,:,1);
imshow(image2_swapped);
title('Color Channels Swapped');
imwrite(image2_swapped, 'changecolor.jpg');
pause;

% (2) 图像灰度化
gray = rgb2gray(image1_resized);
subplot(1,2,1); imshow(image1_resized); title('Original Image');
subplot(1,2,2); imshow(gray); title('Gray Image');
imwrite(gray, 'grayimage.jpg');
pause;

% (3) 图像旋转
[h, w] = size(gray);
center = [w/2, h/2];
angle = 15;
new_gray1 = imrotate(gray, angle, 'nearest', 'crop');
new_gray2 = imrotate(gray, angle, 'bilinear', 'crop');
subplot(1,2,1); imshow(new_gray1); title('Rotated 15° (Nearest)');
subplot(1,2,2); imshow(new_gray2); title('Rotated 15° (Bilinear)');
imwrite(new_gray1, 'rotate1.jpg');
imwrite(new_gray2, 'rotate2.jpg');
pause;

% (4) 图像缩放
new_gray3 = imresize(gray, 2.5, 'nearest');
new_gray4 = imresize(gray, 2.5, 'bilinear');
subplot(1,2,1); imshow(new_gray3); title('Scaled 2.5x (Nearest)');
subplot(1,2,2); imshow(new_gray4); title('Scaled 2.5x (Bilinear)');
imwrite(new_gray3, 'scale1.jpg');
imwrite(new_gray4, 'scale2.jpg');
pause;

% (5) 图像镜像与拼接
h_image = fliplr(image2_resized);
v_image = flipud(image2_resized);
c_image = flipud(h_image);
[h, w, ~] = size(image2_resized);
new_image = zeros(h*2, w*2, 3, 'uint8');
new_image(1:h, 1:w, :) = image2_resized;
new_image(1:h, w+1:2*w, :) = h_image;
new_image(h+1:2*h, 1:w, :) = v_image;
new_image(h+1:2*h, w+1:2*w, :) = c_image;
imshow(new_image);
title('Mirrored and Concatenated Image');
imwrite(new_image, 'newlotus.jpg');
pause;

% 图像加法
added_image = imadd(image1_resized, image2_resized);

% 图像减法
subtracted_image = imsubtract(image1_resized, image2_resized);

% 图像乘法
multiplied_image = immultiply(im2double(image1_resized), im2double(image2_resized));

% 图像除法
divided_image = imdivide(im2double(image1_resized), im2double(image2_resized) + 1);

% 创建拼接图像
[h, w, ~] = size(image1_resized);
combined_image = zeros(h*2, w*2, 3, 'uint8');
combined_image(1:h, 1:w, :) = image1_resized;
combined_image(1:h, w+1:2*w, :) = image2_resized;
combined_image(h+1:2*h, 1:w, :) = added_image;
combined_image(h+1:2*h, w+1:2*w, :) = subtracted_image;

% 显示结果
figure;
imshow(combined_image);
title('Combined Operations');
imwrite(combined_image, 'combined_operations.jpg');

% 显示乘法和除法结果
figure;
subplot(1,2,1); imshow(multiplied_image); title('Multiplied Image');
subplot(1,2,2); imshow(divided_image); title('Divided Image');
imwrite(multiplied_image, 'multiplied_image.jpg');
imwrite(divided_image, 'divided_image.jpg');
<br>import cv2
import numpy as np

# 读取两幅不同大小的图像
image1 = cv2.imread('image1.jpg')
image2 = cv2.imread('image2.jpg')

# 获取两幅图像的尺寸
height1, width1, _ = image1.shape
height2, width2, _ = image2.shape

# 确定统一的目标尺寸（可以选择较小的尺寸或者较大的尺寸）
target_height = max(height1, height2)  # 选择较大的高度
target_width = max(width1, width2)     # 选择较大的宽度

# 调整图像大小到目标尺寸
image1_resized = cv2.resize(image1, (target_width, target_height), interpolation=cv2.INTER_LINEAR)
image2_resized = cv2.resize(image2, (target_width, target_height), interpolation=cv2.INTER_LINEAR)

# (1) 红绿通道互换
image2_swapped = image1_resized.copy()
image2_swapped[:, :, 0] = image1_resized[:, :, 1]  # 绿色通道替换到蓝色通道
image2_swapped[:, :, 1] = image1_resized[:, :, 0]  # 蓝色通道替换到绿色通道
cv2.imshow('Color Channels Swapped', image2_swapped)
cv2.imwrite('changecolor.jpg', image2_swapped)  # 保存互换通道后的图像
cv2.waitKey(0)
cv2.destroyAllWindows()

# (2) 图像灰度化
gray = cv2.cvtColor(image1_resized, cv2.COLOR_BGR2GRAY)
cv2.imshow('Original Image', image1_resized)
cv2.imshow('Gray Image', gray)
cv2.imwrite('grayimage.jpg', gray)  # 保存灰度图像
cv2.waitKey(0)
cv2.destroyAllWindows()

# (3) 图像旋转
(h, w) = gray.shape[:2]
center = (w // 2, h // 2)
M_nearest = cv2.getRotationMatrix2D(center, 15, 1.0)
new_gray1 = cv2.warpAffine(gray, M_nearest, (w, h), flags=cv2.INTER_NEAREST)
M_bilinear = cv2.getRotationMatrix2D(center, 15, 1.0)
new_gray2 = cv2.warpAffine(gray, M_bilinear, (w, h), flags=cv2.INTER_LINEAR)
cv2.imshow('Rotated 15° (Nearest Interpolation)', new_gray1)
cv2.imshow('Rotated 15° (Bilinear Interpolation)', new_gray2)
cv2.imwrite('rotate1.jpg', new_gray1)  # 保存最近邻插值旋转后的图像
cv2.imwrite('rotate2.jpg', new_gray2)  # 保存双线性插值旋转后的图像
cv2.waitKey(0)
cv2.destroyAllWindows()

# (4) 图像缩放
new_gray3 = cv2.resize(gray, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_NEAREST)
new_gray4 = cv2.resize(gray, None, fx=2.5, fy=2.5, interpolation=cv2.INTER_LINEAR)
cv2.imshow('Scaled 2.5x (Nearest Interpolation)', new_gray3)
cv2.imshow('Scaled 2.5x (Bilinear Interpolation)', new_gray4)
cv2.imwrite('scale1.jpg', new_gray3)  # 保存最近邻插值缩放后的图像
cv2.imwrite('scale2.jpg', new_gray4)  # 保存双线性插值缩放后的图像
cv2.waitKey(0)
cv2.destroyAllWindows()

# (5) 图像镜像与拼接
h_image = cv2.flip(image2_resized, 1)  # 水平镜像
v_image = cv2.flip(image2_resized, 0)  # 垂直镜像
c_image = cv2.flip(h_image, 0)  # 水平镜像后再垂直镜像
[h, w, _] = image2_resized.shape
new_image = np.zeros((h * 2, w * 2, 3), dtype=np.uint8)
new_image[0:h, 0:w, :] = image2_resized
new_image[0:h, w:2*w, :] = h_image
new_image[h:2*h, 0:w, :] = v_image
new_image[h:2*h, w:2*w, :] = c_image
cv2.imshow('Mirrored and Concatenated Image', new_image)
cv2.imwrite('newlotus.jpg', new_image)  # 保存拼接后的图像
cv2.waitKey(0)
cv2.destroyAllWindows()

# 图像加法
added_image = cv2.add(image1_resized, image2_resized)

# 图像减法
subtracted_image = cv2.subtract(image1_resized, image2_resized)

# 图像乘法 (元素级别的乘法)
multiplied_image = cv2.multiply(image1_resized, image2_resized, scale=1/255)

# 图像除法 (避免除以零)
divided_image = cv2.divide(image1_resized, image2_resized + 1)

# 创建拼接图像
h, w = image1_resized.shape[:2]
combined_image = np.zeros((h*2, w*2, 3), dtype=np.uint8)
combined_image[0:h, 0:w] = image1_resized
combined_image[0:h, w:2*w] = image2_resized
combined_image[h:2*h, 0:w] = added_image
combined_image[h:2*h, w:2*w] = subtracted_image

# 显示结果
cv2.imshow('Combined Operations', combined_image)
cv2.imwrite('combined_operations.jpg', combined_image)

# 显示乘法和除法结果
cv2.imshow('Multiplied Image', multiplied_image)
cv2.imshow('Divided Image', divided_image)
cv2.imwrite('multiplied_image.jpg', multiplied_image)
cv2.imwrite('divided_image.jpg', divided_image)

cv2.waitKey(0)
cv2.destroyAllWindows()
<br>四、运行结果<br>
原图<img alt="image1.jpg" src="\lib\media\image1.jpg"><br>
<img alt="image2.jpg" src="\lib\media\image2.jpg"><br>
在Matlab或Python环境中运行上述代码后，您将会看到以下结果：<br>
<br>原始图像Image1经过色彩通道互换后的效果。<img alt="{A62CB1F7-0231-4621-A434-58BDF366506E}.png" src="\lib\media\{a62cb1f7-0231-4621-a434-58bdf366506e}.png">
<br>Image1转换成灰度图像后的效果。<img alt="{33F604D1-83D8-483E-9710-85A49052B526}.png" src="\lib\media\{33f604d1-83d8-483e-9710-85a49052b526}.png">
<br>灰度图像经过15度旋转以及放大2.5倍的效果。<img alt="rotate1.jpg" src="\lib\media\rotate1.jpg"><img alt="scale1.jpg" src="\lib\media\scale1.jpg">
<br>图像镜像与拼接<img alt="newlotus.jpg" src="\lib\media\newlotus.jpg">
<br>代数运算，运用拼接、加减乘除等技术处理两张图片<img alt="{3BDD9F73-1456-48E7-B5F3-565E992E64FB}.png" src="\lib\media\{3bdd9f73-1456-48e7-b5f3-565e992e64fb}.png"><br>
五、拓展任务<br>
（1）将彩色图像采用不同的灰度化方法实现灰度化；
<br>def grayscale_methods(image):
    # 方法1: 使用OpenCV的cvtColor函数
    gray_opencv = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # 方法2: 平均法
    gray_average = np.mean(image, axis=2).astype(np.uint8)
    
    # 方法3: 加权平均法 (BT.601标准)
    gray_weighted = np.dot(image[..., :3], [0.299, 0.587, 0.114]).astype(np.uint8)
    
    return gray_opencv, gray_average, gray_weighted
<br><img alt="{AD746270-C838-4225-AA27-EB26B5694947}.png" src="\lib\media\{ad746270-c838-4225-aa27-eb26b5694947}.png"><br>
（2）将彩色图像变换到YCbCr、HSV空间，熟悉各分量数据并显示。<br>def color_space_conversion(image):
    # BGR to YCbCr
    ycbcr = cv2.cvtColor(image, cv2.COLOR_BGR2YCrCb)
    y, cb, cr = cv2.split(ycbcr)
    
    # BGR to HSV
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    h, s, v = cv2.split(hsv)
    
<br><img alt="{85622EBA-631D-4E1C-BAD8-582D4631C6AE}.png" src="\lib\media\{85622eba-631d-4e1c-bad8-582d4631c6ae}.png"><br>
（3）不采用Matlab函数，自行设计基于双线性插值的图像放大程序；<br>def bilinear_interpolation(image, scale):
    height, width = image.shape[:2]
    new_height, new_width = int(height * scale), int(width * scale)
    
    resized = np.zeros((new_height, new_width, 3), dtype=np.uint8)
    
    for i in range(new_height):
        for j in range(new_width):
            x = i / scale
            y = j / scale
            
            x1, y1 = int(x), int(y)
            x2, y2 = min(x1 + 1, height - 1), min(y1 + 1, width - 1)
            
            dx, dy = x - x1, y - y1
            
            for c in range(3):
                resized[i, j, c] = int((1 - dx) * (1 - dy) * image[x1, y1, c] +
                                       dx * (1 - dy) * image[x2, y1, c] +
                                       (1 - dx) * dy * image[x1, y2, c] +
                                       dx * dy * image[x2, y2, c])
    
    return resized

<br><img alt="{3479C8E2-F09F-446B-8068-6803FC5D175F}.png" src="\lib\media\{3479c8e2-f09f-446b-8068-6803fc5d175f}.png">]]></description><link>technology\collegeproject\数字图像处理\实验\实验一-图像基本变换.html</link><guid isPermaLink="false">Technology/CollegeProject/数字图像处理/实验/实验一  图像基本变换.md</guid><pubDate>Mon, 21 Oct 2024 14:27:21 GMT</pubDate><enclosure url="lib\media\image1.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\image1.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[双线性插值]]></title><description><![CDATA[ 
 <br><br><img alt="{B9409D6A-0887-47AF-B62F-A6277A9C1D44}.png" src="\lib\media\{b9409d6a-0887-47af-b62f-a6277a9c1d44}.png"><br>
<img alt="{EE5B18AB-D071-445D-B435-343F4F3FAE1B}.png" src="\lib\media\{ee5b18ab-d071-445d-b435-343f4f3fae1b}.png"><br>双线性插值是一种插值方法，用于在多维数据集中查找特定位置的值。它特别适合于图像处理，因为在图像中，我们经常需要在非整数坐标处查找像素值。以下是一个简单的双线性插值的例子，说明如何在2D图像中使用这种方法。<br>假设我们有一个3x3的图像矩阵 f，其内容如下：<br><br>现在，我们希望在坐标 (1.5, 1.5) 处进行插值。这是一个介于像素之间的地方，所以我们不能直接取任何单一像素的值。双线性插值将使用周围的四个像素来计算这个位置的近似值。<br>首先，确定四个最近的像素点及其坐标：<br>
<br>(1, 1): f(1, 1) = 1
<br>(1, 2): f(1, 2) = 4
<br>(2, 1): f(2, 1) = 2
<br>(2, 2): f(2, 2) = 5
<br>然后，我们需要计算权重因子，这些因子决定了每个像素对最终插值的贡献。这些权重因子取决于给定坐标相对于周围像素的位置。对于 (1.5, 1.5)，权重因子如下：<br>
<br>α = (1.5 - 1) / 1 = 0.5
<br>β = (1.5 - 1) / 1 = 0.5
<br>接着，我们可以计算每个像素的加权平均值：<br>
<br>f(1, 1)  (1 - α)  (1 - β) = 1  (1 - 0.5)  (1 - 0.5) = 0.25
<br>f(1, 2)  α  (1 - β) = 4  0.5  (1 - 0.5) = 1
<br>f(2, 1)  (1 - α)  β = 2  (1 - 0.5)  0.5 = 0.5
<br>f(2, 2)  α  β = 5  0.5  0.5 = 1.25
<br>最后，将这些加权值相加以获得最终的插值：<br><br>所以，在坐标 (1.5, 1.5) 处的插值值为 2.75。这个过程可以推广到更大的图像和任意数量的维度，只要确保正确地计算权重因子即可。<br>在实际应用中，我们通常使用编程语言（如Python）和科学计算库（如NumPy）来实现这个过程。以下是一个使用NumPy的简单示例：<br>import numpy as np

# 定义原始图像矩阵
f = np.array([[1, 4, 7], [2, 5, 8], [3, 6, 9]])

# 给定插值坐标
x, y = 1.5, 1.5

# 计算权重因子
alpha = (x - int(x)) / float(x)
beta = (y - int(y)) / float(y)

# 计算插值值
result = (1 - alpha) * (1 - beta) * f[int(x), int(y)] + alpha * (1 - beta) * f[int(x)+1, int(y)] \
       + (1 - alpha) * beta * f[int(x), int(y)+1] + alpha * beta * f[int(x)+1, int(y)+1]

print(result)  # 输出: 2.75
<br>这个例子展示了如何使用双线性插值在非整数坐标处查找图像中的值。这种方法在图像缩放和其他相关任务中非常有用，因为它提供了平滑的过渡效果。]]></description><link>technology\collegeproject\数字图像处理\作业\双线性插值.html</link><guid isPermaLink="false">Technology/CollegeProject/数字图像处理/作业/双线性插值.md</guid><pubDate>Tue, 08 Oct 2024 04:03:41 GMT</pubDate><enclosure url="lib\media\{b9409d6a-0887-47af-b62f-a6277a9c1d44}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{b9409d6a-0887-47af-b62f-a6277a9c1d44}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[习题5]]></title><description><![CDATA[ 
 <br><br><img alt="扫描件_数字图像处理.习题5._001.jpg" src="\technology\collegeproject\数字图像处理\作业\习题5_files\扫描件_数字图像处理.习题5._001.jpg"><br><br>import numpy as np
import matplotlib.pyplot as plt
from fractions import Fraction
# 设置中文字体
plt.rcParams['font.sans-serif'] = ['SimHei']  # 使用黑体
plt.rcParams['axes.unicode_minus'] = False  # 解决负号显示问题
# 给定的灰度级和对应的像素数
gray_levels = [0, 1/7, 2/7, 3/7, 4/7, 5/7, 6/7, 1]
pixel_counts = [560, 920, 1046, 705, 356, 267, 170, 72]

# 总像素数
total_pixels = sum(pixel_counts)

# 计算每个灰度级的概率
probabilities = [count / total_pixels for count in pixel_counts]

# 计算累积分布函数 (CDF)
cdf = np.cumsum(probabilities)

# 将 CDF 映射到新的灰度级
new_gray_levels = (cdf * 7).round() / 7

# 转换为分数形式
original_gray_levels_fraction = [Fraction(level).limit_denominator(7) for level in gray_levels]
new_gray_levels_fraction = [Fraction(level).limit_denominator(7) for level in new_gray_levels]

# 创建一个新的像素计数字典，用于绘制新灰度级的直方图
new_pixel_counts = {level: 0 for level in set(new_gray_levels)}
for i, level in enumerate(new_gray_levels):
    new_pixel_counts[level] += pixel_counts[i]

# 提取新的灰度级和对应的像素数
new_gray_levels_list = list(new_pixel_counts.keys())
new_pixel_counts_list = list(new_pixel_counts.values())

# 绘制原始灰度级直方图
plt.figure(figsize=(12, 6))
plt.subplot(1, 2, 1)
plt.bar(gray_levels, pixel_counts, width=0.1, color='blue')
plt.title('原始灰度级直方图')
plt.xlabel('灰度级')
plt.ylabel('像素数')

# 绘制新灰度级直方图
plt.subplot(1, 2, 2)
plt.bar(new_gray_levels_list, new_pixel_counts_list, width=0.1, color='green')
plt.title('新灰度级直方图')
plt.xlabel('灰度级')
plt.ylabel('像素数')

# 显示图形
plt.tight_layout()
plt.show()

# 打印分数形式的灰度级
print("原始灰度级（分数形式）:", [str(frac) for frac in original_gray_levels_fraction])
print("新灰度级（分数形式）:", [str(frac) for frac in new_gray_levels_fraction])
<br><img alt="png" src="\technology\collegeproject\数字图像处理\作业\习题5_files\习题5_3_0.png"><br>原始灰度级（分数形式）: ['0', '1/7', '2/7', '3/7', '4/7', '5/7', '6/7', '1']
新灰度级（分数形式）: ['1/7', '3/7', '4/7', '6/7', '6/7', '1', '1', '1']
<br><br>% 设置中文字体
set(0, 'DefaultTextFontName', 'SimHei');
set(0, 'DefaultAxesFontName', 'SimHei');

% 给定的灰度级和对应的像素数
gray_levels = [0, 1/7, 2/7, 3/7, 4/7, 5/7, 6/7, 1];
pixel_counts = [560, 920, 1046, 705, 356, 267, 170, 72];

% 总像素数
total_pixels = sum(pixel_counts);

% 计算每个灰度级的概率
probabilities = pixel_counts / total_pixels;

% 计算累积分布函数 (CDF)
cdf = cumsum(probabilities);

% 将 CDF 映射到新的灰度级
new_gray_levels = round(cdf * 7) / 7;

% 创建一个新的像素计数字典，用于绘制新灰度级的直方图
new_pixel_counts = containers.Map('KeyType','double','ValueType','double');
for i = 1:length(new_gray_levels)
    if isKey(new_pixel_counts, new_gray_levels(i))
        new_pixel_counts(new_gray_levels(i)) = new_pixel_counts(new_gray_levels(i)) + pixel_counts(i);
    else
        new_pixel_counts(new_gray_levels(i)) = pixel_counts(i);
    end
end

% 提取新的灰度级和对应的像素数
new_gray_levels_list = keys(new_pixel_counts);
new_pixel_counts_list = values(new_pixel_counts);

% 绘制原始灰度级直方图
figure;
subplot(1, 2, 1);
bar(gray_levels, pixel_counts, 0.1);
title('原始灰度级直方图');
xlabel('灰度级');
ylabel('像素数');

% 绘制新灰度级直方图
subplot(1, 2, 2);
bar(new_gray_levels_list, new_pixel_counts_list, 0.1);
title('新灰度级直方图');
xlabel('灰度级');
ylabel('像素数');

% 打印分数形式的灰度级
disp(['原始灰度级（分数形式）:', strjoin(cellfun(@(x) num2str(x, '%d/%d'), num2cell(gray_levels), 'UniformOutput', false), ', ')]);
disp(['新灰度级（分数形式）:', strjoin(cellfun(@(x) num2str(x, '%d/%d'), num2cell(new_gray_levels), 'UniformOutput', false), ', ')]);
<br><br>import cv2
import numpy as np

# 创建一个8位灰度级的图像
image = np.zeros((100, 200), dtype=np.uint8)

# 设置左边一半为深灰色（灰度值为1/7）
image[:, :100] = int(255 * (1 / 7))

# 设置右边一半为黑色（灰度值为0）
image[:, 100:] = 0

# 显示原始图像
cv2.imshow('Original Image', image)
cv2.waitKey(0)

# 进行直方图均衡化处理
equalized_image = cv2.equalizeHist(image)

# 显示均衡化后的图像
cv2.imshow('Equalized Image', equalized_image)
cv2.waitKey(0)

# 关闭所有窗口
cv2.destroyAllWindows()
<br><img alt="{CB9E4769-339B-41A2-98C1-1E6F3939FD82}.png" src="\technology\collegeproject\数字图像处理\作业\习题5_files\{cb9e4769-339b-41a2-98c1-1e6f3939fd82}.png"><br>
<img alt="{2F601C54-91F7-4C2E-B679-57B925B7C270}.png" src="\technology\collegeproject\数字图像处理\作业\习题5_files\{2f601c54-91f7-4c2e-b679-57b925b7c270}.png"><br><br>% 创建一个8位灰度级的图像
image = uint8(zeros(100, 200));

% 设置左边一半为深灰色（灰度值为1/7）
image(:, 1:100) = round(255 * (1 / 7));

% 设置右边一半为黑色（灰度值为0）
image(:, 101:end) = 0;

% 显示原始图像
figure;
subplot(1, 2, 1);
imshow(image, []);
title('原始图像');

% 进行直方图均衡化处理
equalized_image = histeq(image);

% 显示均衡化后的图像
subplot(1, 2, 2);
imshow(equalized_image, []);
title('均衡化后的图像');

% 不需要显式关闭窗口，MATLAB会自动管理窗口生命周期
]]></description><link>technology\collegeproject\数字图像处理\作业\习题5.html</link><guid isPermaLink="false">Technology/CollegeProject/数字图像处理/作业/习题5.md</guid><pubDate>Sat, 09 Nov 2024 02:24:03 GMT</pubDate><enclosure url="technology\collegeproject\数字图像处理\作业\习题5_files\扫描件_数字图像处理.习题5._001.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数字图像处理\作业\习题5_files\扫描件_数字图像处理.习题5._001.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[习题六]]></title><description><![CDATA[ 
 <br><br><img alt="附件/{E815AE4E-9FB4-45DC-A97A-B32A64CEAF69}.png" src="\lib\media\{e815ae4e-9fb4-45dc-a97a-b32a64ceaf69}.png"><br>
<img alt="附件/{B3D02C7F-58B3-492C-AA1C-B59556375E71}.png" src="\lib\media\{b3d02c7f-58b3-492c-aa1c-b59556375e71}.png"><br><br><br>import numpy as np

# 定义图像矩阵
image = np.array([
    [0, 0, 0, 0, 0],
    [0, 5, 1, 6, 0],
    [0, 4, 6, 3, 0],
    [0, 7, 2, 1, 0],
    [0, 0, 0, 0, 0]
])

# 定义3x3均值滤波器的大小
filter_size = 3
half_filter_size = filter_size // 2

# 初始化滤波后的图像矩阵
filtered_image = np.zeros_like(image,dtype=float)

# 应用滤波器
for i in range(half_filter_size, image.shape[0] - half_filter_size):
    for j in range(half_filter_size, image.shape[1] - half_filter_size):
        # 提取3x3邻域
        neighborhood = image[i-half_filter_size:i+half_filter_size+1, j-half_filter_size:j+half_filter_size+1]
        # 计算邻域的平均值
        filtered_image[i, j] = np.mean(neighborhood)

# 打印滤波后的图像矩阵，保留一位小数
print(np.round(filtered_image, 1))
<br>[[0.  0.  0.  0.  0. ]
 [0.  1.8 2.8 1.8 0. ]
 [0.  2.8 3.9 2.1 0. ]
 [0.  2.1 2.6 1.3 0. ]
 [0.  0.  0.  0.  0. ]]
<br>% 定义图像矩阵
image = [
    0, 0, 0, 0, 0;
    0, 5, 1, 6, 0;
    0, 4, 6, 3, 0;
    0, 7, 2, 1, 0;
    0, 0, 0, 0, 0
];

% 定义3x3均值滤波器的大小
filter_size = 3;
half_filter_size = floor(filter_size / 2);

% 初始化滤波后的图像矩阵
filtered_image = zeros(size(image));

% 应用滤波器
for i = half_filter_size + 1:size(image, 1) - half_filter_size
    for j = half_filter_size + 1:size(image, 2) - half_filter_size
        % 提取3x3邻域
        neighborhood = image(i-half_filter_size:i+half_filter_size, j-half_filter_size:j+half_filter_size);
        % 计算邻域的平均值
        filtered_image(i, j) = mean(neighborhood(:));
    end
end

% 打印滤波后的图像矩阵，保留一位小数
fprintf('%.1f ', filtered_image);
disp(' ');
<br><br>import scipy.ndimage


def gaussian_kernel(size: int, sigma: float):
    """
    生成一个高斯滤波器（核）。
    
    :param size: 滤波器的大小（一般为奇数）
    :param sigma: 高斯函数的标准差
    :return: 高斯滤波器（二维数组）
    """
    kernel_1d = np.linspace(-(size // 2), size // 2, size)
    kernel_2d = np.outer(kernel_1d, kernel_1d)
    kernel_2d = np.exp(-(kernel_2d**2) / (2 * sigma**2))
    kernel_2d /= np.sum(kernel_2d)  # 归一化，使得卷积不改变图像的亮度
    return kernel_2d

def apply_gaussian_filter(image: np.ndarray, size: int, sigma: float):
    """
    手动实现高斯滤波器进行图像平滑。
    
    :param image: 输入图像（二维数组）
    :param size: 高斯滤波器的大小（奇数）
    :param sigma: 高斯核的标准差
    :return: 滤波后的图像
    """
    # 生成高斯核
    gaussian_kern = gaussian_kernel(size, sigma)
    
    # 获取图像的行列数
    image_height, image_width = image.shape
    
    # 计算高斯核的一半大小，用于处理边界
    half_filter_size = size // 2
    
    # 创建输出图像矩阵
    filtered_image = np.zeros_like(image, dtype=float)
    
    # 遍历图像的每个像素，进行卷积操作
    for i in range(half_filter_size, image_height - half_filter_size):
        for j in range(half_filter_size, image_width - half_filter_size):
            # 提取当前像素周围的邻域区域
            neighborhood = image[i - half_filter_size:i + half_filter_size + 1, j - half_filter_size:j + half_filter_size + 1]
            
            # 进行卷积操作：邻域与高斯核元素逐一相乘并求和
            filtered_image[i, j] = np.sum(neighborhood * gaussian_kern)
    
    return filtered_image

filter_size = 3  # 高斯滤波器的大小（奇数）
sigma = 1.0  # 高斯滤波器的标准差

# 应用高斯滤波
filtered_image = apply_gaussian_filter(image, filter_size, sigma)

# 打印滤波后的图像矩阵，保留一位小数
print(np.round(filtered_image, 1))
filter_size = 3  # 高斯滤波器的大小（奇数）
sigma = 0.8  # 高斯滤波器的标准差

# 应用高斯滤波
filtered_image = apply_gaussian_filter(image, filter_size, sigma)

# 打印滤波后的图像矩阵，保留一位小数
print(np.round(filtered_image, 1))
<br>[[0.  0.  0.  0.  0. ]
 [0.  1.8 3.  1.8 0. ]
 [0.  3.2 3.7 2.4 0. ]
 [0.  2.2 2.7 1.3 0. ]
 [0.  0.  0.  0.  0. ]]
[[0.  0.  0.  0.  0. ]
 [0.  1.9 3.1 1.9 0. ]
 [0.  3.4 3.6 2.5 0. ]
 [0.  2.3 2.8 1.3 0. ]
 [0.  0.  0.  0.  0. ]]
<br>% 定义图像矩阵
image = [
    0, 0, 0, 0, 0;
    0, 5, 1, 6, 0;
    0, 4, 6, 3, 0;
    0, 7, 2, 1, 0;
    0, 0, 0, 0, 0
];

% 高斯滤波器参数
filter_size = 3; % 滤波器大小（奇数）
sigma = 1.0;     % 高斯滤波器的标准差

% 生成高斯滤波器
gaussian_kern = fspecial('gaussian', filter_size, sigma);

% 应用高斯滤波
filtered_image = imfilter(image, gaussian_kern, 'replicate');

% 打印滤波后的图像矩阵，保留一位小数
disp(arrayfun(@(x) sprintf('%.1f ', x), filtered_image, 'UniformOutput', false));

% 修改高斯滤波器标准差并重新应用
sigma = 0.8; % 修改高斯滤波器的标准差

% 重新生成高斯滤波器
gaussian_kern = fspecial('gaussian', filter_size, sigma);

% 再次应用高斯滤波
filtered_image = imfilter(image, gaussian_kern, 'replicate');

% 再次打印滤波后的图像矩阵，保留一位小数
disp(arrayfun(@(x) sprintf('%.1f ', x), filtered_image, 'UniformOutput', false));
<br><br>import numpy as np

# 定义图像矩阵
image = np.array([
    [1, 3, 6, 8, 6, 3],
    [15, 4, 7, 9, 8, 1],
    [13, 3, 5, 5, 7, 4],
    [3, 4, 0, 2, 5, 7],
    [6, 12, 3, 6, 9, 7],
    [9, 11, 3, 11, 14, 13]
])

# 定义3x3中值滤波器的大小
filter_size = 3
half_filter_size = filter_size // 2

# 初始化滤波后的图像矩阵
filtered_image = np.copy(image)

# 应用滤波器
for i in range(half_filter_size, image.shape[0] - half_filter_size):
    for j in range(half_filter_size, image.shape[1] - half_filter_size):
        # 提取3x3邻域
        neighborhood = image[i-half_filter_size:i+half_filter_size+1, j-half_filter_size:j+half_filter_size+1]
        # 计算邻域的中值
        filtered_image[i, j] = np.median(neighborhood)

# 打印滤波后的图像矩阵
print(filtered_image)
<br>[[ 1  3  6  8  6  3]
 [15  5  5  7  6  1]
 [13  4  4  5  5  4]
 [ 3  4  4  5  6  7]
 [ 6  4  4  5  7  7]
 [ 9 11  3 11 14 13]]
<br>% 定义图像矩阵
image = [
    1, 3, 6, 8, 6, 3;
    15, 4, 7, 9, 8, 1;
    13, 3, 5, 5, 7, 4;
    3, 4, 0, 2, 5, 7;
    6, 12, 3, 6, 9, 7;
    9, 11, 3, 11, 14, 13
];

% 定义3x3中值滤波器的大小
filter_size = [3, 3]; % MATLAB 中需要指定为行和列的向量

% 应用中值滤波器
filtered_image = medfilt2(image, filter_size);

% 打印滤波后的图像矩阵
disp(filtered_image)
]]></description><link>technology\collegeproject\数字图像处理\作业\习题六.html</link><guid isPermaLink="false">Technology/CollegeProject/数字图像处理/作业/习题六.md</guid><pubDate>Thu, 05 Dec 2024 02:43:25 GMT</pubDate><enclosure url="lib\media\{e815ae4e-9fb4-45dc-a97a-b32a64ceaf69}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{e815ae4e-9fb4-45dc-a97a-b32a64ceaf69}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[作业一]]></title><description><![CDATA[ 
 <br><br><img alt="{A5192323-A836-40AA-82CA-D0061862C554}.png" src="\lib\media\{a5192323-a836-40aa-82ca-d0061862c554}.png"><br><br><br>齐次坐标是一种数学概念，在几何学和计算机图形学中广泛使用。它们提供了一种方便的方式来描述点、向量和平面等几何对象，特别是在变换操作（如旋转、平移和投影）中。在图像处理领域，齐次坐标可以帮助简化一些复杂的运算，比如仿射变换和透视变换。<br>在齐次坐标系中，一个三维点可以用四个实数组成的向量表示，其中三个分量对应于点的空间坐标，第四个分量始终为1。这种表示法允许我们将几何变换表示为一个4×4的矩阵乘以一个4维向量，从而简化了变换的计算过程。同样地，二维点也可以用三维齐次坐标表示，即使用三个实数来表示，其中前两个分量表示点的笛卡尔坐标，第三个分量始终为1。<br>在图像处理中，使用齐次坐标有以下几个优点：<br>
<br>便于表示和执行变换：齐次坐标使得图像变换（如旋转、缩放和位移）可以通过简单的矩阵乘法完成，大大简化了计算过程。
<br>易于实现视口映射：在图形渲染中，齐次坐标有助于将物体从模型空间转换到屏幕空间，也就是所谓的视口映射。
<br>支持无限远点：齐次坐标系统中存在一个特殊的无穷远点，这对于处理平行线和透视关系非常有用。
<br>统一的表示形式：齐次坐标使二维和三维坐标系统的表示方式更加一致，有利于代码复用和模块化设计。
<br>因此，使用齐次坐标表示图像矩阵可以使图像处理算法更简洁、高效，并且更容易扩展到更高维度或更多类型的变换。<br><br>一个具体的例子是在图像处理中应用旋转变换。如果我们想把一个图像绕着其中心点逆时针旋转角度θ，可以使用齐次坐标来简化这个过程。<br>首先，我们需要获取图像的宽度和高度，以及中心点坐标。然后，我们可以创建一个旋转矩阵，如下所示：<br><br>接下来，我们可以遍历图像中的每个像素点 (x, y)，并将其转换为齐次坐标表示 (x', y', 1)。然后，我们可以使用旋转矩阵 R 将这些点进行旋转：<br><br>最后，我们将旋转后的点 (x'', y'') 转换回笛卡尔坐标 (x, y)，并将新的坐标与图像矩阵相交，更新对应的像素值。<br>这个过程在齐次坐标下变得简单明了，因为只需要几个基本的矩阵运算就可以完成。如果没有使用齐次坐标，我们需要分别处理旋转和缩放的过程，而且可能会遇到边界条件的问题。<br>以下是使用Python和NumPy库实现此功能的伪代码：<br>import numpy as np

def rotate_image(image, angle):
    # 获取图像尺寸和中心点
    height, width = image.shape[:2]
    center = (width // 2, height // 2)

    # 创建旋转矩阵
    rotation_matrix = np.array([[np.cos(angle), -np.sin(angle),0],
                             [np.sin(angle), np.cos(angle),0],
                             [0,0,1]])
    
    # 遍历图像中的每个像素点
    rotated_image = np.zeros_like(image)
    for x in range(width):
        for y in range(height):
            # 将当前点转换为齐次坐标
            point = np.array([x - center[0], y - center[1], 1])

            # 应用旋转矩阵
            rotated_point = np.dot(rotation_matrix, point)[:2] + center
            
            # 更新旋转后图像的像素值
            x_rotated, y_rotated = int(rotated_point[0]), int(rotated_point[1])
            if 0 &lt;= x_rotated &lt; width and 0 &lt;= y_rotated &lt; height:
                rotated_image[y_rotated, x_rotated] = image[y, x]

    return rotated_image
<br>这个函数接受一个图像和一个旋转角度作为输入，并返回一个新的旋转后的图像。可以看到，整个过程只涉及简单的矩阵运算和坐标转换，没有额外的边界检查或其他复杂的逻辑。这就是齐次坐标在图像处理中的优势之一。<br><br><img alt="{6CDFD978-F995-42D4-9961-059F89B76D93}.png" src="\lib\media\{6cdfd978-f995-42d4-9961-059f89b76d93}.png"><br>旋转矩阵是用来在二维或三维空间中执行旋转变换的。对于二维空间中的点，我们通常使用2×2的旋转矩阵来表示绕原点的旋转。但是，在齐次坐标系中，为了统一处理平移、旋转和缩放等变换，我们会使用3×3的矩阵。<br>二维平面内绕原点逆时针旋转θ角度的旋转矩阵可以定义为：<br><br>这个矩阵的推导基于三角函数和向量旋转的基本原理。如果我们有一个向量 (x, y)，它与正x轴的夹角是α，那么它的极坐标表示就是 (r, α)，其中 r 是向量的模长。当我们把这个向量绕原点逆时针旋转θ角度后，新的坐标将是 (r  cos(α + θ), r  sin(α + θ))。<br>根据三角恒等式，我们可以得到：<br>
<br>
<br>
<br>由于  和 ，我们可以将上面的公式简化为：<br>
<br>
<br>
<br>这正是上述2×2旋转矩阵对 (x, y) 乘积的结果。<br>当我们将这个概念扩展到齐次坐标系中，以方便地包含平移操作，我们就得到了3×3的旋转矩阵：<br><br>在这个矩阵中，最后一行（[0, 0, 1]）是为了保持齐次坐标的特性，即最后一个分量总是1，这样就可以直接应用平移变换而不需要额外的操作。在实际计算中，这个矩阵会与一个形式为 [x, y, 1] 的齐次坐标向量相乘，从而实现旋转变换。<br>总结来说，旋转矩阵来源于几何变换的基本数学原理，并通过线性代数的形式表达出来，以便于计算机图形学中的高效实现。<br><br><br>我们可以使用<a data-href="双线性插值" href="\technology\collegeproject\数字图像处理\作业\双线性插值.html" class="internal-link" target="_self" rel="noopener nofollow">双线性插值</a>来放大图像。以下是一个简单的示例：<br>% 定义原始图像矩阵
f = [1 4 7; 2 5 8; 3 6 9];

% 目标图像尺寸
k_x = 2.3;
k_y = 1.6;

% 计算新图像尺寸
new_size = round(size(f) .* [k_x, k_y]);

% 初始化新图像
new_f = zeros(new_size);

% 遍历新图像中的每个像素
for i = 1:new_size(1)
    for j = 1:new_size(2)
        
        % 计算原图像中对应区域的左上角和右下角坐标
        x1 = floor((i-1)/k_x);
        y1 = floor((j-1)/k_y);
        x2 = min(floor(i/k_x), size(f, 1));
        y2 = min(floor(j/k_y), size(f, 2));
        
        % 计算权重因子
        alpha_x = (i - x1*k_x) / k_x;
        beta_x = (x2 - x1) / k_x;
        alpha_y = (j - y1*k_y) / k_y;
        beta_y = (y2 - y1) / k_y;
        
        % 计算插值值
        result = (1-alpha_x)*(1-alpha_y)*f(x1, y1) + alpha_x*(1-alpha_y)*f(x2, y1) ...
                + (1-alpha_x)*alpha_y*f(x1, y2) + alpha_x*alpha_y*f(x2, y2);
        
        new_f(i, j) = result;
    end
end

disp(new_f)
<br>在Python中，你可以使用OpenCV库来实现双线性插值。以下是一个简单的示例：<br>import cv2
import numpy as np

# 定义原始图像矩阵
f = np.array([[1, 4, 7], [2, 5, 8], [3, 6, 9]])

# 目标图像尺寸
k_x, k_y = 2.3, 1.6

# 使用OpenCV的resize函数进行双线性插值
new_f = cv2.resize(f, None, fx=k_x, fy=k_y, interpolation=cv2.INTER_LINEAR)

print(new_f)
<br>这两个示例都实现了相同的功能，即使用双线性插值放大图像。MATLAB版本使用手动计算权重因子和插值，而OpenCV版本则利用内置的resize函数自动完成插值过程。<br>matlab结果：<br>    1.0000    4.7500    4.0000    8.5000    7.0000
    1.0000    4.7500    4.0000    8.5000    7.0000
    2.3043    6.0543    5.3043    9.8043    8.3043
    2.0000    5.7500    5.0000    9.5000    8.0000
    3.1739    6.9239    6.1739   10.6739    9.1739
    3.0000    6.7500    6.0000   10.5000    9.0000
    3.0000    6.7500    6.0000   10.5000    9.0000
<br>python结果：<br>[[1.        1.4565217 2.7608695 4.0652175 5.369565  6.673913  7.       ]
 [1.4375    1.8940217 3.1983695 4.5027175 5.807065  7.111413  7.4375   ]
 [2.0625    2.5190217 3.8233695 5.1277175 6.432065  7.736413  8.0625   ]
 [2.6875    3.1440217 4.4483695 5.7527175 7.057065  8.361413  8.6875   ]
 [3.        3.4565217 4.7608695 6.0652175 7.369565  8.673913  9.       ]]
<br><br>import numpy as np

def rotate_image(image, angle):
    # 获取图像尺寸和中心点
    height, width = image.shape[:2]
    center = (width // 2, height // 2)

    # 创建旋转矩阵
    rotation_matrix = np.array([[np.cos(angle), -np.sin(angle),0],
                             [np.sin(angle), np.cos(angle),0],
                             [0,0,1]])
    
    # 遍历图像中的每个像素点
    rotated_image = np.zeros_like(image)
    for x in range(width):
        for y in range(height):
            # 将当前点转换为齐次坐标
            point = np.array([x - center[0], y - center[1], 1])

            # 应用旋转矩阵
            rotated_point = np.dot(rotation_matrix, point)[:2] + center
            
            # 更新旋转后图像的像素值
            x_rotated, y_rotated = int(rotated_point[0]), int(rotated_point[1])
            if 0 &lt;= x_rotated &lt; width and 0 &lt;= y_rotated &lt; height:
                rotated_image[y_rotated, x_rotated] = image[y, x]

    return rotated_image

f = np.array([[1, 4, 7], [2, 5, 8], [3, 6, 9]])

print(rotate_image(f,-60))
<br>旋转后图像：<br>[[9 3 0]
 [8 5 1]
 [7 0 0]]
<br><br>% 加载图像
img = imread('bird.jpg');

% 顺时针旋转图像20度
rotated_img = imrotate(img, -20, 'bilinear', 'crop');

% 创建水平镜像
horizontal_mirror_img = fliplr(rotated_img);

% 错切变换
kx = 0.3;  % 水平错切参数
ky = 0.5;  % 垂直错切参数

% 创建错切变换的仿射矩阵
tform = maketform('affine', [1 kx 0; ky 1 0; 0 0 1]);

% 应用错切变换
shear_img = imtransform(horizontal_mirror_img, tform, 'bilinear');

% 缩小图像
scale_factor = 0.6;
final_img = imresize(shear_img, scale_factor, 'bilinear');

% 显示原图、中间结果和最终结果
figure; imshow(img); title('Original Image');
figure; imshow(rotated_img); title('Rotated Image');
figure; imshow(horizontal_mirror_img); title('Horizontal Mirror Image');
figure; imshow(shear_img); title('Sheared Image');
figure; imshow(final_img); title('Final Image');

<br><img alt="{4CF8281E-83EB-4B08-8617-7BAF42B6AFDE}.png" src="\lib\media\{4cf8281e-83eb-4b08-8617-7baf42b6afde}.png">]]></description><link>technology\collegeproject\数字图像处理\作业\作业一.html</link><guid isPermaLink="false">Technology/CollegeProject/数字图像处理/作业/作业一.md</guid><pubDate>Tue, 08 Oct 2024 12:38:38 GMT</pubDate><enclosure url="lib\media\{a5192323-a836-40aa-82ca-d0061862c554}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{a5192323-a836-40aa-82ca-d0061862c554}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[实验二：图像增强]]></title><description><![CDATA[ 
 <br><br>图像增强是通过图像处理技术对图像进行改善，使其更加符合人类视觉感知或某些应用需求的过程。常见的图像增强方法包括灰度变换、直方图均衡化、噪声去除、锐化等技术。本实验使用Matlab对图像进行以下处理：<br>
<br>
灰度化（Grayscale Conversion）：

<br>将彩色图像转换为灰度图像，以减少计算复杂度，同时保留图像的亮度信息。
<br>公式：，其中分别为图像的红、绿、蓝通道像素值。


<br>
分段线性变换（Piecewise Linear Transformation）：

<br>通过调整像素的值范围对图像进行变换，目的是增强图像的对比度或亮度。常见方法是线性函数，其中像素值分段。
<br>公式：，其中和为调整系数。


<br>
直方图均衡化（Histogram Equalization）：

<br>通过调整图像的灰度值分布，使其分布更加均匀，从而增强图像的对比度。特别适用于亮度分布不均的图像。
<br>公式：对于灰度级，均衡化后的灰度级为累积概率分布的反函数。


<br>
伪彩色增强（Pseudo-Color Enhancement）：

<br>将灰度图像映射为彩色图像，以便更好地展示细节。常见的方法有使用热金属或彩虹编码方案，将灰度值映射到色彩梯度中。


<br>
噪声添加与平滑（Noise Addition and Smoothing）：

<br>向图像添加噪声（如高斯噪声），然后使用平滑滤波器（如均值滤波器、Gaussian滤波器等）对图像进行去噪，减少噪声影响。


<br>
Sobel算子锐化（Sobel Edge Detection）：

<br>通过Sobel算子对图像进行边缘检测。Sobel算子是一种常见的边缘检测方法，通过计算图像梯度来找到边缘。


<br><br>
<br>读取图像：使用Matlab中的imread函数读取图像文件Image1。
<br>灰度化：通过rgb2gray函数将彩色图像转换为灰度图像。
<br>直方图显示：使用imhist函数显示灰度图像的直方图。
<br>分段线性变换：设计并应用线性变换公式，调整图像的亮度或对比度。
<br>直方图均衡化：使用histeq函数对灰度图像进行直方图均衡化。
<br>伪彩色增强：应用colormap函数，采用热金属或彩虹编码方法增强图像色彩。
<br>添加噪声和平滑：使用imnoise函数向图像添加噪声，然后应用fspecial和imfilter函数进行平滑。
<br>Sobel锐化：使用fspecial('sobel')函数创建Sobel算子，应用imfilter进行锐化。
<br><br>% 1. 读取图像
img = imread('Image1.jpg'); 

% 2. 灰度化处理
gray = rgb2gray(img);

% 3. 显示灰度图的直方图
figure;
imhist(gray);
title('灰度图像直方图');

% 4. 分段线性变换
alpha = 1.5; % 增强系数
beta = 0; % 偏移量
gray_linear = alpha * double(gray) + beta;
figure;
imshow(uint8(gray_linear));
title('分段线性变换图像');

% 5. 直方图均衡化
gray_eq = histeq(gray);
figure;
imshow(gray_eq);
title('直方图均衡化');

% 6. 伪彩色增强
gray_pseudo = gray; 
colormap jet; % 使用彩虹编码
figure;
imshow(gray_pseudo);
title('伪彩色增强');

% 7. 添加噪声并平滑
noisy_img = imnoise(gray, 'gaussian', 0, 0.02); % 添加高斯噪声
h = fspecial('average', [3 3]); % 均值滤波器
smooth_img = imfilter(noisy_img, h);
figure;
imshow(smooth_img);
title('噪声添加与平滑');

% 8. Sobel算子锐化
sobel_filter = fspecial('sobel');
sobel_img = imfilter(gray, sobel_filter);
figure;
imshow(sobel_img);
title('Sobel锐化');
<br>import cv2
import numpy as np
import matplotlib.pyplot as plt
from skimage import exposure

# 1. 读取图像
img = cv2.imread('Image1.jpg')

# 2. 灰度化处理
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 3. 显示灰度图的直方图
plt.figure()
plt.hist(gray.ravel(), bins=256, range=(0, 256))
plt.title('灰度图像直方图')
plt.show()

# 4. 分段线性变换
alpha = 1.5  # 增强系数
beta = 0  # 偏移量
gray_linear = np.clip(alpha * gray + beta, 0, 255).astype(np.uint8)  # 保证值在0-255之间
plt.figure()
plt.imshow(gray_linear, cmap='gray')
plt.title('分段线性变换图像')
plt.axis('off')
plt.show()

# 5. 直方图均衡化
gray_eq = cv2.equalizeHist(gray)
plt.figure()
plt.imshow(gray_eq, cmap='gray')
plt.title('直方图均衡化')
plt.axis('off')
plt.show()

# 6. 伪彩色增强
# 使用彩虹编码（colormap jet）
gray_pseudo = cv2.applyColorMap(gray, cv2.COLORMAP_JET)
plt.figure()
plt.imshow(gray_pseudo)
plt.title('伪彩色增强')
plt.axis('off')
plt.show()

# 7. 添加噪声并平滑
# 添加高斯噪声
noise = np.random.normal(0, 0.02, gray.shape) * 255
noisy_img = np.clip(gray + noise, 0, 255).astype(np.uint8)

# 均值滤波
smooth_img = cv2.blur(noisy_img, (3, 3))  # 3x3的均值滤波
plt.figure()
plt.imshow(smooth_img, cmap='gray')
plt.title('噪声添加与平滑')
plt.axis('off')
plt.show()

# 8. Sobel算子锐化
sobel_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)  # Sobel X方向
sobel_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)  # Sobel Y方向
sobel_img = cv2.magnitude(sobel_x, sobel_y)  # 计算梯度幅度
sobel_img = np.uint8(np.clip(sobel_img, 0, 255))  # 转换为uint8类型并确保在0-255之间
plt.figure()
plt.imshow(sobel_img, cmap='gray')
plt.title('Sobel锐化')
plt.axis('off')
plt.show()
<br><img alt="{14515C37-616A-413B-8700-2EE471667ECD}.png" src="\lib\media\{14515c37-616a-413b-8700-2ee471667ecd}.png"><br>
<img alt="{A4093481-6618-439B-A018-A99D9A005195}.png" src="\lib\media\{a4093481-6618-439b-a018-a99d9a005195}.png"><br>
<img alt="{BAEB6F8D-35FB-43EB-9A4E-2BDA6E6C1F61}.png" src="\lib\media\{baeb6f8d-35fb-43eb-9a4e-2bda6e6c1f61}.png"><br>
<img alt="{55BA19FC-640D-4F66-A90A-798579594EF3}.png" src="\lib\media\{55ba19fc-640d-4f66-a90a-798579594ef3}.png"><br>
<img alt="{81421E7A-A12F-411E-B607-3AC07741D9AF}.png" src="\lib\media\{81421e7a-a12f-411e-b607-3ac07741d9af}.png"><br>
<img alt="{61EE0D0A-1355-4BDA-9900-67800D434D7E}.png" src="\lib\media\{61ee0d0a-1355-4bda-9900-67800d434d7e}.png"><br><br>
<br>
灰度化与直方图：

<br>原图被成功灰度化，并显示出其灰度直方图，直方图反映了图像中像素亮度的分布。


<br>
分段线性变换：

<br>图像亮度增强，灰度值通过线性变换调整。实验中可以通过调整参数alpha和beta来观察不同的增强效果。


<br>
直方图均衡化：

<br>灰度图像的对比度得到了显著改善，细节更加清晰，尤其是在亮度分布不均的图像中。


<br>
伪彩色增强：

<br>使用热金属或彩虹编码将灰度图像转换为彩色图像，增强了图像的可视化效果。不同的伪彩色映射方法对图像细节有不同的表现。


<br>
噪声添加与平滑：

<br>向图像添加了高斯噪声，并通过均值滤波器平滑噪声，成功去除了图像中的噪声干扰。


<br>
Sobel算子锐化：

<br>成功提取了图像中的边缘信息，通过Sobel算子对图像进行了锐化处理，边缘更加明显。


<br><br>
<br>
调整处理变换参数：

<br>通过修改线性变换的参数（如alpha和beta），观察图像在不同参数下的变化，调整结果达到最佳效果。


<br>
更改伪彩色增强方法：

<br>使用colormap hot或colormap cool等其他编码方式，测试不同伪彩色方案对图像增强的效果。


<br>
设计不同的平滑与锐化滤波方法：

<br>除了均值滤波器，还可以尝试Gaussian滤波器、Median滤波器等对图像进行平滑。锐化滤波器如Laplacian算子也可以用于增强图像细节。


<br>
彩色图像增强设计：

<br>对彩色图像进行处理时，可以分别对RGB三个通道进行增强处理，并结合伪彩色编码方法进行增强。


<br><br><br>在分段线性变换和直方图均衡化的基础上，可以调整处理参数，例如通过修改alpha、beta等值来观察不同效果。<br>% 分段线性变换（修改alpha和beta）
alpha = 2; % 增强系数
beta = 50; % 偏移量
gray_linear = alpha * double(gray) + beta;
figure;
imshow(uint8(gray_linear));
title('调整后的分段线性变换');

% 直方图均衡化后的效果对比
gray_eq = histeq(gray);
figure;
imshow(gray_eq);
title('直方图均衡化后的效果');
<br>import cv2
import numpy as np
import matplotlib.pyplot as plt

# 读取图像
img = cv2.imread('Image1.jpg')

# 灰度化处理
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 分段线性变换（修改alpha和beta）
alpha = 2  # 增强系数
beta = 50  # 偏移量
gray_linear = np.clip(alpha * gray + beta, 0, 255).astype(np.uint8)  # 保证值在0-255之间
plt.figure()
plt.imshow(gray_linear, cmap='gray')
plt.title('调整后的分段线性变换')
plt.axis('off')
plt.show()

# 直方图均衡化后的效果对比
gray_eq = cv2.equalizeHist(gray)
plt.figure()
plt.imshow(gray_eq, cmap='gray')
plt.title('直方图均衡化后的效果')
plt.axis('off')
plt.show()

<br><img alt="{3DD51313-C10F-45B6-9DFC-DEEDA7267A6A}.png" src="\lib\media\{3dd51313-c10f-45b6-9dfc-deeda7267a6a}.png"><br>
<img alt="{92DAEEB5-7AC4-47B4-A52E-200974ADB1EE}.png" src="\lib\media\{92daeeb5-7ac4-47b4-a52e-200974adb1ee}.png"><br><br>使用colormap函数改变伪彩色增强的方式，可以选用热金属编码（hot）或彩虹编码（jet）。<br>% 伪彩色增强（热金属编码）
gray_pseudo_hot = gray; 
colormap hot; % 使用热金属编码
figure;
imshow(gray_pseudo_hot);
title('热金属编码增强');

% 伪彩色增强（彩虹编码）
gray_pseudo_jet = gray;
colormap jet; % 使用彩虹编码
figure;
imshow(gray_pseudo_jet);
title('彩虹编码增强');
<br>import cv2
import numpy as np
import matplotlib.pyplot as plt

# 读取图像
img = cv2.imread('Image1.jpg')

# 灰度化处理
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 伪彩色增强（热金属编码）
gray_pseudo_hot = cv2.applyColorMap(gray, cv2.COLORMAP_HOT)  # 热金属编码
plt.figure()
plt.imshow(gray_pseudo_hot)
plt.title('热金属编码增强')
plt.axis('off')
plt.show()

# 伪彩色增强（彩虹编码）
gray_pseudo_jet = cv2.applyColorMap(gray, cv2.COLORMAP_JET)  # 彩虹编码
plt.figure()
plt.imshow(gray_pseudo_jet)
plt.title('彩虹编码增强')
plt.axis('off')
plt.show()

<br><img alt="{76E92D93-E4AB-457E-94FD-A48A68172CE6}.png" src="\lib\media\{76e92d93-e4ab-457e-94fd-a48a68172ce6}.png"><br>
<img alt="{E2976213-2F79-4771-A932-F1081AC7555B}.png" src="\lib\media\{e2976213-2f79-4771-a932-f1081ac7555b}.png"><br><br><br>可以尝试不同的平滑滤波方法，例如均值滤波、Gaussian滤波和中值滤波等。<br>% 均值滤波（已使用fspecial）
h = fspecial('average', [5 5]); % 5x5的均值滤波器
smooth_img_avg = imfilter(gray, h);
figure;
imshow(smooth_img_avg);
title('均值滤波');

% Gaussian滤波（使用fspecial生成Gaussian核）
h_gauss = fspecial('gaussian', [5 5], 1); % 5x5的Gaussian滤波器，标准差为1
smooth_img_gauss = imfilter(gray, h_gauss);
figure;
imshow(smooth_img_gauss);
title('Gaussian滤波');

% 中值滤波（使用medfilt2）
smooth_img_median = medfilt2(gray, [3 3]); % 3x3的中值滤波器
figure;
imshow(smooth_img_median);
title('中值滤波');
<br>import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import median_filter

# 读取图像
img = cv2.imread('Image1.jpg')

# 灰度化处理
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# 均值滤波（5x5的均值滤波器）
smooth_img_avg = cv2.blur(gray, (5, 5))  # 使用OpenCV的blur函数进行均值滤波
plt.figure()
plt.imshow(smooth_img_avg, cmap='gray')
plt.title('均值滤波')
plt.axis('off')
plt.show()

# Gaussian滤波（5x5的Gaussian滤波器，标准差为1）
smooth_img_gauss = cv2.GaussianBlur(gray, (5, 5), 1)  # 使用OpenCV的GaussianBlur函数进行Gaussian滤波
plt.figure()
plt.imshow(smooth_img_gauss, cmap='gray')
plt.title('Gaussian滤波')
plt.axis('off')
plt.show()

# 中值滤波（3x3的中值滤波器）
smooth_img_median = median_filter(gray, size=(3, 3))  # 使用scipy的median_filter函数进行中值滤波
plt.figure()
plt.imshow(smooth_img_median, cmap='gray')
plt.title('中值滤波')
plt.axis('off')
plt.show()

<br><img alt="{D6399CCA-F727-4FD6-A174-2F5FBE813A96}.png" src="\lib\media\{d6399cca-f727-4fd6-a174-2f5fbe813a96}.png"><br>
<img alt="{274EDFC6-F86D-4C3D-9E72-08838DA9CC2C}.png" src="\lib\media\{274edfc6-f86d-4c3d-9e72-08838da9cc2c}.png"><br>
<img alt="{A6A492B3-611E-4297-8A40-3D65D31F6C60}.png" src="\lib\media\{a6a492b3-611e-4297-8a40-3d65d31f6c60}.png"><br><br>除了Sobel算子，可以尝试其他锐化滤波方法，如Laplacian滤波器和高通滤波器。<br>% Laplacian锐化
laplacian_filter = fspecial('laplacian', 0.2); % 生成Laplacian滤波器
sharpened_lap = imfilter(gray, laplacian_filter);
figure;
imshow(sharpened_lap);
title('Laplacian锐化');

% 高通滤波锐化
highpass_filter = fspecial('highpass', 3); % 生成高通滤波器
sharpened_hp = imfilter(gray, highpass_filter);
figure;
imshow(sharpened_hp);
title('高通滤波锐化');
<br>import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import laplace

# 读取图像
img = cv2.imread('Image1.jpg')

# 灰度化处理
gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)

# Laplacian锐化
laplacian_filter = np.array([[0, 1, 0],
                             [1, -4, 1],
                             [0, 1, 0]])  # 自定义Laplacian滤波器
sharpened_lap = cv2.filter2D(gray, -1, laplacian_filter)  # 使用filter2D进行卷积操作
plt.figure()
plt.imshow(sharpened_lap, cmap='gray')
plt.title('Laplacian锐化')
plt.axis('off')
plt.show()

# 高通滤波锐化
# 高通滤波器是一个低通滤波器的反向滤波，首先生成一个低通滤波器，然后用1减去该滤波器
lowpass_filter = cv2.getGaussianKernel(3, 1)  # 生成3x3的高斯核
lowpass_filter = np.outer(lowpass_filter, lowpass_filter.T)  # 构造二维高斯核
highpass_filter = np.ones_like(lowpass_filter) - lowpass_filter  # 高通滤波器是1减去低通滤波器
sharpened_hp = cv2.filter2D(gray, -1, highpass_filter)  # 使用filter2D进行卷积操作
plt.figure()
plt.imshow(sharpened_hp, cmap='gray')
plt.title('高通滤波锐化')
plt.axis('off')
plt.show()

<br><img alt="{5AA4811A-3B93-4AEB-B12C-4AF6D4779B81}.png" src="\lib\media\{5aa4811a-3b93-4aeb-b12c-4af6d4779b81}.png"><br><br>对于彩色图像增强，可以对每个颜色通道分别进行处理，再合并回去进行展示。例如，可以分别对RGB三个通道应用不同的增强方法：<br>% 读取图像
img = imread('Image1.jpg');

% 提取RGB通道
R = img(:,:,1);
G = img(:,:,2);
B = img(:,:,3);

% 对每个通道进行增强（例如直方图均衡化）
R_eq = histeq(R);
G_eq = histeq(G);
B_eq = histeq(B);

% 合并增强后的RGB通道
color_img_eq = cat(3, R_eq, G_eq, B_eq);
figure;
imshow(color_img_eq);
title('彩色图像直方图均衡化');

% 另一种示例：对RGB通道使用不同的伪彩色增强
% 对红色通道使用热金属编码
R_pseudo = R;
R_pseudo = uint8(R_pseudo); % 确保是uint8类型
colormap hot;
figure;
imshow(R_pseudo);
title('红色通道热金属增强');

% 对绿色通道使用彩虹编码
G_pseudo = G;
G_pseudo = uint8(G_pseudo); % 确保是uint8类型
colormap jet;
figure;
imshow(G_pseudo);
title('绿色通道彩虹增强');

% 对蓝色通道进行平滑处理
B_smooth = medfilt2(B, [3 3]); % 对蓝色通道应用中值滤波
figure;
imshow(B_smooth);
title('蓝色通道平滑');

% 合并处理后的RGB通道
color_img_processed = cat(3, R_pseudo, G_pseudo, B_smooth);
figure;
imshow(color_img_processed);
title('合并后的处理结果');

<br>import cv2
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import median_filter

# 1. 读取图像
img = cv2.imread('Image1.jpg')

# 2. 提取RGB通道
R = img[:,:,2]  # OpenCV使用BGR格式，R在第2个通道
G = img[:,:,1]  # G在第1个通道
B = img[:,:,0]  # B在第0个通道

# 3. 对每个通道进行直方图均衡化
R_eq = cv2.equalizeHist(R)
G_eq = cv2.equalizeHist(G)
B_eq = cv2.equalizeHist(B)

# 4. 合并增强后的RGB通道
color_img_eq = cv2.merge([R_eq, G_eq, B_eq])
plt.figure()
plt.imshow(cv2.cvtColor(color_img_eq, cv2.COLOR_BGR2RGB))  # 转换为RGB以显示
plt.title('彩色图像直方图均衡化')
plt.axis('off')
plt.show()

# 5. 伪彩色增强：红色通道使用热金属编码
R_pseudo = R.astype(np.uint8)  # 确保是uint8类型
plt.figure()
plt.imshow(R_pseudo, cmap='hot')
plt.title('红色通道热金属增强')
plt.axis('off')
plt.show()

# 6. 伪彩色增强：绿色通道使用彩虹编码
G_pseudo = G.astype(np.uint8)  # 确保是uint8类型
plt.figure()
plt.imshow(G_pseudo, cmap='jet')
plt.title('绿色通道彩虹增强')
plt.axis('off')
plt.show()

# 7. 对蓝色通道进行平滑处理
B_smooth = median_filter(B, size=(3, 3))  # 使用中值滤波进行平滑
plt.figure()
plt.imshow(B_smooth, cmap='gray')
plt.title('蓝色通道平滑')
plt.axis('off')
plt.show()

# 8. 合并处理后的RGB通道
color_img_processed = cv2.merge([R_pseudo, G_pseudo, B_smooth])
plt.figure()
plt.imshow(cv2.cvtColor(color_img_processed, cv2.COLOR_BGR2RGB))  # 转换为RGB以显示
plt.title('合并后的处理结果')
plt.axis('off')
plt.show()

<br><img alt="{5305C70F-B4F4-48AF-84F2-DF2A1C27835C}.png" src="\lib\media\{5305c70f-b4f4-48af-84f2-df2a1c27835c}.png"><br><br><br>本实验通过Matlab实现了多种图像增强方法，包括灰度化、直方图均衡化、伪彩色增强、噪声添加与平滑以及Sobel锐化等。通过调整参数和不同的增强方法，可以观察到图像在处理后的效果显著改善，增强了细节和对比度。这些方法不仅能够提高图像质量，还能为后续的图像分析和计算机视觉任务打下基础。]]></description><link>technology\collegeproject\数字图像处理\实验二：图像增强.html</link><guid isPermaLink="false">Technology/CollegeProject/数字图像处理/实验二：图像增强.md</guid><pubDate>Sat, 28 Dec 2024 05:02:12 GMT</pubDate><enclosure url="lib\media\{14515c37-616a-413b-8700-2ee471667ecd}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{14515c37-616a-413b-8700-2ee471667ecd}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[数字图像处理期中考试]]></title><description><![CDATA[ 
 <br><br>利用图像基本运算实现以下两幅图像的和合成，实现冬天夜晚漫天飘雪的效果<br># 二值转换
import cv2
import numpy as np
import random

def invert_colors(image_path, output_path):
    # 读取图片
    img = cv2.imread(image_path)

    # 将颜色反转
    inverted_img = cv2.bitwise_not(img)

    # 保存结果
    cv2.imwrite(output_path, inverted_img)

inputpath = 'snowflakes.jpg'
outputpath = 'snowflakes_transform.jpg'
invert_colors(inputpath, outputpath)

# 读取夜晚图像和雪花图像（雪花图像已经进行翻转）
night_image = cv2.imread('night.jpg')
snowflake_image = cv2.imread('snowflakes_transform.jpg', cv2.IMREAD_GRAYSCALE)  # 只读取灰度图像

# 将雪花图像二值化，提取雪花的形状（白色部分）
_, snowflake_binary = cv2.threshold(snowflake_image, 1, 255, cv2.THRESH_BINARY)  # 白色部分为雪花

# 获取夜晚图像的尺寸
night_height, night_width = night_image.shape[:2]

# 设置雪花的数量
num_snowflakes = 250

# 循环生成多个雪花并随机放置
for _ in range(num_snowflakes):
    # 随机选择一个雪花的大小
    scale_factor = random.uniform(0.01, 0.01)  # 调整范围以使雪花更小
    new_size = (int(snowflake_binary.shape[1] * scale_factor), int(snowflake_binary.shape[0] * scale_factor))
    
    # 缩放雪花图像
    snowflake_resized = cv2.resize(snowflake_binary, new_size, interpolation=cv2.INTER_NEAREST)
    
    # 随机选择雪花放置的x, y坐标
    x_offset = random.randint(0, night_width - snowflake_resized.shape[1])
    y_offset = random.randint(0, night_height - snowflake_resized.shape[0])
    
    # 将雪花图案涂到夜晚图像上
    for c in range(3):  # 对RGB三个通道进行处理
        night_image[y_offset:y_offset+snowflake_resized.shape[0], x_offset:x_offset+snowflake_resized.shape[1], c] = \
            np.where(snowflake_resized == 255, 255, night_image[y_offset:y_offset+snowflake_resized.shape[0], x_offset:x_offset+snowflake_resized.shape[1], c])

# 显示合成后的图像
cv2.imshow('Snowy Night', night_image)
cv2.imwrite('snowy_night_white_snowflakes.jpg', night_image)

cv2.waitKey(0)
cv2.destroyAllWindows()
<br>% 读取图片路径
inputpath = 'snowflakes.jpg';
outputpath = 'snowflakes_transform.jpg';

% 读取图像
img = imread(inputpath);

% 将颜色反转
inverted_img = 255 - img;

% 保存结果
imwrite(inverted_img, outputpath);

% 读取夜晚图像和雪花图像（白底黑色图案）
night_image = imread('night.jpg');
snowflake_image = imread('snowflakes_transform.jpg');  % 读取灰度图像

% 将雪花图像二值化，提取雪花的形状（白色部分）
snowflake_binary = snowflake_image &gt; 1;  % 白色部分为雪花

% 获取夜晚图像的尺寸
[night_height, night_width, ~] = size(night_image);

% 设置雪花的数量
num_snowflakes = 250;

% 循环生成多个雪花并随机放置
for i = 1:num_snowflakes
    % 随机选择一个雪花的大小
    scale_factor = rand() * (0.01 - 0.01) + 0.01;  % 调整范围以使雪花更小
    new_size = round([size(snowflake_binary, 1) * scale_factor, size(snowflake_binary, 2) * scale_factor]);

    % 缩放雪花图像
    snowflake_resized = imresize(snowflake_binary, new_size, 'nearest');
    
    % 随机选择雪花放置的x, y坐标
    x_offset = randi([1, night_width - size(snowflake_resized, 2)]);
    y_offset = randi([1, night_height - size(snowflake_resized, 1)]);
    
    % 将雪花图案涂到夜晚图像上
    for c = 1:3  % 对RGB三个通道进行处理
        night_channel = night_image(:,:,c);
        night_channel(y_offset:y_offset+size(snowflake_resized, 1)-1, x_offset:x_offset+size(snowflake_resized, 2)-1) = ...
            night_channel(y_offset:y_offset+size(snowflake_resized, 1)-1, x_offset:x_offset+size(snowflake_resized, 2)-1) .* uint8(~snowflake_resized) + 255 * uint8(snowflake_resized);
        night_image(:,:,c) = night_channel;
    end
end

% 显示合成后的图像
imshow(night_image);

% 保存合成的雪夜图像
imwrite(night_image, 'snowy_night_white_snowflakes.jpg');

<br><img alt="snowy_night_white_snowflakes.jpg" src="\technology\collegeproject\数字图像处理\数字图像处理期中考试_files\snowy_night_white_snowflakes.jpg"><br><br>分别利用基于图像变换的非模型图像增强算法，和基于图像去雾模型的图像增强算法，对低光照图像进行图像增强。<br><br>import cv2
import numpy as np

# 读取低光照图像
low_light_image = cv2.imread('low-light.png')

# 转换为灰度图像
gray_image = cv2.cvtColor(low_light_image, cv2.COLOR_BGR2GRAY)

# 直方图均衡化
equalized_image = cv2.equalizeHist(gray_image)

# 将均衡化后的图像转换回彩色
color_equalized_image = cv2.cvtColor(equalized_image, cv2.COLOR_GRAY2BGR)

# 显示和保存结果
cv2.imshow('Histogram Equalized Image', color_equalized_image)
cv2.imwrite('equalized_image.png', color_equalized_image)

cv2.waitKey(0)
cv2.destroyAllWindows()

<br>% 读取低光照图像
low_light_image = imread('low-light.png');

% 转换为灰度图像
gray_image = rgb2gray(low_light_image);

% 直方图均衡化
equalized_image = histeq(gray_image);

% 将均衡化后的灰度图像转换回彩色
color_equalized_image = cat(3, equalized_image, equalized_image, equalized_image);

% 显示和保存结果
imshow(color_equalized_image);
imwrite(color_equalized_image, 'equalized_image.png');

<br><img alt="equalized_image.png" src="\technology\collegeproject\数字图像处理\数字图像处理期中考试_files\equalized_image.png"><br><br>import cv2
import numpy as np

# 读取低光照图像
low_light_image = cv2.imread('low-light.png')

# 将图像转换为浮动类型，并进行对数变换
low_light_image_float = np.float32(low_light_image)
log_image = np.log(1 + low_light_image_float)

# 归一化回0到255之间的值
log_image_normalized = np.uint8(cv2.normalize(log_image, None, 0, 255, cv2.NORM_MINMAX))

# 显示和保存结果
cv2.imshow('Log Transformed Image', log_image_normalized)
cv2.imwrite('log_transformed_image.png', log_image_normalized)

cv2.waitKey(0)
cv2.destroyAllWindows()

<br>% 读取低光照图像
low_light_image = imread('low-light.png');

% 将图像转换为浮动类型，并进行对数变换
low_light_image_float = double(low_light_image);
log_image = log(1 + low_light_image_float);

% 归一化回0到255之间的值
log_image_normalized = uint8(mat2gray(log_image) * 255);

% 显示和保存结果
imshow(log_image_normalized);
imwrite(log_image_normalized, 'log_transformed_image.png');

<br><img alt="log_transformed_image.png" src="\technology\collegeproject\数字图像处理\数字图像处理期中考试_files\log_transformed_image.png"><br><br>import cv2
import numpy as np

def dark_channel_prior(img, size=15):
    # 转换为浮动类型
    img = np.float32(img) / 255.0
    # 计算每个通道的最小值
    min_channel = np.min(img, axis=2)
    # 计算暗原色通道
    dark_channel = cv2.erode(min_channel, np.ones((size, size)))
    return dark_channel

def recover_image(I, dark_channel, omega=0.95, t0=0.1):
    # 将输入图像转换为浮动类型
    I = np.float32(I)
    
    # 估算大气光
    A = np.max(dark_channel)
    
    # 计算传输图
    transmission = 1 - omega * dark_channel
    transmission = np.clip(transmission, t0, 1)
    
    # 将单通道传输图扩展为三通道
    transmission = np.repeat(transmission[:, :, np.newaxis], 3, axis=2)
    
    # 恢复图像（通过增强暗部区域）
    J = (I - A) / transmission + A
    
    # 提高对比度和亮度
    J = np.clip(J, 0, 255).astype(np.uint8)
    
    enhanced_image = cv2.convertScaleAbs(J, alpha=1.5, beta=30)  
    
    return enhanced_image

# 读取低光照图像
low_light_image = cv2.imread('low-light.png')

# 计算暗原色通道
dark_channel = dark_channel_prior(low_light_image)

# 恢复图像
recovered_image = recover_image(low_light_image, dark_channel)

# 显示和保存恢复后的图像
cv2.imshow('Restored Image', recovered_image)
cv2.imwrite('restored_image.png', recovered_image)

cv2.waitKey(0)
cv2.destroyAllWindows()

<br>% 读取低光照图像
low_light_image = imread('low-light.png');

% 使用 MATLAB 内置的去雾函数进行去雾处理
dehazed_image = dehaze(low_light_image);

% 显示和保存结果
imshow(dehazed_image);
imwrite(dehazed_image, 'dehazed_image.png');

<br><img alt="restored_image.png" src="\technology\collegeproject\数字图像处理\数字图像处理期中考试_files\restored_image.png"><br><br>对于一张人脸图像，要求通过空间颜色模型进行肤色分辨并利用合适的方法进行人脸的美化<br>import cv2
import numpy as np

def enhance_brightness(image):
    # 将图像转换为HSV颜色空间
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    
    # 提取V（亮度）通道
    h, s, v = cv2.split(hsv)

    # 增强V通道，提升图像亮度
    v = cv2.equalizeHist(v)  # 直方图均衡化提升亮度

    # 合并通道
    enhanced_hsv = cv2.merge([h, s, v])

    # 将增强后的HSV图像转换回BGR
    enhanced_image = cv2.cvtColor(enhanced_hsv, cv2.COLOR_HSV2BGR)
    
    return enhanced_image

def skin_color_segmentation(image):
    # 将图像从BGR转换为HSV颜色空间
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)

    # 定义肤色的HSV范围
    lower_skin = np.array([0, 10, 20])  # 最小肤色值，放宽对比度限制
    upper_skin = np.array([20, 255, 255])  # 最大肤色值

    # 使用cv2.inRange进行阈值化，提取肤色区域
    skin_mask = cv2.inRange(hsv, lower_skin, upper_skin)

    # 对掩膜进行形态学处理，去除噪点
    kernel = np.ones((5, 5), np.uint8)
    skin_mask = cv2.morphologyEx(skin_mask, cv2.MORPH_CLOSE, kernel)
    
    # 将肤色区域从原图提取出来
    skin = cv2.bitwise_and(image, image, mask=skin_mask)
    return skin, skin_mask

def beautify_face(image, mask):
    # 对人脸区域进行高斯模糊，平滑皮肤，去除瑕疵
    beautified_face = cv2.GaussianBlur(image, (15, 15), 0)
    
    # 将原图和模糊后的图像结合
    beautified_face = cv2.bitwise_and(beautified_face, beautified_face, mask=mask)
    result = cv2.addWeighted(image, 0.7, beautified_face, 0.3, 0)
    return result

# 读取人脸图像
image = cv2.imread('face.png')

# 增强暗部亮度
enhanced_image = enhance_brightness(image)

# 肤色分割
skin, skin_mask = skin_color_segmentation(enhanced_image)

# 对提取的肤色区域进行美化
beautified_image = beautify_face(enhanced_image, skin_mask)

# 显示结果
cv2.imshow('Original Image', image)               # 原始图像
cv2.imshow('Enhanced Image', enhanced_image)       # 增强后的图像
cv2.imshow('Skin Region', skin)                    # 肤色区域提取结果
cv2.imshow('Beautified Image', beautified_image)   # 美化后的图像

# 保存结果
cv2.imwrite('beautified_face.png', beautified_image)   # 保存美化后的图像
cv2.imwrite('Enhanced_face.png',  enhanced_image)   # 保存美化后的图像
cv2.imwrite('skin_extracted.png', skin)                # 保存肤色提取的区域

cv2.waitKey(0)
cv2.destroyAllWindows()

<br>% 读取人脸图像
image = imread('face.png');

% 增强亮度
enhanced_image = enhance_brightness(image);

% 肤色分割
[skin, skin_mask] = skin_color_segmentation(enhanced_image);

% 对提取的肤色区域进行美化
beautified_image = beautify_face(enhanced_image, skin_mask);

% 显示结果
figure, imshow(image), title('Original Image');               % 原始图像
figure, imshow(enhanced_image), title('Enhanced Image');       % 增强后的图像
figure, imshow(skin), title('Skin Region');                    % 肤色区域提取结果
figure, imshow(beautified_image), title('Beautified Image');   % 美化后的图像

% 保存结果
imwrite(beautified_image, 'beautified_face.png');   % 保存美化后的图像
imwrite(enhanced_image, 'Enhanced_face.png');      % 保存增强后的图像
imwrite(skin, 'skin_extracted.png');               % 保存肤色提取的区域

%% 增强亮度函数
function enhanced_image = enhance_brightness(image)
    % 将图像转换为HSV颜色空间
    hsv = rgb2hsv(image);
    
    % 提取V（亮度）通道
    v = hsv(:,:,3);

    % 增强V通道，提升图像亮度
    v = histeq(v);  % 直方图均衡化提升亮度

    % 合并通道
    enhanced_hsv = cat(3, hsv(:,:,1), hsv(:,:,2), v);

    % 将增强后的HSV图像转换回BGR
    enhanced_image = hsv2rgb(enhanced_hsv);
end

%% 肤色分割函数
function [skin, skin_mask] = skin_color_segmentation(image)
    % 将图像从BGR转换为HSV颜色空间
    hsv = rgb2hsv(image);

    % 定义肤色的HSV范围
    lower_skin = [0, 0.1, 0.2];  % 最小肤色值，放宽对比度限制
    upper_skin = [0.1, 1, 1];    % 最大肤色值

    % 使用inRange进行阈值化，提取肤色区域
    skin_mask = (hsv(:,:,1) &gt;= lower_skin(1) &amp; hsv(:,:,1) &lt;= upper_skin(1)) &amp; ...
                (hsv(:,:,2) &gt;= lower_skin(2) &amp; hsv(:,:,2) &lt;= upper_skin(2)) &amp; ...
                (hsv(:,:,3) &gt;= lower_skin(3) &amp; hsv(:,:,3) &lt;= upper_skin(3));

    % 对掩膜进行形态学处理，去除噪点
    skin_mask = imclose(skin_mask, strel('disk', 5));  % 使用圆形结构元素进行形态学闭运算
    
    % 将肤色区域从原图提取出来
    skin = bsxfun(@times, image, cast(skin_mask, 'like', image));  % 通过掩膜提取肤色区域
end

%% 美化人脸函数
function beautified_image = beautify_face(image, mask)
    % 对人脸区域进行高斯模糊，平滑皮肤，去除瑕疵
    beautified_face = imgaussfilt(image, 5);
    
    % 将原图和模糊后的图像结合
    beautified_face = bsxfun(@times, beautified_face, cast(mask, 'like', image));  % 只保留肤色区域
    result = imblend(image, beautified_face, 0.7, 0.3);  % 加权合成原图和美化图
    
    beautified_image = result;
end

%% 图像加权合成函数
function result = imblend(image1, image2, alpha, beta)
    % 对两张图像进行加权合成
    result = uint8(alpha * double(image1) + beta * double(image2));
end

<br><img alt="skin_extracted.png" src="\technology\collegeproject\数字图像处理\数字图像处理期中考试_files\skin_extracted.png"><img alt="beautified_face.png" src="\technology\collegeproject\数字图像处理\数字图像处理期中考试_files\beautified_face.png">]]></description><link>technology\collegeproject\数字图像处理\数字图像处理期中考试.html</link><guid isPermaLink="false">Technology/CollegeProject/数字图像处理/数字图像处理期中考试.md</guid><pubDate>Wed, 11 Dec 2024 08:49:47 GMT</pubDate><enclosure url="technology\collegeproject\数字图像处理\数字图像处理期中考试_files\snowy_night_white_snowflakes.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;technology\collegeproject\数字图像处理\数字图像处理期中考试_files\snowy_night_white_snowflakes.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[模板和语法]]></title><description><![CDATA[ 
 <br><br><br>#include&lt;bits/stdc++.h&gt;
using namespace std;
#define int long long
signed main(){
	ios::sync_with_stdio(false);
	return 0;
}
<br><br>struct Cost{
	int p;
	int s;
	friend ostream&amp; operator &lt;&lt;(ostream &amp;out,const Cost &amp;c){
		out&lt;&lt;c.p&lt;&lt;' '&lt;&lt;c.s;
		return out;
	}
	friend bool operator &lt;(const Cost&amp;a,const Cost&amp;b){
		return a.p+a.s&lt;b.p+b.s;
	}
};

<br><br>template&lt;typename T&gt;
void output(vector&lt;T&gt;&amp; cost){
	for(int i=0;i&lt;cost.size();i++){
		cout&lt;&lt;cost[i]&lt;&lt;endl;	
	}
}
<br><br>priority_queue&lt;int&gt; maxHeap;//大根堆
priority_queue&lt;int, std::vector&lt;int&gt;, std::greater&lt;int&gt;&gt; minHeap;//小根堆
// 自定义比较函数
struct CustomCompare {
    bool operator&gt;(const int&amp; lhs, const int&amp; rhs) {
        return lhs &gt; rhs; // 实现小根堆
    }
};
priority_queue&lt;int, std::vector&lt;int&gt;, CustomCompare&gt; customHeap;
<br><br>v1.insert(v1.end(),v2.begin(),v2.end());
<br><br>vector&lt;int&gt; alls; 
sort(alls.begin(), alls.end()); // 将所有值排序，因unique只能移除相邻重复值
alls.erase(unique(alls.begin(), alls.end()), alls.end());   // 去掉重复元素
<br><br>在标准的 multimap 中，排序是基于键的，而不是值的。<br>//遍历的两种方式
for(multimap&lt;int,Edge&gt;::iterator it=G.begin(); it!=G.end(); it++)
		cout&lt;&lt;it-&gt;first&lt;&lt;"-&gt;"&lt;&lt;it-&gt;second.ev&lt;&lt;": "&lt;&lt;it-&gt;second.cost&lt;&lt;endl;
for (const auto&amp; [key, value] : G) {
        std::cout &lt;&lt; "Key: " &lt;&lt; key &lt;&lt; " Value: " &lt;&lt; value &lt;&lt; std::endl;
    }
//插入,默认按键升序
G.insert(std::pair&lt;int, Edge&gt;(sv, e));
//自定义比较函数
// 自定义比较函数，用于按键降序排序
struct CustomCompare {
    bool operator()(const int&amp; lhs, const int&amp; rhs) const {
        return lhs &gt; rhs; // 降序排列
    }
};
multimap&lt;int, Edge, CustomCompare&gt; G;
<br><br>vector, 变长数组，倍增的思想
    size()  返回元素个数
    empty()  返回是否为空
    clear()  清空
    front()/back()
    push_back()/pop_back()
    begin()/end()
    []
    支持比较运算，按字典序

pair&lt;int, int&gt;
    first, 第一个元素
    second, 第二个元素
    支持比较运算，以first为第一关键字，以second为第二关键字（字典序）

string，字符串
    size()/length()  返回字符串长度
    empty()
    clear()
    substr(起始下标，(子串长度))  返回子串
    c_str()  返回字符串所在字符数组的起始地址

queue, 队列
    size()
    empty()
    push()  向队尾插入一个元素
    front()  返回队头元素
    back()  返回队尾元素
    pop()  弹出队头元素

priority_queue, 优先队列，默认是大根堆
    size()
    empty()
    push()  插入一个元素
    top()  返回堆顶元素
    pop()  弹出堆顶元素
    定义成小根堆的方式：priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; q;

stack, 栈
    size()
    empty()
    push()  向栈顶插入一个元素
    top()  返回栈顶元素
    pop()  弹出栈顶元素

deque, 双端队列
    size()
    empty()
    clear()
    front()/back()
    push_back()/pop_back()
    push_front()/pop_front()
    begin()/end()
    []

set, map, multiset, multimap, 基于平衡二叉树（红黑树），动态维护有序序列
    size()
    empty()
    clear()
    begin()/end()
    ++, -- 返回前驱和后继，时间复杂度 O(logn)

    set/multiset
        insert()  插入一个数
        find()  查找一个数
        count()  返回某一个数的个数
        erase()
            (1) 输入是一个数x，删除所有x   O(k + logn)
            (2) 输入一个迭代器，删除这个迭代器
        lower_bound()/upper_bound()
            lower_bound(x)  返回大于等于x的最小的数的迭代器
            upper_bound(x)  返回大于x的最小的数的迭代器
    map/multimap
        insert()  插入的数是一个pair
        erase()  输入的参数是pair或者迭代器
        find()
        []  注意multimap不支持此操作。 时间复杂度是 O(logn)
        lower_bound()/upper_bound()

unordered_set, unordered_map, unordered_multiset, unordered_multimap, 哈希表
    和上面类似，增删改查的时间复杂度是 O(1)
    不支持 lower_bound()/upper_bound()， 迭代器的++，--

bitset, 圧位
    bitset&lt;10000&gt; s;
    ~, &amp;, |, ^
    &gt;&gt;, &lt;&lt;
    ==, !=
    []

    count()  返回有多少个1

    any()  判断是否至少有一个1
    none()  判断是否全为0

    set()  把所有位置成1
    set(k, v)  将第k位变成v
    reset()  把所有位变成0
    flip()  等价于~
    flip(k) 把第k位取反

<br><br><br>void quick_sort(int q[], int l, int r)
{
    if (l &gt;= r) return;

    int i = l - 1, j = r + 1, x = q[l + r &gt;&gt; 1];
    while (i &lt; j)
    {
        do i ++ ; while (q[i] &lt; x);
        do j -- ; while (q[j] &gt; x);
        if (i &lt; j) swap(q[i], q[j]);
    }
    quick_sort(q, l, j), quick_sort(q, j + 1, r);
}
<br><br>void merge_sort(int q[], int l, int r)
{
    if (l &gt;= r) return;

    int mid = l + r &gt;&gt; 1;
    merge_sort(q, l, mid);
    merge_sort(q, mid + 1, r);

    int k = 0, i = l, j = mid + 1;
    while (i &lt;= mid &amp;&amp; j &lt;= r)
        if (q[i] &lt;= q[j]) tmp[k ++ ] = q[i ++ ];
        else tmp[k ++ ] = q[j ++ ];

    while (i &lt;= mid) tmp[k ++ ] = q[i ++ ];
    while (j &lt;= r) tmp[k ++ ] = q[j ++ ];

    for (i = l, j = 0; i &lt;= r; i ++, j ++ ) q[i] = tmp[j];
}

<br><br>bool check(int x) {/* ... */} // 检查x是否满足某种性质

// 区间[l, r]被划分成[l, mid]和[mid + 1, r]时使用：
int bsearch_1(int l, int r)
{
    while (l &lt; r)
    {
        int mid = l + r &gt;&gt; 1;
        if (check(mid)) r = mid;    // check()判断mid是否满足性质
        else l = mid + 1;
    }
    return l;
}
// 区间[l, r]被划分成[l, mid - 1]和[mid, r]时使用：
int bsearch_2(int l, int r)
{
    while (l &lt; r)
    {
        int mid = l + r + 1 &gt;&gt; 1;
        if (check(mid)) l = mid;
        else r = mid - 1;
    }
    return l;
}
<br><br>// C = A + B, A &gt;= 0, B &gt;= 0
vector&lt;int&gt; add(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B)
{
    if (A.size() &lt; B.size()) return add(B, A);

    vector&lt;int&gt; C;
    int t = 0;
    for (int i = 0; i &lt; A.size(); i ++ )
    {
        t += A[i];
        if (i &lt; B.size()) t += B[i];
        C.push_back(t % 10);
        t /= 10;
    }

    if (t) C.push_back(t);
    return C;
}
<br><br>// C = A - B, 满足A &gt;= B, A &gt;= 0, B &gt;= 0
vector&lt;int&gt; sub(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B)
{
    vector&lt;int&gt; C;
    for (int i = 0, t = 0; i &lt; A.size(); i ++ )
    {
        t = A[i] - t;
        if (i &lt; B.size()) t -= B[i];
        C.push_back((t + 10) % 10);
        if (t &lt; 0) t = 1;
        else t = 0;
    }
    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();
    return C;
}
<br><br>// C = A * b, A &gt;= 0, b &gt;= 0
vector&lt;int&gt; mul(vector&lt;int&gt; &amp;A, int b)
{
    vector&lt;int&gt; C;

    int t = 0;
    for (int i = 0; i &lt; A.size() || t; i ++ )
    {
        if (i &lt; A.size()) t += A[i] * b;
        C.push_back(t % 10);
        t /= 10;
    }
    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();
    return C;
}

<br><br>// A / b = C ... r, A &gt;= 0, b &gt; 0
vector&lt;int&gt; div(vector&lt;int&gt; &amp;A, int b, int &amp;r)
{
    vector&lt;int&gt; C;
    r = 0;
    for (int i = A.size() - 1; i &gt;= 0; i -- )
    {
        r = r * 10 + A[i];
        C.push_back(r / b);
        r %= b;
    }
    reverse(C.begin(), C.end());
    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();
    return C;
}
<br><br>S[i] = a[1] + a[2] + ... a[i]
a[l] + ... + a[r] = S[r] - S[l - 1]
<br><br>S[i, j] = 第i行j列格子左上部分所有元素的和
以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵的和为：
S[x2, y2] - S[x1 - 1, y2] - S[x2, y1 - 1] + S[x1 - 1, y1 - 1]
<br><br>给区间[l, r]中的每个数加上c：B[l] += c, B[r + 1] -= c
<br><br>给以(x1, y1)为左上角，(x2, y2)为右下角的子矩阵中的所有元素加上c：
S[x1, y1] += c, S[x2 + 1, y1] -= c, S[x1, y2 + 1] -= c, S[x2 + 1, y2 + 1] += c
<br><br>for (int i = 0, j = 0; i &lt; n; i ++ )
{
    while (j &lt; i &amp;&amp; check(i, j)) j ++ ;

    // 具体问题的逻辑
}
常见问题分类：
    (1) 对于一个序列，用两个指针维护一段区间
    (2) 对于两个序列，维护某种次序，比如归并排序中合并两个有序序列的操作
<br><br>求n的第k位数字: n &gt;&gt; k &amp; 1
返回n的最后一位1：lowbit(n) = n &amp; -n
<br><br>常见模型：找出滑动窗口中的最大值/最小值
int hh = 0, tt = -1;
for (int i = 0; i &lt; n; i ++ )
{
    while (hh &lt;= tt &amp;&amp; check_out(q[hh])) hh ++ ;  // 判断队头是否滑出窗口
    while (hh &lt;= tt &amp;&amp; check(q[tt], i)) tt -- ;
    q[ ++ tt] = i;
}
<br><br>常见模型：找出每个数左边离它最近的比它大/小的数
int tt = 0;
for (int i = 1; i &lt;= n; i ++ )
{
    while (tt &amp;&amp; check(stk[tt], i)) tt -- ;
    stk[ ++ tt] = i;
}
<br><br> int p[N], size[N];
//p[]存储每个点的祖宗节点, size[]只有祖宗节点的有意义，表示祖宗节点所在集合中的点的数量

// 返回x的祖宗节点
int find(int x)
{
	if (p[x] != x) p[x] = find(p[x]);
	return p[x];
}

// 初始化，假定节点编号是1~n
for (int i = 1; i &lt;= n; i ++ )
{
	p[i] = i;
	size[i] = 1;
}

// 合并a和b所在的两个集合：
size[find(b)] += size[find(a)];
p[find(a)] = find(b);
<br><br>DFS（int x, int y） //这里假设存的是二维数组，x、y表示两个坐标
{
     if (找到解)
     {
     }
      for (......)
 //每到一个点下一步都有上下左右四个方向可以走，这里用一个循环遍历方向数组表示四个方向
        {
            // 如果这个点(a,b)符合要求并且没走过
            flag[a][b] = 1; //标记‘1’表示走过
            DFS(a, b);      //进入下一次递归
            flag[a][b] = 0; //回溯，标记‘0’表示可以走
        }
}
<br><br>BFS()
{
       queue&lt;int&gt; q;//初始化队列Q 
       while(!q.empty())  //队列不为空
       {
               if() //判断是否找到了目标
               {
               
               }
               //队首出队
               for()
               {
                       //依旧是四个方向
                       //符合条件的入队
                       //标记入队的点
               }
       }
}
<br><br>时间复杂度 O(mlogn), n 表示点数，m 表示边数<br>typedef pair&lt;int, int&gt; PII;

int n;      // 点的数量
int h[N], w[N], e[N], ne[N], idx;       // 邻接表存储所有边
int dist[N];        // 存储所有点到1号点的距离
bool st[N];     // 存储每个点的最短距离是否已确定

// 求1号点到n号点的最短距离，如果不存在，则返回-1
int dijkstra()
{
    memset(dist, 0x3f, sizeof dist);
    dist[1] = 0;
    priority_queue&lt;PII, vector&lt;PII&gt;, greater&lt;PII&gt;&gt; heap;
    heap.push({0, 1});      // first存储距离，second存储节点编号

    while (heap.size())
    {
        auto t = heap.top();
        heap.pop();

        int ver = t.second, distance = t.first;

        if (st[ver]) continue;
        st[ver] = true;

        for (int i = h[ver]; i != -1; i = ne[i])
        {
            int j = e[i];
            if (dist[j] &gt; distance + w[i])
            {
                dist[j] = distance + w[i];
                heap.push({dist[j], j});
            }
        }
    }
    if (dist[n] == 0x3f3f3f3f) return -1;
    return dist[n];
}
<br><br>// 此处为查询区间和的树状数组。
int bit[500010];
void add(int k, int x) {
	while (k &lt;= n) {
		bit[k] += x;
		k += lowbit(k);
	}
}//add 函数用于在位置 k 处增加值 x，并更新树状数组。
int lowbit(int x) {
	return x &amp; -x;
}
int ask(int k) {
	int res = 0;
	while (k) {
		res += bit[k];
		k -= lowbit(k);
	}
	return res;
}//ask 函数用于查询从数组开始到位置 k 的前缀和。

<br><br><br>
走头无路的浩渡波来到了澳门，身无分文的他在街边捡到了一元硬币。于是他兴起走进了一个馆子玩玩“游戏”。<br>
这个“公平的游戏“，规则是这样的，抛出一枚公平的硬币，有一半的概率投到正面，那么浩渡波获得一元硬币。还有另一半概率投到反面，浩渡波就会失去一元硬币。当他把硬币输光时，游戏提前结束。现在要你计算一下经过n轮（包括n轮前就输光），最后有多大的概率血本无归，并以此对他提出建议。（由于结果为小数，因此输出硬币的期望数量乘上2的n次方。请给出答案模上100007的余数。）
<br>输入格式<br>
一个整数n，表示玩了至多n轮。<br>输出格式<br>
一个整数，表示期望硬币数。<br>链接<br>
<a rel="noopener nofollow" class="external-link" href="https://vijos.org/d/nnu_contest/contest/663757386e9552d60cf9b19b/1583" target="_blank">https://vijos.org/d/nnu_contest/contest/663757386e9552d60cf9b19b/1583</a><br><br>图示：<br>		1               times=0     p=0
	0       2           times=1     p=1/2
		1       3       times=2     p=1/2
	0      2 2      4   times=3     p=1/2+1/4
<br>观察可知，这个问题的结构类似二叉树。假设当前节点为n,左子树就是n-1,右子树就是n+1。<br>
我们可构造基础的迭代式子，如下：<br>
约束条件：<br><br><br>其中deepth和times分别是树的深度和赌局次数。<br>得到以下代码：<br><br>def f(n,deepth,times):
    if deepth&gt;times:
        return 0
    deepth+=1
    if n==0:
        return 1
    return 1/2*f(n-1,deepth,times)+1/2*f(n+1,deepth,times)


def main():
    n =int(input())
    a=f(1,0,n)
    a=int(a*2**n)
    a=a%100007
    print(a)
if __name__=="__main__":
    main()
<br><br>
由于f(n)=f(n-1)+f(n+1),所以dp无论从左到右还是从右到左都不行。所以可以考虑二维dp。<br>
考虑一个二维dp数组，dp[i][j]表示，第i轮时手里有j个硬币的期望。那么最后dp[n][0]即表示第n轮中亏空的期望。dp[0][1]则表示没开始是手里有1元的概率，即初始节点，显然为1。注意这里的期望为累加期望，即dp[3][0]是3/4，不是1/4。<br>
那么迭代的方程我们可以将原本的f(n)=1/2f(n-1)+1/2f(n+1)反过来想，递归思想是大问题分成小问题，递推则是小问题组成大问题，对于第i轮手中有j块钱的情况，他只能由第i-1轮的j-1和j+1得到，分别对应第j局赌局的输赢两种情况。所以迭代方程<br>
dp[i][j]=dp[i-1][j-1]+dp[i-1][j+1](这里不加1/2是因为题目要乘2的n次取模，而乘2的n次取模就是将二叉树最底层的权重看做1，往上一层乘以二。)<br>
对于没有j-1的0和1，则单独处理，将0看成往下分出两个0。而j迭代到i+1是因为最右边的值一定是树的深度+1。且由于最右边的j+1是存在的且一定为0，所以不需要考虑越界问题。
<br>#include &lt;iostream&gt;
#define maxn 1024 
using namespace std; 
int p=100007; 
int dp[maxn][maxn]={0}; 
int main () 
{ 
	dp[0][1]=1; int n; cin&gt;&gt;n;
	for (int i=1;i&lt;=n;i++)
	{ 
		dp[i][0]=(dp[i-1][1]+dp[i-1][0]*2)%p; 
		dp[i][1]=dp[i-1][2]%p; 
		for (int j=2;j&lt;=i+1;j++)
		{ 
			dp[i][j]=(dp[i-1][j-1]+dp[i-1][j+1])%p;
		} 
	}
	cout&lt;&lt;dp[n][0];
	return 0;
}
<br><br><br>bool is_prime(int x)
{
    if (x &lt; 2) return false;
    for (int i = 2; i &lt;= x / i; i ++ )
        if (x % i == 0)
            return false;
    return true;
}
<br><br>int primes[N], cnt;     // primes[]存储所有素数
bool st[N];         // st[x]存储x是否被筛掉

void get_primes(int n)
{
    for (int i = 2; i &lt;= n; i ++ )
    {
        if (st[i]) continue;
        primes[cnt ++ ] = i;
        for (int j = i + i; j &lt;= n; j += i)
            st[j] = true;
    }
}
<br><br>vector&lt;int&gt; get_divisors(int x)
{
    vector&lt;int&gt; res;
    for (int i = 1; i &lt;= x / i; i ++ )
        if (x % i == 0)
        {
            res.push_back(i);
            if (i != x / i) res.push_back(x / i);
        }
    sort(res.begin(), res.end());
    return res;
}
<br><br>求 m^k mod p，时间复杂度 O(logk)。

int qmi(int m, int k, int p)
{
    int res = 1 % p, t = m;
    while (k)
    {
        if (k&amp;1) res = res * t % p;
        t = t * t % p;
        k &gt;&gt;= 1;
    }
    return res;
}
<br><br>int pow(int x,int y,int p){ //快速幂
	int res=1;
	x%=p;
	for(;b;b&gt;&gt;=1,a=a*a%p) if(b&amp;1) res=res*a%p;
    return res;
}

int inv(int x,int p){ //求逆元
	return pow(x,p-2);
}
int C(int n,int m){
	fac[0]=1;
	for(int i=1;i&lt;=n;i++)
		fac[i]=fac[i-1]*i; //预处理出阶乘
	return ((fac[n]*inv(fac[m],p))%p*inv(fac[n-m],p))%p;
}
<br><br>int gcd(int a, int b) {
	while (b != 0) {
		int tmp = a;
		a = b;
		b = tmp % b;
	}
	return a;
}
int lcm(int a,int b){
	return a*b/gcd(a,b);
}
]]></description><link>technology\collegeproject\算法设计\模板和语法.html</link><guid isPermaLink="false">Technology/CollegeProject/算法设计/模板和语法.md</guid><pubDate>Sun, 14 Jul 2024 02:03:58 GMT</pubDate></item><item><title><![CDATA[1. Record]]></title><description><![CDATA[<a class="tag" href="?query=tag:CollegeProjectNotes" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#CollegeProjectNotes</a> 
 <br><a href=".?query=tag:CollegeProjectNotes" class="tag" target="_blank" rel="noopener nofollow">#CollegeProjectNotes</a> <br><br><br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1873/problem/E" target="_blank">https://codeforces.com/contest/1873/problem/E</a><br>
题意：想象有一个二维平面，现在有一个数列，每一个数表示平面对应列的高度，现在要给这个平面在两边加上护栏，问护栏最高可以设置为多高，可以使得在完全填满的情况下，使用的水量不会超过给定的用水量。已知最大用水量为k
思路：对于一个护栏高度，水池高度低于护栏高度的地方都需要被水填满。为了便于分析，我们可以将水池高度进行排序。那么就会很显然的一个二分题目了，我们需要二分的就是护栏的高度（最小为1，最大需要考虑一下，就是只有一列的情况下，最大高度就是最高水池高度 ），check的条件就是当前h的护栏高度时，消耗的水量与最大用水量之间的大小关系，如果超过了，那么高度就要下降，反之可以上升。由于是求最大高度，因此要使用的是求右边界的二分板子
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

typedef long long ll;

void solve()
{
	int n, w;
	cin &gt;&gt; n &gt;&gt; w;
	vector&lt;ll&gt; a(n);
	
	for (int i = 0; i &lt; n; i ++)
		cin &gt;&gt; a[i];
	
	sort(a.begin(), a.end());
	
	ll l = 0, r = 2e9 + 1;
	while (l &lt; r)
	{
		ll h = (l + r + 1) &gt;&gt; 1;
		
		ll t = 0;
		for (int i = 0; i &lt; n; i ++)
			if (a[i] &lt; h)
				t += h - a[i];
			else break;
		
		if (t &lt;= w) l = h;
		else r = h - 1;
	}
	cout &lt;&lt; r &lt;&lt; endl;
}

int main()
{
	int T; cin &gt;&gt; T;
	while (T --) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.lanqiao.cn/problems/5129/learning/" target="_blank">https://www.lanqiao.cn/problems/5129/learning/</a><br>
题意：给定一个序列，现在需要将这个数列分为k组，如何分组可以使得每一组的极差中，最大值最小
最开始想到的思路：
很容易联想到的一种方法其实就是高中组合数学中学到的“隔板法”，现在有n个数，需要分成k组，则方案数就是在n-1个空档中插入k-1个隔板，即  种方案
时间复杂度 
优化思路：
上述思路是正向思维，即对于构思分组情况计算极差。我们不妨逆向思维，即枚举极差的情况，判断此时的分组情况。如果对于当前的极差lim，我们显然可以分成n组，即有一个最大分组值；我们也可以求一个最小分组值cnt，即如果再少分一组那么此时的极差就会超过当前约束的极差值lim。因此对于当前约束的极差值lim，我们可以求一个最小分组值cnt

<br>如果当前的最小分组值cnt &gt; k，那么  就无法包含k，也就是说当前约束的极差lim不符合条件，lim偏小
<br>如果当前的最小分组值cnt &lt;= k，那么  就一定包含k，且当前分组的最小极差一定是 &lt;= 约束的极差值lim，lim偏大

于是二分极差的思路就跃然纸上了。我们二分极差，然后根据可以分组的最小数量cnt判断二分的结果进行左右约束调整即可。
时间复杂度 
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;


bool check(int lim, vector&lt;int&gt;&amp; a, int n, int k) {
    int cnt = 1; // 当前可以分的最小组数
    int pre = a[0];
    for (int i = 0; i &lt; n; i++) {
        if (a[i] - pre &gt; lim) {
            pre = a[i];
            cnt++;
        }
    }
    return cnt &lt;= k;
}


void solve() {
    int n, k;
    cin &gt;&gt; n &gt;&gt; k;

    vector&lt;int&gt; a(n);
    for (int i = 0; i &lt; n; i++) {
        cin &gt;&gt; a[i];
    }

    sort(a.begin(), a.begin() + n);

    int l = 0, r = a[n - 1] - a[0];
    while (l &lt; r) {
        int mid = (l + r) &gt;&gt; 1;
        if (check(mid, a, n, k)) {
            // 分的最小组数 &lt;= k，则当前极差大了
            r = mid;
        } else {
            // 分的最小组数 &gt;  k，则当前极差小了
            l = mid + 1;
        }
    }

    cout &lt;&lt; r &lt;&lt; "\n";
}


int main() {
    ios::sync_with_stdio(false);
    cin.tie(0), cout.tie(0);
    int T = 1;
    // cin &gt;&gt; T;
    while (T--) {
        solve();
    }    
    return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P2440" target="_blank">https://www.luogu.com.cn/problem/P2440</a><br>
题意：给定一个序列，现在需要将这个序列切分为等长的 k 段，长度必须为整数且尽可能的长，如果无法切分可以将多余的长度丢弃，问最长的长度是多少
思路：可以发现切分长度与切分的段数具有单调性，可以进行二分。二分的思路就是直接二分答案，根据长度判断可切得的段数，最终套右边界的模板找到最大的长度即可。需要注意的是，对于无法切割的情况，就是需要切出的段数 k 超过了序列之和
时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;
#define int long long 
using namespace std;

const int N = 1e5 + 10;

int n, k;
int a[N];

bool chk(int x) {
	int sum = 0;
	for (int i = 0; i &lt; n; i++)
		sum += a[i] / x;
	return sum &gt;= k;
}

void solve() {
	cin &gt;&gt; n &gt;&gt; k;
	
	int sum = 0;
	for (int i = 0; i &lt; n; i++) {
		cin &gt;&gt; a[i];
		sum += a[i];
	}
	
	int l = 1, r = 1e8;
	while (l &lt; r) {
		int mid = (l + r + 1) &gt;&gt; 1;
		if (chk(mid)) l = mid;
		else r = mid - 1;
	}
	
	if (k &gt; sum) cout &lt;&lt; "0\n";
	else cout &lt;&lt; r &lt;&lt; "\n";	
} 

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();	
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P2678" target="_blank">https://www.luogu.com.cn/problem/P2678</a><br>
题意：给定一个一维递增的不重复序列数，现在可以从其中拿去若干个数字，使得相邻数字之间的最小差值最大，问最大的最小差值是多少
思路：可以发现拿的数字越多，最小差值就越大，具有单调性，可以二分。我们直接二分答案，即直接二分最小差值的具体数值，通过判断当前的最小差值至少需要拿掉多少个数才能满足，进行 check 操作。至于如何计算至少要拿掉的数字，我们采用右贪心准则，即检查当前点与上一个点之间的距离是否满足最小差值的要求，如果不满足就需要记数，为了便于后续的计算，直接将当前的下标用上一个点的下标覆盖掉即可
时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;
#define int long long 
using namespace std;

const int N = 5e4 + 10;

int lim, n, k;
int a[N], b[N];
bool del[N];

bool ok(int x) {
	int cnt = 0;
	memset(del, false, sizeof del);
	
	for (int i = 1; i &lt;= n; i++) {
		b[i] = a[i];
	}
	
	for (int i = 1; i &lt;= n; i++) {
		if (b[i] - b[i - 1] &lt; x) {
			del[i] = true;
			b[i] = b[i - 1];
			cnt++;
		}
	}
	
	if (lim - b[n] &lt; x) {
		cnt++;
	}
	
	return cnt &lt;= k;
}

void solve() {
	cin &gt;&gt; lim &gt;&gt; n &gt;&gt; k;
	for (int i = 1; i &lt;= n; i++)
		cin &gt;&gt; a[i];
	
	int l = 1, r = lim;
	while (l &lt; r) {
		int mid = (l + r + 1) &gt;&gt; 1;
		if (ok(mid)) l = mid;
		else r = mid - 1;
	}
	
	cout &lt;&lt; r &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();	
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P3853" target="_blank">https://www.luogu.com.cn/problem/P3853</a><br>
题意：与第四题题面几乎一致，只是现在不是从序列中拿走数字，而是往序列中插入数字（插入数字后要保证序列仍然没有重复数且递增），问在插入一定数量数字的情况下，最小的最大差值是多少
思路：同样可以发现，插入的数字越多，最大差值就越小，具有单调性，可以二分。我们依然直接二分答案，即直接二分最大差值的具体数值，通过判断当前的最大差值需要插入多少个数来检查当前状态是否合理。需要插入的数字的个数为：

时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;
#define int long long 
using namespace std;

const int N = 1e6;

int lim, n, k;
int a[N];

bool chk(int x) {
	int cnt = 0;
	for (int i = 1; i &lt; n; i++) {
		int gap = a[i] - a[i - 1];
		if (gap &gt; x) {
			cnt += (gap + x - 1) / x - 1;
		}
	}
	return cnt &gt; k;
}

void solve() {
	cin &gt;&gt; lim &gt;&gt; n &gt;&gt; k;
	for (int i = 0; i &lt; n; i++) {
		cin &gt;&gt; a[i];
	}
	
	int l = 1, r = lim;
	while (l &lt; r) {
		int mid = (l + r) &gt;&gt; 1;
		if (chk(mid)) l = mid + 1;
		else r = mid;
	}
	
	cout &lt;&lt; r &lt;&lt; "\n";
} 

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();	
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1182" target="_blank">https://www.luogu.com.cn/problem/P1182</a><br>
题意：给定一个无序的序列，现在需要将这个序列进行分段（连续的），分成指定的段数。问应该如何分段可以使得所有段的分段和的最大值最小
思路：可以发现，分的段数越多，所有分段和的最大值就越小，具有单调性，可以二分。我们直接二分答案，即直接二分分段最大值，通过判断当前最大值的约束条件下可以分的组数进行判断。至于如何计算当前最大值条件下可分得的组数，直接线性扫描进行局部求和即可
时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;
#define int long long 
using namespace std;

const int N = 1e5 + 10;

int n, k;
int a[N];

// 当前分组时最大子段和为 x 
bool chk(int x) {
	int cnt = 0;
	for (int i = 0, s = 0; i &lt; n; i++) {
		if (a[i] &gt; x) return true;
		
		if (s + a[i] &lt;= x) s += a[i];
		else {
			cnt++;
			s = a[i];
		}
	}
	cnt += 1;
	
	return cnt &gt; k;
}

void solve() {
	cin &gt;&gt; n &gt;&gt; k;
	for (int i = 0; i &lt; n; i++) {
		cin &gt;&gt; a[i];
	}
	
	int l = 0, r = 1e9;
	while (l &lt; r) {
		int mid = (l + r) &gt;&gt; 1;
		if (chk(mid)) l = mid + 1;
		else r = mid;
	}
	
	cout &lt;&lt; r &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();	
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/832/" target="_blank">https://www.acwing.com/problem/content/832/</a><br>
题意：对于一个序列中的每一个元素，寻找每一个元素前面第一个比他小的元素
思路：

<br>首先很容易想到一个暴力的做法，就是对于每一个数，再从  进行枚举寻找第一个比当前数小的那个数
<br>时间复杂度：

优化：首先每一个数一定是要遍历到的，那么关键在于如何优化掉寻找前面的最近的比他小的数的计算过程。我们逆向思考一下，不要考虑当前数字 a[i] 前面最近的一个比他小的数字我们考虑当前数字如何才能成为后面数字的最近的最小值。
我们将这个序列想象成一个散点图

<br>
如果当前数字能够成为后面的最近的最小值，那么当前数字就一定严格小于后面的数字。保留当前的散点

<br>
那么与上面相反的是，如果 a[i]&gt;=后面的数字 那么当前数字就一定不可能成为后面数字的最近的比他小的数字，就需要不断删除当前数以及前面的数，直到第一次寻找到比当前数小的那个数。


经过上述流程之后，我们发现，此时的“散点图”上剩下来的点，呈现一个严格单调递增的形状。于是优化的思路就来了：
我们只需要在扫描到 a[i] 的时候，维护 a[0] 到 a[i-1] 中的单调递增的序列即可，算法思路就是：
如果当前数 &gt;   容器中的最后一个数，那么当前数的最近的那个数就是容器中的最后一个数
如果当前数 &lt;= 容器中的最后一个数，那么就需要不断删除容器中的最后一个数，直到最后一个数 &lt; 当前数，那么当前容器中的最后一个数就是当前数最近的那个比他小的数
最后将当前数加入容器尾部即可维护一个单调递增序列了。
至于选用什么样的容器，支持高效率查询尾部元素、高效率尾插入、高效率尾删除，即可。那么数组、栈、队列等很多线性结构的容器都是可以的。我们这里选用数组。
时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

int main() {
    ios::sync_with_stdio(false);
    cin.tie(nullptr), cout.tie(nullptr);
    
    int n; cin &gt;&gt; n;
    vector&lt;int&gt; a(n + 1);
    for (int i = 0; i &lt; n; i++) {
        cin &gt;&gt; a[i];
    }
    
    vector&lt;int&gt; v;
    
    for (int i = 0; i &lt; n; i++) {
        if (v.empty()) {
            cout &lt;&lt; -1 &lt;&lt; " ";
            v.push_back(a[i]);
        } 
        else {
            while (!v.empty() &amp;&amp; a[i] &lt;= v.back()) {
                v.pop_back();
            }
            if (v.empty()) {
                cout &lt;&lt; -1 &lt;&lt; " ";
            } else {
                cout &lt;&lt; v.back() &lt;&lt; " ";
            }
            v.push_back(a[i]);
        }
    }
    
    return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P3379" target="_blank">https://www.luogu.com.cn/problem/P3379</a><br>
题意：寻找树中指定两个结点的最近公共祖先
思路：对于每次查询，我们可以从指定的两个结点开始往上跳，第一个公共结点就是目标的LCA，每一次询问的时间复杂度均为 ，为了加速查询，我们可以采用倍增法，预处理出往上跳的结果，即 fa[i][j] 数组，表示  号点向上跳  步后到达的结点。接下来在往上跳跃的过程中，利用二进制拼凑的思路，即可在  的时间内查询到LCA。
预处理：可以发现，对于 fa[i][j]，我们可以通过递推的方式获得，即 fa[i][j] = fa[fa[i][j-1]][j-1]，当前结点向上跳跃  步可以拆分为先向上  步，在此基础之上再向上  步。于是我们可以采用宽搜  深搜的顺序维护  数组。
跳跃：我们首先需要将两个结点按照倍增的思路向上跳到同一个深度，接下来两个结点同时按照倍增的思路向上跳跃，为了确保求出最近的，我们需要确保在跳跃的步调一致的情况下，两者的祖先始终不相同，那么倍增结束后，两者的父结点就是最近公共祖先，即 fa[x][k] 或 fa[y][k]
时间复杂度： 

<br> 为预处理每一个结点向上跳跃抵达的情况
<br> 为  次询问的情况

<br>const int N = 5e5 + 10;

int n, Q, root;
vector&lt;int&gt; G[N];
int fa[N][20], dep[N];
queue&lt;int&gt; q;

void init() {
	dep[root] = 1;
	q.push(root);

	while (q.size()) {
		int now = q.front();
		q.pop();
		for (int ch: G[now]) {
			if (!dep[ch]) {
				dep[ch] = dep[now] + 1;
				fa[ch][0] = now;
				for (int k = 1; k &lt;= 19; k++) {
					fa[ch][k] = fa[ fa[ch][k-1] ][k-1];
				}
				q.push(ch);
			}
		}
	}
}

int lca(int a, int b) {
	if (dep[a] &lt; dep[b]) swap(a, b);

	for (int k = 19; k &gt;= 0; k--)
		if (dep[fa[a][k]] &gt;= dep[b])
			a = fa[a][k];

	if (a == b) return a;

	for (int k = 19; k &gt;= 0; k--)
		if (fa[a][k] != fa[b][k])
			a = fa[a][k], b = fa[b][k];

	return fa[a][0];
}

void solve() {
	cin &gt;&gt; n &gt;&gt; Q &gt;&gt; root;
	for (int i = 0; i &lt; n - 1; ++i) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		G[a].push_back(b);
		G[b].push_back(a);
	}

	init();

	while (Q--) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		cout &lt;&lt; lca(a, b) &lt;&lt; "\n";
	}
}	
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P5836" target="_blank">https://www.luogu.com.cn/problem/P5836</a><br>
tag：并查集
题意：给定一棵树，结点被标记成两种，一种是H，一种是G，在每一次查询中，需要知道指定的两个结点之间是否含有某一种标记
思路：对于树上标记，我们可以将相同颜色的分支连成一个连通块

<br>如果查询的两个结点在同一个连通块，则查询两个结点所在的颜色与所需的颜色是否匹配即可
<br>如果查询的两个结点不在同一个连通块，两个结点之间的路径一定是覆盖了两种颜色的标记，则答案一定是1

时间复杂度：
<br>const int N = 100010;

int n, m, p[N];
char col[N];

int find(int x) {
	if (p[x] != x) {
		p[x] = find(p[x]);
	}
	return p[x];
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m;
	cin &gt;&gt; (col + 1);

	for (int i = 1; i &lt;= n; i++) {
		p[i] = i;
	}

	for (int i = 1; i &lt;= n - 1; i++) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		if (col[a] == col[b]) {
			p[find(a)] = find(b);
		}
	}

	string res;

	while (m--) {
		int u, v;
		cin &gt;&gt; u &gt;&gt; v;

		char cow;
		cin &gt;&gt; cow;

		if (find(u) == find(v)) {
			res += to_string(col[u] == cow);
		} else {
			res += '1';
		}
	}

	cout &lt;&lt; res &lt;&lt; "\n";
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/22/" target="_blank">https://www.acwing.com/problem/content/22/</a><br>class Solution {
public:
    int res = 0;
    
    int movingCount(int threshold, int rows, int cols)
    {
        if (!rows || !cols) return 0;
        vector&lt;vector&lt;int&gt;&gt; g(rows, vector&lt;int&gt;(cols, 0));
        vector&lt;vector&lt;bool&gt;&gt; vis(rows, vector&lt;bool&gt;(cols, false));
        dfs(g, vis, 0, 0, threshold);
        return res;
    }
    
    void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; g, vector&lt;vector&lt;bool&gt;&gt;&amp; vis, int x, int y, int threshold)
    {
        vis[x][y] = true;
        res ++;
        
        int dx[] = {-1, 0, 1, 0}, dy[] = {0, 1, 0, -1};
        for (int k = 0; k &lt; 4; k ++)
        {
            int i = x + dx[k], j = y + dy[k];
            if (i &lt; 0 || i &gt;= int(g.size()) || j &lt; 0 || j &gt;= int(g[0].size()) || vis[i][j] || cnt(i, j) &gt; threshold) continue;
            dfs(g, vis, i, j, threshold);
        }
    }
    
    int cnt(int x, int y)
    {
        int sum = 0;
        while (x) sum += x % 10, x /= 10;
        while (y) sum += y % 10, y /= 10;
        return sum;
    }
};
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5168/" target="_blank">https://www.acwing.com/problem/content/5168/</a><br>
搜索逻辑：分为正十字与斜十字
更新答案逻辑：需要进行两个条件的约数，一个是是否匹配到了最后一个字母，一个是转弯次数不超过一次
转弯判断逻辑：
1. 首先不能是起点开始的
2. 对于正十字：如果next的行&amp;列都与pre的行和列不相等，就算转弯
3. 对于斜十字：如果next的行|列有和pre相等的，就算转弯

<br>#include &lt;iostream&gt;
#include &lt;algorithm&gt;
#include &lt;cstring&gt;

using namespace std;

const int N = 110;

string s;
int m, n;
char g[N][N];
int res;

// 正十字，a，b为之前的位置，x，y为当前的位置，now为当前待匹配的字母位，cnt为转弯次数
void dfs1(int a, int b, int x, int y, int now, int cnt)
{
	if (g[x][y] != s[now]) return;
	
	if (now == s.size() - 1)
	{
		if (cnt &lt;= 1) res++; 
		return;
	}
	
	int dx[] = {-1, 0, 1, 0}, dy[] = {0, 1, 0, -1};
	
	for (int k = 0; k &lt; 4; k ++)
	{
		int i = x + dx[k], j = y + dy[k];
		if (x &lt; 0 || x &gt;= m || y &lt; 0 || y &gt;= n) continue;
		
		// 判断是否转弯（now不是起点 且 pre和next行列均不相等） 
		if (a != -1 &amp;&amp; b != -1 &amp;&amp; a != i &amp;&amp; b != j) dfs1(x, y, i, j, now + 1, cnt + 1);
		else dfs1(x, y, i, j, now + 1, cnt);
	}
}

// 斜十字
void dfs2(int a, int b, int x, int y, int now, int cnt)
{
	if (g[x][y] != s[now]) return;
	
	if (now == s.size() - 1)
	{
		if (cnt &lt;= 1) res++; 
		return;
	}
	
	int dx[] = {-1, -1, 1, 1}, dy[] = {-1, 1, 1, -1};
	
	for (int k = 0; k &lt; 4; k ++)
	{
		int i = x + dx[k], j = y + dy[k];
		if (x &lt; 0 || x &gt;= m || y &lt; 0 || y &gt;= n) continue;
		
		// 判断是否转弯（now不是起点 且 不在同一对角线） 
		if (a != -1 &amp;&amp; b != -1 &amp;&amp; (a == i || b == j)) dfs2(x, y, i, j, now + 1, cnt + 1);
		else dfs2(x, y, i, j, now + 1, cnt);
	}
}


int main()
{
	cin &gt;&gt; s;
	cin &gt;&gt; m &gt;&gt; n;
	
	for (int i = 0; i &lt; m; i ++)
		for (int j = 0; j &lt; n; j ++)
			cin &gt;&gt; g[i][j];
	
	for (int i = 0; i &lt; m; i ++)
		for (int j = 0; j &lt; n; j ++)
			dfs1(-1, -1, i, j, 0, 0);
	
	for (int i = 0; i &lt; m; i ++)
		for (int j = 0; j &lt; n; j ++)
			dfs2(-1, -1, i, j, 0, 0);
	
	cout &lt;&lt; res &lt;&lt; "\n";
	
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5150/" target="_blank">https://www.acwing.com/problem/content/5150/</a><br>法一：dfs<br>
题意：给定一个数n，问[1, n]中有多少个数只含有4或7
思路：对于一个数，我们可以构造一个二叉搜数进行搜索，因为每一位只有两种可能，那么从最高位开始搜索。如果当前数超过了n就return，否则就算一个答案
时间复杂度：

<br>#include &lt;iostream&gt;
using namespace std;

#define int long long

int n, res;

void dfs(int x) {
    if (x &gt; n) return;
    
    res ++;
    
    dfs(x * 10 + 4);
    dfs(x * 10 + 7);
}

signed main() {
    cin &gt;&gt; n;
    dfs(4);
    dfs(7);
    cout &lt;&lt; res &lt;&lt; "\n";
    return 0;
}
<br>法二：二进制枚举<br>
题意：给定一个数n，问[1, n]中有多少个数只含有4或7
思路：按照数位进行计算。对于一个x位的数，1到x-1位的情况下所有的数都符合条件，对于一个t位的数，满情况就是  种，所以[1, x - 1]位就一共有  种情况 。对于第x位，采取二进制枚举与原数进行比较，如果小于原数，则答案+1，反之结束循环输出答案即可
<br>#include &lt;iostream&gt;
using namespace std;

int WS(int x) {
	int res = 0;
	while (x) {
		res++;
		x /= 10;
	}
	return res;
}

int calc(int a[], int ws) {
	int res = 0;
	for (int i = ws - 1; i &gt;= 0; i --) {
		res = res * 10 + a[i];
	}
	return res;
}

int main() {
	int n;
	cin &gt;&gt; n;
	
	int ws = WS(n);
	
	int ans = (1 &lt;&lt; ws) - 2;
	
	int a[20] {};
	for (int i = 0; i &lt; (1 &lt;&lt; ws); i ++) {
		for (int j = 0; j &lt; ws; j ++) {
			if ((1 &lt;&lt; j) &amp; i) {
				a[j] = 7;
			} else {
				a[j] = 4;
			}
		}
		if (calc(a, ws) &lt;= n) {
			ans ++;
		} else {
			break;
		}
	}
	
	cout &lt;&lt; ans;
	
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://leetcode.cn/problems/combination-sum/" target="_blank">https://leetcode.cn/problems/combination-sum/</a><br>
题意：给定一个序列，其中的元素没有重复，问如何选取其中的元素，使得选出的数字总和为指定的数字target，选取的数字可以重复
思路：思路比较简答，很容易想到用dfs搜索出所有的组合情况，即对于每一个“结点”，我们直接遍历序列中的元素即可。但是由于题目的限制，即不允许合法的序列经过排序后相等。那么为了解决这个约束，我们可以将最终搜索到的序列排序后进行去重，但是这样的时间复杂度会很高，于是我们从搜索的过程切入。观看这一篇题解<a data-tooltip-position="top" aria-label="https://leetcode.cn/problems/combination-sum/solutions/2363929/39-zu-he-zong-he-hui-su-qing-xi-tu-jie-b-9zx7/" rel="noopener nofollow" class="external-link" href="https://leetcode.cn/problems/combination-sum/solutions/2363929/39-zu-he-zong-he-hui-su-qing-xi-tu-jie-b-9zx7/" target="_blank">防止出现重复序列的启蒙题解</a>，我们提取其中最关键的一个图解
<img alt="subset_sum_i_pruning.png" src="https://pic.leetcode.cn/1690625058-WYmZtD-subset_sum_i_pruning.png" referrerpolicy="no-referrer">
可见3，4和4，3的剩余选项（其中可能包含了答案序列）全部重复，因此我们直接减去这个枝即可。不难发现，我们根据上述优化思想，剪枝的操作可以为：让当前序列开始枚举的下标 idx 从上一层开始的下标 i 开始，于是剪枝就可以实现了。
时间复杂度：??? 

<br>class Solution {
public:
    // 答案数组res，目标数组c，目标总和target，答案数组now，当前总和sum，起始下标idx
    void dfs(vector&lt;vector&lt;int&gt;&gt;&amp; res, vector&lt;int&gt;&amp; c, int target, vector&lt;int&gt;&amp; now, int sum, int idx) {
        if (sum &gt; target) {
            return;
        } else if (sum == target) {
            res.emplace_back(now);
            return;
        }
        for (int i = idx; i &lt; c.size(); i++) {
            now.emplace_back(c[i]);
            dfs(res, c, target, now, sum + c[i], i);
            now.pop_back();
        }
    }

    vector&lt;vector&lt;int&gt;&gt; combinationSum(vector&lt;int&gt;&amp; candidates, int target) {
        vector&lt;vector&lt;int&gt;&gt; res;
        vector&lt;int&gt; now;
        dfs(res, candidates, target, now, 0, 0);
        return res;
    }
};
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5284/" target="_blank">https://www.acwing.com/problem/content/5284/</a><br>
题意：给定一种字符串的构造方式，问构造n次以后的字符串中的第k个字符是什么
思路：由于构造的方法是基于上一种情况的，很容易可以想到一个递归搜索树来解决。只是这道题有好几个坑，故记录一下。

<br>首先说一下搜索的思路：对于当前的状态，我们想要知道第k个位置上的字符，很显然我们可以通过预处理每一种构造状态下的字符串长度得到下一个字符串的长度，于是我们可以在当前的字符串中，通过比对下标与五段字符串长度的大小，来确定是继续递归还是直接输出
<br>特判：可以发现，对于  的情况，我们无法采用相同的结构进行计算，故进行特判，如果当前来到了最初始的字符串状态，我们直接输出相应位置上的字符即可
<br>最后说一下递归终点的设计：与搜索所有的答案情况不同，这道题的答案是唯一的，因此我们在搜索到答案后，可以通过一个 bool 变量作为一个标记，表示已经找到答案了，只需要不断回溯直到回溯结束为止，就不需要再遍历其他的分支了
<br>坑：这道题的坑说实话有点难崩。

<br>首先是一个k的大小，是一定要开 long long 的，我一开始直接全局宏定义 int 为 long long 了
<br>还有一个坑可能是只要我才会犯的，就是字符串按照下标输出字符的时候，是需要 -1 的，闹心的是我有的加了，有的没加，还是debug的时候调出来的
<br>最后一个大坑，属于是引以为戒了。就是这句 len[i] = min(len[i], (int)2e18)，因为我们可以发现，抛开那三个固定长度的字符串来说，每一次新构造出来的字符串长度都是上一个字符串长度  倍，那么构造  次后的字符串长度就是  长度的  倍，那么对于  的取值范围来说，直接存储长度肯定是不可取的。那么如何解决这个问题呢？方法是我们对 len[i] 进行一个约束即可，见代码。最后进行递归比较长度就没问题了。


<br>时间复杂度： - 由于每一个构造的状态我们都是常数级别的比较，因此相当于一个状态的搜索时间复杂度为 ，那么总合就是 

<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

#define int long long

int n, k;
string s = "DKER EPH VOS GOLNJ ER RKH HNG OI RKH UOPMGB CPH VOS FSQVB DLMM VOS QETH SQB";
string t1 = "DKER EPH VOS GOLNJ UKLMH QHNGLNJ A";
string t2 = "AB CPH VOS FSQVB DLMM VOS QHNG A";
string t3 = "AB";

// 记录每一层构造出来的字符串 Si 的长度 len，当前递归的层数 i (i&gt;=1)，对于当前层数需要查询的字符的下标 pos
void dfs(vector&lt;int&gt;&amp; len, int i, int pos, bool&amp; ok) {
	// 已经搜到答案了就不断返回
	if (ok) {
		return;
	}

	// 如果还没有搜到答案，并且已经递归到了最开始的一层，就输出原始字符串相应位置的字符即可
	if (!i) {
		cout &lt;&lt; s[pos - 1];
		return;
	}

	int l1 = t1.size(), l2 = l1 + len[i - 1], l3 = l2 + t2.size(), l4 = l3 + len[i - 1];
	if (pos &lt;= l1) {
		cout &lt;&lt; t1[pos - 1];
		ok = true;
		return;
	} else if (pos &lt;= l2) {
		dfs(len, i - 1, pos - l1, ok);
	} else if (pos &lt;= l3) {
		cout &lt;&lt; t2[pos - l2 - 1];
		ok = true;
		return;
	} else if (pos &lt;= l4) {
		dfs(len, i - 1, pos - l3, ok);
	} else {
		cout &lt;&lt; t3[pos - l4 - 1];
		ok = true;
		return;
	}
}

void solve() {
	cin &gt;&gt; n &gt;&gt; k;

	vector&lt;int&gt; len(n + 10);
	len[0] = s.size();

	for (int i = 1; i &lt;= n; i++) {
		len[i] = 2 * len[i - 1] + t1.size() + t2.size() + t3.size();
		len[i] = min(len[i], (int)2e18); // 点睛之笔...
	}

	// 特判下标越界的情况
	if (k &gt; len[n]) {
		cout &lt;&lt; ".";
		return;
	}

	// 否则开始从第n层开始递归搜索
	bool ok = false;
	dfs(len, n, k, ok);
}

signed main() {
	int T = 1;
	cin &gt;&gt; T;
	while (T--) {
		solve();
	}
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P2420" target="_blank">https://www.luogu.com.cn/problem/P2420</a><br>
题意：给定一棵树，树上每一条边都有一个权值，现在有Q次询问，对于每次询问会给出两个结点编号u，v，需要输出结点u到结点v所经过的路径的所有边权的异或之和
思路：对于每次询问，我们当然可以遍历从根到两个结点的所有边权，然后全部异或计算结果，但是时间复杂度是 ，显然不行，那么有什么优化策略吗？答案是有的。我们可以发现，对于两个结点之间的所有边权，其实就是根到两个结点的边权相异或得到的结果（异或的性质），我们只需要预处理出根结点到所有结点的边权已异或值，后续询问的时候直接  计算即可
时间复杂度：
<br>const int N = 100010;

struct node {
	int id;
	int w;
};

int n, m, f[N];		// f[i] 表示从根结点到 i 号结点的所有边权的异或值
vector&lt;node&gt; G[N];
bool vis[N];

void dfs(int fa) {
	if (!vis[fa]) {
		vis[fa] = true;
		for (auto&amp; ch: G[fa]) {
			f[ch.id] = f[fa] ^ ch.w;
			dfs(ch.id);
		}
	}
}

void solve() {
	cin &gt;&gt; n;

	for (int i = 0; i &lt; n - 1; i++) {
		int a, b, w;
		cin &gt;&gt; a &gt;&gt; b &gt;&gt; w;
		G[a].push_back({b, w});
		G[b].push_back({a, w});
	}

	dfs(1);

	cin &gt;&gt; m;

	while (m--) {
		int u, v;
		cin &gt;&gt; u &gt;&gt; v;
		cout &lt;&lt; (f[u] ^ f[v]) &lt;&lt; "\n";
	}
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1464" target="_blank">https://www.luogu.com.cn/problem/P1464</a><br>
题意：
思路一：直接dfs

<br>直接按照题意进行dfs代码的编写，但是很显然时间复杂极高
<br>时间复杂度：

思路二：记忆化dfs

<br>记忆化逻辑：

<br>如果当前的状态没有记忆过，就记忆一下
<br>如果当前的状态已经记忆过了，就不需要继续递归搜索了，直接使用之前已经记忆过的答案即可


<br>上述起始状态需要和搜到答案的状态做一个区别。我们知道，对于一组合法的输入，答案一定是
<br>注意点：

<br>输入终止条件不是 a != -1 &amp;&amp; b != -1 &amp;&amp; c != -1，而是要三者都不是 -1 才行
<br>对于每一组输入，我们不需要 memset 记忆数组，因为每一组的记忆依赖是相同的
<br>由于答案一定是  的，因此是否记忆过只需要看当前状态的答案是否  即可


<br>时间复杂度：

<br>直接dfs代码：<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

ll dfs(int a, int b, int c) {
	if (a &lt;= 0 || b &lt;= 0 || c &lt;= 0) return 1;
	else if (a &gt; 20 || b &gt; 20 || c &gt; 20) return dfs(20, 20, 20);
	else if (a &lt; b &amp;&amp; b &lt; c) return dfs(a, b, c - 1) + dfs(a, b - 1, c - 1) - dfs(a, b - 1, c);
	else return dfs(a - 1, b, c) + dfs(a - 1, b - 1, c) + dfs(a - 1, b, c - 1) - dfs(a - 1, b - 1, c - 1);
}

void solve() {
	int a, b, c;
	cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;
	while (a != -1 &amp;&amp; b != -1 &amp;&amp; c != -1) {
		printf("w(%d, %d, %d) = %lld\n", a, b, c, dfs(a, b, c));
		cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;
	}
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br>记忆化dfs代码：<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 25;

ll f[N][N][N];

ll dfs(ll a, ll b, ll c) {
	// 上下界
	if (a &lt;= 0 || b &lt;= 0 || c &lt;= 0) return 1;
	else if (a &gt; 20 || b &gt; 20 || c &gt; 20) return dfs(20, 20, 20);

	if (f[a][b][c]) {
		// 已经记忆化过了，直接返回当前状态的解
		return f[a][b][c];
	}
	else {
		// 没有记忆化过，就递归计算并且记忆化
		if (a &lt; b &amp;&amp; b &lt; c) return f[a][b][c] = dfs(a, b, c - 1) + dfs(a, b - 1, c - 1) - dfs(a, b - 1, c);
		else return f[a][b][c] = dfs(a - 1, b, c) + dfs(a - 1, b - 1, c) + dfs(a - 1, b, c - 1) - dfs(a - 1, b - 1, c - 1);
	}
}

void solve() {
	ll a, b, c;
	cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;
	while (!(a == -1 &amp;&amp; b == -1 &amp;&amp; c == -1)) {
		printf("w(%lld, %lld, %lld) = %lld\n", a, b, c, dfs(a, b, c));
		cin &gt;&gt; a &gt;&gt; b &gt;&gt; c;
	}
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1928" target="_blank">https://www.luogu.com.cn/problem/P1928</a><br>
线性递归
题意：给定一个压缩后的密码串，需要解压为原来的形式。压缩形式距离

<br>AC[3FUN]  ACFUNFUNFUN
<br>AB[2[2GH]]OP  ABGHGHGHGHOP

思路：

<br>
我们采用递归的策略

<br>
我们知道，对于每一个字符，一共有4种情况，分别是："字母"、"数字"、"["、"]"。如果是字母。我们分情况考虑

<br>"字母"：

<br>直接加入答案字符串即可


<br>"["：

<br>获取左括号后面的整体 - 采用递归策略获取后面的整体
<br>加入答案字符串


<br>"数字"：

<br>获取完整的数 - 循环小trick
<br>获取数字后面的整体 - 采用递归策略获取后面的整体
<br>加入答案字符串 - 循环尾加入即可
<br>返回当前的答案字符串


<br>"]"：

<br>返回当前的答案字符串 - 与上述 "[" 对应




<br>
代码设计分析：

<br>
我们将压缩后的字符串看成由下面两种单元组成：

<br>最外层中括号组成的单元：如 [2[2AB]] 就算一个最外层中括号组成的单元
<br>连续的字母单元：如 OPQ 就算一个连续的字母单元


<br>
解决各单元连接问题：

<br>
为了在递归处理完第一种单元后还能继续处理后续的第二种单元，我们直接按照压缩字符串的长度进行遍历，即 while (i &lt; s.size()) 操作

<br>
解决两种单元内部问题：

<br>最外层中括号组成的单元：递归处理
<br>连续的字母单元：直接加入当前答案字符串即可




<br>
手模样例：
  <img style="zoom: 50%;" alt="image-20231125121853866" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231125121853866.png" referrerpolicy="no-referrer">

<br>显然按照定义，上述压缩字符串一共有五个单元
<br>我们用红色表示进入递归，蓝色表示驱动递归结束并回溯。可以发现


<br>
时间复杂度：


<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

string s;
int i;

string dfs() {
	string res;

	while (i &lt; s.size()) {
		if (s[i] &gt;= 'A' &amp;&amp; s[i] &lt;= 'Z') {
			while (s[i] &gt;= 'A' &amp;&amp; s[i] &lt;= 'Z') {
				res += s[i++];
			}
		}
		if (s[i] == '[') {
			i++;
			res += dfs();
		}
		if (isdigit(s[i])) {
			int cnt = 0;
			while (isdigit(s[i])) {
				cnt = cnt * 10 + s[i] - '0';
				i++;
			}
			string t = dfs();
			while (cnt--) {
				res += t;
			}
			return res;
		}
		if (s[i] == ']') {
			i++;
			return res;
		}
	}

	return res;
}

void solve() {
	cin &gt;&gt; s;
	cout &lt;&lt; dfs() &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1036" target="_blank">https://www.luogu.com.cn/problem/P1036</a><br>
题意：给定n个数，从中选出k个数，问一共有多少种方案可以使得选出来的k个数之和为质数
思路一：dfs+剪枝

<br>按照数据量可以直接暴搜，搜索依据是每一个数有两种状态，即选和不选，于是搜索树就是一棵二叉树
<br>搜索状态定义为：对于当前第idx个数，已经选择了cnt个数，已经选择的数之和为sum
<br>搜索终止条件为：idx越界
<br>剪枝：已经选择了k个数就直接返回，不用再选剩下的数了
<br>时间复杂度： - 剪枝后一定是小于这个复杂度的

思路二：二进制枚举

<br>直接枚举 ，按照其中含有的  的个数，来进行选数判断
<br>时间复杂度： - 一定会跑满的

<br>dfs+剪枝<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 30;

int n, k, a[N];
int res;

bool isPrime(int x) {
	if (x &lt; 2) return false;
	for (int i = 2; i &lt;= x / i; i++)
		if (x % i == 0)
			return false;
	return true;
}

/**
 * @param cnt 当前已经选择的数的数量
 * @param idx 当前数的下标
 * @param sum 当前选数状态下的总和
 */
void dfs(int cnt, int idx, int sum) {
	if (idx &gt; n) return;

	if (cnt == k) {
		if (isPrime(sum)) res++;
		return;
	}

	dfs(cnt, idx + 1, sum);
	dfs(cnt + 1, idx + 1, sum + a[idx + 1]);
}

void solve() {
	cin &gt;&gt; n &gt;&gt; k;
	for (int i = 1; i &lt;= n; i++)
		cin &gt;&gt; a[i];

	dfs(0, 1, 0);		// 不选第一个数
	dfs(1, 1, a[1]);	// 选第一个数

	cout &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br>二进制枚举<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 30;

int n, k, a[N];
int res;

bool isPrime(int x) {
	if (x &lt; 2) return false;
	for (int i = 2; i &lt;= x / i; i++)
		if (x % i == 0)
			return false;
	return true;
}

void solve() {
	cin &gt;&gt; n &gt;&gt; k;
	for (int i = 1; i &lt;= n; i++)
		cin &gt;&gt; a[i];

	for (int i = 0; i &lt; (1 &lt;&lt; n); i++) {
		int cnt = 0, sum = 0;
		for (int j = 0; j &lt; n; j++)
			if (i &amp; (1 &lt;&lt; j))
				cnt++, sum += a[j + 1];

		if (cnt != k) continue;

		if (isPrime(sum)) res++;
	}

	cout &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1141" target="_blank">https://www.luogu.com.cn/problem/P1141</a><br>
题意：给定一个01矩阵，行走规则为“可以走到相邻的数字不同的位置”，现在给定m次询问 (u,v)，输出从 (u,v) 开始最多可以走多少个位置？
思路：我们可以将此问题转化为一个求解连通块的问题。对于矩阵中的一个连通块，我们定义为：在其中任意一个位置开始行走，都可以走过整个连通块每一个位置。那么在询问时，只需要输出所在连通块元素的个数即可。现在将问题转化为了

<br>
如何遍历每一个连通块？
按照标记数组的情况，如果一个位置没有被标记，就从这个位置出发开始打标记并统计

<br>
如何统计每一个连通块中元素的个数？
按照题目中给定的迷宫行走规则，可以通过bfs或者dfs实现遍历


<br>bfs代码<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 1010;

int n, m, res[N][N];
char g[N][N];
bool vis[N][N];

void bfs(int u, int v) {
	queue&lt;pair&lt;int, int&gt;&gt; q;
	int cnt = 0; // 当前“连通块”的大小
	vector&lt;pair&lt;int, int&gt;&gt; a;

	q.push({u, v});
	a.push_back({u, v});
	vis[u][v] = true;
	cnt++;

	int dx[4] = {-1, 1, 0, 0}, dy[4] = {0, 0, 1, -1};

	while (q.size()) {
		auto&amp; now = q.front();
		q.pop();

		for (int i = 0; i &lt; 4; i++) {
			int x = dx[i] + now.first, y = dy[i] + now.second;
			if (x &gt;= 1 &amp;&amp; x &lt;= n &amp;&amp; y &gt;= 1 &amp;&amp; y &lt;= n &amp;&amp; !vis[x][y] &amp;&amp; g[x][y] != g[now.first][now.second]) {
				q.push({x, y});
				a.push_back({x, y});
				vis[x][y] = true;
				cnt++;
			}
		}
	}

	for (auto&amp; loc: a) {
		res[loc.first][loc.second] = cnt;
	}
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m;
	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= n; j++)
			cin &gt;&gt; g[i][j];

	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= n; j++)
			if (!vis[i][j])
				bfs(i, j);

	while (m--) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		if (vis[a][b]) {
			cout &lt;&lt; res[a][b] &lt;&lt; "\n";
		} else {
			cout &lt;&lt; 1 &lt;&lt; "\n";
		}
	}
}

int main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br>dfs代码<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 1010;

int n, m, res[N][N];
char g[N][N];
bool vis[N][N];

// 当前点的坐标 (u, v)，当前连通块的元素个数cnt，当前连通块的元素存到 a 数组
void dfs(int u, int v, int&amp; cnt, vector&lt;pair&lt;int, int&gt;&gt;&amp; a) {
	cnt++;
	a.push_back({u, v});
	vis[u][v] = true;

	int dx[4] = {0, 0, 1, -1}, dy[4] = {1, -1, 0, 0};

	for (int k = 0; k &lt; 4; k++) {
		int x = u + dx[k], y = v + dy[k];
		if (x &gt;= 1 &amp;&amp; x &lt;= n &amp;&amp; y &gt;= 1 &amp;&amp; y &lt;= n &amp;&amp; !vis[x][y] &amp;&amp; g[x][y] != g[u][v]) {
			dfs(x, y, cnt, a);
		}
	}
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m;
	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= n; j++)
			cin &gt;&gt; g[i][j];

	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= n; j++)
			if (!vis[i][j]) {
				int cnt = 0;
				vector&lt;pair&lt;int, int&gt;&gt; a;
				dfs(i, j, cnt, a);
				for (auto&amp; loc: a) {
					res[loc.first][loc.second] = cnt;
				}
			}

	while (m--) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		if (vis[a][b]) {
			cout &lt;&lt; res[a][b] &lt;&lt; "\n";
		} else {
			cout &lt;&lt; 1 &lt;&lt; "\n";
		}
	}
}

int main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5169/" target="_blank">https://www.acwing.com/problem/content/5169/</a><br>模拟，时间复杂度 <br>#include &lt;iostream&gt;
#include &lt;cmath&gt;

using namespace std;

const int N = 5010;

int n;
int a[N];

int main()
{
	cin &gt;&gt; n;
	
	for (int i = 1; i &lt;= n; i ++)
		cin &gt;&gt; a[i];
		
	// 枚举区间长度
	for (int len = 1; len &lt;= n; len ++)
	{
		int res = 2e9;
		// 枚举相应长度的所有区间
		for (int i = 1, j = i + len - 1; j &lt;= n; i ++, j ++)
		{
		    // 计算区间的不对称值
			int l = i, r = j;
			int sum = 0;
			while (l &lt; r)
			{
				sum += abs(a[l] - a[r]);
				l ++ , r --;
			}
			res = min(res, sum);
		}
		cout &lt;&lt; res &lt;&lt; ' ';
	}
		
	return 0;
}
<br>dp优化，时间复杂度 <br>#include &lt;iostream&gt;
#include &lt;cmath&gt;
#include &lt;cstring&gt;

using namespace std;

const int N = 5010;

int n;
int a[N];

int dp[N][N]; // dp[i][j] 表示第 i 到 j 的不对称值
int res[N];   // res[len] 表示长度为 len 的山脉的最小不对称值 

int main()
{
	cin &gt;&gt; n;
	
	for (int i = 1; i &lt;= n; i ++)
		cin &gt;&gt; a[i];
		
	memset(res, 0x3f, sizeof res);
	
	// 长度为 1 的情况
	res[1] = 0; 
	
	// 长度为 2 的情况
	for (int i = 1, j = i + 1; j &lt;= n; i ++, j ++)
	{
		dp[i][j] = abs(a[i] - a[j]);
		res[2] = min(res[2], dp[i][j]);
	}
	
	// 长度 &gt;= 3 的情况 
	for (int len = 3; len &lt;= n; len ++)
	{
		for (int i = 1, j = i + len - 1; j &lt;= n; i ++, j ++)
		{
			dp[i][j] = dp[i + 1][j - 1] + abs(a[i] - a[j]);
			res[len] = min(res[len], dp[i][j]);
		}
	}
	
	for (int i = 1; i &lt;= n; i ++)
		cout &lt;&lt; res[i] &lt;&lt; ' ';
	
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://vijos.org/d/nnu_contest/p/1492" target="_blank">https://vijos.org/d/nnu_contest/p/1492</a><br>
题意：现在有一个线性网络需要分配并发线程，每一个网络有一个权重，现在有一个线程分配规则。对于当前网络，如果权重比相邻的网络大，则线程就必须比相邻的网络大。
思路：我们从答案角度来看，对于一个网络，我们想知道它的相邻的左边线程数和右边线程数，如果当前网络比左边和右边的权重都大，则就是左右线程数的最大值+1，当然这些的前提是左右线程数已经是最优的状态，因此我们要先求“左右线程”。分析可知，左线程只取决于左边的权重与线程数，右线程同样只取决于右边的权重和线程数，因此我们可以双向扫描一遍即可求得“左右线程”。最后根据“左右线程”即可求得每一个点的最优状态。
<br>void solve() {
	int n; cin &gt;&gt; n;
	vector&lt;int&gt; w(n + 1), l(n + 1, 1), r(n + 1, 1);
	for (int i = 1; i &lt;= n; i++) {
		cin &gt;&gt; w[i];
	}
	for (int i = 2, j = n - 1; i &lt;= n &amp;&amp; j &gt;= 1; i++, j--) {
		if (w[i] &gt; w[i - 1]) {
			l[i] = l[i - 1] + 1;
		}
		if (w[j] &gt; w[j + 1]) {
			r[j] = r[j + 1] + 1;
		}
	}
	int res = 0;
	for (int i = 1; i &lt;= n; i++) {
		res += max(l[i], r[i]);
	}
	cout &lt;&lt; res &lt;&lt; "\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/1017/" target="_blank">https://www.acwing.com/problem/content/1017/</a><br>
题意：给定一个二维矩阵，每一个位置有一个价值，问：从左上角（1,1）走到右下角（r,c）能获得的最大价值是多少
思路：我们不妨从结果位置出发，对于（r,c）这个位置而言，能走到这里的只有两个位置，即上面的位置（r-1,c）和左边（r,c-1）的位置，那么答案就是（r-1,c）和（r,c-1）中的最大价值 +（r,c）处的价值。那么对于（r-1,c）和（r,c-1）中的最大价值，同样需要其相应位置的左方和上方的价值最优计算而来，因此就很容易想到动态规划的思路。我们需要初始化dp[1][j]和dp[i][1]的答案，然后从dp[2][2]开始计算。
代码优化：不难发现，直接从dp[1][1]开始迭代也是可以的。因为dp[0][j]均为0，同样的dp[1][0]也均为0。
<br>优化前代码：<br>void solve() {
	int r, c;
	cin &gt;&gt; r &gt;&gt; c;
	vector&lt;vector&lt;int&gt;&gt; w(r + 1, vector&lt;int&gt;(c + 1)), dp(r + 1, vector&lt;int&gt;(c + 1, 0));

	for (int i = 1; i &lt;= r; i++) {
		for (int j = 1; j &lt;= c; j++) {
			cin &gt;&gt; w[i][j];
		}
	}

	dp[1][1] = w[1][1];

	for (int j = 2; j &lt;= c; j++) {
		dp[1][j] = dp[1][j - 1] + w[1][j];
	}

	for (int i = 2; i &lt;= r; i++) {
		dp[i][1] = dp[i - 1][1] + w[i][1];
	}

	for (int i = 2; i &lt;= r; i++) {
		for (int j = 2; j &lt;= c; j++) {
			dp[i][j] = w[i][j] + max(dp[i - 1][j], dp[i][j - 1]);
		}
	}

	cout &lt;&lt; dp[r][c] &lt;&lt; "\n";
}
<br>优化后代码：<br>void solve() {
	int r, c;
	cin &gt;&gt; r &gt;&gt; c;
	vector&lt;vector&lt;int&gt;&gt; w(r + 1, vector&lt;int&gt;(c + 1)), dp(r + 1, vector&lt;int&gt;(c + 1, 0));

	for (int i = 1; i &lt;= r; i++) {
		for (int j = 1; j &lt;= c; j++) {
			cin &gt;&gt; w[i][j];
		}
	}

	for (int i = 1; i &lt;= r; i++) {
		for (int j = 1; j &lt;= c; j++) {
			dp[i][j] = w[i][j] + max(dp[i - 1][j], dp[i][j - 1]);
		}
	}

	cout &lt;&lt; dp[r][c] &lt;&lt; "\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://vijos.org/d/nnu_contest/p/1534" target="_blank">https://vijos.org/d/nnu_contest/p/1534</a><br>
算法：换根dp | BFS
题意：给定一棵树，现在需要选择其中的一个结点为根节点，使得深度和最大。深度的定义是以每个结点到树根所经历的结点数
思路：

<br>
暴力：

<br>显然可以直接遍历每一个结点，计算每个结点的深度和，然后取最大值即可
<br>时间复杂度：


<br>
优化：
  先看图：
  <img style="zoom:50%;" alt="image-20231105233631038" src="https://s2.loli.net/2023/11/05/wPA9eDqIjChMfkN.png" referrerpolicy="no-referrer">

<br>
我们可以发现，对于当前的根结点 fa，我们选择其中的一个子结点 ch，将 ch 作为新的根结点（如右图）。那么对于当前的 ch 的深度和，我们可以借助 fa 的深度和进行求解。我们假设以 ch 为子树的结点总数为 x，那么这 x 个结点在换根之后，相对于 ch 的深度和，贡献了 -x 的深度；而对于 fa 的剩下来的 n-x 个结点，相对于 ch 的深度和，贡献了 n-x 的深度。于是 ch 的深度和就是 fa的深度和 -x+n-x，即

  于是我们很快就能想到利用前后层的递推关系， 的计算出所有子结点的深度和

<br>
代码实现：我们可以先计算出 base 的情况，即任选一个结点作为根结点，然后基于此进行迭代计算。在迭代计算的时候需要注意的点就是在一遍 dfs 计算某个结点的深度和 dep[root] 时，如果希望同时计算出每一个结点作为子树时，子树的结点数，显然需要分治计算一波。关于分治的计算我熟练度不够高，特此标注一下debug了3h的点：即在递归到最底层，进行回溯计算的时候，需要注意不能统计父结点的结点值（因为建的是双向图，所以一定会有从父结点回溯的情况），那么为了避开这个点，就需要在  的时间复杂度内获得当前结点的父结点的编号，从而进行特判，采用的方式就是增加递归参数 fa。

<br>
没有考虑从父结点回溯的情况的dfs代码
void dfs(int now, int depth) {
	if (!st[now]) {
		st[now] = true;
		dep[root] += depth;
		for (auto&amp; ch: G[now]) {
			dfs(ch, depth + 1);
			cnt[now] += cnt[ch];
		}
	}
}


<br>
考虑了从父结点回溯的情况的dfs代码
void dfs(int now, int fa, int depth) {
	if (!st[now]) {
		st[now] = true;
		dep[root] += depth;
		for (auto&amp; ch: G[now]) {
			dfs(ch, now, depth + 1);
			if (ch != fa) {
				cnt[now] += cnt[ch];
			}
		}
	}
}




<br>
时间复杂度：




<br>暴力代码：<br>const int N = 500010;

int n;
vector&lt;int&gt; G[N];
int st[N], dep[N];

void dfs(int id, int now, int depth) {
	if (!st[now]) {
		st[now] = 1;
		dep[id] += depth;
		for (auto&amp; node: G[now]) {
			dfs(id, node, depth + 1);
		}
	}
}

void solve() {
	cin &gt;&gt; n;
	for (int i = 1; i &lt;= n - 1; i++) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		G[a].push_back(b);
		G[b].push_back(a);
	}

	int res = 0;

	for (int i = 1; i &lt;= n; i++) {
		memset(st, 0, sizeof st);
		dfs(i, i, 1);
		res = max(res, dep[i]);
	}

	cout &lt;&lt; res &lt;&lt; "\n";
}
<br>优化代码：<br>const int N = 500010;

int n, dep[N], root = 1;
vector&lt;int&gt; G[N], cnt(N, 1);;
bool st[N];

// 当前结点编号 now，当前结点的父结点 fa，当前结点深度 depth
void dfs(int now, int fa, int depth) {
	if (!st[now]) {
		st[now] = true;
		dep[root] += depth;
		for (auto&amp; ch: G[now]) {
			dfs(ch, now, depth + 1);
			if (ch != fa) {
				cnt[now] += cnt[ch];
			}
		}
	}
}

void bfs() {
	memset(st, 0, sizeof st);
	queue&lt;int&gt; q;
	q.push(root);
	st[root] = true;

	while (q.size()) {
		int fa = q.front(); // 父结点编号 fa
		q.pop();
		for (auto&amp; ch: G[fa]) {
			if (!st[ch]) {
				st[ch] = true;
				dep[ch] = dep[fa] + n - 2 * cnt[ch];
				q.push(ch);
			}
		}
	}
}

void solve() {
	cin &gt;&gt; n;
	for (int i = 1; i &lt;= n - 1; i++) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		G[a].push_back(b);
		G[b].push_back(a);
	}

	dfs(root, -1, 1);
	bfs();

	cout &lt;&lt; *max_element(dep, dep + n + 1) &lt;&lt; "\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1002" target="_blank">https://www.luogu.com.cn/problem/P1002</a><br>
题意：给定一个矩阵，现在需要从左上角走到右下角，问一共有多少种走法？有一个特殊限制是，对于图中的9个点是无法通过的。
思路一：dfs

<br>
我们可以采用深搜的方法。但是会超时，我们可以这样估算时间复杂度：对于每一个点，我们都需要计算当前点的右下角的矩阵中的每一个点，那么总运算次数就近似为阶乘级别。当然实际的时间复杂度不会这么大，但是这种做法  一旦超过100就很容易tle

<br>
时间复杂度：


思路二：dp

<br>
我们可以考虑，对于当前的点，可以从哪些点走过来，很显然就是上面一个点和左边一个点，而对于走到当前这个点的路线就是走到上面的点和左边的点的路线之和，base状态就是 dp[1][1] = 1，即起点的路线数为1

<br>
时间复杂度：


<br>dfs代码<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 30;

int n, m, a, b;
int res;
bool notsafe[N][N];

void init() {
	int px[9] = {0, -1, -2, -2, -1, 1, 2, 2, 1};
	int py[9] = {0, 2, 1, -1, -2, -2, -1, 1, 2};
	for (int i = 0; i &lt; 9; i++) {
		int na = a + px[i], nb = b + py[i];
		if (na &lt; 0 || nb &lt; 0) continue;
		notsafe[na][nb] = true;
	}
}

void dfs(int x, int y) {
	if (x &gt; n || y &gt; m || notsafe[x][y]) {
		return;
	}

	if (x == n &amp;&amp; y == m) {
		res++;
		return;
	}

	dfs(x, y + 1);
	dfs(x + 1, y);
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m &gt;&gt; a &gt;&gt; b;
	init();
	dfs(0, 0);
	cout &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br>dp代码<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 30;

int n, m, a, b;
bool notsafe[N][N];
ll dp[N][N];

void solve() {
	cin &gt;&gt; n &gt;&gt; m &gt;&gt; a &gt;&gt; b;

	// 初始化
	++n, ++m, ++a, ++b;
	int px[9] = {0, -1, -2, -2, -1, 1, 2, 2, 1};
	int py[9] = {0, 2, 1, -1, -2, -2, -1, 1, 2};
	for (int i = 0; i &lt; 9; i++) {
		int na = a + px[i], nb = b + py[i];
		if (na &lt; 0 || nb &lt; 0) continue;
		notsafe[na][nb] = true;
	}

	// dp求解
	dp[1][1] = 1;
	for (int i = 1; i &lt;= n; i++) {
		for (int j = 1; j &lt;= m; j++) {
			if (!notsafe[i - 1][j]) dp[i][j] += dp[i - 1][j];
			if (!notsafe[i][j - 1]) dp[i][j] += dp[i][j - 1];
		}
	}

	cout &lt;&lt; dp[n][m] &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1028" target="_blank">https://www.luogu.com.cn/problem/P1028</a><br>
题意：给定一个数和一种构造方法，即对于当前的数，可以在其后面添加一个最大为当前一半大的数，以此类推构造成一个数列。问一共可以构造出多少个这种数列
思路一：dfs

<br>非常显然的一个搜索树，答案就是结点数
<br>时间复杂度：

思路二：dp

<br>
非常显然的一个dp，我们定义一个dp记忆数组。其中 dp[i] 表示数字 i 的构造方案总数，那么状态转移方程就是


<br>
时间复杂度：


<br>dfs代码<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

int n, res;

void dfs(int x) {
	res++;
	for (int i = x &gt;&gt; 1; i &gt;= 1; i--) {
		dfs(i);
	}
}

void solve() {
	cin &gt;&gt; n;
	dfs(n);
	cout &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br>dp代码<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

int n;

void solve() {
	cin &gt;&gt; n;

	vector&lt;ll&gt; dp(n + 1, 1);
	for (int i = 2; i &lt;= n; i++) {
		for (int j = 1; j &lt;= i &gt;&gt; 1; j++) {
			dp[i] += dp[j];
		}
	}

	cout &lt;&lt; dp[n] &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1044" target="_blank">https://www.luogu.com.cn/problem/P1044</a><br>
题意：n个数依次进栈，随机出栈，问一共有多少种出栈序列？
思路一：dfs

<br>我们可以这么构造搜索树：已知对于当前的栈，一共有两种状态

<br>入栈 - 如果当前还有数没有入栈
<br>出栈 - 如果当前栈内还有元素


<br>搜索参数：i,j 表示入栈数为 i 出栈数为 j 的状态
<br>搜索终止条件

<br>入栈数 &lt; 出栈数 - 
<br>入栈数 &gt; 总数  - 


<br>答案状态：入栈数为n，出栈数也为n
<br>时间复杂度：

思路二：dp

<br>
采用上述dfs时的状态表示方法，i,j 表示入栈数为 i 出栈数为 j 的状态。

<br>
我们在搜索的时候，考虑的是接下来可以搜索的状态

<br>
即出栈一个数的状态 - i+1,j

<br>
和入栈一个数的状态 - i,j+1


  如图：
  <img style="zoom:50%;" alt="image-20231121192133801" src="https://s2.loli.net/2023/11/21/wRQkKeEDhBZ6MC4.png" referrerpolicy="no-referrer">
  而我们在dp的时候，需要考虑的是子结构的解来得出当前状态的答案，就需要考虑之前的状态。即当前状态是从之前的哪些状态转移过来的。和上述dfs思路是相反的。我们需要考虑的是

<br>上一个状态入栈一个数到当前状态 - i-1,j  i,j
<br>上一个状态出栈一个数到当前状态 - i,j-1  i,j


<br>特例： 时，只能是上述第二种状态转移而来，因为要始终保证入栈数大于等于出栈数，即 

  如图：
  <img style="zoom: 33%;" alt="image-20231121192152555" src="https://s2.loli.net/2023/11/21/NIKbWduh9P3rGD2.png" referrerpolicy="no-referrer">

<br>
我们知道，入栈数一定是大于等于出栈数的，即 。于是我们在枚举  的时候，枚举的范围是 

<br>
 状态的构建取决于  时的所有状态，我们知道没有任何数出栈也是一种状态，于是


<br>
时间复杂度：


<br>dfs代码<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

int n, res;

// 入栈i个数，出栈j个数
void dfs(int i, int j) {
	if (i &lt; j || i &gt; n) return;

	if (i == n &amp;&amp; j == n) res++;

	dfs(i + 1, j);
	dfs(i, j + 1);
}

void solve() {
	cin &gt;&gt; n;
	dfs(0, 0);
	cout &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br>dp代码<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 20;

int n;
ll dp[N][N]; // dp[i][j] 表示入栈数为i，出栈数为j的方案总数

void solve() {
	cin &gt;&gt; n;

	// base状态：没有数出栈也是一种状态
	for (int i = 1; i &lt;= n; i++) dp[i][0] = 1;

	// dp转移
	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= i; j++)
			if (i == j) dp[i][j] = dp[i][j - 1];
			else dp[i][j] = dp[i - 1][j] + dp[i][j - 1];

	cout &lt;&lt; dp[n][n] &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1255" target="_blank">https://www.luogu.com.cn/problem/P1255</a><br>
题意：给定楼梯的台阶数，每次可以走1步或者2步，问走到第n层台阶可以走的方案数
思路一：dfs

<br>我们可以从前往后思考，即正向思维。对于剩余的台阶，我们可以走1步或者走2步，最终走到第n层就算一种
<br>时间复杂度：指数级别

思路二：递推（dp）

<br>
对于递推的思路，我们从后往前考虑，即逆向思维。对于当前的层数，是从之前的哪几个台阶走过来的（即对于当前的状态，是之前哪几个状态转移过来的）。

<br>
我们定义 f[i] 为走到第 i 层台阶的方案数

<br>
则很显然第 i 层台阶是从前1个或者前2个台阶走过来的，于是状态转移方程就是


<br>
时间复杂度：


注意：采用高精度加法
<br>dfs代码：<br>int n, res;

void dfs(int x) {
	if (x &lt; 0) return;

	if (x == 0) res++;

	dfs(x - 1);
	dfs(x - 2);
}
<br>递推（dp）代码：<br>int n;
Int dp[N];

void solve() {
	cin &gt;&gt; n;

	dp[1] = 1, dp[2] = 2;
	for (int i = 3; i &lt;= n; i++) {
		dp[i] = dp[i - 1] + dp[i - 2];
	}

	cout &lt;&lt; dp[n] &lt;&lt; "\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P2437" target="_blank">https://www.luogu.com.cn/problem/P2437</a><br>
题意：可以按照下面的路线从小数到相邻大数，问给定起点和终点，一共有多少种走法
<img style="zoom:33%;" alt="image-20231126231329349" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231126231329349.png" referrerpolicy="no-referrer">
思路：

<br>
可以发现，对于每一个数 ，可以从  和  两个位置走过来。定义  表示从  走到  的路线数（状态数），于是状态转移方程就是


<br>
方程一写其实就是斐波那契数，需要使用高精度加法


时间复杂度：
<br>int m, n;
Int dp[N];

void solve() {
	cin &gt;&gt; m &gt;&gt; n;
	n = n - m + 1;

	dp[1] = 1;
	for (int i = 2; i &lt;= n; i++) {
		dp[i] = dp[i - 1] + dp[i - 2];
	}

	cout &lt;&lt; dp[n] &lt;&lt; "\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1881/problem/E" target="_blank">https://codeforces.com/contest/1881/problem/E</a><br>
题意：给定一个序列，问最少可以删除其中的几个数，使得最终的序列满足：从中选择一些数 num[]，使得 num[i] 后面有 num[i] 个数，且这些数包括 num[] 涵盖且只涵盖了一遍最终序列中所有的数
思路：我们考虑动态规划。

<br>我们考虑状态表示：其中 dp[i] 表示使得序列 [i,n] 满足上述条件的最少删除个数
<br>我们考虑状态转移：我们知道对于当前的数 num[i]，有两种状态 - 删除 | 不删除。

<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1990" target="_blank">https://www.luogu.com.cn/problem/P1990</a><br>
题意：给定两种砖块，分别为日字型与L型，问铺满  的地板一共有多少种铺法
思路：

<br>我们采用递推的思路
<br> f[i] 表示铺满前  个地板的方案数，g[i] 表示铺满前  块地板的方案数
<br> f[0] = 1, f[1] = 1, g[0] = 0, g[1] = 1
<br> f[i] = f[i-1] + f[i-2] + g[i-1]  g[i] = f[i-1] + g[i-1]
<br> f[n]

手绘：
<img style="zoom:50%;" alt="image-20231221100352559" src="https://s2.loli.net/2023/12/21/T7U6AjwBna1hCRE.png" referrerpolicy="no-referrer"> <img style="zoom:50%;" alt="image-20231221100410409" src="https://s2.loli.net/2023/12/21/RmgtDn9siwMXO47.png" referrerpolicy="no-referrer">
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 1000010, mod = 10000;

int n;
int f[N], g[N];

void solve() {
	cin &gt;&gt; n;

	// base
	f[0] = 1, f[1] = 1;
	g[0] = 0, g[1] = 1;

	// dp
	for (int i = 2; i &lt;= n; i++) {
		f[i] = (f[i - 1] + f[i - 2] + 2 * g[i - 2]) % mod;
		g[i] = (f[i - 1] + g[i - 1]) % mod;
	}

	// result
	cout &lt;&lt; f[n] &lt;&lt; "\n";
}

int main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1867/problem/C" target="_blank">https://codeforces.com/contest/1867/problem/C</a><br>
tag：交互题+博弈+贪心
题面：对于给定n个数的数列，先手可以放入一个数列中不存在的数（0-1e9），后手可以从数列中拿掉一个数，但是这个数必须严格小于刚才先手放入的数。
终止条件：后手没法拿数或者操作次数达到了2n+1次
问：当你是先手时，如何放数可以使得最终数列的MEX值最大
思路：先手每次放入的数一定是当前数列的MEX值，此后不管后手拿掉什么数，先手都将刚刚被拿掉的数放进去即可。那么最多操作次数就刚好是2n+1次，因为加入当前数列就是一个从0开始的连续整数数列，那么先手放入的数就是最大数+1，即n，那么假如后手从n-1开始拿，后手最多拿n次，先手再放n次，那么就是2n+1次
时间复杂度：
<br>#include &lt;iostream&gt;
#include &lt;vector&gt;

using namespace std;

int main()
{
	int T; cin &gt;&gt; T;
	
	while (T--)
	{
		int n; cin &gt;&gt; n;
		vector&lt;int&gt; a(n);
		
		for (int i = 0; i &lt; n; i ++)
			cin &gt;&gt; a[i];
		
		int mex = n;
		for (int i = 0; i &lt; n; i ++)
			if (a[i] != i)
			{
				mex = i;
				break;
			}
		
		cout &lt;&lt; mex &lt;&lt; endl;
		
		int remove;
		cin &gt;&gt; remove;
		
		while (remove != -1)
		{
			cout &lt;&lt; remove &lt;&lt; endl;
			cin &gt;&gt; remove;
		}
	}
	
	return 0;
} 
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/gym/104639/problem/J" target="_blank">https://codeforces.com/gym/104639/problem/J</a><br>
题意：给定两个圆的直径的两个点坐标，其中约束条件是两个圆一定是处在相离的两个角上。问如何在C2圆上或圆内找到一点p，使得点p到C1圆的所有点的曼哈顿距离的期望值最小
思路：

<br>看似需要积分，其实我们可以发现，对于点p到C1中某个点q1的曼哈顿距离，我们一定可以找到q1关于C1对称的点q2，那么点p到q1和q2的曼哈顿距离之和就是点p到C1的曼哈顿距离的两倍（证明就是中线定理）那么期望的最小值就是点p到C1的曼哈顿距离的最小值。目标转化后，我们开始思考如何计算此目标的最小值，思路如下图
<br>
<img style="zoom: 25%;" alt="image-20231031233842979" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231031233842979.png" referrerpolicy="no-referrer">


注意点：

<br>double的读取速度很慢，可以用 int or long long 读入，后续强制类型转换（显示 or 和浮点数计算）
<br>注意输出答案的精度控制 cout &lt;&lt; fixed &lt;&lt; setprecision(10) &lt;&lt; res &lt;&lt; "\n";

<br>void solve() {
	double x1, y1, x2, y2;
	long long a, b, c, d;

	cin &gt;&gt; a &gt;&gt; b &gt;&gt; c &gt;&gt; d;
	x1 = (a + c) / 2.0;
	y1 = (b + d) / 2.0;

	cin &gt;&gt; a &gt;&gt; b &gt;&gt; c &gt;&gt; d;
	x2 = (a + c) / 2.0;
	y2 = (b + d) / 2.0;

	double r2 = sqrt((a - c) * (a - c) + (b - d) * (b - d)) / 2;

	cout &lt;&lt; fixed &lt;&lt; setprecision(10) &lt;&lt;  abs(x1 - x2) + abs(y1 - y2) - sqrt(2) * r2 &lt;&lt; "\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5383/" target="_blank">https://www.acwing.com/problem/content/5383/</a><br>
题意：给定两个直角三角形的两条直角边的长度 a, b，问能不能在坐标轴上找到三个整数点使得三点满足该直角三角形且三遍均不与坐标轴垂直
思路：首先确定两个直角边的顶点为原点 (0, 0)，接着根据对称性直接在第一象限中按照边长枚举其中一个顶点 A，对于每一个枚举到的顶点 A，按照斜率枚举最后一个顶点 B，如果满足长度以及不平行于坐标轴的条件就是合法的点。如果全部枚举完都没有找到就是没有合法组合，直接输出 NO 即可。
时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

#define int long long

int a, b;

void solve() {
	cin &gt;&gt; a &gt;&gt; b;

	for (int i = 0; i &lt;= a; i++) {
		for (int j = 0; j &lt;= a; j++) {
			if (i * i + j * j == a * a &amp;&amp; i &amp;&amp; j) {
				int gcd = __gcd(i, j);
				int p = -i / gcd, q = j / gcd;
				int y = p, x = q;
				while (x * x + y * y &lt; b * b) {
					x += q, y += p;
				}
				if (x * x + y * y == b * b &amp;&amp; x != i &amp;&amp; y != j) {
					cout &lt;&lt; "YES\n";
					cout &lt;&lt; 0 &lt;&lt; ' ' &lt;&lt; 0 &lt;&lt; "\n";
					cout &lt;&lt; i &lt;&lt; ' ' &lt;&lt; j &lt;&lt; "\n";
					cout &lt;&lt; x &lt;&lt; ' ' &lt;&lt; y &lt;&lt; "\n";
					return;
				}
			}
		}
	}

	cout &lt;&lt; "NO\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/850/" target="_blank">https://www.acwing.com/problem/content/850/</a><br>
题意：输出一个图的拓扑序，不存在则输出-1
思路：

<br>首先我们要知道拓扑图的概念，感官上就是一张图可以从一个方向拓展到全图，用数学语言就是：若一个由图中所有点构成的序列 A 满足：对于图中的每条边 (x,y)，x 在 A 中都出现在 y 之前，则称 A 是该图的一个拓扑序列
<br>接着我们就想要寻找这样的序列 A 了，可以发现对于每一个可扩展的点，入度一定为0，那么我们就从这些点开始宽搜，将搜到的点的入度-1，即删除这条边，直到最后。如果全图的点的入度都变为了0，则此图可拓扑

时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 100010;

int n, m;
vector&lt;int&gt; G[N];

void solve() {
	// 建图 
	cin &gt;&gt; n &gt;&gt; m;
	vector&lt;int&gt; d(n + 1, 0);
	for (int i = 1; i &lt;= m; i++) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		d[b]++;
		G[a].push_back(b);
	}
	
	// 预处理宽搜起始点集
	queue&lt;int&gt; q;
	for (int i = 1; i &lt;= n; i++)
		if (!d[i])
			q.push(i);
	
	// 宽搜处理
	vector&lt;int&gt; res;
	while (q.size()) {
		auto h = q.front();
		q.pop();
		res.push_back(h);
		
		for (auto&amp; ch: G[h]) {
			d[ch]--;
			if (!d[ch]) q.push(ch);
		}
	}
	
	// 输出合法拓扑序
	if (res.size() == n) {
		for (auto&amp; x: res) {
			cout &lt;&lt; x &lt;&lt; " ";
		}
	} else {
		cout &lt;&lt; -1 &lt;&lt; "\n";
	}
}

int main() {
	solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1873/problem/H" target="_blank">https://codeforces.com/contest/1873/problem/H</a><br>
tag：基环树、拓扑排序
题意：给定一个基环树，现在图上有两个点，分别叫做A，B。现在B想要逃脱A的抓捕，问对于给定的局面，B能否永远逃离A的抓捕
思路：思路很简单，我们只需要分B所在位置的两种情况讨论即可

<br>B不在环上：此时我们记距离B最近的环上的那个点叫 ，我们需要比较的是A到tag点的距离  和B到tag的距离 ，如果 ，则一定可以逃脱，否则一定不可以逃脱
<br>B在环上：此时我们只需要判断当前的A点是否与B的位置重合即可，如果重合那就无法逃脱，反之B一定可以逃脱。

代码实现：

<br>对于第一种情况，我们需要找到tag点以及计算A和B到tag点的距离，

时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 200010;

int n, a, b;
vector&lt;int&gt; G[N];
int rd[N], tag, d[N];
bool del[N], vis[N];

void init() {
	for (int i = 1; i &lt;= n; i++) {
		G[i].clear();		// 存无向图 
		rd[i] = 0;			// 统计每一个结点的入度 
		del[i] = false;		// 拓扑删点删边时使用 
		d[i] = 0;			// 图上所有点到 tag 点的距离 
		vis[i] = false;		// bfs计算距离时使用 
	}
}

void topu(int now) {
	if (rd[now] == 1) {
		rd[now]--;
		del[now] = true;
		for (auto&amp; ch: G[now]) {
			if (del[ch]) continue;
			rd[ch]--;
			if (now == tag) {
				tag = ch;
			}
			topu(ch);
		}
	}
}

void bfs() {
	queue&lt;int&gt; q;
	q.push(tag);
	d[tag] = 0;
	
	while (q.size()) {
		auto now = q.front();
		vis[now] = true;
		q.pop();
		
		for (auto&amp; ch: G[now]) {
			if (!vis[ch]) {
				d[ch] = d[now] + 1;
				q.push(ch);
				vis[ch] = true;
			}
		}
	}
}

void solve() {
	// 初始化
	cin &gt;&gt; n &gt;&gt; a &gt;&gt; b; 
	init();
	
	// 建图 
	for (int i = 1; i &lt;= n; i++) {
		int u, v;
		cin &gt;&gt; u &gt;&gt; v;
		G[u].push_back(v), rd[v]++;
		G[v].push_back(u), rd[u]++;
	}
	
	// 拓扑删边 &amp; 缩b点
	tag = b;
	for (int i = 1; i &lt;= n; i++) {
		topu(i);
	}

	// 判断结果 &amp; 计算距离 
	if (rd[b] == 2 &amp;&amp; a != b) {
		// b点在环上
		cout &lt;&lt; "Yes\n";
	} else {
		// b不在环上
		bfs();
		cout &lt;&lt; (d[a] &gt; d[b] ? "Yes\n" : "No\n");
	}
}

int main() {
	ios::sync_with_stdio(false);
	cin.tie(0);
	int T = 1;
	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/862/" target="_blank">https://www.acwing.com/problem/content/862/</a><br>
题意：给定一个无向图，可能有重边和自环。问是否可以构成二分图。
二分图的定义：一个图可以被分成两个点集，每个点集内部没有边相连（可以不是连通图）
思路：利用染色法，遍历每一个连通分量，选择连通分量中的任意一点进行染色扩展

<br>如果扩展到的点没有染过色，则染成与当前点相对的颜色
<br>如果扩展到的点已经被染过色了且染的颜色和当前点的颜色相同，则无法构成二分图（奇数环）

时间复杂度：
<br>const int N = 100010;

int n, m;
vector&lt;int&gt; G[N], col(N);

bool bfs(int u) {
	queue&lt;int&gt; q;
	q.push(u);
	col[u] = 1;

	while (q.size()) {
		int now = q.front();
		q.pop();
		for (auto&amp; ch: G[now]) {
			if (!col[ch]) {
				col[ch] = -col[now];
				q.push(ch);
			}
			else if (col[ch] == col[now]) {
				return false;
			}
		}
	}

	return true;
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m;
	while (m--) {
		int u, v;
		cin &gt;&gt; u &gt;&gt; v;
		G[u].push_back(v);
		G[v].push_back(u);
	}

	// 遍历每一个连通分量
	for (int i = 1; i &lt;= n; i++) {
		if (!col[i]) {
			bool ok = bfs(i);
			if (!ok) {
				cout &lt;&lt; "No\n";
				return;
			}
		}
	}

	cout &lt;&lt; "Yes\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/861/" target="_blank">https://www.acwing.com/problem/content/861/</a><br>
题意：给定一个无向图，可能含有重边和自环。试判断能否求解其中的最小生成树，如果可以给出最小生成树的权值
思路：根据数据量，可以发现顶点数很大，不适用  算法，只能用  算法，下面简单介绍一下该算法的流程

<br>自环首先排除 - 显然这条边连接的“两个”顶点是不可能选进  的
<br>首先将每一个结点看成一个连通分量
<br>接着按照权值将所有的边升序排序后，依次选择

<br>如果选出的这条边的两个顶点不在一个连通分量中，则选择这条边并将两个顶点所在的连通分量合并
<br>如果选出的这条边的两个顶点在同一个连通分量中，则不能选择这条边（否则会使得构造的树形成环）


<br>最后统计选择的边的数量  进行判断即可

<br>，则可以生成最小生成树
<br>，则无法生成最小生成树


<br>时间复杂度： - 因为最大的时间开销在对所有的边的权值进行排序上

<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 100010;

struct edge {
	int a, b;
	int w;
};

int n, m;
vector&lt;edge&gt; edges;
vector&lt;int&gt; p(N);

int Find(int now) {
	if (p[now] != now) {
		p[now] = Find(p[now]);
	}
	return p[now];
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m;
	for (int i = 1; i &lt;= m; i++) {
		int a, b, w;
		cin &gt;&gt; a &gt;&gt; b &gt;&gt; w;
		if (a == b) {
			continue;
		}
		edges.push_back({a, b, w});
	}

	// 按照边权升序排序
	sort(edges.begin(), edges.end(), [&amp;](edge&amp; x, edge&amp; y) {
		return x.w &lt; y.w;
	});

	// 选边
	for (int i = 1; i &lt;= n; i++) {
		p[i] = i;
	}

	int res = 0, num = 0;

	for (auto&amp; e: edges) {
		int pa = Find(e.a), pb = Find(e.b);
		if (pa != pb) {
			num++;
			p[pa] = pb;
			res += e.w;
		}

		if (num == n - 1) {
			break;
		}
	}

	// 特判：选出来的边数无法构成一棵树
	if (num &lt; n - 1) {
		cout &lt;&lt; "impossible\n";
		return;
	}

	cout &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/860/" target="_blank">https://www.acwing.com/problem/content/860/</a><br>
题意：给定一个稠密无向图，有重边和自环。求出最小生成树
思路：根据题目的数据量，可以使用邻接矩阵存储的方法配合  算法求解最小生成树，下面给出该算法的流程

<br>首先明确一下变量的定义：

<br>g[i][j] 为无向图的邻接矩阵存储结构
<br>MST[i] 表示  号点是否加入了  集合
<br>d[i] 表示 i 号点到  集合的最短边长度


<br>自环不存储，重边只保留最短的一条
<br>任选一个点到集合  中，并且更新  数组
<br>选择剩余的  个点，每次选择有以下流程

<br>找到最短边，记录最短边长度  和相应的在  集合中对应的顶点序号 
<br>将  号点加入  集合，同时根据此时选出的最短边的长度来判断是否存在最小生成树
<br>根据  号点，更新  数组，即更新在集合  中的点到  集合中的点的交叉边的最短长度


<br>时间复杂度：

<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 510;

int n, m;
vector&lt;vector&lt;int&gt;&gt; g(N, vector&lt;int&gt;(N, INT_MAX));
vector&lt;int&gt; d(N, INT_MAX); // d[i]表示i号点到MST集合中的最短边长度
bool MST[N];
int res;

void prim() {
	// 选任意一个点到MST中并更新d数组
	MST[1] = true;
	for (int i = 1; i &lt;= n; i++)
		if (!MST[i])
			d[i] = min(d[i], g[i][1]);

	// 选剩下的n-1个点到MST中
	for (int i = 2; i &lt;= n; i++) {
		// 1. 找到最短边
		int e = INT_MAX, v = -1; // e: 最短边长度，v: 最短边不在MST集合中的顶点
		for (int j = 1; j &lt;= n; j++)
			if (!MST[j] &amp;&amp; d[j] &lt; e)
				e = d[j], v = j;

		// 2. 加入MST集合
		MST[v] = true;
		if (e == INT_MAX) {
			// 特判无法构造MST的情况
			cout &lt;&lt; "impossible\n";
			return;
		} else {
			res += e;
		}

		// 3. 更新交叉边 - 迭代（覆盖更新）
		for (int j = 1; j &lt;= n; j++)
			if (!MST[j])
				d[j] = min(d[j], g[j][v]);
	}

	cout &lt;&lt; res &lt;&lt; "\n";
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m;
	while (m--) {
		int a, b, w;
		cin &gt;&gt; a &gt;&gt; b &gt;&gt; w;

		if (a == b) {
			continue;
		}

		if (g[a][b] == INT_MAX) {
			g[a][b] = w;
			g[b][a] = w;
		} else {
			g[a][b] = min(g[a][b], w);
			g[b][a] = min(g[b][a], w);
		}
	}

	prim();
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/851/" target="_blank">https://www.acwing.com/problem/content/851/</a><br>
题意：给定一个无向图，可能存在重边与自环，问1号点到n号点的最短路径长度是多少，1到n没有通路就输出-1
思路：

<br>存储：根据数据量，即点少边多的稠密图，我们采用邻接矩阵的方式存储图
<br>求解：我们定义 d[i] 数组表示源点到 i 号点的最短距离。先将源点放入 SPT 集合，然后更新所有 V-SPT 中的点到 SPT 集合的最短路径长度。接着循环 n-1 次迭代更新剩余的 n-1 个点，最终的 d[end] 就是答案。
<br>总结：算法整体采用贪心与动态规划的思路，与 Prim 算法仔细比对可知，其中的贪心过程几乎一致，而动态规划的过程体现在在求解出集合 V-SPT 中到集合 STP 最短距离的点 vex 之后，利用该点对其余在 V-SPT 中的点更新 d[j] 的过程。更新前的状态都是在之前的子结构下的最优解，因此更新就是基于动态规划进行的。（此处仔细体悟）

时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;

using namespace std;

const int N = 510, INF = 0x3f3f3f3f;

int n, m;
int g[N][N];

int dijkstra(int start, int end) {
	vector&lt;int&gt; d(n + 1, INF);
	vector&lt;bool&gt; SPT(n + 1, false);

	d[start] = 0;

	/* 1. 将起点加入SPT集合 */
	SPT[start] = true;
	for (int j = 1; j &lt;= n; j++)
		if (!SPT[j])
			d[j] = min(d[j], d[start] + g[start][j]);

	/* 2. 选择到起点最近的点(greedy)，更新到起点最近的点(dp) */
	for (int i = 1; i &lt;= n - 1; i++) {
		// 找到V-SPT中到起点最近的点vex
		int vex = -1;
		for (int j = 1; j &lt;= n; j++)
			if (!SPT[j] &amp;&amp; (vex == -1 || d[j] &lt; d[vex]))
				vex = j;

		// 将vex加入SPT
		SPT[vex] = true;

		// 更新所有V-SPT中的点到起点的最短距离
		for (int j = 1; j &lt;= n; j++)
			if (!SPT[j])
				d[j] = min(d[j], d[vex] + g[vex][j]);
	}

	return d[end] == INF ? -1 : d[end];
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m;

	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= n; j++)
			g[i][j] = i == j ? 0 : INF;

	while (m--) {
		int u, v, w;
		cin &gt;&gt; u &gt;&gt; v &gt;&gt; w;
		g[u][v] = min(g[u][v], w);
//		g[v][u] = min(g[v][u], w);
	}

	cout &lt;&lt; dijkstra(1, n) &lt;&lt; "\n";
}

int main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/856/" target="_blank">https://www.acwing.com/problem/content/856/</a><br>
题意：
给定一个稠密有向图，可能存在重边与自环，给出多个询问，需要给出每一个询问的两个点之前的最短路径长度
思路：
我们采用动态规划的思路。在此使用多阶段决策的方法，即每一个路径状态为选择  个点的情况下的最短路径长度

<br>状态表示：f[k][i][j] 表示在前  个顶点中进行选择（中转）， 号点到  号点的最短路径长度
<br>状态转移：对于第  个顶点，我们可以选择中转，也可以不中转。

<br>对于不选择中转的情况：f[k][i][j] = f[k-1][i][j]
<br>对于可选择中转的情况：f[k][i][j] = f[k-1][i][k] + f[k-1][k][j]
<br>在其中取最小值即可，但是有一个注意点：对于第二种情况，选择是有一个约束的：即如果选择了  号点进行转移的话，那么  号点到  号点以及  号点到  号点都是需要有路径可达的，从而可以选择最小距离


<br>初始化：即选择 0 个站点进行中转时，即 f[0][i][j] 的情况中，

<br>如果  号点与  号点自环，则取 
<br>如果  号点与  号点之间有边，则取重边的最小值
<br>如果  号点与  号点之间无边，则初始化为正无穷


<br>答案状态：对于  号点到  号点之间的最小路径长度，就是 f[n][a][b]
<br>时间复杂度：
<br>空间复杂度：

空间优化推导：

<br>
我们尝试优化掉记忆数组的第一维度

<br>
对于不选择的情况：由于决策局面  是从前往后枚举，故当前状态 f[k][i][j] 可以直接依赖于已经更新出来且不会被当前状态之后的状态再次覆盖的最优子结构 f[i][j]。即上一个局面的选择情况，就是不选择第  个顶点的情况

<br>
对于选择的情况：如果删除第一维度，我们担心的是当前状态 f[k][i][j] 依赖的两个状态 f[i][k] 与 f[k][j] 会不会被后续覆盖掉，即我们不确定 f[i][k] 与 f[k][j] 是否是当前第 k 个局面的最优子结构。尝试推导：

为了确定 f[i][k] 与 f[k][j] 是否是当前第  个局面的最优子结构，其实就是确定对于当前第  个局面，这两个状态会不会在当前状态 f[i][j] 之后被更新覆盖，那么我们就看这两个状态是从哪里转移过来进行更新的。如果 f[i][k] 与 f[k][j] 这两个状态的转移会依赖于当前状态之后的状态，那么删除第一维度就是错误的，反之就是成立的。
尝试推导 f[i][k] 与 f[k][j] 从何转移更新：利用我们未删除维度时正确的状态转移方程进行推演
我们知道：f[k][i][k] = min(f[k-1][i][k], f[k-1][i][k] + f[k-1][k][k])，其中的 f[k-1][k][k] 就是一个自环的路径长度，由于  算法的约束条件是没有负环，因此 f[k-1][k][k] 一定大于零，故 f[k][i][k] 一定取前者，即 f[k][i][k] = f[k-1][i][k]
同理可知：
f[k][k][j] = f[k-1][k][j]

  基于上述推导我们可以知道，当前第  个决策局面中的 f[k][i][k] 与 f[k][k][j] 是依赖于上一个决策局面  的，也就是说这两个状态一定是早于当前状态 f[i][j] 被更新覆盖的，故 f[i][k] 与 f[k][j] 就是当前第  个局面的最优子结构，证毕，可以进行维度的删除

<br>
时间复杂度：

<br>
空间复杂度：


<br>不优化空间<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 210, INF = 0x3f3f3f3f;

int n, m, Q;
int f[N][N][N];

int main() {
    cin &gt;&gt; n &gt;&gt; m &gt;&gt; Q;
    
    // init
    memset(f, INF, sizeof f);
    
    // add edges and generate base
    while (m--) {
        int a, b, w;
        cin &gt;&gt; a &gt;&gt; b &gt;&gt; w;
        if (a == b) continue;                           // 重边就不赋值
        else if (f[0][a][b] == INF) f[0][a][b] = w;     // 第一次加边则直接赋值
        else f[0][a][b] = min(f[0][a][b], w);           // 再次赋边权就取最小值
    }
    
    // generate base again
    for (int i = 1; i &lt;= n; i++)
        for (int j = 1; j &lt;= n; j++)
            if (i == j) 
                f[0][i][j] = 0;                         // 自环取边权为 0
    
    // dp 
    for (int k = 1; k &lt;= n; k++)
        for (int i = 1; i &lt;= n; i++)
            for (int j = 1; j &lt;= n; j++) {
                // 不选第k个顶点
                f[k][i][j] = f[k - 1][i][j];
                
                // 选择第k个顶点
                if (f[k - 1][i][k] != INF &amp;&amp; f[k - 1][k][j] != INF)
                    f[k][i][j] = min(f[k][i][j], f[k - 1][i][k] + f[k - 1][k][j]);
            }

    // query
    while (Q--) {
        int a, b;
        cin &gt;&gt; a &gt;&gt; b;
        if (f[n][a][b] == INF) cout &lt;&lt; "impossible\n";
        else cout &lt;&lt; f[n][a][b] &lt;&lt; "\n";
    }
    
    return 0;
}
<br>优化空间<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 210, INF = 0x3f3f3f3f;

int n, m, Q;
int f[N][N];

int main() {
    cin &gt;&gt; n &gt;&gt; m &gt;&gt; Q;
    
    // init
    for (int i = 1; i &lt;= n; i++)
        for (int j = 1; j &lt;= n; j++)
            if (i == j) f[i][j] = 0;
            else f[i][j] = INF;
            
    // base
    while (m--) {
        int a, b, w;
        cin &gt;&gt; a &gt;&gt; b &gt;&gt; w;
        if (a == b) continue;
        else if (f[a][b] == INF) f[a][b] = w;
        else f[a][b] = min(f[a][b], w);
    }
    
    // dp
    for (int k = 1; k &lt;= n; k++)
        for (int i = 1; i &lt;= n; i++)
            for (int j = 1; j &lt;= n; j++)
                if (f[i][k] != INF &amp;&amp; f[k][j] != INF)
                    f[i][j] = min(f[i][j], f[i][k] + f[k][j]);
    
    // query
    while (Q--) {
        int a, b;
        cin &gt;&gt; a &gt;&gt; b;
        if (f[a][b] == INF) cout &lt;&lt; "impossible\n";
        else cout &lt;&lt; f[a][b] &lt;&lt; "\n";
    }
    
    return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1867/problem/A" target="_blank">https://codeforces.com/contest/1867/problem/A</a><br>
题意：给定n个数a[i]，其中可能有重复数，请构造一个n个数的排列b[i]，使得c[i]=a[i]-b[i]中，c[i]的不同数字的个数最多
思路：思路比较好想，就是最大的数匹配最小的数，次大的数匹配次小的数，以此类推。起初我想通过将原数列的拷贝数列降序排序后，创建一个哈希表来记录每一个数的排位，最终通过原数列的数作为键，通过哈希表直接输出排位，但是问题是原数列中的数可能会有重复的，那么在哈希的时候如果有重复的数，那么后来再次出现的数就会顶替掉原来的数的排位，故错误。
正确思路：为了保证原数列中每个数的唯一性，我们可以给原数列每一个数赋一个下标，排序后以下标进行唯一的一一对应的索引。那么就是：首先赋下标，接着以第一关键词进行排序，然后最大的数（其实是下标）匹配最小的结果以此类推
模拟一个样例：<br>
5<br>
8 7 4 5 5 9
最终的答案应该是<br>
2 3 6 4 5 1
首先对每一个数赋予一个下标作为为唯一性索引<br>
8 7 4 5 5 9<br>
1 2 3 4 5 6（替身）
接着将上述数列按照第一关键词进行排序<br>
9 8 7 5 5 4<br>
6 1 2 4 5 3（替身）
对每一个数进行赋值匹配<br>
9 8 7 5 5 4<br>
6 1 2 4 5 3（替身）<br>
1 2 3 4 5 6（想要输出的结果）
按照替身进行排序<br>
8 7 4 5 5 9<br>
1 2 3 4 5 6（替身）（排序后）<br>
2 3 6 4 5 1（想要输出的结果）
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

void solve()
{
	int n; cin &gt;&gt; n;
	
    // 第一关键词是原数列，第二关键词是赋予的唯一下标
	vector&lt;pair&lt;int, int&gt;&gt; a(n + 1);
	for (int i = 1; i &lt;= n; i ++)
	{
		cin &gt;&gt; a[i].first;
		a[i].second = i;
	}
	
    // 按照第一关键词排序
	sort(a.begin() + 1, a.end(), [&amp;](pair&lt;int, int&gt; x, pair&lt;int, int&gt; y) {
		return x.first &gt; y.first;
	});
	
    // 以下标作为原数列的替身，每一个替身对应一个升序的最终排名
	vector&lt;pair&lt;int, int&gt;&gt; res(n + 1);
	for (int i = 1; i &lt;= n; i ++)
	{
		res[i].first = a[i].second;
		res[i].second = i;
	}
	
    // 通过下标，还原原数列的排序
	sort(res.begin() + 1, res.end());
	
    // 输出第二关键词
	for (int i = 1; i &lt;= n; i ++)
		cout &lt;&lt; res[i].second &lt;&lt; " \n"[i == n];
}

int main()
{
	int T; cin &gt;&gt; T;
	while (T --) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1873/problem/B" target="_blank">https://codeforces.com/contest/1873/problem/B</a><br>
题意：对于一个数列，现在可以选择其中的一个数使其+1，问如何选择这个数，可以使得修改后的数列中的所有数之积的值最大
思路：其实就是选择n-1个数的乘积值加一倍，关键在于选哪一个n-1个数的乘积值，逆向思维就是对于n个数，去掉那个最小值，那么剩下来的n-1个数之积就会最大了，于是就是选择最小的数+1，最终数列之积就是答案了。
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

typedef long long ll;

void solve()
{
	int n; cin &gt;&gt; n;
	vector&lt;int&gt; a(n);
	
	for (int i = 0; i &lt; n; i ++)
		cin &gt;&gt; a[i];
	
	sort(a.begin(), a.end());
	
	ll res = a[0] + 1;
	for (int i = 1; i &lt; n; i ++)
		res *= a[i];
	cout &lt;&lt; res &lt;&lt; endl; 
}

int main()
{
	int T; cin &gt;&gt; T;
	while (T --) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1873/problem/D" target="_blank">https://codeforces.com/contest/1873/problem/D</a><br>
题意：给定一个只有B和W两种字符的字符串，现在有一种操作可以将一个指定大小的区间（大小为k）中所有的字符全部变为W，问对于这个字符串，至少需要几次上述操作才可以将字符串全部变为W字符
思路：我们直接遍历一边字符串即可，在遍历到B字符的时候，指针向后移动k位，如果是W字符，指针向后移动1位即可，最终统计一下遇到B字符的次数即可。
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

typedef long long ll;

void solve()
{
	int n, k;
	cin &gt;&gt; n &gt;&gt; k;
	string s;
	cin &gt;&gt; s;
	
	int res = 0;
	
	for (int i = 0; i &lt; n;)
	{
		if (s[i] == 'B')
		{
			res ++;
			i += k;
		}
		else i++;
	}
	cout &lt;&lt; res &lt;&lt; endl;
}

int main()
{
	int T; cin &gt;&gt; T;
	while (T --) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1873/problem/G" target="_blank">https://codeforces.com/contest/1873/problem/G</a><br>
题意：现在有一个只有A和B两种字符的字符串，有如下两种操作：第一种，可以将AB转化为BC，第二种，可以将BA转化为CB。问最多可以执行上述操作几次
思路：其实一开始想到了之前做过的翻转数字为-1，最后的逻辑是将数字向左右移动，于是这道题就有了突破口了。上述两种操作就可以看做将A和B两种字符交换位置，并且B保持不变，A变为另一种字符C。由于C是无法执行上述操作得到，因此就可以理解为B走过的路就不可以再走了，那么就是说对于一个字符串，最终都会变成B走过的路C。并且只要有B，那么一个方向上所有的A都会被利用转化为C（直到遇到下一个B停止），那么我们就可以将B看做一个独立的个体，他可以选择一个方向上的所有的A并且执行操作将该方向的A全部转化为C，那么在左和右的抉择中，就是要选择A数量最多的方向进行操作，但是如果B的足够多，那就不需要考虑哪个方向了，所有的A都可以获得一次操作机会。现在就转向考虑B需要多少呢，
答案是两种：如果B的数量小于A“块”的数量，其实就是有一块A无法被转化，那么为了让被转化的A数量尽可能的多，就选择A块数量最少的那一块不被转化。如果B的数量&gt;=A块的数量，那么可以保证所有的A都可以被转化为C块，从而最终的答案就是A字符的数量
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

typedef long long ll;

void solve()
{
	string s; cin &gt;&gt; s;
	int cntb = 0, blocka = 0, cnta = 0; // B字符的数量，A连续区间的数量，A字符的个数 
	
	vector&lt;int&gt; a; // 每一个A连续区间中A字符的数量 
	
	for (int i = 0; i &lt; s.size();)
	{
		if (s[i] == 'A')
		{
			int sum = 0;
			while (s[i] == 'A') cnta ++, sum ++, i ++;
			a.emplace_back(sum);
			blocka ++;
		}
		else
		{
			cntb ++;
			i ++;
		}
	}
	
	if (cntb &gt;= blocka) cout &lt;&lt; cnta &lt;&lt; endl;
	else
	{
		sort(a.begin(), a.end());
		cout &lt;&lt; cnta - a[0] &lt;&lt; endl;
	}
}

int main()
{
	int T; cin &gt;&gt; T;
	while (T --) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1891/problem/C" target="_blank">https://codeforces.com/contest/1891/problem/C</a><br>
题意：给定一个序列，其中每一个元素代表一个怪物群中的怪物的数量。现在有两种操作：

<br>选择一个怪物群，杀死其中的一只怪物。同时累加值 
<br>选择一个怪物群，通过之前积累的累加值，一次性杀死当前怪物群中的  只怪物，同时累加值  归零

现在询问杀死所有怪物的最小操作次数
思路：一开始我是分奇偶进行判断的，但是那只是局部最优解，全局最优解的计算需要我们“纵观全局”。
我们可以先做一个假设：假设当前只有一个怪物群，为了最小化操作次数，最优解肯定是先杀死一半的怪物（假设数量为n，则获得累计值x=n），然后无论剩余n个还是n+1个，我们都使用累计值x一次性杀死n个怪物。
现在我们回到原题，有很多个怪物群，易证，最终的最优解也一点是最大化利用操作2，和特殊情况类似，能够利用的一次性杀死的次数就是怪物总数的一半。区别在于：此时不止一个怪物群。那么我们就要考虑累加值如何使用。很容易想到先将怪物群按照数量大小进行排序，关键就在于将累加值从小到大进行使用还是从大到小进行使用。可以发现，对于一个确定的累加值，由于操作2的次数也会算在答案中。那么如果从最小的怪物群开始使用，就会导致操作2的次数变多。因此我们需要从最大值开始进行操作2。
那么最终的答案就是：

<br>首先根据怪物数量的总和计算出最终的累加值s（s=sum/2）
<br>接着我们将怪物群按照数量进行升序排序
<br>然后我们从怪物数量最大的开始进行操作2，即一次性杀死当前怪物群，没进行一次，答案数量+1
<br>最后将答案累加上无法一次性杀死的怪物群中怪物的总数

时间复杂度：
<br>void solve() {
	n = read(); s = 0; res = 0;
	for (int i = 1; i &lt;= n; i++) {
		a[i] = read();
		s += a[i];
	}
 
	s &gt;&gt;= 1;
 
	sort(a + 1, a + n + 1);
 
	for (int i = n; i &gt;= 1; i--) {
		if (s &gt;= a[i]) {
			s -= a[i], a[i] = 0, res++;
		} else if (s) {
			a[i] -= s;
			s = 0;
			res++;
		}
	}
 
	for (int i = 1; i &lt;= n; i++) {
		res += a[i];
	}
 
	printf("%lld\n", res);
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.lanqiao.cn/problems/5889/learning/?contest_id=145" target="_blank">https://www.lanqiao.cn/problems/5889/learning/?contest_id=145</a><br>
声明：谨以此题记录我的第一道正式图论题（存图技巧抛弃了y总的纯数组，转而使用动态数组vector进行建图）e.g.
struct Node {
 int id;		// 当前结点的编号
 int a;	// 属性1
 int b;	// 属性2
};
vector&lt;Node&gt; G[N];

题意：给定一棵树，每个结点代表一个关卡，每个关卡拥有两个属性：通关奖励值val和可通关的最低价值cost。现在从根节点开始尝试通关，每一个结点下面的关卡必须要当前结点通过了之后才能继续闯关。问应该如何选择通关规划使得通过的关卡数最多？
思路：一开始想到的是直接莽bfs，对每一层结点按照cost升序排序进行闯关，然后wa麻了。最后一看正解原来是还不够贪。正确的闯关思路应该是始终选择当前可以闯过的cost最小的关卡，而非限定在了一层上。因此我们最终的闯关顺序是：对于所有解锁的关卡，选择cost最小的关卡进行通关，如果连cost最小的关卡都无法通过就直接结束闯关。那么我们应该如何进行代码的编写呢？分析可得，解锁的关卡都是当前可通过的关卡的所有子结点，而快速获得当前cost最小值的操作可以通过一个堆来维护。
时间复杂度：
<br>const int N = 100010;
typedef long long ll;

struct Node {
    int id;
    int val;
    int cost;
    // 有趣的重载
    bool operator&lt; (const Node&amp; t) const {
        return this-&gt;cost &gt; t.cost;
    }
};

int n, p;
ll res;
vector&lt;Node&gt; G[N];
priority_queue&lt;Node&gt; q;

void bfs() {
    q.push(G[0][0]);

    while (q.size()) {
        Node now = q.top();
        q.pop();
        if (p &gt;= now.cost) {
            res++;
            p += now.val;
            for (auto&amp; child: G[now.id]) {
                q.push(child);
            }
        } else {
            break;
        }
    }
}

void solve() {
    cin &gt;&gt; n &gt;&gt; p;
    for (int i = 1; i &lt;= n; i++) {
        int fa, v, c;
        cin &gt;&gt; fa &gt;&gt; v &gt;&gt; c;
        G[fa].push_back({i, v, c});
    }
    bfs();
    cout &lt;&lt; res &lt;&lt; "\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.lanqiao.cn/problems/5890/learning/?contest_id=145" target="_blank">https://www.lanqiao.cn/problems/5890/learning/?contest_id=145</a><br>
题意：给定一棵无向树，边权为正。现在询问在访问到每一个结点的情况下最小化行走的路径长度
思路：首先我们不管路径长度的长短，我们直接开始串门。可以发现，我们一点会有访问的起点和终点，那么在起点到终点的这条路上，可能会有很多个分叉，对于每一个分叉，我们都需要进入再返回来确保分叉中的结点也被访问到，那么最终的路径长度就是总路径长度的2倍 - 起点到终点的距离，知道了这个性质后。我们可以发现，路径的总长度是一个定值，我们只有最大化起点到终点距离才能确保行走路径长度的最小值。那么问题就转化为了求解一棵树中，最长路径长度的问题。即求解树的直径的问题。
树的直径：首先我们反向考虑，假设知道了直径的一个端点，那么树的直径长度就是这棵树以当前结点为根的深度。那么我们就需要先确定一个直径的端点。不难发现，对于树中的任意一个结点，距离它最远的一个（可能是两个）结点一定是树的直径的端点。那么问题就迎刃而解了。
为了降低代码量，我们可以设置一个dist数组来记录当前结点到根的距离。

<br>在确定直径端点的时候，选择任意一个结点为根节点，然后维护dist数组，最终dist[i~n]中的最大值对应的下标maxi就是直径的一个端点。
<br>接着在计算直径长度的时候，以maxi为树根，再来一次上述的维护dist数组的过程，最终dist[1~n]中的最大值就是树的直径的长度

时间复杂度：
<br>const int N = 100010;
typedef long long ll;

struct Node {
	int id;
	ll w;
};

int n;
vector&lt;Node&gt; G[N];
bool st[N];
ll sum, d, dist[N];

/**
 * @note 计算当前所有子结点到当前点的距离
 * @param now 当前点的编号
 * @param x 上一个点到当前点的距离
 */
void dfs(int now, ll x) {
	if (!st[now]) {
		st[now] = true;
		dist[now] = x;
		for (int i = 0; i &lt; G[now].size(); i++) {
			int ch = G[now][i].id;
			dfs(ch, x + G[now][i].w);
		}
	}
}

void solve() {
	cin &gt;&gt; n;
	for (int i = 0; i &lt; n - 1; i++) {
		int a, b, w;
		cin &gt;&gt; a &gt;&gt; b &gt;&gt; w;
		sum += w;
		G[a].push_back({b, w});
		G[b].push_back({a, w});
	}

	// 以1号点为根，计算所有点到1号点的距离
	dfs(1, 0);

	memset(st, 0, sizeof st);

	// 到1号点最远的那个点的编号 maxi，即直径的一个端点
	int maxi = 0;
	for (int i = 1; i &lt;= n; i++) {
		if (dist[i] &gt; dist[maxi]) {
			maxi = i;
		}
	}

	// 以直径的一个端点 maxi 为根，计算所有点到 maxi 点的距离
	dfs(maxi, 0);

	// 找到直径长度
	for (int i = 1; i &lt;= n; i++) {
		d = max(d, dist[i]);
	}

	cout &lt;&lt; sum * 2 - d &lt;&lt; "\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://vijos.org/d/nnu_contest/p/1532" target="_blank">https://vijos.org/d/nnu_contest/p/1532</a><br>
题意：现在已知一个初始值R，现在给定了n个P值，选择其中的合适的值，使得最终的  最大
思路：首先一点就是我们一定要选择P比当前R大的值，接下来就是选择合适的P使得最终迭代出来的R'最大。首先我们知道，对于筛选出来的比当前R大的P集合，任意选择其中的一个P，都会让R增大，但是不管增加多少都是不会超过选择的P。那么显然，如果筛选出来的P集合是一个递增序列，那么就可以让R不断的增加。但是这一定是最大的吗？我们不妨反证一下，现在我们有两个P，分别为x，y，其中 。
那么按照上述思路，首先就是 

接着就是 

反之，首先选择一个较大的P=y，再选择一个较小的P=x，即首先就是

此时我们还不一点可以继续选择x，因为此时的R'可能已经超过了x的值，那么我们按照最优的情况计算，可以选择x，那么就是

可以发现

即会使得最终的答案变小。因此最优的策略就是按照增序进行叠加计算
注意点：
四舍五入的语句
cout &lt;&lt; (int)(res + 0.5) &lt;&lt; "\n";

<br>void solve() {
	cin &gt;&gt; n &gt;&gt; k;
	for (int i = 0; i &lt; n; i++) {
		cin &gt;&gt; a[i];
	}

	sort(a, a + n);

	int i = 0;
	for (; i &lt; n; i++) {
		if (a[i] &gt; k) {
			break;
		}
	}

	double res = k;

	for (; i &lt; n; i++) {
		res = (res * 3.0 + a[i] * 1.0) / 4.0;
	}

	cout &lt;&lt; (int)(res + 0.5) &lt;&lt; "\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5380/" target="_blank">https://www.acwing.com/problem/content/5380/</a><br>
题意：给定  个运货订单，每个订单需要运送一定量的货物，同时给予一定量的报酬。现在有  个卡车进行运送，每个卡车有运送容量。需要合理规划卡车的装配，使得最终获得的总报酬最大。有以下约束条件：

<br>每一个订单只能用一辆货车运送
<br>每一辆货车只能运送不超过最大容量的货物
<br>每一辆货车只能运送一次
<br>每一辆货车在装得下的情况下只能装运一个订单

思路：一开始尝试采用 01 背包的思路，但是题目中货物是否可以被运送是取决于卡车的装载的。思考无果后考虑贪心。

<br>
为了让总收益最大，很显然报酬越多，就越优先选择该订单

<br>
在报酬一致时，货物量越少，就越优先选择该订单

<br>
按照上述规则对订单排序后，我们需要安排合理的货车进行运输。我们优先将运输量小的货车安排给合适的订单。因为运输量大的货车既可以满足当前订单，同样也满足后续的订单，那么为了最大化增加利润，就需要在运输量小的货车满足当前订单时，保留运输量大的货车用于后续的订单。我们可以画一个图进一步理解为什么这么安排货车进行运输：
  <img style="zoom: 50%;" alt="image-20231223222627134" src="https://s2.loli.net/2023/12/23/djYO9h43PLCrQ1t.png" referrerpolicy="no-referrer">
  图例：我们按照上述红笔的需要进行货车的选择进行运输
  如果红色序号顺序变掉了，则就不能将上述图例中的 6 个订单全部运输了

<br>
时间复杂度 


<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 1010;

struct Item {
	int id, weight, money;
	bool operator&lt; (const Item&amp; t) const {
		if (money != t.money) return money &gt; t.money;
		else return weight &lt; t.weight;
	}
} item[N];

struct Car {
	int id, v;
	bool operator&lt; (const Car&amp; t) const {
		return v &lt; t.v;
	}
} car[N];

pair&lt;int, int&gt; res[N];
bool vis[N];
int cnt, sum;

void solve() {
	int n;
	cin &gt;&gt; n;
	for (int i = 1; i &lt;= n; i++) {
		item[i].id = i;
		cin &gt;&gt; item[i].weight &gt;&gt; item[i].money;
	}

	int k;
	cin &gt;&gt; k;
	for (int i = 1; i &lt;= k; i++) {
		car[i].id = i;
		cin &gt;&gt; car[i].v;
	}

	sort(item + 1, item + n + 1);
	sort(car + 1, car + k + 1);

	for (int i = 1; i &lt;= n; i++) {
		for (int j = 1; j &lt;= k; j++) {
			if (!vis[j] &amp;&amp; car[j].v &gt;= item[i].weight) {
				sum += item[i].money;
				vis[j] = true;
				res[cnt++] = {item[i].id, car[j].id};
				break;
			}
		}
	}

	cout &lt;&lt; cnt &lt;&lt; " " &lt;&lt; sum &lt;&lt; "\n";

	for (int i = 0; i &lt; cnt; i++) {
		cout &lt;&lt; res[i].first &lt;&lt; " " &lt;&lt; res[i].second &lt;&lt; "\n";
	}
}

int main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5182/" target="_blank">https://www.acwing.com/problem/content/5182/</a><br>
存储不想同组和想同组的人员信息：存入数组，数据类型为一对字符串<br>
存储所有的组队信息：存入哈希表，数据类型为“键:字符串”“值:一对字符串”<br>
想要知道最终的分组情况，只需要查询数组中的队员情况与想同组 or 不想同组的成员名字是否一致即可<br>
时间复杂度 ，空间复杂度 
<br>#include &lt;iostream&gt;
#include &lt;vector&gt;
#include &lt;unordered_map&gt;
using namespace std;

int main()
{
	int x;
	cin &gt;&gt; x;
	
	vector&lt;pair&lt;string, string&gt;&gt; X(x);
	
	for (int i = 0; i &lt; x; i ++)
		cin &gt;&gt; X[i].first &gt;&gt; X[i].second;
	
	int y;
	cin &gt;&gt; y;
	
	vector&lt;pair&lt;string, string&gt;&gt; Y(y);
	
	for (int i = 0; i &lt; y; i ++)
		cin &gt;&gt; Y[i].first &gt;&gt; Y[i].second;
		
	int sum;
	cin &gt;&gt; sum;
	
	unordered_map&lt;string, pair&lt;string, string&gt;&gt; a;
	
	for (int i = 0; i &lt; sum; i ++)
	{
		string s, t, p;
		cin &gt;&gt; s &gt;&gt; t &gt;&gt; p;
		a[s] = {t, p};
		a[t] = {s, p};
		a[p] = {s, t};
	}
	
	int res = 0;
	
	// 想同组 
	for (int i = 0; i &lt; x; i ++)
	{
		string s = X[i].first, t = X[i].second;
		if (a[s].first != t &amp;&amp; a[s].second != t)
			res ++;
	}
	
	// 不想同组 
	for (int i = 0; i &lt; y; i ++)
	{
		string s = Y[i].first, t = Y[i].second;
		if (a[s].first == t || a[s].second == t)
			res ++; 
	}
	
	cout &lt;&lt; res &lt;&lt; endl; 
	
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5167/" target="_blank">https://www.acwing.com/problem/content/5167/</a><br>

<br>每一个1都有三个边
<br>对于每一个1，判断左右是否也有1，如果有则减掉一条边
<br>对于奇数位的1，判断上 | 下是否有1，如果有也要减掉一条边

<br>#include &lt;bits/stdc++.h&gt;

using namespace std;

const int N = 200010;

int n;
int a[N], b[N];

int main()
{
	cin &gt;&gt; n;
	
	int res = 0;
	
	for (int i = 1; i &lt;= n; i ++)
	{
		cin &gt;&gt; a[i];
		if (a[i] == 1) res += 3;
	}
	
	for (int i = 1; i &lt;= n; i ++)
	{
		cin &gt;&gt; b[i];
		if (b[i] == 1) res += 3;
	}
	
	for (int i = 1; i &lt;= n; i ++)
	{
		if (a[i])
		{
			if (a[i - 1]) res --;
			if (a[i + 1]) res --;
			if (i % 2 == 1)
			{
				if (b[i] == 1) res --;
			}
		}
	}
	
	for (int i = 1; i &lt;= n; i ++)
	{
		if (b[i])
		{
			if (b[i - 1]) res --;
			if (b[i + 1]) res --;
			if (i % 2 == 1)
			{
				if (a[i] == 1) res --;
			}
		}
	}
	
	cout &lt;&lt; res &lt;&lt; endl;
	
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1867/problem/B" target="_blank">https://codeforces.com/contest/1867/problem/B</a><br>
题意：给定一个二进制字符串s长度为n，现在需要构造一个长度为n+1的字符串t，对于t中的每一位，即0&lt;=i&lt;=n的t[i]，如果将s中的数字0变为1或1变为0一共i次后，s成为了一个回文串，那么t[i]就是1，如果成为不了回文串就是0
输出：给出最终构造的t字符串
注意点：对于回文问题，多考虑双指针算法
思路：想要在改变了x（0&lt;=x&lt;=n）个数位后成为一个回文串，那么就要先统计当前的字符串s的回文情况。假如对称位置相同，那么可以不消耗改变次数或者消耗两次改变次数，假如对称位置不同，那么就必须要消耗一次改变次数。同时需要特判的是假如原串的字符数为奇数，那么中间的位置可以提供一个缓冲的机会，即假如被前面的两种情况消耗掉改变次数之后，还剩一次改变次数，那么就可以改变中间的字符。当然了假如改变完了中间的字符之后还是多了改变次数，那么就无法使得原串为回文串了。
时间复杂度：
<br>#include &lt;iostream&gt;
using namespace std;

int main()
{
	int T;
	cin &gt;&gt; T;
	
	while (T--)
	{
		int n; cin &gt;&gt; n;
		string s; cin &gt;&gt; s;
		
         // 判断原串是否为奇数个字符
		bool odd = false;
		if (n % 2) odd = true;
		
         // 双指针统计原串的对应情况
		int l = 0, r = n - 1;
		int same = 0, dif = 0;
		while (l &lt; r)
		{
			if (s[l] == s[r]) same ++;
			else dif ++;
			l ++, r --;
		}
		
		// 对当前s的x个数位进行转换数字 
		for (int x = 0; x &lt;= n; x ++)
             // 不同的对应位是一定要改变的
			if (x &lt; dif) cout &lt;&lt; 0;
			else
			{
				int aft = x - dif; // aft为消耗掉不同对应位次数后剩余的改变次数
				for (int i = 2 * same; i &gt;= 0; i -= 2) // 时间复杂度为log n
					if (aft &gt;= i)
					{
						aft -= i;
						break;
					}
				
                  // 此时为消耗掉不同对应位和相同对应位次数之后的剩余改变次数
				if (aft &gt; 1) cout &lt;&lt; 0;
				else if (aft == 1)
				{
					if (odd) cout &lt;&lt; 1;
					else cout &lt;&lt; 0;
				}
				else cout &lt;&lt; 1;
			}
		
		cout &lt;&lt; endl;
	}
	
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1873/problem/C" target="_blank">https://codeforces.com/contest/1873/problem/C</a><br>
题意：给了一个定尺寸的正方形，类似于靶子的得分机制，对于最终给出的打靶情况，计算最终的得分
思路：我们可以根据下标来观察规律，比如1分的靶位，横坐标都是0或9，或者纵坐标都是0或9，其余的得分同理，但是会出现一些重复，我们开一个相同尺寸的二维st表即可解决这个重复计数的问题
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

typedef long long ll;

void solve()
{
	vector&lt;string&gt; a(10);
	for (int i = 0; i &lt; 10; i ++)
		cin &gt;&gt; a[i];
	
	bool st[10][10] {};
	
	int res = 0;
	
	for (int i = 0; i &lt; 10; i ++)
		for (int j = 0; j &lt; 10; j ++)
		{
			if (i == 0 || i == 9 || j == 0 || j == 9) if (a[i][j] == 'X') res += 1, st[i][j] = true;
			if (i == 1 || i == 8 || j == 1 || j == 8) if (a[i][j] == 'X' &amp;&amp; !st[i][j]) res += 2, st[i][j] = true;
			if (i == 2 || i == 7 || j == 2 || j == 7) if (a[i][j] == 'X' &amp;&amp; !st[i][j]) res += 3, st[i][j] = true;
			if (i == 3 || i == 6 || j == 3 || j == 6) if (a[i][j] == 'X' &amp;&amp; !st[i][j]) res += 4, st[i][j] = true;
			if (i == 4 || i == 5 || j == 4 || j == 5) if (a[i][j] == 'X' &amp;&amp; !st[i][j]) res += 5, st[i][j] = true;
		}
	cout &lt;&lt; res &lt;&lt; endl;
}

int main()
{
	int T; cin &gt;&gt; T;
	while (T --) solve();
	return 0;
}
<br><br><br>
题意：给定  个数，问能否找到一个数 ，使得 
原始思路：起初我的思路是二分，我们需要寻找一个数使得n个数相乘为原数组所有元素之积，那么我们预计算出所有数之积，并且在数组最大值和最小值之间进行二分，每次二分出来的数计算n次方进行笔比较即可。但是有一个很大的问题是，数据量是 ，而数字最大为 ，最大之积为  吗？不是！最大之和才是，最大之积是 
最终思路：我们可以将选数看做多个水池匀水的过程。现在每一个水池的水高都不定，很显然我们一定可以一个值使得所有的水池的高度一致，即 。但是我们最终的数字是一个整数，显然不可以直接求和然后除以n，那么应该如何分配呢？我们知道水池之所以可以直接除以n，是因为水的最小分配单位是无穷小，可以随意分割；而对于整数而言，最小分配单位是什么呢？答案是质因子！为了通过分配最小单位使得最终的“水池高度一致”，我们需要让每一个“水池”获得的数值相同的质因子数量相同。于是我们只需要统计一下数组中所有数的质因子数量即可。如果对于每一种质因子的数量都可以均匀分配每一个数（即数量是n的整数倍），那么就一定可以找到这个数使得 
<br>void solve() {
	int n;
	cin &gt;&gt; n;

	// 统计所有数字的所有质因数
	unordered_map&lt;int, int&gt; m;
	for (int i = 0; i &lt; n; i++) {
		int x;
		cin &gt;&gt; x;

		for (int k = 2; k &lt;= x / k; k++) {
			if (x % k == 0) {
				while (x % k == 0) {
					m[k]++;
					x /= k;
				}
			}
		}

		if (x &gt; 1) {
			m[x]++;
		}
	}

	// 查看每一种质因数是否是n的整数倍
	for (auto&amp; x: m) {
		if (x.second % n) {
			cout &lt;&lt; "No\n";
			return;
		}
	}

	cout &lt;&lt; "Yes\n";
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1891/problem/B" target="_blank">https://codeforces.com/contest/1891/problem/B</a><br>
题意：给点序列a和b，对于b中的每一个元素 ，如果a中的元素  能够整除 ，则将  加上 。给出最后的a序列
思路：我们很容易就想到暴力的做法，即两层循环，第一层枚举b中的元素，第二层枚举a中的元素，如果a中的元素能够整除2
的bi次方，就将a中相应的元素加上一个值即可。但是时间复杂度肯定过不了。于是我们考虑优化。
时间复杂度：
优化：现在我们假设a中有一个数  是  的整数倍（其中  是b序列中第一个枚举到的能够让  整除的数），那么就有 ，那么  就要加上 ，于是  就变为了 。此后  就一定是 的倍数。

<br>
因此我们需要做的就是首先找到b序列中第一个数x，能够在a中找到数是  的整数倍

这一步可以这样进行：对于a中的每一个数，我们进行30次循环统计当前数是否是  的倍数，如果是就用哈希表记录当前的 。最后我们在遍历寻找x时，只需要查看当前的x是否被哈希过即可


<br>
接着我们统计b序列中从x开始的严格降序序列c（由题意知，次序列的数量一定  30，因为b序列中数值的值域为 ）

<br>
最后我们再按照原来的思路，双重循环a序列和c序列即可


时间复杂度：
<br>void solve() {
	int n, m;
	cin &gt;&gt; n &gt;&gt; m;

	vector&lt;int&gt; a(n + 1), b(m + 1);
	unordered_map&lt;int, int&gt; ha;

    // 边读边哈希
	for (int i = 1; i &lt;= n; i++) {
		cin &gt;&gt; a[i];
		for (int j = 30; j &gt;= 1; j--) {
			if (a[i] % (1 &lt;&lt; j) == 0) {
				ha[j]++;
			}
		}
	}

	for (int i = 1; i &lt;= m; i++) {
		cin &gt;&gt; b[i];
	}

	// 寻找b中第一个能够让a[j]整除的数b[flag]
	int flag = -1;
	for (int i = 1; i &lt;= m; i++) {
		if (ha[b[i]]) {
			flag = i;
			break;
		}
	}

    // 特判
	if (flag == -1) {
		for (int j = 1; j &lt;= n; j++) {
			cout &lt;&lt; a[j] &lt;&lt; " \n"[j == n];
		}
		return;
	}

    // 寻找b中从flag开始的严格单调递减的序列c
	vector&lt;int&gt; c;
	c.push_back(b[flag]);
	for (; flag &lt;= m; flag++) {
		if (b[flag] &lt; c.back()) {
			c.push_back(b[flag]);
		}
	}

    // 暴力循环一遍即可
	for (int j = 1; j &lt;= n; j++) {
		for (int k = 0; k &lt; c.size(); k++) {
			if (a[j] % (1 &lt;&lt; c[k]) == 0) {
				a[j] += 1 &lt;&lt; (c[k] - 1);
			}
		}
	}

	for (int j = 1; j &lt;= n; j++) {
		cout &lt;&lt; a[j] &lt;&lt; " \n"[j == n];
	}
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.lanqiao.cn/problems/8732/learning/?contest_id=147" target="_blank">https://www.lanqiao.cn/problems/8732/learning/?contest_id=147</a><br>
题意：给定  个数初始化为 ，现在给定  个位置，每个位置给定两个参数 ，表示从第  个数开始连续  个数 。有以下两种约束

<br>如果连续  个数越界了，则越界的部分就不 
<br>一个位置最多只能被一种  对应的种类 

思路：

<br>现在假设只有一个种类的p，如果不考虑上述第二个条件的约束，那么就是纯差分。如果考虑了，那么我们从左到右考虑+1区间覆盖的问题，就需要判断当前位置是否被上一个+1区间覆盖过，解决办法就是记录上一个区间覆盖的起始点or终止点，这里选择起始点。
<br>现在我们考虑多个种类的p，那么就是分种类重复上述思路即可，因为不同种类之间是没有约束上的冲突的。那么如何分种类解决呢，我们可以对输入的q个位置的所有p、k参数进行排序，p为第一关键词，k为第二个关键词。
<br>时间复杂度：

<br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 100010;

struct node {
	int p, k; // 第p种宝石丢在了第k个坑
	bool operator&lt;(const node &amp;t) const {
		if (p == t.p) {
			return k &gt; t.k;
		} else {
			return p &gt; t.p;
		}
	}
};

int n, m, q, s[N]; // n个坑，m种宝石，q个采集的宝石，s[i]表示第i种宝石的能量
vector&lt;int&gt; last(N, -1e6); // last[i]表示上一个第i种宝石的位置
int a[N], b[N]; // a[]为原数组，b[]为差分数组
priority_queue&lt;node&gt; que;

void solve() {
	cin &gt;&gt; n &gt;&gt; m &gt;&gt; q;
	for (int i = 1; i &lt;= m; i++) {
		cin &gt;&gt; s[i];
	}

	while (q--) {
		int p, k;
		cin &gt;&gt; p &gt;&gt; k;
		que.push({p, k});
	}

	while (que.size()) {
		auto h = que.top();
		que.pop();
		int p = h.p, k = h.k; // 第p种宝石丢在了第k个坑

		int l, r;
		if (k - last[p] &gt;= s[p]) {
			// 和上一种没有重叠
			l = k, r = min(n, k + s[p] - 1);
			b[l]++, b[r + 1]--;
			last[p] = k;
		} else {
			// 和上一种有重叠
			l = last[p] + s[p];
			r = min(n, k + s[p] - 1);
			if (l &lt;= r) {
				b[l]++, b[r + 1]--;
			}
			last[p] = k;
		}
	}

	for (int i = 1; i &lt;= n; i++) {
		a[i] = a[i - 1] + b[i];
		cout &lt;&lt; a[i] &lt;&lt; " \n"[i == n];
	}
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5273/" target="_blank">https://www.acwing.com/problem/content/5273/</a><br>
题意：给定长度为n的序列，问将这个序列拼接n次后，最长严格递增子序列的长度为多少？
思路：其实最终的思路很简单，讲题目转化为在每个序列中选一个数，一共可以选出多少个不同的数。但是在产生这样的想法之前，先讲一下我的思考过程。我将序列脑补出一幅散点折线图，然后将这些点投影到y轴上，最终投影点的个数就是答案的数量，但是投影会有重合，因此答案最多就是n个数，最少1个数，从而想到就是在n个序列中选数，选的数依次增大即可，相信的就是一个求序列不重复数的个数的过程。去重即可。
注意点：由于C++的STL的unique函数的前提是一个有序的序列，因此在unique之前需要将序列进行排序。
时间复杂度：
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

int main()
{
    int T;
    cin &gt;&gt; T;

    while (T--)
    {
        int n;
        cin &gt;&gt; n;

        vector&lt;int&gt; a;
        for (int i = 0; i &lt; n; i++)
        {
            int x;
            cin &gt;&gt; x;
            a.emplace_back(x);
        }

        // 去重老套路，string也可以用
        sort(a.begin(), a.end());
        a.erase(unique(a.begin(), a.end()), a.end());

        cout &lt;&lt; a.size() &lt;&lt; endl;
    }

    return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5280/" target="_blank">https://www.acwing.com/problem/content/5280/</a><br>
题意：在一个序列中如何选择一个三元组，使得三个数之积最小，给出情况数
思路：首先很容易得知，这三个数一定是序列排序后的前三个数，那么就是对这三个数可能的情况进行讨论

<br>情况1：前三个数都相等 （2 2 2 2 2 4 5），则就是在所有的 a[0] 中选3个，情况数就是 
<br>情况2：前三个数中有两个数相等，由于数组经过了排序，因此情况2分为两种情况

<br>前两个数相等 （1 1 3 3 3 5），则就是在所有的 a[2] 中选1个，情况数就是 
<br>后两个数相等 （1 2 2 2 4 6），则就是在所有的 a[1] 中选2个，情况数就是 


<br>情况3：前三个数中全都不相等 （1 2 4 4 4 5 7），这就是在所有的 a[2] 中选1个，情况数就是 

可以发现上述情况2的第一种和情况3的答案相等，故分为三种情况即可。
<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

typedef long long ll;

// 计算组合数 C_{a}^{b}
ll calc(ll a, ll b) {
    ll fz = 1, fm = 1;
    for (int i = 0, num = a; i &lt; b; i++, num--) {
        fz *= num;
    }
    for (int i = 1; i &lt;= b; i++) {
        fm *= i;
    }
    return fz / fm;
}

int main() {
    int n; cin &gt;&gt; n;
    vector&lt;int&gt; a(n);
    for (int i = 0; i &lt; n; i++) {
        cin &gt;&gt; a[i];
    }
    
    sort(a.begin(), a.begin() + n);
    
    ll res = 0;
    
    if (a[0] == a[1] &amp;&amp; a[1] == a[2]) {
        // 情况1：前三个数都相等（2 2 2 2 2 4 5），则就是在所有的a[0]中选3个
        ll cnt = count(a.begin(), a.begin() + n, a[0]);
        res = calc(cnt, 3);
    } else if (a[0] == a[1] || (a[0] != a[1] &amp;&amp; a[1] != a[2])) {
        // 情况2：前两个数相等（1 1 3 3 3 4 5） or 三个数都不相等（1 2 4 4 4 5 7），则就是在所有的a[2]中选2个
        res = count(a.begin(), a.begin() + n, a[2]);
    } else {
        // 情况3：后两个数相等（1 2 2 2 4 6），则就是在所有的a[1]中选2个
        ll cnt = count(a.begin(), a.begin() + n, a[1]);
        res = calc(cnt, 2);
    }
    
    cout &lt;&lt; res &lt;&lt; "\n";
    
    return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5281/" target="_blank">https://www.acwing.com/problem/content/5281/</a><br>
题意：给定一个排列为1~n，定义一个数“有价值”为当前数的前面没有数比当前的数大。现在需要删除一个数，使得序列中增加尽可能多的“有价值”的数，如果这个数有多个，则删除最小的那个数
最开始想到的思路：枚举每一个数，如果删除，则序列中会增加多少个“有价值”的数，算法设计如下：

<br>首先判断每一个数是否是有价值的数

<br>创建一个变量来记录当前数的前面序列的最大值
<br>比较判断当前数和前方最大值的关系，如果小于，则无价值，反之有价值


<br>接着枚举每一个数，如果删除该数，则序列会损失多少个有价值的数

<br>首先判断自己是不是有价值的数，如果是，则当前损失值 -1
<br>接着判断删除当前数对后续的影响 :star: ：我们在枚举后续数的时候，起始的newd（前驱除掉a[i]的最大值）应该就是当前的d，只不过需要使用新变量newd而非d是因为这一步与整体无关，不可以改变整体的d。否则会出现错误，比如对于4 3 5 1 2，如果我们在枚举后续数的时候直接对d进行迭代，那么在第一轮d就会被更新为5，就再也无法更新了


<br>最终根据维护的损失值数组cnt即可求解
<br>时间复杂度 


优化的思路：

<br>
同样是枚举每一个数，如果当前数字是有价值的数，那么cnt[a[i]]就 -1

<br>取决于当前数字前面是否有比它大的数，如果没有，那么就是有价值的


<br>
接下来我们不需要遍历j=i+1到j=n-1，而是讨论当前数a[i]不是有价值数时的所有情况。现在我们想要维护cnt数组。不难发现，对于某个位置上的数a[k]，能否成为有价值的数只取决于前排序列是否有比他大的数以及大的数的个数。那么理论上我们在枚举a[i]的时候维护cnt[1~i-1]就可以确保cnt数组的正确性了。

<br>假设a[k]的前排有一个比它大的数d：那么把d去掉之后，a[k]就会从无价值变为有价值
<br>假设a[k]的前排有至少两个比它大的数d1,d2,...dj...：那么不管去掉哪一个 ，我们都没法让a[k]变得有价值

如此一来，cnt数组就可以正确维护了

<br>
最终根据维护的损失值数组cnt即可求解

<br>
时间复杂度 


<br>暴力：<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

int main() {
	int n;
	cin &gt;&gt; n;
	
	vector&lt;int&gt; a(n);
	for (int i = 0; i &lt; n; i++) {
		cin &gt;&gt; a[i];
	}
	
	// 判断每个数是否是有价值的数
	int d = 0; // 前方序列中的最大值
	vector&lt;bool&gt; is_val(n + 1);
	for (int i = 0; i &lt; n; i++) {
		if (a[i] &gt; d) {
			is_val[a[i]] = true;
			d = a[i];
		}
	}
	
	// 枚举每一个数，计算删除该数之后会增加的有价值的数的个数 
	d = 0; // 同上
	vector&lt;int&gt; cnt(n + 1); // cnt[x]表示删除数x之后可以增加的有价值的数的个数
	for (int i = 0; i &lt; n; i++) {
		if (is_val[a[i]]) {
			cnt[a[i]]--;
		}
		
		int newd = d; // 去掉a[i]后的前方序列的最大值 newd
		for (int j = i + 1; j &lt; n; j++) {
			if (is_val[a[j]]) {
				if (a[j] &lt; newd) {
					cnt[a[i]]--;
				}
			} else {
				if (a[j] &gt; newd) {
					cnt[a[i]]++;
				}
			}
			if (a[j] &gt; newd) {
			    newd = a[j];
			}
		}
		
		// 更新前方序列的最大值 d
		if (a[i] &gt; d) {
			d = a[i];
		}
	}

	// 找出可以增加的有价值的数的最大个数 ma
	int ma = -n - 1;
	for (int i = 0; i &lt; n; i++) {
		if (cnt[a[i]] &gt; ma) {
			ma = max(ma, cnt[a[i]]);
		}
	}

	// 答案是满足个数的最小的数字
	int res = 0;
	for (int i = 1; i &lt;= n; i++) {
		if (cnt[i] == ma) {
			res = i;
			break;
		}
	}
	
	cout &lt;&lt; res &lt;&lt; "\n";
	
	return 0;
}
<br>优化：<br>#include &lt;bits/stdc++.h&gt;
using namespace std;

int main() {
    int n; 
    cin &gt;&gt; n;
    
    vector&lt;int&gt; a(n);
    for (int i = 0; i &lt; n; i++) {
        cin &gt;&gt; a[i];
    }
     
    vector&lt;int&gt; cnt(n + 1);     // cnt[x]表示删除数x之后可以增加的有价值的数的个数
    int d1 = 0, d2 = 0;         // d1: 最大值, d2: 次大值
    for (int i = 0; i &lt; n; i++) {
        if (a[i] &gt; d1) {
            // 前方序列 没有数比当前的数大
            cnt[a[i]]--;
        } else if (a[i] &gt; d2) {
            // 前方序列 只有一个数比当前大
            cnt[d1]++;
        }
        
        // 更新最大值d1和次大值d2
        if (a[i] &gt; d1) d2 = d1, d1 = a[i];
        else if (a[i] &gt; d2) d2 = a[i];
    }
    
    // 找到可以增加的最大值
    int ma = -1;
    for (int i = 1; i &lt;= n; i++) {
        if (cnt[i] &gt; ma) {
            ma = cnt[i];
        }
    }
    
    // 取元素的最小值
    int res = n + 1;
    for (int i = 1; i &lt;= n; i++) {
        if (cnt[i] == ma) {
            res = i;
            break;
        }
    }
    
    cout &lt;&lt; res &lt;&lt; "\n";
    
    return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://codeforces.com/contest/1891/problem/A" target="_blank">https://codeforces.com/contest/1891/problem/A</a><br>
题意：给定一个序列，现在需要通过以下方法对序列进行升序排序

<br>可以选择前  个数执行  的操作（保证不会越界的情况下）

现在需要确定给定的序列经过k次上述后能否变为升序序列
思路：我们可以将每  个数看成一个数，可以不断的-1。那么可以发现执行一定的次数后，一定可以实现升序序列。但是现在是  个数，那么只需要这相邻区段的数是升序即可，即  之间的数是升序即可。按区间进行判断即可
时间复杂度：
<br>void judge(vector&lt;int&gt;&amp; a, int l, int r, bool&amp; ok, int n) {
	for (int i = l + 1; i &lt;= r &amp;&amp; i &lt;= n; i++) {
		if (a[i] &lt; a[i - 1]) {
			ok = false;
			return;
		}
	}
}
 
void solve() {
	int n;
	cin &gt;&gt; n;
 
	vector&lt;int&gt; a(n + 1);
	for (int i = 1; i &lt;= n; i++) {
		cin &gt;&gt; a[i];
	}
 
	bool ok = true;
	judge(a, 3, 4, ok, n);
	judge(a, 5, 8, ok, n);
	judge(a, 9, 16, ok, n);
	judge(a, 17, 20, ok, n);
 
	if (ok) {
		cout &lt;&lt; "YES\n";
	} else {
		cout &lt;&lt; "NO\n";
	}
}
<br><br><br>class Int : public std::vector&lt;int&gt; {
public:
	Int(int n = 0) {
		push_back(n);
		check();
	}

	Int&amp; check() {
		for (int i = 1; i &lt; size(); ++i) {
			(*this)[i] += (*this)[i - 1] / 10;
			(*this)[i - 1] %= 10;
		}
		while (back() &gt;= 10) {
			push_back(back() / 10);
			(*this)[size() - 2] %= 10;
		}
		return *this;
	}

	friend std::istream&amp; operator&gt;&gt;(std::istream&amp; in, Int&amp; n) {
		std::string s;
		in &gt;&gt; s;
		n.clear();
		for (int i = s.size() - 1; i &gt;= 0; --i) n.push_back(s[i] - '0');
		return in;
	}

	friend std::ostream&amp; operator&lt;&lt;(std::ostream&amp; out, const Int&amp; n) {
		if (n.empty()) out &lt;&lt; 0;
		for (int i = n.size() - 1; i &gt;= 0; --i) out &lt;&lt; n[i];
		return out;
	}

	friend Int&amp; operator+=(Int&amp; a, const Int&amp; b) {
		if (a.size() &lt; b.size()) a.resize(b.size());
		for (int i = 0; i != b.size(); ++i) a[i] += b[i];
		return a.check();
	}

	friend Int operator+(Int a, const Int&amp; b) {
		return a += b;
	}
};
<br>​	]]></description><link>technology\collegeproject\算法设计\算法.html</link><guid isPermaLink="false">Technology/CollegeProject/算法设计/算法.md</guid><pubDate>Tue, 16 Jan 2024 03:33:58 GMT</pubDate><enclosure url="https://pic.leetcode.cn/1690625058-WYmZtD-subset_sum_i_pruning.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://pic.leetcode.cn/1690625058-WYmZtD-subset_sum_i_pruning.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[算法复习]]></title><description><![CDATA[ 
 <br><br>#include &lt;iostream&gt;
#include &lt;iomanip&gt;
#include &lt;vector&gt;
#include &lt;queue&gt;
using namespace std;

struct CW
{
	char c;  // 字符
	int  w;  // 权重
};
struct HuffNode
{
	char c;  // 字符
	int  w;  // 权重
	int lchild,rchild,parent; 
};

struct Node
{
	int w;  // 权重
	int i;  // 下标
	Node(int w,int i):w(w),i(i){}
};
bool operator&gt;(const Node &amp;n1,const Node &amp;n2)
{
	return n1.w&gt;n2.w;
}

// 编码个数 = n
// 时间复杂度：O(n*n) -&gt; O(n*log2(n))
// 空间复杂度：O(1)   -&gt; O(n)
void CreateHT(CW cw[],int n, HuffNode HT[])
{
	priority_queue&lt;Node,vector&lt;Node&gt;, greater&lt;Node&gt; &gt;  Q; // 小根堆
	int i=0;
	for(; i&lt;n; i++)
	{
		HT[i].c=cw[i].c,
		HT[i].w=cw[i].w,
		HT[i].lchild=HT[i].rchild=HT[i].parent=-1;
		Q.push( Node(HT[i].w, i) );  // 进队列
	}
	for(; i&lt;2*n-1; i++)//哈夫曼树必然只有两种节点，一种是叶子结点，一种是有两个分支的节点，因为二叉树性质n0=n2+1
	{
		HT[i].c = ' ';
		HT[i].parent = -1;
		// 优先队列中出队列，找权值最小的根结点的下标min1,min2
		Node min1 = Q.top();Q.pop();
		Node min2 = Q.top();Q.pop();		
		HT[min1.i].parent=i; HT[min2.i].parent=i;  // 认爹
		HT[i].lchild=min1.i, HT[i].rchild=min2.i;  // 爹认左右孩子
		HT[i].w = HT[min1.i].w + HT[min2.i].w;
		Q.push( Node(HT[i].w, i) );
	}
}
<br><br>#include &lt;iostream&gt;
#include &lt;iomanip&gt;
#include &lt;vector&gt;
#include &lt;queue&gt;
using namespace std;

struct CW
{
	char c;  // 字符
	int  w;  // 权重
};
struct HuffNode
{
	char c;  // 字符
	int  w;  // 权重
	int i;//下标
	int l,r,parent; 
	bool operator&gt;(const HuffNode &amp;n1,const HuffNode &amp;n2){
		return n1.w&gt;n2.w;
	}
};


struct Node
{
	int w;  // 权重
	int i;  // 下标
	Node(int w,int i):w(w),i(i){}
};
bool operator&gt;(const Node &amp;n1,const Node &amp;n2)
{
	return n1.w&gt;n2.w;
}

// 编码个数 = n
// 时间复杂度：O(n*n) -&gt; O(n*log2(n))
// 空间复杂度：O(1)   -&gt; O(n)
void CreateHT(CW cw[],int n, HuffNode HT[])
{
	priority_queue&lt;HuffNode,vector&lt;HuffNode&gt;,greater&lt;HuffNode&gt; &gt;Q;
	int i=0;
	for(;i&lt;n;i++){
		HT[i].c=cw[i].c;
		HT[i].w=cw[i].w;
		HT[i].i=i;
		HT[i].l=HT[i].r=HT[i].parent=-1;
		Q.push(HT[i]);
	}
	int tt=n;
	while(!Q.empty()){
		HuffNode min1=Q.top();Q.pop();
		HuffNode min2=Q.top();Q.pop();
		HuffNode newnode;
		newnode.w=min1.w+min2.w;
		newnode.c='o';//占位字符
		newnode.i=tt++;
		HT[min1.i].parent=HT[min2.i].parent=newnode.i;
		newnode.l=min1.i;newnode.r=min2.i;
		HT[tt-1]=newnode;
		Q.push(newnode);
	}
}
<br><br>class Heap
{
	int a[N],n;
public:
	Heap():n(0){ }
	//已知a[0]...a[n-1]是小根堆，插入了a[n]
	void push(int x)
	{
		a[n++]=x;
		int p=n-1, parent= (p-1)/2;
		while(p&gt;0)
		{
			if(a[parent]&lt;=a[p])  return;
			swap(a[parent], a[p]);
			p=parent, parent= (p-1)/2;
		}
	}
	void pop()
	{
		a[0]=a[n-1], n--;
		int p=0;
		while( 2*p+1&lt;n )//判左是否越界
		{
			int child=2*p+1; // child是左右孩子中最小值的下标，因为从0开始，所以左孩子是2*p+1,右孩子是2*p+2.
			if(child+1&lt;n &amp;&amp; a[child+1]&lt;a[child])//判右是否越界
				child++;
			if(a[p]&lt;=a[child])  break;
			swap(a[p], a[child]);
			p=child;
		}
	}
	int top(){ return a[0]; }
	bool empty(){ return n==0; }
}
<br><br>int findKthLargest(vector&lt;int&gt;&amp; num, int k) {  
    int l=0,r=num.size()-1;  
    return findk(num,0,r,k);  
}  
  
int partition( int left, int right,vector&lt;int&gt;&amp; num) {  
    int pivot = num[right];  // 选择最右边的元素作为pivot  
    int i = left - 1;  // i用来追踪大于pivot的元素的最后一个索引位置  
	for (int j = left; j &lt; right; ++j) {  
		if (num[i] &gt; pivot) {  // 如果当前元素大于pivot  
			++i;  // 移动到下一个索引  
			swap(num[i], num[j]);  // 交换大于pivot的元素和当前元素
		}  
	}  

    // 最后交换pivot和第一个小于pivot的元素  
    swap(num[i+1], num[right]);  
    return i + 1;  // 返回pivot的索引  
}  
  
int findk(vector&lt;int&gt;&amp;num,int l,int r,int k){  
    int mid=partition(l,r,num);  
    if(mid==k-1) return num[mid];//如果相等就返回  
    else if(mid&lt;k-1){  
        return findk(num,mid+1,r);  
    }     
    else{  
        return findk(num,l,mid-1);  
    }  
}
<br><br>int partition(int l,int r,vector&lt;int&gt;&amp;num){
	int i=l-1;int tmp=num[r];
	for(int j=left;j&lt;r;j++){
		if(num[j]&gt;tmp){
			i++;
			swap(num[i],num[j]);
		}
	}
	swap(num[i++],num[r]);
	return i;
}
int findk(int l,int r,int k,vector&lt;int&gt;&amp;num){
	int mid=partition(l,r,num);
	if(mid==k-1){
		return num[mid];
	}
	else if(mid&lt;k-1){
		return findk(mid+1,r,num);
	}
	else return findk(l,mid-1,num);
}
<br><br>// 在sd[]找最小值的下标imin，要求set[imin]=false
int FindiMin(int sd[],bool set[], int n)
{
	int imin=0;
	while(set[imin]==true) imin++;
	for(int i=imin+1; i&lt;n; i++)
	{
		if(set[i]==true)  continue;
		if(sd[i]&lt;sd[imin]) imin=i;
	}
	return imin;
}

void Dijkstra(int M[N][N],int n, int sv,int sd[],int prev[])
{
	bool set[N];  
	for(int i=0;i&lt;n; i++)
		sd[i]=M[sv][i], set[i]=false, prev[i]=-1;
	set[sv]=true;
	// 找最近的顶点，调整sd[],set[]
	for(i=0; i&lt;n-1; i++)
	{
		int w=FindiMin(sd,set, n);	set[w]=true; // sv-&gt;w的最短距离已经确定
		// 借助w,以w为中转站，优化sd[]
		for(int j=0; j&lt;n; j++)
		{
			if(set[j]==true)  continue; // 忽略已经确定最短距离的顶点
			if(sd[w]+M[w][j] &lt; sd[j])
				sd[j] = sd[w]+M[w][j],  // 贪心法：找到了更近的路
				prev[j] = w;  // 记住sv-&gt;j的路上最后一个中间顶点
		}
	}
}
<br>// 在sd[]找最小值的下标imin，要求set[imin]=false
int FindiMin(int sd[],bool set[], int n)
{
	int imin=0;
	while(set[imin]==true) imin++;
	for(int i=imin+1; i&lt;n; i++)
	{
		if(set[i]==true)  continue;
		if(sd[i]&lt;sd[imin]) imin=i;
	}
	return imin;
}

void Dijkstra(int M[N][N],int n, int sv,int sd[],int prev[])
{
	bool set[N]={false};
	for(int i=0;i&lt;n;i++){
		sd[i]=M[sv][i];prev[i]=-1;
	}
	for(int i=0;i&lt;n;i++){
		int imin=FindMin(sd,set,n);
		//更新set
		set[imin]=true;
		//更新sd
		for(int j=0;j&lt;n;j++){
			if(set[j]==true)continue;
			if(sd[j]&gt;sd[imin]+M[imin][j])
				sd[j]=sd[imin]+M[imin][j];
				prev[j]=imin;
		}
	}
	
}
<br><br><br>// C = A + B, A &gt;= 0, B &gt;= 0
vector&lt;int&gt; add(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B)
{
    if (A.size() &lt; B.size()) return add(B, A);

    vector&lt;int&gt; C;
    int t = 0;
    for (int i = 0; i &lt; A.size(); i ++ )
    {
        t += A[i];
        if (i &lt; B.size()) t += B[i];
        C.push_back(t % 10);
        t /= 10;
    }

    if (t) C.push_back(t);
    return C;
}
<br><br>// C = A - B, 满足A &gt;= B, A &gt;= 0, B &gt;= 0
vector&lt;int&gt; sub(vector&lt;int&gt; &amp;A, vector&lt;int&gt; &amp;B)
{
    vector&lt;int&gt; C;
    for (int i = 0, t = 0; i &lt; A.size(); i ++ )
    {
        t = A[i] - t;
        if (i &lt; B.size()) t -= B[i];
        C.push_back((t + 10) % 10);
        if (t &lt; 0) t = 1;
        else t = 0;
    }
    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();
    return C;
}
<br><br>// C = A * b, A &gt;= 0, b &gt;= 0
vector&lt;int&gt; mul(vector&lt;int&gt; &amp;A, int b)
{
    vector&lt;int&gt; C;

    int t = 0;
    for (int i = 0; i &lt; A.size() || t; i ++ )
    {
        if (i &lt; A.size()) t += A[i] * b;
        C.push_back(t % 10);
        t /= 10;
    }
    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();
    return C;
}

<br><br>// A / b = C ... r, A &gt;= 0, b &gt; 0
vector&lt;int&gt; div(vector&lt;int&gt; &amp;A, int b, int &amp;r)
{
    vector&lt;int&gt; C;
    r = 0;
    for (int i = A.size() - 1; i &gt;= 0; i -- )
    {
        r = r * 10 + A[i];
        C.push_back(r / b);
        r %= b;
    }
    reverse(C.begin(), C.end());
    while (C.size() &gt; 1 &amp;&amp; C.back() == 0) C.pop_back();
    return C;
}
<br><br>vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {
        int row=matrix.size();
        int col=matrix[0].size();
        vector&lt;vector&lt;bool&gt;&gt; flag(row,vector&lt;bool&gt;(col));
        pair&lt;int,int&gt; dirct[4]={{0,1},{1,0},{0,-1},{-1,0}};//右下左上
        bool stop=false; int i=0,j=0;
        vector&lt;int&gt;res;
        
        res.push_back(matrix[i][j]);
        flag[0][0]=true;

        while(!stop){
            stop = true;  // 假设所有的位置都已经遍历结束
            for(int t = 0; t &lt; 4; t++)
            {
                while (true)  // 尝试按照当前的方向前进
                {
                    int new_i = i + dirct[t].first;
                    int new_j = j + dirct[t].second;
                    // 如果新的位置越界或者已经被访问过，就换一个新的方向
                    if (new_i &lt; 0 || new_i &gt;= row || new_j &lt; 0 || new_j &gt;= col || flag[new_i][new_j] == true) {
                        break;
                    }
                    // 否则，前进到新的位置，并标记新的位置已被访问
                    i = new_i;
                    j = new_j;

                    res.push_back(matrix[i][j]);
                    cout &lt;&lt; matrix[i][j] &lt;&lt; ' ';
                    flag[i][j] = true;
                    stop = false;  // 只要有新的位置被访问，就表示还没有遍历结束
                }
            }
        }
        return res;
    }
<br><br>#include &lt;iostream&gt;
#include &lt;vector&gt;
using namespace std;

void Output(vector&lt;int&gt; &amp;v)
{
	for(int i=0; i&lt;v.size(); i++)  cout&lt;&lt;v[i]&lt;&lt;" ";
	cout&lt;&lt;endl;
}
void Output(vector&lt;int&gt; &amp;prev, int v) // 输出方案
{
	while(prev[v]!=-1)
	{
		int v1=v-prev[v]; // 这一步选择的物品的体积
		cout&lt;&lt;v1&lt;&lt;" ";
		v=prev[v];
	}
	cout&lt;&lt;endl; 
/* 5 5 8 11
    dp[29]=5+dp[24]
	         dp[24]=5+dp[19] 
			          dp[19] =11+dp[8] 
					             dp[8]=8+dp[0]  
*/
}
// vs[]={5,8,11}, n=3;
//V=    0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29
//prev:-1 -1 -1 -1 -1  0  1  2  0  1  5  0  1  8 
//dp:   0  0  0  0  0  5  5  5  8  8 10 11 11 13 
// dp[5] = 5 + dp[0] =5
// dp[6] = 5 + dp[1] =5
// dp[8] = 5 + dp[3] =5
// dp[8] = 8 + dp[0] =8   = 8
// dp[10] = 5 + dp[5] =10
// dp[10] = 8 + dp[2] =8   =10

// dp[12] = 5 + dp[7] =10
// dp[12] = 8 + dp[4] =8
// dp[12] =11 + dp[1] =11  =11
int Solve(int vs[],int n, int Vol)
{
	vector&lt;int&gt; dp(Vol+1,0);
	vector&lt;int&gt; prev(Vol+1,-1);
	for(int v=1; v&lt;=Vol; v++)
	{
		for(int i=0; i&lt;n; i++)  // 尝试放入vs[i]
		{
			if(vs[i]&gt;v)    continue;  // 放不进去
			if(vs[i] + dp[v-vs[i]]&gt;dp[v])
				dp[v] = vs[i] + dp[v-vs[i]], prev[v]=v-vs[i];
		}
	}
	//Output(prev);
	Output(prev, Vol); // 输出方案
	return dp.back();
}

int main()
{
	int vs[]={5,8,11}, n=3;
	int Vol=29;   // 27=11+11+5   5+5+5+5+8=28    5+5+11+8=29
	cout&lt;&lt;Solve(vs,n, Vol)&lt;&lt;endl;
	return 0;	
}

<br><br>#include &lt;iostream&gt;
#include &lt;vector&gt;
using namespace std;

/*
	X2[]=   空 {2, 4, 3, 1, 2, 1};
	    空   0  0  0  0  0  0  0
	X1[]={1, 0  0  0  0  1  1  1
		  2, 0  1  1  1  1  2  2
		  3, 0  1  1  2  2  2  2
		  2, 0  1  1  2  2  3  3
		  4, 0  1  2  2  2  3  3  
		  1, 0  1  2  2  3  3  4
		  2: 0  1  2  2  3  4  4
*/
int FindLCS(int X1[],int n1,int X2[],int n2)
{
	vector&lt;vector&lt;int&gt; &gt; M(n1+1,vector&lt;int&gt;(n2+1,0) );
	for(int i=1; i&lt;=n1; i++)
		for(int j=1; j&lt;=n2; j++)
			if(X1[i-1] == X2[j-1])
				M[i][j] = M[i-1][j-1]+1;
			else
				if(M[i-1][j]&gt;M[i][j-1])
					M[i][j] = M[i-1][j];
				else
					M[i][j] = M[i][j-1];
	return M[n1][n2];
}

void main()
{
	int X1[]={1,2,3,2,4,1,2};  // 2 3 1 2 
	int X2[]={2,4,3,1,2,1};    // 2 3 1 2 
	int L=FindLCS(X1,7,X2,6);
	cout&lt;&lt;L&lt;&lt;endl;
}

<br><br>#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;iomanip&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;
using namespace std;

template&lt;typename T&gt;
void Output(vector&lt;T&gt; &amp;es)
{
	static int k=0;
	k++;
	cout&lt;&lt;k&lt;&lt;":   ";
	for(int i=0; i&lt;es.size(); i++)
		cout&lt;&lt;setw(3)&lt;&lt;es[i]&lt;&lt;"  ";
	cout&lt;&lt;endl;
}

class Graph
{
	int vn; // 顶点个数
	vector&lt;vector&lt;int&gt; &gt; M;  // 代价矩阵
public:
	Graph(char fname[])
	{
		ifstream fin(fname);
		fin&gt;&gt;vn;
		M.resize(vn, vector&lt;int&gt;(vn, 0));
		for(int i=0; i&lt;vn; i++)
			for(int j=0; j&lt;vn; j++)
				fin&gt;&gt;M[i][j];
	}
	bool isOK(vector&lt;int&gt; &amp;cs, int c)
	{
		int n=cs.size();  // 已经着色的顶点数
		// 当前给区域n 赋色c
		for(int i=0; i&lt;n; i++)
		{
			if(M[n][i]==0)  continue; // 无边相连
			if(cs[i]==c)  return  false; // 颜色冲突
		}
		return true;
	}
	void dfs(int ith, vector&lt;int&gt; &amp;cs)
	{
		if(ith==vn)
			Output(cs);
		else
		{
			for(int c=1; c&lt;=4; c++)
			{
				if(isOK(cs,c)==false)  continue;   // 颜色c不合法，则舍弃
				cs.push_back(c);  // 给ith区域赋色c
				dfs(ith+1, cs);
				cs.pop_back();    // 撤销ith区的颜色
			}
		}
	}
	friend ostream &amp; operator&lt;&lt;(ostream &amp;out, Graph &amp;g)
	{
		for(int i=0; i&lt;g.vn; i++)
		{
			for(int j=0; j&lt;g.vn; j++)
				out&lt;&lt;setw(3)&lt;&lt;g.M[i][j]&lt;&lt;"  ";
			out&lt;&lt;endl;
		}
		return out;
	}
};
int main()
{
	Graph G("g1.txt");
	vector&lt;int&gt; cs;  // 颜色表：cs[i]表示区域i的颜色
	G.dfs(0, cs);
	return 0;	
}

<br><br>#include&lt;bits/stdc++.h&gt;
using namespace std;

void output(const vector&lt;int&gt;&amp; tmp) {
	for (int i = 0; i &lt; tmp.size(); i++) {
		cout &lt;&lt; tmp[i] &lt;&lt; ' ';
	}
	cout &lt;&lt; endl;
}

vector&lt;bool&gt; visited;

void permutation(int n, vector&lt;int&gt;&amp; tmp) {
	if (tmp.size() == n) {
		output(tmp);
		return;
	}
	for (int i = 1; i &lt;= n; i++) {
		if (!visited[i]) {
			visited[i] = true;
			tmp.push_back(i);
			permutation(n, tmp);
			tmp.pop_back();
			visited[i] = false;
		}
	}
}

int main() {
	int n;
	cin &gt;&gt; n;
	vector&lt;int&gt; tmp;
	visited.resize(n + 1, false);
	permutation(n, tmp);
	return 0;
}

<br><br>#include &lt;iostream&gt;
#include &lt;fstream&gt;
#include &lt;iomanip&gt;
#include &lt;vector&gt;
#include &lt;algorithm&gt;
using namespace std;

struct Edge
{
	int sv,ev;
	int cost;
	Edge(int sv=0,int ev=0,int cost=0): sv(sv),ev(ev),cost(cost){}
	friend istream &amp; operator&gt;&gt;(istream &amp;in, Edge &amp;e)
	{
		return in&gt;&gt;e.sv&gt;&gt;e.ev&gt;&gt;e.cost;
	}
	friend ostream &amp; operator&lt;&lt;(ostream &amp;out, Edge &amp;e)
	{
		return out&lt;&lt;e.sv&lt;&lt;"&lt;-&gt;"&lt;&lt;e.ev&lt;&lt;": "&lt;&lt;e.cost;
	}
};
bool operator&lt;(const Edge &amp;e1,const Edge &amp;e2)
{
	return e1.cost&lt;e2.cost;
}
void Output(vector&lt;Edge&gt; &amp;es)
{
	for(int i=0; i&lt;es.size(); i++)
		cout&lt;&lt;es[i]&lt;&lt;endl;
}

class Graph
{
	int vn; // 顶点个数
	vector&lt;Edge&gt; es;  // 边集
public:
	Graph(char fname[])
	{
		ifstream fin(fname);
		int en;   // 边数
		fin&gt;&gt;vn&gt;&gt;en;
		es.resize(en);
		for(int i=0; i&lt;en; i++)
			fin&gt;&gt;es[i];
		sort(es.begin(), es.end());
	}
	friend ostream &amp; operator&lt;&lt;(ostream &amp;out, Graph &amp;g)
	{
		for(int i=0; i&lt;g.es.size(); i++)
			out&lt;&lt;g.es[i]&lt;&lt;endl;
		return out;
	}
	// 返回连通分量的编号：根结点的下标
	int FindParent(vector&lt;int&gt; &amp;parent, int v)
	{
		while(parent[v]!=-1)
			v=parent[v];
		return v;
	}
	void Kruskal(vector&lt;Edge&gt; &amp;mst)
	{
		// parent[i]: k是顶点i所属的连通分量的编号
		vector&lt;int&gt;  parent(vn, -1);
		for(int i=0; i&lt;es.size(); i++)
		{
			// es[i].sv   es[i].ev 是否属于同一个连通分量
			int sv = FindParent(parent,es[i].sv);
			int ev = FindParent(parent,es[i].ev);
			if(sv==ev)   continue;
			mst.push_back(es[i]);
			parent[sv]=ev;   // 建立sv和ev之间的连通关系
		}
	}
};
int main()
{
	Graph G("g1.txt");
	//cout&lt;&lt;G;
	vector&lt;Edge&gt; mst;
	G.Kruskal(mst);
	Output(mst);
	return 0;	
}

<br><br>#include &lt;iostream&gt;
#include &lt;iomanip&gt;
#include &lt;vector&gt;
#include &lt;queue&gt;
#include &lt;map&gt;
using namespace std;
#define   N 10
#define Inf 999

struct Edge
{
	int ev;
	int cost;
	Edge(int ev=0,int cost=0): ev(ev),cost(cost){}
	friend istream &amp; operator&gt;&gt;(istream &amp;in, Edge &amp;e)
	{
		return in&gt;&gt;e.ev&gt;&gt;e.cost;
	}
};
bool operator&lt;(const Edge &amp;e1,const Edge &amp;e2)
{
	return e1.cost&gt;e2.cost;
}

// 2-&gt;3
int GetCost(multimap&lt;int,Edge&gt; &amp;G, int i,int j)
{
	multimap&lt;int,Edge&gt;::iterator it= G.find(i);
	if(it==G.end())  return Inf;
	while(it!=G.end() &amp;&amp; it-&gt;first==i)
	{
		if(it-&gt;second.ev==j) 
			return it-&gt;second.cost;
		it++;	
	}
	return Inf;
}

void Dijkstra(multimap&lt;int,Edge&gt; &amp;G,int n, int sv,int sd[],int prev[])
{
	priority_queue&lt;Edge&gt; Q, nextQ;    // 大根堆,得出小根堆的效果
	bool set[N];  
	for(int i=0; i&lt;n; i++)
	{
		sd[i]=GetCost(G,sv,i), set[i]=false, prev[i]=-1;
		if(i==sv)   continue;   // 忽略sd-&gt;sd:0
		Q.push( Edge(i, sd[i]) );
	}
	set[sv]=true;   
	// 找最近的顶点，调整sd[],set[]
	for(i=0; i&lt;n-1; i++)
	{
		Edge e =Q.top();  Q.pop();  // 优先队列取最小值O(log2(n))
		int w=e.ev;
		set[w]=true; // sv-&gt;w的最短距离已经确定
		// 借助w,以w为中转站，优化sd[]
		while( !Q.empty() )
		{
			Edge e1 =Q.top();  Q.pop();  
			int j=e1.ev;   // j是尚未确定最短距离的顶点
			int w2j=GetCost(G,w, j);
			if(sd[w]+ w2j &lt; sd[j])
				sd[j] = sd[w]+w2j,  // 贪心法：找到了更近的路
				prev[j] = w;  // 记住sv-&gt;j的路上最后一个中间顶点
			nextQ.push( Edge(j, sd[j]) );
		}
		Q = nextQ;
	}
}
// 输出sv-&gt;v的所有中间顶点
void GetPath(int prev[], int v)
{
	while(v!=-1)
	{
		cout&lt;&lt;prev[v]&lt;&lt;" ";
		v=prev[v];   // p=p-&gt;next
	}
}
void Output(multimap&lt;int,Edge&gt; &amp;G)
{
	for(multimap&lt;int,Edge&gt;::iterator it=G.begin(); it!=G.end(); it++)
		cout&lt;&lt;it-&gt;first&lt;&lt;"-&gt;"&lt;&lt;it-&gt;second.ev&lt;&lt;": "&lt;&lt;it-&gt;second.cost&lt;&lt;endl;
}
int main()
{
	multimap&lt;int,Edge&gt; G;   // 巨大的稀疏图
	freopen("G1.txt", "r", stdin);
	int vn;  cin&gt;&gt;vn;   // 顶点数
	int i, en;  cin&gt;&gt;en;   // 边数
	for(i=0; i&lt;en; i++)
	{
		int sv; Edge e; 
		cin&gt;&gt;sv&gt;&gt;e;
		G.insert( pair&lt;int,Edge&gt; (sv, e) );
	}
	Output(G);
	// 测试最短路径算法
	int sv=0;
	int sd[N];     // sd[i]：  sv-&gt;i的最短距离长度
	int prev[N];   // prev[i]：sv-&gt;i之前的最后顶点的下标
	Dijkstra(G, vn, sv,sd,prev);
	for(i=0; i&lt;vn; i++)
	{
		cout&lt;&lt;"-&gt;"&lt;&lt;i&lt;&lt;": "&lt;&lt;sd[i]&lt;&lt;": ";
		GetPath(prev, i);
		cout&lt;&lt;endl;
	}
	return 0;	
}

]]></description><link>technology\collegeproject\算法设计\算法复习.html</link><guid isPermaLink="false">Technology/CollegeProject/算法设计/算法复习.md</guid><pubDate>Thu, 27 Jun 2024 03:15:45 GMT</pubDate></item><item><title><![CDATA[算法设计解题报告]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/算法/算法设计" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/算法/算法设计</a> 
 <br><a href=".?query=tag:科技\算法\算法设计" class="tag" target="_blank" rel="noopener nofollow">#科技/算法/算法设计</a> <br><br><br><br>
走头无路的浩渡波来到了澳门，身无分文的他在街边捡到了一元硬币。于是他兴起走进了一个馆子玩玩“游戏”。<br>
这个“公平的游戏“，规则是这样的，抛出一枚公平的硬币，有一半的概率投到正面，那么浩渡波获得一元硬币。还有另一半概率投到反面，浩渡波就会失去一元硬币。当他把硬币输光时，游戏提前结束。现在要你计算一下经过n轮（包括n轮前就输光），最后有多大的概率血本无归，并以此对他提出建议。（由于结果为小数，因此输出硬币的期望数量乘上2的n次方。请给出答案模上100007的余数。）
<br>输入格式<br>
一个整数n，表示玩了至多n轮。<br>输出格式<br>
一个整数，表示期望硬币数。<br>链接<br>
<a rel="noopener nofollow" class="external-link" href="https://vijos.org/d/nnu_contest/contest/663757386e9552d60cf9b19b/1583" target="_blank">https://vijos.org/d/nnu_contest/contest/663757386e9552d60cf9b19b/1583</a><br><br>图示：<br>		1               times=0     p=0
	0       2           times=1     p=1/2
		1       3       times=2     p=1/2
	0      2 2      4   times=3     p=1/2+1/4
<br>观察可知，这个问题的结构类似二叉树。假设当前节点为n,左子树就是n-1,右子树就是n+1。<br>
我们可构造基础的迭代式子，如下：<br>
约束条件：<br><br><br>其中deepth和times分别是树的深度和赌局次数。<br>得到以下代码：<br><br>def f(n,deepth,times):
    if deepth&gt;times:
        return 0
    deepth+=1
    if n==0:
        return 1
    return 1/2*f(n-1,deepth,times)+1/2*f(n+1,deepth,times)


def main():
    n =int(input())
    a=f(1,0,n)
    a=int(a*2**n)
    a=a%100007
    print(a)
if __name__=="__main__":
    main()
<br><br>
由于f(n)=f(n-1)+f(n+1),所以dp无论从左到右还是从右到左都不行。所以可以考虑二维dp。<br>
考虑一个二维dp数组，dp[i][j]表示，第i轮时手里有j个硬币的期望。那么最后dp[n][0]即表示第n轮中亏空的期望。dp[0][1]则表示没开始是手里有1元的概率，即初始节点，显然为1。注意这里的期望为累加期望，即dp[3][0]是3/4，不是1/4。<br>
那么迭代的方程我们可以将原本的f(n)=f(n-1)+f(n+1)反过来想，递归思想是大问题分成小问题，递推则是小问题组成大问题，对于第i轮手中有j块钱的情况，他只能由第i-1轮的j-1和j+1得到，分别对应第j局赌局的输赢两种情况。所以迭代方程<br>
dp[i][j]=dp[i-1][j-1]+dp[i-1][j+1](这里不加1/2是因为题目要乘2的n次取模，而乘2的n次取模就是将二叉树最底层的权重看做1，往上一层乘以二。)<br>
对于没有j-1的0和1，则单独处理，将0看成往下分出两个0。而j迭代到i+1是因为最右边的值一定是树的深度+1。且由于最右边的j+1是存在的且一定为0，所以不需要考虑越界问题。
<br>#include &lt;iostream&gt;
#define maxn 1024 
using namespace std; 
int p=100007; 
int dp[maxn][maxn]={0}; 
int main () 
{ 
	dp[0][1]=1; int n; cin&gt;&gt;n;
	for (int i=1;i&lt;=n;i++)
	{ 
		dp[i][0]=(dp[i-1][1]+dp[i-1][0]*2)%p; 
		dp[i][1]=dp[i-1][2]%p; 
		for (int j=2;j&lt;=i+1;j++)
		{ 
			dp[i][j]=(dp[i-1][j-1]+dp[i-1][j+1])%p;
		} 
	}
	cout&lt;&lt;dp[n][0];
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/1017/" target="_blank">https://www.acwing.com/problem/content/1017/</a><br>
题意：给定一个二维矩阵，每一个位置有一个价值，问：从左上角（1,1）走到右下角（r,c）能获得的最大价值是多少
<br><br>
思路：我们不妨从结果位置出发，对于（r,c）这个位置而言，能走到这里的只有两个位置，即上面的位置（r-1,c）和左边（r,c-1）的位置，那么答案就是（r-1,c）和（r,c-1）中的最大价值 +（r,c）处的价值。那么对于（r-1,c）和（r,c-1）中的最大价值，同样需要其相应位置的左方和上方的价值最优计算而来，因此就很容易想到动态规划的思路。我们需要初始化dp[1][j]和dp[i][1]的答案，然后从dp[2][2]开始计算。
<br>
代码优化：不难发现，直接从dp[1][1]开始迭代也是可以的。因为dp[0][j]均为0，同样的dp[1][0]也均为0。
<br><br>void solve() {
	int r, c;
	cin &gt;&gt; r &gt;&gt; c;
	vector&lt;vector&lt;int&gt;&gt; w(r + 1, vector&lt;int&gt;(c + 1)), dp(r + 1, vector&lt;int&gt;(c + 1, 0));

	for (int i = 1; i &lt;= r; i++) {
		for (int j = 1; j &lt;= c; j++) {
			cin &gt;&gt; w[i][j];
		}
	}

	dp[1][1] = w[1][1];

	for (int j = 2; j &lt;= c; j++) {
		dp[1][j] = dp[1][j - 1] + w[1][j];
	}

	for (int i = 2; i &lt;= r; i++) {
		dp[i][1] = dp[i - 1][1] + w[i][1];
	}

	for (int i = 2; i &lt;= r; i++) {
		for (int j = 2; j &lt;= c; j++) {
			dp[i][j] = w[i][j] + max(dp[i - 1][j], dp[i][j - 1]);
		}
	}

	cout &lt;&lt; dp[r][c] &lt;&lt; "\n";
}
<br><br>void solve() {
	int r, c;
	cin &gt;&gt; r &gt;&gt; c;
	vector&lt;vector&lt;int&gt;&gt; w(r + 1, vector&lt;int&gt;(c + 1)), dp(r + 1, vector&lt;int&gt;(c + 1, 0));

	for (int i = 1; i &lt;= r; i++) {
		for (int j = 1; j &lt;= c; j++) {
			cin &gt;&gt; w[i][j];
		}
	}

	for (int i = 1; i &lt;= r; i++) {
		for (int j = 1; j &lt;= c; j++) {
			dp[i][j] = w[i][j] + max(dp[i - 1][j], dp[i][j - 1]);
		}
	}

	cout &lt;&lt; dp[r][c] &lt;&lt; "\n";
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1002" target="_blank">https://www.luogu.com.cn/problem/P1002</a><br>
题意：给定一个矩阵，现在需要从左上角走到右下角，问一共有多少种走法？有一个特殊限制是，对于图中的9个点是无法通过的。
<br><br>
思路一：dfs
<br>
我们可以采用深搜的方法。但是会超时，我们可以这样估算时间复杂度：对于每一个点，我们都需要计算当前点的右下角的矩阵中的每一个点，那么总运算次数就近似为阶乘级别。当然实际的时间复杂度不会这么大，但是这种做法<br>
n∗m 一旦超过100就很容易tle<br>
时间复杂度：O(nm!)
<br>
思路二：dp<br>
我们可以考虑，对于当前的点，可以从哪些点走过来，很显然就是上面一个点和左边一个点，而对于走到当前这个点的路线就是走到上面的点和左边的点的路线之和，base状态就是 dp[1][1] = 1，即起点的路线数为1<br>
时间复杂度：O(nm)
<br><br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 30;

int n, m, a, b;
int res;
bool notsafe[N][N];

void init() {
	int px[9] = {0, -1, -2, -2, -1, 1, 2, 2, 1};
	int py[9] = {0, 2, 1, -1, -2, -2, -1, 1, 2};
	for (int i = 0; i &lt; 9; i++) {
		int na = a + px[i], nb = b + py[i];
		if (na &lt; 0 || nb &lt; 0) continue;
		notsafe[na][nb] = true;
	}
}

void dfs(int x, int y) {
	if (x &gt; n || y &gt; m || notsafe[x][y]) {
		return;
	}

	if (x == n &amp;&amp; y == m) {
		res++;
		return;
	}

	dfs(x, y + 1);
	dfs(x + 1, y);
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m &gt;&gt; a &gt;&gt; b;
	init();
	dfs(0, 0);
	cout &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br>#include &lt;bits/stdc++.h&gt;
using namespace std;
typedef long long ll;

const int N = 30;

int n, m, a, b;
bool notsafe[N][N];
ll dp[N][N];

void solve() {
	cin &gt;&gt; n &gt;&gt; m &gt;&gt; a &gt;&gt; b;

	// 初始化
	++n, ++m, ++a, ++b;
	int px[9] = {0, -1, -2, -2, -1, 1, 2, 2, 1};
	int py[9] = {0, 2, 1, -1, -2, -2, -1, 1, 2};
	for (int i = 0; i &lt; 9; i++) {
		int na = a + px[i], nb = b + py[i];
		if (na &lt; 0 || nb &lt; 0) continue;
		notsafe[na][nb] = true;
	}

	// dp求解
	dp[1][1] = 1;
	for (int i = 1; i &lt;= n; i++) {
		for (int j = 1; j &lt;= m; j++) {
			if (!notsafe[i - 1][j]) dp[i][j] += dp[i - 1][j];
			if (!notsafe[i][j - 1]) dp[i][j] += dp[i][j - 1];
		}
	}

	cout &lt;&lt; dp[n][m] &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1255" target="_blank">https://www.luogu.com.cn/problem/P1255</a><br>
题意：给定楼梯的台阶数，每次可以走1步或者2步，问走到第n层台阶可以走的方案数
<br><br>
思路一：dfs<br>
我们可以从前往后思考，即正向思维。对于剩余的台阶，我们可以走1步或者走2步，最终走到第n层就算一种<br>
时间复杂度：指数级别
<br>
思路二：递推（dp）<br>
对于递推的思路，我们从后往前考虑，即逆向思维。对于当前的层数，是从之前的哪几个台阶走过来的（即对于当前的状态，是之前哪几个状态转移过来的）。<br>
我们定义 f[i] 为走到第 i 层台阶的方案数<br>
则很显然第 i 层台阶是从前1个或者前2个台阶走过来的，于是状态转移方程就是f[i]=f[i-1]+f[i-2]<br>
时间复杂度：O(n)
<br>
注意：采用高精度加法
<br><br>int n, res;

void dfs(int x) {
	if (x &lt; 0) return;

	if (x == 0) res++;

	dfs(x - 1);
	dfs(x - 2);
}
<br><br>int n;
Int dp[N];

void solve() {
	cin &gt;&gt; n;

	dp[1] = 1, dp[2] = 2;
	for (int i = 3; i &lt;= n; i++) {
		dp[i] = dp[i - 1] + dp[i - 2];
	}

	cout &lt;&lt; dp[n] &lt;&lt; "\n";
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.acwing.com/problem/content/5150/" target="_blank">https://www.acwing.com/problem/content/5150/</a><br><br>
题意：给定一个数n，问[1, n]中有多少个数只含有4或7
思路：对于一个数，我们可以构造一个二叉搜数进行搜索，因为每一位只有两种可能，那么从最高位开始搜索。如果当前数超过了n就return，否则就算一个答案
时间复杂度：

<br>#include &lt;iostream&gt;
using namespace std;

#define int long long

int n, res;

void dfs(int x) {
    if (x &gt; n) return;
    
    res ++;
    
    dfs(x * 10 + 4);
    dfs(x * 10 + 7);
}

signed main() {
    cin &gt;&gt; n;
    dfs(4);
    dfs(7);
    cout &lt;&lt; res &lt;&lt; "\n";
    return 0;
}
<br><br>
题意：给定一个数n，问[1, n]中有多少个数只含有4或7
思路：按照数位进行计算。对于一个x位的数，1到x-1位的情况下所有的数都符合条件，对于一个t位的数，满情况就是  种，所以[1, x - 1]位就一共有  种情况 。对于第x位，采取二进制枚举与原数进行比较，如果小于原数，则答案+1，反之结束循环输出答案即可
<br>#include &lt;iostream&gt;
using namespace std;

int WS(int x) {
	int res = 0;
	while (x) {
		res++;
		x /= 10;
	}
	return res;
}

int calc(int a[], int ws) {
	int res = 0;
	for (int i = ws - 1; i &gt;= 0; i --) {
		res = res * 10 + a[i];
	}
	return res;
}

int main() {
	int n;
	cin &gt;&gt; n;
	
	int ws = WS(n);
	
	int ans = (1 &lt;&lt; ws) - 2;
	
	int a[20] {};
	for (int i = 0; i &lt; (1 &lt;&lt; ws); i ++) {
		for (int j = 0; j &lt; ws; j ++) {
			if ((1 &lt;&lt; j) &amp; i) {
				a[j] = 7;
			} else {
				a[j] = 4;
			}
		}
		if (calc(a, ws) &lt;= n) {
			ans ++;
		} else {
			break;
		}
	}
	
	cout &lt;&lt; ans;
	
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1605" target="_blank">https://www.luogu.com.cn/problem/P1605</a><br>
题意：矩阵寻路，有障碍物，每一个点只能走一次，找到起点到终点可达路径数<br>
思路：其实就是一个四叉树的题目，只需要进行四个方向的遍历搜索即可找到路径，由于会进行：越界、障碍物、以及不可重复遍历的剪枝，故遍历的数量会很少
<br><br>#include &lt;bits/stdc++.h&gt;
#define int long long
using namespace std;

const int N = 10;

int n, m, k;
int aa, bb, cc, dd;
int g[N][N], vis[N][N];
int res;

int dx[] = {-1, 1, 0, 0}, dy[] = {0, 0, 1, -1};

void dfs(int x, int y) {
	if (x == cc &amp;&amp; y == dd) {
		res++;
		return;
	}
	
	for (int k = 0; k &lt; 4; k++) {
		int xx = x + dx[k], yy = y + dy[k];
		if (xx &gt; 0 &amp;&amp; xx &lt;= n &amp;&amp; yy &gt; 0 &amp;&amp; yy &lt;= m &amp;&amp; !g[xx][yy] &amp;&amp; !vis[xx][yy]) {
			vis[x][y] = true;
			dfs(xx, yy);
			vis[x][y] = false;
		}
	}
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m &gt;&gt; k;
	cin &gt;&gt; aa &gt;&gt; bb &gt;&gt; cc &gt;&gt; dd;
	
	while (k--) {
		int x, y;
		cin &gt;&gt; x &gt;&gt; y;
		g[x][y] = 1;
	}
	
	dfs(aa, bb);
	
	cout &lt;&lt; res &lt;&lt; "\n";
} 

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1141" target="_blank">https://www.luogu.com.cn/problem/P1141</a><br>
题意：给定一个01矩阵，行走规则为“可以走到相邻的数字不同的位置”，现在给定m次询问 (u,v)，输出从 (u,v) 开始最多可以走多少个位置？<br>
思路：我们可以将此问题转化为一个求解连通块的问题。对于矩阵中的一个连通块，我们定义为：在其中任意一个位置开始行走，都可以走过整个连通块每一个位置。那么在询问时，只需要输出所在连通块元素的个数即可。现在将问题转化为了<br>
如何遍历每一个连通块？<br>
按照标记数组的情况，如果一个位置没有被标记，就从这个位置出发开始打标记并统计<br>
如何统计每一个连通块中元素的个数？<br>
按照题目中给定的迷宫行走规则，可以通过bfs或者dfs实现遍历
<br><br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 1010;

int n, m, res[N][N];
char g[N][N];
bool vis[N][N];

void bfs(int u, int v) {
	queue&lt;pair&lt;int, int&gt;&gt; q;
	int cnt = 0; // 当前“连通块”的大小
	vector&lt;pair&lt;int, int&gt;&gt; a;

	q.push({u, v});
	a.push_back({u, v});
	vis[u][v] = true;
	cnt++;

	int dx[4] = {-1, 1, 0, 0}, dy[4] = {0, 0, 1, -1};

	while (q.size()) {
		auto&amp; now = q.front();
		q.pop();

		for (int i = 0; i &lt; 4; i++) {
			int x = dx[i] + now.first, y = dy[i] + now.second;
			if (x &gt;= 1 &amp;&amp; x &lt;= n &amp;&amp; y &gt;= 1 &amp;&amp; y &lt;= n &amp;&amp; !vis[x][y] &amp;&amp; g[x][y] != g[now.first][now.second]) {
				q.push({x, y});
				a.push_back({x, y});
				vis[x][y] = true;
				cnt++;
			}
		}
	}

	for (auto&amp; loc: a) {
		res[loc.first][loc.second] = cnt;
	}
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m;
	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= n; j++)
			cin &gt;&gt; g[i][j];

	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= n; j++)
			if (!vis[i][j])
				bfs(i, j);

	while (m--) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		if (vis[a][b]) {
			cout &lt;&lt; res[a][b] &lt;&lt; "\n";
		} else {
			cout &lt;&lt; 1 &lt;&lt; "\n";
		}
	}
}

int main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br>#include &lt;bits/stdc++.h&gt;
using namespace std;

const int N = 1010;

int n, m, res[N][N];
char g[N][N];
bool vis[N][N];

// 当前点的坐标 (u, v)，当前连通块的元素个数cnt，当前连通块的元素存到 a 数组
void dfs(int u, int v, int&amp; cnt, vector&lt;pair&lt;int, int&gt;&gt;&amp; a) {
	cnt++;
	a.push_back({u, v});
	vis[u][v] = true;

	int dx[4] = {0, 0, 1, -1}, dy[4] = {1, -1, 0, 0};

	for (int k = 0; k &lt; 4; k++) {
		int x = u + dx[k], y = v + dy[k];
		if (x &gt;= 1 &amp;&amp; x &lt;= n &amp;&amp; y &gt;= 1 &amp;&amp; y &lt;= n &amp;&amp; !vis[x][y] &amp;&amp; g[x][y] != g[u][v]) {
			dfs(x, y, cnt, a);
		}
	}
}

void solve() {
	cin &gt;&gt; n &gt;&gt; m;
	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= n; j++)
			cin &gt;&gt; g[i][j];

	for (int i = 1; i &lt;= n; i++)
		for (int j = 1; j &lt;= n; j++)
			if (!vis[i][j]) {
				int cnt = 0;
				vector&lt;pair&lt;int, int&gt;&gt; a;
				dfs(i, j, cnt, a);
				for (auto&amp; loc: a) {
					res[loc.first][loc.second] = cnt;
				}
			}

	while (m--) {
		int a, b;
		cin &gt;&gt; a &gt;&gt; b;
		if (vis[a][b]) {
			cout &lt;&lt; res[a][b] &lt;&lt; "\n";
		} else {
			cout &lt;&lt; 1 &lt;&lt; "\n";
		}
	}
}

int main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><br>
贪吃的吃豆人（Pac-Man）想要吃掉一张地图上的所有豆子，但是小红（Blinky）今天追的出奇的紧，因此他想要找到一种方法不回头的（不能走重复的路径）吃完所有的豆子。<br>
地图上有n个节点，记作0到n-1号点，我们的吃豆人在0号点上，节点直接存在着m条无向边连接，每个边上都有许多豆子。总的来说，吃豆人现在需要找到这么一条路径，从0号点开始，不重复的走完所有边。<br>
注意，边可以链接同一个节点，可以有多条相同的边，不保证全部连通。
<br>
<a rel="noopener nofollow" class="external-link" href="https://vijos.org/d/nnu_contest/contest/665376e56e955279ba03e4a6/1603" target="_blank">https://vijos.org/d/nnu_contest/contest/665376e56e955279ba03e4a6/1603</a>
<br><br>
这道题一开始的思路是dfs遍历所有路径找到长度等于所有边数的路径为止。但是时间复杂度太高不适合。这里的n的总和不大于1e5。我们考虑图论性质。这道题不难看出是一笔画问题，即连通图找奇点的问题。所以首先判断是否是连通图，然后判断是否奇点个数为0或者2。<br>
关于连通图判断需要用到并查集。参考了这篇文档：<a rel="noopener nofollow" class="external-link" href="https://www.cnblogs.com/noKing/p/8018609.html" target="_blank">https://www.cnblogs.com/noKing/p/8018609.html</a>
<br>
并查集的思路，主要维护一个parent数组，这个数组的含义是，下标为i的元素是下标为parent[i]的小弟，如parent[1]=2即元素1为元素2的小弟。元素1属于的集合由元素2决定。当parent[i]=i时，表示他是老大哥，代表了这个集合的最终分类。<br>
当我们去find的时候，可以不断地向父节点找直到找到parent[i]=i，则找到了这个元素的分类。同时我们也可以通过paren[i]=find(i)进行路径压缩，我在程序中没用，考虑到递归可能会TL。<br>
当我们去Union的时候就简单了。可以直接使用find判断是否是同一集合，不是则合并，我这里设计了一个hight用来根据树高来判断谁向谁合并。
<br><br>#include&lt;queue&gt;
#include&lt;map&gt;
#include&lt;vector&gt;
using namespace std;

class UnionFind {
	vector&lt;int&gt; parent;
	int size;
	int count;//记录连通分量数
public:
	UnionFind(int n){
		parent.resize(n);
		size=n;
		count=n;
		for(int i=0;i&lt;n;i++){
			parent[i]=i;
		}
	}
	
	int find(int i,int &amp;hight) {
		while(parent[i]!=i){
			parent[i]=parent[parent[i]];
			i=parent[i];
			hight++;
		}
		return i;
	}
	
	void Union(int i,int j) {
		int hight_i=0;int hight_j=0;
		int find_i=find(i,hight_i);
		int find_j=find(j,hight_j);
		if(find_i==find_j){
			return;
		}
		if(hight_i&gt;hight_j)
			parent[find_j]=find_i;
		else
			parent[find_i]=find_j;
		count--;
	}
	
	bool isConnected(){
		return count==1;
	}
};

struct Edge{
	int sv;
	int ev;
};

void Output(vector&lt;Edge&gt; &amp;G){
	for(int i=0;i&lt;G.size();i++){
		cout&lt;&lt;G[i].sv&lt;&lt;"-&gt;"&lt;&lt;G[i].ev&lt;&lt;endl;
	}
}

bool judge(vector&lt;Edge&gt; &amp;G,int vn){
	int a[100000]={0};
	for(int i=0;i&lt;G.size();i++){
		if(G[i].sv==G[i].ev){
			a[G[i].sv]-=2;
		}
		else{
			a[G[i].sv]++;
			a[G[i].ev]++;
		}
	}
	int num_of_Odd=0;
	for(int i=0;i&lt;vn;i++){
		if(a[i]%2==1) num_of_Odd++; 
	}
	if(num_of_Odd==2||num_of_Odd==0)
		return true;
	return false;
}

int main(){
	int T=0;cin&gt;&gt;T;
	while(T&gt;0){
		vector&lt;Edge&gt; G;
		int vn;cin&gt;&gt;vn;//顶点数
		int en;cin&gt;&gt;en;//边数
		UnionFind uf(vn);
		for(int i=0;i&lt;en;i++){
			int sv;int ev;
			cin&gt;&gt;sv&gt;&gt;ev;
			Edge tmp;
			tmp.sv=sv;tmp.ev=ev;
			G.push_back(tmp);
			uf.Union(sv,ev);
		}
		if(uf.isConnected()==true){
			bool t=judge(G,vn);
			cout&lt;&lt;t&lt;&lt;endl;	
		}
		else
			cout&lt;&lt;'0'&lt;&lt;endl;
		T--;
	}
	
	return 0;
}
<br><br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P2240" target="_blank">https://www.luogu.com.cn/problem/P2240</a><br>
题意：给定一组物品，每一个物品有一定的重量与价值，现在给定一个背包总承重，需要从中选择合适的物品进行装载，使得最终装载的物品的总价值最大。现在规定每一个物品可以进行随意分割，按照单位重量计算价值
<br><br>
思路：考虑一般情况。很显然，如果不说可以随意分割，那就是一个 01 背包，既然说了可以随意分割，那就直接贪心选择即可，按照单位重量的价值降序进行选择<br>
时间复杂度：O(nlog(n))
<br><br>#include &lt;bits/stdc++.h&gt;
#define int long long
using namespace std;

const int N = 110;

int n, W;
double res;

struct Item {
	double w;
	double val;
	
	bool operator&lt; (const Item&amp; t) const {
		return this-&gt;val / this-&gt;w &gt; t.val / t.w;
	}
} a[N];

void solve() {
	cin &gt;&gt; n &gt;&gt; W;
	for (int i = 0; i &lt; n; i++) cin &gt;&gt; a[i].w &gt;&gt; a[i].val;	
	
	sort(a, a + n);
	
	for (int i = 0; i &lt; n; i++) {
		if (W &gt; a[i].w) {
			W -= a[i].w;
			res += a[i].val;
		} else {
			res += W * a[i].val / a[i].w;
			break;
		}
	}
	
	cout &lt;&lt; fixed &lt;&lt; setprecision(2) &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	cout &lt;&lt; fixed &lt;&lt; setprecision(2);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1803" target="_blank">https://www.luogu.com.cn/problem/P1803</a><br>
题意：给定一个数轴和数轴上的 n 个线段，现在需要从中选出尽可能多的 k 个线段，使得线段之间两两不相交，问 k 最大是多少
<br><br>
最重要的一点，那就是一开始应该选择线段。即考虑边界，对于最左侧我们应该选择哪一条线段呢？答案是最左侧的右端点最靠左的那一条线段，这样子后续的线段才能有更多的摆放空间<br>
时间复杂度:O(nlog(n))
<br><br>#include &lt;bits/stdc++.h&gt;
#define int long long
using namespace std;

const int N = 1000010;

int n;

struct Item {
	int l, r;
	bool operator&lt; (const Item&amp; t) const {
		return this-&gt;r &lt; t.r;
	}
} a[N];

void solve() {
	cin &gt;&gt; n;
	for (int i = 1; i &lt;= n; i++) cin &gt;&gt; a[i].l &gt;&gt; a[i].r;
	
	sort(a + 1, a + n + 1);
	
	int right = -1, res = 0;
	
	for (int i = 1; i &lt;= n; i++) {
		if (a[i].l &gt;= right) {
			res++;
			right = a[i].r;
		}
	}
	
	cout &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P3817" target="_blank">https://www.luogu.com.cn/problem/P3817</a><br>
题意：给定一个序列，现在每次可以选择序列中的某个数进行减一操作，问最少需要减多少可以使得序列中相邻两个元素之和不超过规定的数值 x
<br><br>
思路：同 T12 的思路展开，考虑边界，我们直接从任意的一个边界开始思考，假设从左边界开始考虑。为了让左边界满足，那么 a[1] 与 a[2] 之和就需要满足条件，为了后续可以尽可能少的进行减一操作，很显然我们最好从两个数的右边的数开始下手，于是贪心的结果就有了<br>
时间复杂度:O(n)
<br><br>#include &lt;bits/stdc++.h&gt;
#define int long long
using namespace std;

const int N = 100010;

int n, x;
int a[N];

void solve() {
	cin &gt;&gt; n &gt;&gt; x;
	for (int i = 1; i &lt;= n; i++) cin &gt;&gt; a[i];
	
	int res = 0;
	
	for (int i = 2; i &lt;= n; i++) {
		if (a[i] + a[i - 1] &gt; x) {
			int eat = a[i] + a[i - 1] - x;
			res += eat;
			a[i] = a[i] &gt;= eat ? a[i] - eat : 0;
		}
	}
	
	cout &lt;&lt; res &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P1090" target="_blank">https://www.luogu.com.cn/problem/P1090</a><br>
题意：给定 n 个数，现在需要将其两两合并为最终的一个数，每次合并的代价是两个数之和，问如何对这些数进行合并可以使得总代价最小
<br><br>
思路：很显然一共需要合并 n-1 次。那么我们从三个物品开始考虑，然后使用数学归纳法推导到 n 个数。对于三个物品，很显然先将两个物品进行合并，再将这个结果与最大的数进行合并方案时最优的。那么推广到 n 个数，我们只需要每次合并当前局面中最小的两个数即可<br>
时间复杂度：O(nlog(n))
<br><br>#include &lt;bits/stdc++.h&gt;
#define int long long
using namespace std;

const int N = 10010;

int n, a[N];
priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; q;
int res;

void solve() {
	cin &gt;&gt; n;
	for (int i = 1; i &lt;= n; i++) {
		int x;
		cin &gt;&gt; x;
		q.push(x);
	}
	
	for (int i = 1; i &lt;= n - 1; i++) {
		int a = q.top(); q.pop();
		int b = q.top(); q.pop();
		
		res += a + b;
		
		q.push(a + b);
	}
	
	cout &lt;&lt; res &lt;&lt; "\n";
} 

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();
	return 0;
}
<br><br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P2440" target="_blank">https://www.luogu.com.cn/problem/P2440</a><br><br>
题意：给定一个序列，现在需要将这个序列切分为等长的 k 段，长度必须为整数且尽可能的长，如果无法切分可以将多余的长度丢弃，问最长的长度是多少
思路：可以发现切分长度与切分的段数具有单调性，可以进行二分。二分的思路就是直接二分答案，根据长度判断可切得的段数，最终套右边界的模板找到最大的长度即可。需要注意的是，对于无法切割的情况，就是需要切出的段数 k 超过了序列之和
时间复杂度：
<br><br>#include &lt;bits/stdc++.h&gt;
#define int long long 
using namespace std;

const int N = 1e5 + 10;

int n, k;
int a[N];

bool chk(int x) {
	int sum = 0;
	for (int i = 0; i &lt; n; i++)
		sum += a[i] / x;
	return sum &gt;= k;
}

void solve() {
	cin &gt;&gt; n &gt;&gt; k;
	
	int sum = 0;
	for (int i = 0; i &lt; n; i++) {
		cin &gt;&gt; a[i];
		sum += a[i];
	}
	
	int l = 1, r = 1e8;
	while (l &lt; r) {
		int mid = (l + r + 1) &gt;&gt; 1;
		if (chk(mid)) l = mid;
		else r = mid - 1;
	}
	
	if (k &gt; sum) cout &lt;&lt; "0\n";
	else cout &lt;&lt; r &lt;&lt; "\n";	
} 

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();	
	return 0;
}
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.luogu.com.cn/problem/P2678" target="_blank">https://www.luogu.com.cn/problem/P2678</a><br><br>
题意：给定一个一维递增的不重复序列数，现在可以从其中拿去若干个数字，使得相邻数字之间的最小差值最大，问最大的最小差值是多少
思路：可以发现拿的数字越多，最小差值就越大，具有单调性，可以二分。我们直接二分答案，即直接二分最小差值的具体数值，通过判断当前的最小差值至少需要拿掉多少个数才能满足，进行 check 操作。至于如何计算至少要拿掉的数字，我们采用右贪心准则，即检查当前点与上一个点之间的距离是否满足最小差值的要求，如果不满足就需要记数，为了便于后续的计算，直接将当前的下标用上一个点的下标覆盖掉即可
时间复杂度：
<br><br>#include &lt;bits/stdc++.h&gt;
#define int long long 
using namespace std;

const int N = 5e4 + 10;

int lim, n, k;
int a[N], b[N];
bool del[N];

bool ok(int x) {
	int cnt = 0;
	memset(del, false, sizeof del);
	
	for (int i = 1; i &lt;= n; i++) {
		b[i] = a[i];
	}
	
	for (int i = 1; i &lt;= n; i++) {
		if (b[i] - b[i - 1] &lt; x) {
			del[i] = true;
			b[i] = b[i - 1];
			cnt++;
		}
	}
	
	if (lim - b[n] &lt; x) {
		cnt++;
	}
	
	return cnt &lt;= k;
}

void solve() {
	cin &gt;&gt; lim &gt;&gt; n &gt;&gt; k;
	for (int i = 1; i &lt;= n; i++)
		cin &gt;&gt; a[i];
	
	int l = 1, r = lim;
	while (l &lt; r) {
		int mid = (l + r + 1) &gt;&gt; 1;
		if (ok(mid)) l = mid;
		else r = mid - 1;
	}
	
	cout &lt;&lt; r &lt;&lt; "\n";
}

signed main() {
	ios::sync_with_stdio(false);
	cin.tie(nullptr), cout.tie(nullptr);
	int T = 1;
//	cin &gt;&gt; T;
	while (T--) solve();	
	return 0;
}
<br><br><br><br>给你一个&nbsp;m&nbsp;行&nbsp;n&nbsp;列的矩阵&nbsp;matrix&nbsp;，请按照&nbsp;顺时针螺旋顺序&nbsp;，返回矩阵中的所有元素。<br>示例 1：<br><img src="https://assets.leetcode.com/uploads/2020/11/13/spiral1.jpg" referrerpolicy="no-referrer"><br>示例 2：<br><img src="https://assets.leetcode.com/uploads/2020/11/13/spiral.jpg" referrerpolicy="no-referrer"><br>提示：<br>
<br>m == matrix.length
<br>n == matrix[i].length
<br>1 &lt;= m, n &lt;= 10
<br>-100 &lt;= matrix[i][j] &lt;= 100
<br>题目链接：<a data-tooltip-position="top" aria-label="https://leetcode.cn/problems/spiral-matrix/description/?envType=study-plan-v2&amp;envId=2024-spring-sprint-100" rel="noopener nofollow" class="external-link" href="https://leetcode.cn/problems/spiral-matrix/description/?envType=study-plan-v2&amp;envId=2024-spring-sprint-100" target="_blank">54. 螺旋矩阵 - 力扣（LeetCode）</a><br><br>这道题关键在于什么时候转弯，什么时候停止。对于停止判断需要一个循环，即while(!stop)，对于什么时候转弯，它需要另一个循环，右下左上四个方向循环。走过的不走，越界的不走，无路可走即stop。
<br><br>初始代码：<br>vector&lt;int&gt;circle(vector&lt;vector&lt;int&gt;&gt; &amp;matrix){  
    int row=matrix.size();  
    int col=matrix[0].size();  
    vector&lt;vector&lt;bool&gt;&gt; flag(row,vector&lt;bool&gt;(col));  
    pair&lt;int,int&gt; dirct[4]={{0,1},{1,0},{0,-1},{-1,0}};//右下左上  
    bool stop=false; int i=0,j=0;  
    vector&lt;int&gt;res;  
        res.push_back(matrix[i][j]);  
    cout&lt;&lt;matrix[i][j]&lt;&lt;' ';flag[0][0]=true;  
        while(!stop){  
        for(int t=0;t&lt;4;t++){  
            i+=dirct[t].first;  
            j+=dirct[t].second;  
            if(i&lt;0||j&lt;0||i&gt;=row||j&gt;=col||flag[i][j]==true){  
                stop=true;break;  
            }  
            while(i&gt;=0&amp;&amp;j&gt;=0&amp;&amp;i&lt;row&amp;&amp;j&lt;col&amp;&amp;flag[i][j]==false){  
                res.push_back(matrix[i][j]);cout&lt;&lt;matrix[i][j]&lt;&lt;' ';flag[i][j]=true;  
                i+=dirct[t].first;j+=dirct[t].second;  
            }  
            i-=dirct[t].first;  
            j-=dirct[t].second;  
        }  
    }        return res;  
}
<br>这段代码对于只有一列的二维数组是错误的，由于将matrix第一个元素单独处理，导致它进入第一次向右操作时直接违法stop。是否可以将第一个放入循环，初步修改如下：<br>    if(i&lt;0||j&lt;0||i&gt;=row||j&gt;=col||flag[i+dirct[t].first][j+dirct[t].second]==true){  
                stop=true;break;  
            }  
            i+=dirct[t].first;  
            j+=dirct[t].second;
<br>仍然存在问题，决定从头修改结构。<br>vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {
        int row=matrix.size();
        int col=matrix[0].size();
        vector&lt;vector&lt;bool&gt;&gt; flag(row,vector&lt;bool&gt;(col));
        pair&lt;int,int&gt; dirct[4]={{0,1},{1,0},{0,-1},{-1,0}};//右下左上
        bool stop=false; int i=0,j=0;
        vector&lt;int&gt;res;
        
        res.push_back(matrix[i][j]);
        flag[0][0]=true;

        while(!stop){
            stop = true;  // 假设所有的位置都已经遍历结束
            for(int t = 0; t &lt; 4; t++)
            {
                while (true)  // 尝试按照当前的方向前进
                {
                    int new_i = i + dirct[t].first;
                    int new_j = j + dirct[t].second;
                    // 如果新的位置越界或者已经被访问过，就换一个新的方向
                    if (new_i &lt; 0 || new_i &gt;= row || new_j &lt; 0 || new_j &gt;= col || flag[new_i][new_j] == true) {
                        break;
                    }
                    // 否则，前进到新的位置，并标记新的位置已被访问
                    i = new_i;
                    j = new_j;

                    res.push_back(matrix[i][j]);
                    cout &lt;&lt; matrix[i][j] &lt;&lt; ' ';
                    flag[i][j] = true;
                    stop = false;  // 只要有新的位置被访问，就表示还没有遍历结束
                }
            }
        }
        return res;
    }
<br><br>#include&lt;iostream&gt;  
#include&lt;vector&gt;  
using namespace std;

vector&lt;int&gt; spiralOrder(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {
        int row=matrix.size();
        int col=matrix[0].size();
        vector&lt;vector&lt;bool&gt;&gt; flag(row,vector&lt;bool&gt;(col));
        pair&lt;int,int&gt; dirct[4]={{0,1},{1,0},{0,-1},{-1,0}};//右下左上
        bool stop=false; int i=0,j=0;
        vector&lt;int&gt;res;
        
        res.push_back(matrix[i][j]);
        flag[0][0]=true;

        while(!stop){
            stop = true;  // 假设所有的位置都已经遍历结束
            for(int t = 0; t &lt; 4; t++)
            {
                while (true)  // 尝试按照当前的方向前进
                {
                    int new_i = i + dirct[t].first;
                    int new_j = j + dirct[t].second;
                    // 如果新的位置越界或者已经被访问过，就换一个新的方向
                    if (new_i &lt; 0 || new_i &gt;= row || new_j &lt; 0 || new_j &gt;= col || flag[new_i][new_j] == true) {
                        break;
                    }
                    // 否则，前进到新的位置，并标记新的位置已被访问
                    i = new_i;
                    j = new_j;

                    res.push_back(matrix[i][j]);
                    cout &lt;&lt; matrix[i][j] &lt;&lt; ' ';
                    flag[i][j] = true;
                    stop = false;  // 只要有新的位置被访问，就表示还没有遍历结束
                }
            }
        }
        return res;
    }
      
int main()  
{  
    vector&lt;vector&lt;int&gt;&gt; matrix;  
    matrix = {{2},{3}};  
    spiralOrder(matrix);  
    return 0;  
}
<br><br><br>题目链接：<a data-tooltip-position="top" aria-label="https://leetcode.cn/problems/game-of-life/description/?envType=study-plan-v2&amp;envId=2024-spring-sprint-100" rel="noopener nofollow" class="external-link" href="https://leetcode.cn/problems/game-of-life/description/?envType=study-plan-v2&amp;envId=2024-spring-sprint-100" target="_blank">289. 生命游戏 - 力扣（LeetCode）</a><br>生命游戏&nbsp;，简称为&nbsp;生命&nbsp;，是英国数学家约翰·何顿·康威在 1970 年发明的细胞自动机。<br>给定一个包含&nbsp;m × n&nbsp;个格子的面板，每一个格子都可以看成是一个细胞。每个细胞都具有一个初始状态：&nbsp;1&nbsp;即为&nbsp;活细胞&nbsp;（live），或&nbsp;0&nbsp;即为&nbsp;死细胞&nbsp;（dead）。每个细胞与其八个相邻位置（水平，垂直，对角线）的细胞都遵循以下四条生存定律：<br>
<br>如果活细胞周围八个位置的活细胞数少于两个，则该位置活细胞死亡；
<br>如果活细胞周围八个位置有两个或三个活细胞，则该位置活细胞仍然存活；
<br>如果活细胞周围八个位置有超过三个活细胞，则该位置活细胞死亡；
<br>如果死细胞周围正好有三个活细胞，则该位置死细胞复活；
<br>下一个状态是通过将上述规则同时应用于当前状态下的每个细胞所形成的，其中细胞的出生和死亡是同时发生的。给你&nbsp;m x n&nbsp;网格面板&nbsp;board&nbsp;的当前状态，返回下一个状态。<br>示例 1：<br><img src="https://assets.leetcode.com/uploads/2020/12/26/grid1.jpg" referrerpolicy="no-referrer"><br>示例 2：<br><img src="https://assets.leetcode.com/uploads/2020/12/26/grid2.jpg" referrerpolicy="no-referrer"><br>提示：<br>
<br>m == board.length
<br>n == board[i].length
<br>1 &lt;= m, n &lt;= 25
<br>board[i][j]&nbsp;为&nbsp;0&nbsp;或&nbsp;1
<br><br>这道题如果不原地操作本质不难，只要复制一个next_board，然后遍历board根据条件判断细胞存活与否即可。<br><br>void gameOfLife(vector&lt;vector&lt;int&gt;&gt;&amp; board) {  
	pair&lt;int,int&gt;dirct[8]={{-1,-1},{0,-1},{1,-1},{-1,0},{1,0},{-1,1},{0,1},{1,1},};  
	vector&lt;vector&lt;int&gt;&gt; ne=board;  
    int n=board.size();  
    int m=board[0].size();  
    for(int i=0;i&lt;n;i++){  
        for(int j=0;j&lt;m;j++){  
            int count=0;  
            for(int k=0;k&lt;8;k++){  
                int new_i=i+dirct[k].first;  
                int new_j=j+dirct[k].second;  
                if(new_i&lt;0||new_i&gt;n-1||new_j&lt;0||new_j&gt;m-1){  
                    continue;  
                }  
                if(board[new_i][new_j]==1) count++;  
            }  
            if(board[i][j]==1){  
                if(count&lt;2||count&gt;3) ne[i][j]=0;  
                else ne[i][j]=1;  
            }  
            else{  
                if(count==3) ne[i][j]=1;  
            }  
        }  
    }  
    board=ne;  
}
<br><br><br>题目链接：<a data-tooltip-position="top" aria-label="https://leetcode.cn/problems/rotate-image/description/?envType=study-plan-v2&amp;envId=2024-spring-sprint-100" rel="noopener nofollow" class="external-link" href="https://leetcode.cn/problems/rotate-image/description/?envType=study-plan-v2&amp;envId=2024-spring-sprint-100" target="_blank">48. 旋转图像 - 力扣（LeetCode）</a><br>给定一个&nbsp;n&nbsp;×&nbsp;n&nbsp;的二维矩阵&nbsp;matrix&nbsp;表示一个图像。请你将图像顺时针旋转 90 度。<br>你必须在&nbsp;<a data-tooltip-position="top" aria-label="https://baike.baidu.com/item/%E5%8E%9F%E5%9C%B0%E7%AE%97%E6%B3%95" rel="noopener nofollow" class="external-link" href="https://baike.baidu.com/item/%E5%8E%9F%E5%9C%B0%E7%AE%97%E6%B3%95" target="_blank">原地</a>&nbsp;旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要&nbsp;使用另一个矩阵来旋转图像。<br>示例 1：<br><img src="https://assets.leetcode.com/uploads/2020/08/28/mat1.jpg" referrerpolicy="no-referrer"><br>示例 2：<br><img src="https://assets.leetcode.com/uploads/2020/08/28/mat2.jpg" referrerpolicy="no-referrer"><br>提示：<br>
<br>n == matrix.length == matrix[i].length
<br>1 &lt;= n &lt;= 20
<br>-1000 &lt;= matrix[i][j] &lt;= 1000
<br><br>这道题旋转的是一个n*n的矩阵，所以可以简化想法，一层一层旋转即可，每次宽度减少2。重点在于对每一层进行旋转时的交换操作。<br><br>void rotate(vector&lt;vector&lt;int&gt;&gt;&amp; matrix) {

    int l=matrix.size();

    int st=0;

    for(int n=l;n&gt;0;n-=2,st++){

        for(int i=st;i&lt;st+n-1;i++){

            swap(matrix[st][i],matrix[2*st-i+n-1][st]);//上左交换

            swap(matrix[2*st-i+n-1][st],matrix[st+n-1][2*st-i+n-1]);

            swap(matrix[st+n-1][2*st-i+n-1],matrix[i][st+n-1]);

        }

    }
}
<br>其中，最关键的是这几句：<br>  swap(matrix[st][i],matrix[2*st-i+n-1][st]);//上左交换

  swap(matrix[2*st-i+n-1][st],matrix[st+n-1][2*st-i+n-1]);

  swap(matrix[st+n-1][2*st-i+n-1],matrix[i][st+n-1]);
<br><br><br>时间限制 : 1000 ms<br>空间限制 : 256 MB<br>题目链接：<a data-tooltip-position="top" aria-label="https://hydro.ac/d/nnu_contest/p/52?tid=65ed9dfaf721466dd08a6069" rel="noopener nofollow" class="external-link" href="https://hydro.ac/d/nnu_contest/p/52?tid=65ed9dfaf721466dd08a6069" target="_blank">Problem Detail - Problem B. 你说的对，但是这是签到 II - HydroOJ</a><br><br>一个字符串s,将其补全成回文字符串，从s[n-1]开始，即s1s2...s(n-1)s(n)s(n-1)s(n-2)...s1。
现在，pzr 希望用&nbsp;**黑白两种颜色**&nbsp;将字符串&nbsp;�t&nbsp;染色，其中每个字符可以染成黑色，也可以染成白色。这样，被染成黑色的字符构成一个子序列，被染成白色的字符构成一个子序列。

在所有染色方案中，考虑满足以下条件的染色方案数：

- 至少有一个字符被染成黑色，至少有一个字符被染成白色。
- 被染成黑色的字符构成的子序列，其字典序&nbsp;**严格大于**&nbsp;被染成白色的字符构成的子序列。
<br><br>仅一个字符串&nbsp;s<br><br>仅一个非负整数，表示满足条件的方案数。<br>可以证明，答案一定在 32 位整数可表示的范围内。 <br><br>这道题本质是靠状态压缩，题目中已经给了明确的提示。即二进制枚举，这是一种状态压缩的技巧。例如有&nbsp;n&nbsp;件物品，需要枚举各个物品选与不选的情况，不必写&nbsp;n&nbsp;重循环&nbsp;for iter_k in (0, 1):，特别是&nbsp;n&nbsp;比较大或者&nbsp;n&nbsp;的值可能变化时。我们可以将&nbsp;n&nbsp;件物品的选与不选用&nbsp;0&nbsp;和&nbsp;1&nbsp;表示，再将这&nbsp;n&nbsp;件物品的状态拼成一个&nbsp;n&nbsp;位二进制数。通过&nbsp;for mask in range(0, 2 ** n):&nbsp;枚举这些状态，既不重复又不遗漏。<br><br>//19220423 李世博  
//B  
#include&lt;iostream&gt;  
#include&lt;cmath&gt;  
using namespace std;  
string s;  
int length;  
string transform(int n){  
    string tmp;  
    string res;  
    while(n&gt;0){  
        int y=n%2;  
        tmp.push_back(y+'0');  
        n/=2;  
    }  
    int num=tmp.size();  
    while(num&lt;length){  
        res.push_back('0');  
        num++;  
    }  
    int i=0;  
    for(int i=tmp.size()-1;i&gt;=0;i--){  
        res.push_back(tmp[i]);  
    }  
    return res;  
}//返回的二进制序列是反的 void buquan(string &amp;S){  
    int l = S.size();  
    for(int i=l-2;i&gt;=0;i--){  
        S.push_back(S[i]);  
    }  
}  
  
int main(){  
    cin&gt;&gt;s;  
    buquan(s);  
    long long count=0;  
    length=int(s.size());  
    for(int i=1;i&lt;pow(2,length)-1;i++){  
        string tmp=transform(i);  
        string s1,s2;//s1黑         
        for(int i=0;i&lt;length;i++){  
            if(tmp[i]=='0'){  
                s2.push_back(s[i]);             }  
            else{  
                s1.push_back(s[i]);  
            }  
                    }  
        if(s1&gt;s2) count++;  
    }  
    cout&lt;&lt;count&lt;&lt;endl;  
    return 0;  
}
<br><br><br><br><a rel="noopener nofollow" class="external-link" href="https://vijos.org/d/nnu_contest/contest/665376e56e955279ba03e4a6/1599" target="_blank">https://vijos.org/d/nnu_contest/contest/665376e56e955279ba03e4a6/1599</a><br><br>//Problem 7A. EMO DEMO 2
//2
//0
//emotimenow
//1
//5
//1 2 3 4 5
//Emo
//NoEmo

#include&lt;iostream&gt;
using namespace std;

void solve_string(){
	string s;cin&gt;&gt;s;
	string t="emo";
	int i=0;int j=0;
	for( i=0,j=0;i&lt;int(s.size()),j&lt;3;i++){
		if(s[i]==t[j]) j++;
		else j=0;
	}
	if(i==int(s.size())) cout&lt;&lt;"NoEmo"&lt;&lt;endl;
	else cout&lt;&lt;"Emo"&lt;&lt;endl;
}

void solve_arr(){
	int len;cin&gt;&gt;len;
	int a[10]={0};
	for(int i=0;i&lt;len;i++){
		cin&gt;&gt;a[i];
	}
	for(int i=0;i&lt;len-1;i++){
		if(a[i]&lt;a[i+1]||(i+2&gt;=len)) continue;
		else{
			if(a[i]==a[i+1]==a[i+2]||a[i]&gt;a[i+1]&gt;a[i+2]){
				cout&lt;&lt;"Emo"&lt;&lt;endl;
				return;
			}
		}
	}
	cout&lt;&lt;"NoEmo"&lt;&lt;endl;
}


int main(){
	int n;cin&gt;&gt;n;
	while(n!=0){
		n--;
		int label;cin&gt;&gt;label;
		if(label==1) solve_arr();
		else solve_string();
	}
	return 0;
}
<br><br><br>#include &lt;queue&gt;
	priority_queue&lt;int&gt; pq1 // 大根堆
	priority_queue&lt;int, vector&lt;int&gt;, greater&lt;int&gt;&gt; pq2 // 小根堆
<br>
也可用multimap
<br><br><br><a rel="noopener nofollow" class="external-link" href="https://vijos.org/d/nnu_contest/contest/665376e56e955279ba03e4a6/1602" target="_blank">https://vijos.org/d/nnu_contest/contest/665376e56e955279ba03e4a6/1602</a><br>#include&lt;iostream&gt;
#include&lt;queue&gt;
using namespace std;
const int N=1e6+1;
int main(){
	int n,q;cin&gt;&gt;n&gt;&gt;q;
	int a[N]={0};
	priority_queue&lt;int&gt; pq;
	for(int i=0;i&lt;n;i++){
		int tmp;cin&gt;&gt;tmp;
		a[i]=tmp;
		pq.push(tmp);
	}	
	for(int i=0;i&lt;q;i++){
		int qq;cin&gt;&gt;qq;
		int sum=0;
		priority_queue&lt;int&gt; pq_tmp=pq;
		while(pq_tmp.top()!=a[qq-1]&amp;&amp;(pq_tmp.empty()==0)){
			sum+=pq_tmp.top();
			pq_tmp.pop();
		}
		cout&lt;&lt;sum&lt;&lt;endl;
	}
	return 0;
}
<br><br><br><br>如何使用快排思想查找第k大数。(复杂度控制在O(n))<br>给定整数数组&nbsp;`nums`&nbsp;和整数&nbsp;`k`，请返回数组中第&nbsp;`k`&nbsp;个最大的元素。

请注意，你需要找的是数组排序后的第&nbsp;`k`&nbsp;个最大的元素，而不是第&nbsp;`k`&nbsp;个不同的元素。

你必须设计并实现时间复杂度为&nbsp;`O(n)`&nbsp;的算法解决此问题。
<br>题目链接：<a data-tooltip-position="top" aria-label="https://leetcode.cn/problems/kth-largest-element-in-an-array/description/" rel="noopener nofollow" class="external-link" href="https://leetcode.cn/problems/kth-largest-element-in-an-array/description/" target="_blank">215. 数组中的第K个最大元素 - 力扣（LeetCode）</a><br><br>快排的最关键思路是划分，设定划分边界值x，将数组中比x大的放到一边，比x小的放到另一边。如果我们想要找到第k大的数，那么只需要保证，我的划分边界值x左边有确定的k-1个比它大的数，即可确定x即为所求值。

具体操作即是调用划分操作，返回pivot下标，判断k与下标mid的关系，来确定是否需要继续递归。如果mid==k-1则可以返回num[mid]。而由于没有其他返回值，只有这一个值可能返回到最上层，则可求出第k大的值。
<br><br>在处理partition操作返回值的时候出现了问题。这是我一开始的partition代码：<br>int partition(int left, int right, vector&lt;int&gt;&amp; num) {
	int i = left, j = right; int x = num[(left + right) / 2]; 
	 while(i &lt; j) { 
		while(num[i] &lt; x) i++; 
		while(num[j] &gt; x) j--; 
		if(i &lt; j) { swap(num[i++], num[j--]); // 避免等于x的值无限循环的问题 
	}
	return i; // 返回划分的位置，左边都是小于x的，右边都是大于等于x的 }
<br>实际上在大部分情况下它都能正确地返回 pivot 的索引。<br>
问题在于：返回&nbsp;i&nbsp;不一定是&nbsp;pivot(即&nbsp;x)的正确位置。<br>更改后的partition操作如下：<br>int partition( int left, int right,vector&lt;int&gt;&amp; num) {  
    int pivot = num[right];  // 选择最右边的元素作为pivot  
    int i = left - 1;  // i用来追踪大于pivot的元素的最后一个索引位置  
    for (int j = left; j &lt; right; ++j) {  
        if (num[j] &gt; pivot) {  // 如果当前元素大于pivot  
            ++i;  // 移动到下一个索引  
            swap(num[i], num[j]);  // 交换大于pivot的元素和当前元素  
        }  
    }  
    // 最后交换pivot和第一个小于pivot的元素  
    swap(num[i+1], num[right]);  
    return i + 1;  // 返回pivot的索引  
}  
<br><br>
<br>时间复杂度：平均:O(n)，最坏:(O(n^2))
<br><br>int findKthLargest(vector&lt;int&gt;&amp; num, int k) {  
    int l=0,r=num.size()-1;  
    return findk(num,0,r,k);  
}  
  
int partition( int left, int right,vector&lt;int&gt;&amp; num) {  
    int pivot = num[right];  // 选择最右边的元素作为pivot  
    int i = left - 1;  // i用来追踪大于pivot的元素的最后一个索引位置  
        for (int j = left; j &lt; right; ++j) {  
        if (num[j] &gt; pivot) {  // 如果当前元素大于pivot  
            ++i;  // 移动到下一个索引  
            swap(num[i], num[j]);  // 交换大于pivot的元素和当前元素  
        }  
    }  
        // 最后交换pivot和第一个小于pivot的元素  
    swap(num[i+1], num[right]);  
        return i + 1;  // 返回pivot的索引  
}  
  
int findk(vector&lt;int&gt;&amp;num,int l,int r,int k){  
    int mid=partition(l,r,num);  
    if(mid==k-1) return num[mid];//如果相等就返回  
    else if(mid&lt;k-1){  
        return findk(num,mid+1,r,k);  
    }     else{  
        return findk(num,l,mid-1,k);  
    }  
}
<br><br><br>给定一个数组，求该数组从绝对乱序(即每一个数字都与排序后的位置不同)到现在的状态经历过几次划分操作。
<br>自命题。<br><br>这道题是快排的一个演变，用来验证快排的状态。快排的过程本质上是将一个个pivot放到正确的位置，每次放一个，每一次划分操作的时间复杂度为O(log(n))，总共n个数，所以快排时间复杂度为O(nlog(n))。对于每一次划分操作后，都会多出一个数，这个数前面的数都小于它，后面的数都大于等于它。所以根据这一性质，我们可以对于一个乱序数组判断其是由几次划分操作得到的。

从前往后遍历，对于每一个值，找到其前面数中，最大的值。
同理，从后往前遍历，对于每一个值找到其后面数中最小的值。
最后只需遍历一遍，即可判断划分次数。
<br><br>
<br>时间复杂度：共遍历三次，每次遍历需要n次操作。共3n次操作。时间复杂度为O(n)
<br><br>#include&lt;iostream&gt;  
#include&lt;vector&gt;  
using namespace std;  
  
//给定一个数组，求该数组从绝对乱序(即每一个数字都与排序后的位置不同)到现在的状态经历过几次划分操作。  
  
/*  
  6  
  3 2 4 0 6 7  
 */ // 即 6,7分别处在划分操作之后的位置。即经过两次划分操作  
  
// 思路：从左往右找每一个数左边的最大值，从右往左找每一个数右边的最小值。最左边放-1e9,最右边放1e9  
  
struct Max_Min{  
    int num;  
    int left_max;  
    int right_min;  
};  
  
void find(vector&lt;Max_Min&gt; &amp;data){  
    int tmp=data.size();  
    int max=-1e9;  
    for(int i=0;i&lt;tmp;i++){  
        data[i].left_max=max;  
        if(data[i].num&gt;max){  
            max=data[i].num;  
        }  
    }  
    int min=1e9;  
    for(int i=tmp-1;i&gt;=0;i--){  
        data[i].right_min=min;  
        if(data[i].num&lt;min){  
            min=data[i].num;  
        }  
    }  
}  
  
  
  
int main(){  
    vector&lt;Max_Min&gt;data;  
    int n;cin&gt;&gt;n;  
    data.resize(n);  
    for(int i=0;i&lt;n;i++){  
        cin&gt;&gt;data[i].num;  
    }  
    int res=0;  
    find(data);  
    for(int i=0;i&lt;data.size();i++){  
        if(data[i].right_min&gt;=data[i].num&amp;&amp;data[i].num&gt;=data[i].left_max){  
            res++;  
        }  
    }  
    cout&lt;&lt;res&lt;&lt;endl;  
    return 0;  
}

<br><br>要证明这个数学原理，我们需要几个步骤：<br>
<br>找到小于等于N的所有质数
<br>确定这些质数的最大幂次
<br>计算这些最大幂次的乘积
<br>这实际上是在计算1到N之间所有整数的最小公倍数（LCM）。我们将逐步解释这个过程。<br><br>小于等于N的质数是所有小于等于N的整数中仅能被1和它自己整除的数。例如，对于N=10，质数是2, 3, 5, 7。<br><br>对于每个质数p，我们找到最大的整数k，使得。<br>
<br>对于质数p=2，找到的k使得，即（因为）。
<br>对于质数p=3，找到的k使得，即（因为）。
<br>对于质数p=5，找到的k使得，即（因为）。
<br>对于质数p=7，找到的k使得，即（因为）。
<br><br>将所有这些最大幂次的质数乘积相乘，就是1到N之间所有整数的最小公倍数：<br><br><br>这个算法的核心在于：<br>
<br>
质数的幂次覆盖所有整数的质因数分解：

<br>每个整数可以分解成质数的幂次乘积。
<br>为了找到所有整数的LCM，我们需要包括每个质数的最大必要幂次。


<br>
最小公倍数的性质：

<br>LCM是可以整除所有给定整数的最小正整数。
<br>通过包含每个质数的最大必要幂次，确保LCM包含所有整数的所有质因数分解。


<br><br>
<br>质数：2, 3, 5, 7
<br>最大幂次：2^3, 3^2, 5^1, 7^1
<br>最小公倍数：2^3 × 3^2 × 5^1 × 7^1 = 2520
<br>每个质数的幂次已经被选择，使得任何小于等于10的整数的质因数分解都包含在内。因此，这个方法是正确且有效的。<br>通过这个过程和证明，可以确认我们找到的是正确的最小公倍数。]]></description><link>technology\collegeproject\算法设计\算法设计解题报告.html</link><guid isPermaLink="false">Technology/CollegeProject/算法设计/算法设计解题报告.md</guid><pubDate>Tue, 11 Jun 2024 09:11:27 GMT</pubDate><enclosure url="https://assets.leetcode.com/uploads/2020/11/13/spiral1.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://assets.leetcode.com/uploads/2020/11/13/spiral1.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[最优化方法]]></title><description><![CDATA[ 
 <br><br>
<br><a data-tooltip-position="top" aria-label="https://github.com/luoyt14/OptimalMethod" rel="noopener nofollow" class="external-link" href="https://github.com/luoyt14/OptimalMethod" target="_blank">luoyt14/OptimalMethod: 最优化方法课程相关资料 (github.com)</a>
<br><a data-tooltip-position="top" aria-label="https://hasegawaazusa.github.io/optimization-method-basis-note.html" rel="noopener nofollow" class="external-link" href="https://hasegawaazusa.github.io/optimization-method-basis-note.html" target="_blank">最优化方法——理论基础 | 独奏の小屋 (hasegawaazusa.github.io)</a>
<br><br><br><img alt="文档扫描_20240705095141583.jpg" src="\lib\media\文档扫描_20240705095141583.jpg"><br>
<img alt="文档扫描_20240705095141816_edit_5268436419369005 1.jpg" src="\lib\media\文档扫描_20240705095141816_edit_5268436419369005-1.jpg"><br>
<img alt="文档扫描_20240705095141971.jpg" src="\lib\media\文档扫描_20240705095141971.jpg"><br><br><br>在线性代数中，矩阵的正定性、负定性和不定性都是描述矩阵特性的重要方法。以下是这三种类型的矩阵的定义：<br>
正定矩阵：一个实对称矩阵A。对于任何非零的实向量 x，都有，那么我们就说矩阵A是正定的。<br>
负定矩阵：一个实对称矩阵B。对于任何非零的实向量 x，都有，那么我们就说矩阵B是负定的。<br>
不定矩阵：一个实对称矩阵C。如果存在非零实向量 x、y，使得和，那么我们就说矩阵C是不定的。<br>以下是正定矩阵、负定矩阵以及不定矩阵的例子：<br>
正定矩阵：对于一个2x2的正定矩阵，我们可以取如下形式：<br>
<br>
<br>
对于任何非零向量，都有，因此这个矩阵是正定的。<br>
负定矩阵：对于一个2x2的负定矩阵，我们可以取如下形式：<br>
<br>
<br>
对于任何非零向量，都有，因此这个矩阵是负定的。<br>
不定矩阵：对于一个2x2的不定矩阵，我们可以取如下形式：<br>
<br>
<br>
取向量，有，取向量，有，因此这个矩阵是不定的。<br><br>判断一个矩阵是否为正定、负定或不定，最常用的方法是查看该矩阵的所有主子式的取值情况。<br>
如果一个矩阵的所有主子式都大于零，那么这个矩阵是正定的。<br>
如果一个矩阵的所有主子式按照“正、负、正、负……”的顺序变化，那么这个矩阵是负定的。<br>
如果这个矩阵的主子式中既有正数也有负数，但并不满足上述两种情况，那么这个矩阵是不定的。<br>
需要注意的是，这种方法只适用于实对称矩阵。对于非对称矩阵，判断其是否为正定矩阵更加复杂，通常需要借助其他的数学工具，例如矩阵的谱。<br>
上面的方法虽然直观，但如果矩阵维度大，计算所有主子式会比较麻烦，所以在实际应用中，我们常常使用更加高效的办法，例如矩阵的特征值：对于一个实对称矩阵，如果它的所有特征值都大于零，那么它就是正定的；如果所有特征值都小于零，那么它就是负定的；如果既有正特征值又有负特征值，那么它就是不定的。<br><br>如果海瑟矩阵是正定的，那么对应的函数在该点处具有局部最小值。换句话说，函数在该点附近的值都大于或等于在该点的值。这是因为正定矩阵对应的二次型函数总是大于零，所以在该点附近，函数值总是处于增加状态。<br>如果海瑟矩阵是负定的，那么对应的函数在该点处具有局部最大值。换句话说，函数在该点附近的值都小于或等于在该点的值。这是因为负定矩阵对应的二次型函数总是小于零，所以在该点附近，函数值总是处于减少状态。<br>如果海瑟矩阵是不定的，那么对应的函数在该点处既不是局部最大值也不是局部最小值，同时在不同的方向上，函数的增减性也会有所不同。这就意味着在该点附近，函数形状是一种鞍形。<br><br>主子式（Principal Minor）：在矩阵中选取r行和r列（必须是同样的行和列次序），由这些行列元素构成的新的r级方阵的行列式叫做原矩阵的r阶主子式。例如在一个3阶的矩阵A中，我们有3个1阶主子式，2个2阶主子式，以及1个3阶主子式。这也是为什么在判断矩阵的正定性时，需要检查它的所有阶数的主子式。<br>
实对称矩阵（Symmetric Matrix）：如果一个矩阵的转置与其本身相等，即A^T = A，那么我们就称这个矩阵为对称矩阵。这里的“实”就表示我们所考虑的矩阵中的元素都是实数。对称矩阵有许多性质，例如其所有的特征值都是实数，可以对角化等等。<br><br>主子式大于零的意思就是该主子式所对应的行列式的值大于零。<br>
行列式是一个函数，定义在方阵（也就是行数和列数相等的矩阵）上。给定一个n阶方阵A，我们可以对A进行各种行列变换，然后得到一个与A等价的三角矩阵，再将三角矩阵对角线上的元素相乘，其结果就是A的行列式。<br>
主子式，顾名思义，就是矩阵的一部分，我们选择某几行和相对应的列组成的子方阵的行列式就是主子式。<br>
比如说，给定一个2阶方阵其中a、b、c、d为任意实数，我们可以看到，矩阵A的1阶主子式有两个，分别是a和d，2阶的主子式有一个，就是整个方阵A的行列式 = ad - bc。<br>
所以，当我们说主子式大于零，就是说这些主子式（也就是子方阵的行列式）的值都大于零。<br><br><br><br>对这道题用普通单纯形法求解，并写出单纯形表的变化<br>为了使用普通单纯形法来求解这个线性规划问题，我们需要将它转换为标准形式并构造初始单纯形表。问题可以重新表述如下：<br><br>其中， 和  是松弛变量。<br>接下来，我们构造初始单纯形表。<br><br><br><br>我们选择  作为入基变量，因为它的系数  是目标行中最正的数。<br>为了确定出基变量，我们计算右端值与对应系数的比值：<br><br>所以，  是出基变量。我们进行枢纽操作（Pivot Operation）。<br>枢纽元素是  （在  和  的交点）。我们将  行除以枢纽元素：<br><br><br>更新其他行：<br>对于  行，我们进行操作 ：<br><br><br>对于目标行 ，我们进行操作 :<br><br><br>选择  作为入基变量，因为它的系数  是目标行中最负的数。<br>为了确定出基变量，我们计算右端值与对应系数的比值：<br><br>所以，  是出基变量。我们进行枢纽操作（Pivot Operation）。<br>枢纽元素是  （在  和  的交点）。我们将  行除以枢纽元素：<br><br><br>更新其他行：<br>对于  行，我们进行操作 ：<br><br>对于目标行 ，我们进行操作 :<br><br>所以最终的单纯形表是：<br><br><br>从最终的单纯形表可以看出，最优解为：<br><br>目标函数的最小值为：<br><br><br>对偶单纯形法在实际应用中主要用于解决约束条件大于等于型的线性规划问题。一般来说对于小于等于型的问题，我们倾向于使用普通的单纯形法；对于大于等于型的问题，则更多的会采用对偶单纯形法。<br>"大于等于型"是指约束条件中所有的不等式都是大于等于型的，即它们的形式均为 A &gt;= B。<br>对于目标函数，它既可以是最大化目标函数也可以是最小化目标函数。线性规划问题是寻找一组变量的最优解，使得目标函数（可以是收益最大化或成本最小化）达到最优（最大或最小），同时满足一系列线性约束条件。约束条件可以是等式也可以是不等式，但是不等式约束又可以具体被分为两类：小于等于型和大于等于型。<br>小于等于型的线性规划问题常常采取使用原始单纯形法求解，而大于等于型的问题一般使用对偶单纯形法求解。这是因为两种方法在解决不同类型的约束条件时，效率和精度有所区别。<br>
需要注意的是，不仅可以通过转化方法（例如，乘以-1）来改变大于等于型为小于等于型，对偶单纯形法还可以直接应用于这类问题，这是由于它在理论上从对偶问题入手，通过求解对偶问题得到原问题的解。<br>对于混合型问题，即约束条件中既有大于等于型也有小于等于型的问题，我们一般会通过一些方法将其转化为单一类型的问题，然后再使用相应的求解方法。<br><br><br><img alt="Pasted image 20240521163938.png" src="\lib\media\pasted-image-20240521163938.png"><br><br><img alt="Pasted image 20240521164049.png" src="\lib\media\pasted-image-20240521164049.png"><br><img alt="Pasted image 20240521164207.png" src="\lib\media\pasted-image-20240521164207.png"><br><br><img alt="Pasted image 20240521164359.png" src="\lib\media\pasted-image-20240521164359.png"><br>设 (1)用 Goldstein 方法极小化 ,.<br>
(2)用Wolfe方法极小化，.<br>我们需要使用 Goldstein 方法和 Wolfe 方法来极小化函数 ，起始点为 ，其中 Goldstein 方法和 Wolfe 方法的参数分别是  和 。<br><br>Goldstein 方法的步骤如下：<br>
<br>
初始设置:

<br>选择初始点 。
<br>选择一个初始步长 ，可以从 1 开始。


<br>
计算梯度:

<br>计算  的一阶导数 :




<br>
寻找合适的 :

<br>选择满足 Goldstein 条件的步长 :


其中  是搜索方向（通常为负梯度方向），即 ，而  和  是常数参数（例如，  和 ）。


<br>现在我们详细计算：<br>
<br>
初始设置:

<br>
<br>初始步长 


<br>
计算梯度:



<br>
计算搜索方向:


<br>
Goldstein 条件:<br>
我们需要寻找合适的步长 ，满足以下条件：



<br><br>Wolfe 方法的步骤如下：<br>
<br>
初始设置:

<br>选择初始点 。
<br>选择一个初始步长 ，可以从 1 开始。


<br>
计算梯度:

<br>计算  的一阶导数 :




<br>
寻找合适的 :

<br>选择满足 Wolfe 条件的步长 :


其中  是搜索方向（通常为负梯度方向），即 ，而  和 。


<br>现在我们详细计算：<br>
<br>
初始设置:

<br>
<br>初始步长 


<br>
计算梯度:<br>


<br>
计算搜索方向:<br>


<br>
Wolfe 条件:<br>
我们需要寻找合适的步长 ，满足以下条件：



<br>由于 Goldstein 和 Wolfe 方法的具体实现涉及试探不同的  值并检查上述条件是否满足，这里给出了使用这些方法的基本步骤。具体的步长选择需要通过计算和试探来确定。<br><br><img alt="Pasted image 20240522094825.png" src="\lib\media\pasted-image-20240522094825.png"><br>
<img alt="Pasted image 20240522100353.png" src="\lib\media\pasted-image-20240522100353.png"><br>梯度是一个一维数组，表示f对x向量的偏导。d是方向由一系列cos，sin组成，L2范数为1<br>
方向导数即梯度乘方向d的转置。<br>
方向d有无数个，给定一个则就有一个d<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1gu41177ZZ/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">https://www.bilibili.com/video/BV1gu41177ZZ/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea</a><br><a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1pB4y1b7Dk/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">https://www.bilibili.com/video/BV1pB4y1b7Dk/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea</a><br>
看8分钟以后<br>
<img alt="Pasted image 20240706150714.png" src="\lib\media\pasted-image-20240706150714.png"><br>
<img alt="Pasted image 20240706150730.png" src="\lib\media\pasted-image-20240706150730.png"><br>
<img alt="Pasted image 20240706150747.png" src="\lib\media\pasted-image-20240706150747.png"><br>
<img alt="Pasted image 20240706153457.png" src="\lib\media\pasted-image-20240706153457.png"><br><img alt="Pasted image 20240706164619.png" src="\lib\media\pasted-image-20240706164619.png"><br><br><img alt="Pasted image 20240706155150.png" src="\lib\media\pasted-image-20240706155150.png"><br>
<img alt="Pasted image 20240706155215.png" src="\lib\media\pasted-image-20240706155215.png"><br>
<img alt="Pasted image 20240706162211.png" src="\lib\media\pasted-image-20240706162211.png"><br>
<img alt="Pasted image 20240706162312.png" src="\lib\media\pasted-image-20240706162312.png"><br>
<img alt="Pasted image 20240706162432.png" src="\lib\media\pasted-image-20240706162432.png"><br>
<img alt="Pasted image 20240706162921.png" src="\lib\media\pasted-image-20240706162921.png">]]></description><link>technology\collegeproject\最优化\最优化方法.html</link><guid isPermaLink="false">Technology/CollegeProject/最优化/最优化方法.md</guid><pubDate>Mon, 08 Jul 2024 10:20:08 GMT</pubDate><enclosure url="lib\media\文档扫描_20240705095141583.jpg" length="0" type="image/jpeg"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\文档扫描_20240705095141583.jpg&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[凸集和凸函数]]></title><description><![CDATA[ 
 <br><br><br>怎么证明<br><br><br>怎么证明<br>
如何判断一个函数是否是凸函数<br>
看海塞矩阵是否正定<br>如果一个函数的海森矩阵（Hessian matrix）在其定义域内是正定的，那么该函数是严格凸函数。<br><br>海森矩阵是一个二阶导数矩阵，对于多变量函数 ，海森矩阵  定义为：<br><br>如果函数  的海森矩阵  在其定义域内是正定的，即对于任意非零向量 ，有：<br>
那么函数  是严格凸函数。<br><br>正定的海森矩阵意味着在每个方向上，函数的二阶导数都大于零。这表明函数在每个方向上的曲率都是向上的，即函数图像是开口向上的曲面，这正是严格凸函数的特征。<br><br>假设  是二阶可微函数，并且其海森矩阵  在定义域内是正定的。对于任意两个点  和 ，考虑函数 。<br>函数  在  处的二阶导数为：<br>
<br>由于  是正定的，对于任意 ，有 。因此， 是严格凸函数，从而有：<br>
这表明  是严格凸函数。<br><br>如果一个函数的海森矩阵在其定义域内是正定的，那么该函数是严格凸函数。这是二阶导数判定法的一部分，用于检查函数的凸性。<br><br>怎么找极大极小点、稳定点。<br>
先求梯度，再求驻点(即梯度为0的点)，在再看海塞矩阵为正定还是负定，正定极小，负定极大<br>
<img alt="Pasted image 20240708111754.png" src="\lib\media\pasted-image-20240708111754.png"><br><br>最简单的方法：(只能作用于二阶的海塞矩阵)<br>
先求海塞矩阵行列式，如果行列式&gt;0，则特征值.<br>
再求海塞矩阵的迹之和，如果和&gt;0,则则.即为正定。<br>
如果和&lt;0,则则.即为负定。<br><br>要解决一个凸优化问题首先要判断这是个凸优化问题，一是判断可行域是凸集，二是判断优化函数是凸函数，即用上述方法证明。<br><br>只会考基本概念。<br><br><img alt="Pasted image 20240708143148.png" src="\lib\media\pasted-image-20240708143148.png"><br><br><img alt="Pasted image 20240708143457.png" src="\lib\media\pasted-image-20240708143457.png"><br>
例子<br>
<img alt="Pasted image 20240708143529.png" src="\lib\media\pasted-image-20240708143529.png"><br>
第一步：5,4,6变成目标函数系数。<br>
第二步：2,3,-5,1放到不等式右边。<br>
第三步：系数矩阵转置换成y。<br>
第四步：约束条件变变量，变量变约束条件。<br>
第五步：max-&gt;min,变量-&gt;约束条件，不等号不变。min-&gt;max,约束条件-&gt;变量，不等号不变。其他符号反转。<br>
<img alt="Pasted image 20240708143542.png" src="\lib\media\pasted-image-20240708143542.png"><br><br><img alt="Pasted image 20240708150632.png" src="\lib\media\pasted-image-20240708150632.png"><br>
<img alt="Pasted image 20240708150744.png" src="\lib\media\pasted-image-20240708150744.png"><br>
<img alt="Pasted image 20240708150949.png" src="\lib\media\pasted-image-20240708150949.png"><br><br>考小题<br>
了解0.618法和fibonaci法的过程即可。<br><br><img alt="Pasted image 20240708152137.png" src="\lib\media\pasted-image-20240708152137.png"><br>
<img alt="Pasted image 20240708152157.png" src="\lib\media\pasted-image-20240708152157.png"><br>
<img alt="Pasted image 20240708152333.png" src="\lib\media\pasted-image-20240708152333.png"><br>
<img alt="Pasted image 20240708152300.png" src="\lib\media\pasted-image-20240708152300.png"><br>
<img alt="Pasted image 20240708152419.png" src="\lib\media\pasted-image-20240708152419.png"><br><br>斐波那契线性搜索是一种优化算法，适用于一维的无约束优化问题，尤其是在函数评价成本高或计算资源有限的情况下。它通过利用斐波那契数列来减少搜索区间，并在每一步选择下一个候选点，使得搜索区间逐渐缩小。<br><br>
<br>
初始设定：

<br>给定搜索区间  和目标精度 。
<br>计算需要的斐波那契数 ，使得 。


<br>
计算初始点：

<br>根据斐波那契数列，计算两个初始点：





<br>
迭代过程：

<br>评估函数值  和 。
<br>在每一步迭代中，根据函数值比较结果来缩小搜索区间：

<br>如果 ，则搜索区间缩小为 ，并重新计算新点：



<br>如果 ，则搜索区间缩小为 ，并重新计算新点：





<br>减少斐波那契数的索引  并继续迭代，直到达到所需的精度 。


<br>
终止条件：

<br>当  时，停止迭代，此时搜索区间  已经足够小，确定最优解在这个区间内。


<br><br>下面是一个使用Python实现的斐波那契线性搜索的示例代码：<br>def fibonacci_numbers(n):
    fibs = [0, 1]
    for i in range(2, n+1):
        fibs.append(fibs[-1] + fibs[-2])
    return fibs

def fibonacci_search(func, a, b, tol=1e-5):
    # 计算所需的斐波那契数列
    n = 1
    while fibonacci_numbers(n)[-1] &lt; (b - a) / tol:
        n += 1
    fibs = fibonacci_numbers(n)
    
    # 初始点
    x1 = a + fibs[-3] / fibs[-1] * (b - a)
    x2 = a + fibs[-2] / fibs[-1] * (b - a)
    f1 = func(x1)
    f2 = func(x2)
    
    for i in range(n-1, 1, -1):
        if f1 &gt; f2:
            a = x1
            x1 = x2
            f1 = f2
            x2 = a + fibs[i-2] / fibs[i] * (b - a)
            f2 = func(x2)
        else:
            b = x2
            x2 = x1
            f2 = f1
            x1 = a + fibs[i-3] / fibs[i] * (b - a)
            f1 = func(x1)
    
    if f1 &lt; f2:
        return x1
    else:
        return x2

# 示例函数
def f(x):
    return (x-2)**2

# 使用斐波那契线性搜索来最小化函数 f
result = fibonacci_search(f, 0, 4)
print("最优解 x =", result)
print("函数值 f(x) =", f(result))
<br><br>斐波那契线性搜索通过利用斐波那契数列来高效地缩小搜索区间。它在每一步选择下一个候选点，使得搜索区间逐渐缩小，最终在所需的精度范围内找到最优解。这个算法特别适用于目标函数评估成本高的情况，因为它可以最小化评估次数。<br><br><br><a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1gu41177ZZ/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">https://www.bilibili.com/video/BV1gu41177ZZ/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea</a><br><a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1pB4y1b7Dk/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">https://www.bilibili.com/video/BV1pB4y1b7Dk/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea</a><br>
看8分钟以后<br>
<img alt="Pasted image 20240706150714.png" src="\lib\media\pasted-image-20240706150714.png"><br>
<img alt="Pasted image 20240706150730.png" src="\lib\media\pasted-image-20240706150730.png"><br>
<img alt="Pasted image 20240706150747.png" src="\lib\media\pasted-image-20240706150747.png"><br>
<img alt="Pasted image 20240706153457.png" src="\lib\media\pasted-image-20240706153457.png"><br><img alt="Pasted image 20240706164619.png" src="\lib\media\pasted-image-20240706164619.png"><br><br><img alt="Pasted image 20240708221747.png" src="\lib\media\pasted-image-20240708221747.png"><br><br><img alt="Pasted image 20240706155150.png" src="\lib\media\pasted-image-20240706155150.png"><br>
<img alt="Pasted image 20240706155215.png" src="\lib\media\pasted-image-20240706155215.png"><br>
<img alt="Pasted image 20240706162211.png" src="\lib\media\pasted-image-20240706162211.png"><br>
<img alt="Pasted image 20240706162312.png" src="\lib\media\pasted-image-20240706162312.png"><br>
<img alt="Pasted image 20240706162432.png" src="\lib\media\pasted-image-20240706162432.png"><br>
<img alt="Pasted image 20240706162921.png" src="\lib\media\pasted-image-20240706162921.png"><br><br><img alt="Pasted image 20240708221836.png" src="\lib\media\pasted-image-20240708221836.png"><br><br>拟牛顿法（Quasi-Newton Methods）是一类用于解决无约束优化问题的迭代算法。它通过逐步近似目标函数的二阶导数信息（即海森矩阵）来寻找最优解，而不需要直接计算和存储海森矩阵。这使得拟牛顿法在处理高维问题时比牛顿法更加高效。<br>
<img alt="Pasted image 20240709110654.png" src="\lib\media\pasted-image-20240709110654.png"><br>
<img alt="Pasted image 20240709110720.png" src="\lib\media\pasted-image-20240709110720.png"><br>
<img alt="Pasted image 20240709110758.png" src="\lib\media\pasted-image-20240709110758.png"><br><br>拟牛顿法的基本思想是使用一个近似矩阵来代替目标函数的海森矩阵 ，并在每次迭代中更新这个近似矩阵。常见的拟牛顿法包括BFGS方法、DFP方法等，其中BFGS方法是最常用的。<br><br>BFGS方法是拟牛顿法中应用最广泛的一种。它通过以下更新公式逐步修正海森矩阵的近似：<br>
其中：<br>
<br>
<br>
<br> 是第  次迭代的海森矩阵近似
<br><br>
<br>
初始化：

<br>选择初始点 
<br>选择初始海森矩阵近似 ，通常取为单位矩阵 
<br>设定容忍度 


<br>
迭代过程：

<br>计算梯度 
<br>计算搜索方向 
<br>进行一维搜索，确定步长 ，使得  最小
<br>更新位置 
<br>计算新的梯度 
<br>更新差值向量  和 
<br>更新海森矩阵近似 ：




<br>
终止条件：

<br>如果 ，则停止迭代，输出  作为最优解
<br>否则，继续迭代


<br><br>以下是一个使用Python实现的BFGS方法的示例代码：<br>import numpy as np

def bfgs_method(func, grad, x0, tol=1e-5, max_iter=1000):
    n = len(x0)
    x = x0
    I = np.eye(n)
    B = I  # 初始化 B 为单位矩阵
    for _ in range(max_iter):
        g = grad(x)
        if np.linalg.norm(g) &lt; tol:
            break
        p = -np.linalg.inv(B).dot(g)
        alpha = line_search(func, grad, x, p)  # 线搜索确定步长
        x_new = x + alpha * p
        s = x_new - x
        g_new = grad(x_new)
        y = g_new - g
        if s.T.dot(y) &gt; 0:  # 防止数值不稳定性
            Bs = B.dot(s)
            B = B + np.outer(y, y) / y.T.dot(s) - np.outer(Bs, Bs) / s.T.dot(Bs)
        x = x_new
    return x

def line_search(func, grad, x, p, alpha0=1, c1=1e-4, rho=0.9):
    alpha = alpha0
    while func(x + alpha * p) &gt; func(x) + c1 * alpha * grad(x).T.dot(p):
        alpha *= rho
    return alpha

# 示例函数
def f(x):
    return (x[0] - 1)**2 + (x[1] - 2)**2

def grad_f(x):
    return np.array([2 * (x[0] - 1), 2 * (x[1] - 2)])

# 使用BFGS方法来最小化函数 f
x0 = np.array([0.0, 0.0])
result = bfgs_method(f, grad_f, x0)
print("最优解 x =", result)
print("函数值 f(x) =", f(result))
<br><br>拟牛顿法通过逐步近似目标函数的二阶导数信息来寻找最优解，相比于牛顿法，它不需要直接计算海森矩阵，从而在处理高维问题时更加高效。BFGS方法是拟牛顿法中最常用的一种，它通过更新海森矩阵的近似来加速收敛过程，是优化领域中重要的算法之一。<br><br>会拉格朗日乘子法即可<br><br><br>
<br>
<br><br><br>
<br>
<br><br>
<br>
<br><br>
<br><br>先看这两个视频学习。<br>
<a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV15T411f7DY/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">https://www.bilibili.com/video/BV15T411f7DY/?spm_id_from=333.1007.top_right_bar_window_history.content.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea</a><br><a rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1HP4y1Y79e/?spm_id_from=333.1007.top_right_bar_window_history.content.click" target="_blank">https://www.bilibili.com/video/BV1HP4y1Y79e/?spm_id_from=333.1007.top_right_bar_window_history.content.click</a><br>例题：<br>
<img alt="Pasted image 20240708213706.png" src="\lib\media\pasted-image-20240708213706.png"><br>
<img alt="Pasted image 20240708213727.png" src="\lib\media\pasted-image-20240708213727.png"><br>
<img alt="Pasted image 20240708213751.png" src="\lib\media\pasted-image-20240708213751.png"><br>
<img alt="Pasted image 20240708213824.png" src="\lib\media\pasted-image-20240708213824.png"><br>
<img alt="Pasted image 20240708213856.png" src="\lib\media\pasted-image-20240708213856.png">]]></description><link>technology\collegeproject\最优化\最优化复习.html</link><guid isPermaLink="false">Technology/CollegeProject/最优化/最优化复习.md</guid><pubDate>Wed, 10 Jul 2024 03:18:32 GMT</pubDate><enclosure url="lib\media\pasted-image-20240708111754.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240708111754.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[大学物理下]]></title><description><![CDATA[<a class="tag" href="?query=tag:CollegeProjectNotes" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#CollegeProjectNotes</a> 
 <br><a href=".?query=tag:CollegeProjectNotes" class="tag" target="_blank" rel="noopener nofollow">#CollegeProjectNotes</a> <br><br><br><br><br>定义：加速度与位移成正比且方向相反，的运动叫做简谐振动<br>恢复力 ：<br><br>加速度 ：<br><br>将  代换为 ，得到  :<br><br>解得  为：<br><br>对  求导得  为：<br><br>对  求导得  为：<br><br><br>即上述的 <br><br>周期的定义：经历一次完全相同的振动经历的时间<br>正余弦振动周期为：<br><br>由于弹簧振子的  为<br><br>故弹簧振子的周期为<br><br>频率的定义：单位时间内完全振动的次数（周期的倒数），为<br><br>从而推导出角频率（圆频率） 为<br><br><br>三角函数括号中的量<br><br>结合  的方程组<br><br>与初值<br><br>可解得 <br><br><br>类似于单位圆，将一个单位向量旋转得到一个矢量<br><br>表1 三类振动公式推导<br><br>表2 简谐振动变量表述<br><br><br><br><br><br><br>
<br>
系统动能


<br>
系统势能


<br>
系统总能量

因为

所以


<br><br><br>根据旋转矢量法合成一个最终的矢量，根据三角函数可以计算出一般情况下的 ，但是一般只考虑相位差为  和  的情况，最终得到合振幅的取值范围为：<br><br><br>联立两个简谐运动方程，消去变量 t<br><br>
<br>
只讨论：两个频率值很大，但是差值很小的情况

<br>
拍的定义：由频率很大但频率之差很小的两个同方向简谐振动合成时，其合振动的振幅时而加强时而减弱的现象就叫做拍

<br>
对于被合成的两个频率和一个最终合成的频率，可以通过旋转矢量法进行计算

<br>
拍的周期  :


<br>
拍频就是 

<br><br><br>所谓振荡电路，就是电能（贮存在电容器）中的能量与磁场能（贮存在自感线圈）中的能量相互转化的电路，<br>而所谓的无阻尼自由电磁振荡，就是上述过程中，没有能量损失的电路。<br><br>某一时刻电路中的电荷量  :<br><br>某一时刻电路中的电流  :<br><br>电路中的振荡角频率  :<br><br><br>电场能量  :<br><br>磁场能量  :<br><br>LC振荡电路总能量  :<br><br><br><br><br>机械振动在弹性介质（固体、液体、气体）中传播就形成了机械波<br><br>横波：波的传播方向与振动方向垂直的波<br>纵波：波的传播方向与振动方向平行的波<br>横波可以在固体中传播<br>纵波可以在固体、液体、气体中传播<br><br>波长：一个周期传播的距离<br>周期：波前进一个波长需要的时间<br>频率：单位时间内传播的完整波的个数，只取决于波源<br>波速：单位时间波传播的距离，只取决于介质<br>表3 横、纵波在三种介质中的传播速度<br><br>表4 符号说明<br><br><br><br><br>假设一个波沿着x轴正方向传播，<br>距离原点O距离为的点的振动方程为：<br><br>则距原点O距离为的点的波函数（波动方程）为：<br><br><br>位移分布：对于一个位置 x，y 随 t 变化<br>振动规律：对于一个时刻 t，y 随 x 变化<br>相位的差：<br><br>
针对求解波动方程与振动（运动）方程展开
<br>对于波动方程 ，假如给了一点A的振动方程 ，我们需要求B，C两个点的振动方程，其中B点在A点传播方向的正方向距A点为b，C点在A点传播方向的负方向距A点为c，波速为u，则<br>
<br>
对于B点：在B点开始振动的时候A点已经开始振动了，因此当  时，B点对应的时刻应该 ，则  点的波动方程为：


<br>
对于C点：在C点开始振动的时候A点还未开始振动，因此当  时，C点对应的时刻应该 ，则  点的波动方程为：


<br>如果需要求解某点的波动方程，则在求解出该点振动方程  后，将  扩展为  即可。加还是取决于波的传播方向，遵循左加右减的原则<br><br><br>在振动的过程中，介质除了具有动能，还有因为发生形变而具有的势能<br>经过推导，体积元的动能 = 势能，于是<br>体积元的总能量 就为：<br><br>能量密度 就为：<br><br>平均能量密度 （取一个周期）就为：<br><br><br>能流：单位时间内垂直经过某一面积的能量<br>能流 就为：<br><br>平均能流 （取一个周期）就为<br><br>能流密度 （垂直通过单位面积的平均能流，也称波的强度）就为<br><br><br><br>波源的振动是通过介质中的质元依次传播出去的，因此每一个质元都可以看做一个新的波源<br><br>定义：波的衍射就是波绕过障碍物的边缘，在障碍物的几何阴影内继续传播的现象<br>现象：障碍物的宽度和波长差不多，衍射越明显，在此基础之上，宽度越小，衍射越明显<br><br>
<br>波的叠加原理：（只适合小振幅波动的线性叠加）

<br>相遇后，保持各自的特征继续传播
<br>相遇处的质点的位移为矢量和


<br>波的干涉：

<br>定义：相干波（频率相同，振动方向平行，相位差恒定）相遇时，某些地方始终加强 or 减弱的现象
<br>对于相位差恒定（不为零）的两列波：

<br>加强点：相位差为  的偶数倍
<br>减弱点：相位差为  的奇数倍


<br>对于相位差恒定（为零）的两列波，简化为波程差的比较：

<br>加强点：波程差为半波长的偶数倍
<br>减弱点：波程差为半波长的奇数倍




<br><br><br>由两列振幅、频率、和波速相同的相干波，同向相遇时，特殊的干涉现象<br><br>对于上述的两列波的波动方程：<br><br><br>合成的驻波方程为（余弦展开，有时需要配凑）：<br><br>
<br>波节：始终静止不动的点

<br>位置：上述波动方程振幅为零的点，算出来为  波长的奇数倍
<br>波节间距：半波长


<br>波腹：振幅为  的点

<br>位置：上述波动方程振幅为  的点，算出来为  波长的偶数倍
<br>波腹间距：半波长


<br><br>波密反射回波疏时会导致相位变化  的现象称为相位越变  ，也叫半波跃变<br><br>驻波中能量始终在波节和波腹之间循环传播，因此驻波不传播能量<br>简述一下能量在驻波中的传播形式：<br>首先要意识到波节处的振幅始终为0<br>
<br>当波腹处的振幅最大时，能量全部集中在波节处的势能中
<br>当波腹处的振幅最小时，能量全部集中在波腹处的动能中
<br><br>对于两端固定的弦线来说，为了形成驻波，弦长  应该为半波长的整数倍。而这些波的频率的集合称为弦振动的本征频率，最低频率称为基频，其余基频的整数倍n称为n次谐频<br>某个端口封闭的时候。形成的驻波在端口就是波节，因为空气相对于端口处的介质是波疏对波密介质<br><br>简化为两句话<br>
<br>
无论是波源靠近接收器还是接收器靠近波源还是两者相对运动，归根结底是波在单位时间传播的距离发生了变化，我们只需要考虑单位时间内波的传播情况即可，最终得出的规律是

  式中，为最终观察者接收到的波频，为波源的波频，为波速，为观察者靠近（远离）波源的速度，为波源靠近（远离）观察者的速度，至于何时取正何时取负，脑子一转就知道了~<br>


<br>
当波源和观察者的相对运动不在同一条直线上时，将速度分解到同一条直线进行上述计算即可

<br><br><br>定义：频率相同、振动方向相同、相位差恒定<br><br><br>就一个公式<br><br>式中， 为相邻两个明条纹之间的距离， 为相干光源距光频之间的距离， 为相干光源之间的距离， 为光波长<br>中央明纹两侧的明条纹分别为第一级，第二级，...，第 k 级明条纹<br><br>
<br>
速度：

  式中： 为光在介质中的传播速度， 为光在真空中传播的速度， 为折射率

<br>
路程：

  式中： 为光程， 为折射率， 为光在介质中传播的路程

<br>
光程差

<br>光程差为半波长的偶数倍时，干涉加强
<br>光程差为半波长的奇数倍时，干涉减弱


<br><br>利用镜面反射，使得一个点光源与其虚光源构成了一对相干光<br>需要注意的是：与机械波的半波损失类似，光波也有半波损失，需要考虑反射处的半波损失<br><br><br>考虑：<br>
<br>光程：光在折射率为  的介质中传播的光程为 
<br>相位跃变：考虑反射时可能产生的半波反射
<br>补充：<br>
<br>使用透镜并不引起附加的光程差
<br>应用在增透膜和增反膜上
<br><br>判断干涉的关键在于计算光程差，下面两个例子从线性与非线性两个角度进行了计算光程差的演示<br><br>干涉增强点：<br><br>干涉减弱点：<br><br>其中， 为劈尖中空气的折射率， 为光程。由于劈尖玻璃的折射率 &gt; 劈尖中空气的折射率，因此会有一个相位跃变<br><br>根据勾股定理计算光程差 <br>又 ，由于 ，故可以近似为 <br>故 <br>当  为半波长的奇数倍时，为暗条纹，此时的 r 为明环半径<br>当  为半波长的偶数倍时，为明条纹，此时的 r 为暗环半径<br><br><br><br><br>在一个波阵面上，某一点处的波振幅是各个子波相互叠加的结果<br><br><br>单色光<br><img style="zoom:67%;" alt="image-20240109105540118" src="https://s2.loli.net/2024/01/09/5PdIZKs4qGuwL6m.png" referrerpolicy="no-referrer"><br>复色光（白光）<br><img style="zoom:67%;" alt="image-20240109105624279" src="https://s2.loli.net/2024/01/09/8Re59n23lyU6dXL.png" referrerpolicy="no-referrer"><br><img style="zoom:50%;" alt="image-20231109180423492" src="https://s2.loli.net/2023/11/09/M9oe8tC1pE742za.png" referrerpolicy="no-referrer"><br>
<br>
波带法：
  判断一束光中，某一方向的光经过透镜汇聚后呈现在光屏上的是暗条纹还是亮条纹。判断方法就是计算光透过透光孔的总光程差  能被完整的划分为几个半波长。

<br>若可以完整的划分为偶数个，则两两干涉抵消，最终中心为暗纹
<br>若可以完整的划分为奇数个，则两两抵消之后还剩一个，最终中心为明纹



<br>
计算光屏上中央亮纹的宽度  ：

<br>
已知第一级暗纹的位置就是中央亮纹边界，于是此时 ，那么 

<br>
于是 

<br>
于是中央亮纹的宽度 



<br>
求解相邻亮纹（暗纹）之间的距离：
  同上，只是不用乘2，那么按照上面的计算方法，相邻两个之间的距离就是 

<br><br><img style="zoom:80%;" alt="image-20240108211858384" src="https://s2.loli.net/2024/01/08/uKkELYIiS5l2OD9.png" referrerpolicy="no-referrer"><br>
<br>
艾里斑满足的关系：

  其中：透镜光心张角 ，艾里斑直径 ，透镜焦距 ，光波波长 ，圆孔直径 

<br>
最小分辨角  ：


<br>
分辨本领：


<br>
瑞利判据：
  定义两个光源之间的夹角为 。若  就可以分辨，反之无法分辨

<br>
瑞利判据示例：
  左1能分辨（），左2恰好能分辨（），左3无法分辨（）
  <img alt="image-20231117220310711" src="https://s2.loli.net/2023/12/28/xgmaMS6B1jeqEFK.png" referrerpolicy="no-referrer">

<br><br><br>为了更精准的测量光波，需要产生亮纹：又窄又亮又稀疏，于是光栅就产生了<br><br>明纹产生的位置公式<br><br>其中： 为光栅上相邻两束光的光程差<br>可以证明：光栅中狭缝条数越多，明纹就越亮越窄<br><br><img alt="image-20231117221119613" src="https://s2.loli.net/2023/12/28/srGmAfMZIpzD31g.png" referrerpolicy="no-referrer"><br>白光通过光栅后，中间产生中央明纹，边上的明纹会由于白光中的单色光波长不同而使得明纹产生了不同颜色的带状，由于波长越短衍射角越小，故对于一个波带，靠内侧的是紫光，靠外侧的是红光<br><br><br>自然光经过偏振片后的光强减弱为原来的一半，即  。因为可以将自然光各个方向的振动分解到两个互相垂直的方向上，于是两个互相垂直的方向上的光强就均分了总光强了<br><br>
<br>起偏器和检偏器方向相同，则光线完全穿过
<br>起偏器和检偏器方向垂直，则光线无法穿过
<br>起偏器和检偏器方向介于上述两者之间，则部分穿过
<br><br>定义：就是定量计算上述第三种情况的穿过的光强<br>推导：由于穿过之后的光的振幅分量  变成了 ，且 ，则（其中  为起偏器与检偏器的夹角）<br><br><br><img style="zoom:67%;" alt="image-20231123161904439" src="https://s2.loli.net/2023/12/28/hKxIAXjedc6pHY7.png" referrerpolicy="no-referrer"><br>已知入射光线为自然光，入射角为 ，入射区域的折射率为 ，折射区域的折射率为 。当上述入射角满足下式时：<br><br>
<br>反射光线为完全偏振光
<br>反射光线与折射光线垂直
<br>此时的入射角  称为布儒斯特角<br><br><br>
<br>
理想气体物态方程: 

  其中  为气压， 为全部气体所占的体积
   为全部体积下的气体分子数， 为气体的物质的量
  、 均为常数
   为单位体积内的分子数， 为当前温度

<br>
热力学第零定律: 
  首先定义热平衡，即如果两个系统之间没有能量传递，则两系统达到了热平衡。那么热力学第零定律就是 A 与 B 达到了热平衡，B 与 C 达到了热平衡，则 A 与 C 也就处于热平衡状态

<br><br><br><br>其中  为气体分子的平均平动动能， 为气体密度， 为单个气体分子的质量<br><br>
<br>
理想气体分子的平均平动动能  与温度  的关系：


<br>
方均根速率 ：


  其中 、 均为常数， 为气体的摩尔质量

<br><br><br>定义：分子能量中速度和坐标的二次方项数<br>
<br>单原子分子自由度：3（三项平动动能）
<br>刚性双原子分子：5（三项平动动能+两项转动动能）
<br>非刚性双原子分子：7（三项平动动能+两项转动动能+两项振动能量）
<br><br><br>其中  为分子的平均能量， 为分子的自由度， 分别为平动、转动和振动中速度和坐标的二次方项数<br><br><br>其中  为  气体分子所含有的平均能量（内能）， 为该气体的自由度。又<br><br>可得<br><br>于是<br><br><br>数学形式：<br><br>三种统计速率：<br>
<br>
最概然速率 


<br>
平均速率 


<br>
方均根速率 


<br>大小关系：<br><img style="zoom:50%;" alt="image-20240108201940820" src="https://s2.loli.net/2024/01/08/7eUWRVPzBjEM2sL.png" referrerpolicy="no-referrer"><br><br><br>
<br>准静态过程：变化过程看做平衡过程
<br>功：系统做功是一个过程量
<br><br>
<br>热力学第一定律（能量守恒）：系统从外界吸收的热量，一部分用来对外界做功，一部分用来增加系统的内能
<br>内能：系统的内能只与系统的初末状态有关，而与过程无关
<br><br><br>定义：系统吸收（放出）的热量全部用来增加（减少）系统的内能<br>计算  内能变化的公式利用  就很显然了<br><br><br>定义：系统吸收（放出）的热量一部分用来增加（减少）系统的内能，一部分用来对外做功（外界对系统做功）<br>计算  内能变化的公式利用  就很显然了<br><br><br>结合上面两式与  的理想气体满足的式子 ，可得<br><br>这也就解释了，对于 1mol 的气体，吸收的热量，一部分用来增加内能，一部分用来对外做功。而这对外做功的热量就是 <br><br>
<br>热容：
<br>比热容：，其中  为系统的质量
<br><br><br>定义：在恒温热源的环境下，系统的温度不变<br>性质：气体膨胀时，从恒温热源吸收的热量全部用来对外做功；气体压缩时，外界对气体做的功全部以热量的形式传递给恒温热源<br><br>定义：系统与外界没有热交换<br>绝热方程：<br><br>其中<br><br><br><img style="zoom:50%;" alt="image-20231228171804863" src="https://s2.loli.net/2023/12/28/L6WkQhGowSJnlia.png" referrerpolicy="no-referrer"><br>在 A 点处，绝热线的斜率比等温线的斜率绝对值来的更大，具体看推导<br><img style="zoom: 50%;" alt="image-20231228173311993" src="https://s2.loli.net/2023/12/28/2YrIMA8kgHOlzPZ.png" referrerpolicy="no-referrer"><br><br><img alt="image-20240106181150702" src="https://s2.loli.net/2024/01/06/nhgoUq26YjPHCLG.png" referrerpolicy="no-referrer"><br><br><br>系统热功持续转换就需要一个循环过程。一个循环过程系统对外界所做的功为 p-V 图像中正循环（顺时针）包围的面积，一个循环结束之后，系统的内能没有改变<br><br>正循环：做正循环的系统一般叫热机，主要代表将热量转化为功的机器。 为热机效率<br><img style="zoom:67%;" alt="image-20231228175210221" src="https://s2.loli.net/2023/12/28/OrSfPUgktQZhuXN.png" referrerpolicy="no-referrer">
$$
\eta = \frac{W}{Q_1} = \frac{Q_1-Q_2}{Q_1} = 1-\frac{Q_2}{Q_1}
$$
负循环：做负循环的系统一般叫制冷机，主要代表利用外界做功使热量由低处流向高处，从而获得低温的机器。$e$ 为制冷系数<br><img style="zoom:67%;" alt="image-20231228175228349" src="https://s2.loli.net/2023/12/28/ditTLl7KOzMGZVQ.png" referrerpolicy="no-referrer">
$$
e=\frac{Q_2}{W} = \frac{Q_2}{Q_1-Q_2}
$$<br><br>理想循环状态<br>正循环：<br><br>负循环：<br><br><br><br>在理解热力学第二定律之前，先回顾一下热力学第零和第一定律。热力学第零定律：理解为热传递；热力学第一定律：理解为能量守恒定律在热学中的应用。第一类永动机就是建立在热力学第一定律的反面上的，即创造一种热机，不需要从外界吸收热量或者消耗系统内部的内能而不断向外做功的过程。下面引入热力学第二定律的两种表述：<br>
<br>开尔文表述：不存在一种热机，能够从单一热源吸收热量对外做功而不放出热量给其他物体
<br>克劳修斯表述：热量不可能从低温物体自动传到高温物体而不引起外界的变化
<br>综合上述两种表述。我们知道两种表述是等价的，即二者相互满足且一方错误另一方也将错误。其中：<br>
<br>开尔文表述表明：热功的转化是有方向性的
<br>克劳修斯表述表明：热量的传递是有方向性的
<br>第二类永动机，即一种可以将单一热源的热量完全转化为功的而不会发生热量耗散的热机。<br><br>定义：逆过程可以完全重复正过程的每一个状态的过程，就叫做可逆过程。<br>需要满足以下两个条件的才能成为可逆过程：<br>
<br>每一刻都是准静态过程
<br>没有其他耗散力做功
<br>世界上不存在绝对的可逆过程，可逆过程是理想化的模型。<br><br>其实卡诺基于热力学第二定律给出了一个世界物理法则，即所有的热循环理想的效率都不会超过卡诺循环。以理想气体的热循环为例，所有的热机进行热循环时，循环效率  都不会超过卡诺热机循环效率 ，即<br>]]></description><link>technology\collegeproject\大学物理.html</link><guid isPermaLink="false">Technology/CollegeProject/大学物理.md</guid><pubDate>Tue, 16 Jan 2024 03:33:27 GMT</pubDate><enclosure url="https://s2.loli.net/2024/01/09/5PdIZKs4qGuwL6m.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://s2.loli.net/2024/01/09/5PdIZKs4qGuwL6m.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[电子技术基础 - 数字部分]]></title><description><![CDATA[<a class="tag" href="?query=tag:CollegeProjectNotes" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#CollegeProjectNotes</a> 
 <br><a href=".?query=tag:CollegeProjectNotes" class="tag" target="_blank" rel="noopener nofollow">#CollegeProjectNotes</a> <br><br>
联系方式：<br>
:email:email：<a data-tooltip-position="top" aria-label="mailto:lijuncst@njnu.edu.cn" rel="noopener nofollow" class="external-link" href="mailto:lijuncst@njnu.edu.cn" target="_blank">lijuncst@njnu.edu.cn</a>
:phone:phone：13770610040
<br><br><br><br>
<br>
电流控制器件

<br>电子管
<br>晶体管（二极管、三极管）
<br>半导体集成电路


<br>
EDA(Electronic Design Automation)技术：硬件设计软件化

<br>设计：EWB or Verilog
<br>仿真
<br>下载
<br>验证结果


<br><br>
<br>
数字集成电路的分类

<br>
从结构特点及其对输入信号的响应规则角度

<br>组合逻辑电路
<br>时序逻辑电路


<br>
从电路的形式角度

<br>集成电路
<br>分立电路


<br>
从器件的角度

<br>TTL电路
<br>CMOS电路


<br>
从集成度的角度

集成度：每一个芯片所包含的门个数


<br>小规模
<br>中规模
<br>大规模
<br>超大规模
<br>甚大规模




<br>
数字集成电路的特点

<br>稳定性高：抗干扰能力强
<br>易于设计：对0和1表示的信号进行逻辑运算和处理
<br>便于集成：体积小、通用性好、成本低
<br>可编程性：可实现硬件设计软件化
<br>高速度、低功耗
<br>便于存储、传输、处理


<br>
数字电路的分析、设计与测试

<br>分析方法

<br>目标：确定输入与输出
<br>工具：逻辑代数
<br>方法：真值表、功能表、逻辑表达式和波形图


<br>设计方法

<br>从功能要求出发，选择合适的逻辑器件进行设计
<br>设计方式：传统的设计方法 or 基于EDA的软件设计方法


<br>测试技术


<br><br>
<br>
模拟信号

时间和数值均连续变化的信号


<br>
数字信号

时间和数值均离散变化的信号


<br>
模拟量的数字表示

模数转换：即将连续的模拟信号经过采样与编码转化为数字信号


<br>首先对时间离散
<br>然后对幅值离散
<br>最后对得到的数字量进行编码


<br><br>
<br>
二值数字逻辑和逻辑电平
二值数字逻辑：0和1两种状态（定量）
逻辑电平：高电压和低电压（定性）

    表1. 正逻辑关系表（负逻辑相反）



<br>
数字波形

是信号逻辑电平对时间的图形表示


<br>
两种类型

<br>
非归零型：用1和0去表示高电平和低电平

<br>
归零型：用1和0去表示有脉冲和无脉冲



<br>
周期性和非周期性

<br>TODO




<br>
实际数字信号波形

<br>
波形图、时序图或定时图

<br><br><br><br><br>
<br>
优点：
易于表达；
二进制数字电路逻辑简单，所用元件少；
基本运算规则简单，运算操作方便。

反相器：非门
三极管：非门 or 信号放大


<br>
波形表示

计数器


<br>
数据传输
串行传输

<br><br>十进制小数转化为二进制：将小数部位不断×2，取整数，直到没有小数部分为止<br><img style="zoom:50%;" alt="Snipaste_2023-09-22_10-45-24" src="app:\\36a18240b7535610b487ffb37fe869ba522b\D:\\installation_package\Snipaste\history\temp\Snipaste_2023-09-22_10-45-24.png" referrerpolicy="no-referrer"><br><br>二进制转十六进制：从右往左每四位换算成十六进制<br>二进制转八进制：从右往左每三位换算成八进制<br><br><br>见下<br><br>
<br>
定义：其实就是多了一个符号位，且不可以省略。其中0表示正数，1表示负数：


<br>
补码、反码和原码：
  对于正数，补码反码原码全部一样
  对于负数，反码为：符号位不动，原码按位取反；补码为：反码最低位+1即可

<br>
加法：
  与十进制竖式计算类似

<br>
减法：

<br>
与十进制竖式计算类似

<br>
溢出：
  是因为数值位不够了，解决方法是进行位扩展

<br>
溢出的判别：
  两个正数的求和，得到的补码的最高位如果为1，则溢出
  两个负数的求和，得到的补码的最高位如果为0，则溢出

<br><br><br>
其实就是在表示0-15的十六个二进制里面，按照不同的规则选取10个二进制数来进行转换
<br>
<br>有权码

<br>最接近逻辑的：8421BCD码


<br>无权码
<br><br><br><br>
<br>
与运算
<img style="zoom:33%;" alt="image-20231008095031818" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008095031818.png" referrerpolicy="no-referrer">
$$
Y_\text{事件} = A_{逻辑1}B_{逻辑2}
$$

<br>
或运算
<img style="zoom:33%;" alt="image-20231008095047759" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008095047759.png" referrerpolicy="no-referrer">
$$
Y = A + B + C + \cdots
$$

<br>
非运算
<img style="zoom:33%;" alt="image-20231008094808523" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008094808523.png" referrerpolicy="no-referrer">

<br>
几种常用逻辑运算（复合）

<br>
与非运算（与的反）
  <img style="zoom:33%;" alt="image-20231008095744254" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008095744254.png" referrerpolicy="no-referrer">
  <img style="zoom:33%;" alt="image-20231008095111128" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008095111128.png" referrerpolicy="no-referrer">

<br>
或非运算（或的反）
  <img style="zoom:33%;" alt="Snipaste_2023-10-08_09-58-22" src="app:\\36a18240b7535610b487ffb37fe869ba522b\D:\\installation_package\Snipaste\history\temp\Snipaste_2023-10-08_09-58-22.png" referrerpolicy="no-referrer">
  <img style="zoom:33%;" alt="image-20231008095809755" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008095809755.png" referrerpolicy="no-referrer">

<br>
异或运算（不进位加法 || 相同状态取0，不同状态取1）

  <img style="zoom:33%;" alt="image-20231008095902796" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008095902796.png" referrerpolicy="no-referrer">

<br>
同或运算（异或的反 || 相同状态取1，不同状态取0）

  <img style="zoom:33%;" alt="image-20231008095922663" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008095922663.png" referrerpolicy="no-referrer">
  

<br>
与或非运算
  <img style="zoom:33%;" alt="image-20231008095947154" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008095947154.png" referrerpolicy="no-referrer">



<br>
逻辑函数使用示例
<img style="zoom:25%;" alt="image-20231008102102546" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008102102546.png" referrerpolicy="no-referrer">
<img style="zoom:25%;" alt="image-20231008102037276" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008102037276.png" referrerpolicy="no-referrer">
<img style="zoom:50%;" alt="image-20231008101253710" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008101253710.png" referrerpolicy="no-referrer">
<img style="zoom: 33%;" alt="image-20231008101303842" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008101303842.png" referrerpolicy="no-referrer">
<img style="zoom:33%;" alt="image-20231008101318582" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008101318582.png" referrerpolicy="no-referrer">

<br><br>描述输入逻辑变量和输出逻辑变量之间的因果关系称为逻辑函数<br><br>
<br>
真值表
<img style="zoom:25%;" alt="image-20231008110656451" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008110656451.png" referrerpolicy="no-referrer">

<br>
逻辑函数表达式
<img style="zoom:25%;" alt="image-20231008110713908" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008110713908.png" referrerpolicy="no-referrer">

<br>
逻辑图
<img style="zoom: 33%;" alt="image-20231008110941639" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008110941639.png" referrerpolicy="no-referrer">

<br>
波形图
<img style="zoom:33%;" alt="image-20231008111013474" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008111013474.png" referrerpolicy="no-referrer">

<br><br>
<br>
真值表到逻辑图的转换

<br>
查看真值表
  <img style="zoom:33%;" alt="image-20231008112605100" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008112605100.png" referrerpolicy="no-referrer">

<br>
根据真值表写出逻辑表达式
  <img style="zoom: 50%;" alt="image-20231008112628066" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008112628066.png" referrerpolicy="no-referrer">

<br>
化简（上式不用化简）

<br>
绘制逻辑图
  <img style="zoom:50%;" alt="image-20231008112708161" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008112708161.png" referrerpolicy="no-referrer">



<br>
逻辑图到真值表的转换

<br>
根据逻辑图逐级写出表达式
  <img style="zoom:50%;" alt="image-20231008112800422" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008112800422.png" referrerpolicy="no-referrer">

<br>
化简

<br>
代入所有输入变量求真值表
  <img style="zoom:50%;" alt="image-20231008112839220" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008112839220.png" referrerpolicy="no-referrer">



<br><br><br><br><img style="zoom:50%;" alt="image-20231008114849627" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008114849627.png" referrerpolicy="no-referrer"><br><img style="zoom:50%;" alt="image-20231008114943429" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008114943429.png" referrerpolicy="no-referrer"><br><br>
<br>
代入规则 - 类似于换元
<img style="zoom:50%;" alt="image-20231008115435355" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008115435355.png" referrerpolicy="no-referrer">

<br>
反演规则（获得反函数  ）

<br>对于任意一个逻辑表达式L，与门 &amp; 或门取反，变量取反，0 &amp; 1取反
<br>保持原来的运算优先顺序（即如果在原函数表达式中，AB之间先运算，再和其他变量进行运算，那么非函数的表达式中，仍然是AB之间先运算）
<br>对于反变量以外的非号应保留不变

<img style="zoom:50%;" alt="image-20231008115328932" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008115328932.png" referrerpolicy="no-referrer">
<img style="zoom:25%;" alt="image-20231008115337125" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231008115337125.png" referrerpolicy="no-referrer">

<br>
对偶规则（获得对偶式  ）

<br>对于任何逻辑函数式，与门 &amp; 或门取反，0 &amp; 1取反


<br><br><br>
<br>
与-或表达式
<img style="zoom:33%;" alt="image-20231013094928938" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231013094928938.png" referrerpolicy="no-referrer">

<br>
或-与表达式
<img style="zoom: 50%;" alt="image-20231013094938441" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231013094938441.png" referrerpolicy="no-referrer">

<br><br>
<br>
最小项的定义和性质 - n个变量的最小项一共有  个
<img style="zoom: 33%;" alt="Snipaste_2023-10-13_09-52-27" src="app:\\36a18240b7535610b487ffb37fe869ba522b\D:\\installation_package\Snipaste\history\temp\Snipaste_2023-10-13_09-52-27.png" referrerpolicy="no-referrer">

<br>
最小项表达式（与-或表达式：若干个与项相或） - 例一
<img style="zoom: 33%;" alt="image-20231013100105922" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231013100105922.png" referrerpolicy="no-referrer">

<br>
例二
<img style="zoom: 33%;" alt="image-20231013100814750" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231013100814750.png" referrerpolicy="no-referrer">

<br><br>
<br>
最大项的定义和性质
或-与表达式：若干个或项相与

<br>
最大项和最小项的关系


<br><br>为什么要学化简？因为化简之后可以减少门的使用，从而增强电路可靠性、降低成本<br><br>最简与-或表达式：包含的与项数最少，且每个与项中变量数最少的与-或表达式<br><img style="zoom:50%;" alt="image-20231013105932046" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231013105932046.png" referrerpolicy="no-referrer"><br><br>
<br>
逻辑函数的化简

<br>并项法 
<br>吸收法 
<br>消去法 
<br>配项法 


<br>
逻辑函数形式的变换

通常在一片集成电路芯片中只有一种门电路，为了减少门电路的种类，需要对逻辑函数表达式进行变换

<img style="zoom:50%;" alt="image-20231013112834593" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231013112834593.png" referrerpolicy="no-referrer">

<br><br><br>
<br>卡诺图的引出
<br>卡诺图的特点
<br>卡诺图的简化表示法
<br>已知逻辑函数，画出卡诺图

<br>先将表达式转化为“标准与-或式”
<br>再根据最小项填卡诺图


<br><br>
<br>化简的依据
<br>化简的步骤
<br>具有无关项的化简
<br><br>
<br>门极表示（门极元件运算）
<br>流式表示（位运算）
<br>底层表示（.v）
<br><br><br><br>
<br>开关：<img style="zoom:50%;" alt="image-20231201090156879" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201090156879.png" referrerpolicy="no-referrer">
<br>反相器：<img style="zoom:33%;" alt="image-20231201090250860" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201090250860.png" referrerpolicy="no-referrer">
<br>与非门：<img style="zoom: 33%;" alt="image-20231201090233084" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201090233084.png" referrerpolicy="no-referrer">
<br>或非门：<img style="zoom:33%;" alt="image-20231201090319423" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201090319423.png" referrerpolicy="no-referrer">
<br>传输门（开关）：<img style="zoom:33%;" alt="image-20231222104533397" src="https://s2.loli.net/2023/12/22/jJ7ovdiOGAFKDZ2.png" referrerpolicy="no-referrer">
<br><br>例一：<br><img style="zoom:67%;" alt="image-20231201090643503" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201090643503.png" referrerpolicy="no-referrer"><br>逻辑表达式为：<br><img style="zoom:50%;" alt="image-20231201090727291" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201090727291.png" referrerpolicy="no-referrer"><br><br>例二：传输门组成的异或门<br><img style="zoom:50%;" alt="image-20231201091736402" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201091736402.png" referrerpolicy="no-referrer"><br>功能描述为：<br><img style="zoom:50%;" alt="image-20231201091750341" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201091750341.png" referrerpolicy="no-referrer"><br><br>例三：传输门组成的数据选择器<br><img style="zoom:50%;" alt="image-20231201091831389" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201091831389.png" referrerpolicy="no-referrer"><br>功能描述为：<br><img style="zoom:50%;" alt="image-20231201091858929" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231201091858929.png" referrerpolicy="no-referrer"><br><br><br><br><br>
<br>基本逻辑门的等效符号 - 简化电路、减少电路门的种类
<br>逻辑门符号的等效应用 - 强调低电平  高电平
<br><br><br><br>
只取决于实时输入，给出相应的输出，与之前的运行结果无关
<br>
<br>没有反馈
<br>没有记忆单元
<br><br>
<br>由逻辑图得到逻辑表达式
<br>化简和变换
<br>罗列真值表
<br>根据真值表（或者波形图）分析电路功能
<br><br><br>
<br>明确逻辑含义 - 确定输入输出并定义逻辑状态的含义
<br>列出真值表 - 根据逻辑描述写出真值表
<br>写出逻辑表达式 - 由真值表写出逻辑表达式，真值取原、假值取反
<br>化简逻辑表达式 - 代数法 or 卡诺图法
<br>画出逻辑图
<br><br>
<br>
单输出电路
<img style="zoom:33%;" alt="image-20231117112320588" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231117112320588.png" referrerpolicy="no-referrer">

<br>
多输出电路
<img style="zoom:33%;" alt="image-20231117112426358" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231117112426358.png" referrerpolicy="no-referrer">

<br>
多级逻辑电路

当限定逻辑门输入端数目，则需要进行逻辑变换。


<br>
提取公因子
  <img style="zoom:33%;" alt="image-20231117112559081" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231117112559081.png" referrerpolicy="no-referrer">

<br>
函数分解
  <img style="zoom: 33%;" alt="image-20231117112618856" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231117112618856.png" referrerpolicy="no-referrer">



<br><br><br>门延时<br><br>
<br>
消除互补变量

<br>
增加乘积项，避免互补项相加

<br>
输出端并联电容器
<img style="zoom: 50%;" alt="image-20231117115217185" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231117115217185.png" referrerpolicy="no-referrer">

<br><br><br>普通编码器<br>优先编码器<br>
<br>
4-2优先编码器（74LS00）



<br>
8-3优先编码器（CD4532）

逻辑符号：<img style="zoom:33%;" alt="image-20231208104642447" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231208104642447.png" referrerpolicy="no-referrer">


<br><br>
<br>
2-4译码器（74X139）

逻辑符号：<img style="zoom: 33%;" alt="image-20231208101820876" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231208101820876.png" referrerpolicy="no-referrer"> 逻辑图：<img style="zoom:50%;" alt="image-20231208101833902" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231208101833902.png" referrerpolicy="no-referrer">


<br>
3-8译码器（74X138）

逻辑符号：<img style="zoom:25%;" alt="image-20231208101658175" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231208101658175.png" referrerpolicy="no-referrer"> 逻辑图：<img style="zoom: 50%;" alt="image-20231208101714034" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231208101714034.png" referrerpolicy="no-referrer">


<br>
一个2-4译码器和四个3-8译码器可以组成一个5-32译码器

逻辑符号：<img style="zoom:50%;" alt="image-20231208104231966" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231208104231966.png" referrerpolicy="no-referrer">


<br>
 译码器可以实现任意  变量的逻辑函数。每一个输出代表一个最小项，那么对于一个  变量的逻辑函数，有以下步骤可以使用  译码器表示该逻辑函数

<br>将逻辑函数转化为最小项表达式
<br>摩根定律
<br>转化为译码器的输出
<br>在译码器的输出端加一个与非门即可

  <img style="zoom:50%;" alt="image-20231208110328594" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231208110328594.png" referrerpolicy="no-referrer">

<br>
七段显示译码器
  显示器：<img style="zoom:50%;" alt="image-20231208112605901" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231208112605901.png" referrerpolicy="no-referrer"> 

<br>
数据分配器

功能：相当于多输出的单刀多掷开关，是将公共数据线上的数据按需要送到不同的通道上去的逻辑电路。
示意图：<img style="zoom:50%;" alt="image-20231208114700981" src="https://s2.loli.net/2023/12/22/QnYLVDN5psEfwjS.png" referrerpolicy="no-referrer">
示例：<img style="zoom:50%;" alt="image-20231208114749275" src="https://s2.loli.net/2023/12/22/LyEQRduPZ4rnNM5.png" referrerpolicy="no-referrer">


<br><br>
 个2选1数据选择器（选择输入）可以控制  个输入（数据输入）

<br>2选1
<br>4选1
<br>8选1
<br>n选1：

<br>
实现逻辑函数
<br><br><br>半加器：<br><br>全加器：<br><br><br><br><img style="zoom:80%;" alt="image-20231222110345818" src="https://s2.loli.net/2023/12/22/sGB8rZY4OWzQHbS.png" referrerpolicy="no-referrer"><br><br>
对电平敏感
<br>或非门实现：高电平有效。全0不变，谁1谁有效，都1不确定状态<br><img style="zoom:50%;" alt="image-20231222100822028" src="https://s2.loli.net/2023/12/22/1i8JxBwD23ptZnL.png" referrerpolicy="no-referrer"><br>与非门实现：低电平有效。全1不变，谁0谁有效，都0不确定状态<br><img style="zoom:50%;" alt="image-20231222100904959" src="https://s2.loli.net/2023/12/22/IHi4sR5V8NbQgZY.png" referrerpolicy="no-referrer"><br>应用：开关电路（与非门），无论开关如何震动，输出始终正常<br>
    <img style="zoom:50%;" alt="image-20231222101855246" src="https://s2.loli.net/2023/12/22/pejKlVkMrQqv8h9.png" referrerpolicy="no-referrer">	<img style="zoom:35%;" alt="image-20231222102251343" src="https://s2.loli.net/2023/12/22/tzFvJp8ulGnRsj5.png" referrerpolicy="no-referrer">
<br>门控 SR 锁存器：就是加了一个使能端 E，如果 E 为 1，则就是一个基本的 SR 锁存器，如果 E 为 0，则保持<br><img style="zoom:33%;" alt="image-20231222103758704" src="https://s2.loli.net/2023/12/22/HYM3aZBkdAVxELl.png" referrerpolicy="no-referrer"><br><br>
对电平敏感
<br><br>传输门控制的D锁存器<br>
<br>E=0, Q=不变
<br>E=1, Q=D
<br><img style="zoom: 50%;" alt="image-20231222105139215" src="https://s2.loli.net/2023/12/22/OhlvsLBzTN9UeDj.png" referrerpolicy="no-referrer"><br>逻辑门控制的D锁存器<br>
<br>E=0, Q=不变
<br>E=1, Q=D
<br><img style="zoom:45%;" alt="image-20231222105918926" src="https://s2.loli.net/2023/12/22/T18wZjhkQ2SxFuR.png" referrerpolicy="no-referrer"><br><br><br>
对边沿敏感
<br><br><img style="zoom:80%;" alt="image-20231222112319354" src="https://s2.loli.net/2023/12/22/LRE6ksiwZzjIBcy.png" referrerpolicy="no-referrer"><br><br><img style="zoom:50%;" alt="image-20231222113334822" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231222113334822.png" referrerpolicy="no-referrer"><br>
	<img style="zoom:67%;" alt="image-20231222113438371" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231222113438371.png" referrerpolicy="no-referrer">
	<img style="zoom:50%;" alt="image-20231222113452256" src="app:\\36a18240b7535610b487ffb37fe869ba522b\C:\\Users\董文杰\AppData\Roaming\Typora\typora-user-images\image-20231222113452256.png" referrerpolicy="no-referrer">

### 5.5 触发器的逻辑功能<br><br><br><br><br><br><br><br>本部分只需要掌握同步时序逻辑电路的分析即可，具体直接从例题出发。三道同步时序逻辑电路分析的例题见教材 P282 ~ P286，分别为<br>
<br>例一：可控二进制计数器
<br>例二：可控双向二进制计数器
<br>例三：脉冲分配器
<br>下面介绍同步时序逻辑电路分析的五个步骤。在分析之前我们要知道我们的最终目标是什么，可以知道，我们分析电路的最终目标是想要量化的确定电路的物理实现的功能，至于如何设计，此处不予讨论。现在给定了一个同步时序逻辑电路的逻辑电路图，接下来我们应该：<br>
<br>
了解电路组成：同步 or 异步？穆尔型输出 or 米利型输出 or 都有？又什么触发器组成的？触发器类型是上升沿出发 or 下降沿触发？

<br>
列出三个方程：

<br>
输出方程：按电路图书写

<br>
激励方程：触发器的输入

<br>
状态方程：触发器的输出（将触发器的输入也就是激励方程代入触发器的特性方程即可）



<br>
写出转换表（分析功能用）

<br>
写出状态图（分析功能用）

<br>
写出时序图（分析功能用）默认状态的初值设置为 0

<br><br>主要讲 N 位二进制计数器中，利用集成电路板 74LVC161 实现的 4 位同步二进制递增计数器。进而引出利用该 4 位计数器实现模 N 计数器的分析与设计思路<br><br><img alt="image-20240111233651905" src="https://s2.loli.net/2024/01/11/Ivm2g5NrxeCL7Du.png" referrerpolicy="no-referrer"><br>图1 74LVC161集成板<br><img style="zoom: 50%;" alt="image-20240111234456513" src="https://s2.loli.net/2024/01/11/EHIDkge2vYOUVZX.png" referrerpolicy="no-referrer"><br>图2 74LVC161逻辑功能表<br>: 异步清零。即无视时钟脉冲信号，直接清零<br>: 同步预置。即当有效始终脉冲沿到来时，实现 4 个预置位的输出，即 <br>: 使能端。同时为高电平电路才能正常工作<br>: 进位输出<br><br><br>]]></description><link>technology\collegeproject\数字电路.html</link><guid isPermaLink="false">Technology/CollegeProject/数字电路.md</guid><pubDate>Tue, 16 Jan 2024 03:33:30 GMT</pubDate><enclosure url="app:\\36a18240b7535610b487ffb37fe869ba522b\D:\\installation_package\Snipaste\history\temp\Snipaste_2023-09-22_10-45-24.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;app:\\36a18240b7535610b487ffb37fe869ba522b\D:\\installation_package\Snipaste\history\temp\Snipaste_2023-09-22_10-45-24.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[线性代数]]></title><description><![CDATA[<a class="tag" href="?query=tag:CollegeProjectNotes" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#CollegeProjectNotes</a> 
 <br><a href=".?query=tag:CollegeProjectNotes" class="tag" target="_blank" rel="noopener nofollow">#CollegeProjectNotes</a> <br><br><br><br><br>线性代数是为了解决多元线性方程组而诞生的<br><br>记住对角线法则即可<br><br><br>排列：就是每个数位上数字的排序方式<br>逆序数：就是一个排列  中每一个数位之前比其大的数字数量之和，即 <br><br><br>对换：就是排列中某两个数位之间的数字进行交换的操作<br>
<br>定理一：一个排列中两个元素对换，排列的奇偶性改变
<br>推论：奇排列对换成标准排列的对换次数为奇数，偶排列对换成标准排列的对换次数为偶数
<br><br>n阶行列式的值为  个项之和，每一项的组成方式为：每行选一个元素，每列选一个元素，这些元素之积，符号为<br><br><br>
<br>
性质一：行列式与它的转置行列式相等

<br>
性质二：对换行列式的两个行或者列，行列式变号

<br>推论：若行列式有两行或两列完全相同，则行列式为零


<br>
性质三：行列式中若某一行（列）都乘以k，等于整个行列式的值乘以k

<br>推论一：行列式的某一行（列）中的公因子可以提出到行列式之外
<br>推论二：若行列式中有两行（列）成比例，则行列式的值为零


<br>
性质四：若行列式中某一行（列）都是两数之和，则可以拆分成两个行列式之和

<br>
性质五：把行列式中的某一行（列）乘以一个常数加到另一个行（列）上，行列式的值不变

<br>
技巧

<br>计算技巧：在一开始对换行或者列的时候，尽可能保证左上角是数字1
<br>所有的行（列）之和相等：先全部加到一行（列），再配凑上三角（下三角）

<br><br>
余子式：
代数余子式：
关系：
<br><br>一行（列）只有一个元素不为零，则 <br>证明：<br>
<br>对于特殊情况，即不为零的元素在左上角，则根据上述分块矩阵，可知


<br>对于一般情况，即某行（列）唯一不为零的元素在任意位置，则经过  次对换后，就是上述特殊情况，可知


<br><br>某行（列）（x）有多个元素不为零，则<br><br>证明：就是将展开的那一行（列）通过加法原理进行拆分，然后利用上述引理的一般情况进行证明即可<br><br>对于上述的定理，讨论代数余子式前面的系数数组 <br>如果系数数组不是第x行（列）的元素，而是其他行（列），那么上述Σ之和就为0<br>证明很简单，就是从原行列式出发，如果两行（列）元素完全一致，那么行列式显然为0<br>
考点：
一般就是把不同行（列）的元素乘上其他行（列）的元素，然后适当配凑即可
<img style="zoom:33%;" alt="image-20230920193358783" src="https://s2.loli.net/2023/12/26/UqoA1TysYV8vClP.png" referrerpolicy="no-referrer">
<br><br><br>0在左下或右上就是左上角与右下角行列式之积（），0在左上或右下就是左下角与右上角行列式之积加上符号判定<br><img style="zoom: 33%;" alt="image-20230920192705683" src="https://s2.loli.net/2023/12/26/W7MaBckEUz6hZGo.png" referrerpolicy="no-referrer"><br>证明：分区域转换为上三角即可<br><br>先行对换，再列对换，通过分块行列式和数学归纳法，可得答案为一个等比数列<br><img style="zoom:50%;" alt="image-20230920193526577" src="https://s2.loli.net/2023/12/26/oOmvwyIMnkBTLDA.png" referrerpolicy="no-referrer"><br><br><img style="zoom:33%;" alt="image-20230920192940206" src="https://s2.loli.net/2023/12/26/A7XHUtnYGDJ9uvL.png" referrerpolicy="no-referrer"><br>证明：首先从最后一行开始，依次减去前一行的  倍，凑出第一列一个元素不为零的情况，最后通过数学归纳发，即可求解。项数为<br><br><br><br><br>把线性方程组中的数据搬到了矩阵中而已<br><br>相较于行列式是一个数，矩阵就是一个数表<br>
<br>n阶矩阵
<br>行（列）矩阵
<br>零矩阵
<br>对角矩阵: 
<br>单位矩阵: 即主对角线全1，其余全0
<br>线性变换： 叫做x到的线性变换
<br><br><br>按元素一个一个加<br><br>按元素一个一个乘<br><br>
<br>基本规则： 中  就是A的第i行与B的第j列元素依次相乘求和
<br>没有交换律：  称为A左乘B，交换成立的前提是A和B两个方阵左乘和右乘相等才可以
<br>有结合律
<br>有分配率
<br>单位矩阵：主对角线上元素全为1，其余全为0
<br>纯量矩阵：主对角线上元素全为  ，其余全为0
<br>幂运算：当A、B两个方阵可交换时，有幂运算规律（因为有结合律）
<br>算律
<br><img style="zoom:50%;" alt="image-20230927200440429" src="https://s2.loli.net/2023/12/26/r8PJEn6SUFYl7bZ.png" referrerpolicy="no-referrer"><br><br>类似于沿着主对角线翻转，其实就是每一个元素的行列号交换一下位置<br>
<br>
算律
<img style="zoom:50%;" alt="image-20230927200631513" src="https://s2.loli.net/2023/12/26/KdDrv2Igth5H3Ew.png" referrerpolicy="no-referrer">

（4）证明：左边的  其实应该是  的  ，对应  的第  行与  的第  列，那么反过来对于ij就是B转置的第i行与A转置的第j列


<br>
对称矩阵：对于一个方阵A，如果  则称A为对称阵

<br>
应用举例
<img style="zoom: 33%;" alt="image-20231013154124164" src="https://s2.loli.net/2023/12/26/F7zcqHhaxXMmZU8.png" referrerpolicy="no-referrer">

<br><br>
<br>
算律
<img style="zoom:50%;" alt="image-20231013154307875" src="https://s2.loli.net/2023/12/26/oBFwv4OWVMIsqxP.png" referrerpolicy="no-referrer">

<br>
伴随矩阵

<img style="zoom:33%;" alt="image-20231013154434881" src="https://s2.loli.net/2023/12/26/1EDZkxrYljewOyC.png" referrerpolicy="no-referrer">

<br><br><br>
<br>定义：如果对于矩阵A，有  ，则称B为A的逆矩阵
<br>如果矩阵A可逆，则A的逆矩阵是唯一的
<br>如果矩阵A可逆，则  
<br>若  ，则矩阵A可逆，且 
<br>奇异矩阵： ，非奇异矩阵：
<br>若  （或 ），则A可逆且 
<br>算律：<br><br><img style="zoom:80%;" alt="image-20231226233254694" src="https://s2.loli.net/2023/12/26/s8NPuCtSZmMYz9U.png" referrerpolicy="no-referrer"><br><br>
<br>
求逆矩阵

只需要将矩阵X左乘A右乘B即可

<br>
矩阵多项式

<br>
定义：
  <img style="zoom:33%;" alt="image-20231021155745119" src="https://s2.loli.net/2023/12/26/6oPNwmfryO7ztIG.png" referrerpolicy="no-referrer">

<br>
计算技巧一
  <img style="zoom:33%;" alt="image-20231021155904932" src="https://s2.loli.net/2023/12/26/5cNFKJSY79kzxIw.png" referrerpolicy="no-referrer">

<br>
计算技巧二：对角阵幂运算
  <img style="zoom:33%;" alt="image-20231021155947814" src="https://s2.loli.net/2023/12/26/mLgyCwkA4xtIGEn.png" referrerpolicy="no-referrer">

<br>
计算技巧三：对角矩阵多项式转化为数的多项式计算
  <img style="zoom:33%;" alt="image-20231021160018932" src="https://s2.loli.net/2023/12/26/criCbESgTqkRaeN.png" referrerpolicy="no-referrer">



<br><br>
<br>
解决问题的场景：
  解决未知数数量和方程个数相等，且系数行列式不为零的线性方程组。
  是求解一般线性方程组的一个特殊场景。

<br>
结论：
  如果线性方程组
  <img style="zoom:33%;" alt="image-20231021162423180" src="https://s2.loli.net/2023/12/26/A6IZXiq1gme2pOU.png" referrerpolicy="no-referrer">
  的系数矩阵A的行列式不为零，即
  <img style="zoom:33%;" alt="image-20231021162450292" src="https://s2.loli.net/2023/12/26/NLjAgzkdQFnuRHb.png" referrerpolicy="no-referrer">
  则方程组有唯一解
  <img style="zoom:33%;" alt="image-20231021162512127" src="https://s2.loli.net/2023/12/26/uL3kPFQVO4mHpMZ.png" referrerpolicy="no-referrer">
  其中  是把系数矩阵A中第  列的元素用方程组右端的常数项代替后所得到的n阶矩阵，即
  <img style="zoom:33%;" alt="image-20231021162710174" src="https://s2.loli.net/2023/12/26/StcNO2BduhwPVzm.png" referrerpolicy="no-referrer">

<br>
证明：
  第一步：方程组转化为矩阵方程
  <img style="zoom:33%;" alt="image-20231021162913234" src="https://s2.loli.net/2023/12/26/4gEwPQjFKAU5Wdc.png" referrerpolicy="no-referrer">
  第二步：应用逆矩阵消元
  <img style="zoom:33%;" alt="image-20231021162928918" src="https://s2.loli.net/2023/12/26/gwrVUXlbFdva7jI.png" referrerpolicy="no-referrer">
  第三步：应用行列式的性质计算
  <img style="zoom:33%;" alt="image-20231021162940241" src="https://s2.loli.net/2023/12/26/eYA7h2NX1jZfuvG.png" referrerpolicy="no-referrer">

<br><br>个人感觉就是一种向量化的更高级的思维，对于一个向量，进行全新向量的拆解，从而实现拆分计算。以下是5个拆分规则，重点关注第5点，即分块对角矩阵以及最后的按行按列分块的两个应用<br>
<br>
拆分规则
首先需要知道的是，在对矩阵进行分块计算的时候，前提有两个：一个是两个矩阵一开始的规格要相同，另一个是两个矩阵分块之后的规格也要相同。

<br>
按位加
  若
  <img style="zoom:33%;" alt="image-20231021171335434" src="https://s2.loli.net/2023/12/26/DtshE17eCk6bWMu.png" referrerpolicy="no-referrer">
  则
  <img style="zoom:33%;" alt="image-20231021171359581" src="https://s2.loli.net/2023/12/26/4fX86Hl2yTPnuca.png" referrerpolicy="no-referrer">

<br>
按位数乘
  若
  <img style="zoom:33%;" alt="image-20231021171433798" src="https://s2.loli.net/2023/12/26/bzv5uXMxHECOwAB.png" referrerpolicy="no-referrer">
  则
  <img style="zoom:33%;" alt="image-20231021171451511" src="https://s2.loli.net/2023/12/26/3Y7JH5c49vky6XU.png" referrerpolicy="no-referrer">

<br>
矩阵乘法
  若
  <img style="zoom:33%;" alt="image-20231021171524198" src="https://s2.loli.net/2023/12/26/YzxliFbPsDryBpZ.png" referrerpolicy="no-referrer">
  则
  <img style="zoom:33%;" alt="image-20231021171548611" src="https://s2.loli.net/2023/12/26/oCSQUvujLbcgmM1.png" referrerpolicy="no-referrer">
  其中
  <img style="zoom:33%;" alt="image-20231021171606419" src="https://s2.loli.net/2023/12/26/nwItUHMg1dmz2fK.png" referrerpolicy="no-referrer">

<br>
按位转置
  若
  <img style="zoom:33%;" alt="image-20231021171643394" src="https://s2.loli.net/2023/12/26/ArN7sfPwh9t4gkE.png" referrerpolicy="no-referrer">
  则
  <img style="zoom:33%;" alt="image-20231021171701572" src="https://s2.loli.net/2023/12/26/Gs5i1LSkcbvAeOT.png" referrerpolicy="no-referrer">

<br>
对角分块矩阵
  <img style="zoom:33%;" alt="image-20231021171744452" src="https://s2.loli.net/2023/12/26/NLYMzAd3vXFniHE.png" referrerpolicy="no-referrer">
  其中  都是方阵，则称  为对角分块矩阵
  运算性质：

<br>
幂运算就是主对角线相应元素的幂运算
<img style="zoom:33%;" alt="image-20231021172102979" src="https://s2.loli.net/2023/12/26/jRBUlp9V4zsScQL.png" referrerpolicy="no-referrer">

<br>
矩阵行列式运算性质
<img style="zoom:33%;" alt="image-20231021172132310" src="https://s2.loli.net/2023/12/26/1PL3yUDsAca9Kvg.png" referrerpolicy="no-referrer">

<br>
矩阵的逆就是主对角线的块按位取逆
<img style="zoom:33%;" alt="image-20231021172215986" src="https://s2.loli.net/2023/12/26/K4Y1shjGCaI3mOR.png" referrerpolicy="no-referrer">





<br>
按行按列分块的应用

<br> 的充要条件是 
<br>线性方程组的三种表示方式：

<br>就是类似于一开始的矩阵数表的表示方式
<br>将系数表示为一个矩阵，将未知数表示成一个矩阵，将常数项也表示成一个矩阵
<br>同上，只是未知数保持不变，即 


<br>线性方程组的解的两种表示方式：

<br>一一表示
<br>列向量表示




<br>
两个好题

<br>
分块的整体运算思想+矩阵提取公因子
  <img style="zoom:33%;" alt="image-20231021174011922" src="https://s2.loli.net/2023/12/26/ytsq2TaIuDmVBJK.png" referrerpolicy="no-referrer">

<br>
逆矩阵的按定义的求法，即配凑求出逆矩阵（常规计算法是利用了伴随矩阵的计算思想）
  <img style="zoom:33%;" alt="image-20231021174034125" src="https://s2.loli.net/2023/12/26/PUAc27rYjvLghBa.png" referrerpolicy="no-referrer">



<br><br><br><br>矩阵的变换  矩阵增广矩阵的行变换  行最简形矩阵<br><br>
<br>
<br>
<br>
<br>
<br>将行变为列，就是矩阵的初等列变换
<br>初等行变换与初等列变化统称初等变换
<br>三种变换都是可逆的
<br><br>
<br> 经过有限次初等行变换变成矩阵 ，就称  与  行等价，记作 
<br> 经过有限次初等列变换变成矩阵 ，就称  与  列等价，记作 
<br> 经过有限次初等变换变成矩阵 ，就称  与  等价，记作 
<br>
<br>反身性：
<br>对称性：
<br>传递性：
<br><br>
<br>
行阶梯型矩阵
<img style="zoom: 33%;" alt="image-20231028112516340" src="https://s2.loli.net/2023/12/26/pm4gPFM3WQnj7BH.png" referrerpolicy="no-referrer">

<br>
行最简形矩阵
<img style="zoom:33%;" alt="image-20231028112539020" src="https://s2.loli.net/2023/12/26/6BnUs9Q3W2Kp8kX.png" referrerpolicy="no-referrer">

<br>
标准形
<img style="zoom:33%;" alt="image-20231028112726679" src="https://s2.loli.net/2023/12/26/tsYGolFOdbWZwHq.png" referrerpolicy="no-referrer">
<img style="zoom:33%;" alt="image-20231028112702780" src="https://s2.loli.net/2023/12/26/nYexESfP9IrpZ2s.png" referrerpolicy="no-referrer">

<br><br>
<br>
对  施行一次初等行变换，相当于在  的左边乘以相应的  阶初等矩阵

<br>
对  施行一次初等列变换，相当于在  的右边乘以相应的  阶初等矩阵

<br><img style="zoom:33%;" alt="image-20231028114217720" src="https://s2.loli.net/2023/12/26/x8pdcaFrWuNhkE4.png" referrerpolicy="no-referrer"><br>其中：<br> 表示：交换初等矩阵的第  行与第  行<br> 表示：将初等矩阵的第  行乘以 <br> 表示：将初等矩阵的第  行加上第  行的  倍<br><br><img style="zoom: 50%;" alt="image-20231102163134078" src="https://s2.loli.net/2023/12/26/jgI4Rm6OhdyvliA.png" referrerpolicy="no-referrer"><br><br><img style="zoom:50%;" alt="image-20231102163243381" src="https://s2.loli.net/2023/12/26/93GzM1q8b2khEwf.png" referrerpolicy="no-referrer"><br>
<br>对于（1），计算  的方法：有配凑的味道 - 计算变换矩阵
<br><img style="zoom:50%;" alt="image-20231102163540003" src="https://s2.loli.net/2023/12/26/oL5QnXlaytBJzTx.png" referrerpolicy="no-referrer"><br><br><img style="zoom:50%;" alt="image-20231102163257748" src="https://s2.loli.net/2023/12/26/cazomZkAd2rRFUE.png" referrerpolicy="no-referrer"><br>
<br>
于是证明一个方阵 可逆就又多了一个策略，即将  经过有限次的初等行变换之后变成了单位阵。

<br>
对于（1），当  为可逆方阵时：计算  的方法：此时计算出来的  就是  - 证明可逆 + 计算逆矩阵

<br><img style="zoom:50%;" alt="image-20231102163706516" src="https://s2.loli.net/2023/12/26/2s16Iin947uL3Cj.png" referrerpolicy="no-referrer"><br>解方程<br>已知矩阵 ，且 ，现在需要求解  矩阵。<br>思路：首先需要证明  可逆，然后需要计算 ，那么采用本节的知识：如果 ，则  可逆，即 ，还需要求 。可以发现，此时的 ，那么答案就是 ，于是我们只需要将  同时进行  初等变换即可。<br>最终的目标就是将拼接后的矩阵转化为行最简形矩阵，左边是一个单位矩阵即可。<br>计算方程数量和未知数数量一致的线性方程组<br>思路同上方解方程的思路 ，只不过  就是系数矩阵， 就是常数矩阵， 就是解方程<br>四种解这种线性方程组的策略：<br>
<br>消元
<br>克拉默法则
<br>求 
<br>线性变换
<br><br>定义：矩阵的非零子式的最高阶数，记作 <br>性质：<br>
<br>


<br>


<br>
若 

<br>
若  可逆，则 

<br>
性质：<img style="zoom:25%;" alt="image-20231108224218756" src="https://s2.loli.net/2023/12/26/4LwcvgDzfkQeIlP.png" referrerpolicy="no-referrer">

<br>
若  的秩为 ，则  一定可以转化为 


<br><br>概括：利用矩阵的初等变换和矩阵的秩求解一般的线性方程组的问题<br>对于  的线性方程组：<br>
<br>无解的充要条件：
<br>有唯一解的充要条件：
<br>有无限多解的充要条件：
<br>求解齐次线性方程组：<br>
<br>化简为行最简 or 行阶梯
<br>求解非齐次线性方程组：<br>
<br>化简为行最简 or 行阶梯
<br><br><br><br>
<br>
 的向量没有直观的几何形象

<br>
所谓向量组，就是由同维度的列（行）向量所组成的集合

<br>
向量组与矩阵的关系
  <img style="zoom:75%;" alt="image-20231122195648569" src="https://s2.loli.net/2023/12/26/suIvDH8Zo5pLrh6.png" referrerpolicy="no-referrer">

<br><br>
<br>
定义：

<br>线性组合：<img style="zoom:50%;" alt="image-20231122195848433" src="https://s2.loli.net/2023/12/26/BqZHQP8tNyoiKh5.png" referrerpolicy="no-referrer">
<br>线性表示：<img style="zoom:50%;" alt="image-20231122195909024" src="https://s2.loli.net/2023/12/26/7EI5ZQDsobjAwm6.png" referrerpolicy="no-referrer">


<br>
判定：

转化为方程组有解问题，从而转化为求解矩阵的秩的问题5


<br>判定向量  能否被向量组  线性表示：<img style="zoom:50%;" alt="image-20231122200148341" src="https://s2.loli.net/2023/12/26/SvX9GTtEP2haprk.png" referrerpolicy="no-referrer">
<br>判定向量组  能否被向量组  线性表示：<img style="zoom:60%;" alt="image-20231122201003536" src="https://s2.loli.net/2023/12/26/b6gUmMnxFPaXjlo.png" referrerpolicy="no-referrer">

<br>推论：<img style="zoom:67%;" alt="image-20231122202652437" src="https://s2.loli.net/2023/12/26/UjKot3z64fyuORT.png" referrerpolicy="no-referrer">


<br>判定向量组  与向量组  等价：<img style="zoom:67%;" alt="image-20231122201122856" src="https://s2.loli.net/2023/12/26/wtSH7ajTe5vnApb.png" referrerpolicy="no-referrer">


<br><br>
<br>
定义：

<br>线性相关：<img style="zoom:67%;" alt="image-20231122203108481" src="https://s2.loli.net/2023/12/26/jr4GTKEXQLc7l6g.png" referrerpolicy="no-referrer">
<br>注意：<img style="zoom: 67%;" alt="image-20231129200937221" src="https://s2.loli.net/2023/12/26/R1LMr243XCGEANv.png" referrerpolicy="no-referrer">


<br>
判定：

<br>
定理一：<img style="zoom: 50%;" alt="image-20231129201146611" src="https://s2.loli.net/2023/12/26/JGZyLaumV9EO1xN.png" referrerpolicy="no-referrer">

note: 按照定义，只需要移项 or 同除，进行构造即可


<br>
定理二：<img style="zoom:67%;" alt="image-20231129202342608" src="https://s2.loli.net/2023/12/26/qetsXCMVYHudibW.png" referrerpolicy="no-referrer">

note: 按照定义，转化为齐次线性方程组解的问题

<br>有非零解  无数组解（将解方程取倍数即可），
<br>仅有零解  唯一解，





<br>
结论：

<br>
一：<img style="zoom:67%;" alt="image-20231129212308358" src="https://s2.loli.net/2023/12/26/Qjfqc7oHayIMrpU.png" referrerpolicy="no-referrer">

note: 


<br>
二：<img style="zoom:67%;" alt="image-20231129212327353" src="https://s2.loli.net/2023/12/26/DCxHm9NnhFoVAQ7.png" referrerpolicy="no-referrer">

note: 


<br>
三：<img style="zoom:67%;" alt="image-20231129212345238" src="https://s2.loli.net/2023/12/26/ER7OPjXcpgLvU5W.png" referrerpolicy="no-referrer">

note: 


<br>
四：<img style="zoom: 50%;" alt="image-20231129214914607" src="https://s2.loli.net/2023/12/26/yguaIsOtHUrkYZ8.png" referrerpolicy="no-referrer">

target: 
confirm: 

<br>
<br>又 
<br>故 
<br>因此 





<br><br><br>
<br>
定义一：<img style="zoom: 50%;" alt="image-20231129220733692" src="https://s2.loli.net/2023/12/26/267L9aBYWp4yDu1.png" referrerpolicy="no-referrer">

note:

<br>最大无关组之间等价
<br>最大无关组  和原向量组  等价



<br>
定义二：<img style="zoom:50%;" alt="image-20231205201511109" src="https://s2.loli.net/2023/12/26/SFravdLHBt1s7mc.png" referrerpolicy="no-referrer">

<br><br><img style="zoom:67%;" alt="image-20231205202042746" src="https://s2.loli.net/2023/12/26/DuvfMw9tciqxNYo.png" referrerpolicy="no-referrer"><br><br><img style="zoom:50%;" alt="image-20231205202658101" src="https://s2.loli.net/2023/12/26/j7tK34yu1JXkRMd.png" referrerpolicy="no-referrer"><br><img style="zoom:50%;" alt="image-20231205202712876" src="https://s2.loli.net/2023/12/26/natMNklCR1zSjHf.png" referrerpolicy="no-referrer"><br>
note：
全部可以使用矩阵的秩的性质进行证明
<br><br><br>可以从高中学到的平面向量以及空间向量入手进行理解，即平面向量就是一个二维向量空间，同理空间向量就是一个三维向量空间，那么次数就是拓展到 n 维向量空间，道理是一样的，只不过超过三维之后就没有直观的效果展示罢了。<br><br>同样可以从高中学到的向量入手，此处的基就是基底，维数就是有几个基底。所有的基之间都是线性无关的，这是显然的。然后整个向量空间中任意一个向量都可以被基线性表示，也就很显然了，此处有三个考点，分别为：<br>考点一：求解空间中的某向量 x 在基 A 下的坐标<br>其实就是求解向量 x 在基 A 的各个“轴”上的投影。我们定义列向量  为向量 x 在基 A 下的坐标，那么就有如下的表述：<br><br>考点二：求解过度矩阵 P<br>我们已知一个向量空间中的两个基分别为 A 和 B，若有矩阵 P 满足基变换公式：，我们就称 P 为从基 A 到基 B 的过渡矩阵<br>考点三：已知空间中的某向量 x 在基 A 下坐标为 ，以及从基 A 到基 B 的过渡矩阵为 P，求解转换基为 B 之后的坐标 <br><img style="zoom: 50%;" alt="image-20231229185334826" src="https://s2.loli.net/2023/12/29/R6rXdjaUCVDAvkL.png" referrerpolicy="no-referrer"><br><br>本目其实就是 3.3 目的一个知识补充，具体的线性方程组求解方法与 3.3 目几乎完全一致，只不过通过解的结构将解的结构进行了划分从而看似有些不同。但是殊途同归，都是一个东西。下面介绍本目与 3.3 目不同的地方：<br>我们从 3.3 目可以知道，无论是齐次线性方程组还是非齐次线性方程组，求解步骤都是：将系数矩阵（非齐次就是增广矩阵）进行行等价变换，然后对得到的方程组进行相对应未知变量的赋值即可。区别在于：<br><br>解释：我们将<br>
<br>齐次线性方程组记为 ，解为 ，则有 
<br>非齐次线性方程组记为 ，假如其中的一个特解为 ，则 ，假如此时我们又计算出了该方程组的其次线性解 ，则有 。那么显然有 ，此时  就是该非齐次线性方程组的通解
<br>也就是说本目对 3.3 目的线性方程组的求解给出了进一步的结构上的解释，即非齐次线性方程组的解的结构是基于本身的一个特解与齐次的通解之上的，仅此而已。当然了，本目在介绍齐次线性方程组解的结构时还引入了一个新的定理，即：<br><br>该定理可以作为一些证明秩相等的证明题的切入点。若想要证明两个$ n$ 元矩阵  和  的秩相等，可以转化为证明两个矩阵的基础解析的维度相等，即解空间相等。证明解空间相等进一步转向证明  与  同解，证明同解就很简单了，就是类似于证明一个充要条件，即证明  以及 <br><br><br><br>各个位置的数依次相乘<br>

<br>运算规律：<img style="zoom: 33%;" alt="image-20231213210321658" src="https://s2.loli.net/2023/12/13/V7WI2qmZiKXs8TB.png" referrerpolicy="no-referrer">
<br>推导全部按照内积的定义来，肥肠煎蛋

<br><br>类似于模长<br>
性质：<img style="zoom:33%;" alt="image-20231213210549826" src="https://s2.loli.net/2023/12/13/cvRwelfuaESU91O.png" referrerpolicy="no-referrer">
n维向量与n维向量间的夹角：
<img style="zoom:33%;" alt="image-20231213210654513" src="https://s2.loli.net/2023/12/13/gsjlef6bkZ7HWKF.png" referrerpolicy="no-referrer">
<br><br>类似于两个非零向量垂直的关系，即两向量内积为0<br>
正交向量组

<br>
定义：向量组之间的任意两两向量均正交

<br>
性质：正交向量组一定线性无关


标准正交基

<br>
定义：是某空间向量的基+正交向量组+每一个向量都是单位向量

<br>
求解方法：施密特正交化

<br>
正交化：（其实就是对基础解系的一个线性组合）
<img style="zoom:33%;" alt="image-20231213211434849" src="https://s2.loli.net/2023/12/13/Py2kWsNRbAIOG8M.png" referrerpolicy="no-referrer">
<img style="zoom:33%;" alt="image-20231213211449866" src="https://s2.loli.net/2023/12/13/Vdfws3QnOPBvmKc.png" referrerpolicy="no-referrer">

<br>
单位化：
<img style="zoom:33%;" alt="image-20231213211514814" src="https://s2.loli.net/2023/12/26/7SWd2PNJ8TVEMhb.png" referrerpolicy="no-referrer">




<br><br>
正交矩阵：（方阵）

<br>定义：满足  的矩阵
<br>定理：正交矩阵的充要条件为矩阵的行（列）向量为单位向量且两两正交

正交变换：

<br>定义：对于正交矩阵 ， 称为称为正交变换
<br>性质：，即线段经过正交变换之后长度保持不变

<br><br><br>对于一个n阶方阵 A，存在一个复数  和一组n阶非零向量 x 使得 <br><br>则称 x 为特征向量， 为特征值， 为特征多项式<br><br>性质一<br>n阶矩阵 A 在复数范围内含有 n 个特征值，且<br><br>性质二<br>若  是 A 的特征值，则  是  的特征值<br><br>对于同一个矩阵，不同的特征值对应的特征向量之间是线性无关的<br><br><br>对于两个 n 阶方阵 A, B 而言，若存在可逆矩阵 P 使得<br><br>则称 B 为 A 的相似矩阵，A 与 B 相似，也称对 A 进行相似变换，P 为相似变换矩阵<br><br>若矩阵 A 与 B 相似，则 A 与 B 的特征多项式相同，则 A 与 B 的特征值也就相同，A 与 B 的行列式也就相同<br><br>一个矩阵 A 的多项式  可以通过其相似矩阵  很轻松地计算出来为 ，即对角矩阵左乘一个可逆阵，右乘可逆阵的逆矩阵即可，而对角矩阵的幂运算就是对角元素的幂运算，故而非常方便就可以计算一个矩阵的多项式。那么计算的关键在于如何找到一个矩阵的相似矩阵？下面给出判定一个矩阵是否存在相似矩阵（可对角化）的判定定理：<br>n 阶方阵可对角化的充要条件为该方阵含有 n 个线性无关的特征向量<br><br>本目讨论一个 n 阶方阵具备什么条件才能拥有 n 个线性无关的特征向量，从而可对角化。但是对于一般的方阵，情况过于复杂，此处只讨论 n 阶对称矩阵。即：一个 n 阶对角矩阵具备什么条件才能拥有 n 个线性无关的特征向量，从而可对角化。<br>答案是 n 阶对角矩阵一定是可对角化的。因为有一个定理是这样的：对于一个对称矩阵 A 而言，一定可以找到一个正交矩阵 P 使得 ，又由于正交矩阵一定是可逆矩阵，因此一定可以找到矩阵 A 的 n 个线性无关的特征向量，从而 A 一定可对角化。<br>对称矩阵的性质<br>
<br>对称矩阵的特征值均为实数
<br>对称矩阵 A 的两个特征值  与  对应的两个特征向量分别为  和 ，若 ，相比于一般的矩阵  与  线性无关，此时两者关系更强，即： 与  正交
<br>对称矩阵的每一个 k 重根，一定对应有 k 个线性无关的特征向量
<br>因此本目相较于 5.3 目其实就是通过可对角化这一个概念，来告诉我们对称矩阵是一定可以求出对角矩阵的。而不用判断当前矩阵是否可对角化了。只不过在此基础之上还附加了一个小定理（也没给出证明），就是对称矩阵的相似变换矩阵一定是一个正交矩阵，那么也就复习回顾了 5.1 目中学到的正交矩阵的概念。为了求解出这个正交矩阵，我们需要在 5.3 目求解特征向量之后再加一个操作，即：对于一个 k 重根，根据上面的性质3我们知道当前的根一定有 k 个线性无关的特征向量，为了凑出最终的正交矩阵，我们需要对这 k 个线性无关的特征向量正交化。那么所有的特征值下的特征向量都正交化之后，又由性质2可知，不同的特征值下的特征向量又是正交的，于是最终的正交的相似变换矩阵也就求出来了，也就得到了对角矩阵 <br><br>本目只需要掌握到：将一个二次型转化为标准型，即可。其实就是比 5.4 目多一个将二次齐次函数的系数取出组成一个二次型的步骤。其中二次型就是一个对称矩阵。接着就是重复 5.4 目中的将对称矩阵转化为对角矩阵的过程了。]]></description><link>technology\collegeproject\线性代数.html</link><guid isPermaLink="false">Technology/CollegeProject/线性代数.md</guid><pubDate>Tue, 16 Jan 2024 03:33:33 GMT</pubDate><enclosure url="https://s2.loli.net/2023/12/26/UqoA1TysYV8vClP.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://s2.loli.net/2023/12/26/UqoA1TysYV8vClP.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Jupter notebook]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具/Jupter" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/Jupter</a> 
 <br><a href=".?query=tag:科技\工具\Jupter" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/Jupter</a><br>
<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/33105153" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/33105153" target="_blank">Jupyter Notebook介绍、安装及使用教程 - 知乎 (zhihu.com)</a><br><a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/32320214" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/32320214" target="_blank">最详尽使用指南：超快上手Jupyter Notebook - 知乎 (zhihu.com)</a>]]></description><link>technology\tools\jupter\jupter-notebook.html</link><guid isPermaLink="false">Technology/Tools/Jupter/Jupter notebook.md</guid><pubDate>Thu, 21 Dec 2023 11:45:04 GMT</pubDate></item><item><title><![CDATA[Jupter上传文件夹到云服务器]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具/Jupter" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/Jupter</a> 
 <br><a href=".?query=tag:科技\工具\Jupter" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/Jupter</a><br>
在&nbsp;Jupyter Notebook&nbsp;中上传文件夹到云服务器的步骤如下：<br>
<br>
打包文件夹：

<br>首先，将要上传的文件夹打包成&nbsp;zip&nbsp;格式。你可以使用工具如&nbsp;7-zip&nbsp;来直接打包成&nbsp;zip&nbsp;文件。


<br>
上传到服务器：

<br>打开&nbsp;Jupyter Notebook，导航到你想要上传文件夹的目录。
<br>点击右上角的&nbsp;“New”&nbsp;按钮，选择&nbsp;“Folder”&nbsp;来创建一个新的文件夹。
<br>进入新创建的文件夹，点击右上角的&nbsp;“Upload”&nbsp;按钮。
<br>在弹出的对话框中，选择要上传的文件夹并点击&nbsp;“Open”。


<br>
解压文件夹：

<br>新建一个&nbsp;notebook&nbsp;文件（注意这个notebook文件要和zip文件在同一目录下），运行以下代码：
  PythonAI 生成的代码。仔细查看和使用。&nbsp;.
# xxx.zip，这里xxx是你打包的名字
import zipfile
import os

files = zipfile.ZipFile('xxx.zip', 'r')
files.extractall(os.getcwd())
files.close()


<br>运行后，你就能在服务器上看到上传的文件夹了。


<br>如果你需要下载文件夹，你可以在要打包的文件夹下运行以下代码来创建一个压缩包：<br>PythonAI 生成的代码。仔细查看和使用。&nbsp;.<br>import os
import tarfile

def recursive_files(dir_name='.', ignore=None):
    for dir_name, subdirs, files in os.walk(dir_name):
        if ignore and os.path.basename(dir_name) in ignore:
            continue
        for file_name in files:
            if ignore and file_name in ignore:
                continue
            yield os.path.join(dir_name, file_name)

def make_tar_file(dir_name='.', tar_file_name='archive.tar', ignore=None):
    tar = tarfile.open(tar_file_name, 'w')
    for file_name in recursive_files(dir_name, ignore):
        tar.add(file_name)
    tar.close()

dir_name = '.'  # xxx.tar，你的压缩包名称
tar_file_name = 'archive.tar'
ignore = {'.ipynb_checkpoints', '__pycache__', tar_file_name}
make_tar_file(dir_name, tar_file_name, ignore)
<br>这样，你就可以下载生成的压缩包了。希望这些步骤对你有帮助！ 🚀]]></description><link>technology\tools\jupter\jupter上传文件夹到云服务器.html</link><guid isPermaLink="false">Technology/Tools/Jupter/Jupter上传文件夹到云服务器.md</guid><pubDate>Sun, 17 Dec 2023 11:10:18 GMT</pubDate></item><item><title><![CDATA[MyGarden]]></title><description><![CDATA[ 
 <br>
<br>dg-publish
<br>dg-home
]]></description><link>technology\tools\obsidian\mygarden.html</link><guid isPermaLink="false">Technology/Tools/Obsidian/MyGarden.md</guid><pubDate>Sun, 31 Dec 2023 05:16:59 GMT</pubDate></item><item><title><![CDATA[Tag Wrangler——快速管理 Obsidian 标签]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具</a> 
 <br><a href=".?query=tag:科技\工具" class="tag" target="_blank" rel="noopener nofollow">#科技/工具</a> <br><br><a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/587111398" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/587111398" target="_blank">Tag Wrangler——快速管理 Obsidian 标签 - 知乎 (zhihu.com)</a>]]></description><link>technology\tools\obsidian\obsidian插件.html</link><guid isPermaLink="false">Technology/Tools/Obsidian/Obsidian插件.md</guid><pubDate>Tue, 12 Dec 2023 02:00:47 GMT</pubDate></item><item><title><![CDATA[一、基础markdown语法]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具</a> 
 <br><a href=".?query=tag:科技\工具" class="tag" target="_blank" rel="noopener nofollow">#科技/工具</a> <br><br>使用Ob写笔记的基本语法，和一些快捷键。有些是Ob的特定格式。<br>
【说明】粗体显示文本表示Ob中的有效输入字符。<br><br>共可分6级。<br>
1级标题：#+空格+标题<br>
2级标题：##+空格+标题<br>
3级标题：###+空格+标题<br>
4级标题：####+空格+标题<br>
5级标题：#####+空格+标题<br>
6级标题：######+空格+标题<br>当在个人网站中使用md文档的时候，为了使标题居中，可以使用以下html语言：<br>&lt;h1 align = "center"&gt;一级标题&lt;/h1&gt;
&lt;h2 align = "center"&gt;二级标题&lt;/h2&gt;
...
<br><br>连续输入≥3个的&nbsp;-&nbsp;或&nbsp;*<br><br>
<br>无序列表：文本开头使用&nbsp;星号 +*空格，或者-+空格*
<br>有序列表：文本开头使用&nbsp;数字+.+空格
<br><br>
<br>以地址方式显示：直接粘贴
<br>以描述显示：[描述]括号链接地址&nbsp;快捷键 Ctrl+K
<br><br>段落开头使用&nbsp;&gt;<br><br>
<br>整段代码：段落开头输入一个制表符(Tab)
<br>段落文本中的代码：·代码内容·&nbsp;(单引号，键盘Esc键下面那个，这里显示的是一个点)
<br>代码块：连用三个&nbsp;·&nbsp;(代码块中会使用语法高亮显示)
<br>【注】在使用代码块时，在三个单引号后面输入指定的语言，来选择语法高亮显示的方式。Ob支持的语言和相应代号可以在这里找到：&nbsp;<a data-tooltip-position="top" aria-label="https://link.zhihu.com/?target=https%3A//prismjs.com/%23supported-languages" rel="noopener nofollow" class="external-link" href="https://link.zhihu.com/?target=https%3A//prismjs.com/%23supported-languages" target="_blank">supported-languages</a>&nbsp;。<br><br>斜体：内容&nbsp;快捷键 Ctrl+I<br>
粗体：**内容**&nbsp;快捷键Ctrl+B<br>
斜+粗：*内容*<br>
删除线：内容<br>
高亮文本：内容<br>【注】在这里&nbsp;*&nbsp;与&nbsp;_&nbsp;是通用的<br>当在个人网站中使用md文档的时候，为了使文字居中，可以使用以下html语言：<br>&lt;p align = "center"&gt; 内容&lt;/p&gt;
<br><br>
<br>网络附件：![附件描述](附件地址）
<br>本地附件：! [ [ 带后缀名的文件名] ] 或者直接从本地拖入
<br>【注1】在Ob中拖入的本地图片与音频会以附件的重新复制到库中，建议先在库中新建一个文件夹，然后右键选择将其作为附件文件夹，这样所有新添加的附件就都会保存到该文件夹中，方便管理。<br>【注2】直接使用![[带后缀文件名]语句时，附件需已存放在附件文件夹中。<br><br>首先在插件中打开标签管理插件，<br>
然后在笔记中使用&nbsp;#+标签文本&nbsp;添加标签。<br>
dg-publish<br><br>
<br>已完成：- [x]+空格+内容
<br>未完成：- [ ]+空格+内容
<br>【注】在预览界面中可以直接单击复选框来改变其状态。<br><br><img src="https://pic4.zhimg.com/80/v2-ed3f84501832dc56d7d63180366c9d8f_1440w.webp" referrerpolicy="no-referrer"><br>
<br>用符号 | 作为列分割。| 和其他字符之间要加空格。
<br>表头和表体使用&nbsp;----&nbsp;进行分割，其中&nbsp;-&nbsp;的数量应≥3。
<br>在分割栏横线中使用&nbsp;:&nbsp;设置该列文本对齐方式，不加为居左，头尾加为居中，尾加为右。
<br>单元格内换行可用<br>。
<br>每一行的列数允许少于总列数。
<br>#### 这是一个简单的3x3表格示例：

| 标题0 | 标题1 | 标题2 |
|----|----|----|
| ddd | sss | aaa |
| ccc | xxx | zzz |

（复制过去之后记得按照这个格式排版）
<br><br>
<br>普通脚注：脚注简介&nbsp;然后另起一行输入&nbsp;脚注简介: 脚注内容
<br>内部脚注：<a data-footref="[inline0" href="\#fn-1-aea58175c031b994" class="footnote-link" target="_self" rel="noopener nofollow">[1]</a>
<br><img src="https://pic3.zhimg.com/80/v2-a5523967dfbaddd56041f9d610dd05de_1440w.webp" referrerpolicy="no-referrer"><br>细节如图所示<br><br>链接到其它页面(笔记)：&nbsp;双方括号笔记名称<br>
直接在笔记中嵌入其它笔记内容：! 双括号笔记名称<br>【注】当在笔记中直接输入双方括号名称创建一个内部链接时，若该链接指定的页面不存在，则关系图中会使用一个灰色的节点来表示。单击该节点或者在预览中单击链接，将会直接创建一个新笔记。<br><br>半方大的空白 或 <br>全方大的空白 或 <br>不断行的空白格&nbsp;或&nbsp;<br>多个空格用 " ; " 符号分开<br><br>两个美元符号<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/138532124" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/138532124" target="_blank">Markdown语言——数学公式 - 知乎 (zhihu.com)</a><br><br>由于Obsidian的笔记既有基于文件夹的层级管理，又有基于关系图谱的双链接管理。层级结构过于死板，关系图谱过于混乱，所以我应该先基于习惯的层级管理，建立基本的笔记量，并建立标签系统，由于标签系统同样可以建立层级，所以基于文件夹的层级系统并不重要，重点在于标签的层级系统。基于此，基本使用思路如下：<br>
<br>获取知识，即对于有用的文本或者视频、课程内容，对其链接或主要内容建立笔记单元。并设置基本标签。
<br>将标签整理成层级结构。
<br>生成知识图谱
<br>根据知识图谱解决目标项目
<br><br>
<br>同步（通过onedrive或者坚果云同步）<a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/531516583" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/531516583" target="_blank">Obsidian 免费同步方案 - 知乎 </a>
<br>插件及外观管理
<br>对onenote笔记移植
<br><br>"请回答问题时使用Markdown格式，对所有数学公式使用$...$或$$...$$作为定界符，并确保$符号前后没有空格。公式中的符号和表达请严格按照标准数学表示方式格式化。"
<br><br>页边距默认，缩放60<br>
<br>
<br>脚注内容<a href="\#fnref-1-aea58175c031b994" class="footnote-backref footnote-link" target="_self" rel="noopener nofollow">↩︎</a>
]]></description><link>technology\tools\obsidian\obsidian基础使用.html</link><guid isPermaLink="false">Technology/Tools/Obsidian/Obsidian基础使用.md</guid><pubDate>Sun, 10 Nov 2024 03:09:17 GMT</pubDate><enclosure url="https://pic4.zhimg.com/80/v2-ed3f84501832dc56d7d63180366c9d8f_1440w.webp" length="0" type="image/webp"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://pic4.zhimg.com/80/v2-ed3f84501832dc56d7d63180366c9d8f_1440w.webp&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[各种环境问题]]></title><description><![CDATA[ 
 <br><br>Windows的文件管理很烦，又很多安全限制，不让读写。我在anaconda下pytorch发现一直失败。<br><br>EnvironmentNotWritableError: The current user does not have write permissions to the target environment.
  environment location: G:\Anaconda
<br><br>需要用管理员身份打开Anaconda Powershell Promt。即使你是管理员也必须要用管理员身份打开才可以有权限。<br><img alt="Pasted image 20240603002421.png" src="\lib\media\pasted-image-20240603002421.png">]]></description><link>technology\tools\各种环境问题.html</link><guid isPermaLink="false">Technology/Tools/各种环境问题.md</guid><pubDate>Mon, 03 Jun 2024 11:19:01 GMT</pubDate><enclosure url="lib\media\pasted-image-20240603002421.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\pasted-image-20240603002421.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[云服务器]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具/云服务器" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/云服务器</a> <a class="tag" href="?query=tag:项目/个人项目/大创" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#项目/个人项目/大创</a> 
 <br><a href=".?query=tag:科技\工具\云服务器" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/云服务器</a><br>
<a href=".?query=tag:项目\个人项目\大创" class="tag" target="_blank" rel="noopener nofollow">#项目/个人项目/大创</a> <br><br><br>大创项目数据集在云服务器，需要掌握云服务器的使用。且云服务器是未来趋势，必须掌握基本使用方法。<br><br>在这里使用vscode为例。<br>
<br>在平台开启云服务器，尽量设定固定的端口号
<br>在vscode中找到ssh，配置C:/Users/aimer/.ssh/config文件
<br>ssh上传公钥ssh-copy-id <a data-tooltip-position="top" aria-label="mailto:username@example.com" rel="noopener nofollow" class="external-link" href="mailto:username@example.com" target="_blank">username@example.com</a>
<br>连接ssh，输入密码
<br>文件传输用WinSCP
<br><br><a rel="noopener nofollow" class="external-link" href="http://223.2.31.209/#/login" target="_blank">http://223.2.31.209/#/login</a><br>
<a rel="noopener nofollow" class="external-link" href="http://223.2.23.47/#/login" target="_blank">http://223.2.23.47/#/login</a><br>
非usr文件夹下，内容在服务器关闭后清除<br><br><br>向云服务器上传秘钥并设置为无需输入密码进行认证，通常指的是设置SSH（Secure Shell）的公钥认证。这种方法比传统的密码认证更安全，也更方便。以下是基本步骤：<br>
<br>
生成SSH密钥对：<br>
如果你还没有SSH密钥对，你需要首先生成一对公钥和私钥。这可以在你的本地机器上完成，例如使用OpenSSH。命令如下：
ssh-keygen -t rsa -b 4096

这将生成一个4096位的RSA密钥对。ssh-keygen会提示你选择保存密钥的位置以及是否需要设置一个保护私钥的密码（passphrase）。

<br>
复制公钥到服务器：<br>
使用ssh-copy-id命令可以很方便地将你的公钥复制到远程服务器上。假设你的用户名是username，服务器地址是example.com，你可以这样操作：
ssh-copy-id username@example.com

第一次执行该命令时，可能需要手动输入一次密码。之后，ssh-copy-id会把你的公钥添加到服务器上的~/.ssh/authorized_keys文件中。

<br>
配置服务器：<br>
在服务器端，确保.ssh目录和authorized_keys文件的权限正确设置。通常应该是：

<br>.ssh目录的权限应为700。
<br>authorized_keys文件的权限应为600。

可以通过以下命令来检查和修改权限：
chmod 700 ~/.ssh
chmod 600 ~/.ssh/authorized_keys


<br>
测试连接：<br>
尝试无密码登录你的服务器，使用以下命令：
ssh username@example.com

如果一切设置正确，你应该可以直接登录而不需要输入密码。

<br>请根据你的实际环境调整上述命令中的用户名和服务器地址。如果你使用的是特定的云服务提供商（如AWS, Azure, Google Cloud等），它们可能会有自己的工具和文档来帮助你完成这一过程。务必妥善保管你的私钥，并且不要将私钥上传到任何公共位置。<br><br>Linux环境下，我们可以使用scp(secure copy)命令通过SSH上传本地文件。假设你现在有一个本地文件需要上传到远程服务器，你可以这样操作：<br>scp /path/to/local/file username@remote_server:/path/to/remote/directory
<br>在上述命令中：<br>
<br>/path/to/local/file&nbsp;替换成你要上传文件的本地路径。"C:\Users\aimer\Desktop\new_video_list_three.txt"
<br>username&nbsp;替换成你的远程服务器用户名。
<br>remote_server&nbsp;替换成你的远程服务器的IP地址或者域名。
<br>/path/to/remote/directory&nbsp;替换成你希望在远程服务器中存放文件的目录。<br>
注意：如果服务器使用的是非标准SSH端口（非22端口），你还需要添加&nbsp;-P&nbsp;参数和端口号，例如scp -P 2222 /path/to/local/file username@remote_server:/path/to/remote/directory。<br>
以上示例是上传单个文件，如果你要上传整个目录，需要使用&nbsp;-r&nbsp;选项：
<br>scp -r /path/to/local/directory username@remote_server:/path/to/remote/directory
<br>scp -r -P 59683 /mnt/g/VideoMae root@223.2.31.209:/root/
<br>使用&nbsp;scp&nbsp;命令上传文件时，会要求你输入远程服务器的密码，文件上传完毕后，你就可以在远程服务器的目标目录中看到上传的文件了。<br><br>在Linux系统中，我们不能直接识别类似G:\VideoMae这样的Windows文件地址。Windows和Linux系统的文件路径格式是不同的。在Linux中，没有诸如G:这样的驱动器概念，所有文件系统的挂载点都在根目录下/。<br>
假设你的G:\VideoMae映射到Linux中某个路径，例如/mnt/VideoMae，那么在Linux中应该访问这个/mnt/VideoMae路径。<br><br>screen是一个强大的终端多路复用器，允许你在一个SSH会话中运行多个终端任务，并且即使SSH连接中断，这些任务也能继续运行。 这对长时间运行的任务或训练任务非常有用，如果在这样的任务中SSH链接断开，没有screen，你会丢失对任务的控制，而有了screen，你可以在链接恢复后接着控制之前的任务。 下面是如何使用screen来运行并管理你的任务：<br>
<br>创建一个新的screen会话： screen -S mysession 在这里，-S参数后面的mysession是你给这个新会话起的名字，你可以用任何你喜欢的名字。
<br>

<br>在这个会话中，你可以运行你的训练代码，比如python train.py。这会跟你平时在终端中运行你的代码一样。


<br>

<br>如果你需要在任务运行的同时断开SSH连接，你可以按下Ctrl+A，然后按下D，这会断开你的screen会话，但你的任务会在后台继续运行。 


<br>

<br>你可以随时重新连接到你的screen会话，在你的SSH会话中输入： shell screen -r mysession  就可以回到名为mysession的screen会话。这里的-r代表re-attach，意为重新连接。


<br>

<br>如果你完成了你的任务，并且想要结束screen会话，你可以在screen会话中输入： shell exit  或者按下Ctrl+A，然后按下K，然后按Y来确认。这会结束你的screen会话。 这样，即使SSH连接被断开，你也可以确保你的训练任务得以继续，并在连接恢复后查看任务的进度。


<br><br>安装screen非常简单，可以通过系统的包管理器进行安装。但首先，你需要确认你的云服务器的操作系统类型，因为不同的操作系统，包管理器是不同的。<br>
如果你的云服务器是基于Debian的系统如Ubuntu，你可以使用apt-get来安装：<br>sudo apt-get update
sudo apt-get install screen
<br>如果你的服务器系统是基于Red Hat的，比如CentOS，可以使用yum安装：<br>sudo yum update
sudo yum install screen
<br>如果你的服务器是其他类型的Linux系统，你可能需要查找适合该系统的安装方法。无论怎样，screen都是一个非常常见的终端工具，大多数的Linux发行版都会提供它的安装包。<br><br>Linux有很多不同的发行版，它们在内核的基础上提供了各种不同的工具和环境。Ubuntu和CentOS就是其中两个非常流行的Linux发行版。<br>
Ubuntu基于Debian，常被用在桌面系统和云服务上，它易用且用户友好，有强大的社区支持和丰富的软件包。<br>
CentOS是Community Enterprise Operating System的简称，它是Red Hat Enterprise Linux（RHEL）的社区版，继承了RHEL的稳定性，并且免费提供使用。CentOS常被用作服务器。<br>
这些系统在软件安装方式上有所不同，比如Ubuntu使用apt-get，CentOS使用yum（最新的版本已经改用dnf）。这就是为什么安装同一个软件包，在不同的系统上需要使用不同的命令。<br><br>Debian 是一个基于 Linux 内核的操作系统发行版。这里需要明确的是，Linux 本质上是一个操作系统内核，它负责处理系统的核心功能，如管理硬件、运行进程等。然而，一个完整的操作系统还包括其他的软件，如命令行工具、图形环境、应用程序等。<br>这就是为何有许多不同的 "Linux 发行版"，例如 Debian、Ubuntu、CentOS、Fedora 等。每个发行版都在 Linux 内核的基础上，提供了一套完整的系统工具、图形环境、包管理等，满足不同的用户需求。<br>所以说，Debian 和 Linux 的关系是，Debian 是一个 Linux 发行版，它使用了 Linux 内核，但又有自己所特有的系统工具、软件包和环境配置等。<br>Ubuntu实际上就是基于Debian的发行版。Ubuntu不仅继承了Debian稳定性和丰富的软件包，同时还注重用户体验，提供了更友好的界面和更方便的配置方式，因此受到大量用户的喜欢。<br>虽然Ubuntu和Debian在许多方面相似，但它们也有自己的特点。例如，Ubuntu提供了统一的发行周期（每六个月一次），以及长期支持版本（每两年一次）。同时，Ubuntu还提供了自己的一些专有配置，比如Unity桌面环境等。<br>总的来说，Ubuntu继承了Debian的稳定性和软件丰富性，同时创新和改进了用户体验，使它在Linux发行版中独树一帜。<br><br>运行训练脚本：&nbsp;在脚本所在的目录下，使用你的脚本所使用的语言的解释器来运行训练脚本。例如，如果你的脚本是Python脚本，并且名为train.py，你可以在命令行输入python train.py来运行。当然，你也可以按照你的需要添加一些参数，例如python train.py --epochs 100 --batch_size 64<br><br>
<br>选择一个文本编辑器打开并编辑你的Python文件。这取决于你的服务器上有哪些编辑器以及你的偏好。一些常见的命令行文本编辑器包括vi、vim、nano和emacs。例如，对于文件"example.py"，你可以使用如下命令：

<br>使用nano编辑器：


<br>   nano example.py
<br>
<br>使用vi或vim编辑器：
<br>   vi example.py
<br>
<br>在编辑器中，修改你的Python文件内容。各种编辑器的操作方式略有不同，具体使用哪个编辑器取决于你的习惯。完成编辑后，保存并关闭文件。
<br>检查你的更改是否生效。你可以运行你的Python脚本以确保一切都按照预期进行：
<br>python example.py
<br>以上步骤仅作为一种可能的方法。实际操作可能会因你使用的云服务提供商、服务器操作系统、使用的编辑器等因素而有所差异。如果你在过程中遇到任何问题，请确保详细描述你所遇到的问题以便得到更具体的帮助。<br><br>查看本机的IP地址的方法取决于你使用的操作系统。以下是在常见的几种操作系统中查看IP地址的方法：<br>
<br>Windows：&nbsp;在命令提示符中输入ipconfig，然后按回车。你的IP地址会显示在“IPv4 地址”条目下。
<br>macOS/Unix/Linux：&nbsp;打开终端，然后输入ifconfig -a（某些系统可能需要管理员权限，例如sudo ifconfig -a）。你的IP地址会在相关的网络接口名旁边，类似于inet 192.168.1.100这样。<br>
请注意，这些命令是查看你的私有（本地）IP地址，通常在类似192.168.x.x，10.x.x.x或172.16.x.x这样的范围内。如果你想要知道你的公共IP地址（这是你的ISP提供给你的，世界上的其他计算机看到的地址），你可以在网页浏览器中访问诸如http://www.whatismyip.com这样的网站。
<br><br>镜像是一种轻量级、可执行的独立软件包，用来打包软件运行环境和基于运行环境开发的软件，它包含运行某个软件所需的所有内容，包括代码、运行时、库、环境变量和配置文件。<br><br><a data-tooltip-position="top" aria-label="https://zhuanlan.zhihu.com/p/21999778" rel="noopener nofollow" class="external-link" href="https://zhuanlan.zhihu.com/p/21999778" target="_blank">SSH 基本用法 - 知乎 (zhihu.com)</a><br><br><br>conda是一个环境管理系统，它的应用场景在于你如果运行一个需要其他版本python的项目，你不需要重新下载一个新的python并配置环境变量，只需要在conda中envs文件夹创建新的虚拟环境即可。我们只需要下载anaconda，则可以得到一个（base）python环境，之后如果有其他环境需要进行虚拟环境配置即可。以下是conda的一些常用命令，这在anaconda prompt中使用。<br><br>查看anaconda配置信息：<br>
conda info<br>
查看虚拟环境列表：<br>
conda env list<br>
anaconda换源：<br>
conda config --add channels <a rel="noopener nofollow" class="external-link" href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/" target="_blank">http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/</a><br>
conda config --add channels <a rel="noopener nofollow" class="external-link" href="http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/" target="_blank">http://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/</a><br>
conda config --set show_channel_urls yes<br>
更改anaconda虚拟环境默认安装位置：<br>
conda config --add envs_dirs D:\software\anaconda\envs<br>
新建虚拟环境：<br>
conda create -n yourname python=3.7<br>
启用虚拟环境<br>
conda activate yourname<br>
删除虚拟环境<br>
conda remove -n yourname --all<br>
指定源安装<br>
pip install opencv-python -i <a rel="noopener nofollow" class="external-link" href="https://pypi.tuna.tsinghua.edu.cn/simple" target="_blank">https://pypi.tuna.tsinghua.edu.cn/simple</a><br>
注意：如果pypi换成mirrors就有问题<br><br><a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1ao4y1E7Vm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1ao4y1E7Vm/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">【python环境安装】超详细的Anaconda(python)环境配置及pycharm专业版安装教程，适合完全零基础学习！！_哔哩哔哩_bilibili</a><br><br><a data-tooltip-position="top" aria-label="https://www.bilibili.com/video/BV1bQ4y1n7sn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" rel="noopener nofollow" class="external-link" href="https://www.bilibili.com/video/BV1bQ4y1n7sn/?spm_id_from=333.337.search-card.all.click&amp;vd_source=b17d4de2c32b04e437ad7699ea8a76ea" target="_blank">Python环境配置小白教学，Anaconda+VScode安装与配置_哔哩哔哩_bilibili</a><br>注意事项：域名一定是http<br>
注意：git clone 用git clone <a rel="noopener nofollow" class="external-link" href="https://gitclone.com/github.com/" target="_blank">https://gitclone.com/github.com/</a>...]]></description><link>technology\tools\云服务器.html</link><guid isPermaLink="false">Technology/Tools/云服务器.md</guid><pubDate>Tue, 10 Sep 2024 03:14:29 GMT</pubDate></item><item><title><![CDATA[AI+PPT]]></title><description><![CDATA[ 
 <br>推荐软件：Gamma&amp;ISlide<br><img alt="{1883B6ED-4C40-4EC8-AE32-85ECF1111E57}.png" src="\lib\media\{1883b6ed-4c40-4ec8-ae32-85ecf1111e57}.png"><br><br><img alt="{E6489854-E9FF-4621-9E51-06B14707494C}.png" src="\lib\media\{e6489854-e9ff-4621-9e51-06b14707494c}.png"><br><br><img alt="{0F8818AE-6716-40BD-A3AD-ED6A401DC5C6}.png" src="\lib\media\{0f8818ae-6716-40bd-a3ad-ed6a401dc5c6}.png">]]></description><link>technology\tools\ai+ppt.html</link><guid isPermaLink="false">Technology/Tools/AI+PPT.md</guid><pubDate>Sun, 10 Nov 2024 09:09:14 GMT</pubDate><enclosure url="lib\media\{1883b6ed-4c40-4ec8-ae32-85ecf1111e57}.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;lib\media\{1883b6ed-4c40-4ec8-ae32-85ecf1111e57}.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[Clash高级操作]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技/工具" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具</a> 
 <br><a href=".?query=tag:科技\工具" class="tag" target="_blank" rel="noopener nofollow">#科技/工具</a><br>
<a data-tooltip-position="top" aria-label="https://docs.reiz.link/%E9%99%84%E5%BD%95/clash-advanced-usage/" rel="noopener nofollow" class="external-link" href="https://docs.reiz.link/%E9%99%84%E5%BD%95/clash-advanced-usage/" target="_blank">Clash 高级使用介绍 (reiz.link)</a>]]></description><link>technology\tools\clash高级操作.html</link><guid isPermaLink="false">Technology/Tools/Clash高级操作.md</guid><pubDate>Mon, 09 Sep 2024 12:37:22 GMT</pubDate></item><item><title><![CDATA[一、工作区域]]></title><description><![CDATA[<a class="tag" href="?query=tag:CollegeProjectNotes" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#CollegeProjectNotes</a> 
 <br><a href=".?query=tag:CollegeProjectNotes" class="tag" target="_blank" rel="noopener nofollow">#CollegeProjectNotes</a><br>
[TOC]<br><br><br><img style="zoom:67%;" alt="image-20230906213107770" src="https://img-blog.csdnimg.cn/img_convert/073689b8e2de1273672794bc60fbd75e.png" referrerpolicy="no-referrer"><br><br><br>git init
<br><br>git status
<br><br>git add
<br><br>git add '文件名'
<br><br>git add .
<br><br>git commit -m '版本号注释'
<br><br><br>git log
<br><br>git reflog
<br><br><br>git reset --hard '版本序列'
<br><br>git checkout -- &lt;filename&gt;
<br><br>git reset HEAD -- &lt;filename&gt;
<br><br><img alt="image-20230906213015774" src="https://img-blog.csdnimg.cn/img_convert/cedf77f958b1f8a6b4c0727581a23d5f.png" referrerpolicy="no-referrer"><br>
<br>主线默认为master
<br>bug与dev双分支齐头并进，但是不影响master分支
<br><br>git branch
<br><br>git branch 分支名
<br><br>git switch 分支名
<br><br>首先切换到某一个准备被合并的分支，现在加入准备将紧急修复的bug分支合并到master主线从而上线<br>git merge 分支名
<br>现在head指向的分支就是head, bug<br>解决冲突：如果合并的时候产生了冲突，就说明两个文件之间的同一行修改的不一样，需要手动调整冲突的代码<br><br>git branch -d 分支名（bug）
<br><br><br>对远程仓库起一个别名origin<br>git remote add origin https://github.com/用户名/仓库名.git
<br><br>git push -u origin
<br><br><br>[TOC]<br><br>git 是一款版本管理软件，适用目前绝大多数操作系统；github 是一个代码托管平台，与 git 没有任何关系，只不过 git 可以基于 github 进行分布式云存储与交互，因此往往需要结合二者从而达到相对良好的 teamwork 状态。本文是我基于 git 的版本管理学习记录，诸多不周还望海涵与指正！<br>全文分为两个部分，分别为 git 版本管理的 architecture 与 git 的相关命令。其中 architecture 使用 Xmind 绘制，git 相关命令采用 git bash 模拟 Unix 命令行终端。本地 OS 为 Microsoft Windows 11<br><br>]]></description><link>technology\tools\git.html</link><guid isPermaLink="false">Technology/Tools/Git.md</guid><pubDate>Tue, 16 Jan 2024 03:34:37 GMT</pubDate><enclosure url="https://img-blog.csdnimg.cn/img_convert/073689b8e2de1273672794bc60fbd75e.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://img-blog.csdnimg.cn/img_convert/073689b8e2de1273672794bc60fbd75e.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[1、前端]]></title><description><![CDATA[<a class="tag" href="?query=tag:CollegeProjectNotes" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#CollegeProjectNotes</a> 
 <br><a href=".?query=tag:CollegeProjectNotes" class="tag" target="_blank" rel="noopener nofollow">#CollegeProjectNotes</a> <br><br><br>参考：<a data-tooltip-position="top" aria-label="https://www.runoob.com/html/html5-intro.html" rel="noopener nofollow" class="external-link" href="https://www.runoob.com/html/html5-intro.html" target="_blank">HTML 教程</a><br><br>
<br>标题&lt;h1&gt;这是一个标题&lt;/h1&gt;
<br>段落&lt;p&gt;这是一个段落。&lt;/p&gt;
<br>链接&lt;a href="https://www.runoob.com"&gt;这是一个链接&lt;/a&gt;
<br>图像&lt;img decoding="async" src="/images/logo.png" width="258" height="39" /&gt;
<br><br>
<br>属性和属性值，尽量小写，本来这样做也方便些。
<br>class 属性可以多用 class=" " （引号里面可以填入多个class属性）
<br>id 属性只能单独设置 id=" "（只能填写一个，多个无效）
<br><br>
<br>&lt;h1&gt;这是一个标题。&lt;/h1&gt;
<br>浏览器会自动地在标题的前后添加空行
<br>水平线&lt;hr&gt;
<br>注释&lt;!-- 这是一个注释 --&gt;
<br>查看源码只需要单击右键，然后选择"查看源文件"（IE）或"查看页面源代码"（Firefox）
<br><br>
<br>换行&lt;br/&gt;
<br>多余的空格回车都会被识别为一个空格
<br><br>
<br>
基本语法
&lt;a href="url"&gt;链接文本&lt;/a&gt;
&lt;a href="https://www.runoob.com/"&gt;访问菜鸟教程&lt;/a&gt;


<br>
target属性
&lt;a href="https://www.runoob.com/" target="_blank"&gt;新开一面展示相关内容&lt;/a&gt;
&lt;a href="http://www.runoob.com/" target="_top"&gt;跳出框架，返回主页&lt;/a&gt; 


<br>
id属性（内部链接）

<br><br>
<br>
使用 &lt;title&gt; 标签定义HTML文档的标题

<br>
在 &lt;head&gt;元素中可以插入脚本（scripts）, 样式文件（CSS），及各种 meta 信息。
可以添加在头部区域的元素标签为: &lt;title&gt;, &lt;style&gt;, &lt;meta&gt;, &lt;link&gt;, &lt;script&gt;, &lt;noscript&gt; 和 &lt;base&gt;。

<br>
head 标签用于定义文档头部，它是所有头部元素的容器。 中的元素可以引用脚本、指示浏览器在哪里找到样式表、提供元信息等等。
如：
&lt;html&gt;
  &lt;head&gt;
     &lt;title&gt;文档标题&lt;/title&gt;
  &lt;/head&gt;
&lt;/html&gt;

header 标签用于定义文档的页眉（介绍信息）。
如：
&lt;html&gt;
  &lt;body&gt;
    &lt;header&gt;
        &lt;p&gt;段落&lt;/p&gt;
        &lt;h1&gt;一级标题&lt;/h1&gt;
    &lt;/header&gt;
  &lt;/body&gt;
&lt;/html&gt;

注意千万不要弄混。

<br>
&lt;base&gt;元素，类似于全局设定前缀
&lt;!DOCTYPE html&gt;
&lt;html&gt;
&lt;head&gt;
&lt;meta charset="utf-8"&gt; 
&lt;title&gt;菜鸟教程(runoob.com)&lt;/title&gt; 
&lt;base href="https://www.runoob.com/images/" target="_blank"&gt;
&lt;/head&gt;

&lt;body&gt;
&lt;img src="logo.png"&gt; - 注意这里我们设置了图片的相对地址。能正常显示是因为我们在 head 部分设置了 base 标签，该标签指定了页面上所有链接的默认 URL，所以该图片的访问地址为 "https://www.runoob.com/images/logo.png"
&lt;br&gt;&lt;br&gt;
&lt;a href="https://www.runoob.com"&gt;菜鸟教程&lt;/a&gt; - 注意这个链接会在新窗口打开，即便它没有 target="_blank" 属性。因为在 base 标签里我们已经设置了 target 属性的值为 "_blank"。

&lt;/body&gt;
&lt;/html&gt;


<br>
&lt;link&gt;元素

<br>
&lt;link&gt;标签定义了文档与外部资源之间的关系

<br>
&lt;link&gt; 标签通常用于链接到样式表

<br>
比如
&lt;head&gt;
&lt;link rel="stylesheet" type="text/css" href="mystyle.css"&gt;
&lt;/head&gt;




<br>
&lt;meta&gt;元素

<br>
meta元素通常用于指定网页的描述，关键词，文件的最后修改时间，作者，和其他元数据。

<br>
例子

<br>为搜索引擎定义关键词:

&lt;meta name="keywords" content="HTML, CSS, XML, XHTML, JavaScript"&gt;


<br>为网页定义描述内容:

&lt;meta name="description" content="免费 Web &amp; 编程 教程"&gt;


<br>定义网页作者:

&lt;meta name="author" content="Runoob"&gt;


<br>每30秒钟刷新当前页面:

&lt;meta http-equiv="refresh" content="30"&gt;




<br>
&lt;style&gt;元素

<br>定义了文档的样式文件CSS引用地址


<br>
&lt;script&gt;元素

<br>用于加载脚本文件，如JavaScript


<br><br>CSS 可以通过以下方式添加到HTML中:<br>
<br>
内联样式

在HTML元素中使用"style" 属性


<br>
内部样式表

在HTML文档头部 &lt;head&gt; 区域使用&lt;style&gt; 元素 来包含CSS


<br>
外部引用

使用外部 CSS 文件


<br><br>
<br>
&lt;h1&gt;这中间是放置标题，与Markdown类似有六级标题&lt;/h1&gt;

<br>
&lt;p&gt;放置段落，每个段落之间会有默认的空行&lt;/p&gt;

<br>
&lt;br /&gt;强制换行

<br>
&lt;strong&gt;加粗&lt;/strong&gt;

<br>
&lt;em&gt;倾斜&lt;/em&gt;

<br>
&lt;del&gt;删除&lt;/del&gt;

<br>
&lt;ins&gt;下划线&lt;/ins&gt;

<br>
&lt;div&gt;一整行布局&lt;/div&gt;

<br>
&lt;span&gt;一小块一小块布局&lt;/span&gt;

<br>
&lt;img src="img.jpg" alt="这是一张照片哦" title="这是代码部分" width="100" border="10" /&gt;

src属性是图片在文件夹中的路径

<br>相对路径

<br>同级路径直接图片名即可
<br>下一级路径加上文件夹名即可，如images/img.jpg
<br>上一级路径加上../跳出即可，如../images/img.jpg


<br>绝对路径

<br>网址



alt属性是图片无法正常显示时显示的替换文字
title属性是鼠标移动到图片上时显示的小字
width属性是调整图片宽度的，一般与height对应，只调一个，另一个等比例缩放
border属性一般通过CSS文件设置


<br>
&lt;a href="<a data-tooltip-position="top" aria-label="https://www.csdn.net/%22" rel="noopener nofollow" class="external-link" href="https://www.csdn.net/%22" target="_blank">https://www.csdn.net/"</a> target="_blank"&gt;显示的元素&lt;/a&gt;

href属性是链接地址，可以是外部链接，也可以是内部其他html文件的链接地址，也可以是空链接#表示待完善的地址，也可以是下载链接，一般放置文件作为链接地址，点击时直接下载
target属性是页面跳转属性，一般是跳转到新的页面，设置为_blank
显示的元素可以是文字、图片等等


<br>
锚点链接&lt;a href="#name"&gt;这里写锚点，一般是页面内目录位置&lt;/a&gt;

对应的标签在想要跳转的内容标签中加一个id="name"即可


<br>
特殊字符
  <img style="zoom:50%;" alt="image-20230515202739453" src="https://s2.loli.net/2023/08/27/wUzX3LYuhyvJHnj.png" referrerpolicy="no-referrer">  

<br>
表格

表格==标签==（展示数据而非布局页面）

```html
&lt;table&gt;
    &lt;tr&gt;
        &lt;td&gt;学院&lt;/td&gt;
        &lt;td&gt;年级&lt;/td&gt;
        &lt;td&gt;姓名&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
        &lt;td&gt; 计电院 &lt;/td&gt;
        &lt;td&gt; 2022 &lt;/td&gt;
        &lt;td&gt; 董文杰 &lt;/td&gt;
    &lt;/tr&gt;
&lt;/table&gt;
```

​	![image-20230515205740156](https://s2.loli.net/2023/08/27/J8tnqiK2uszG6kb.png)

---

表头`table head`单元格\&lt;th&gt;元素\&lt;/th&gt;自动实现**加粗**与**居中**

​	![image-20230516160701767](https://s2.loli.net/2023/08/27/QWnGO8brteV21oR.png)

---

表格==属性==\&lt;table align="center" border="1" cellpadding="5" cellspacing="0" width="500"&gt;

​    &lt;img src="https://s2.loli.net/2023/08/27/tCvUGEzbg35ncfN.png" alt="image-20230516161402112" style="zoom:50%;" /&gt;

---

表格头部\&lt;thead&gt;放置表头标签\&lt;/thead&gt;与身体\&lt;tbody&gt;放置表体标签\&lt;/tbody&gt;的结构

---

==合并单元格==

1. 确定跨行`rowspan="格子数"`还是跨列`colspan="格子数"`
2. 在最左侧或最上侧的单元格中加入上述属性
3. 删除多余的单元格



<br>
列表

布局页面

<br>
无序列表

​	<img style="zoom:50%;" alt="image-20230516164938661" src="https://s2.loli.net/2023/08/27/IJRxLmgQiPsk4WV.png" referrerpolicy="no-referrer">
​	<img style="zoom:50%;" alt="image-20230516165006697" src="https://s2.loli.net/2023/08/27/elRiE8ZbhuS1GJD.png" referrerpolicy="no-referrer">


<br>
有序列表

有序列表只是将&lt;ul&gt;&lt;/ul&gt;写成&lt;ol&gt;&lt;/ol&gt;


<br>
自定义列表

&lt;h4&gt;这是一个自定义列表&lt;/h4&gt;
&lt;dl&gt;
 &lt;dt&gt;这是大哥&lt;/dt&gt;
 &lt;dd&gt;这是第一个小弟&lt;/dd&gt;
 &lt;dd&gt;这是&lt;a href="404.html"&gt;第二个小弟&lt;/a&gt;&lt;/dd&gt;
 &lt;dd&gt;这是第三个小弟&lt;/dd&gt;
&lt;/dl&gt;

​	<img style="zoom:50%;" alt="image-20230516170158910" src="https://s2.loli.net/2023/08/27/RzLJVlCqUwtcYBQ.png" referrerpolicy="no-referrer">





<br>
表单（收集用户信息）

​	<img style="zoom:50%;" alt="image-20230518222333590" src="https://s2.loli.net/2023/08/27/EgaCbeLGvxT5HJ1.png" referrerpolicy="no-referrer">
构成
​	<img style="zoom: 33%;" alt="image-20230518222523325" src="https://s2.loli.net/2023/08/27/G5BQfMJy3mPNaYL.png" referrerpolicy="no-referrer">

<br>
表单域
&lt;form action="demo.php" method="post" name="name1"&gt;

&lt;/form&gt;


<br>action标签代表传输数据的URL地址
<br>method标签代表传输方式
<br>name标签代表表单名称


<br>
表单控件

<br>
输入表单元素
  <img style="zoom: 50%;" alt="image-20230518224354386" src="https://s2.loli.net/2023/08/27/dNILSOgeJXyUVta.png" referrerpolicy="no-referrer">
&lt;form&gt;
    用户名：&lt;input type="text"&gt; &lt;br /&gt;
    密码：&lt;input type="password"&gt;
&lt;/form&gt;

  ​	<img style="zoom:50%;" alt="image-20230518224717331" src="https://s2.loli.net/2023/08/27/pS5AmckiDTn9WVN.png" referrerpolicy="no-referrer">
  <img style="zoom: 67%;" alt="image-20230518230011931" src="https://s2.loli.net/2023/08/27/2mpfHC1gOdDVGWY.png" referrerpolicy="no-referrer">

<br>
下拉表单元素

<br>
文本域元素



<br>
提示信息
TODO（由于要与数据库后端相关联，故先搁置）




<br><br><br><br><br><br><br><br><br><img style="zoom:67%;" alt="image-20230604104859769" src="https://s2.loli.net/2023/08/27/1jne3Ioh24b6wFg.png" referrerpolicy="no-referrer"><br><br><img style="zoom:50%;" alt="image-20230604111402280" src="https://s2.loli.net/2023/08/27/FusazwLeWoimb4T.png" referrerpolicy="no-referrer"><br>正向索引<br>
<br>
存储结构：按照每一个信息段，整条存储为一个文档

<br>
搜索形式：根据用户输入的词条在存储的每一个文档中进行匹配，记录符合的id信息

<br>倒排索引<br>
<br>存储结构：首先将每一个信息段进行语义分割（中文按照词义，英文按照空格），然后将每一个分割的单元创建唯一的文档，同时记录原始文档的 ID（数据量小可以用哈希表，数据量大可以用 B+ 树实现）
<br>搜索形式：首先将用户输入的进行语义分割，将分割出来的所有关键词进行倒排索引，拿一个分割出来的单词举例-&gt;首先将这个单词在文档中进行检索（盲猜 ，比如 ，就可以检索了，然后记录返回值，即相应的文档 id 即可）
<br>个人小结<br>
<br>感觉正向索引就相当于朴素遍历，而倒排索引就是舍弃存储空间建立一个哈希表，最后根据哈希值进行用户展示
<br>最终未能选择 es 作为数据，转而使用 mysql
<br><br>
<br>Flask 作为 Web 框架，处理前端请求和后端逻辑
<br>Elasticsearch 作为数据库，存储诗文数据
<br>使用 Flask-SQLAlchemy 作为 ORM，连接 Elasticsearch
<br>使用 HTML、CSS、JavaScript 等前端技术展示搜索结果
<br><br><img style="zoom: 67%;" alt="image-20230604113740076" src="https://s2.loli.net/2023/08/27/sxKrHwWOC8pf21g.png" referrerpolicy="no-referrer"><br><br><br>MySQL是一款目前较为流行的关系型数据库<br><br><img style="zoom:67%;" alt="image-20231222160504794" src="https://s2.loli.net/2023/12/22/kWuOVrKFUiAtegp.png" referrerpolicy="no-referrer"><br>
<br>schema 是架构的意思，可以理解为项目名，即一个项目一个 schema
<br>tables 为自动生成的文件夹，其中包含很多个 table
<br>table 就是用户自定义的二维表，其中含有字段与相关的信息
<br><br><br><br>一个云服务器相当于一个抽象的类，在其中购买配置了指定的实例后相当于实例化一个类，从而一个云服务器对应一个实例<br><br>在给购买好的域名进行解析的时候，即指向自己服务器的公网IP的时候，可能会有一段时间的延时。但其实可能是没有给云服务器放通80端口导致的<br><br>首先需要清除的概念是，备案指的是给网站主机，也就是云服务器进行备案，而一般而言的域名备案其实就是给云服务器备案，只不过叫做域名备案很可能是因为大家在使用域名的时候才发现不备案是无法通过域名访问网站的。这是因为云服务器厂家做的设定，也只是顺应了政策的需求<br>当前的形式是，对于指向中国大陆 ip 的云服务器需要备案，如果指向的是非中国大陆的 ip，就不需要备案了。一般而言，中文的指向HK，英文的指向UK<br><br>http协议默认使用的是80端口，而申请了SSL证书后，通过https协议访问的网站默认使用的是443端口，因此需要提前在实例的安全组中，放通443端口<br><br>
<br>如果是基于bt面板操作的话。可以通过ssl选项中“Let's Encrypt”的选项免费申请三个月的用量
<br>由于是基于bt面板管理，需要打开强制通过https进入这个选项，从而直接默认使用https协议访问网站
<br>如果想要通过官方渠道获取。可以在阿里云或者腾讯云等直接免费领取一定额度的ssl证书
<br><br>获得已签发的ssl证书后，下载下来，再通过bt面板进行部署<br>
<br>证书文件：pem 文件
<br>密钥文件：key 文件
<br><img alt="image-20230826104235878" src="https://s2.loli.net/2023/08/27/qnCeXZwEHIh35fd.png" referrerpolicy="no-referrer"><br><br>
<br>LNMP是一组Linux操作系统下的Nginx、MySQL、PHP和Perl的组合安装包，常用于构建高性能的Web服务器。通过使用LNMP，可以快速搭建一个功能强大的网站系统
<br>LAMP是指Linux、Apache、MySQL和PHP的组合，它是一个开源的Web开发平台。这个组合通常被用来构建高性能的Web应用程序
<br><br>简介：其实就是一个类windows的linux环境下的可视化管理工具<br>安装：服务器安装宝塔面板，基于不同的linux系统会有不同的指令，详情见<a data-tooltip-position="top" aria-label="https://www.bt.cn/new/download.html" rel="noopener nofollow" class="external-link" href="https://www.bt.cn/new/download.html" target="_blank">宝塔面板安装地址</a>，选择相应的指令进行安装即可<br>进入：通过bt指令进入服务器可视化管理界面<br><img style="zoom:50%;" alt="image-20231215190014294" src="https://s2.loli.net/2023/12/15/l54bNxPO1fhGqEK.png" referrerpolicy="no-referrer"><br>管理：安装网站运行所需的环境，耗时如下：<br><img style="zoom:67%;" alt="image-20230826190642441" src="https://s2.loli.net/2023/08/27/Qf4eCdbNDRjJBgs.png" referrerpolicy="no-referrer"><br><br>参考：<a data-tooltip-position="top" aria-label="https://blog.csdn.net/qq_38431321/article/details/123018259" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/qq_38431321/article/details/123018259" target="_blank">通过Nginx在一台服务器部署多个Web应用</a><br><br>多个网站可以通过二级域名的形式只依赖一个一级域名，从而实现一个域名衍生出多个子域名的形式，即一级域名为 baidu.com，二级域名为 mcn.baidu.com、career.baidu.com 等等<br><br>每一个二级域名都需要解析到相应的IP地址，即主机记录对应记录值，才能进行后续的访问。其实可以理解为，将不同的二级域名都绑定到当前的服务器上，像这样：<br><img style="zoom:50%;" alt="image-20230826011106105" src="https://s2.loli.net/2023/08/27/odjR69UYpuwLOG4.png" referrerpolicy="no-referrer"><br><br>我们通过不同的二级域名访问网站时，其实就是访问不同的文件夹中的文件信息，像这样：<br><img alt="image-20230826011328462" src="https://s2.loli.net/2023/08/27/fwd8NXg2hDPvLsK.png" referrerpolicy="no-referrer"><br><br>这时我们就需要配置 nginx 的代理服务器了， nginx 中的 nginx.conf 文件示例配置如下<br>##### example project #####
server {
    listen       443 ssl; # 监听的端口
    server_name  test.cn; # 监听的网址

    # ssl证书的相关文件路径
    ssl_certificate      /usr/local/nginx/ssl/test.cn_bundle.pem;
    ssl_certificate_key  /usr/local/nginx/ssl/test.cn.key;

    ssl_session_cache    shared:SSL:1m;
    ssl_session_timeout  5m;

    ssl_ciphers  HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    # 项目路径
    location / {
        proxy_pass https://localhost:8080/; # 转向“本地”8080端口
        # root path;  						# 根目录
        # index demo.html;  				# 设置默认页
        # proxy_pass  http://mysvr;  		# 请求转向 mysvr 定义的服务器列表
        # deny 127.0.0.1;  					# 拒绝的ip
        # allow 172.18.5.54; 				# 允许的ip       
    }
}
<br>假如此时我们需要 docs.example.com 访问文档分站（静态），<a data-tooltip-position="top" aria-label="http://www.example.com" rel="noopener nofollow" class="external-link" href="http://www.example.com" target="_blank">www.example.com</a> 与 example.com 都访问主站（动态），我们就需要配置 nginx 中的 nginx.conf 文件，如下<br>#----- docs.example.com -----#
server {
    listen       443 ssl; 			# 监听的端口
    server_name  docs.example.com; 	# 监听的网址

    # ssl证书的相关文件路径
    ssl_certificate      /usr/local/nginx/ssl/test.cn_bundle.pem;
    ssl_certificate_key  /usr/local/nginx/ssl/test.cn.key;

    ssl_session_cache    shared:SSL:1m;
    ssl_session_timeout  5m;

    ssl_ciphers  HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    # 项目路径
    location / {
        root /usr/web/docs;  				# 根目录
    }
}

#----- www.example.com -----#
server {
    listen       443 ssl; 			# 监听的端口
    server_name  www.example.com; 	# 监听的网址

	# ssl证书的相关文件路径
    ssl_certificate      /usr/local/nginx/ssl/b.test.cn_bundle.pem;
    ssl_certificate_key  /usr/local/nginx/ssl/b.test.cn.key;

    ssl_session_cache    shared:SSL:1m;
    ssl_session_timeout  5m;

    ssl_ciphers  HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    location / {
		root /usr/web/www;  				# 根目录
    }
}

#----- example.com -----#
server {
    listen       443 ssl; 			# 监听的端口
    server_name  www.example.com; 	# 监听的网址

	# ssl证书的相关文件路径
    ssl_certificate      /usr/local/nginx/ssl/b.test.cn_bundle.pem;
    ssl_certificate_key  /usr/local/nginx/ssl/b.test.cn.key;

    ssl_session_cache    shared:SSL:1m;
    ssl_session_timeout  5m;

    ssl_ciphers  HIGH:!aNULL:!MD5;
    ssl_prefer_server_ciphers  on;

    location / {
		proxy_pass  https://www;  			# 请求转向 mysvr 定义的服务器列表
    }
}
<br><br><br>服务器信息<br>[root@DwjDemo1 ~]# cat /etc/os-release

NAME="Alibaba Cloud Linux"								发行版的名称
VERSION="3 (Soaring Falcon)"							发行版的版本号
ID="alinux"												唯一的标识符
ID_LIKE="rhel fedora centos anolis"						一些类似的发行版
VERSION_ID="3"											发行版的版本编号
PLATFORM_ID="platform:al8"								平台的标识符
PRETTY_NAME="Alibaba Cloud Linux 3 (Soaring Falcon)"	可读的发行版名称和版本号
ANSI_COLOR="0;31"										ANSI终端输出的颜色: "0;31"，通常用于表示错误或警告信息
HOME_URL="https://www.aliyun.com/"						发行版的官方网站链接
<br>连接方法<br>
<br>
方法一：利用阿里云自带的服务器连接入口，远程连接服务器

<br>
方法二：使用MobaXterm端口连接工具并更新全局软件
yum update


<br>
输入 username 和 password

<br><br><br>服务器放通端口3306<br><br>参考：<a data-tooltip-position="top" aria-label="https://blog.csdn.net/weixin_55914667/article/details/126410095" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/weixin_55914667/article/details/126410095" target="_blank">Linux安装mysql8.0（官方教程！）</a><br><br>设置mysql登录密码<br>在服务器中连接mysql<br>mysql -uroot -p
<br>授予权限给自己<br># MySQL 5 版本
GRANT ALL ON *.* TO root@'%' IDENTIFIED BY '替换成你的root密码' WITH GRANT OPTION;

# MySQL 8 版本
ALTER USER 'root'@'localhost' IDENTIFIED WITH mysql_native_password BY '替换成你的root密码';
<br>使用数据库<br>use mysql
<br>允许远程登录数据库<br>update user set host = '%' where user = 'root';
<br>刷新更新配置<br>FLUSH PRIVILEGES;
<br><br>修改项目中 config.py 中的配置信息<br># @Time   : 2023-12-03 23:25
# @File   : config.py
# @Author : Mr_Dwj

'''
配置文件：
	1. 数据库配置信息
	2. ...
'''

# 数据库的配置信息
HOSTNAME = '47.113.205.127'
PORT = '3306'
DATABASE = 'test1'
USERNAME = 'root'
PASSWORD = 'dwjadmin'
DB_URI = 'mysql+pymysql://{}:{}@{}:{}/{}?charset=utf8mb4'.format(USERNAME, PASSWORD, HOSTNAME, PORT, DATABASE)
SQLALCHEMY_DATABASE_URI = DB_URI
<br><br><img style="zoom:50%;" alt="image-20231207232537233" src="https://s2.loli.net/2023/12/07/ocUCG1N3PBEH6m2.png" referrerpolicy="no-referrer"><br><img style="zoom:50%;" alt="image-20231207232615304" src="https://s2.loli.net/2023/12/07/tg3WfE2r1pF8kIU.png" referrerpolicy="no-referrer"><br><br>拷贝数据库表 - 直接在DataGrip中寻找进行复制即可<br><img style="zoom:50%;" alt="image-20231207232434015" src="https://s2.loli.net/2023/12/07/inUoMYVPatjzW3Q.png" referrerpolicy="no-referrer"><br><br>参考：<a data-tooltip-position="top" aria-label="https://blog.csdn.net/qq_45752401/article/details/122660965" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/qq_45752401/article/details/122660965" target="_blank">Linux安装Nginx（超详细步骤）</a><br><br>服务器放通80端口<br><br>进入<a data-tooltip-position="top" aria-label="http://nginx.org/en/download.html" rel="noopener nofollow" class="external-link" href="http://nginx.org/en/download.html" target="_blank">nginx官网</a>并下载稳定版至本地：<img style="zoom: 50%;" alt="image-20231208234403083" src="https://s2.loli.net/2023/12/15/bktJ4lHNhBMjo1p.png" referrerpolicy="no-referrer"><br>上传服务器（直接通过mobaxterm拖拽）并解压到当前目录下并进入nginx文件夹<br>tar -zxvf nginx-1.24.0.tar.gz
cd "/home/nginx-1.24.0/"
<br>配置nginx并编译安装<br># 配置configure 
# --prefix 代表安装的路径
# --with-http_ssl_module 安装ssl
# --with-http_stub_status_module 查看nginx的客户端状态
./configure --prefix=/usr/local/nginx-1.24.0 --with-http_ssl_module --with-http_stub_status_module

# 编译安装
make &amp;&amp; make install
<br>进入sbin目录，启动nginx<br># 启动nginx
./nginx
<br>
解决启动遇到的端口占用的问题
<img style="zoom:67%;" alt="image-20231209001749320" src="https://s2.loli.net/2023/12/15/d6UFwPvxcuqQg4r.png" referrerpolicy="no-referrer">
killall -9 nginx 杀掉 nginx 的进程，然后重启

然后浏览器通过http的80端口访问公网ip，就可以看到欢呼雀跃的一幕
<img style="zoom: 50%;" alt="image-20231209001703919" src="https://s2.loli.net/2023/12/15/q4XJUR9tiKT1xns.png" referrerpolicy="no-referrer">
<br><br><br>参考：<a data-tooltip-position="top" aria-label="https://blog.csdn.net/weixin_64940494/article/details/126266917" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/weixin_64940494/article/details/126266917" target="_blank">linux安装python</a><br>命令集合<br># 安装python依赖
If you want a release build with all stable optimizations active (PGO, etc),please run ./configure --enable-optimizations

# 本地下载拖拽上传至服务器，解压安装包
tar -xvf Python-3.11.5.tgz

# 进入安装包，配置安装路径
cd Python-3.10.6
./configure --prefix=/usr/local/python311

# 编译安装
make &amp;&amp; make install

# 将最新的python创建软链链接
ln -s /usr/local/python311/bin/python3.11 /usr/bin/python311

# 修改yum依赖默认的python版本
vi /usr/libexec/urlgrabber-ext-down
vi /usr/bin/yum

# 修改防火墙
vi /usr/bin/firewall-cmd
vi /usr/sbin/firewalld

# 创建pip软连接
ln -s /usr/local/python311/bin/pip3.11 /usr/bin/pip311
<br>vim的编辑指令<br># 进入编辑模式
i

# 退出编辑模式进入命令模式
Esc

# 保存并关闭文件
:w

# 退出vim编辑模式
:q
<br><br>安装python虚拟环境管理依赖<br>pip install virtualenvwrapper
<br>配置虚拟环境<br># 在根目录下进入.bashrc文件进行编辑
vi .bashrc
i

# ctrl+f进入末尾，粘贴一下文字，保存并退出
export WORKON_HOME=$HOME/.virtualenvs
VIRTUALENVWRAPPER_PYTHON=/usr/bin/python311
source /usr/local/bin/virtualenvwrapper.sh

# 刷新配置文件
source ~/.bashrc
<br>
刷新配置文件时报错：virtualenvwrapper.sh: There was a problem running the initialization hooks.
解决方案参考：<a data-tooltip-position="top" aria-label="https://www.cnblogs.com/cpl9412290130/p/10019231.html" rel="noopener nofollow" class="external-link" href="https://www.cnblogs.com/cpl9412290130/p/10019231.html" target="_blank">virtualenvwrapper.sh报错: There was a problem running the initialization hooks.解决</a>
<br><br><br>创建虚拟py环境<br>mkvirtualenv --python=/usr/bin/python311 &lt;EnvName&gt;
<br>启动虚拟环境<br>workon &lt;EnvName&gt;
<br>退出虚拟环境<br>deactivate
<br><br>进入python虚拟环境目录&lt;EnvName&gt;<br>初次部署：拉取远程源文件<br>git clone https://github.com/Explorer-Dong/YunJinWeb.git
<br>后续更新：覆盖原始代码并重新运行应用<br>git pull
<br># 找到所有uwsgi进程
ps -ef|grep uwsgi
# 杀死所有进程
kill -9 &lt;进程号&gt;
# 退出uwsgi但是不停止服务的操作
uwsgi -d --ini uwsgi.ini
<br><br>检查本项目所需py模块<br>pip freeze &gt;requirements.txt
<br>安装所需py模块<br>pip install -r requirements.txt
<br><br><br>使用flask自带的服务器运行<br>运行flask主接口文件 app.py<br>python app.py
<br>
运行app.py时报错，端口已被占用，解决方案：

<br>
方法一：换一个端口运行

<br>
<a data-tooltip-position="top" aria-label="https://blog.csdn.net/weixin_45753080/article/details/124114096" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/weixin_45753080/article/details/124114096" target="_blank">方法二：</a>杀死其余的端口占用进程，重启应用
# 检测端口占用 
netstat -npl | grep "端口"
                                                        
# 查找占用端口的进程的PID
sudo lsof -i:"端口"
                                                        
# 根据PID杀死该进程
sudo kill -9 &lt;PID&gt;



<br><br>使用uwsgi应用服务器运行<br>安装并配置uwsgi应用服务器<br>
<br>
安装uwsgi包
pip install uwsgi


<br>
创建uwsgi.ini文件并编辑
touch uwsgi.ini

[uwsgi]

# -------------------- 路径相关的设置 --------------------

# 项目的路径
chdir           = /root/.virtualenvs/test111/demo/

# Flask的uwsgi文件配对的应用
wsgi-file       = /root/.virtualenvs/test111/demo/app.py

# 回调的app对象
callable        = app

# Python虚拟环境的路径
home            = /root/.virtualenvs/test111

# -------------------- 进程相关的设置 --------------------

# 主进程
master          = true

# 最大数量的工作进程
processes       = 10

# 监听5000端口（或监听socket文件，与nginx配合）
http            = :5000 

# socket监听
# socket        = /srv/[项目名称]/[项目名称].sock

# 设置socket的权限
# chmod-socket    = 666

# 退出的时候是否清理环境
vacuum          = true


<br>
通过uwsgi应用服务器运行flask应用
  <a data-tooltip-position="top" aria-label="https://www.cnblogs.com/pengpengdeyuan/p/14742090.html" rel="noopener nofollow" class="external-link" href="https://www.cnblogs.com/pengpengdeyuan/p/14742090.html" target="_blank">uwsgi启动flask项目(venv虚拟环境) </a>
# 初始启动uwsgi指令
uwsgi --ini uwsgi.ini


<br>
<a data-tooltip-position="top" aria-label="https://blog.csdn.net/wjwj1203/article/details/105336943" rel="noopener nofollow" class="external-link" href="https://blog.csdn.net/wjwj1203/article/details/105336943" target="_blank">退出uwsgi但是不停止服务的操作</a>
# 退出uwsgi但是不停止服务的操作
uwsgi -d --ini uwsgi.ini

# 此时想要停止就需要找到uwsgi的进程并全部杀死
	# 找到所有uwsgi进程
	ps -ef|grep uwsgi
	
	# 杀死所有进程
	kill -9 &lt;进程号&gt;


<br><br>问题一：读取json时出现问题<br>
error: UnicodeDecodeError: 'utf-8' codec can't decode byte 0xc3 in position 39: invalid continuation byte
reason: 对 string 解码时出现错误
solve: 
将app.py中的
with open('static/json/image_text.json', 'r') as f:
	image_text = json.load(f)

改为
with open('static/json/image_text.json', 'r', encoding='gbk') as f:
	image_text = json.load(f)

参考：<a rel="noopener nofollow" class="external-link" href="https://bobbyhadz.com/blog/python-unicodedecodeerror-utf-8-codec-cant-decode-byte" target="_blank">https://bobbyhadz.com/blog/python-unicodedecodeerror-utf-8-codec-cant-decode-byte</a>
<br><br><br><br><br>C:\Users\董文杰&gt;systeminfo

主机名:           SUNSHINE
OS 名称:          Microsoft Windows 11 家庭中文版
OS 版本:          10.0.22621 暂缺 Build 22621
OS 制造商:        Microsoft Corporation
OS 配置:          独立工作站
OS 构建类型:      Multiprocessor Free
注册的所有人:     董文杰
注册的组织:       暂缺
产品 ID:          00342-30589-00027-AAOEM
初始安装日期:     2022-12-24, 16:33:58
系统启动时间:     2023-12-15, 21:02:34
系统制造商:       HUAWEI
系统型号:         KLVF-XX
系统类型:         x64-based PC
处理器:           安装了 1 个处理器。
                  [01]: Intel64 Family 6 Model 154 Stepping 3 GenuineIntel ~1700 Mhz
BIOS 版本:        HUAWEI 1.21, 2023-06-06
Windows 目录:     C:\WINDOWS
系统目录:         C:\WINDOWS\system32
启动设备:         \Device\HarddiskVolume1
系统区域设置:     zh-cn;中文(中国)
输入法区域设置:   zh-cn;中文(中国)
时区:             (UTC+08:00) 北京，重庆，香港特别行政区，乌鲁木齐
物理内存总量:     16,108 MB
可用的物理内存:   4,948 MB
虚拟内存: 最大值: 18,163 MB
虚拟内存: 可用:   2,743 MB
虚拟内存: 使用中: 15,420 MB
页面文件位置:     D:\pagefile.sys
域:               WORKGROUP
登录服务器:       \\SUNSHINE
修补程序:         安装了 4 个修补程序。
                  [01]: KB5032007
                  [02]: KB5012170
                  [03]: KB5033375
                  [04]: KB5032393
网卡:             安装了 2 个 NIC。
                  [01]: Intel(R) Wi-Fi 6 AX201 160MHz
                      连接名:      WLAN
                      启用 DHCP:   是
                      DHCP 服务器: 10.20.0.1
                      IP 地址
                        [01]: 10.20.106.210
                        [02]: fe80::fd62:d41a:2045:b304
                  [02]: Bluetooth Device (Personal Area Network)
                      连接名:      蓝牙网络连接
                      状态:        媒体连接已中断
Hyper-V 要求:     已检测到虚拟机监控程序。将不显示 Hyper-V 所需的功能。
<br>
<br>
MySQL
# user
root

# password
root


<br>
<br><br><br>[root@DwjDemo1 ~]# cat /etc/os-release

NAME="Alibaba Cloud Linux"								发行版的名称
VERSION="3 (Soaring Falcon)"							发行版的版本号
ID="alinux"												唯一的标识符
ID_LIKE="rhel fedora centos anolis"						一些类似的发行版
VERSION_ID="3"											发行版的版本编号
PLATFORM_ID="platform:al8"								平台的标识符
PRETTY_NAME="Alibaba Cloud Linux 3 (Soaring Falcon)"	可读的发行版名称和版本号
ANSI_COLOR="0;31"										ANSI终端输出的颜色: "0;31"，通常用于表示错误或警告信息
HOME_URL="https://www.aliyun.com/"						发行版的官方网站链接
<br>
<br>
2023年8月25日 13:00:00 创建，2024年3月25日 23:59:59 到期，共7个月

<br>
提供服务云厂商：阿里云

<br>
操作系统：Alibaba Cloud Linux 3.2104 LTS 64位

<br>
运行内存：1核2G

<br>
系统内存：40G

<br>
MySQL
# user
root

# password
dwjadmin


<br>
<br><br>
<br>flask项目，见上述第5大点
<br><br><br>
<br>
2023年8月25日 13:00:00 创建，2024年3月25日 23:59:59 到期，共7个月

<br>
提供服务云厂商：阿里云

<br>
操作系统：Alibaba Cloud Linux 3.2104 LTS 64位

<br>
运行内存：1核2G

<br>
系统内存：40G

<br>
cat /etc/os-release


<br><br>
<br>
<br><br><br>
<br>
2023-07-07 00:03:00 创建，2024-07-07 00:03:00到期，共一年

<br>
提供云服务厂商：腾讯云

<br><br>
<br>
2023-08-26 23:26:07 创建，2024-08-26 23:26:07 到期，共一年

<br>
提供云服务厂商：阿里云

<br><br>
<br>
2023-12-19 22:02:16 创建，2024-12-19 22:02:16 到期，共一年

<br>
提供云服务厂商：阿里云

]]></description><link>technology\tools\web.html</link><guid isPermaLink="false">Technology/Tools/Web.md</guid><pubDate>Tue, 16 Jan 2024 03:34:40 GMT</pubDate><enclosure url="https://s2.loli.net/2023/08/27/wUzX3LYuhyvJHnj.png" length="0" type="image/png"/><content:encoded>&lt;figure&gt;&lt;img src=&quot;https://s2.loli.net/2023/08/27/wUzX3LYuhyvJHnj.png&quot;&gt;&lt;/figure&gt;</content:encoded></item><item><title><![CDATA[标签管理]]></title><description><![CDATA[<a class="tag" href="?query=tag:科技" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技</a> <a class="tag" href="?query=tag:科技/工具" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具</a> <a class="tag" href="?query=tag:科技/工具/Jupter" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/Jupter</a> <a class="tag" href="?query=tag:科技/工具/数电" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/数电</a> <a class="tag" href="?query=tag:科技/工具/云服务器" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/云服务器</a> <a class="tag" href="?query=tag:科技/工具/Linux" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/Linux</a> <a class="tag" href="?query=tag:科技/工具/MMaction2" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/工具/MMaction2</a> <a class="tag" href="?query=tag:科技/算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/算法</a> <a class="tag" href="?query=tag:科技/数据结构算法" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/数据结构算法</a> <a class="tag" href="?query=tag:科技/算法/算法设计" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/算法/算法设计</a> <a class="tag" href="?query=tag:科技/人工智能" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能</a> <a class="tag" href="?query=tag:科技/人工智能/机器学习" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/人工智能/机器学习</a> <a class="tag" href="?query=tag:科技/操作系统" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统</a> <a class="tag" href="?query=tag:科技/操作系统/PA" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/操作系统/PA</a> <a class="tag" href="?query=tag:科技/cplusplus" style="background-color: rgb(4, 108, 116); color: white; font-weight: 700; border: none; border-radius: 1em; padding: 0.2em 0.5em;">#科技/cplusplus</a> 
 <br><a href=".?query=tag:科技" class="tag" target="_blank" rel="noopener nofollow">#科技</a> <br>
<br><a href=".?query=tag:科技\工具" class="tag" target="_blank" rel="noopener nofollow">#科技/工具</a>

<br><a href=".?query=tag:科技\工具\Jupter" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/Jupter</a> 
<br><a href=".?query=tag:科技\工具\数电" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/数电</a> 
<br><a href=".?query=tag:科技\工具\云服务器" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/云服务器</a>
<br><a href=".?query=tag:科技\工具\Linux" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/Linux</a> 
<br><a href=".?query=tag:科技\工具\MMaction2" class="tag" target="_blank" rel="noopener nofollow">#科技/工具/MMaction2</a> 


<br><a href=".?query=tag:科技\算法" class="tag" target="_blank" rel="noopener nofollow">#科技/算法</a>

<br><a href=".?query=tag:科技\数据结构算法" class="tag" target="_blank" rel="noopener nofollow">#科技/数据结构算法</a>
<br><a href=".?query=tag:科技\算法\算法设计" class="tag" target="_blank" rel="noopener nofollow">#科技/算法/算法设计</a> 


<br><a href=".?query=tag:科技\人工智能" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能</a> 

<br><a href=".?query=tag:科技\人工智能\机器学习" class="tag" target="_blank" rel="noopener nofollow">#科技/人工智能/机器学习</a>


<br><a href=".?query=tag:科技\操作系统" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统</a>

<br><a href=".?query=tag:科技\操作系统\PA" class="tag" target="_blank" rel="noopener nofollow">#科技/操作系统/PA</a>


<br><a href=".?query=tag:科技\cplusplus" class="tag" target="_blank" rel="noopener nofollow">#科技/cplusplus</a>
]]></description><link>technology\标签管理.html</link><guid isPermaLink="false">Technology/标签管理.md</guid><pubDate>Mon, 08 Apr 2024 01:59:52 GMT</pubDate></item><item><title><![CDATA[index]]></title><description><![CDATA[ 
 <br><br>Hi,welcome to my page.<br><br>Email:<a data-tooltip-position="top" aria-label="mailto:aisaberli0423@gmail.com" rel="noopener nofollow" class="external-link" href="mailto:aisaberli0423@gmail.com" target="_blank">aisaberli0423@gmail.com</a><br>
QQ:2835817201<br><br><a data-href="Waferen - CV(English Version)" href="\resume\waferen-cv(english-version).html" class="internal-link" target="_self" rel="noopener nofollow">Waferen - CV(English Version)</a><br>
<a data-href="李世博 - CV(中文版本)" href="\resume\李世博-cv(中文版本).html" class="internal-link" target="_self" rel="noopener nofollow">李世博 - CV(中文版本)</a><br><br>
<br><a data-href="C++" href="\technology\collegeproject\编程语言\c++\c++.html" class="internal-link" target="_self" rel="noopener nofollow">C++</a>
<br><a data-href="数据结构" href="\technology\collegeproject\数据结构\数据结构.html" class="internal-link" target="_self" rel="noopener nofollow">数据结构</a>
<br><a data-href="云服务器" href="\technology\tools\云服务器.html" class="internal-link" target="_self" rel="noopener nofollow">云服务器</a>
<br><a data-href="Git" href="\technology\tools\git.html" class="internal-link" target="_self" rel="noopener nofollow">Git</a>
<br><a data-href="数学建模" href="\technology\数学建模\数学建模.html" class="internal-link" target="_self" rel="noopener nofollow">数学建模</a>
<br><a data-href="机器学习" href="\technology\collegeproject\机器学习\机器学习.html" class="internal-link" target="_self" rel="noopener nofollow">机器学习</a>
<br><a data-href="算法" href="\technology\collegeproject\算法设计\算法.html" class="internal-link" target="_self" rel="noopener nofollow">算法</a>
<br><br><a data-href="正在做的事" href="\plan\正在做的事.html" class="internal-link" target="_self" rel="noopener nofollow">正在做的事</a><br><br><a data-href="教育学" href="\culture\教育学\教育学.html" class="internal-link" target="_self" rel="noopener nofollow">教育学</a><br><br><a data-href="思想" href="\culture\思想\思想.html" class="internal-link" target="_self" rel="noopener nofollow">思想</a><br><br><a data-href="阅读" href="\culture\阅读\阅读.html" class="internal-link" target="_self" rel="noopener nofollow">阅读</a><br><br><a data-href="小说" href="\culture\小说\小说.html" class="internal-link" target="_self" rel="noopener nofollow">小说</a>]]></description><link>index.html</link><guid isPermaLink="false">index.md</guid><pubDate>Sun, 12 Jan 2025 03:05:03 GMT</pubDate></item></channel></rss>